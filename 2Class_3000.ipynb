{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOw/XyfpEGUalwNNGi8b6jp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kittikhun62/efficientnet_keras_transfer_learning/blob/master/2Class_3000.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# import from drive"
      ],
      "metadata": {
        "id": "_2DRC-anSxem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "BVIqfqC1DtDt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f367caf6-b717-40a8-914c-9366a69c0a3d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "S1vTfbZAhkbI"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline\n",
        "     "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## hyper parameter\n"
      ],
      "metadata": {
        "id": "T529UM_tVV-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "width = 150\n",
        "height = 150\n",
        "\n",
        "epochs = 1000 #จำนวนรอบในการ Train\n",
        "\n",
        "NUM_TRAIN = 598  # จำนวนภาพ Train\n",
        "NUM_TEST = 101 #จำนวนภาพ Test\n",
        "\n",
        "dropout_rate = 0.3\n",
        "input_shape = (height, width, 3) #ขนาด image enter"
      ],
      "metadata": {
        "id": "zXpmkJ2GVZ1l"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone efficientnet repo"
      ],
      "metadata": {
        "id": "DSSZIFGhUyQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/"
      ],
      "metadata": {
        "id": "nFvKcuBDTj1N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0126effd-9dbe-4bec-8e47-229965137118"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 779, done.\u001b[K\n",
            "remote: Counting objects: 100% (301/301), done.\u001b[K\n",
            "remote: Compressing objects: 100% (114/114), done.\u001b[K\n",
            "remote: Total 779 (delta 219), reused 248 (delta 187), pack-reused 478\u001b[K\n",
            "Receiving objects: 100% (779/779), 13.20 MiB | 38.29 MiB/s, done.\n",
            "Resolving deltas: 100% (459/459), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import efficientnet and load the conv base model"
      ],
      "metadata": {
        "id": "j3EgSOiSZHaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "iI3DQ18HU2TF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/My Drive/new project'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Directories for our training,\n",
        "# validation and test splits\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.makedirs(test_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "fCWiYGPMhsCg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load model"
      ],
      "metadata": {
        "id": "qyqFwhs8h-F4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/new/2Class_2000.h5')\n",
        "\n",
        "from efficientnet.layers import Swish, DropConnect\n",
        "from efficientnet.model import ConvKernalInitializer\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "\n",
        "get_custom_objects().update({\n",
        "    'ConvKernalInitializer': ConvKernalInitializer,\n",
        "    'Swish': Swish,\n",
        "    'DropConnect':DropConnect\n",
        "})"
      ],
      "metadata": {
        "id": "PD1ngaxDh9tq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load model \n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/drive/My Drive/new/2Class_2000.h5')\n",
        "height = width = model.input_shape[1]"
      ],
      "metadata": {
        "id": "9d1GnaRniIaK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "iqfZypmOiNsI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce37ea74-dda2-4a46-b43c-0fe324ca23cb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 2)                 2562      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,052,126\n",
            "Trainable params: 2,562\n",
            "Non-trainable params: 4,049,564\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting data augmentation"
      ],
      "metadata": {
        "id": "X9Xfp10TY9xE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "#Image Augmentation \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, # image input 0-255 --> 0-1 เปลี่ยนค่าสี\n",
        "      rotation_range=40,# หมุนภาพในองศา\n",
        "      width_shift_range=0.2, #เปลี่ยนความกว้าง\n",
        "      height_shift_range=0.2, #ปลี่ยนความสูง\n",
        "      shear_range=0.2, #ทำให้ภาพเบี้ยว\n",
        "      zoom_range=0.2, # Randomly zoom image\n",
        "      horizontal_flip=True, \n",
        "      #โดย Default เมื่อมีการเลื่อนภาพ บิดภาพ หมุนภาพ จะเกิดพื้นที่ว่างที่มุม \n",
        "      #ซึ่งจะมีการเติมภาพให้เต็มโดยใช้เทคนิคแบบ Nearest neighbor ซึ่งเป็นการดึงสีบริเวณใหล้าเคียงมาระบายให้เต็ม แต่เราก็ยังสามารถกำหนดวิธีการ Fill ภาพด้วยเทคนิคอื่นได้จาก Parameter fill_mode\n",
        "      fill_mode='nearest')\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory #ไดเรกเป้าหมาย\n",
        "        train_dir,\n",
        "        # รูปภาพทั้งหมดจะถูกปรับขนาดตามความสูงและความกว้างของเป้าหมาย\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        #เนื่องจากเราใช้ categorical_crossentropy loss เราจึงต้องมีป้ายกำกับตามหมวดหมู่\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory( #การดึงภาพจาก Directory มาเข้าโมเดล \n",
        "        validation_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "id": "GC-vPos9Y9HD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4476ae55-bdf5-4e72-86bd-424033293df2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 598 images belonging to 2 classes.\n",
            "Found 101 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "8Egr3yJwiSQ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa421cc8-cdeb-4189-bd06-050388821199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-caa7b37242a8>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "37/37 [==============================] - 39s 731ms/step - loss: 0.5379 - acc: 0.7199 - val_loss: 0.7224 - val_acc: 0.5833\n",
            "Epoch 2/1000\n",
            "37/37 [==============================] - 3s 63ms/step - loss: 0.5576 - acc: 0.7131 - val_loss: 0.7269 - val_acc: 0.5729\n",
            "Epoch 3/1000\n",
            "37/37 [==============================] - 3s 62ms/step - loss: 0.5401 - acc: 0.6993 - val_loss: 0.7202 - val_acc: 0.5833\n",
            "Epoch 4/1000\n",
            "37/37 [==============================] - 3s 63ms/step - loss: 0.5021 - acc: 0.7577 - val_loss: 0.7105 - val_acc: 0.5938\n",
            "Epoch 5/1000\n",
            "37/37 [==============================] - 3s 63ms/step - loss: 0.5174 - acc: 0.7440 - val_loss: 0.7267 - val_acc: 0.5833\n",
            "Epoch 6/1000\n",
            "37/37 [==============================] - 3s 63ms/step - loss: 0.4894 - acc: 0.7509 - val_loss: 0.7031 - val_acc: 0.5938\n",
            "Epoch 7/1000\n",
            "37/37 [==============================] - 3s 61ms/step - loss: 0.5129 - acc: 0.7509 - val_loss: 0.7073 - val_acc: 0.6042\n",
            "Epoch 8/1000\n",
            "37/37 [==============================] - 3s 64ms/step - loss: 0.5004 - acc: 0.7595 - val_loss: 0.7130 - val_acc: 0.5938\n",
            "Epoch 9/1000\n",
            "37/37 [==============================] - 3s 61ms/step - loss: 0.5583 - acc: 0.7182 - val_loss: 0.7171 - val_acc: 0.5938\n",
            "Epoch 10/1000\n",
            "37/37 [==============================] - 3s 62ms/step - loss: 0.5266 - acc: 0.7440 - val_loss: 0.7143 - val_acc: 0.5833\n",
            "Epoch 11/1000\n",
            "37/37 [==============================] - 3s 63ms/step - loss: 0.5451 - acc: 0.7268 - val_loss: 0.7162 - val_acc: 0.5521\n",
            "Epoch 12/1000\n",
            "37/37 [==============================] - 3s 64ms/step - loss: 0.5577 - acc: 0.7320 - val_loss: 0.7071 - val_acc: 0.6042\n",
            "Epoch 13/1000\n",
            "37/37 [==============================] - 3s 67ms/step - loss: 0.5537 - acc: 0.7199 - val_loss: 0.6871 - val_acc: 0.6042\n",
            "Epoch 14/1000\n",
            "37/37 [==============================] - 3s 63ms/step - loss: 0.5542 - acc: 0.6993 - val_loss: 0.6972 - val_acc: 0.5938\n",
            "Epoch 15/1000\n",
            "37/37 [==============================] - 3s 64ms/step - loss: 0.5300 - acc: 0.7268 - val_loss: 0.7033 - val_acc: 0.5208\n",
            "Epoch 16/1000\n",
            "37/37 [==============================] - 3s 63ms/step - loss: 0.5163 - acc: 0.7405 - val_loss: 0.7087 - val_acc: 0.5938\n",
            "Epoch 17/1000\n",
            "37/37 [==============================] - 3s 63ms/step - loss: 0.5066 - acc: 0.7595 - val_loss: 0.6924 - val_acc: 0.5417\n",
            "Epoch 18/1000\n",
            "37/37 [==============================] - 3s 64ms/step - loss: 0.5471 - acc: 0.7247 - val_loss: 0.6981 - val_acc: 0.5521\n",
            "Epoch 19/1000\n",
            "37/37 [==============================] - 3s 62ms/step - loss: 0.5668 - acc: 0.6890 - val_loss: 0.6820 - val_acc: 0.5938\n",
            "Epoch 20/1000\n",
            "37/37 [==============================] - 3s 62ms/step - loss: 0.5337 - acc: 0.7423 - val_loss: 0.6910 - val_acc: 0.6146\n",
            "Epoch 21/1000\n",
            "37/37 [==============================] - 3s 64ms/step - loss: 0.5435 - acc: 0.7234 - val_loss: 0.7041 - val_acc: 0.5521\n",
            "Epoch 22/1000\n",
            "37/37 [==============================] - 3s 65ms/step - loss: 0.5316 - acc: 0.7466 - val_loss: 0.6987 - val_acc: 0.5729\n",
            "Epoch 23/1000\n",
            "37/37 [==============================] - 3s 65ms/step - loss: 0.5324 - acc: 0.7182 - val_loss: 0.7046 - val_acc: 0.5938\n",
            "Epoch 24/1000\n",
            "37/37 [==============================] - 3s 63ms/step - loss: 0.5189 - acc: 0.7354 - val_loss: 0.6910 - val_acc: 0.6042\n",
            "Epoch 25/1000\n",
            "37/37 [==============================] - 3s 63ms/step - loss: 0.5255 - acc: 0.7216 - val_loss: 0.7150 - val_acc: 0.5833\n",
            "Epoch 26/1000\n",
            "37/37 [==============================] - 3s 62ms/step - loss: 0.5306 - acc: 0.7423 - val_loss: 0.7082 - val_acc: 0.5625\n",
            "Epoch 27/1000\n",
            "37/37 [==============================] - 3s 62ms/step - loss: 0.5741 - acc: 0.7113 - val_loss: 0.6942 - val_acc: 0.5729\n",
            "Epoch 28/1000\n",
            "37/37 [==============================] - 3s 62ms/step - loss: 0.5671 - acc: 0.7148 - val_loss: 0.7183 - val_acc: 0.5729\n",
            "Epoch 29/1000\n",
            "37/37 [==============================] - 3s 64ms/step - loss: 0.5534 - acc: 0.6942 - val_loss: 0.6913 - val_acc: 0.6146\n",
            "Epoch 30/1000\n",
            "37/37 [==============================] - 3s 63ms/step - loss: 0.5560 - acc: 0.7216 - val_loss: 0.7054 - val_acc: 0.5938\n",
            "Epoch 31/1000\n",
            "37/37 [==============================] - 3s 62ms/step - loss: 0.5351 - acc: 0.7354 - val_loss: 0.6979 - val_acc: 0.5938\n",
            "Epoch 32/1000\n",
            "37/37 [==============================] - 3s 64ms/step - loss: 0.5738 - acc: 0.7302 - val_loss: 0.7096 - val_acc: 0.5833\n",
            "Epoch 33/1000\n",
            "37/37 [==============================] - 3s 64ms/step - loss: 0.5510 - acc: 0.7079 - val_loss: 0.7103 - val_acc: 0.5938\n",
            "Epoch 34/1000\n",
            "37/37 [==============================] - 3s 63ms/step - loss: 0.5572 - acc: 0.7251 - val_loss: 0.7035 - val_acc: 0.6042\n",
            "Epoch 35/1000\n",
            "37/37 [==============================] - 3s 62ms/step - loss: 0.5249 - acc: 0.7491 - val_loss: 0.7031 - val_acc: 0.5833\n",
            "Epoch 36/1000\n",
            "37/37 [==============================] - 3s 64ms/step - loss: 0.5832 - acc: 0.6993 - val_loss: 0.7041 - val_acc: 0.5625\n",
            "Epoch 37/1000\n",
            "37/37 [==============================] - 3s 64ms/step - loss: 0.5238 - acc: 0.7388 - val_loss: 0.7009 - val_acc: 0.6042\n",
            "Epoch 38/1000\n",
            "37/37 [==============================] - 3s 65ms/step - loss: 0.5342 - acc: 0.6959 - val_loss: 0.7058 - val_acc: 0.6042\n",
            "Epoch 39/1000\n",
            "37/37 [==============================] - 3s 65ms/step - loss: 0.5353 - acc: 0.7285 - val_loss: 0.7123 - val_acc: 0.5938\n",
            "Epoch 40/1000\n",
            "37/37 [==============================] - 3s 65ms/step - loss: 0.5482 - acc: 0.7371 - val_loss: 0.7202 - val_acc: 0.5729\n",
            "Epoch 41/1000\n",
            "37/37 [==============================] - 3s 62ms/step - loss: 0.5210 - acc: 0.7457 - val_loss: 0.6909 - val_acc: 0.6042\n",
            "Epoch 42/1000\n",
            "24/37 [==================>...........] - ETA: 0s - loss: 0.5449 - acc: 0.7273"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Process Keras_worker_ForkPoolWorker-331:\n",
            "Process Keras_worker_ForkPoolWorker-330:\n",
            "Process Keras_worker_ForkPoolWorker-332:\n",
            "Process Keras_worker_ForkPoolWorker-329:\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 580, in get_index\n",
            "    return _SHARED_SEQUENCES[uid][i]\n",
            "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 580, in get_index\n",
            "    return _SHARED_SEQUENCES[uid][i]\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/preprocessing/image.py\", line 110, in __getitem__\n",
            "    return self._get_batches_of_transformed_samples(index_array)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/preprocessing/image.py\", line 110, in __getitem__\n",
            "    return self._get_batches_of_transformed_samples(index_array)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/preprocessing/image.py\", line 350, in _get_batches_of_transformed_samples\n",
            "    x = self.image_data_generator.apply_transform(x, params)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/preprocessing/image.py\", line 1800, in apply_transform\n",
            "    x = apply_affine_transform(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/preprocessing/image.py\", line 337, in _get_batches_of_transformed_samples\n",
            "    img = image_utils.load_img(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 580, in get_index\n",
            "    return _SHARED_SEQUENCES[uid][i]\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/preprocessing/image.py\", line 2324, in apply_affine_transform\n",
            "    channel_images = [ndimage.interpolation.affine_transform(  # pylint: disable=g-complex-comprehension\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/preprocessing/image.py\", line 2324, in <listcomp>\n",
            "    channel_images = [ndimage.interpolation.affine_transform(  # pylint: disable=g-complex-comprehension\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/scipy/ndimage/interpolation.py\", line 557, in affine_transform\n",
            "    output = _ni_support._get_output(output, input, shape=output_shape,\n",
            "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 580, in get_index\n",
            "    return _SHARED_SEQUENCES[uid][i]\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/image_utils.py\", line 393, in load_img\n",
            "    with open(path, 'rb') as f:\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/preprocessing/image.py\", line 110, in __getitem__\n",
            "    return self._get_batches_of_transformed_samples(index_array)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/scipy/ndimage/_ni_support.py\", line 78, in _get_output\n",
            "    output = numpy.zeros(shape, dtype=input.dtype.name)\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/preprocessing/image.py\", line 110, in __getitem__\n",
            "    return self._get_batches_of_transformed_samples(index_array)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/preprocessing/image.py\", line 350, in _get_batches_of_transformed_samples\n",
            "    x = self.image_data_generator.apply_transform(x, params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/preprocessing/image.py\", line 1800, in apply_transform\n",
            "    x = apply_affine_transform(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/preprocessing/image.py\", line 2324, in apply_affine_transform\n",
            "    channel_images = [ndimage.interpolation.affine_transform(  # pylint: disable=g-complex-comprehension\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/preprocessing/image.py\", line 2324, in <listcomp>\n",
            "    channel_images = [ndimage.interpolation.affine_transform(  # pylint: disable=g-complex-comprehension\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/preprocessing/image.py\", line 350, in _get_batches_of_transformed_samples\n",
            "    x = self.image_data_generator.apply_transform(x, params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/numpy/core/_dtype.py\", line 336, in _name_get\n",
            "    name += \"{}\".format(dtype.itemsize * 8)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/scipy/ndimage/interpolation.py\", line 611, in affine_transform\n",
            "    _nd_image.geometric_transform(filtered, None, None, matrix, offset,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/preprocessing/image.py\", line 1800, in apply_transform\n",
            "    x = apply_affine_transform(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/preprocessing/image.py\", line 2324, in apply_affine_transform\n",
            "    channel_images = [ndimage.interpolation.affine_transform(  # pylint: disable=g-complex-comprehension\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/preprocessing/image.py\", line 2324, in <listcomp>\n",
            "    channel_images = [ndimage.interpolation.affine_transform(  # pylint: disable=g-complex-comprehension\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/scipy/ndimage/interpolation.py\", line 611, in affine_transform\n",
            "    _nd_image.geometric_transform(filtered, None, None, matrix, offset,\n",
            "Process Keras_worker_ForkPoolWorker-336:\n",
            "Process Keras_worker_ForkPoolWorker-334:\n",
            "Traceback (most recent call last):\n",
            "Process Keras_worker_ForkPoolWorker-333:\n",
            "Process Keras_worker_ForkPoolWorker-335:\n",
            "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 356, in get\n",
            "    res = self._reader.recv_bytes()\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 216, in recv_bytes\n",
            "    buf = self._recv_bytes(maxlength)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
            "    buf = self._recv(4)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 379, in _recv\n",
            "    chunk = read(handle, remaining)\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'co', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'k', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'co', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iEZRZuH8iVGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('./content/drive/My Drive/new', exist_ok=True)\n",
        "model.save('./content/drive/My Drive/new/2Class_3000.h5')"
      ],
      "metadata": {
        "id": "VWrYGbQbiXjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"./content/drive/My Drive/new/2Class_3000.h5\")"
      ],
      "metadata": {
        "id": "XPm79yKMwkt3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}