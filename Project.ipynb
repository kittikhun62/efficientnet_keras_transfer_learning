{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOq/0u+KP04CqmG3RY9uUN8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kittikhun62/efficientnet_keras_transfer_learning/blob/master/Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# import from drive"
      ],
      "metadata": {
        "id": "_2DRC-anSxem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "BVIqfqC1DtDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (r'/content/drive/My Drive/data - All SEM.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "gABRUdVwDtBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## hist check class"
      ],
      "metadata": {
        "id": "WMazXBQcTMl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "W34NcexJDs_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.hist();"
      ],
      "metadata": {
        "id": "Fm07UpEbDs5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = df['BET']\n",
        "\n",
        "fig, ax = plt.subplots(figsize =(10, 5))\n",
        "ax.hist(a, bins = 200)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bxfNFKW2TXAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ['0-500','501-1000','1001-3200']\n",
        "len(classes)"
      ],
      "metadata": {
        "id": "TBsLszHgTW-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone efficientnet repo"
      ],
      "metadata": {
        "id": "DSSZIFGhUyQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/"
      ],
      "metadata": {
        "id": "nFvKcuBDTj1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# การเเบ่งข้อมูล train/validation/test sets"
      ],
      "metadata": {
        "id": "JDJCDzEDWnVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/My Drive/Project'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Directories for our training,\n",
        "# validation and test splits\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.makedirs(test_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "R7L0rJNRU2MY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_1_dir = os.path.join(train_dir, '0-500')\n",
        "os.makedirs(train_1_dir, exist_ok=True)\n",
        "\n",
        "train_2_dir = os.path.join(train_dir, '501-1000')\n",
        "os.makedirs(train_2_dir, exist_ok=True)\n",
        "\n",
        "train_3_dir = os.path.join(train_dir, '1001-3200')\n",
        "os.makedirs(train_3_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "validation_1_dir = os.path.join(validation_dir, '0-500')\n",
        "os.makedirs(validation_1_dir, exist_ok=True)\n",
        "\n",
        "validation_2_dir = os.path.join(validation_dir, '501-1000')\n",
        "os.makedirs(validation_2_dir, exist_ok=True)\n",
        "\n",
        "validation_3_dir = os.path.join(validation_dir, '1001-3200')\n",
        "os.makedirs(validation_3_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "test_1_dir = os.path.join(test_dir, '0-500')\n",
        "os.makedirs(test_1_dir, exist_ok=True)\n",
        "\n",
        "test_2_dir = os.path.join(test_dir, '501-1000')\n",
        "os.makedirs(test_2_dir, exist_ok=True)\n",
        "\n",
        "test_3_dir = os.path.join(test_dir, '1001-3200')\n",
        "os.makedirs(test_3_dir, exist_ok=True)\n",
        "     "
      ],
      "metadata": {
        "id": "jtyFMXrWU2KD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val = df[df['No'].between(257,289)]\n",
        "train = df[df['No'].between(1,256)]\n",
        "test = df[df['No'].between(290,320)] \n",
        "\n",
        "#Path Train\n",
        "T1_train = train[train['Class']=='0-500' ]\n",
        "T1_path_train = T1_train['path_Picture'].tolist() \n",
        "T2_train = train[train['Class']=='501-1000' ]\n",
        "T2_path_train = T2_train['path_Picture'].tolist() \n",
        "T3_train = train[train['Class']=='1001-3200' ]\n",
        "T3_path_train = T3_train['path_Picture'].tolist()\n",
        "\n",
        "#Path Validation\n",
        "T1_val = val[val['Class']=='0-500' ]\n",
        "T1_path_val = T1_val['path_Picture'].tolist() \n",
        "T2_val = val[val['Class']=='501-1000' ]\n",
        "T2_path_val = T2_val['path_Picture'].tolist() \n",
        "T3_val = val[val['Class']=='1001-3200']\n",
        "T3_path_val = T3_val['path_Picture'].tolist()\n",
        "\n",
        "\n",
        "#Path Test\n",
        "T1_test = test[test['Class']=='0-500' ]\n",
        "T1_path_test = T1_test['path_Picture'].tolist() \n",
        "T2_test = test[test['Class']=='501-1000' ]\n",
        "T2_path_test = T2_test['path_Picture'].tolist() \n",
        "T3_test = test[test['Class']=='1001-3200']\n",
        "T3_path_test = T3_test['path_Picture'].tolist()"
      ],
      "metadata": {
        "id": "mlmd_kyhW2LZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "ZkfPduNQW43l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fnames = T1_path_train\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_1_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "fnames = T2_path_train\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_2_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "    \n",
        "fnames = T3_path_train \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_3_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)"
      ],
      "metadata": {
        "id": "9jMgUluKU2Hp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test"
      ],
      "metadata": {
        "id": "Mj3sViKJaLSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fnames = T1_path_test\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_1_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "fnames = T2_path_test\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_2_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "    \n",
        "fnames = T3_path_test \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_3_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)"
      ],
      "metadata": {
        "id": "WvK0Y2FIYat1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Validation"
      ],
      "metadata": {
        "id": "rc4HwwbPaD6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fnames = T1_path_val\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(test_1_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "fnames = T2_path_val\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(test_2_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "    \n",
        "fnames = T3_path_val \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(test_3_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)"
      ],
      "metadata": {
        "id": "XxtmCbyUYarp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('total training 1 images:', len(os.listdir(train_1_dir))) \n",
        "print('total training 2 images:', len(os.listdir(train_2_dir)))\n",
        "print('total training 3 images:', len(os.listdir(train_3_dir)),'\\n')\n",
        "\n",
        "\n",
        "print('total validation 1 images:', len(os.listdir(validation_1_dir)))\n",
        "print('total validation 2 images:', len(os.listdir(validation_2_dir)))\n",
        "print('total validation 3 images:', len(os.listdir(validation_3_dir)),'\\n')\n",
        "\n",
        "\n",
        "print('total test 1 images:', len(os.listdir(test_1_dir)))\n",
        "print('total test 2 images:', len(os.listdir(test_2_dir)))\n",
        "print('total test 3 images:', len(os.listdir(test_3_dir)),'\\n')"
      ],
      "metadata": {
        "id": "Tvk53f-WYapl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports library"
      ],
      "metadata": {
        "id": "VkYa-4LeTbir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "myAsBcVhTW7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## hyper parameter\n"
      ],
      "metadata": {
        "id": "T529UM_tVV-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 20\n",
        "\n",
        "width = 150\n",
        "height = 150\n",
        "\n",
        "epochs = 1000 #จำนวนรอบในการ Train\n",
        "\n",
        "NUM_TRAIN = 300  # จำนวนภาพ Train\n",
        "NUM_TEST = 20 #จำนวนภาพ Test\n",
        "\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3) #ขนาด image enter"
      ],
      "metadata": {
        "id": "zXpmkJ2GVZ1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import efficientnet and load the conv base model"
      ],
      "metadata": {
        "id": "j3EgSOiSZHaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "iI3DQ18HU2TF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "#EfficientNet สร้างขึ้นสำหรับการจำแนกประเภท ImageNet ประกอบด้วยป้ายกำกับคลาส 1,000 รายการ เรามีเพียง 2 เลเยอร์เท่านั้น ซึ่งหมายความว่าเลเยอร์สองสามเลเยอร์สุดท้ายสำหรับการจำแนกไม่มีประโยชน์สำหรับเรา สามารถยกเว้นได้ขณะโหลดโมเดลโดยระบุอาร์กิวเมนต์ include_top เป็น False และนำไปใช้กับโมเดล ImageNet อื่นๆ ที่มีอยู่ในแอปพลิเคชัน Keras เช่นกัน\n",
        "\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "UmBDAgF_VAjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "id": "rRXoFFzfU2Oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting data augmentation"
      ],
      "metadata": {
        "id": "X9Xfp10TY9xE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "#Image Augmentation \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, # image input 0-255 --> 0-1 เปลี่ยนค่าสี\n",
        "      rotation_range=40,# หมุนภาพในองศา\n",
        "      width_shift_range=0.2, #เปลี่ยนความกว้าง\n",
        "      height_shift_range=0.2, #ปลี่ยนความสูง\n",
        "      shear_range=0.2, #ทำให้ภาพเบี้ยว\n",
        "      zoom_range=0.2, # Randomly zoom image\n",
        "      horizontal_flip=True, \n",
        "      #โดย Default เมื่อมีการเลื่อนภาพ บิดภาพ หมุนภาพ จะเกิดพื้นที่ว่างที่มุม \n",
        "      #ซึ่งจะมีการเติมภาพให้เต็มโดยใช้เทคนิคแบบ Nearest neighbor ซึ่งเป็นการดึงสีบริเวณใหล้าเคียงมาระบายให้เต็ม แต่เราก็ยังสามารถกำหนดวิธีการ Fill ภาพด้วยเทคนิคอื่นได้จาก Parameter fill_mode\n",
        "      fill_mode='nearest')\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory #ไดเรกเป้าหมาย\n",
        "        train_dir,\n",
        "        # รูปภาพทั้งหมดจะถูกปรับขนาดตามความสูงและความกว้างของเป้าหมาย\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        #เนื่องจากเราใช้ categorical_crossentropy loss เราจึงต้องมีป้ายกำกับตามหมวดหมู่\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory( #การดึงภาพจาก Directory มาเข้าโมเดล \n",
        "        validation_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "id": "GC-vPos9Y9HD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Show architecture model"
      ],
      "metadata": {
        "id": "W1JJhCEWZjiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดัดแปลง GlobalMaxPooling2D เพื่อแปลง 4D the (batch_size, rows, cols,channels) tensor เป็น 2D tensor with shape (batch_size,channels)\n",
        "#GlobalMaxPooling2D ส่งผลให้มีจำนวนฟีเจอร์น้อยกว่ามากเมื่อเทียบกับเลเยอร์ Flatten ซึ่งช่วยลดจำนวนพารามิเตอร์ได้อย่างมีประสิทธิภาพ\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
        "# model.add(layers.Flatten(name=\"flatten\"))\n",
        "if dropout_rate > 0:\n",
        "    model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n",
        "# model.add(layers.Dense(256, activation='relu', name=\"fc1\"))\n",
        "model.add(layers.Dense(3, activation='softmax', name=\"fc_out\"))"
      ],
      "metadata": {
        "id": "-9EQ5AdjZT9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "wmBUcgsMZVkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('This is the number of trainable layers '\n",
        "      'before freezing the conv base:', len(model.trainable_weights))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "print('This is the number of trainable layers '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ],
      "metadata": {
        "id": "xRyPafCIZXzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "8S60IpOWcB7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
        "              metrics=['acc'])\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "Od8zqlOwb9Iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.history"
      ],
      "metadata": {
        "id": "tO_KJFVJu6ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot training performance"
      ],
      "metadata": {
        "id": "54D1y5fZcRUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Aig-yHOBcNrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine tuning last several layers.\n"
      ],
      "metadata": {
        "id": "SjMIiVzEedXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# multiply_16\n",
        "# set 'multiply_16' and following layers trainable\n",
        "conv_base.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'multiply_16':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False"
      ],
      "metadata": {
        "id": "sWUrVteMd7Dp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "ZPTA-GaQiYwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "K97nCJbgkx2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SAVE model** "
      ],
      "metadata": {
        "id": "okE8lIwPkoSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#os.makedirs(\"./content/drive/My Drive/new\", exist_ok=True)\n",
        "#model.save('./content/drive/My Drive/new/Sem_BET.h5')"
      ],
      "metadata": {
        "id": "f_Xlg2XSuT9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#os.makedirs(\"./models\", exist_ok=True)\n",
        "#model.save('./models/SEM')"
      ],
      "metadata": {
        "id": "Ho8u8un7m6P9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#os.makedirs(\"./models\", exist_ok=True)\n",
        "#model.save('./models/Sem_BET.h5')"
      ],
      "metadata": {
        "id": "jqg0OYYtijKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('./content/drive/My Drive/new/SEM.h5')"
      ],
      "metadata": {
        "id": "6qmnKVpZysnx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}