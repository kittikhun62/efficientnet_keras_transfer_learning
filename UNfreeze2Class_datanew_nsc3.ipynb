{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOIP27zeEr9DKL9DDu4IYtR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kittikhun62/efficientnet_keras_transfer_learning/blob/master/UNfreeze2Class_datanew_nsc3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# import from drive"
      ],
      "metadata": {
        "id": "bB2gfuYWczY-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpXyZ9k5YIJu",
        "outputId": "cd823e2c-9137-454c-8e39-2262bb026871"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (r'/content/drive/My Drive/data_nsc - ใช้อันนี้เทรน.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "7mqo2OLAc2pG",
        "outputId": "55bf2360-85f1-4984-c7ad-9e1b88bc27f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        No                                          Name_file  \\\n",
              "0        1  /content/drive/My Drive/modelnsc/acssuschemeng...   \n",
              "1        2  /content/drive/My Drive/modelnsc/acssuschemeng...   \n",
              "2        3  /content/drive/My Drive/modelnsc/acssuschemeng...   \n",
              "3        4  /content/drive/My Drive/modelnsc/acssuschemeng...   \n",
              "4        5  /content/drive/My Drive/modelnsc/acssuschemeng...   \n",
              "...    ...                                                ...   \n",
              "1321  1322                      1-s2.0-S0926669022000292-main   \n",
              "1322  1323                      1-s2.0-S0926669022000292-main   \n",
              "1323  1324                      1-s2.0-S0926669022000292-main   \n",
              "1324  1325                      1-s2.0-S0926669022000292-main   \n",
              "1325  1326                      1-s2.0-S0926669022000292-main   \n",
              "\n",
              "                                             Name_Paper  \\\n",
              "0     Sugarcane Biowaste-Derived Biochars as Capacit...   \n",
              "1     Sugarcane Biowaste-Derived Biochars as Capacit...   \n",
              "2     Sugarcane Biowaste-Derived Biochars as Capacit...   \n",
              "3     Sugarcane Biowaste-Derived Biochars as Capacit...   \n",
              "4     Sugarcane Biowaste-Derived Biochars as Capacit...   \n",
              "...                                                 ...   \n",
              "1321  Low-cost activated carbon preparation from Cor...   \n",
              "1322  Low-cost activated carbon preparation from Cor...   \n",
              "1323  Low-cost activated carbon preparation from Cor...   \n",
              "1324  Low-cost activated carbon preparation from Cor...   \n",
              "1325  Low-cost activated carbon preparation from Cor...   \n",
              "\n",
              "                                journal  \\\n",
              "0     Sustainable Chemistry&Engineering   \n",
              "1     Sustainable Chemistry&Engineering   \n",
              "2     Sustainable Chemistry&Engineering   \n",
              "3     Sustainable Chemistry&Engineering   \n",
              "4     Sustainable Chemistry&Engineering   \n",
              "...                                 ...   \n",
              "1321        Industrial Crops & Products   \n",
              "1322        Industrial Crops & Products   \n",
              "1323        Industrial Crops & Products   \n",
              "1324        Industrial Crops & Products   \n",
              "1325        Industrial Crops & Products   \n",
              "\n",
              "                                           path_Picture    detail     Class  \\\n",
              "0     /content/drive/My Drive/modelnsc/acssuschemeng...  original     0-400   \n",
              "1     /content/drive/My Drive/modelnsc/acssuschemeng...   resize1     0-400   \n",
              "2     /content/drive/My Drive/modelnsc/acssuschemeng...   resize2     0-400   \n",
              "3     /content/drive/My Drive/modelnsc/acssuschemeng...   resize3     0-400   \n",
              "4     /content/drive/My Drive/modelnsc/acssuschemeng...   resize4     0-400   \n",
              "...                                                 ...       ...       ...   \n",
              "1321  /content/drive/My Drive/modelnsc/1-s2.0-S09266...  original  401-3200   \n",
              "1322  /content/drive/My Drive/modelnsc/1-s2.0-S09266...  original  401-3200   \n",
              "1323  /content/drive/My Drive/modelnsc/1-s2.0-S09266...  original  401-3200   \n",
              "1324  /content/drive/My Drive/modelnsc/1-s2.0-S09266...  original     0-400   \n",
              "1325  /content/drive/My Drive/modelnsc/1-s2.0-S09266...  original     0-400   \n",
              "\n",
              "        BET  Size(mico)  \n",
              "0     240.0          10  \n",
              "1     240.0          20  \n",
              "2     240.0          20  \n",
              "3     240.0          20  \n",
              "4     240.0          20  \n",
              "...     ...         ...  \n",
              "1321  583.0          10  \n",
              "1322  820.0          10  \n",
              "1323  589.0          10  \n",
              "1324  389.0          10  \n",
              "1325   11.0          10  \n",
              "\n",
              "[1326 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9524e230-4791-491d-a811-b5e51c21a554\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>No</th>\n",
              "      <th>Name_file</th>\n",
              "      <th>Name_Paper</th>\n",
              "      <th>journal</th>\n",
              "      <th>path_Picture</th>\n",
              "      <th>detail</th>\n",
              "      <th>Class</th>\n",
              "      <th>BET</th>\n",
              "      <th>Size(mico)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>/content/drive/My Drive/modelnsc/acssuschemeng...</td>\n",
              "      <td>Sugarcane Biowaste-Derived Biochars as Capacit...</td>\n",
              "      <td>Sustainable Chemistry&amp;Engineering</td>\n",
              "      <td>/content/drive/My Drive/modelnsc/acssuschemeng...</td>\n",
              "      <td>original</td>\n",
              "      <td>0-400</td>\n",
              "      <td>240.0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>/content/drive/My Drive/modelnsc/acssuschemeng...</td>\n",
              "      <td>Sugarcane Biowaste-Derived Biochars as Capacit...</td>\n",
              "      <td>Sustainable Chemistry&amp;Engineering</td>\n",
              "      <td>/content/drive/My Drive/modelnsc/acssuschemeng...</td>\n",
              "      <td>resize1</td>\n",
              "      <td>0-400</td>\n",
              "      <td>240.0</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>/content/drive/My Drive/modelnsc/acssuschemeng...</td>\n",
              "      <td>Sugarcane Biowaste-Derived Biochars as Capacit...</td>\n",
              "      <td>Sustainable Chemistry&amp;Engineering</td>\n",
              "      <td>/content/drive/My Drive/modelnsc/acssuschemeng...</td>\n",
              "      <td>resize2</td>\n",
              "      <td>0-400</td>\n",
              "      <td>240.0</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>/content/drive/My Drive/modelnsc/acssuschemeng...</td>\n",
              "      <td>Sugarcane Biowaste-Derived Biochars as Capacit...</td>\n",
              "      <td>Sustainable Chemistry&amp;Engineering</td>\n",
              "      <td>/content/drive/My Drive/modelnsc/acssuschemeng...</td>\n",
              "      <td>resize3</td>\n",
              "      <td>0-400</td>\n",
              "      <td>240.0</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>/content/drive/My Drive/modelnsc/acssuschemeng...</td>\n",
              "      <td>Sugarcane Biowaste-Derived Biochars as Capacit...</td>\n",
              "      <td>Sustainable Chemistry&amp;Engineering</td>\n",
              "      <td>/content/drive/My Drive/modelnsc/acssuschemeng...</td>\n",
              "      <td>resize4</td>\n",
              "      <td>0-400</td>\n",
              "      <td>240.0</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1321</th>\n",
              "      <td>1322</td>\n",
              "      <td>1-s2.0-S0926669022000292-main</td>\n",
              "      <td>Low-cost activated carbon preparation from Cor...</td>\n",
              "      <td>Industrial Crops &amp; Products</td>\n",
              "      <td>/content/drive/My Drive/modelnsc/1-s2.0-S09266...</td>\n",
              "      <td>original</td>\n",
              "      <td>401-3200</td>\n",
              "      <td>583.0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1322</th>\n",
              "      <td>1323</td>\n",
              "      <td>1-s2.0-S0926669022000292-main</td>\n",
              "      <td>Low-cost activated carbon preparation from Cor...</td>\n",
              "      <td>Industrial Crops &amp; Products</td>\n",
              "      <td>/content/drive/My Drive/modelnsc/1-s2.0-S09266...</td>\n",
              "      <td>original</td>\n",
              "      <td>401-3200</td>\n",
              "      <td>820.0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1323</th>\n",
              "      <td>1324</td>\n",
              "      <td>1-s2.0-S0926669022000292-main</td>\n",
              "      <td>Low-cost activated carbon preparation from Cor...</td>\n",
              "      <td>Industrial Crops &amp; Products</td>\n",
              "      <td>/content/drive/My Drive/modelnsc/1-s2.0-S09266...</td>\n",
              "      <td>original</td>\n",
              "      <td>401-3200</td>\n",
              "      <td>589.0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1324</th>\n",
              "      <td>1325</td>\n",
              "      <td>1-s2.0-S0926669022000292-main</td>\n",
              "      <td>Low-cost activated carbon preparation from Cor...</td>\n",
              "      <td>Industrial Crops &amp; Products</td>\n",
              "      <td>/content/drive/My Drive/modelnsc/1-s2.0-S09266...</td>\n",
              "      <td>original</td>\n",
              "      <td>0-400</td>\n",
              "      <td>389.0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1325</th>\n",
              "      <td>1326</td>\n",
              "      <td>1-s2.0-S0926669022000292-main</td>\n",
              "      <td>Low-cost activated carbon preparation from Cor...</td>\n",
              "      <td>Industrial Crops &amp; Products</td>\n",
              "      <td>/content/drive/My Drive/modelnsc/1-s2.0-S09266...</td>\n",
              "      <td>original</td>\n",
              "      <td>0-400</td>\n",
              "      <td>11.0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1326 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9524e230-4791-491d-a811-b5e51c21a554')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9524e230-4791-491d-a811-b5e51c21a554 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9524e230-4791-491d-a811-b5e51c21a554');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports library"
      ],
      "metadata": {
        "id": "VkYa-4LeTbir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "myAsBcVhTW7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## hyper parameter\n"
      ],
      "metadata": {
        "id": "T529UM_tVV-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "width = 150\n",
        "height = 150\n",
        "\n",
        "epochs = 1000 #จำนวนรอบในการ Train\n",
        "\n",
        "NUM_TRAIN = 1272  # จำนวนภาพ Train\n",
        "NUM_TEST = 22 #จำนวนภาพ Test\n",
        "\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3) #ขนาด image enter"
      ],
      "metadata": {
        "id": "zXpmkJ2GVZ1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone efficientnet repo"
      ],
      "metadata": {
        "id": "DSSZIFGhUyQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/"
      ],
      "metadata": {
        "id": "nFvKcuBDTj1N",
        "outputId": "21548e8d-076e-4f27-aa97-eae71a34be4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 1100, done.\u001b[K\n",
            "remote: Counting objects: 100% (263/263), done.\u001b[K\n",
            "remote: Compressing objects: 100% (142/142), done.\u001b[K\n",
            "remote: Total 1100 (delta 133), reused 241 (delta 121), pack-reused 837\u001b[K\n",
            "Receiving objects: 100% (1100/1100), 14.10 MiB | 15.56 MiB/s, done.\n",
            "Resolving deltas: 100% (630/630), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import efficientnet and load the conv base model"
      ],
      "metadata": {
        "id": "j3EgSOiSZHaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "iI3DQ18HU2TF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "#EfficientNet สร้างขึ้นสำหรับการจำแนกประเภท ImageNet ประกอบด้วยป้ายกำกับคลาส 1,000 รายการ เรามีเพียง 2 เลเยอร์เท่านั้น ซึ่งหมายความว่าเลเยอร์สองสามเลเยอร์สุดท้ายสำหรับการจำแนกไม่มีประโยชน์สำหรับเรา สามารถยกเว้นได้ขณะโหลดโมเดลโดยระบุอาร์กิวเมนต์ include_top เป็น False และนำไปใช้กับโมเดล ImageNet อื่นๆ ที่มีอยู่ในแอปพลิเคชัน Keras เช่นกัน\n",
        "\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "UmBDAgF_VAjq",
        "outputId": "65cd4987-4717-4dac-f4d3-beda6e5147ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "id": "rRXoFFzfU2Oi",
        "outputId": "24a4ac06-8c73-41a0-96eb-23dc66752fb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 4,007,548\n",
            "Non-trainable params: 42,016\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/new/nsc.h5')\n",
        "\n",
        "from efficientnet.layers import Swish, DropConnect\n",
        "from efficientnet.model import ConvKernalInitializer\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "\n",
        "get_custom_objects().update({\n",
        "    'ConvKernalInitializer': ConvKernalInitializer,\n",
        "    'Swish': Swish,\n",
        "    'DropConnect':DropConnect\n",
        "})"
      ],
      "metadata": {
        "id": "MwNk3sNbc2Qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load model \n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/drive/My Drive/new/nsc.h5')\n",
        "height = width = model.input_shape[1]"
      ],
      "metadata": {
        "id": "4v4nzKQtJZ4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/My Drive/modeldatansc'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Directories for our training,\n",
        "# validation and test splits\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.makedirs(test_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "UDxvF-b8Jcq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, # image input 0-255 --> 0-1 เปลี่ยนค่าสี\n",
        "      rotation_range=40,# หมุนภาพในองศา\n",
        "      width_shift_range=0.2, #เปลี่ยนความกว้าง\n",
        "      height_shift_range=0.2, #ปลี่ยนความสูง\n",
        "      shear_range=0.2, #ทำให้ภาพเบี้ยว\n",
        "      zoom_range=0.2, # Randomly zoom image\n",
        "      horizontal_flip=True, \n",
        "      #โดย Default เมื่อมีการเลื่อนภาพ บิดภาพ หมุนภาพ จะเกิดพื้นที่ว่างที่มุม \n",
        "      #ซึ่งจะมีการเติมภาพให้เต็มโดยใช้เทคนิคแบบ Nearest neighbor ซึ่งเป็นการดึงสีบริเวณใหล้าเคียงมาระบายให้เต็ม แต่เราก็ยังสามารถกำหนดวิธีการ Fill ภาพด้วยเทคนิคอื่นได้จาก Parameter fill_mode\n",
        "      fill_mode='nearest')\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory #ไดเรกเป้าหมาย\n",
        "        train_dir,\n",
        "        # รูปภาพทั้งหมดจะถูกปรับขนาดตามความสูงและความกว้างของเป้าหมาย\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        #เนื่องจากเราใช้ categorical_crossentropy loss เราจึงต้องมีป้ายกำกับตามหมวดหมู่\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory( #การดึงภาพจาก Directory มาเข้าโมเดล \n",
        "        validation_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "     \n",
        "\n"
      ],
      "metadata": {
        "id": "znE38DtIJeN-",
        "outputId": "d986f874-2b55-4ebc-8612-008c6f747612",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1272 images belonging to 2 classes.\n",
            "Found 22 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multiply_16\n",
        "# set 'multiply_16' and following layers trainable\n",
        "model.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'multiply_16':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False  \n",
        "     "
      ],
      "metadata": {
        "id": "tEaPoHJCJq13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IC-3EwwkJHGS",
        "outputId": "bba27e9a-9d71-4055-85df-b030af8317a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 2)                 2562      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,052,126\n",
            "Trainable params: 4,010,110\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "z7ERVUfUJsQq",
        "outputId": "f452ea75-7570-44e2-b270-e3cc436344e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-caa7b37242a8>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "79/79 [==============================] - 104s 1s/step - loss: 0.5219 - acc: 0.7516 - val_loss: 0.4948 - val_acc: 0.6250\n",
            "Epoch 2/1000\n",
            "79/79 [==============================] - 3s 39ms/step - loss: 0.5092 - acc: 0.7667 - val_loss: 0.4636 - val_acc: 0.7500\n",
            "Epoch 3/1000\n",
            "79/79 [==============================] - 3s 38ms/step - loss: 0.5061 - acc: 0.7572 - val_loss: 0.4381 - val_acc: 0.7500\n",
            "Epoch 4/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5243 - acc: 0.7468 - val_loss: 0.5060 - val_acc: 0.6875\n",
            "Epoch 5/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5119 - acc: 0.7476 - val_loss: 0.5136 - val_acc: 0.6250\n",
            "Epoch 6/1000\n",
            "79/79 [==============================] - 3s 37ms/step - loss: 0.5211 - acc: 0.7468 - val_loss: 0.5228 - val_acc: 0.6875\n",
            "Epoch 7/1000\n",
            "79/79 [==============================] - 3s 38ms/step - loss: 0.5155 - acc: 0.7492 - val_loss: 0.6139 - val_acc: 0.6250\n",
            "Epoch 8/1000\n",
            "79/79 [==============================] - 3s 37ms/step - loss: 0.4991 - acc: 0.7420 - val_loss: 0.6694 - val_acc: 0.6250\n",
            "Epoch 9/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.4906 - acc: 0.7643 - val_loss: 0.4690 - val_acc: 0.7500\n",
            "Epoch 10/1000\n",
            "79/79 [==============================] - 3s 39ms/step - loss: 0.5027 - acc: 0.7516 - val_loss: 0.5806 - val_acc: 0.6250\n",
            "Epoch 11/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5059 - acc: 0.7548 - val_loss: 0.4293 - val_acc: 0.7500\n",
            "Epoch 12/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.4960 - acc: 0.7476 - val_loss: 0.5567 - val_acc: 0.6875\n",
            "Epoch 13/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5325 - acc: 0.7309 - val_loss: 0.5667 - val_acc: 0.6875\n",
            "Epoch 14/1000\n",
            "79/79 [==============================] - 3s 38ms/step - loss: 0.4982 - acc: 0.7532 - val_loss: 0.4307 - val_acc: 0.6875\n",
            "Epoch 15/1000\n",
            "79/79 [==============================] - 3s 38ms/step - loss: 0.5358 - acc: 0.7341 - val_loss: 0.6151 - val_acc: 0.6250\n",
            "Epoch 16/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5221 - acc: 0.7484 - val_loss: 0.4631 - val_acc: 0.7500\n",
            "Epoch 17/1000\n",
            "79/79 [==============================] - 3s 38ms/step - loss: 0.5138 - acc: 0.7516 - val_loss: 0.4004 - val_acc: 0.7500\n",
            "Epoch 18/1000\n",
            "79/79 [==============================] - 4s 39ms/step - loss: 0.5314 - acc: 0.7237 - val_loss: 0.4692 - val_acc: 0.7500\n",
            "Epoch 19/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5216 - acc: 0.7468 - val_loss: 0.6401 - val_acc: 0.6250\n",
            "Epoch 20/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5220 - acc: 0.7444 - val_loss: 0.5364 - val_acc: 0.6875\n",
            "Epoch 21/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5196 - acc: 0.7476 - val_loss: 0.4483 - val_acc: 0.7500\n",
            "Epoch 22/1000\n",
            "79/79 [==============================] - 3s 39ms/step - loss: 0.5031 - acc: 0.7572 - val_loss: 0.4301 - val_acc: 0.7500\n",
            "Epoch 23/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5170 - acc: 0.7460 - val_loss: 0.5445 - val_acc: 0.6875\n",
            "Epoch 24/1000\n",
            "79/79 [==============================] - 3s 38ms/step - loss: 0.5033 - acc: 0.7596 - val_loss: 0.5635 - val_acc: 0.6875\n",
            "Epoch 25/1000\n",
            "79/79 [==============================] - 4s 39ms/step - loss: 0.5308 - acc: 0.7349 - val_loss: 0.6217 - val_acc: 0.5625\n",
            "Epoch 26/1000\n",
            "79/79 [==============================] - 4s 39ms/step - loss: 0.5283 - acc: 0.7269 - val_loss: 0.5655 - val_acc: 0.6250\n",
            "Epoch 27/1000\n",
            "79/79 [==============================] - 4s 40ms/step - loss: 0.5153 - acc: 0.7532 - val_loss: 0.5547 - val_acc: 0.6875\n",
            "Epoch 28/1000\n",
            "79/79 [==============================] - 4s 39ms/step - loss: 0.5169 - acc: 0.7484 - val_loss: 0.5129 - val_acc: 0.6250\n",
            "Epoch 29/1000\n",
            "79/79 [==============================] - 3s 38ms/step - loss: 0.5055 - acc: 0.7484 - val_loss: 0.5582 - val_acc: 0.6875\n",
            "Epoch 30/1000\n",
            "79/79 [==============================] - 4s 40ms/step - loss: 0.5245 - acc: 0.7396 - val_loss: 0.5594 - val_acc: 0.6250\n",
            "Epoch 31/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5213 - acc: 0.7516 - val_loss: 0.4589 - val_acc: 0.7500\n",
            "Epoch 32/1000\n",
            "79/79 [==============================] - 4s 39ms/step - loss: 0.5177 - acc: 0.7389 - val_loss: 0.4570 - val_acc: 0.7500\n",
            "Epoch 33/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5281 - acc: 0.7357 - val_loss: 0.4267 - val_acc: 0.6875\n",
            "Epoch 34/1000\n",
            "79/79 [==============================] - 4s 40ms/step - loss: 0.5141 - acc: 0.7476 - val_loss: 0.4681 - val_acc: 0.7500\n",
            "Epoch 35/1000\n",
            "79/79 [==============================] - 4s 39ms/step - loss: 0.5272 - acc: 0.7436 - val_loss: 0.6336 - val_acc: 0.6875\n",
            "Epoch 36/1000\n",
            "79/79 [==============================] - 4s 39ms/step - loss: 0.5132 - acc: 0.7484 - val_loss: 0.4700 - val_acc: 0.7500\n",
            "Epoch 37/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5191 - acc: 0.7460 - val_loss: 0.5119 - val_acc: 0.6875\n",
            "Epoch 38/1000\n",
            "79/79 [==============================] - 4s 39ms/step - loss: 0.5242 - acc: 0.7428 - val_loss: 0.4572 - val_acc: 0.7500\n",
            "Epoch 39/1000\n",
            "79/79 [==============================] - 4s 40ms/step - loss: 0.5116 - acc: 0.7460 - val_loss: 0.5130 - val_acc: 0.7500\n",
            "Epoch 40/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5168 - acc: 0.7484 - val_loss: 0.6124 - val_acc: 0.6250\n",
            "Epoch 41/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.4944 - acc: 0.7611 - val_loss: 0.3599 - val_acc: 0.8125\n",
            "Epoch 42/1000\n",
            "79/79 [==============================] - 4s 39ms/step - loss: 0.5177 - acc: 0.7373 - val_loss: 0.4034 - val_acc: 0.7500\n",
            "Epoch 43/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.4981 - acc: 0.7659 - val_loss: 0.5592 - val_acc: 0.7500\n",
            "Epoch 44/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5201 - acc: 0.7365 - val_loss: 0.5331 - val_acc: 0.6875\n",
            "Epoch 45/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5292 - acc: 0.7277 - val_loss: 0.6092 - val_acc: 0.6875\n",
            "Epoch 46/1000\n",
            "79/79 [==============================] - 4s 40ms/step - loss: 0.5186 - acc: 0.7325 - val_loss: 0.5043 - val_acc: 0.6250\n",
            "Epoch 47/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5250 - acc: 0.7476 - val_loss: 0.4686 - val_acc: 0.8125\n",
            "Epoch 48/1000\n",
            "79/79 [==============================] - 4s 40ms/step - loss: 0.5221 - acc: 0.7285 - val_loss: 0.5783 - val_acc: 0.6875\n",
            "Epoch 49/1000\n",
            "79/79 [==============================] - 4s 40ms/step - loss: 0.5041 - acc: 0.7484 - val_loss: 0.4597 - val_acc: 0.6875\n",
            "Epoch 50/1000\n",
            "79/79 [==============================] - 4s 40ms/step - loss: 0.5216 - acc: 0.7484 - val_loss: 0.4295 - val_acc: 0.8125\n",
            "Epoch 51/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5036 - acc: 0.7548 - val_loss: 0.6253 - val_acc: 0.6250\n",
            "Epoch 52/1000\n",
            "79/79 [==============================] - 4s 40ms/step - loss: 0.5123 - acc: 0.7333 - val_loss: 0.5155 - val_acc: 0.7500\n",
            "Epoch 53/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5087 - acc: 0.7627 - val_loss: 0.5214 - val_acc: 0.6875\n",
            "Epoch 54/1000\n",
            "79/79 [==============================] - 4s 40ms/step - loss: 0.5353 - acc: 0.7277 - val_loss: 0.5816 - val_acc: 0.6875\n",
            "Epoch 55/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5041 - acc: 0.7707 - val_loss: 0.4805 - val_acc: 0.7500\n",
            "Epoch 56/1000\n",
            "79/79 [==============================] - 4s 39ms/step - loss: 0.5272 - acc: 0.7468 - val_loss: 0.5251 - val_acc: 0.6875\n",
            "Epoch 57/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5302 - acc: 0.7269 - val_loss: 0.5431 - val_acc: 0.6875\n",
            "Epoch 58/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5198 - acc: 0.7556 - val_loss: 0.5187 - val_acc: 0.7500\n",
            "Epoch 59/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5121 - acc: 0.7508 - val_loss: 0.4880 - val_acc: 0.7500\n",
            "Epoch 60/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5132 - acc: 0.7420 - val_loss: 0.5263 - val_acc: 0.7500\n",
            "Epoch 61/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5160 - acc: 0.7556 - val_loss: 0.5459 - val_acc: 0.6875\n",
            "Epoch 62/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5315 - acc: 0.7420 - val_loss: 0.4653 - val_acc: 0.6875\n",
            "Epoch 63/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5328 - acc: 0.7357 - val_loss: 0.4418 - val_acc: 0.7500\n",
            "Epoch 64/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5120 - acc: 0.7396 - val_loss: 0.5367 - val_acc: 0.6875\n",
            "Epoch 65/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5294 - acc: 0.7365 - val_loss: 0.5357 - val_acc: 0.6875\n",
            "Epoch 66/1000\n",
            "79/79 [==============================] - 4s 40ms/step - loss: 0.5429 - acc: 0.7412 - val_loss: 0.5511 - val_acc: 0.7500\n",
            "Epoch 67/1000\n",
            "79/79 [==============================] - 4s 40ms/step - loss: 0.5360 - acc: 0.7269 - val_loss: 0.6009 - val_acc: 0.6250\n",
            "Epoch 68/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5080 - acc: 0.7556 - val_loss: 0.5697 - val_acc: 0.6875\n",
            "Epoch 69/1000\n",
            "79/79 [==============================] - 4s 40ms/step - loss: 0.5079 - acc: 0.7675 - val_loss: 0.3949 - val_acc: 0.7500\n",
            "Epoch 70/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5297 - acc: 0.7460 - val_loss: 0.5969 - val_acc: 0.6250\n",
            "Epoch 71/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5095 - acc: 0.7524 - val_loss: 0.5929 - val_acc: 0.6250\n",
            "Epoch 72/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5043 - acc: 0.7540 - val_loss: 0.6359 - val_acc: 0.6250\n",
            "Epoch 73/1000\n",
            "79/79 [==============================] - 4s 40ms/step - loss: 0.5086 - acc: 0.7564 - val_loss: 0.6541 - val_acc: 0.6250\n",
            "Epoch 74/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5299 - acc: 0.7556 - val_loss: 0.4318 - val_acc: 0.8750\n",
            "Epoch 75/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5012 - acc: 0.7643 - val_loss: 0.4693 - val_acc: 0.7500\n",
            "Epoch 76/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5220 - acc: 0.7508 - val_loss: 0.5181 - val_acc: 0.6875\n",
            "Epoch 77/1000\n",
            "79/79 [==============================] - 4s 40ms/step - loss: 0.5348 - acc: 0.7285 - val_loss: 0.6384 - val_acc: 0.6250\n",
            "Epoch 78/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5105 - acc: 0.7500 - val_loss: 0.5958 - val_acc: 0.6875\n",
            "Epoch 79/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5080 - acc: 0.7516 - val_loss: 0.5056 - val_acc: 0.6875\n",
            "Epoch 80/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5190 - acc: 0.7460 - val_loss: 0.4483 - val_acc: 0.7500\n",
            "Epoch 81/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5221 - acc: 0.7286 - val_loss: 0.4988 - val_acc: 0.8125\n",
            "Epoch 82/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5138 - acc: 0.7444 - val_loss: 0.5780 - val_acc: 0.6875\n",
            "Epoch 83/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5059 - acc: 0.7548 - val_loss: 0.6963 - val_acc: 0.6250\n",
            "Epoch 84/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5175 - acc: 0.7428 - val_loss: 0.6025 - val_acc: 0.6250\n",
            "Epoch 85/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5293 - acc: 0.7325 - val_loss: 0.4679 - val_acc: 0.6250\n",
            "Epoch 86/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5352 - acc: 0.7492 - val_loss: 0.6260 - val_acc: 0.6875\n",
            "Epoch 87/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5124 - acc: 0.7349 - val_loss: 0.4829 - val_acc: 0.6875\n",
            "Epoch 88/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5172 - acc: 0.7492 - val_loss: 0.6147 - val_acc: 0.6875\n",
            "Epoch 89/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5262 - acc: 0.7420 - val_loss: 0.6079 - val_acc: 0.7500\n",
            "Epoch 90/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5098 - acc: 0.7580 - val_loss: 0.4352 - val_acc: 0.6875\n",
            "Epoch 91/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5234 - acc: 0.7572 - val_loss: 0.4505 - val_acc: 0.8125\n",
            "Epoch 92/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5231 - acc: 0.7444 - val_loss: 0.5726 - val_acc: 0.6250\n",
            "Epoch 93/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5168 - acc: 0.7404 - val_loss: 0.5315 - val_acc: 0.6875\n",
            "Epoch 94/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5179 - acc: 0.7428 - val_loss: 0.5390 - val_acc: 0.7500\n",
            "Epoch 95/1000\n",
            "79/79 [==============================] - 4s 40ms/step - loss: 0.5176 - acc: 0.7389 - val_loss: 0.3940 - val_acc: 0.8125\n",
            "Epoch 96/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5106 - acc: 0.7548 - val_loss: 0.4360 - val_acc: 0.7500\n",
            "Epoch 97/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5175 - acc: 0.7420 - val_loss: 0.4425 - val_acc: 0.7500\n",
            "Epoch 98/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5177 - acc: 0.7341 - val_loss: 0.5057 - val_acc: 0.6875\n",
            "Epoch 99/1000\n",
            "79/79 [==============================] - 4s 39ms/step - loss: 0.5244 - acc: 0.7484 - val_loss: 0.5807 - val_acc: 0.6875\n",
            "Epoch 100/1000\n",
            "79/79 [==============================] - 4s 40ms/step - loss: 0.5252 - acc: 0.7293 - val_loss: 0.5967 - val_acc: 0.6250\n",
            "Epoch 101/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5343 - acc: 0.7261 - val_loss: 0.4932 - val_acc: 0.6875\n",
            "Epoch 102/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.4957 - acc: 0.7564 - val_loss: 0.4281 - val_acc: 0.8750\n",
            "Epoch 103/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5254 - acc: 0.7325 - val_loss: 0.3934 - val_acc: 0.8750\n",
            "Epoch 104/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5073 - acc: 0.7564 - val_loss: 0.5470 - val_acc: 0.7500\n",
            "Epoch 105/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5125 - acc: 0.7460 - val_loss: 0.6022 - val_acc: 0.6875\n",
            "Epoch 106/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5170 - acc: 0.7428 - val_loss: 0.4425 - val_acc: 0.7500\n",
            "Epoch 107/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.4991 - acc: 0.7659 - val_loss: 0.5085 - val_acc: 0.6250\n",
            "Epoch 108/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5079 - acc: 0.7604 - val_loss: 0.4791 - val_acc: 0.8125\n",
            "Epoch 109/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5226 - acc: 0.7412 - val_loss: 0.4814 - val_acc: 0.8125\n",
            "Epoch 110/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5162 - acc: 0.7476 - val_loss: 0.4621 - val_acc: 0.6875\n",
            "Epoch 111/1000\n",
            "79/79 [==============================] - 4s 47ms/step - loss: 0.5015 - acc: 0.7580 - val_loss: 0.4900 - val_acc: 0.6250\n",
            "Epoch 112/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5232 - acc: 0.7436 - val_loss: 0.5116 - val_acc: 0.7500\n",
            "Epoch 113/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5323 - acc: 0.7357 - val_loss: 0.5832 - val_acc: 0.6875\n",
            "Epoch 114/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5347 - acc: 0.7357 - val_loss: 0.4706 - val_acc: 0.7500\n",
            "Epoch 115/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5136 - acc: 0.7643 - val_loss: 0.5754 - val_acc: 0.6875\n",
            "Epoch 116/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5216 - acc: 0.7476 - val_loss: 0.5386 - val_acc: 0.6250\n",
            "Epoch 117/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5126 - acc: 0.7604 - val_loss: 0.4701 - val_acc: 0.7500\n",
            "Epoch 118/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5060 - acc: 0.7412 - val_loss: 0.5144 - val_acc: 0.7500\n",
            "Epoch 119/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5155 - acc: 0.7532 - val_loss: 0.4818 - val_acc: 0.8125\n",
            "Epoch 120/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5100 - acc: 0.7452 - val_loss: 0.6417 - val_acc: 0.6875\n",
            "Epoch 121/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5025 - acc: 0.7460 - val_loss: 0.4163 - val_acc: 0.7500\n",
            "Epoch 122/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5196 - acc: 0.7452 - val_loss: 0.5819 - val_acc: 0.6875\n",
            "Epoch 123/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5170 - acc: 0.7404 - val_loss: 0.6752 - val_acc: 0.6250\n",
            "Epoch 124/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5016 - acc: 0.7532 - val_loss: 0.4909 - val_acc: 0.7500\n",
            "Epoch 125/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5098 - acc: 0.7468 - val_loss: 0.4881 - val_acc: 0.8125\n",
            "Epoch 126/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5426 - acc: 0.7341 - val_loss: 0.5141 - val_acc: 0.6875\n",
            "Epoch 127/1000\n",
            "79/79 [==============================] - 4s 40ms/step - loss: 0.5188 - acc: 0.7532 - val_loss: 0.6289 - val_acc: 0.6250\n",
            "Epoch 128/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5184 - acc: 0.7365 - val_loss: 0.4565 - val_acc: 0.7500\n",
            "Epoch 129/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5120 - acc: 0.7389 - val_loss: 0.5422 - val_acc: 0.6875\n",
            "Epoch 130/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5282 - acc: 0.7428 - val_loss: 0.5003 - val_acc: 0.7500\n",
            "Epoch 131/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5032 - acc: 0.7428 - val_loss: 0.4022 - val_acc: 0.7500\n",
            "Epoch 132/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5301 - acc: 0.7508 - val_loss: 0.5459 - val_acc: 0.7500\n",
            "Epoch 133/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5061 - acc: 0.7500 - val_loss: 0.4264 - val_acc: 0.7500\n",
            "Epoch 134/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5194 - acc: 0.7452 - val_loss: 0.5813 - val_acc: 0.6875\n",
            "Epoch 135/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5115 - acc: 0.7404 - val_loss: 0.5999 - val_acc: 0.6250\n",
            "Epoch 136/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.4963 - acc: 0.7691 - val_loss: 0.5340 - val_acc: 0.7500\n",
            "Epoch 137/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5084 - acc: 0.7532 - val_loss: 0.5019 - val_acc: 0.6875\n",
            "Epoch 138/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5245 - acc: 0.7572 - val_loss: 0.3384 - val_acc: 0.8125\n",
            "Epoch 139/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5340 - acc: 0.7357 - val_loss: 0.4393 - val_acc: 0.7500\n",
            "Epoch 140/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5314 - acc: 0.7237 - val_loss: 0.5490 - val_acc: 0.6875\n",
            "Epoch 141/1000\n",
            "79/79 [==============================] - 4s 47ms/step - loss: 0.5145 - acc: 0.7508 - val_loss: 0.5498 - val_acc: 0.5625\n",
            "Epoch 142/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5092 - acc: 0.7349 - val_loss: 0.5782 - val_acc: 0.6250\n",
            "Epoch 143/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5255 - acc: 0.7293 - val_loss: 0.3766 - val_acc: 0.7500\n",
            "Epoch 144/1000\n",
            "79/79 [==============================] - 4s 49ms/step - loss: 0.5164 - acc: 0.7468 - val_loss: 0.4751 - val_acc: 0.7500\n",
            "Epoch 145/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5194 - acc: 0.7428 - val_loss: 0.4327 - val_acc: 0.7500\n",
            "Epoch 146/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5091 - acc: 0.7365 - val_loss: 0.4817 - val_acc: 0.7500\n",
            "Epoch 147/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5141 - acc: 0.7460 - val_loss: 0.3690 - val_acc: 0.8125\n",
            "Epoch 148/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5217 - acc: 0.7341 - val_loss: 0.3990 - val_acc: 0.8125\n",
            "Epoch 149/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5134 - acc: 0.7420 - val_loss: 0.5164 - val_acc: 0.7500\n",
            "Epoch 150/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5049 - acc: 0.7436 - val_loss: 0.5026 - val_acc: 0.7500\n",
            "Epoch 151/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5185 - acc: 0.7428 - val_loss: 0.4835 - val_acc: 0.6875\n",
            "Epoch 152/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5228 - acc: 0.7412 - val_loss: 0.5512 - val_acc: 0.7500\n",
            "Epoch 153/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5247 - acc: 0.7349 - val_loss: 0.4353 - val_acc: 0.7500\n",
            "Epoch 154/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5135 - acc: 0.7476 - val_loss: 0.4172 - val_acc: 0.7500\n",
            "Epoch 155/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5212 - acc: 0.7373 - val_loss: 0.4421 - val_acc: 0.7500\n",
            "Epoch 156/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5216 - acc: 0.7548 - val_loss: 0.3169 - val_acc: 0.8750\n",
            "Epoch 157/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.4980 - acc: 0.7580 - val_loss: 0.5392 - val_acc: 0.7500\n",
            "Epoch 158/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5181 - acc: 0.7468 - val_loss: 0.4894 - val_acc: 0.7500\n",
            "Epoch 159/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5053 - acc: 0.7580 - val_loss: 0.4205 - val_acc: 0.8125\n",
            "Epoch 160/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5301 - acc: 0.7476 - val_loss: 0.3866 - val_acc: 0.8125\n",
            "Epoch 161/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.4918 - acc: 0.7596 - val_loss: 0.6620 - val_acc: 0.6250\n",
            "Epoch 162/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5162 - acc: 0.7325 - val_loss: 0.4311 - val_acc: 0.8125\n",
            "Epoch 163/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.4963 - acc: 0.7492 - val_loss: 0.5688 - val_acc: 0.7500\n",
            "Epoch 164/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5106 - acc: 0.7611 - val_loss: 0.5934 - val_acc: 0.6250\n",
            "Epoch 165/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5101 - acc: 0.7381 - val_loss: 0.5733 - val_acc: 0.6250\n",
            "Epoch 166/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5232 - acc: 0.7420 - val_loss: 0.4245 - val_acc: 0.8125\n",
            "Epoch 167/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5030 - acc: 0.7548 - val_loss: 0.4706 - val_acc: 0.6875\n",
            "Epoch 168/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5379 - acc: 0.7341 - val_loss: 0.5310 - val_acc: 0.6875\n",
            "Epoch 169/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5034 - acc: 0.7452 - val_loss: 0.6203 - val_acc: 0.6875\n",
            "Epoch 170/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5304 - acc: 0.7404 - val_loss: 0.4852 - val_acc: 0.7500\n",
            "Epoch 171/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5043 - acc: 0.7412 - val_loss: 0.4670 - val_acc: 0.8125\n",
            "Epoch 172/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5303 - acc: 0.7412 - val_loss: 0.4585 - val_acc: 0.7500\n",
            "Epoch 173/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5021 - acc: 0.7572 - val_loss: 0.5874 - val_acc: 0.6250\n",
            "Epoch 174/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5167 - acc: 0.7580 - val_loss: 0.4747 - val_acc: 0.7500\n",
            "Epoch 175/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5013 - acc: 0.7604 - val_loss: 0.5168 - val_acc: 0.7500\n",
            "Epoch 176/1000\n",
            "79/79 [==============================] - 4s 48ms/step - loss: 0.5331 - acc: 0.7436 - val_loss: 0.5948 - val_acc: 0.6875\n",
            "Epoch 177/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5273 - acc: 0.7301 - val_loss: 0.4052 - val_acc: 0.7500\n",
            "Epoch 178/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5250 - acc: 0.7412 - val_loss: 0.6400 - val_acc: 0.6875\n",
            "Epoch 179/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5067 - acc: 0.7516 - val_loss: 0.4935 - val_acc: 0.6250\n",
            "Epoch 180/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5234 - acc: 0.7412 - val_loss: 0.5181 - val_acc: 0.7500\n",
            "Epoch 181/1000\n",
            "79/79 [==============================] - 4s 39ms/step - loss: 0.5182 - acc: 0.7492 - val_loss: 0.6019 - val_acc: 0.6875\n",
            "Epoch 182/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5264 - acc: 0.7484 - val_loss: 0.4160 - val_acc: 0.8750\n",
            "Epoch 183/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5146 - acc: 0.7373 - val_loss: 0.5841 - val_acc: 0.7500\n",
            "Epoch 184/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5122 - acc: 0.7468 - val_loss: 0.4230 - val_acc: 0.8125\n",
            "Epoch 185/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5324 - acc: 0.7349 - val_loss: 0.4513 - val_acc: 0.6875\n",
            "Epoch 186/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5066 - acc: 0.7540 - val_loss: 0.6347 - val_acc: 0.6250\n",
            "Epoch 187/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5145 - acc: 0.7540 - val_loss: 0.4879 - val_acc: 0.7500\n",
            "Epoch 188/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5134 - acc: 0.7396 - val_loss: 0.6271 - val_acc: 0.6875\n",
            "Epoch 189/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5031 - acc: 0.7556 - val_loss: 0.4721 - val_acc: 0.6875\n",
            "Epoch 190/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5277 - acc: 0.7389 - val_loss: 0.6175 - val_acc: 0.6250\n",
            "Epoch 191/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5109 - acc: 0.7540 - val_loss: 0.4579 - val_acc: 0.8125\n",
            "Epoch 192/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5125 - acc: 0.7572 - val_loss: 0.5208 - val_acc: 0.8125\n",
            "Epoch 193/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5155 - acc: 0.7564 - val_loss: 0.5546 - val_acc: 0.6250\n",
            "Epoch 194/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5354 - acc: 0.7301 - val_loss: 0.6501 - val_acc: 0.6250\n",
            "Epoch 195/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5047 - acc: 0.7564 - val_loss: 0.6629 - val_acc: 0.6250\n",
            "Epoch 196/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.4999 - acc: 0.7572 - val_loss: 0.5151 - val_acc: 0.6250\n",
            "Epoch 197/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5079 - acc: 0.7508 - val_loss: 0.5722 - val_acc: 0.6875\n",
            "Epoch 198/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5062 - acc: 0.7468 - val_loss: 0.3472 - val_acc: 0.8125\n",
            "Epoch 199/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.4843 - acc: 0.7691 - val_loss: 0.4429 - val_acc: 0.8125\n",
            "Epoch 200/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5174 - acc: 0.7492 - val_loss: 0.5984 - val_acc: 0.6875\n",
            "Epoch 201/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5161 - acc: 0.7476 - val_loss: 0.5818 - val_acc: 0.6250\n",
            "Epoch 202/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5331 - acc: 0.7452 - val_loss: 0.5126 - val_acc: 0.7500\n",
            "Epoch 203/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5105 - acc: 0.7588 - val_loss: 0.5590 - val_acc: 0.7500\n",
            "Epoch 204/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5171 - acc: 0.7476 - val_loss: 0.5371 - val_acc: 0.7500\n",
            "Epoch 205/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5116 - acc: 0.7476 - val_loss: 0.5536 - val_acc: 0.6875\n",
            "Epoch 206/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5322 - acc: 0.7484 - val_loss: 0.6932 - val_acc: 0.6250\n",
            "Epoch 207/1000\n",
            "79/79 [==============================] - 4s 40ms/step - loss: 0.5097 - acc: 0.7404 - val_loss: 0.5753 - val_acc: 0.7500\n",
            "Epoch 208/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.4940 - acc: 0.7643 - val_loss: 0.5995 - val_acc: 0.7500\n",
            "Epoch 209/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5128 - acc: 0.7468 - val_loss: 0.3760 - val_acc: 0.8125\n",
            "Epoch 210/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.4916 - acc: 0.7803 - val_loss: 0.4557 - val_acc: 0.6875\n",
            "Epoch 211/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5372 - acc: 0.7286 - val_loss: 0.6192 - val_acc: 0.6875\n",
            "Epoch 212/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5176 - acc: 0.7484 - val_loss: 0.5077 - val_acc: 0.8125\n",
            "Epoch 213/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5390 - acc: 0.7412 - val_loss: 0.4691 - val_acc: 0.8125\n",
            "Epoch 214/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5339 - acc: 0.7237 - val_loss: 0.5331 - val_acc: 0.6875\n",
            "Epoch 215/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.4998 - acc: 0.7611 - val_loss: 0.5877 - val_acc: 0.6875\n",
            "Epoch 216/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5010 - acc: 0.7564 - val_loss: 0.6414 - val_acc: 0.6875\n",
            "Epoch 217/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.4881 - acc: 0.7699 - val_loss: 0.4468 - val_acc: 0.7500\n",
            "Epoch 218/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5054 - acc: 0.7492 - val_loss: 0.6219 - val_acc: 0.6875\n",
            "Epoch 219/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5284 - acc: 0.7428 - val_loss: 0.5874 - val_acc: 0.7500\n",
            "Epoch 220/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5150 - acc: 0.7349 - val_loss: 0.5545 - val_acc: 0.6250\n",
            "Epoch 221/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5279 - acc: 0.7333 - val_loss: 0.6770 - val_acc: 0.6250\n",
            "Epoch 222/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5161 - acc: 0.7635 - val_loss: 0.6449 - val_acc: 0.6250\n",
            "Epoch 223/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5265 - acc: 0.7349 - val_loss: 0.5866 - val_acc: 0.6875\n",
            "Epoch 224/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5204 - acc: 0.7357 - val_loss: 0.5617 - val_acc: 0.7500\n",
            "Epoch 225/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5236 - acc: 0.7357 - val_loss: 0.5479 - val_acc: 0.6875\n",
            "Epoch 226/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5133 - acc: 0.7548 - val_loss: 0.6325 - val_acc: 0.6250\n",
            "Epoch 227/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5105 - acc: 0.7532 - val_loss: 0.6040 - val_acc: 0.6875\n",
            "Epoch 228/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5241 - acc: 0.7452 - val_loss: 0.3591 - val_acc: 0.8750\n",
            "Epoch 229/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5306 - acc: 0.7460 - val_loss: 0.5987 - val_acc: 0.6250\n",
            "Epoch 230/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5325 - acc: 0.7365 - val_loss: 0.4032 - val_acc: 0.8125\n",
            "Epoch 231/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5360 - acc: 0.7436 - val_loss: 0.3645 - val_acc: 0.8750\n",
            "Epoch 232/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5061 - acc: 0.7404 - val_loss: 0.6092 - val_acc: 0.6250\n",
            "Epoch 233/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5303 - acc: 0.7389 - val_loss: 0.4821 - val_acc: 0.7500\n",
            "Epoch 234/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5407 - acc: 0.7412 - val_loss: 0.4827 - val_acc: 0.7500\n",
            "Epoch 235/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5187 - acc: 0.7484 - val_loss: 0.4609 - val_acc: 0.7500\n",
            "Epoch 236/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5016 - acc: 0.7500 - val_loss: 0.5474 - val_acc: 0.6875\n",
            "Epoch 237/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5007 - acc: 0.7476 - val_loss: 0.4805 - val_acc: 0.7500\n",
            "Epoch 238/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5261 - acc: 0.7476 - val_loss: 0.5668 - val_acc: 0.6875\n",
            "Epoch 239/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5178 - acc: 0.7532 - val_loss: 0.5390 - val_acc: 0.7500\n",
            "Epoch 240/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5035 - acc: 0.7667 - val_loss: 0.5405 - val_acc: 0.7500\n",
            "Epoch 241/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5006 - acc: 0.7596 - val_loss: 0.5706 - val_acc: 0.7500\n",
            "Epoch 242/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5197 - acc: 0.7524 - val_loss: 0.4355 - val_acc: 0.8125\n",
            "Epoch 243/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.4942 - acc: 0.7619 - val_loss: 0.4986 - val_acc: 0.8125\n",
            "Epoch 244/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5408 - acc: 0.7166 - val_loss: 0.5422 - val_acc: 0.7500\n",
            "Epoch 245/1000\n",
            "79/79 [==============================] - 4s 47ms/step - loss: 0.5186 - acc: 0.7468 - val_loss: 0.4980 - val_acc: 0.7500\n",
            "Epoch 246/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5174 - acc: 0.7365 - val_loss: 0.5760 - val_acc: 0.7500\n",
            "Epoch 247/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5057 - acc: 0.7468 - val_loss: 0.4542 - val_acc: 0.6875\n",
            "Epoch 248/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.4955 - acc: 0.7580 - val_loss: 0.5848 - val_acc: 0.6875\n",
            "Epoch 249/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5013 - acc: 0.7723 - val_loss: 0.6994 - val_acc: 0.6250\n",
            "Epoch 250/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5164 - acc: 0.7524 - val_loss: 0.6061 - val_acc: 0.6875\n",
            "Epoch 251/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5150 - acc: 0.7524 - val_loss: 0.5320 - val_acc: 0.7500\n",
            "Epoch 252/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5021 - acc: 0.7500 - val_loss: 0.5213 - val_acc: 0.7500\n",
            "Epoch 253/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5011 - acc: 0.7604 - val_loss: 0.5956 - val_acc: 0.7500\n",
            "Epoch 254/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5082 - acc: 0.7572 - val_loss: 0.6242 - val_acc: 0.6250\n",
            "Epoch 255/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5018 - acc: 0.7596 - val_loss: 0.3739 - val_acc: 0.7500\n",
            "Epoch 256/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5160 - acc: 0.7460 - val_loss: 0.4715 - val_acc: 0.7500\n",
            "Epoch 257/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.4967 - acc: 0.7761 - val_loss: 0.5966 - val_acc: 0.6875\n",
            "Epoch 258/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5224 - acc: 0.7404 - val_loss: 0.5093 - val_acc: 0.7500\n",
            "Epoch 259/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5099 - acc: 0.7444 - val_loss: 0.4222 - val_acc: 0.7500\n",
            "Epoch 260/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5217 - acc: 0.7317 - val_loss: 0.5024 - val_acc: 0.8125\n",
            "Epoch 261/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5495 - acc: 0.7357 - val_loss: 0.5316 - val_acc: 0.7500\n",
            "Epoch 262/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5348 - acc: 0.7508 - val_loss: 0.5326 - val_acc: 0.6875\n",
            "Epoch 263/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5116 - acc: 0.7548 - val_loss: 0.6793 - val_acc: 0.6250\n",
            "Epoch 264/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5120 - acc: 0.7627 - val_loss: 0.5553 - val_acc: 0.6875\n",
            "Epoch 265/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5341 - acc: 0.7436 - val_loss: 0.6421 - val_acc: 0.6250\n",
            "Epoch 266/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5061 - acc: 0.7468 - val_loss: 0.5732 - val_acc: 0.7500\n",
            "Epoch 267/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5352 - acc: 0.7404 - val_loss: 0.5524 - val_acc: 0.6875\n",
            "Epoch 268/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5188 - acc: 0.7532 - val_loss: 0.6021 - val_acc: 0.6875\n",
            "Epoch 269/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5049 - acc: 0.7508 - val_loss: 0.5152 - val_acc: 0.8125\n",
            "Epoch 270/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5237 - acc: 0.7317 - val_loss: 0.6145 - val_acc: 0.6875\n",
            "Epoch 271/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5087 - acc: 0.7484 - val_loss: 0.6780 - val_acc: 0.6250\n",
            "Epoch 272/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5017 - acc: 0.7508 - val_loss: 0.5237 - val_acc: 0.7500\n",
            "Epoch 273/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5225 - acc: 0.7452 - val_loss: 0.5192 - val_acc: 0.6875\n",
            "Epoch 274/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5458 - acc: 0.7182 - val_loss: 0.5503 - val_acc: 0.6875\n",
            "Epoch 275/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5207 - acc: 0.7532 - val_loss: 0.4614 - val_acc: 0.8125\n",
            "Epoch 276/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5261 - acc: 0.7389 - val_loss: 0.5680 - val_acc: 0.7500\n",
            "Epoch 277/1000\n",
            "79/79 [==============================] - 4s 48ms/step - loss: 0.5099 - acc: 0.7476 - val_loss: 0.4494 - val_acc: 0.6875\n",
            "Epoch 278/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5167 - acc: 0.7365 - val_loss: 0.3633 - val_acc: 0.8750\n",
            "Epoch 279/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5031 - acc: 0.7564 - val_loss: 0.5145 - val_acc: 0.7500\n",
            "Epoch 280/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5008 - acc: 0.7524 - val_loss: 0.5425 - val_acc: 0.6875\n",
            "Epoch 281/1000\n",
            "79/79 [==============================] - 4s 49ms/step - loss: 0.5328 - acc: 0.7452 - val_loss: 0.5777 - val_acc: 0.6875\n",
            "Epoch 282/1000\n",
            "79/79 [==============================] - 4s 47ms/step - loss: 0.5054 - acc: 0.7580 - val_loss: 0.6491 - val_acc: 0.6875\n",
            "Epoch 283/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5155 - acc: 0.7381 - val_loss: 0.4830 - val_acc: 0.7500\n",
            "Epoch 284/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5156 - acc: 0.7389 - val_loss: 0.4689 - val_acc: 0.8125\n",
            "Epoch 285/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5141 - acc: 0.7540 - val_loss: 0.4864 - val_acc: 0.7500\n",
            "Epoch 286/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5116 - acc: 0.7611 - val_loss: 0.6050 - val_acc: 0.6875\n",
            "Epoch 287/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5461 - acc: 0.7309 - val_loss: 0.6759 - val_acc: 0.6250\n",
            "Epoch 288/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.4928 - acc: 0.7675 - val_loss: 0.3694 - val_acc: 0.7500\n",
            "Epoch 289/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5149 - acc: 0.7412 - val_loss: 0.5935 - val_acc: 0.6875\n",
            "Epoch 290/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5253 - acc: 0.7572 - val_loss: 0.3997 - val_acc: 0.8125\n",
            "Epoch 291/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5106 - acc: 0.7404 - val_loss: 0.5681 - val_acc: 0.7500\n",
            "Epoch 292/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5094 - acc: 0.7548 - val_loss: 0.4274 - val_acc: 0.6875\n",
            "Epoch 293/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5201 - acc: 0.7500 - val_loss: 0.3026 - val_acc: 0.8750\n",
            "Epoch 294/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5203 - acc: 0.7452 - val_loss: 0.5344 - val_acc: 0.7500\n",
            "Epoch 295/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5193 - acc: 0.7508 - val_loss: 0.6649 - val_acc: 0.6250\n",
            "Epoch 296/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5113 - acc: 0.7333 - val_loss: 0.3837 - val_acc: 0.6875\n",
            "Epoch 297/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5228 - acc: 0.7444 - val_loss: 0.5843 - val_acc: 0.6875\n",
            "Epoch 298/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5135 - acc: 0.7444 - val_loss: 0.5480 - val_acc: 0.6875\n",
            "Epoch 299/1000\n",
            "79/79 [==============================] - 4s 50ms/step - loss: 0.5192 - acc: 0.7428 - val_loss: 0.4252 - val_acc: 0.7500\n",
            "Epoch 300/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5129 - acc: 0.7436 - val_loss: 0.4983 - val_acc: 0.6250\n",
            "Epoch 301/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5286 - acc: 0.7420 - val_loss: 0.6292 - val_acc: 0.6875\n",
            "Epoch 302/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5179 - acc: 0.7540 - val_loss: 0.4332 - val_acc: 0.7500\n",
            "Epoch 303/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5346 - acc: 0.7389 - val_loss: 0.3587 - val_acc: 0.8125\n",
            "Epoch 304/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5211 - acc: 0.7548 - val_loss: 0.6138 - val_acc: 0.6875\n",
            "Epoch 305/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5186 - acc: 0.7580 - val_loss: 0.6247 - val_acc: 0.6875\n",
            "Epoch 306/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5334 - acc: 0.7269 - val_loss: 0.5650 - val_acc: 0.6250\n",
            "Epoch 307/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5050 - acc: 0.7444 - val_loss: 0.4415 - val_acc: 0.7500\n",
            "Epoch 308/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.4736 - acc: 0.7627 - val_loss: 0.4467 - val_acc: 0.6875\n",
            "Epoch 309/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5315 - acc: 0.7341 - val_loss: 0.5180 - val_acc: 0.6875\n",
            "Epoch 310/1000\n",
            "79/79 [==============================] - 4s 40ms/step - loss: 0.5158 - acc: 0.7516 - val_loss: 0.5696 - val_acc: 0.6875\n",
            "Epoch 311/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5016 - acc: 0.7596 - val_loss: 0.5966 - val_acc: 0.6875\n",
            "Epoch 312/1000\n",
            "79/79 [==============================] - 4s 47ms/step - loss: 0.5059 - acc: 0.7476 - val_loss: 0.6592 - val_acc: 0.6250\n",
            "Epoch 313/1000\n",
            "79/79 [==============================] - 4s 48ms/step - loss: 0.5069 - acc: 0.7492 - val_loss: 0.4613 - val_acc: 0.6875\n",
            "Epoch 314/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5117 - acc: 0.7572 - val_loss: 0.6212 - val_acc: 0.6250\n",
            "Epoch 315/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5130 - acc: 0.7492 - val_loss: 0.4828 - val_acc: 0.6875\n",
            "Epoch 316/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5111 - acc: 0.7460 - val_loss: 0.4480 - val_acc: 0.8125\n",
            "Epoch 317/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.4999 - acc: 0.7675 - val_loss: 0.5448 - val_acc: 0.6875\n",
            "Epoch 318/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5133 - acc: 0.7468 - val_loss: 0.6535 - val_acc: 0.6250\n",
            "Epoch 319/1000\n",
            "79/79 [==============================] - 4s 47ms/step - loss: 0.4911 - acc: 0.7580 - val_loss: 0.6537 - val_acc: 0.6250\n",
            "Epoch 320/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5416 - acc: 0.7341 - val_loss: 0.5979 - val_acc: 0.6250\n",
            "Epoch 321/1000\n",
            "79/79 [==============================] - 4s 47ms/step - loss: 0.5011 - acc: 0.7564 - val_loss: 0.6058 - val_acc: 0.6875\n",
            "Epoch 322/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5349 - acc: 0.7444 - val_loss: 0.6470 - val_acc: 0.5625\n",
            "Epoch 323/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5208 - acc: 0.7524 - val_loss: 0.6033 - val_acc: 0.6250\n",
            "Epoch 324/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5377 - acc: 0.7285 - val_loss: 0.4730 - val_acc: 0.8125\n",
            "Epoch 325/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5237 - acc: 0.7404 - val_loss: 0.4593 - val_acc: 0.7500\n",
            "Epoch 326/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5062 - acc: 0.7500 - val_loss: 0.5149 - val_acc: 0.6875\n",
            "Epoch 327/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.4964 - acc: 0.7619 - val_loss: 0.3823 - val_acc: 0.7500\n",
            "Epoch 328/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.4924 - acc: 0.7691 - val_loss: 0.5815 - val_acc: 0.6875\n",
            "Epoch 329/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5228 - acc: 0.7500 - val_loss: 0.5004 - val_acc: 0.7500\n",
            "Epoch 330/1000\n",
            "79/79 [==============================] - 4s 48ms/step - loss: 0.5085 - acc: 0.7468 - val_loss: 0.5983 - val_acc: 0.6250\n",
            "Epoch 331/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5218 - acc: 0.7389 - val_loss: 0.5551 - val_acc: 0.7500\n",
            "Epoch 332/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5049 - acc: 0.7627 - val_loss: 0.6008 - val_acc: 0.6875\n",
            "Epoch 333/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.4927 - acc: 0.7532 - val_loss: 0.3656 - val_acc: 0.8125\n",
            "Epoch 334/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5174 - acc: 0.7412 - val_loss: 0.6740 - val_acc: 0.5625\n",
            "Epoch 335/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5005 - acc: 0.7500 - val_loss: 0.5335 - val_acc: 0.7500\n",
            "Epoch 336/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5344 - acc: 0.7349 - val_loss: 0.5881 - val_acc: 0.7500\n",
            "Epoch 337/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5201 - acc: 0.7349 - val_loss: 0.6280 - val_acc: 0.6875\n",
            "Epoch 338/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5116 - acc: 0.7627 - val_loss: 0.5149 - val_acc: 0.6875\n",
            "Epoch 339/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5061 - acc: 0.7468 - val_loss: 0.4711 - val_acc: 0.8125\n",
            "Epoch 340/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.4823 - acc: 0.7739 - val_loss: 0.4521 - val_acc: 0.8125\n",
            "Epoch 341/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5143 - acc: 0.7444 - val_loss: 0.5198 - val_acc: 0.6875\n",
            "Epoch 342/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5150 - acc: 0.7412 - val_loss: 0.6193 - val_acc: 0.6875\n",
            "Epoch 343/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5133 - acc: 0.7404 - val_loss: 0.4273 - val_acc: 0.7500\n",
            "Epoch 344/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5428 - acc: 0.7366 - val_loss: 0.3859 - val_acc: 0.7500\n",
            "Epoch 345/1000\n",
            "79/79 [==============================] - 4s 48ms/step - loss: 0.5474 - acc: 0.7317 - val_loss: 0.4782 - val_acc: 0.8125\n",
            "Epoch 346/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5296 - acc: 0.7460 - val_loss: 0.6461 - val_acc: 0.6250\n",
            "Epoch 347/1000\n",
            "79/79 [==============================] - 5s 50ms/step - loss: 0.5190 - acc: 0.7476 - val_loss: 0.4526 - val_acc: 0.7500\n",
            "Epoch 348/1000\n",
            "79/79 [==============================] - 4s 48ms/step - loss: 0.5018 - acc: 0.7508 - val_loss: 0.5150 - val_acc: 0.8125\n",
            "Epoch 349/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5076 - acc: 0.7436 - val_loss: 0.4677 - val_acc: 0.8125\n",
            "Epoch 350/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5304 - acc: 0.7357 - val_loss: 0.6395 - val_acc: 0.6875\n",
            "Epoch 351/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5175 - acc: 0.7420 - val_loss: 0.6451 - val_acc: 0.6250\n",
            "Epoch 352/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5104 - acc: 0.7508 - val_loss: 0.5940 - val_acc: 0.7500\n",
            "Epoch 353/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5153 - acc: 0.7484 - val_loss: 0.3074 - val_acc: 0.8125\n",
            "Epoch 354/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5246 - acc: 0.7428 - val_loss: 0.4816 - val_acc: 0.7500\n",
            "Epoch 355/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5067 - acc: 0.7500 - val_loss: 0.3709 - val_acc: 0.8125\n",
            "Epoch 356/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5138 - acc: 0.7540 - val_loss: 0.5182 - val_acc: 0.7500\n",
            "Epoch 357/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5478 - acc: 0.7436 - val_loss: 0.3724 - val_acc: 0.7500\n",
            "Epoch 358/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5153 - acc: 0.7563 - val_loss: 0.5580 - val_acc: 0.7500\n",
            "Epoch 359/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5256 - acc: 0.7476 - val_loss: 0.4745 - val_acc: 0.8125\n",
            "Epoch 360/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.4937 - acc: 0.7524 - val_loss: 0.3886 - val_acc: 0.7500\n",
            "Epoch 361/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5234 - acc: 0.7333 - val_loss: 0.3293 - val_acc: 0.8750\n",
            "Epoch 362/1000\n",
            "79/79 [==============================] - 4s 47ms/step - loss: 0.5062 - acc: 0.7452 - val_loss: 0.4612 - val_acc: 0.6875\n",
            "Epoch 363/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5336 - acc: 0.7245 - val_loss: 0.5421 - val_acc: 0.6875\n",
            "Epoch 364/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.4873 - acc: 0.7619 - val_loss: 0.3600 - val_acc: 0.8125\n",
            "Epoch 365/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5009 - acc: 0.7604 - val_loss: 0.3271 - val_acc: 0.8125\n",
            "Epoch 366/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5215 - acc: 0.7468 - val_loss: 0.3951 - val_acc: 0.8125\n",
            "Epoch 367/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5194 - acc: 0.7476 - val_loss: 0.6000 - val_acc: 0.6875\n",
            "Epoch 368/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5094 - acc: 0.7468 - val_loss: 0.3215 - val_acc: 0.8750\n",
            "Epoch 369/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.4985 - acc: 0.7604 - val_loss: 0.5615 - val_acc: 0.6875\n",
            "Epoch 370/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5146 - acc: 0.7428 - val_loss: 0.4866 - val_acc: 0.7500\n",
            "Epoch 371/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5278 - acc: 0.7333 - val_loss: 0.6407 - val_acc: 0.6875\n",
            "Epoch 372/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5047 - acc: 0.7476 - val_loss: 0.6168 - val_acc: 0.6250\n",
            "Epoch 373/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5329 - acc: 0.7269 - val_loss: 0.6432 - val_acc: 0.6875\n",
            "Epoch 374/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5061 - acc: 0.7516 - val_loss: 0.5929 - val_acc: 0.6250\n",
            "Epoch 375/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.4952 - acc: 0.7500 - val_loss: 0.5876 - val_acc: 0.6875\n",
            "Epoch 376/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5164 - acc: 0.7476 - val_loss: 0.5761 - val_acc: 0.6875\n",
            "Epoch 377/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5376 - acc: 0.7277 - val_loss: 0.5906 - val_acc: 0.6875\n",
            "Epoch 378/1000\n",
            "79/79 [==============================] - 4s 50ms/step - loss: 0.5162 - acc: 0.7436 - val_loss: 0.5973 - val_acc: 0.6875\n",
            "Epoch 379/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5120 - acc: 0.7381 - val_loss: 0.5100 - val_acc: 0.8125\n",
            "Epoch 380/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.4995 - acc: 0.7436 - val_loss: 0.4888 - val_acc: 0.6875\n",
            "Epoch 381/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5236 - acc: 0.7396 - val_loss: 0.6377 - val_acc: 0.6875\n",
            "Epoch 382/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5381 - acc: 0.7492 - val_loss: 0.5105 - val_acc: 0.7500\n",
            "Epoch 383/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5227 - acc: 0.7396 - val_loss: 0.6114 - val_acc: 0.6875\n",
            "Epoch 384/1000\n",
            "79/79 [==============================] - 4s 48ms/step - loss: 0.5170 - acc: 0.7428 - val_loss: 0.4255 - val_acc: 0.8125\n",
            "Epoch 385/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5169 - acc: 0.7412 - val_loss: 0.5580 - val_acc: 0.7500\n",
            "Epoch 386/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5191 - acc: 0.7429 - val_loss: 0.3995 - val_acc: 0.8125\n",
            "Epoch 387/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.4994 - acc: 0.7476 - val_loss: 0.3191 - val_acc: 0.8750\n",
            "Epoch 388/1000\n",
            "79/79 [==============================] - 4s 50ms/step - loss: 0.5369 - acc: 0.7373 - val_loss: 0.5158 - val_acc: 0.6250\n",
            "Epoch 389/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5046 - acc: 0.7476 - val_loss: 0.5941 - val_acc: 0.6875\n",
            "Epoch 390/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5310 - acc: 0.7452 - val_loss: 0.5193 - val_acc: 0.6250\n",
            "Epoch 391/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5271 - acc: 0.7452 - val_loss: 0.4467 - val_acc: 0.6875\n",
            "Epoch 392/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5226 - acc: 0.7452 - val_loss: 0.5080 - val_acc: 0.6875\n",
            "Epoch 393/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.4873 - acc: 0.7619 - val_loss: 0.4775 - val_acc: 0.6875\n",
            "Epoch 394/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5029 - acc: 0.7619 - val_loss: 0.4758 - val_acc: 0.8125\n",
            "Epoch 395/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5149 - acc: 0.7516 - val_loss: 0.6305 - val_acc: 0.6250\n",
            "Epoch 396/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5057 - acc: 0.7532 - val_loss: 0.5422 - val_acc: 0.6875\n",
            "Epoch 397/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5128 - acc: 0.7500 - val_loss: 0.6384 - val_acc: 0.6875\n",
            "Epoch 398/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5308 - acc: 0.7221 - val_loss: 0.4431 - val_acc: 0.6875\n",
            "Epoch 399/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5033 - acc: 0.7484 - val_loss: 0.5900 - val_acc: 0.6875\n",
            "Epoch 400/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5160 - acc: 0.7540 - val_loss: 0.4688 - val_acc: 0.6875\n",
            "Epoch 401/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.4880 - acc: 0.7667 - val_loss: 0.3769 - val_acc: 0.7500\n",
            "Epoch 402/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5204 - acc: 0.7516 - val_loss: 0.5123 - val_acc: 0.7500\n",
            "Epoch 403/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5026 - acc: 0.7580 - val_loss: 0.5739 - val_acc: 0.7500\n",
            "Epoch 404/1000\n",
            "79/79 [==============================] - 4s 47ms/step - loss: 0.5384 - acc: 0.7373 - val_loss: 0.6720 - val_acc: 0.6250\n",
            "Epoch 405/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5077 - acc: 0.7333 - val_loss: 0.6755 - val_acc: 0.6250\n",
            "Epoch 406/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5072 - acc: 0.7508 - val_loss: 0.4784 - val_acc: 0.7500\n",
            "Epoch 407/1000\n",
            "79/79 [==============================] - 5s 50ms/step - loss: 0.5141 - acc: 0.7572 - val_loss: 0.4262 - val_acc: 0.8125\n",
            "Epoch 408/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5129 - acc: 0.7580 - val_loss: 0.5124 - val_acc: 0.6875\n",
            "Epoch 409/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.4882 - acc: 0.7619 - val_loss: 0.4665 - val_acc: 0.7500\n",
            "Epoch 410/1000\n",
            "79/79 [==============================] - 4s 52ms/step - loss: 0.5027 - acc: 0.7476 - val_loss: 0.4934 - val_acc: 0.8125\n",
            "Epoch 411/1000\n",
            "79/79 [==============================] - 4s 48ms/step - loss: 0.5394 - acc: 0.7341 - val_loss: 0.5890 - val_acc: 0.6875\n",
            "Epoch 412/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5096 - acc: 0.7540 - val_loss: 0.4578 - val_acc: 0.6875\n",
            "Epoch 413/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5232 - acc: 0.7436 - val_loss: 0.4620 - val_acc: 0.7500\n",
            "Epoch 414/1000\n",
            "79/79 [==============================] - 4s 49ms/step - loss: 0.4819 - acc: 0.7556 - val_loss: 0.6126 - val_acc: 0.6875\n",
            "Epoch 415/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5291 - acc: 0.7389 - val_loss: 0.5202 - val_acc: 0.6875\n",
            "Epoch 416/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5128 - acc: 0.7341 - val_loss: 0.5680 - val_acc: 0.6875\n",
            "Epoch 417/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5042 - acc: 0.7428 - val_loss: 0.4964 - val_acc: 0.6875\n",
            "Epoch 418/1000\n",
            "79/79 [==============================] - 4s 48ms/step - loss: 0.5186 - acc: 0.7588 - val_loss: 0.5192 - val_acc: 0.6875\n",
            "Epoch 419/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5193 - acc: 0.7436 - val_loss: 0.6649 - val_acc: 0.6875\n",
            "Epoch 420/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5347 - acc: 0.7452 - val_loss: 0.5855 - val_acc: 0.6875\n",
            "Epoch 421/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5117 - acc: 0.7556 - val_loss: 0.3577 - val_acc: 0.8125\n",
            "Epoch 422/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5209 - acc: 0.7396 - val_loss: 0.3252 - val_acc: 0.8125\n",
            "Epoch 423/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.4961 - acc: 0.7667 - val_loss: 0.6188 - val_acc: 0.6875\n",
            "Epoch 424/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5391 - acc: 0.7309 - val_loss: 0.4171 - val_acc: 0.6875\n",
            "Epoch 425/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.4938 - acc: 0.7524 - val_loss: 0.5436 - val_acc: 0.7500\n",
            "Epoch 426/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5233 - acc: 0.7484 - val_loss: 0.6072 - val_acc: 0.6875\n",
            "Epoch 427/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5055 - acc: 0.7659 - val_loss: 0.3859 - val_acc: 0.8750\n",
            "Epoch 428/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5000 - acc: 0.7516 - val_loss: 0.5458 - val_acc: 0.6875\n",
            "Epoch 429/1000\n",
            "79/79 [==============================] - 5s 51ms/step - loss: 0.5025 - acc: 0.7651 - val_loss: 0.5363 - val_acc: 0.7500\n",
            "Epoch 430/1000\n",
            "79/79 [==============================] - 4s 48ms/step - loss: 0.5110 - acc: 0.7532 - val_loss: 0.4811 - val_acc: 0.6875\n",
            "Epoch 431/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5268 - acc: 0.7349 - val_loss: 0.5241 - val_acc: 0.8125\n",
            "Epoch 432/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5213 - acc: 0.7460 - val_loss: 0.5795 - val_acc: 0.6875\n",
            "Epoch 433/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5083 - acc: 0.7572 - val_loss: 0.5833 - val_acc: 0.6875\n",
            "Epoch 434/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5193 - acc: 0.7381 - val_loss: 0.5044 - val_acc: 0.8125\n",
            "Epoch 435/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5252 - acc: 0.7365 - val_loss: 0.5982 - val_acc: 0.6875\n",
            "Epoch 436/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5348 - acc: 0.7158 - val_loss: 0.5508 - val_acc: 0.7500\n",
            "Epoch 437/1000\n",
            "79/79 [==============================] - 4s 50ms/step - loss: 0.5155 - acc: 0.7428 - val_loss: 0.4502 - val_acc: 0.8750\n",
            "Epoch 438/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5094 - acc: 0.7540 - val_loss: 0.5391 - val_acc: 0.6875\n",
            "Epoch 439/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5376 - acc: 0.7142 - val_loss: 0.3227 - val_acc: 0.7500\n",
            "Epoch 440/1000\n",
            "79/79 [==============================] - 4s 49ms/step - loss: 0.5101 - acc: 0.7524 - val_loss: 0.3043 - val_acc: 0.8125\n",
            "Epoch 441/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.4955 - acc: 0.7611 - val_loss: 0.4247 - val_acc: 0.7500\n",
            "Epoch 442/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5278 - acc: 0.7420 - val_loss: 0.5534 - val_acc: 0.6875\n",
            "Epoch 443/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5523 - acc: 0.7221 - val_loss: 0.5989 - val_acc: 0.7500\n",
            "Epoch 444/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5305 - acc: 0.7365 - val_loss: 0.3416 - val_acc: 0.8125\n",
            "Epoch 445/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5123 - acc: 0.7349 - val_loss: 0.6365 - val_acc: 0.5625\n",
            "Epoch 446/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5372 - acc: 0.7301 - val_loss: 0.3070 - val_acc: 0.8125\n",
            "Epoch 447/1000\n",
            "79/79 [==============================] - 4s 49ms/step - loss: 0.5108 - acc: 0.7428 - val_loss: 0.4611 - val_acc: 0.6875\n",
            "Epoch 448/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5276 - acc: 0.7261 - val_loss: 0.5766 - val_acc: 0.6875\n",
            "Epoch 449/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5265 - acc: 0.7404 - val_loss: 0.6180 - val_acc: 0.6875\n",
            "Epoch 450/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5291 - acc: 0.7349 - val_loss: 0.4823 - val_acc: 0.7500\n",
            "Epoch 451/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5330 - acc: 0.7444 - val_loss: 0.3514 - val_acc: 0.8125\n",
            "Epoch 452/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5197 - acc: 0.7476 - val_loss: 0.6427 - val_acc: 0.6875\n",
            "Epoch 453/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5281 - acc: 0.7357 - val_loss: 0.4613 - val_acc: 0.7500\n",
            "Epoch 454/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5409 - acc: 0.7468 - val_loss: 0.5240 - val_acc: 0.7500\n",
            "Epoch 455/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5214 - acc: 0.7452 - val_loss: 0.5865 - val_acc: 0.6875\n",
            "Epoch 456/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5088 - acc: 0.7500 - val_loss: 0.5313 - val_acc: 0.6875\n",
            "Epoch 457/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.4876 - acc: 0.7532 - val_loss: 0.5274 - val_acc: 0.7500\n",
            "Epoch 458/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5129 - acc: 0.7516 - val_loss: 0.4642 - val_acc: 0.8125\n",
            "Epoch 459/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5014 - acc: 0.7444 - val_loss: 0.5380 - val_acc: 0.7500\n",
            "Epoch 460/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.4912 - acc: 0.7540 - val_loss: 0.5150 - val_acc: 0.7500\n",
            "Epoch 461/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5284 - acc: 0.7460 - val_loss: 0.2704 - val_acc: 0.8125\n",
            "Epoch 462/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5188 - acc: 0.7516 - val_loss: 0.5622 - val_acc: 0.7500\n",
            "Epoch 463/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5080 - acc: 0.7604 - val_loss: 0.4992 - val_acc: 0.6875\n",
            "Epoch 464/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5150 - acc: 0.7365 - val_loss: 0.6253 - val_acc: 0.6250\n",
            "Epoch 465/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5165 - acc: 0.7444 - val_loss: 0.6223 - val_acc: 0.6250\n",
            "Epoch 466/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5114 - acc: 0.7301 - val_loss: 0.5719 - val_acc: 0.6250\n",
            "Epoch 467/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5053 - acc: 0.7524 - val_loss: 0.5373 - val_acc: 0.8125\n",
            "Epoch 468/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.4993 - acc: 0.7564 - val_loss: 0.5182 - val_acc: 0.7500\n",
            "Epoch 469/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5223 - acc: 0.7325 - val_loss: 0.4165 - val_acc: 0.7500\n",
            "Epoch 470/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5152 - acc: 0.7468 - val_loss: 0.4022 - val_acc: 0.7500\n",
            "Epoch 471/1000\n",
            "79/79 [==============================] - 4s 48ms/step - loss: 0.5086 - acc: 0.7588 - val_loss: 0.4659 - val_acc: 0.6875\n",
            "Epoch 472/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5428 - acc: 0.7452 - val_loss: 0.5943 - val_acc: 0.7500\n",
            "Epoch 473/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5166 - acc: 0.7460 - val_loss: 0.5568 - val_acc: 0.7500\n",
            "Epoch 474/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5119 - acc: 0.7349 - val_loss: 0.5530 - val_acc: 0.6875\n",
            "Epoch 475/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5141 - acc: 0.7492 - val_loss: 0.5512 - val_acc: 0.6875\n",
            "Epoch 476/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5393 - acc: 0.7349 - val_loss: 0.6114 - val_acc: 0.6875\n",
            "Epoch 477/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5336 - acc: 0.7381 - val_loss: 0.3763 - val_acc: 0.8125\n",
            "Epoch 478/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.4973 - acc: 0.7611 - val_loss: 0.5608 - val_acc: 0.7500\n",
            "Epoch 479/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5239 - acc: 0.7460 - val_loss: 0.5497 - val_acc: 0.7500\n",
            "Epoch 480/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.4880 - acc: 0.7683 - val_loss: 0.5157 - val_acc: 0.6875\n",
            "Epoch 481/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5127 - acc: 0.7404 - val_loss: 0.2959 - val_acc: 0.8750\n",
            "Epoch 482/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.4869 - acc: 0.7643 - val_loss: 0.5435 - val_acc: 0.6875\n",
            "Epoch 483/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5051 - acc: 0.7500 - val_loss: 0.4824 - val_acc: 0.7500\n",
            "Epoch 484/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5103 - acc: 0.7500 - val_loss: 0.4423 - val_acc: 0.8125\n",
            "Epoch 485/1000\n",
            "79/79 [==============================] - 4s 50ms/step - loss: 0.5315 - acc: 0.7436 - val_loss: 0.4889 - val_acc: 0.8125\n",
            "Epoch 486/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.4957 - acc: 0.7667 - val_loss: 0.5560 - val_acc: 0.7500\n",
            "Epoch 487/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5242 - acc: 0.7389 - val_loss: 0.5164 - val_acc: 0.7500\n",
            "Epoch 488/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5089 - acc: 0.7604 - val_loss: 0.3283 - val_acc: 0.8750\n",
            "Epoch 489/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5393 - acc: 0.7309 - val_loss: 0.5640 - val_acc: 0.6875\n",
            "Epoch 490/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5243 - acc: 0.7366 - val_loss: 0.5728 - val_acc: 0.7500\n",
            "Epoch 491/1000\n",
            "79/79 [==============================] - 4s 48ms/step - loss: 0.5069 - acc: 0.7532 - val_loss: 0.4990 - val_acc: 0.7500\n",
            "Epoch 492/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5191 - acc: 0.7452 - val_loss: 0.6041 - val_acc: 0.6875\n",
            "Epoch 493/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5311 - acc: 0.7389 - val_loss: 0.5271 - val_acc: 0.7500\n",
            "Epoch 494/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.4983 - acc: 0.7492 - val_loss: 0.3656 - val_acc: 0.8125\n",
            "Epoch 495/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5120 - acc: 0.7468 - val_loss: 0.4624 - val_acc: 0.8750\n",
            "Epoch 496/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5122 - acc: 0.7619 - val_loss: 0.5297 - val_acc: 0.6875\n",
            "Epoch 497/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5027 - acc: 0.7420 - val_loss: 0.5180 - val_acc: 0.7500\n",
            "Epoch 498/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5255 - acc: 0.7428 - val_loss: 0.5625 - val_acc: 0.6875\n",
            "Epoch 499/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5232 - acc: 0.7468 - val_loss: 0.5396 - val_acc: 0.6875\n",
            "Epoch 500/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.4962 - acc: 0.7731 - val_loss: 0.5572 - val_acc: 0.6875\n",
            "Epoch 501/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5322 - acc: 0.7357 - val_loss: 0.2963 - val_acc: 0.8750\n",
            "Epoch 502/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5130 - acc: 0.7420 - val_loss: 0.5631 - val_acc: 0.7500\n",
            "Epoch 503/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5099 - acc: 0.7588 - val_loss: 0.5602 - val_acc: 0.7500\n",
            "Epoch 504/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.4979 - acc: 0.7436 - val_loss: 0.5734 - val_acc: 0.6250\n",
            "Epoch 505/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5051 - acc: 0.7468 - val_loss: 0.5655 - val_acc: 0.7500\n",
            "Epoch 506/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5178 - acc: 0.7404 - val_loss: 0.4612 - val_acc: 0.6875\n",
            "Epoch 507/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.4904 - acc: 0.7675 - val_loss: 0.4066 - val_acc: 0.7500\n",
            "Epoch 508/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.4923 - acc: 0.7476 - val_loss: 0.5944 - val_acc: 0.6875\n",
            "Epoch 509/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5030 - acc: 0.7500 - val_loss: 0.5816 - val_acc: 0.7500\n",
            "Epoch 510/1000\n",
            "79/79 [==============================] - 4s 50ms/step - loss: 0.5263 - acc: 0.7524 - val_loss: 0.5935 - val_acc: 0.6875\n",
            "Epoch 511/1000\n",
            "79/79 [==============================] - 4s 48ms/step - loss: 0.5193 - acc: 0.7341 - val_loss: 0.5728 - val_acc: 0.7500\n",
            "Epoch 512/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5164 - acc: 0.7468 - val_loss: 0.6334 - val_acc: 0.6875\n",
            "Epoch 513/1000\n",
            "79/79 [==============================] - 4s 47ms/step - loss: 0.4864 - acc: 0.7747 - val_loss: 0.5925 - val_acc: 0.6875\n",
            "Epoch 514/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5041 - acc: 0.7476 - val_loss: 0.4089 - val_acc: 0.8125\n",
            "Epoch 515/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5139 - acc: 0.7444 - val_loss: 0.5535 - val_acc: 0.7500\n",
            "Epoch 516/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5141 - acc: 0.7404 - val_loss: 0.5877 - val_acc: 0.6875\n",
            "Epoch 517/1000\n",
            "79/79 [==============================] - 4s 41ms/step - loss: 0.5170 - acc: 0.7500 - val_loss: 0.4322 - val_acc: 0.8125\n",
            "Epoch 518/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5095 - acc: 0.7572 - val_loss: 0.6371 - val_acc: 0.6250\n",
            "Epoch 519/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5286 - acc: 0.7468 - val_loss: 0.5607 - val_acc: 0.6875\n",
            "Epoch 520/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5081 - acc: 0.7588 - val_loss: 0.5577 - val_acc: 0.7500\n",
            "Epoch 521/1000\n",
            "79/79 [==============================] - 4s 50ms/step - loss: 0.5224 - acc: 0.7532 - val_loss: 0.3804 - val_acc: 0.8125\n",
            "Epoch 522/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5035 - acc: 0.7556 - val_loss: 0.5097 - val_acc: 0.6875\n",
            "Epoch 523/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.4932 - acc: 0.7715 - val_loss: 0.6285 - val_acc: 0.6250\n",
            "Epoch 524/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5151 - acc: 0.7572 - val_loss: 0.6054 - val_acc: 0.5625\n",
            "Epoch 525/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.4827 - acc: 0.7691 - val_loss: 0.4270 - val_acc: 0.7500\n",
            "Epoch 526/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5253 - acc: 0.7476 - val_loss: 0.3591 - val_acc: 0.8750\n",
            "Epoch 527/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5179 - acc: 0.7365 - val_loss: 0.3781 - val_acc: 0.7500\n",
            "Epoch 528/1000\n",
            "79/79 [==============================] - 4s 50ms/step - loss: 0.5053 - acc: 0.7516 - val_loss: 0.5065 - val_acc: 0.7500\n",
            "Epoch 529/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5126 - acc: 0.7524 - val_loss: 0.5842 - val_acc: 0.6875\n",
            "Epoch 530/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5163 - acc: 0.7420 - val_loss: 0.6215 - val_acc: 0.7500\n",
            "Epoch 531/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5213 - acc: 0.7420 - val_loss: 0.4508 - val_acc: 0.8125\n",
            "Epoch 532/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.4952 - acc: 0.7604 - val_loss: 0.5363 - val_acc: 0.6875\n",
            "Epoch 533/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5263 - acc: 0.7596 - val_loss: 0.6013 - val_acc: 0.6875\n",
            "Epoch 534/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5288 - acc: 0.7420 - val_loss: 0.5835 - val_acc: 0.6250\n",
            "Epoch 535/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5012 - acc: 0.7436 - val_loss: 0.4383 - val_acc: 0.7500\n",
            "Epoch 536/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5322 - acc: 0.7484 - val_loss: 0.5150 - val_acc: 0.7500\n",
            "Epoch 537/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5272 - acc: 0.7389 - val_loss: 0.5008 - val_acc: 0.7500\n",
            "Epoch 538/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5349 - acc: 0.7436 - val_loss: 0.3894 - val_acc: 0.8125\n",
            "Epoch 539/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.4992 - acc: 0.7611 - val_loss: 0.5537 - val_acc: 0.6875\n",
            "Epoch 540/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5307 - acc: 0.7396 - val_loss: 0.5663 - val_acc: 0.6250\n",
            "Epoch 541/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5112 - acc: 0.7412 - val_loss: 0.4390 - val_acc: 0.6250\n",
            "Epoch 542/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5301 - acc: 0.7468 - val_loss: 0.5314 - val_acc: 0.7500\n",
            "Epoch 543/1000\n",
            "79/79 [==============================] - 4s 49ms/step - loss: 0.5189 - acc: 0.7460 - val_loss: 0.3765 - val_acc: 0.8125\n",
            "Epoch 544/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.4996 - acc: 0.7484 - val_loss: 0.5911 - val_acc: 0.7500\n",
            "Epoch 545/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5490 - acc: 0.7301 - val_loss: 0.4331 - val_acc: 0.7500\n",
            "Epoch 546/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5077 - acc: 0.7508 - val_loss: 0.6089 - val_acc: 0.6875\n",
            "Epoch 547/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5160 - acc: 0.7484 - val_loss: 0.3852 - val_acc: 0.7500\n",
            "Epoch 548/1000\n",
            "79/79 [==============================] - 5s 50ms/step - loss: 0.5403 - acc: 0.7357 - val_loss: 0.3282 - val_acc: 0.8125\n",
            "Epoch 549/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5431 - acc: 0.7357 - val_loss: 0.5431 - val_acc: 0.6875\n",
            "Epoch 550/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5059 - acc: 0.7492 - val_loss: 0.6038 - val_acc: 0.6250\n",
            "Epoch 551/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5305 - acc: 0.7357 - val_loss: 0.4262 - val_acc: 0.6875\n",
            "Epoch 552/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5189 - acc: 0.7301 - val_loss: 0.4033 - val_acc: 0.7500\n",
            "Epoch 553/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5281 - acc: 0.7389 - val_loss: 0.4577 - val_acc: 0.7500\n",
            "Epoch 554/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5196 - acc: 0.7500 - val_loss: 0.4324 - val_acc: 0.7500\n",
            "Epoch 555/1000\n",
            "79/79 [==============================] - 4s 50ms/step - loss: 0.5242 - acc: 0.7564 - val_loss: 0.4952 - val_acc: 0.8125\n",
            "Epoch 556/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5120 - acc: 0.7492 - val_loss: 0.5971 - val_acc: 0.6875\n",
            "Epoch 557/1000\n",
            "79/79 [==============================] - 4s 47ms/step - loss: 0.5064 - acc: 0.7548 - val_loss: 0.4773 - val_acc: 0.7500\n",
            "Epoch 558/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5360 - acc: 0.7293 - val_loss: 0.5251 - val_acc: 0.7500\n",
            "Epoch 559/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5143 - acc: 0.7627 - val_loss: 0.4215 - val_acc: 0.7500\n",
            "Epoch 560/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5304 - acc: 0.7412 - val_loss: 0.6656 - val_acc: 0.6250\n",
            "Epoch 561/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5299 - acc: 0.7420 - val_loss: 0.5596 - val_acc: 0.6875\n",
            "Epoch 562/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5329 - acc: 0.7460 - val_loss: 0.6036 - val_acc: 0.6875\n",
            "Epoch 563/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5000 - acc: 0.7611 - val_loss: 0.6211 - val_acc: 0.6875\n",
            "Epoch 564/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.4910 - acc: 0.7604 - val_loss: 0.6218 - val_acc: 0.6250\n",
            "Epoch 565/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5309 - acc: 0.7389 - val_loss: 0.6238 - val_acc: 0.6250\n",
            "Epoch 566/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5130 - acc: 0.7492 - val_loss: 0.6703 - val_acc: 0.5625\n",
            "Epoch 567/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.4979 - acc: 0.7675 - val_loss: 0.4135 - val_acc: 0.7500\n",
            "Epoch 568/1000\n",
            "79/79 [==============================] - 4s 50ms/step - loss: 0.5308 - acc: 0.7452 - val_loss: 0.4633 - val_acc: 0.8125\n",
            "Epoch 569/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5268 - acc: 0.7412 - val_loss: 0.3398 - val_acc: 0.8125\n",
            "Epoch 570/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5341 - acc: 0.7420 - val_loss: 0.6023 - val_acc: 0.6875\n",
            "Epoch 571/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5059 - acc: 0.7516 - val_loss: 0.3405 - val_acc: 0.7500\n",
            "Epoch 572/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5143 - acc: 0.7556 - val_loss: 0.5102 - val_acc: 0.8125\n",
            "Epoch 573/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5473 - acc: 0.7301 - val_loss: 0.3318 - val_acc: 0.8750\n",
            "Epoch 574/1000\n",
            "79/79 [==============================] - 4s 49ms/step - loss: 0.5065 - acc: 0.7436 - val_loss: 0.5863 - val_acc: 0.6875\n",
            "Epoch 575/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5019 - acc: 0.7532 - val_loss: 0.3742 - val_acc: 0.7500\n",
            "Epoch 576/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5107 - acc: 0.7524 - val_loss: 0.5673 - val_acc: 0.7500\n",
            "Epoch 577/1000\n",
            "79/79 [==============================] - 4s 48ms/step - loss: 0.5373 - acc: 0.7301 - val_loss: 0.4345 - val_acc: 0.7500\n",
            "Epoch 578/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5136 - acc: 0.7476 - val_loss: 0.5970 - val_acc: 0.7500\n",
            "Epoch 579/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5261 - acc: 0.7484 - val_loss: 0.5420 - val_acc: 0.6875\n",
            "Epoch 580/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5073 - acc: 0.7548 - val_loss: 0.6556 - val_acc: 0.6875\n",
            "Epoch 581/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5124 - acc: 0.7373 - val_loss: 0.6391 - val_acc: 0.6250\n",
            "Epoch 582/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5028 - acc: 0.7508 - val_loss: 0.6519 - val_acc: 0.5625\n",
            "Epoch 583/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5140 - acc: 0.7460 - val_loss: 0.5787 - val_acc: 0.7500\n",
            "Epoch 584/1000\n",
            "79/79 [==============================] - 4s 48ms/step - loss: 0.5302 - acc: 0.7357 - val_loss: 0.6488 - val_acc: 0.6250\n",
            "Epoch 585/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5103 - acc: 0.7516 - val_loss: 0.4733 - val_acc: 0.7500\n",
            "Epoch 586/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5059 - acc: 0.7627 - val_loss: 0.4380 - val_acc: 0.8125\n",
            "Epoch 587/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5036 - acc: 0.7659 - val_loss: 0.5320 - val_acc: 0.7500\n",
            "Epoch 588/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5125 - acc: 0.7532 - val_loss: 0.6349 - val_acc: 0.6875\n",
            "Epoch 589/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.4985 - acc: 0.7532 - val_loss: 0.3882 - val_acc: 0.6875\n",
            "Epoch 590/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5023 - acc: 0.7580 - val_loss: 0.6000 - val_acc: 0.6250\n",
            "Epoch 591/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.4998 - acc: 0.7611 - val_loss: 0.5700 - val_acc: 0.7500\n",
            "Epoch 592/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5091 - acc: 0.7588 - val_loss: 0.4049 - val_acc: 0.7500\n",
            "Epoch 593/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5357 - acc: 0.7516 - val_loss: 0.4089 - val_acc: 0.8125\n",
            "Epoch 594/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5113 - acc: 0.7548 - val_loss: 0.5832 - val_acc: 0.6875\n",
            "Epoch 595/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5151 - acc: 0.7428 - val_loss: 0.6142 - val_acc: 0.6875\n",
            "Epoch 596/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5139 - acc: 0.7659 - val_loss: 0.6074 - val_acc: 0.6875\n",
            "Epoch 597/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5353 - acc: 0.7436 - val_loss: 0.5155 - val_acc: 0.8125\n",
            "Epoch 598/1000\n",
            "79/79 [==============================] - 4s 50ms/step - loss: 0.5360 - acc: 0.7253 - val_loss: 0.4148 - val_acc: 0.7500\n",
            "Epoch 599/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5360 - acc: 0.7333 - val_loss: 0.5969 - val_acc: 0.6875\n",
            "Epoch 600/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5242 - acc: 0.7500 - val_loss: 0.5191 - val_acc: 0.7500\n",
            "Epoch 601/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5197 - acc: 0.7460 - val_loss: 0.5531 - val_acc: 0.7500\n",
            "Epoch 602/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5184 - acc: 0.7404 - val_loss: 0.6998 - val_acc: 0.5625\n",
            "Epoch 603/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5119 - acc: 0.7516 - val_loss: 0.6501 - val_acc: 0.6250\n",
            "Epoch 604/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5217 - acc: 0.7365 - val_loss: 0.6407 - val_acc: 0.6250\n",
            "Epoch 605/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5060 - acc: 0.7396 - val_loss: 0.5537 - val_acc: 0.6875\n",
            "Epoch 606/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5201 - acc: 0.7548 - val_loss: 0.5814 - val_acc: 0.7500\n",
            "Epoch 607/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5133 - acc: 0.7524 - val_loss: 0.5025 - val_acc: 0.8125\n",
            "Epoch 608/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5157 - acc: 0.7460 - val_loss: 0.6218 - val_acc: 0.6875\n",
            "Epoch 609/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5167 - acc: 0.7436 - val_loss: 0.4184 - val_acc: 0.7500\n",
            "Epoch 610/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5165 - acc: 0.7532 - val_loss: 0.5921 - val_acc: 0.6875\n",
            "Epoch 611/1000\n",
            "79/79 [==============================] - 5s 51ms/step - loss: 0.5114 - acc: 0.7580 - val_loss: 0.6153 - val_acc: 0.7500\n",
            "Epoch 612/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5309 - acc: 0.7428 - val_loss: 0.6577 - val_acc: 0.6875\n",
            "Epoch 613/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5320 - acc: 0.7396 - val_loss: 0.3867 - val_acc: 0.6875\n",
            "Epoch 614/1000\n",
            "79/79 [==============================] - 4s 47ms/step - loss: 0.5296 - acc: 0.7365 - val_loss: 0.6555 - val_acc: 0.6875\n",
            "Epoch 615/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5275 - acc: 0.7460 - val_loss: 0.5459 - val_acc: 0.7500\n",
            "Epoch 616/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5331 - acc: 0.7468 - val_loss: 0.4291 - val_acc: 0.7500\n",
            "Epoch 617/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.4941 - acc: 0.7516 - val_loss: 0.6326 - val_acc: 0.6875\n",
            "Epoch 618/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5197 - acc: 0.7548 - val_loss: 0.3060 - val_acc: 0.8750\n",
            "Epoch 619/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5364 - acc: 0.7341 - val_loss: 0.5597 - val_acc: 0.8125\n",
            "Epoch 620/1000\n",
            "79/79 [==============================] - 5s 50ms/step - loss: 0.5132 - acc: 0.7444 - val_loss: 0.4237 - val_acc: 0.7500\n",
            "Epoch 621/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5290 - acc: 0.7317 - val_loss: 0.5217 - val_acc: 0.7500\n",
            "Epoch 622/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5405 - acc: 0.7357 - val_loss: 0.3853 - val_acc: 0.7500\n",
            "Epoch 623/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5206 - acc: 0.7285 - val_loss: 0.3646 - val_acc: 0.7500\n",
            "Epoch 624/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5271 - acc: 0.7404 - val_loss: 0.6368 - val_acc: 0.6250\n",
            "Epoch 625/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5372 - acc: 0.7492 - val_loss: 0.5862 - val_acc: 0.7500\n",
            "Epoch 626/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5181 - acc: 0.7444 - val_loss: 0.5418 - val_acc: 0.6875\n",
            "Epoch 627/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5020 - acc: 0.7524 - val_loss: 0.6114 - val_acc: 0.6875\n",
            "Epoch 628/1000\n",
            "79/79 [==============================] - 4s 50ms/step - loss: 0.5221 - acc: 0.7436 - val_loss: 0.5152 - val_acc: 0.8125\n",
            "Epoch 629/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5261 - acc: 0.7428 - val_loss: 0.5012 - val_acc: 0.8125\n",
            "Epoch 630/1000\n",
            "79/79 [==============================] - 5s 50ms/step - loss: 0.5298 - acc: 0.7436 - val_loss: 0.5395 - val_acc: 0.7500\n",
            "Epoch 631/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5205 - acc: 0.7436 - val_loss: 0.6574 - val_acc: 0.5625\n",
            "Epoch 632/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5146 - acc: 0.7484 - val_loss: 0.5704 - val_acc: 0.6875\n",
            "Epoch 633/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5162 - acc: 0.7381 - val_loss: 0.5996 - val_acc: 0.7500\n",
            "Epoch 634/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5096 - acc: 0.7468 - val_loss: 0.6097 - val_acc: 0.6875\n",
            "Epoch 635/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5383 - acc: 0.7253 - val_loss: 0.6152 - val_acc: 0.6875\n",
            "Epoch 636/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5306 - acc: 0.7373 - val_loss: 0.4605 - val_acc: 0.7500\n",
            "Epoch 637/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5251 - acc: 0.7516 - val_loss: 0.6592 - val_acc: 0.6250\n",
            "Epoch 638/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5117 - acc: 0.7524 - val_loss: 0.5446 - val_acc: 0.8125\n",
            "Epoch 639/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5006 - acc: 0.7635 - val_loss: 0.5908 - val_acc: 0.6250\n",
            "Epoch 640/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5212 - acc: 0.7460 - val_loss: 0.6386 - val_acc: 0.7500\n",
            "Epoch 641/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5205 - acc: 0.7420 - val_loss: 0.6246 - val_acc: 0.6875\n",
            "Epoch 642/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5152 - acc: 0.7604 - val_loss: 0.5229 - val_acc: 0.7500\n",
            "Epoch 643/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5058 - acc: 0.7460 - val_loss: 0.5597 - val_acc: 0.7500\n",
            "Epoch 644/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5154 - acc: 0.7643 - val_loss: 0.5737 - val_acc: 0.7500\n",
            "Epoch 645/1000\n",
            "79/79 [==============================] - 4s 47ms/step - loss: 0.5196 - acc: 0.7556 - val_loss: 0.3520 - val_acc: 0.8125\n",
            "Epoch 646/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5214 - acc: 0.7556 - val_loss: 0.6594 - val_acc: 0.6875\n",
            "Epoch 647/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5135 - acc: 0.7572 - val_loss: 0.3630 - val_acc: 0.8125\n",
            "Epoch 648/1000\n",
            "79/79 [==============================] - 4s 48ms/step - loss: 0.5111 - acc: 0.7365 - val_loss: 0.5637 - val_acc: 0.7500\n",
            "Epoch 649/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5223 - acc: 0.7611 - val_loss: 0.5840 - val_acc: 0.7500\n",
            "Epoch 650/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5179 - acc: 0.7548 - val_loss: 0.5426 - val_acc: 0.7500\n",
            "Epoch 651/1000\n",
            "79/79 [==============================] - 4s 48ms/step - loss: 0.5084 - acc: 0.7484 - val_loss: 0.6538 - val_acc: 0.7500\n",
            "Epoch 652/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5335 - acc: 0.7293 - val_loss: 0.4186 - val_acc: 0.7500\n",
            "Epoch 653/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5243 - acc: 0.7500 - val_loss: 0.5845 - val_acc: 0.7500\n",
            "Epoch 654/1000\n",
            "79/79 [==============================] - 5s 51ms/step - loss: 0.5224 - acc: 0.7389 - val_loss: 0.6069 - val_acc: 0.6875\n",
            "Epoch 655/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5267 - acc: 0.7444 - val_loss: 0.4546 - val_acc: 0.8125\n",
            "Epoch 656/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.4936 - acc: 0.7604 - val_loss: 0.3091 - val_acc: 0.8125\n",
            "Epoch 657/1000\n",
            "79/79 [==============================] - 5s 51ms/step - loss: 0.5174 - acc: 0.7548 - val_loss: 0.5165 - val_acc: 0.8125\n",
            "Epoch 658/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5201 - acc: 0.7373 - val_loss: 0.5430 - val_acc: 0.7500\n",
            "Epoch 659/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5087 - acc: 0.7476 - val_loss: 0.5991 - val_acc: 0.6250\n",
            "Epoch 660/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5086 - acc: 0.7412 - val_loss: 0.4693 - val_acc: 0.7500\n",
            "Epoch 661/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5240 - acc: 0.7508 - val_loss: 0.6130 - val_acc: 0.6250\n",
            "Epoch 662/1000\n",
            "79/79 [==============================] - 4s 50ms/step - loss: 0.5066 - acc: 0.7548 - val_loss: 0.4047 - val_acc: 0.7500\n",
            "Epoch 663/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5157 - acc: 0.7524 - val_loss: 0.5540 - val_acc: 0.6875\n",
            "Epoch 664/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5199 - acc: 0.7580 - val_loss: 0.5858 - val_acc: 0.6875\n",
            "Epoch 665/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5083 - acc: 0.7548 - val_loss: 0.5462 - val_acc: 0.6875\n",
            "Epoch 666/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5078 - acc: 0.7524 - val_loss: 0.5828 - val_acc: 0.6875\n",
            "Epoch 667/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5045 - acc: 0.7548 - val_loss: 0.3878 - val_acc: 0.7500\n",
            "Epoch 668/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5016 - acc: 0.7619 - val_loss: 0.4700 - val_acc: 0.8125\n",
            "Epoch 669/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5157 - acc: 0.7468 - val_loss: 0.5694 - val_acc: 0.6875\n",
            "Epoch 670/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5019 - acc: 0.7516 - val_loss: 0.5792 - val_acc: 0.6875\n",
            "Epoch 671/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5015 - acc: 0.7492 - val_loss: 0.5464 - val_acc: 0.7500\n",
            "Epoch 672/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5159 - acc: 0.7508 - val_loss: 0.3852 - val_acc: 0.8125\n",
            "Epoch 673/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.4942 - acc: 0.7635 - val_loss: 0.4353 - val_acc: 0.6875\n",
            "Epoch 674/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5011 - acc: 0.7691 - val_loss: 0.5076 - val_acc: 0.6875\n",
            "Epoch 675/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5111 - acc: 0.7532 - val_loss: 0.6132 - val_acc: 0.6250\n",
            "Epoch 676/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5107 - acc: 0.7619 - val_loss: 0.5540 - val_acc: 0.7500\n",
            "Epoch 677/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5283 - acc: 0.7420 - val_loss: 0.4776 - val_acc: 0.6875\n",
            "Epoch 678/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5332 - acc: 0.7349 - val_loss: 0.3907 - val_acc: 0.7500\n",
            "Epoch 679/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5164 - acc: 0.7293 - val_loss: 0.5222 - val_acc: 0.7500\n",
            "Epoch 680/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.4857 - acc: 0.7691 - val_loss: 0.4609 - val_acc: 0.6875\n",
            "Epoch 681/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5141 - acc: 0.7373 - val_loss: 0.5590 - val_acc: 0.6875\n",
            "Epoch 682/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5410 - acc: 0.7396 - val_loss: 0.6049 - val_acc: 0.6875\n",
            "Epoch 683/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5220 - acc: 0.7532 - val_loss: 0.6332 - val_acc: 0.6875\n",
            "Epoch 684/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5334 - acc: 0.7460 - val_loss: 0.5251 - val_acc: 0.6875\n",
            "Epoch 685/1000\n",
            "79/79 [==============================] - 5s 52ms/step - loss: 0.5082 - acc: 0.7524 - val_loss: 0.5922 - val_acc: 0.6875\n",
            "Epoch 686/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5575 - acc: 0.7349 - val_loss: 0.5826 - val_acc: 0.6875\n",
            "Epoch 687/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5130 - acc: 0.7420 - val_loss: 0.5774 - val_acc: 0.7500\n",
            "Epoch 688/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5036 - acc: 0.7667 - val_loss: 0.5286 - val_acc: 0.7500\n",
            "Epoch 689/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5073 - acc: 0.7444 - val_loss: 0.5911 - val_acc: 0.6875\n",
            "Epoch 690/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5209 - acc: 0.7412 - val_loss: 0.6407 - val_acc: 0.6875\n",
            "Epoch 691/1000\n",
            "79/79 [==============================] - 4s 47ms/step - loss: 0.5189 - acc: 0.7476 - val_loss: 0.5860 - val_acc: 0.7500\n",
            "Epoch 692/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5295 - acc: 0.7381 - val_loss: 0.4389 - val_acc: 0.7500\n",
            "Epoch 693/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5241 - acc: 0.7460 - val_loss: 0.4860 - val_acc: 0.8125\n",
            "Epoch 694/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5263 - acc: 0.7524 - val_loss: 0.7073 - val_acc: 0.6250\n",
            "Epoch 695/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5170 - acc: 0.7452 - val_loss: 0.6910 - val_acc: 0.6250\n",
            "Epoch 696/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5138 - acc: 0.7389 - val_loss: 0.4949 - val_acc: 0.7500\n",
            "Epoch 697/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5106 - acc: 0.7532 - val_loss: 0.6386 - val_acc: 0.6875\n",
            "Epoch 698/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5242 - acc: 0.7500 - val_loss: 0.6190 - val_acc: 0.6250\n",
            "Epoch 699/1000\n",
            "79/79 [==============================] - 4s 50ms/step - loss: 0.5399 - acc: 0.7325 - val_loss: 0.5354 - val_acc: 0.8125\n",
            "Epoch 700/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5072 - acc: 0.7564 - val_loss: 0.6739 - val_acc: 0.6250\n",
            "Epoch 701/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5168 - acc: 0.7460 - val_loss: 0.6304 - val_acc: 0.6875\n",
            "Epoch 702/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5401 - acc: 0.7381 - val_loss: 0.6393 - val_acc: 0.6875\n",
            "Epoch 703/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5404 - acc: 0.7381 - val_loss: 0.6337 - val_acc: 0.6875\n",
            "Epoch 704/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5504 - acc: 0.7269 - val_loss: 0.4103 - val_acc: 0.7500\n",
            "Epoch 705/1000\n",
            "79/79 [==============================] - 4s 47ms/step - loss: 0.4971 - acc: 0.7604 - val_loss: 0.5401 - val_acc: 0.8125\n",
            "Epoch 706/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5085 - acc: 0.7596 - val_loss: 0.6352 - val_acc: 0.6875\n",
            "Epoch 707/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5210 - acc: 0.7373 - val_loss: 0.7011 - val_acc: 0.6250\n",
            "Epoch 708/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5070 - acc: 0.7508 - val_loss: 0.4933 - val_acc: 0.7500\n",
            "Epoch 709/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5236 - acc: 0.7420 - val_loss: 0.5271 - val_acc: 0.7500\n",
            "Epoch 710/1000\n",
            "79/79 [==============================] - 5s 50ms/step - loss: 0.5310 - acc: 0.7404 - val_loss: 0.5743 - val_acc: 0.7500\n",
            "Epoch 711/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5190 - acc: 0.7476 - val_loss: 0.4609 - val_acc: 0.6875\n",
            "Epoch 712/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5115 - acc: 0.7548 - val_loss: 0.5242 - val_acc: 0.7500\n",
            "Epoch 713/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5133 - acc: 0.7476 - val_loss: 0.6091 - val_acc: 0.6250\n",
            "Epoch 714/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5170 - acc: 0.7412 - val_loss: 0.4792 - val_acc: 0.7500\n",
            "Epoch 715/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5270 - acc: 0.7396 - val_loss: 0.6125 - val_acc: 0.6875\n",
            "Epoch 716/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5355 - acc: 0.7381 - val_loss: 0.5336 - val_acc: 0.7500\n",
            "Epoch 717/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5100 - acc: 0.7556 - val_loss: 0.4170 - val_acc: 0.7500\n",
            "Epoch 718/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5204 - acc: 0.7468 - val_loss: 0.6330 - val_acc: 0.6875\n",
            "Epoch 719/1000\n",
            "79/79 [==============================] - 4s 47ms/step - loss: 0.5107 - acc: 0.7516 - val_loss: 0.3455 - val_acc: 0.8125\n",
            "Epoch 720/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5320 - acc: 0.7333 - val_loss: 0.4314 - val_acc: 0.7500\n",
            "Epoch 721/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5235 - acc: 0.7325 - val_loss: 0.6023 - val_acc: 0.6875\n",
            "Epoch 722/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5231 - acc: 0.7404 - val_loss: 0.4651 - val_acc: 0.8125\n",
            "Epoch 723/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5242 - acc: 0.7492 - val_loss: 0.3824 - val_acc: 0.7500\n",
            "Epoch 724/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5483 - acc: 0.7277 - val_loss: 0.3517 - val_acc: 0.7500\n",
            "Epoch 725/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5093 - acc: 0.7412 - val_loss: 0.6558 - val_acc: 0.6250\n",
            "Epoch 726/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5273 - acc: 0.7580 - val_loss: 0.5104 - val_acc: 0.8125\n",
            "Epoch 727/1000\n",
            "79/79 [==============================] - 5s 51ms/step - loss: 0.5205 - acc: 0.7468 - val_loss: 0.3498 - val_acc: 0.8750\n",
            "Epoch 728/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5282 - acc: 0.7436 - val_loss: 0.6190 - val_acc: 0.6250\n",
            "Epoch 729/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5407 - acc: 0.7404 - val_loss: 0.3016 - val_acc: 0.8750\n",
            "Epoch 730/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.4966 - acc: 0.7580 - val_loss: 0.5071 - val_acc: 0.8125\n",
            "Epoch 731/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5053 - acc: 0.7532 - val_loss: 0.3663 - val_acc: 0.8125\n",
            "Epoch 732/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5076 - acc: 0.7484 - val_loss: 0.4796 - val_acc: 0.7500\n",
            "Epoch 733/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5275 - acc: 0.7444 - val_loss: 0.4686 - val_acc: 0.8125\n",
            "Epoch 734/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5298 - acc: 0.7500 - val_loss: 0.4591 - val_acc: 0.8750\n",
            "Epoch 735/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5347 - acc: 0.7349 - val_loss: 0.5861 - val_acc: 0.6875\n",
            "Epoch 736/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5234 - acc: 0.7460 - val_loss: 0.6167 - val_acc: 0.6875\n",
            "Epoch 737/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5079 - acc: 0.7540 - val_loss: 0.5200 - val_acc: 0.6875\n",
            "Epoch 738/1000\n",
            "79/79 [==============================] - 5s 50ms/step - loss: 0.5325 - acc: 0.7404 - val_loss: 0.5406 - val_acc: 0.7500\n",
            "Epoch 739/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5117 - acc: 0.7643 - val_loss: 0.6268 - val_acc: 0.6250\n",
            "Epoch 740/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5157 - acc: 0.7444 - val_loss: 0.5898 - val_acc: 0.6875\n",
            "Epoch 741/1000\n",
            "79/79 [==============================] - 5s 52ms/step - loss: 0.5262 - acc: 0.7389 - val_loss: 0.5744 - val_acc: 0.6875\n",
            "Epoch 742/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5177 - acc: 0.7436 - val_loss: 0.5920 - val_acc: 0.6875\n",
            "Epoch 743/1000\n",
            "79/79 [==============================] - 5s 50ms/step - loss: 0.5108 - acc: 0.7548 - val_loss: 0.6286 - val_acc: 0.6875\n",
            "Epoch 744/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5363 - acc: 0.7412 - val_loss: 0.6182 - val_acc: 0.6875\n",
            "Epoch 745/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5457 - acc: 0.7237 - val_loss: 0.6333 - val_acc: 0.6875\n",
            "Epoch 746/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5283 - acc: 0.7508 - val_loss: 0.2439 - val_acc: 0.9375\n",
            "Epoch 747/1000\n",
            "79/79 [==============================] - 5s 51ms/step - loss: 0.5199 - acc: 0.7516 - val_loss: 0.5832 - val_acc: 0.6875\n",
            "Epoch 748/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5014 - acc: 0.7604 - val_loss: 0.6034 - val_acc: 0.7500\n",
            "Epoch 749/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5249 - acc: 0.7412 - val_loss: 0.4675 - val_acc: 0.8125\n",
            "Epoch 750/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5149 - acc: 0.7436 - val_loss: 0.4433 - val_acc: 0.6875\n",
            "Epoch 751/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.4952 - acc: 0.7588 - val_loss: 0.5760 - val_acc: 0.6875\n",
            "Epoch 752/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5227 - acc: 0.7373 - val_loss: 0.4104 - val_acc: 0.8125\n",
            "Epoch 753/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5252 - acc: 0.7412 - val_loss: 0.5907 - val_acc: 0.7500\n",
            "Epoch 754/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5223 - acc: 0.7428 - val_loss: 0.5057 - val_acc: 0.6875\n",
            "Epoch 755/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5196 - acc: 0.7500 - val_loss: 0.2887 - val_acc: 0.8125\n",
            "Epoch 756/1000\n",
            "79/79 [==============================] - 4s 50ms/step - loss: 0.5179 - acc: 0.7293 - val_loss: 0.3175 - val_acc: 0.8125\n",
            "Epoch 757/1000\n",
            "79/79 [==============================] - 5s 51ms/step - loss: 0.5122 - acc: 0.7484 - val_loss: 0.5680 - val_acc: 0.6875\n",
            "Epoch 758/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5064 - acc: 0.7524 - val_loss: 0.6741 - val_acc: 0.6250\n",
            "Epoch 759/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5272 - acc: 0.7381 - val_loss: 0.5088 - val_acc: 0.7500\n",
            "Epoch 760/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5141 - acc: 0.7508 - val_loss: 0.3942 - val_acc: 0.7500\n",
            "Epoch 761/1000\n",
            "79/79 [==============================] - 4s 50ms/step - loss: 0.5007 - acc: 0.7691 - val_loss: 0.6263 - val_acc: 0.7500\n",
            "Epoch 762/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5093 - acc: 0.7492 - val_loss: 0.4303 - val_acc: 0.7500\n",
            "Epoch 763/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.4921 - acc: 0.7659 - val_loss: 0.2752 - val_acc: 0.9375\n",
            "Epoch 764/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.4900 - acc: 0.7596 - val_loss: 0.5906 - val_acc: 0.6875\n",
            "Epoch 765/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5148 - acc: 0.7484 - val_loss: 0.6590 - val_acc: 0.6250\n",
            "Epoch 766/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5102 - acc: 0.7404 - val_loss: 0.4632 - val_acc: 0.6875\n",
            "Epoch 767/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.4875 - acc: 0.7580 - val_loss: 0.5913 - val_acc: 0.6875\n",
            "Epoch 768/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5208 - acc: 0.7301 - val_loss: 0.5658 - val_acc: 0.6875\n",
            "Epoch 769/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5109 - acc: 0.7492 - val_loss: 0.4516 - val_acc: 0.7500\n",
            "Epoch 770/1000\n",
            "79/79 [==============================] - 4s 49ms/step - loss: 0.5021 - acc: 0.7707 - val_loss: 0.5130 - val_acc: 0.7500\n",
            "Epoch 771/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5299 - acc: 0.7500 - val_loss: 0.4921 - val_acc: 0.7500\n",
            "Epoch 772/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5325 - acc: 0.7365 - val_loss: 0.4085 - val_acc: 0.7500\n",
            "Epoch 773/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5319 - acc: 0.7452 - val_loss: 0.4411 - val_acc: 0.6875\n",
            "Epoch 774/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5052 - acc: 0.7484 - val_loss: 0.5947 - val_acc: 0.6875\n",
            "Epoch 775/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5290 - acc: 0.7452 - val_loss: 0.4762 - val_acc: 0.7500\n",
            "Epoch 776/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5232 - acc: 0.7365 - val_loss: 0.5630 - val_acc: 0.6875\n",
            "Epoch 777/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5219 - acc: 0.7452 - val_loss: 0.4578 - val_acc: 0.8125\n",
            "Epoch 778/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5161 - acc: 0.7373 - val_loss: 0.4670 - val_acc: 0.6875\n",
            "Epoch 779/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5141 - acc: 0.7548 - val_loss: 0.5354 - val_acc: 0.7500\n",
            "Epoch 780/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5087 - acc: 0.7524 - val_loss: 0.5474 - val_acc: 0.7500\n",
            "Epoch 781/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5100 - acc: 0.7588 - val_loss: 0.5371 - val_acc: 0.7500\n",
            "Epoch 782/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5255 - acc: 0.7476 - val_loss: 0.5531 - val_acc: 0.6875\n",
            "Epoch 783/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5064 - acc: 0.7548 - val_loss: 0.4989 - val_acc: 0.8125\n",
            "Epoch 784/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5287 - acc: 0.7484 - val_loss: 0.4646 - val_acc: 0.6875\n",
            "Epoch 785/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5234 - acc: 0.7604 - val_loss: 0.4719 - val_acc: 0.6875\n",
            "Epoch 786/1000\n",
            "79/79 [==============================] - 4s 48ms/step - loss: 0.4843 - acc: 0.7532 - val_loss: 0.4161 - val_acc: 0.7500\n",
            "Epoch 787/1000\n",
            "79/79 [==============================] - 5s 51ms/step - loss: 0.5073 - acc: 0.7564 - val_loss: 0.6404 - val_acc: 0.6250\n",
            "Epoch 788/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5179 - acc: 0.7627 - val_loss: 0.6157 - val_acc: 0.6875\n",
            "Epoch 789/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.4815 - acc: 0.7627 - val_loss: 0.3832 - val_acc: 0.7500\n",
            "Epoch 790/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5105 - acc: 0.7293 - val_loss: 0.5687 - val_acc: 0.6875\n",
            "Epoch 791/1000\n",
            "79/79 [==============================] - 5s 51ms/step - loss: 0.5278 - acc: 0.7508 - val_loss: 0.4590 - val_acc: 0.8125\n",
            "Epoch 792/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5306 - acc: 0.7460 - val_loss: 0.2177 - val_acc: 0.9375\n",
            "Epoch 793/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5166 - acc: 0.7452 - val_loss: 0.6202 - val_acc: 0.6250\n",
            "Epoch 794/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5293 - acc: 0.7428 - val_loss: 0.4659 - val_acc: 0.6875\n",
            "Epoch 795/1000\n",
            "79/79 [==============================] - 4s 50ms/step - loss: 0.5086 - acc: 0.7460 - val_loss: 0.5436 - val_acc: 0.7500\n",
            "Epoch 796/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5379 - acc: 0.7508 - val_loss: 0.5615 - val_acc: 0.7500\n",
            "Epoch 797/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.4915 - acc: 0.7699 - val_loss: 0.6314 - val_acc: 0.6250\n",
            "Epoch 798/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5132 - acc: 0.7564 - val_loss: 0.3465 - val_acc: 0.8125\n",
            "Epoch 799/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.4969 - acc: 0.7604 - val_loss: 0.4974 - val_acc: 0.7500\n",
            "Epoch 800/1000\n",
            "79/79 [==============================] - 4s 49ms/step - loss: 0.5028 - acc: 0.7540 - val_loss: 0.4515 - val_acc: 0.6875\n",
            "Epoch 801/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5117 - acc: 0.7596 - val_loss: 0.5119 - val_acc: 0.7500\n",
            "Epoch 802/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5183 - acc: 0.7468 - val_loss: 0.6167 - val_acc: 0.6250\n",
            "Epoch 803/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5339 - acc: 0.7333 - val_loss: 0.3558 - val_acc: 0.7500\n",
            "Epoch 804/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.4917 - acc: 0.7619 - val_loss: 0.5125 - val_acc: 0.8125\n",
            "Epoch 805/1000\n",
            "79/79 [==============================] - 5s 53ms/step - loss: 0.5220 - acc: 0.7484 - val_loss: 0.5759 - val_acc: 0.6875\n",
            "Epoch 806/1000\n",
            "79/79 [==============================] - 4s 47ms/step - loss: 0.5341 - acc: 0.7452 - val_loss: 0.5984 - val_acc: 0.6875\n",
            "Epoch 807/1000\n",
            "79/79 [==============================] - 4s 48ms/step - loss: 0.4812 - acc: 0.7739 - val_loss: 0.4465 - val_acc: 0.7500\n",
            "Epoch 808/1000\n",
            "79/79 [==============================] - 5s 50ms/step - loss: 0.5216 - acc: 0.7516 - val_loss: 0.5454 - val_acc: 0.6875\n",
            "Epoch 809/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5114 - acc: 0.7452 - val_loss: 0.5295 - val_acc: 0.6875\n",
            "Epoch 810/1000\n",
            "79/79 [==============================] - 5s 52ms/step - loss: 0.5069 - acc: 0.7468 - val_loss: 0.3841 - val_acc: 0.7500\n",
            "Epoch 811/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5102 - acc: 0.7532 - val_loss: 0.4065 - val_acc: 0.8125\n",
            "Epoch 812/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5284 - acc: 0.7524 - val_loss: 0.6337 - val_acc: 0.6875\n",
            "Epoch 813/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5322 - acc: 0.7460 - val_loss: 0.6233 - val_acc: 0.7500\n",
            "Epoch 814/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5147 - acc: 0.7325 - val_loss: 0.3898 - val_acc: 0.8125\n",
            "Epoch 815/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5138 - acc: 0.7460 - val_loss: 0.5614 - val_acc: 0.7500\n",
            "Epoch 816/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5158 - acc: 0.7420 - val_loss: 0.5322 - val_acc: 0.8125\n",
            "Epoch 817/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5010 - acc: 0.7436 - val_loss: 0.4377 - val_acc: 0.6875\n",
            "Epoch 818/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5157 - acc: 0.7373 - val_loss: 0.4056 - val_acc: 0.8125\n",
            "Epoch 819/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5240 - acc: 0.7500 - val_loss: 0.5595 - val_acc: 0.7500\n",
            "Epoch 820/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5080 - acc: 0.7468 - val_loss: 0.4492 - val_acc: 0.7500\n",
            "Epoch 821/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5148 - acc: 0.7500 - val_loss: 0.3101 - val_acc: 0.8750\n",
            "Epoch 822/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.4939 - acc: 0.7428 - val_loss: 0.5328 - val_acc: 0.6875\n",
            "Epoch 823/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5227 - acc: 0.7516 - val_loss: 0.3374 - val_acc: 0.8125\n",
            "Epoch 824/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5071 - acc: 0.7675 - val_loss: 0.5917 - val_acc: 0.6875\n",
            "Epoch 825/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5284 - acc: 0.7373 - val_loss: 0.3070 - val_acc: 0.8125\n",
            "Epoch 826/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5207 - acc: 0.7532 - val_loss: 0.6361 - val_acc: 0.6875\n",
            "Epoch 827/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5049 - acc: 0.7508 - val_loss: 0.5635 - val_acc: 0.7500\n",
            "Epoch 828/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5309 - acc: 0.7381 - val_loss: 0.6064 - val_acc: 0.6875\n",
            "Epoch 829/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5194 - acc: 0.7707 - val_loss: 0.5849 - val_acc: 0.7500\n",
            "Epoch 830/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.4992 - acc: 0.7619 - val_loss: 0.6398 - val_acc: 0.6250\n",
            "Epoch 831/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5287 - acc: 0.7381 - val_loss: 0.5117 - val_acc: 0.7500\n",
            "Epoch 832/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5177 - acc: 0.7611 - val_loss: 0.5880 - val_acc: 0.7500\n",
            "Epoch 833/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5179 - acc: 0.7412 - val_loss: 0.6631 - val_acc: 0.6250\n",
            "Epoch 834/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5271 - acc: 0.7556 - val_loss: 0.4030 - val_acc: 0.7500\n",
            "Epoch 835/1000\n",
            "79/79 [==============================] - 4s 49ms/step - loss: 0.5369 - acc: 0.7444 - val_loss: 0.3813 - val_acc: 0.7500\n",
            "Epoch 836/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5260 - acc: 0.7476 - val_loss: 0.6469 - val_acc: 0.6875\n",
            "Epoch 837/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5222 - acc: 0.7277 - val_loss: 0.6082 - val_acc: 0.6875\n",
            "Epoch 838/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5179 - acc: 0.7564 - val_loss: 0.6885 - val_acc: 0.6250\n",
            "Epoch 839/1000\n",
            "79/79 [==============================] - 4s 47ms/step - loss: 0.5232 - acc: 0.7381 - val_loss: 0.6128 - val_acc: 0.7500\n",
            "Epoch 840/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5245 - acc: 0.7444 - val_loss: 0.4818 - val_acc: 0.8125\n",
            "Epoch 841/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5191 - acc: 0.7405 - val_loss: 0.4107 - val_acc: 0.8125\n",
            "Epoch 842/1000\n",
            "79/79 [==============================] - 4s 48ms/step - loss: 0.4994 - acc: 0.7643 - val_loss: 0.5675 - val_acc: 0.7500\n",
            "Epoch 843/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5193 - acc: 0.7468 - val_loss: 0.5729 - val_acc: 0.7500\n",
            "Epoch 844/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.4935 - acc: 0.7643 - val_loss: 0.4449 - val_acc: 0.6875\n",
            "Epoch 845/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5434 - acc: 0.7381 - val_loss: 0.5208 - val_acc: 0.7500\n",
            "Epoch 846/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5095 - acc: 0.7588 - val_loss: 0.4891 - val_acc: 0.7500\n",
            "Epoch 847/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5114 - acc: 0.7540 - val_loss: 0.6224 - val_acc: 0.6875\n",
            "Epoch 848/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.4988 - acc: 0.7460 - val_loss: 0.4172 - val_acc: 0.7500\n",
            "Epoch 849/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5151 - acc: 0.7381 - val_loss: 0.6620 - val_acc: 0.6250\n",
            "Epoch 850/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5249 - acc: 0.7389 - val_loss: 0.6253 - val_acc: 0.6875\n",
            "Epoch 851/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5197 - acc: 0.7468 - val_loss: 0.5674 - val_acc: 0.7500\n",
            "Epoch 852/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5168 - acc: 0.7476 - val_loss: 0.3825 - val_acc: 0.7500\n",
            "Epoch 853/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5210 - acc: 0.7373 - val_loss: 0.3711 - val_acc: 0.7500\n",
            "Epoch 854/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5111 - acc: 0.7452 - val_loss: 0.5780 - val_acc: 0.7500\n",
            "Epoch 855/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5338 - acc: 0.7309 - val_loss: 0.5905 - val_acc: 0.7500\n",
            "Epoch 856/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5017 - acc: 0.7540 - val_loss: 0.5215 - val_acc: 0.6875\n",
            "Epoch 857/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.4956 - acc: 0.7619 - val_loss: 0.6672 - val_acc: 0.6875\n",
            "Epoch 858/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5318 - acc: 0.7412 - val_loss: 0.5455 - val_acc: 0.7500\n",
            "Epoch 859/1000\n",
            "79/79 [==============================] - 5s 52ms/step - loss: 0.5248 - acc: 0.7476 - val_loss: 0.6083 - val_acc: 0.6875\n",
            "Epoch 860/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5353 - acc: 0.7540 - val_loss: 0.3229 - val_acc: 0.8125\n",
            "Epoch 861/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5336 - acc: 0.7468 - val_loss: 0.3920 - val_acc: 0.8125\n",
            "Epoch 862/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.4760 - acc: 0.7795 - val_loss: 0.6171 - val_acc: 0.7500\n",
            "Epoch 863/1000\n",
            "79/79 [==============================] - 4s 50ms/step - loss: 0.5493 - acc: 0.7468 - val_loss: 0.6933 - val_acc: 0.6250\n",
            "Epoch 864/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5266 - acc: 0.7412 - val_loss: 0.6818 - val_acc: 0.6250\n",
            "Epoch 865/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5261 - acc: 0.7341 - val_loss: 0.6727 - val_acc: 0.6250\n",
            "Epoch 866/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5256 - acc: 0.7476 - val_loss: 0.5074 - val_acc: 0.7500\n",
            "Epoch 867/1000\n",
            "79/79 [==============================] - 4s 47ms/step - loss: 0.5151 - acc: 0.7452 - val_loss: 0.4708 - val_acc: 0.6875\n",
            "Epoch 868/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5095 - acc: 0.7460 - val_loss: 0.6688 - val_acc: 0.6250\n",
            "Epoch 869/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.4915 - acc: 0.7659 - val_loss: 0.4964 - val_acc: 0.8125\n",
            "Epoch 870/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5171 - acc: 0.7436 - val_loss: 0.5424 - val_acc: 0.7500\n",
            "Epoch 871/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5091 - acc: 0.7508 - val_loss: 0.5706 - val_acc: 0.6875\n",
            "Epoch 872/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5052 - acc: 0.7516 - val_loss: 0.5337 - val_acc: 0.7500\n",
            "Epoch 873/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5353 - acc: 0.7404 - val_loss: 0.6012 - val_acc: 0.6875\n",
            "Epoch 874/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5160 - acc: 0.7540 - val_loss: 0.5191 - val_acc: 0.7500\n",
            "Epoch 875/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5021 - acc: 0.7675 - val_loss: 0.6185 - val_acc: 0.6875\n",
            "Epoch 876/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5036 - acc: 0.7619 - val_loss: 0.4945 - val_acc: 0.8125\n",
            "Epoch 877/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5452 - acc: 0.7412 - val_loss: 0.4204 - val_acc: 0.7500\n",
            "Epoch 878/1000\n",
            "79/79 [==============================] - 4s 42ms/step - loss: 0.5007 - acc: 0.7627 - val_loss: 0.5592 - val_acc: 0.7500\n",
            "Epoch 879/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5200 - acc: 0.7412 - val_loss: 0.5099 - val_acc: 0.8125\n",
            "Epoch 880/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5142 - acc: 0.7492 - val_loss: 0.4178 - val_acc: 0.7500\n",
            "Epoch 881/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5247 - acc: 0.7412 - val_loss: 0.6613 - val_acc: 0.6875\n",
            "Epoch 882/1000\n",
            "79/79 [==============================] - 5s 50ms/step - loss: 0.5303 - acc: 0.7516 - val_loss: 0.6406 - val_acc: 0.6875\n",
            "Epoch 883/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5150 - acc: 0.7484 - val_loss: 0.5621 - val_acc: 0.7500\n",
            "Epoch 884/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5173 - acc: 0.7516 - val_loss: 0.3458 - val_acc: 0.8750\n",
            "Epoch 885/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5096 - acc: 0.7564 - val_loss: 0.5302 - val_acc: 0.8125\n",
            "Epoch 886/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5095 - acc: 0.7349 - val_loss: 0.6487 - val_acc: 0.6875\n",
            "Epoch 887/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5118 - acc: 0.7580 - val_loss: 0.6036 - val_acc: 0.6875\n",
            "Epoch 888/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5115 - acc: 0.7548 - val_loss: 0.3473 - val_acc: 0.8125\n",
            "Epoch 889/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5132 - acc: 0.7500 - val_loss: 0.6328 - val_acc: 0.6875\n",
            "Epoch 890/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5150 - acc: 0.7516 - val_loss: 0.3738 - val_acc: 0.8125\n",
            "Epoch 891/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5165 - acc: 0.7604 - val_loss: 0.6535 - val_acc: 0.6875\n",
            "Epoch 892/1000\n",
            "79/79 [==============================] - 5s 53ms/step - loss: 0.5251 - acc: 0.7452 - val_loss: 0.5949 - val_acc: 0.6875\n",
            "Epoch 893/1000\n",
            "79/79 [==============================] - 4s 48ms/step - loss: 0.5411 - acc: 0.7317 - val_loss: 0.5931 - val_acc: 0.6875\n",
            "Epoch 894/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5082 - acc: 0.7667 - val_loss: 0.5952 - val_acc: 0.6875\n",
            "Epoch 895/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5256 - acc: 0.7373 - val_loss: 0.4465 - val_acc: 0.6875\n",
            "Epoch 896/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5268 - acc: 0.7389 - val_loss: 0.5091 - val_acc: 0.8125\n",
            "Epoch 897/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5158 - acc: 0.7564 - val_loss: 0.5584 - val_acc: 0.7500\n",
            "Epoch 898/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5259 - acc: 0.7341 - val_loss: 0.6707 - val_acc: 0.6250\n",
            "Epoch 899/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5033 - acc: 0.7667 - val_loss: 0.5252 - val_acc: 0.8125\n",
            "Epoch 900/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5271 - acc: 0.7428 - val_loss: 0.3969 - val_acc: 0.7500\n",
            "Epoch 901/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5252 - acc: 0.7508 - val_loss: 0.5758 - val_acc: 0.6875\n",
            "Epoch 902/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5193 - acc: 0.7452 - val_loss: 0.6064 - val_acc: 0.6250\n",
            "Epoch 903/1000\n",
            "79/79 [==============================] - 5s 50ms/step - loss: 0.5252 - acc: 0.7476 - val_loss: 0.3248 - val_acc: 0.8125\n",
            "Epoch 904/1000\n",
            "79/79 [==============================] - 4s 48ms/step - loss: 0.5286 - acc: 0.7412 - val_loss: 0.6084 - val_acc: 0.6875\n",
            "Epoch 905/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5456 - acc: 0.7317 - val_loss: 0.6472 - val_acc: 0.6875\n",
            "Epoch 906/1000\n",
            "79/79 [==============================] - 4s 49ms/step - loss: 0.5129 - acc: 0.7357 - val_loss: 0.5766 - val_acc: 0.7500\n",
            "Epoch 907/1000\n",
            "79/79 [==============================] - 4s 47ms/step - loss: 0.5110 - acc: 0.7508 - val_loss: 0.5222 - val_acc: 0.7500\n",
            "Epoch 908/1000\n",
            "79/79 [==============================] - 4s 50ms/step - loss: 0.5382 - acc: 0.7317 - val_loss: 0.6302 - val_acc: 0.6875\n",
            "Epoch 909/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5238 - acc: 0.7460 - val_loss: 0.6217 - val_acc: 0.6875\n",
            "Epoch 910/1000\n",
            "79/79 [==============================] - 4s 48ms/step - loss: 0.5356 - acc: 0.7508 - val_loss: 0.5304 - val_acc: 0.8125\n",
            "Epoch 911/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5121 - acc: 0.7508 - val_loss: 0.6111 - val_acc: 0.6875\n",
            "Epoch 912/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5083 - acc: 0.7452 - val_loss: 0.5984 - val_acc: 0.7500\n",
            "Epoch 913/1000\n",
            "79/79 [==============================] - 4s 47ms/step - loss: 0.5100 - acc: 0.7580 - val_loss: 0.6594 - val_acc: 0.5625\n",
            "Epoch 914/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5136 - acc: 0.7420 - val_loss: 0.4215 - val_acc: 0.7500\n",
            "Epoch 915/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5062 - acc: 0.7500 - val_loss: 0.5525 - val_acc: 0.7500\n",
            "Epoch 916/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5059 - acc: 0.7532 - val_loss: 0.5376 - val_acc: 0.8125\n",
            "Epoch 917/1000\n",
            "79/79 [==============================] - 5s 50ms/step - loss: 0.5169 - acc: 0.7548 - val_loss: 0.5368 - val_acc: 0.7500\n",
            "Epoch 918/1000\n",
            "79/79 [==============================] - 4s 50ms/step - loss: 0.5138 - acc: 0.7301 - val_loss: 0.6610 - val_acc: 0.6250\n",
            "Epoch 919/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5264 - acc: 0.7428 - val_loss: 0.5385 - val_acc: 0.7500\n",
            "Epoch 920/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.4944 - acc: 0.7564 - val_loss: 0.6136 - val_acc: 0.6875\n",
            "Epoch 921/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5281 - acc: 0.7516 - val_loss: 0.6092 - val_acc: 0.6875\n",
            "Epoch 922/1000\n",
            "79/79 [==============================] - 5s 52ms/step - loss: 0.5086 - acc: 0.7381 - val_loss: 0.6380 - val_acc: 0.6250\n",
            "Epoch 923/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5289 - acc: 0.7325 - val_loss: 0.6531 - val_acc: 0.6250\n",
            "Epoch 924/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5226 - acc: 0.7596 - val_loss: 0.3670 - val_acc: 0.8125\n",
            "Epoch 925/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5066 - acc: 0.7373 - val_loss: 0.4268 - val_acc: 0.7500\n",
            "Epoch 926/1000\n",
            "79/79 [==============================] - 5s 50ms/step - loss: 0.5302 - acc: 0.7325 - val_loss: 0.3713 - val_acc: 0.8125\n",
            "Epoch 927/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5454 - acc: 0.7381 - val_loss: 0.3185 - val_acc: 0.8750\n",
            "Epoch 928/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5192 - acc: 0.7508 - val_loss: 0.5483 - val_acc: 0.8125\n",
            "Epoch 929/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5090 - acc: 0.7532 - val_loss: 0.4372 - val_acc: 0.8125\n",
            "Epoch 930/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5241 - acc: 0.7428 - val_loss: 0.6223 - val_acc: 0.6875\n",
            "Epoch 931/1000\n",
            "79/79 [==============================] - 4s 47ms/step - loss: 0.5108 - acc: 0.7564 - val_loss: 0.4945 - val_acc: 0.8125\n",
            "Epoch 932/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5249 - acc: 0.7309 - val_loss: 0.4325 - val_acc: 0.8750\n",
            "Epoch 933/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5051 - acc: 0.7484 - val_loss: 0.5447 - val_acc: 0.7500\n",
            "Epoch 934/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5214 - acc: 0.7404 - val_loss: 0.6248 - val_acc: 0.6250\n",
            "Epoch 935/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5292 - acc: 0.7325 - val_loss: 0.5677 - val_acc: 0.7500\n",
            "Epoch 936/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5221 - acc: 0.7691 - val_loss: 0.5920 - val_acc: 0.8125\n",
            "Epoch 937/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5339 - acc: 0.7341 - val_loss: 0.5308 - val_acc: 0.7500\n",
            "Epoch 938/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5106 - acc: 0.7564 - val_loss: 0.3583 - val_acc: 0.8125\n",
            "Epoch 939/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5125 - acc: 0.7532 - val_loss: 0.4353 - val_acc: 0.7500\n",
            "Epoch 940/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5139 - acc: 0.7532 - val_loss: 0.6417 - val_acc: 0.6875\n",
            "Epoch 941/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5066 - acc: 0.7412 - val_loss: 0.6092 - val_acc: 0.6875\n",
            "Epoch 942/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5253 - acc: 0.7452 - val_loss: 0.4359 - val_acc: 0.8750\n",
            "Epoch 943/1000\n",
            "79/79 [==============================] - 4s 47ms/step - loss: 0.4961 - acc: 0.7675 - val_loss: 0.5906 - val_acc: 0.6875\n",
            "Epoch 944/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5256 - acc: 0.7396 - val_loss: 0.5639 - val_acc: 0.7500\n",
            "Epoch 945/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5070 - acc: 0.7492 - val_loss: 0.6165 - val_acc: 0.6250\n",
            "Epoch 946/1000\n",
            "79/79 [==============================] - 4s 49ms/step - loss: 0.5077 - acc: 0.7484 - val_loss: 0.4570 - val_acc: 0.8125\n",
            "Epoch 947/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5099 - acc: 0.7588 - val_loss: 0.4910 - val_acc: 0.8750\n",
            "Epoch 948/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5409 - acc: 0.7293 - val_loss: 0.4347 - val_acc: 0.7500\n",
            "Epoch 949/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5129 - acc: 0.7524 - val_loss: 0.2606 - val_acc: 0.8750\n",
            "Epoch 950/1000\n",
            "79/79 [==============================] - 4s 47ms/step - loss: 0.5080 - acc: 0.7436 - val_loss: 0.2516 - val_acc: 0.8125\n",
            "Epoch 951/1000\n",
            "79/79 [==============================] - 4s 49ms/step - loss: 0.5386 - acc: 0.7365 - val_loss: 0.5690 - val_acc: 0.7500\n",
            "Epoch 952/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.4961 - acc: 0.7532 - val_loss: 0.6245 - val_acc: 0.6875\n",
            "Epoch 953/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.4965 - acc: 0.7596 - val_loss: 0.5885 - val_acc: 0.6875\n",
            "Epoch 954/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5363 - acc: 0.7333 - val_loss: 0.2282 - val_acc: 0.8750\n",
            "Epoch 955/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5153 - acc: 0.7524 - val_loss: 0.4254 - val_acc: 0.6875\n",
            "Epoch 956/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5432 - acc: 0.7428 - val_loss: 0.2802 - val_acc: 0.8750\n",
            "Epoch 957/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5154 - acc: 0.7540 - val_loss: 0.6247 - val_acc: 0.6875\n",
            "Epoch 958/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5393 - acc: 0.7460 - val_loss: 0.5977 - val_acc: 0.6875\n",
            "Epoch 959/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5093 - acc: 0.7619 - val_loss: 0.4282 - val_acc: 0.7500\n",
            "Epoch 960/1000\n",
            "79/79 [==============================] - 4s 49ms/step - loss: 0.5040 - acc: 0.7619 - val_loss: 0.6052 - val_acc: 0.6875\n",
            "Epoch 961/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5460 - acc: 0.7373 - val_loss: 0.3735 - val_acc: 0.8125\n",
            "Epoch 962/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5496 - acc: 0.7205 - val_loss: 0.5778 - val_acc: 0.7500\n",
            "Epoch 963/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5008 - acc: 0.7572 - val_loss: 0.5975 - val_acc: 0.7500\n",
            "Epoch 964/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5282 - acc: 0.7484 - val_loss: 0.4432 - val_acc: 0.6875\n",
            "Epoch 965/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5164 - acc: 0.7420 - val_loss: 0.3822 - val_acc: 0.7500\n",
            "Epoch 966/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5067 - acc: 0.7500 - val_loss: 0.5694 - val_acc: 0.6875\n",
            "Epoch 967/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.4986 - acc: 0.7723 - val_loss: 0.4633 - val_acc: 0.6250\n",
            "Epoch 968/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5253 - acc: 0.7484 - val_loss: 0.5776 - val_acc: 0.6875\n",
            "Epoch 969/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5160 - acc: 0.7365 - val_loss: 0.6177 - val_acc: 0.7500\n",
            "Epoch 970/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5220 - acc: 0.7476 - val_loss: 0.6475 - val_acc: 0.6250\n",
            "Epoch 971/1000\n",
            "79/79 [==============================] - 4s 48ms/step - loss: 0.5181 - acc: 0.7436 - val_loss: 0.6780 - val_acc: 0.5625\n",
            "Epoch 972/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5026 - acc: 0.7580 - val_loss: 0.5906 - val_acc: 0.7500\n",
            "Epoch 973/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5392 - acc: 0.7205 - val_loss: 0.4960 - val_acc: 0.7500\n",
            "Epoch 974/1000\n",
            "79/79 [==============================] - 4s 47ms/step - loss: 0.4946 - acc: 0.7667 - val_loss: 0.6644 - val_acc: 0.5625\n",
            "Epoch 975/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5018 - acc: 0.7412 - val_loss: 0.6350 - val_acc: 0.6875\n",
            "Epoch 976/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.4963 - acc: 0.7651 - val_loss: 0.5523 - val_acc: 0.7500\n",
            "Epoch 977/1000\n",
            "79/79 [==============================] - 5s 50ms/step - loss: 0.5085 - acc: 0.7580 - val_loss: 0.6102 - val_acc: 0.6875\n",
            "Epoch 978/1000\n",
            "79/79 [==============================] - 4s 49ms/step - loss: 0.5415 - acc: 0.7349 - val_loss: 0.5713 - val_acc: 0.6875\n",
            "Epoch 979/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5139 - acc: 0.7516 - val_loss: 0.6115 - val_acc: 0.7500\n",
            "Epoch 980/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5136 - acc: 0.7460 - val_loss: 0.6726 - val_acc: 0.6250\n",
            "Epoch 981/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5220 - acc: 0.7524 - val_loss: 0.7327 - val_acc: 0.6250\n",
            "Epoch 982/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5023 - acc: 0.7588 - val_loss: 0.6490 - val_acc: 0.6875\n",
            "Epoch 983/1000\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.5067 - acc: 0.7420 - val_loss: 0.6330 - val_acc: 0.7500\n",
            "Epoch 984/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5130 - acc: 0.7444 - val_loss: 0.5595 - val_acc: 0.7500\n",
            "Epoch 985/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.4983 - acc: 0.7548 - val_loss: 0.6084 - val_acc: 0.7500\n",
            "Epoch 986/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5136 - acc: 0.7452 - val_loss: 0.4426 - val_acc: 0.6250\n",
            "Epoch 987/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5385 - acc: 0.7325 - val_loss: 0.6694 - val_acc: 0.6250\n",
            "Epoch 988/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5201 - acc: 0.7484 - val_loss: 0.4029 - val_acc: 0.7500\n",
            "Epoch 989/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5262 - acc: 0.7333 - val_loss: 0.5539 - val_acc: 0.6875\n",
            "Epoch 990/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5130 - acc: 0.7404 - val_loss: 0.5603 - val_acc: 0.6875\n",
            "Epoch 991/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5434 - acc: 0.7444 - val_loss: 0.5615 - val_acc: 0.6875\n",
            "Epoch 992/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5246 - acc: 0.7492 - val_loss: 0.5667 - val_acc: 0.7500\n",
            "Epoch 993/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.4985 - acc: 0.7596 - val_loss: 0.5971 - val_acc: 0.6250\n",
            "Epoch 994/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5142 - acc: 0.7556 - val_loss: 0.6197 - val_acc: 0.6250\n",
            "Epoch 995/1000\n",
            "79/79 [==============================] - 5s 52ms/step - loss: 0.5238 - acc: 0.7492 - val_loss: 0.7422 - val_acc: 0.6250\n",
            "Epoch 996/1000\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.5060 - acc: 0.7548 - val_loss: 0.3338 - val_acc: 0.7500\n",
            "Epoch 997/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5128 - acc: 0.7524 - val_loss: 0.6550 - val_acc: 0.6250\n",
            "Epoch 998/1000\n",
            "79/79 [==============================] - 5s 51ms/step - loss: 0.5002 - acc: 0.7548 - val_loss: 0.5754 - val_acc: 0.6875\n",
            "Epoch 999/1000\n",
            "79/79 [==============================] - 4s 43ms/step - loss: 0.5070 - acc: 0.7484 - val_loss: 0.4807 - val_acc: 0.7500\n",
            "Epoch 1000/1000\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.5209 - acc: 0.7301 - val_loss: 0.6252 - val_acc: 0.6250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot training performance"
      ],
      "metadata": {
        "id": "YFxMJycOpEew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'co', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'k', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'co', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "     "
      ],
      "metadata": {
        "id": "l9PYKbRNpEK8",
        "outputId": "6c30fd87-1133-4989-c620-283060529803",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SAVE model"
      ],
      "metadata": {
        "id": "kNtlq_LZpKNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('./content/drive/My Drive/new', exist_ok=True)\n",
        "model.save('./content/drive/My Drive/new/nsc2.h5')"
      ],
      "metadata": {
        "id": "TegSVqblpLEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "KdsdaIgMpMeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"./content/drive/My Drive/new/nsc2.h5\")"
      ],
      "metadata": {
        "id": "sZFZ1c_kpMcN",
        "outputId": "3299d627-6844-44df-e044-cbf62128e827",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f03ac75d-4971-4391-b4db-188952db73a9\", \"nsc2.h5\", 16602400)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gEfCB1RfpMZ6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}