{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kittikhun62/efficientnet_keras_transfer_learning/blob/master/regression_test_2_class_Unfreeze.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vYOj7qs68CC"
      },
      "source": [
        "##เรียกใช้ CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WlXPl93BpDM",
        "outputId": "298a498b-6fdf-4ca7-e1ca-bc728fcb40c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vCxtnct6BtlL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwAfx2vRCdxm",
        "outputId": "ed2c5089-6a3f-4766-e549-2b0ddda90ae1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 837, done.\u001b[K\n",
            "remote: Total 837 (delta 0), reused 0 (delta 0), pack-reused 837\u001b[K\n",
            "Receiving objects: 100% (837/837), 13.85 MiB | 13.12 MiB/s, done.\n",
            "Resolving deltas: 100% (497/497), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Sa_dq25vCUfN"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('./content/drive/My Drive/new/regression_unfreeze.h5')\n",
        "\n",
        "from efficientnet.layers import Swish, DropConnect\n",
        "from efficientnet.model import ConvKernalInitializer\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "\n",
        "get_custom_objects().update({\n",
        "    'ConvKernalInitializer': ConvKernalInitializer,\n",
        "    'Swish': Swish,\n",
        "    'DropConnect':DropConnect\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dDq_RhxuB3US",
        "outputId": "2c791aa5-810e-47d6-f9f4-86824d11ec22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-b6f354e842a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./content/drive/My Drive/new/regression_unfreeze.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/saving/legacy/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m                         raise IOError(\n\u001b[0m\u001b[1;32m    228\u001b[0m                             \u001b[0;34mf\"No file or directory found at {filepath_str}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                         )\n",
            "\u001b[0;31mOSError\u001b[0m: No file or directory found at ./content/drive/My Drive/new/regression_unfreeze.h5"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('./content/drive/My Drive/new/regression_unfreeze.h5')\n",
        "height = width = model.input_shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RiTwdWRBvgU"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv (f'/content/drive/My Drive/data - 2 class Regress.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = df[df['No'].between(1,598)]\n",
        "test = df[df['No'].between(700,800)] "
      ],
      "metadata": {
        "id": "-8k5KWBRxwf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"/content/drive/My Drive/new Regress\"\n",
        "os.chdir(DATA_PATH)\n",
        "train_dir = os.path.join(DATA_PATH, 'train')\n",
        "print(train_dir)\n",
        "test_dir = os.path.join(DATA_PATH, 'test')\n",
        "print(test_dir)"
      ],
      "metadata": {
        "id": "3jWpRK9HyW1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xi1ozW49B_cT"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe = train,\n",
        "        directory = train_dir,\n",
        "        x_col = 'path_Picture',\n",
        "        y_col = 'BET',\n",
        "        # รูปภาพทั้งหมดจะถูกปรับขนาดตามความสูงและความกว้างของเป้าหมาย\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        #เนื่องจากเราใช้ categorical_crossentropy loss เราจึงต้องมีป้ายกำกับตามหมวดหมู่\n",
        "        class_mode = 'other')\n",
        "\n",
        "#label\n",
        "# labels = (train_generator.class_indices)\n",
        "# labels = dict((v,k) for k,v in labels.items())\n",
        "# print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1_BK5epD6r5"
      },
      "outputs": [],
      "source": [
        "test = df[df['No'].between(700,800)]\n",
        "test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TRhj_ncDbqq"
      },
      "outputs": [],
      "source": [
        "act = test['BET'].tolist() #ค่าจริง\n",
        "path = test['path_Picture'].tolist() #path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBFLv9UJD9m0"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "def predict_image(img_path):\n",
        "    # Read the image and resize it\n",
        "    img = image.load_img(img_path, target_size=(height, width)) #รูปทุกรูปมีขนาดไม่เท่ากันจึงตั้งไว้ว่าเวลาจะให้ model ดึงรูปมาทำนายให้ดึงรูปเข้ามาตามขนาดที่ตั้งไว้ตามพารามิตเตอร์\n",
        "    # Convert it to a Numpy array with target shape.\n",
        "    x = image.img_to_array(img)  #model ไม่สามารถทำนายรูปภาพโดยตรงได้ จึงเเปลงรูปภาพให้เป็น array เเล้วให้โมเดลทำนาย\n",
        "    # Reshape\n",
        "    x = x.reshape((1,) + x.shape) # เพิ่ม ไดเมนชั่นของโมเดล ให้เป็น 4 ได้ เมนชั่น โดยที่ 1, คือบอกให้โมเดลนำเข้าทีละ 1 รูปเเล้วค่อยทำนาย เเละ + ไดเมนชั่น คือ 150 ,150 ,3(สีของ RGB)\n",
        "    x /= 255.\n",
        "    result = model.predict([x])\n",
        "    return result[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_xWno8PFb5K"
      },
      "outputs": [],
      "source": [
        "predict_image(path[0])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qierSwCnFC8"
      },
      "outputs": [],
      "source": [
        "#Predict\n",
        "pred_list = list()\n",
        "prob_list = list()\n",
        "img_path= path\n",
        "for i in range(0,len(img_path)):\n",
        "    predict = predict_image(img_path[i])\n",
        "    result = predict[0]\n",
        "    pred_list.append(result)\n",
        "    # prob_list.append(predict[result])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQqw0uH8-T4O"
      },
      "outputs": [],
      "source": [
        "pred_list"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(pred_list))"
      ],
      "metadata": {
        "id": "UcNyZKXzHEED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_int = np.around(pred_list)\n",
        "act_int = np.around(act)"
      ],
      "metadata": {
        "id": "tWblsHwTEpaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezbChl5EKQA7"
      },
      "outputs": [],
      "source": [
        "pred = np.array(pred_int) #แปลงเป็น array\n",
        "act = np.array(act_int)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "id": "ODV31M8k8sK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Convert continuous labels to integer-encoded labels\n",
        "# le = LabelEncoder()\n",
        "# act = le.fit_transform(act)\n",
        "# pred = le.transform(pred)\n",
        "\n",
        "# Compute confusion matrix and accuracy\n",
        "cmat = confusion_matrix(act, pred)\n",
        "print('classifier accuracy = {}%'.format((100.*np.trace(cmat))/(np.sum(cmat))))"
      ],
      "metadata": {
        "id": "2TLly0sOHOxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Compute confusion matrix and classification report\n",
        "cmat = confusion_matrix(act, pred)\n",
        "report = classification_report(act, pred)\n",
        "\n",
        "# Print confusion matrix and classification report\n",
        "print('Confusion matrix:')\n",
        "print(cmat)\n",
        "print('Classifier accuracy = {}%'.format((100.*np.trace(cmat))/(np.sum(cmat))))\n",
        "print('Classification report:')\n",
        "print(report)"
      ],
      "metadata": {
        "id": "0c1M-IJXGITE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pzpwmMAJwz-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# act = test['BET'].array\n",
        "# pred = test['path_Picture'].array\n",
        "\n",
        "cmat = confusion_matrix(act, pred)\n",
        "print('classifier accuracy = {}%'.format((100.*np.trace(cmat))/(np.sum(cmat))))\n",
        "\n",
        "#Marking the Confusion Matrix\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "print(classification_report(act, pred))#performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCeaPS3pJzwt"
      },
      "outputs": [],
      "source": [
        "#create CF \n",
        "data = {'Actual': act,'Predicted' : pred}\n",
        "df = pd.DataFrame(data, columns=['Actual','Predicted'])\n",
        "conf_mat = pd.crosstab(df['Actual'],df['Predicted'],rownames=['Actual'],colnames=['Predicted'])\n",
        "\n",
        "#Confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "cm = confusion_matrix(act, pred)\n",
        "\n",
        "#plot Confusion matrix\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "\n",
        "ax = sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"YlGnBu\") #Blues,Oranges,Reds\n",
        "ax.set_title('Confusion matrix',fontsize=20)\n",
        "ax.set_ylabel('True label',fontsize=18)\n",
        "ax.set_xlabel('Predicted label',fontsize=18)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
        "  \n",
        "mae = mean_absolute_error(y_true=act,y_pred=pred)\n",
        "#squared True returns MSE value, False returns RMSE value.\n",
        "mse = mean_squared_error(y_true=act,y_pred=pred) #default=True\n",
        "rmse = mean_squared_error(y_true=act,y_pred=pred,squared=False)\n",
        "  \n",
        "print(\"MAE:\",mae)\n",
        "print(\"MSE:\",mse)\n",
        "print(\"RMSE:\",rmse)"
      ],
      "metadata": {
        "id": "2f-6UoETM_b_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wv3kRyGxArop"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}