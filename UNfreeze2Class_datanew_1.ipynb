{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMaudo6X0Uc78AdkM3/EcDT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kittikhun62/efficientnet_keras_transfer_learning/blob/master/UNfreeze2Class_datanew_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# import from drive"
      ],
      "metadata": {
        "id": "bB2gfuYWczY-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpXyZ9k5YIJu",
        "outputId": "96d7b5bc-e8a8-4369-96f1-73ed1246a241"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (r'/content/drive/My Drive/data - 2 class เพิ่ม 4 paper.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "7mqo2OLAc2pG",
        "outputId": "f9c39a66-4123-410e-d6be-598af4c5763c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      No                      Name_file  \\\n",
              "0      1                        pore-sb   \n",
              "1      2                        pore-sb   \n",
              "2      3                        pore-sb   \n",
              "3      4                        pore-sb   \n",
              "4      5                        pore-sb   \n",
              "..   ...                            ...   \n",
              "825  826  1-s2.0-S2095268622000210-main   \n",
              "826  827  1-s2.0-S2095268622000210-main   \n",
              "827  828  1-s2.0-S2095268622000210-main   \n",
              "828  829  1-s2.0-S2095268622000210-main   \n",
              "829  830  1-s2.0-S2095268622000210-main   \n",
              "\n",
              "                                            Name_Paper  \\\n",
              "0    Preparation and electrochemical behaviour of b...   \n",
              "1    Preparation and electrochemical behaviour of b...   \n",
              "2    Preparation and electrochemical behaviour of b...   \n",
              "3    Preparation and electrochemical behaviour of b...   \n",
              "4    Preparation and electrochemical behaviour of b...   \n",
              "..                                                 ...   \n",
              "825  Integration of preparation of K, Na-embedded a...   \n",
              "826  Integration of preparation of K, Na-embedded a...   \n",
              "827  Integration of preparation of K, Na-embedded a...   \n",
              "828  Integration of preparation of K, Na-embedded a...   \n",
              "829  Integration of preparation of K, Na-embedded a...   \n",
              "\n",
              "                                               journal  \\\n",
              "0                                  Korean J. Chem. Eng   \n",
              "1                                  Korean J. Chem. Eng   \n",
              "2                                  Korean J. Chem. Eng   \n",
              "3                                  Korean J. Chem. Eng   \n",
              "4                                  Korean J. Chem. Eng   \n",
              "..                                                 ...   \n",
              "825  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "826  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "827  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "828  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "829  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "\n",
              "                                          path_Picture  detail  Class     BET  \\\n",
              "0    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom1  0-800  135.06   \n",
              "1    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom2  0-800  135.06   \n",
              "2    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom3  0-800  135.06   \n",
              "3    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom4  0-800  135.06   \n",
              "4    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom5  0-800  135.06   \n",
              "..                                                 ...     ...    ...     ...   \n",
              "825  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom21  0-800  301.70   \n",
              "826  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom22  0-800  301.70   \n",
              "827  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom23  0-800  301.70   \n",
              "828  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom24  0-800  301.70   \n",
              "829  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom25  0-800  301.70   \n",
              "\n",
              "     Size(mico)  Class_01  \n",
              "0            10         0  \n",
              "1            10         0  \n",
              "2            10         0  \n",
              "3            10         0  \n",
              "4            10         0  \n",
              "..          ...       ...  \n",
              "825          10         0  \n",
              "826          10         0  \n",
              "827          10         0  \n",
              "828          10         0  \n",
              "829          10         0  \n",
              "\n",
              "[830 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-59682d97-e159-4fa9-a4a7-4f9c69f39b91\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>No</th>\n",
              "      <th>Name_file</th>\n",
              "      <th>Name_Paper</th>\n",
              "      <th>journal</th>\n",
              "      <th>path_Picture</th>\n",
              "      <th>detail</th>\n",
              "      <th>Class</th>\n",
              "      <th>BET</th>\n",
              "      <th>Size(mico)</th>\n",
              "      <th>Class_01</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom1</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom2</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom3</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom4</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom5</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>825</th>\n",
              "      <td>826</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom21</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>826</th>\n",
              "      <td>827</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom22</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>827</th>\n",
              "      <td>828</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom23</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>828</th>\n",
              "      <td>829</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom24</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>829</th>\n",
              "      <td>830</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom25</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>830 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59682d97-e159-4fa9-a4a7-4f9c69f39b91')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-59682d97-e159-4fa9-a4a7-4f9c69f39b91 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-59682d97-e159-4fa9-a4a7-4f9c69f39b91');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports library"
      ],
      "metadata": {
        "id": "VkYa-4LeTbir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "myAsBcVhTW7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## hyper parameter\n"
      ],
      "metadata": {
        "id": "T529UM_tVV-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "width = 150\n",
        "height = 150\n",
        "\n",
        "epochs = 1000 #จำนวนรอบในการ Train\n",
        "\n",
        "NUM_TRAIN = 628  # จำนวนภาพ Train\n",
        "NUM_TEST = 101 #จำนวนภาพ Test\n",
        "\n",
        "dropout_rate = 0.3\n",
        "input_shape = (height, width, 3) #ขนาด image enter"
      ],
      "metadata": {
        "id": "zXpmkJ2GVZ1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone efficientnet repo"
      ],
      "metadata": {
        "id": "DSSZIFGhUyQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/"
      ],
      "metadata": {
        "id": "nFvKcuBDTj1N",
        "outputId": "91faee3e-a280-4d37-c788-07954615e06a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 1079, done.\u001b[K\n",
            "remote: Counting objects: 100% (242/242), done.\u001b[K\n",
            "remote: Compressing objects: 100% (121/121), done.\u001b[K\n",
            "remote: Total 1079 (delta 121), reused 241 (delta 121), pack-reused 837\u001b[K\n",
            "Receiving objects: 100% (1079/1079), 13.94 MiB | 16.21 MiB/s, done.\n",
            "Resolving deltas: 100% (618/618), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import efficientnet and load the conv base model"
      ],
      "metadata": {
        "id": "j3EgSOiSZHaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "iI3DQ18HU2TF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "#EfficientNet สร้างขึ้นสำหรับการจำแนกประเภท ImageNet ประกอบด้วยป้ายกำกับคลาส 1,000 รายการ เรามีเพียง 2 เลเยอร์เท่านั้น ซึ่งหมายความว่าเลเยอร์สองสามเลเยอร์สุดท้ายสำหรับการจำแนกไม่มีประโยชน์สำหรับเรา สามารถยกเว้นได้ขณะโหลดโมเดลโดยระบุอาร์กิวเมนต์ include_top เป็น False และนำไปใช้กับโมเดล ImageNet อื่นๆ ที่มีอยู่ในแอปพลิเคชัน Keras เช่นกัน\n",
        "\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "UmBDAgF_VAjq",
        "outputId": "1375ab3a-03f0-4f0f-c5f6-c25b4f4c6a53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "id": "rRXoFFzfU2Oi",
        "outputId": "4aa4f3c6-24d5-4edd-d5f4-025c182c32ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 4,007,548\n",
            "Non-trainable params: 42,016\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/new/2Class_UNfreeze_newdata.h5')\n",
        "\n",
        "from efficientnet.layers import Swish, DropConnect\n",
        "from efficientnet.model import ConvKernalInitializer\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "\n",
        "get_custom_objects().update({\n",
        "    'ConvKernalInitializer': ConvKernalInitializer,\n",
        "    'Swish': Swish,\n",
        "    'DropConnect':DropConnect\n",
        "})"
      ],
      "metadata": {
        "id": "MwNk3sNbc2Qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load model \n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/drive/My Drive/new/2Class_UNfreeze_newdata.h5')\n",
        "height = width = model.input_shape[1]"
      ],
      "metadata": {
        "id": "4v4nzKQtJZ4z",
        "outputId": "11c13e23-f652-4b77-e9f5-aea6be01fa5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/My Drive/new project'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Directories for our training,\n",
        "# validation and test splits\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.makedirs(test_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "UDxvF-b8Jcq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, # image input 0-255 --> 0-1 เปลี่ยนค่าสี\n",
        "      rotation_range=40,# หมุนภาพในองศา\n",
        "      width_shift_range=0.2, #เปลี่ยนความกว้าง\n",
        "      height_shift_range=0.2, #ปลี่ยนความสูง\n",
        "      shear_range=0.2, #ทำให้ภาพเบี้ยว\n",
        "      zoom_range=0.2, # Randomly zoom image\n",
        "      horizontal_flip=True, \n",
        "      #โดย Default เมื่อมีการเลื่อนภาพ บิดภาพ หมุนภาพ จะเกิดพื้นที่ว่างที่มุม \n",
        "      #ซึ่งจะมีการเติมภาพให้เต็มโดยใช้เทคนิคแบบ Nearest neighbor ซึ่งเป็นการดึงสีบริเวณใหล้าเคียงมาระบายให้เต็ม แต่เราก็ยังสามารถกำหนดวิธีการ Fill ภาพด้วยเทคนิคอื่นได้จาก Parameter fill_mode\n",
        "      fill_mode='nearest')\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory #ไดเรกเป้าหมาย\n",
        "        train_dir,\n",
        "        # รูปภาพทั้งหมดจะถูกปรับขนาดตามความสูงและความกว้างของเป้าหมาย\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        #เนื่องจากเราใช้ categorical_crossentropy loss เราจึงต้องมีป้ายกำกับตามหมวดหมู่\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory( #การดึงภาพจาก Directory มาเข้าโมเดล \n",
        "        validation_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "     \n",
        "\n"
      ],
      "metadata": {
        "id": "znE38DtIJeN-",
        "outputId": "a1ff0f7a-bbf6-45a6-96ff-40d286873beb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 628 images belonging to 2 classes.\n",
            "Found 101 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multiply_16\n",
        "# set 'multiply_16' and following layers trainable\n",
        "model.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'multiply_16':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False  \n",
        "     "
      ],
      "metadata": {
        "id": "tEaPoHJCJq13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IC-3EwwkJHGS",
        "outputId": "d6653ddd-f36a-4390-fd39-b9f79449b594"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 2)                 2562      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,052,126\n",
            "Trainable params: 4,010,110\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "z7ERVUfUJsQq",
        "outputId": "ba000679-cc52-4b61-9813-2a3e62d5a5ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-caa7b37242a8>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "39/39 [==============================] - 91s 1s/step - loss: 3.2646 - acc: 0.5719 - val_loss: 0.5950 - val_acc: 0.6771\n",
            "Epoch 2/1000\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 2.7023 - acc: 0.6046 - val_loss: 0.8519 - val_acc: 0.6042\n",
            "Epoch 3/1000\n",
            "39/39 [==============================] - 9s 237ms/step - loss: 2.4608 - acc: 0.6619 - val_loss: 1.1036 - val_acc: 0.5625\n",
            "Epoch 4/1000\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 2.4656 - acc: 0.6078 - val_loss: 1.1905 - val_acc: 0.5521\n",
            "Epoch 5/1000\n",
            "39/39 [==============================] - 10s 242ms/step - loss: 2.4172 - acc: 0.6522 - val_loss: 1.5533 - val_acc: 0.5417\n",
            "Epoch 6/1000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 2.0434 - acc: 0.6781 - val_loss: 1.4606 - val_acc: 0.5521\n",
            "Epoch 7/1000\n",
            "39/39 [==============================] - 6s 131ms/step - loss: 1.8849 - acc: 0.7141 - val_loss: 1.7387 - val_acc: 0.5729\n",
            "Epoch 8/1000\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 1.7742 - acc: 0.7190 - val_loss: 1.8381 - val_acc: 0.5625\n",
            "Epoch 9/1000\n",
            "39/39 [==============================] - 5s 118ms/step - loss: 1.7545 - acc: 0.7288 - val_loss: 1.4192 - val_acc: 0.5729\n",
            "Epoch 10/1000\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 1.5762 - acc: 0.7369 - val_loss: 1.2732 - val_acc: 0.6458\n",
            "Epoch 11/1000\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 1.5791 - acc: 0.7320 - val_loss: 1.2934 - val_acc: 0.6354\n",
            "Epoch 12/1000\n",
            "39/39 [==============================] - 10s 240ms/step - loss: 1.3233 - acc: 0.7925 - val_loss: 1.2665 - val_acc: 0.6562\n",
            "Epoch 13/1000\n",
            "39/39 [==============================] - 5s 114ms/step - loss: 1.5087 - acc: 0.7288 - val_loss: 1.5275 - val_acc: 0.6354\n",
            "Epoch 14/1000\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 1.1685 - acc: 0.7949 - val_loss: 1.4354 - val_acc: 0.6354\n",
            "Epoch 15/1000\n",
            "39/39 [==============================] - 5s 113ms/step - loss: 1.1741 - acc: 0.7892 - val_loss: 1.3649 - val_acc: 0.6771\n",
            "Epoch 16/1000\n",
            "39/39 [==============================] - 5s 128ms/step - loss: 1.1904 - acc: 0.7729 - val_loss: 1.7341 - val_acc: 0.6250\n",
            "Epoch 17/1000\n",
            "39/39 [==============================] - 10s 242ms/step - loss: 0.9683 - acc: 0.8268 - val_loss: 1.6278 - val_acc: 0.6562\n",
            "Epoch 18/1000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 0.8821 - acc: 0.8023 - val_loss: 1.9320 - val_acc: 0.6562\n",
            "Epoch 19/1000\n",
            "39/39 [==============================] - 5s 128ms/step - loss: 0.9250 - acc: 0.8170 - val_loss: 2.0677 - val_acc: 0.6458\n",
            "Epoch 20/1000\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 1.0417 - acc: 0.8186 - val_loss: 1.8622 - val_acc: 0.6146\n",
            "Epoch 21/1000\n",
            "39/39 [==============================] - 10s 244ms/step - loss: 1.0636 - acc: 0.8056 - val_loss: 2.0293 - val_acc: 0.6667\n",
            "Epoch 22/1000\n",
            "39/39 [==============================] - 10s 244ms/step - loss: 0.9642 - acc: 0.8235 - val_loss: 2.0059 - val_acc: 0.6979\n",
            "Epoch 23/1000\n",
            "39/39 [==============================] - 10s 251ms/step - loss: 1.1594 - acc: 0.8007 - val_loss: 2.0764 - val_acc: 0.6354\n",
            "Epoch 24/1000\n",
            "39/39 [==============================] - 10s 241ms/step - loss: 0.6564 - acc: 0.8529 - val_loss: 2.1154 - val_acc: 0.6667\n",
            "Epoch 25/1000\n",
            "39/39 [==============================] - 5s 115ms/step - loss: 0.8772 - acc: 0.8529 - val_loss: 2.0155 - val_acc: 0.6146\n",
            "Epoch 26/1000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 0.7439 - acc: 0.8513 - val_loss: 2.0648 - val_acc: 0.6562\n",
            "Epoch 27/1000\n",
            "39/39 [==============================] - 10s 239ms/step - loss: 0.6901 - acc: 0.8399 - val_loss: 2.4968 - val_acc: 0.6667\n",
            "Epoch 28/1000\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 0.5605 - acc: 0.8840 - val_loss: 2.6616 - val_acc: 0.6562\n",
            "Epoch 29/1000\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.7844 - acc: 0.8333 - val_loss: 3.0289 - val_acc: 0.6458\n",
            "Epoch 30/1000\n",
            "39/39 [==============================] - 10s 241ms/step - loss: 0.7464 - acc: 0.8399 - val_loss: 2.3121 - val_acc: 0.6458\n",
            "Epoch 31/1000\n",
            "39/39 [==============================] - 5s 113ms/step - loss: 0.5581 - acc: 0.8562 - val_loss: 2.3950 - val_acc: 0.6667\n",
            "Epoch 32/1000\n",
            "39/39 [==============================] - 6s 130ms/step - loss: 0.6373 - acc: 0.8627 - val_loss: 2.8580 - val_acc: 0.6562\n",
            "Epoch 33/1000\n",
            "39/39 [==============================] - 5s 119ms/step - loss: 0.5990 - acc: 0.8546 - val_loss: 2.8817 - val_acc: 0.6667\n",
            "Epoch 34/1000\n",
            "39/39 [==============================] - 5s 115ms/step - loss: 0.5545 - acc: 0.8742 - val_loss: 2.8737 - val_acc: 0.6979\n",
            "Epoch 35/1000\n",
            "39/39 [==============================] - 6s 143ms/step - loss: 0.5268 - acc: 0.8758 - val_loss: 2.9806 - val_acc: 0.6771\n",
            "Epoch 36/1000\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.5839 - acc: 0.8611 - val_loss: 3.1301 - val_acc: 0.7083\n",
            "Epoch 37/1000\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.4734 - acc: 0.8709 - val_loss: 3.4944 - val_acc: 0.6771\n",
            "Epoch 38/1000\n",
            "39/39 [==============================] - 5s 117ms/step - loss: 0.4174 - acc: 0.8840 - val_loss: 3.4299 - val_acc: 0.6771\n",
            "Epoch 39/1000\n",
            "39/39 [==============================] - 10s 241ms/step - loss: 0.5817 - acc: 0.8595 - val_loss: 3.4519 - val_acc: 0.6875\n",
            "Epoch 40/1000\n",
            "39/39 [==============================] - 10s 243ms/step - loss: 0.3862 - acc: 0.8856 - val_loss: 4.2816 - val_acc: 0.6875\n",
            "Epoch 41/1000\n",
            "39/39 [==============================] - 10s 243ms/step - loss: 0.4195 - acc: 0.8873 - val_loss: 3.5548 - val_acc: 0.7396\n",
            "Epoch 42/1000\n",
            "39/39 [==============================] - 11s 258ms/step - loss: 0.3837 - acc: 0.8814 - val_loss: 3.0669 - val_acc: 0.7500\n",
            "Epoch 43/1000\n",
            "39/39 [==============================] - 5s 120ms/step - loss: 0.4569 - acc: 0.8725 - val_loss: 2.9097 - val_acc: 0.7188\n",
            "Epoch 44/1000\n",
            "39/39 [==============================] - 10s 243ms/step - loss: 0.2566 - acc: 0.9183 - val_loss: 2.9453 - val_acc: 0.7188\n",
            "Epoch 45/1000\n",
            "39/39 [==============================] - 10s 251ms/step - loss: 0.3388 - acc: 0.8971 - val_loss: 2.5835 - val_acc: 0.7396\n",
            "Epoch 46/1000\n",
            "39/39 [==============================] - 7s 162ms/step - loss: 0.2962 - acc: 0.9101 - val_loss: 2.7917 - val_acc: 0.7292\n",
            "Epoch 47/1000\n",
            "39/39 [==============================] - 5s 115ms/step - loss: 0.2943 - acc: 0.8971 - val_loss: 3.0457 - val_acc: 0.7083\n",
            "Epoch 48/1000\n",
            "39/39 [==============================] - 10s 240ms/step - loss: 0.3169 - acc: 0.8873 - val_loss: 3.0174 - val_acc: 0.6979\n",
            "Epoch 49/1000\n",
            "39/39 [==============================] - 5s 122ms/step - loss: 0.2992 - acc: 0.8954 - val_loss: 3.0736 - val_acc: 0.6979\n",
            "Epoch 50/1000\n",
            "39/39 [==============================] - 6s 135ms/step - loss: 0.2468 - acc: 0.9167 - val_loss: 2.9698 - val_acc: 0.6979\n",
            "Epoch 51/1000\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.2162 - acc: 0.9248 - val_loss: 3.0276 - val_acc: 0.7083\n",
            "Epoch 52/1000\n",
            "39/39 [==============================] - 5s 120ms/step - loss: 0.2683 - acc: 0.9036 - val_loss: 3.1631 - val_acc: 0.7083\n",
            "Epoch 53/1000\n",
            "39/39 [==============================] - 10s 251ms/step - loss: 0.2745 - acc: 0.9036 - val_loss: 2.9859 - val_acc: 0.7083\n",
            "Epoch 54/1000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 0.2646 - acc: 0.9216 - val_loss: 3.2071 - val_acc: 0.6875\n",
            "Epoch 55/1000\n",
            "39/39 [==============================] - 6s 137ms/step - loss: 0.3299 - acc: 0.9003 - val_loss: 3.0371 - val_acc: 0.7188\n",
            "Epoch 56/1000\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.2727 - acc: 0.9167 - val_loss: 2.5228 - val_acc: 0.6771\n",
            "Epoch 57/1000\n",
            "39/39 [==============================] - 5s 128ms/step - loss: 0.2328 - acc: 0.9118 - val_loss: 2.7588 - val_acc: 0.6771\n",
            "Epoch 58/1000\n",
            "39/39 [==============================] - 6s 129ms/step - loss: 0.2137 - acc: 0.9183 - val_loss: 2.8054 - val_acc: 0.7188\n",
            "Epoch 59/1000\n",
            "39/39 [==============================] - 5s 128ms/step - loss: 0.1501 - acc: 0.9493 - val_loss: 3.2859 - val_acc: 0.6562\n",
            "Epoch 60/1000\n",
            "39/39 [==============================] - 10s 243ms/step - loss: 0.1788 - acc: 0.9444 - val_loss: 2.9866 - val_acc: 0.6875\n",
            "Epoch 61/1000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 0.2859 - acc: 0.9199 - val_loss: 1.9971 - val_acc: 0.7083\n",
            "Epoch 62/1000\n",
            "39/39 [==============================] - 5s 120ms/step - loss: 0.2284 - acc: 0.9265 - val_loss: 2.5685 - val_acc: 0.7188\n",
            "Epoch 63/1000\n",
            "39/39 [==============================] - 5s 115ms/step - loss: 0.1926 - acc: 0.9444 - val_loss: 3.1218 - val_acc: 0.7188\n",
            "Epoch 64/1000\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.2828 - acc: 0.9118 - val_loss: 3.6738 - val_acc: 0.7083\n",
            "Epoch 65/1000\n",
            "39/39 [==============================] - 10s 242ms/step - loss: 0.1795 - acc: 0.9363 - val_loss: 3.9451 - val_acc: 0.7188\n",
            "Epoch 66/1000\n",
            "39/39 [==============================] - 5s 122ms/step - loss: 0.2986 - acc: 0.9101 - val_loss: 3.4079 - val_acc: 0.7083\n",
            "Epoch 67/1000\n",
            "39/39 [==============================] - 10s 251ms/step - loss: 0.2499 - acc: 0.9379 - val_loss: 2.9891 - val_acc: 0.6875\n",
            "Epoch 68/1000\n",
            "39/39 [==============================] - 10s 244ms/step - loss: 0.2015 - acc: 0.9297 - val_loss: 2.3644 - val_acc: 0.6667\n",
            "Epoch 69/1000\n",
            "39/39 [==============================] - 5s 113ms/step - loss: 0.2364 - acc: 0.9330 - val_loss: 3.4135 - val_acc: 0.7188\n",
            "Epoch 70/1000\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.1649 - acc: 0.9346 - val_loss: 3.5179 - val_acc: 0.6979\n",
            "Epoch 71/1000\n",
            "39/39 [==============================] - 10s 243ms/step - loss: 0.1692 - acc: 0.9477 - val_loss: 3.0647 - val_acc: 0.7188\n",
            "Epoch 72/1000\n",
            "39/39 [==============================] - 10s 240ms/step - loss: 0.1737 - acc: 0.9477 - val_loss: 2.7134 - val_acc: 0.7396\n",
            "Epoch 73/1000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 0.1568 - acc: 0.9477 - val_loss: 2.5615 - val_acc: 0.6979\n",
            "Epoch 74/1000\n",
            "39/39 [==============================] - 5s 114ms/step - loss: 0.1185 - acc: 0.9526 - val_loss: 2.4834 - val_acc: 0.7292\n",
            "Epoch 75/1000\n",
            "39/39 [==============================] - 6s 133ms/step - loss: 0.1463 - acc: 0.9444 - val_loss: 3.3477 - val_acc: 0.7292\n",
            "Epoch 76/1000\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.1142 - acc: 0.9690 - val_loss: 3.5862 - val_acc: 0.6875\n",
            "Epoch 77/1000\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.1533 - acc: 0.9592 - val_loss: 3.7472 - val_acc: 0.7292\n",
            "Epoch 78/1000\n",
            "39/39 [==============================] - 10s 241ms/step - loss: 0.1897 - acc: 0.9444 - val_loss: 4.3058 - val_acc: 0.7188\n",
            "Epoch 79/1000\n",
            "39/39 [==============================] - 10s 238ms/step - loss: 0.1169 - acc: 0.9542 - val_loss: 4.3956 - val_acc: 0.7500\n",
            "Epoch 80/1000\n",
            "39/39 [==============================] - 5s 114ms/step - loss: 0.0737 - acc: 0.9739 - val_loss: 4.1330 - val_acc: 0.7188\n",
            "Epoch 81/1000\n",
            "39/39 [==============================] - 10s 238ms/step - loss: 0.1174 - acc: 0.9542 - val_loss: 4.4300 - val_acc: 0.7396\n",
            "Epoch 82/1000\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 0.1506 - acc: 0.9657 - val_loss: 3.8414 - val_acc: 0.7604\n",
            "Epoch 83/1000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 0.2141 - acc: 0.9395 - val_loss: 3.7606 - val_acc: 0.7396\n",
            "Epoch 84/1000\n",
            "39/39 [==============================] - 6s 128ms/step - loss: 0.1413 - acc: 0.9444 - val_loss: 5.1278 - val_acc: 0.7292\n",
            "Epoch 85/1000\n",
            "39/39 [==============================] - 10s 252ms/step - loss: 0.1772 - acc: 0.9510 - val_loss: 4.6626 - val_acc: 0.7500\n",
            "Epoch 86/1000\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.1457 - acc: 0.9510 - val_loss: 5.3408 - val_acc: 0.7396\n",
            "Epoch 87/1000\n",
            "39/39 [==============================] - 10s 243ms/step - loss: 0.1198 - acc: 0.9526 - val_loss: 5.4250 - val_acc: 0.7292\n",
            "Epoch 88/1000\n",
            "39/39 [==============================] - 10s 242ms/step - loss: 0.1135 - acc: 0.9493 - val_loss: 5.1112 - val_acc: 0.7292\n",
            "Epoch 89/1000\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 0.0831 - acc: 0.9690 - val_loss: 5.3189 - val_acc: 0.6979\n",
            "Epoch 90/1000\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.1659 - acc: 0.9493 - val_loss: 4.7429 - val_acc: 0.6979\n",
            "Epoch 91/1000\n",
            "39/39 [==============================] - 10s 252ms/step - loss: 0.1474 - acc: 0.9510 - val_loss: 4.5722 - val_acc: 0.7083\n",
            "Epoch 92/1000\n",
            "39/39 [==============================] - 10s 241ms/step - loss: 0.1662 - acc: 0.9657 - val_loss: 5.0022 - val_acc: 0.6979\n",
            "Epoch 93/1000\n",
            "39/39 [==============================] - 5s 113ms/step - loss: 0.1929 - acc: 0.9575 - val_loss: 5.3204 - val_acc: 0.6875\n",
            "Epoch 94/1000\n",
            "39/39 [==============================] - 6s 137ms/step - loss: 0.1681 - acc: 0.9493 - val_loss: 4.8603 - val_acc: 0.6771\n",
            "Epoch 95/1000\n",
            "39/39 [==============================] - 5s 115ms/step - loss: 0.1202 - acc: 0.9542 - val_loss: 4.6950 - val_acc: 0.6979\n",
            "Epoch 96/1000\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.1321 - acc: 0.9624 - val_loss: 5.1282 - val_acc: 0.7083\n",
            "Epoch 97/1000\n",
            "39/39 [==============================] - 5s 122ms/step - loss: 0.1217 - acc: 0.9624 - val_loss: 4.5232 - val_acc: 0.7188\n",
            "Epoch 98/1000\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.0646 - acc: 0.9739 - val_loss: 3.9183 - val_acc: 0.7604\n",
            "Epoch 99/1000\n",
            "39/39 [==============================] - 10s 252ms/step - loss: 0.1553 - acc: 0.9575 - val_loss: 3.5274 - val_acc: 0.7188\n",
            "Epoch 100/1000\n",
            "39/39 [==============================] - 5s 121ms/step - loss: 0.1538 - acc: 0.9461 - val_loss: 4.1587 - val_acc: 0.7396\n",
            "Epoch 101/1000\n",
            "39/39 [==============================] - 5s 115ms/step - loss: 0.0875 - acc: 0.9788 - val_loss: 3.5716 - val_acc: 0.7500\n",
            "Epoch 102/1000\n",
            "39/39 [==============================] - 10s 252ms/step - loss: 0.0564 - acc: 0.9853 - val_loss: 3.9426 - val_acc: 0.7396\n",
            "Epoch 103/1000\n",
            "39/39 [==============================] - 10s 245ms/step - loss: 0.0712 - acc: 0.9820 - val_loss: 3.5484 - val_acc: 0.7500\n",
            "Epoch 104/1000\n",
            "39/39 [==============================] - 5s 113ms/step - loss: 0.1013 - acc: 0.9592 - val_loss: 3.7455 - val_acc: 0.7500\n",
            "Epoch 105/1000\n",
            "39/39 [==============================] - 6s 133ms/step - loss: 0.0792 - acc: 0.9755 - val_loss: 3.7379 - val_acc: 0.7396\n",
            "Epoch 106/1000\n",
            "39/39 [==============================] - 5s 113ms/step - loss: 0.1186 - acc: 0.9641 - val_loss: 3.4931 - val_acc: 0.7188\n",
            "Epoch 107/1000\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 0.1156 - acc: 0.9657 - val_loss: 3.7813 - val_acc: 0.7396\n",
            "Epoch 108/1000\n",
            "39/39 [==============================] - 5s 113ms/step - loss: 0.1079 - acc: 0.9575 - val_loss: 4.1793 - val_acc: 0.7188\n",
            "Epoch 109/1000\n",
            "39/39 [==============================] - 10s 251ms/step - loss: 0.0760 - acc: 0.9690 - val_loss: 4.2403 - val_acc: 0.7188\n",
            "Epoch 110/1000\n",
            "39/39 [==============================] - 5s 115ms/step - loss: 0.0736 - acc: 0.9771 - val_loss: 3.8687 - val_acc: 0.6979\n",
            "Epoch 111/1000\n",
            "39/39 [==============================] - 6s 143ms/step - loss: 0.0736 - acc: 0.9776 - val_loss: 4.3304 - val_acc: 0.7083\n",
            "Epoch 112/1000\n",
            "39/39 [==============================] - 10s 242ms/step - loss: 0.0823 - acc: 0.9706 - val_loss: 5.3463 - val_acc: 0.7292\n",
            "Epoch 113/1000\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 0.1096 - acc: 0.9722 - val_loss: 4.5499 - val_acc: 0.7292\n",
            "Epoch 114/1000\n",
            "39/39 [==============================] - 5s 122ms/step - loss: 0.1301 - acc: 0.9690 - val_loss: 4.6610 - val_acc: 0.7604\n",
            "Epoch 115/1000\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.0774 - acc: 0.9739 - val_loss: 4.4570 - val_acc: 0.7292\n",
            "Epoch 116/1000\n",
            "39/39 [==============================] - 10s 241ms/step - loss: 0.0769 - acc: 0.9739 - val_loss: 4.1893 - val_acc: 0.7292\n",
            "Epoch 117/1000\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.1220 - acc: 0.9739 - val_loss: 4.2547 - val_acc: 0.7083\n",
            "Epoch 118/1000\n",
            "39/39 [==============================] - 10s 241ms/step - loss: 0.1317 - acc: 0.9673 - val_loss: 3.7650 - val_acc: 0.6458\n",
            "Epoch 119/1000\n",
            "39/39 [==============================] - 10s 242ms/step - loss: 0.0878 - acc: 0.9739 - val_loss: 3.6444 - val_acc: 0.6562\n",
            "Epoch 120/1000\n",
            "39/39 [==============================] - 6s 130ms/step - loss: 0.1505 - acc: 0.9608 - val_loss: 3.7531 - val_acc: 0.6875\n",
            "Epoch 121/1000\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 0.0670 - acc: 0.9820 - val_loss: 3.7704 - val_acc: 0.7083\n",
            "Epoch 122/1000\n",
            "39/39 [==============================] - 10s 240ms/step - loss: 0.0962 - acc: 0.9673 - val_loss: 4.1697 - val_acc: 0.7083\n",
            "Epoch 123/1000\n",
            "39/39 [==============================] - 5s 128ms/step - loss: 0.1274 - acc: 0.9657 - val_loss: 4.2387 - val_acc: 0.6979\n",
            "Epoch 124/1000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 0.0763 - acc: 0.9788 - val_loss: 4.7335 - val_acc: 0.7292\n",
            "Epoch 125/1000\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 0.0757 - acc: 0.9722 - val_loss: 4.4713 - val_acc: 0.6979\n",
            "Epoch 126/1000\n",
            "39/39 [==============================] - 10s 241ms/step - loss: 0.0664 - acc: 0.9739 - val_loss: 3.8142 - val_acc: 0.7188\n",
            "Epoch 127/1000\n",
            "39/39 [==============================] - 10s 242ms/step - loss: 0.1367 - acc: 0.9722 - val_loss: 3.6545 - val_acc: 0.6771\n",
            "Epoch 128/1000\n",
            "39/39 [==============================] - 10s 241ms/step - loss: 0.0852 - acc: 0.9706 - val_loss: 3.7317 - val_acc: 0.7188\n",
            "Epoch 129/1000\n",
            "39/39 [==============================] - 6s 131ms/step - loss: 0.0513 - acc: 0.9788 - val_loss: 3.5006 - val_acc: 0.7188\n",
            "Epoch 130/1000\n",
            "39/39 [==============================] - 5s 115ms/step - loss: 0.0738 - acc: 0.9673 - val_loss: 3.4116 - val_acc: 0.7188\n",
            "Epoch 131/1000\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 0.0914 - acc: 0.9771 - val_loss: 3.2926 - val_acc: 0.7396\n",
            "Epoch 132/1000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 0.0192 - acc: 0.9951 - val_loss: 3.0574 - val_acc: 0.7500\n",
            "Epoch 133/1000\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.0621 - acc: 0.9788 - val_loss: 3.8851 - val_acc: 0.7188\n",
            "Epoch 134/1000\n",
            "39/39 [==============================] - 10s 244ms/step - loss: 0.0328 - acc: 0.9886 - val_loss: 4.0584 - val_acc: 0.7396\n",
            "Epoch 135/1000\n",
            "39/39 [==============================] - 10s 243ms/step - loss: 0.0739 - acc: 0.9706 - val_loss: 3.6436 - val_acc: 0.7396\n",
            "Epoch 136/1000\n",
            "39/39 [==============================] - 10s 241ms/step - loss: 0.1022 - acc: 0.9673 - val_loss: 4.3341 - val_acc: 0.7500\n",
            "Epoch 137/1000\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.0567 - acc: 0.9788 - val_loss: 4.7247 - val_acc: 0.7396\n",
            "Epoch 138/1000\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.0819 - acc: 0.9722 - val_loss: 4.5584 - val_acc: 0.7396\n",
            "Epoch 139/1000\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.0744 - acc: 0.9755 - val_loss: 4.1041 - val_acc: 0.7396\n",
            "Epoch 140/1000\n",
            "39/39 [==============================] - 10s 251ms/step - loss: 0.0638 - acc: 0.9771 - val_loss: 5.4970 - val_acc: 0.7188\n",
            "Epoch 141/1000\n",
            "39/39 [==============================] - 7s 165ms/step - loss: 0.0585 - acc: 0.9788 - val_loss: 4.5468 - val_acc: 0.7604\n",
            "Epoch 142/1000\n",
            "39/39 [==============================] - 5s 117ms/step - loss: 0.0748 - acc: 0.9739 - val_loss: 4.4440 - val_acc: 0.7500\n",
            "Epoch 143/1000\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.0691 - acc: 0.9771 - val_loss: 4.5237 - val_acc: 0.7396\n",
            "Epoch 144/1000\n",
            "39/39 [==============================] - 10s 240ms/step - loss: 0.0708 - acc: 0.9739 - val_loss: 3.6454 - val_acc: 0.7292\n",
            "Epoch 145/1000\n",
            "39/39 [==============================] - 10s 242ms/step - loss: 0.0448 - acc: 0.9853 - val_loss: 3.5824 - val_acc: 0.7396\n",
            "Epoch 146/1000\n",
            "39/39 [==============================] - 10s 241ms/step - loss: 0.1264 - acc: 0.9608 - val_loss: 3.4343 - val_acc: 0.7604\n",
            "Epoch 147/1000\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 0.0283 - acc: 0.9886 - val_loss: 3.7131 - val_acc: 0.7396\n",
            "Epoch 148/1000\n",
            "39/39 [==============================] - 10s 242ms/step - loss: 0.0654 - acc: 0.9886 - val_loss: 4.0908 - val_acc: 0.7500\n",
            "Epoch 149/1000\n",
            "39/39 [==============================] - 5s 117ms/step - loss: 0.0494 - acc: 0.9804 - val_loss: 4.3045 - val_acc: 0.7500\n",
            "Epoch 150/1000\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.0642 - acc: 0.9808 - val_loss: 4.3130 - val_acc: 0.7500\n",
            "Epoch 151/1000\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.0449 - acc: 0.9853 - val_loss: 4.0745 - val_acc: 0.7500\n",
            "Epoch 152/1000\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 0.0491 - acc: 0.9820 - val_loss: 4.2040 - val_acc: 0.7396\n",
            "Epoch 153/1000\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.1076 - acc: 0.9624 - val_loss: 4.0993 - val_acc: 0.7396\n",
            "Epoch 154/1000\n",
            "39/39 [==============================] - 10s 241ms/step - loss: 0.1049 - acc: 0.9739 - val_loss: 3.8636 - val_acc: 0.7292\n",
            "Epoch 155/1000\n",
            "39/39 [==============================] - 5s 119ms/step - loss: 0.0538 - acc: 0.9788 - val_loss: 3.8408 - val_acc: 0.7083\n",
            "Epoch 156/1000\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.0629 - acc: 0.9820 - val_loss: 3.4021 - val_acc: 0.7292\n",
            "Epoch 157/1000\n",
            "39/39 [==============================] - 5s 115ms/step - loss: 0.0407 - acc: 0.9869 - val_loss: 4.0102 - val_acc: 0.7083\n",
            "Epoch 158/1000\n",
            "39/39 [==============================] - 10s 243ms/step - loss: 0.0430 - acc: 0.9837 - val_loss: 3.5917 - val_acc: 0.7083\n",
            "Epoch 159/1000\n",
            "39/39 [==============================] - 10s 242ms/step - loss: 0.0409 - acc: 0.9886 - val_loss: 3.9607 - val_acc: 0.7292\n",
            "Epoch 160/1000\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.0900 - acc: 0.9853 - val_loss: 4.1749 - val_acc: 0.6979\n",
            "Epoch 161/1000\n",
            "39/39 [==============================] - 7s 162ms/step - loss: 0.0641 - acc: 0.9820 - val_loss: 3.8207 - val_acc: 0.7188\n",
            "Epoch 162/1000\n",
            "39/39 [==============================] - 10s 242ms/step - loss: 0.1030 - acc: 0.9755 - val_loss: 4.3060 - val_acc: 0.7396\n",
            "Epoch 163/1000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 0.0548 - acc: 0.9788 - val_loss: 4.9755 - val_acc: 0.7500\n",
            "Epoch 164/1000\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.0587 - acc: 0.9820 - val_loss: 4.7633 - val_acc: 0.7292\n",
            "Epoch 165/1000\n",
            "39/39 [==============================] - 5s 115ms/step - loss: 0.0540 - acc: 0.9869 - val_loss: 5.1958 - val_acc: 0.7292\n",
            "Epoch 166/1000\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 0.0421 - acc: 0.9869 - val_loss: 4.6047 - val_acc: 0.7500\n",
            "Epoch 167/1000\n",
            "39/39 [==============================] - 10s 244ms/step - loss: 0.0768 - acc: 0.9837 - val_loss: 4.6953 - val_acc: 0.7083\n",
            "Epoch 168/1000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 0.0219 - acc: 0.9951 - val_loss: 4.6922 - val_acc: 0.7396\n",
            "Epoch 169/1000\n",
            "39/39 [==============================] - 6s 136ms/step - loss: 0.0659 - acc: 0.9872 - val_loss: 3.7873 - val_acc: 0.7604\n",
            "Epoch 170/1000\n",
            "39/39 [==============================] - 10s 241ms/step - loss: 0.0203 - acc: 0.9951 - val_loss: 4.4310 - val_acc: 0.7396\n",
            "Epoch 171/1000\n",
            "39/39 [==============================] - 5s 119ms/step - loss: 0.0193 - acc: 0.9902 - val_loss: 3.8978 - val_acc: 0.7500\n",
            "Epoch 172/1000\n",
            "39/39 [==============================] - 6s 135ms/step - loss: 0.0698 - acc: 0.9820 - val_loss: 4.3345 - val_acc: 0.7396\n",
            "Epoch 173/1000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 0.0339 - acc: 0.9820 - val_loss: 4.7263 - val_acc: 0.7292\n",
            "Epoch 174/1000\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.1010 - acc: 0.9771 - val_loss: 4.3339 - val_acc: 0.7292\n",
            "Epoch 175/1000\n",
            "39/39 [==============================] - 10s 244ms/step - loss: 0.0192 - acc: 0.9951 - val_loss: 5.1229 - val_acc: 0.7500\n",
            "Epoch 176/1000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 0.0289 - acc: 0.9853 - val_loss: 5.3245 - val_acc: 0.7292\n",
            "Epoch 177/1000\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.0527 - acc: 0.9853 - val_loss: 4.0875 - val_acc: 0.7188\n",
            "Epoch 178/1000\n",
            "39/39 [==============================] - 5s 115ms/step - loss: 0.0352 - acc: 0.9853 - val_loss: 4.4277 - val_acc: 0.7500\n",
            "Epoch 179/1000\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 0.0432 - acc: 0.9886 - val_loss: 5.2923 - val_acc: 0.7604\n",
            "Epoch 180/1000\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 0.0507 - acc: 0.9804 - val_loss: 5.2444 - val_acc: 0.7396\n",
            "Epoch 181/1000\n",
            "39/39 [==============================] - 5s 128ms/step - loss: 0.0503 - acc: 0.9886 - val_loss: 5.1856 - val_acc: 0.7396\n",
            "Epoch 182/1000\n",
            "39/39 [==============================] - 5s 118ms/step - loss: 0.0646 - acc: 0.9804 - val_loss: 4.3461 - val_acc: 0.7604\n",
            "Epoch 183/1000\n",
            "39/39 [==============================] - 10s 245ms/step - loss: 0.0677 - acc: 0.9886 - val_loss: 4.1532 - val_acc: 0.7500\n",
            "Epoch 184/1000\n",
            "39/39 [==============================] - 10s 243ms/step - loss: 0.0945 - acc: 0.9755 - val_loss: 4.5318 - val_acc: 0.7500\n",
            "Epoch 185/1000\n",
            "39/39 [==============================] - 10s 243ms/step - loss: 0.0519 - acc: 0.9869 - val_loss: 4.0759 - val_acc: 0.7396\n",
            "Epoch 186/1000\n",
            "39/39 [==============================] - 5s 128ms/step - loss: 0.0497 - acc: 0.9837 - val_loss: 4.1066 - val_acc: 0.7604\n",
            "Epoch 187/1000\n",
            "39/39 [==============================] - 10s 241ms/step - loss: 0.0321 - acc: 0.9936 - val_loss: 4.3341 - val_acc: 0.7604\n",
            "Epoch 188/1000\n",
            "39/39 [==============================] - 10s 245ms/step - loss: 0.0447 - acc: 0.9853 - val_loss: 4.4518 - val_acc: 0.7292\n",
            "Epoch 189/1000\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.0268 - acc: 0.9935 - val_loss: 5.4018 - val_acc: 0.7292\n",
            "Epoch 190/1000\n",
            "39/39 [==============================] - 10s 241ms/step - loss: 0.0369 - acc: 0.9853 - val_loss: 4.4018 - val_acc: 0.6979\n",
            "Epoch 191/1000\n",
            "39/39 [==============================] - 10s 241ms/step - loss: 0.0369 - acc: 0.9886 - val_loss: 4.8195 - val_acc: 0.7500\n",
            "Epoch 192/1000\n",
            "39/39 [==============================] - 10s 240ms/step - loss: 0.0226 - acc: 0.9951 - val_loss: 5.5894 - val_acc: 0.7604\n",
            "Epoch 193/1000\n",
            "39/39 [==============================] - 10s 251ms/step - loss: 0.0504 - acc: 0.9820 - val_loss: 4.7467 - val_acc: 0.7604\n",
            "Epoch 194/1000\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.0354 - acc: 0.9886 - val_loss: 5.0941 - val_acc: 0.7292\n",
            "Epoch 195/1000\n",
            "39/39 [==============================] - 5s 119ms/step - loss: 0.0375 - acc: 0.9902 - val_loss: 6.2288 - val_acc: 0.7396\n",
            "Epoch 196/1000\n",
            "39/39 [==============================] - 6s 143ms/step - loss: 0.0575 - acc: 0.9886 - val_loss: 6.0056 - val_acc: 0.7292\n",
            "Epoch 197/1000\n",
            "39/39 [==============================] - 5s 118ms/step - loss: 0.0424 - acc: 0.9869 - val_loss: 6.3121 - val_acc: 0.7292\n",
            "Epoch 198/1000\n",
            "39/39 [==============================] - 10s 252ms/step - loss: 0.0134 - acc: 0.9951 - val_loss: 5.7263 - val_acc: 0.7292\n",
            "Epoch 199/1000\n",
            "39/39 [==============================] - 10s 244ms/step - loss: 0.0185 - acc: 0.9951 - val_loss: 4.9491 - val_acc: 0.7604\n",
            "Epoch 200/1000\n",
            "39/39 [==============================] - 6s 131ms/step - loss: 0.0610 - acc: 0.9804 - val_loss: 5.4308 - val_acc: 0.7083\n",
            "Epoch 201/1000\n",
            "39/39 [==============================] - 10s 258ms/step - loss: 0.0297 - acc: 0.9935 - val_loss: 5.4985 - val_acc: 0.7188\n",
            "Epoch 202/1000\n",
            "39/39 [==============================] - 5s 121ms/step - loss: 0.0368 - acc: 0.9886 - val_loss: 5.1704 - val_acc: 0.7396\n",
            "Epoch 203/1000\n",
            "39/39 [==============================] - 11s 257ms/step - loss: 0.0547 - acc: 0.9853 - val_loss: 6.3697 - val_acc: 0.7292\n",
            "Epoch 204/1000\n",
            "39/39 [==============================] - 6s 129ms/step - loss: 0.0133 - acc: 0.9935 - val_loss: 5.2308 - val_acc: 0.7396\n",
            "Epoch 205/1000\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 0.0225 - acc: 0.9886 - val_loss: 5.0010 - val_acc: 0.7396\n",
            "Epoch 206/1000\n",
            "39/39 [==============================] - 6s 140ms/step - loss: 0.0321 - acc: 0.9918 - val_loss: 5.3954 - val_acc: 0.7292\n",
            "Epoch 207/1000\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 0.0207 - acc: 0.9935 - val_loss: 5.7899 - val_acc: 0.7188\n",
            "Epoch 208/1000\n",
            "39/39 [==============================] - 6s 137ms/step - loss: 0.0512 - acc: 0.9935 - val_loss: 4.8064 - val_acc: 0.7083\n",
            "Epoch 209/1000\n",
            "39/39 [==============================] - 10s 245ms/step - loss: 0.0423 - acc: 0.9902 - val_loss: 4.8826 - val_acc: 0.6979\n",
            "Epoch 210/1000\n",
            "39/39 [==============================] - 11s 260ms/step - loss: 0.0502 - acc: 0.9869 - val_loss: 4.2695 - val_acc: 0.7188\n",
            "Epoch 211/1000\n",
            "39/39 [==============================] - 11s 264ms/step - loss: 0.0317 - acc: 0.9902 - val_loss: 4.0144 - val_acc: 0.7188\n",
            "Epoch 212/1000\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 0.0213 - acc: 0.9951 - val_loss: 5.7147 - val_acc: 0.7292\n",
            "Epoch 213/1000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 0.0471 - acc: 0.9820 - val_loss: 4.8747 - val_acc: 0.7292\n",
            "Epoch 214/1000\n",
            "39/39 [==============================] - 6s 133ms/step - loss: 0.0404 - acc: 0.9918 - val_loss: 5.4023 - val_acc: 0.7292\n",
            "Epoch 215/1000\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.0415 - acc: 0.9886 - val_loss: 7.3222 - val_acc: 0.7188\n",
            "Epoch 216/1000\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 0.0291 - acc: 0.9902 - val_loss: 7.3204 - val_acc: 0.7292\n",
            "Epoch 217/1000\n",
            "39/39 [==============================] - 11s 259ms/step - loss: 0.0653 - acc: 0.9918 - val_loss: 7.2659 - val_acc: 0.7188\n",
            "Epoch 218/1000\n",
            "39/39 [==============================] - 5s 130ms/step - loss: 0.0855 - acc: 0.9869 - val_loss: 5.3810 - val_acc: 0.7292\n",
            "Epoch 219/1000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 0.0334 - acc: 0.9918 - val_loss: 3.2627 - val_acc: 0.7083\n",
            "Epoch 220/1000\n",
            "39/39 [==============================] - 5s 120ms/step - loss: 0.0526 - acc: 0.9869 - val_loss: 4.1364 - val_acc: 0.6979\n",
            "Epoch 221/1000\n",
            "39/39 [==============================] - 10s 256ms/step - loss: 0.0258 - acc: 0.9918 - val_loss: 4.2531 - val_acc: 0.7188\n",
            "Epoch 222/1000\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 0.0512 - acc: 0.9918 - val_loss: 4.4488 - val_acc: 0.7292\n",
            "Epoch 223/1000\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 0.0243 - acc: 0.9951 - val_loss: 4.4451 - val_acc: 0.6979\n",
            "Epoch 224/1000\n",
            "39/39 [==============================] - 5s 120ms/step - loss: 0.0092 - acc: 0.9984 - val_loss: 3.9534 - val_acc: 0.6875\n",
            "Epoch 225/1000\n",
            "39/39 [==============================] - 6s 139ms/step - loss: 0.0149 - acc: 0.9984 - val_loss: 3.4005 - val_acc: 0.6875\n",
            "Epoch 226/1000\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.0200 - acc: 0.9951 - val_loss: 3.7914 - val_acc: 0.6771\n",
            "Epoch 227/1000\n",
            "39/39 [==============================] - 5s 119ms/step - loss: 0.0261 - acc: 0.9902 - val_loss: 4.2515 - val_acc: 0.6875\n",
            "Epoch 228/1000\n",
            "39/39 [==============================] - 6s 129ms/step - loss: 0.0144 - acc: 0.9967 - val_loss: 5.3293 - val_acc: 0.7292\n",
            "Epoch 229/1000\n",
            "39/39 [==============================] - 6s 131ms/step - loss: 0.0282 - acc: 0.9935 - val_loss: 5.2031 - val_acc: 0.6562\n",
            "Epoch 230/1000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 0.0170 - acc: 0.9951 - val_loss: 5.1956 - val_acc: 0.6979\n",
            "Epoch 231/1000\n",
            "39/39 [==============================] - 7s 168ms/step - loss: 0.0108 - acc: 0.9967 - val_loss: 5.5058 - val_acc: 0.7083\n",
            "Epoch 232/1000\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 0.0305 - acc: 0.9869 - val_loss: 6.5326 - val_acc: 0.7188\n",
            "Epoch 233/1000\n",
            "39/39 [==============================] - 6s 135ms/step - loss: 0.0249 - acc: 0.9902 - val_loss: 6.6895 - val_acc: 0.7292\n",
            "Epoch 234/1000\n",
            "39/39 [==============================] - 5s 119ms/step - loss: 0.0584 - acc: 0.9951 - val_loss: 5.7406 - val_acc: 0.7083\n",
            "Epoch 235/1000\n",
            "39/39 [==============================] - 6s 144ms/step - loss: 0.0401 - acc: 0.9886 - val_loss: 4.8900 - val_acc: 0.7292\n",
            "Epoch 236/1000\n",
            "39/39 [==============================] - 6s 128ms/step - loss: 0.0482 - acc: 0.9869 - val_loss: 5.1401 - val_acc: 0.7083\n",
            "Epoch 237/1000\n",
            "39/39 [==============================] - 6s 139ms/step - loss: 0.0344 - acc: 0.9902 - val_loss: 4.7201 - val_acc: 0.7083\n",
            "Epoch 238/1000\n",
            "39/39 [==============================] - 10s 245ms/step - loss: 0.0211 - acc: 0.9918 - val_loss: 4.7696 - val_acc: 0.7396\n",
            "Epoch 239/1000\n",
            "39/39 [==============================] - 6s 130ms/step - loss: 0.0315 - acc: 0.9902 - val_loss: 5.5374 - val_acc: 0.6875\n",
            "Epoch 240/1000\n",
            "39/39 [==============================] - 10s 256ms/step - loss: 0.0211 - acc: 0.9935 - val_loss: 5.1169 - val_acc: 0.7500\n",
            "Epoch 241/1000\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 0.0226 - acc: 0.9886 - val_loss: 5.3704 - val_acc: 0.7292\n",
            "Epoch 242/1000\n",
            "39/39 [==============================] - 11s 254ms/step - loss: 0.0401 - acc: 0.9853 - val_loss: 4.6698 - val_acc: 0.7292\n",
            "Epoch 243/1000\n",
            "39/39 [==============================] - 10s 257ms/step - loss: 0.0290 - acc: 0.9886 - val_loss: 4.3188 - val_acc: 0.7292\n",
            "Epoch 244/1000\n",
            "39/39 [==============================] - 5s 121ms/step - loss: 0.0186 - acc: 0.9951 - val_loss: 4.4087 - val_acc: 0.7500\n",
            "Epoch 245/1000\n",
            "39/39 [==============================] - 6s 143ms/step - loss: 0.0247 - acc: 0.9935 - val_loss: 5.9376 - val_acc: 0.7083\n",
            "Epoch 246/1000\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.0253 - acc: 0.9886 - val_loss: 5.8367 - val_acc: 0.7188\n",
            "Epoch 247/1000\n",
            "39/39 [==============================] - 5s 122ms/step - loss: 0.0221 - acc: 0.9952 - val_loss: 5.2720 - val_acc: 0.7292\n",
            "Epoch 248/1000\n",
            "39/39 [==============================] - 6s 142ms/step - loss: 0.0157 - acc: 0.9951 - val_loss: 5.8988 - val_acc: 0.7188\n",
            "Epoch 249/1000\n",
            "39/39 [==============================] - 6s 130ms/step - loss: 0.0756 - acc: 0.9869 - val_loss: 5.3971 - val_acc: 0.7292\n",
            "Epoch 250/1000\n",
            "39/39 [==============================] - 6s 131ms/step - loss: 0.0172 - acc: 0.9951 - val_loss: 5.2105 - val_acc: 0.7188\n",
            "Epoch 251/1000\n",
            "39/39 [==============================] - 5s 119ms/step - loss: 0.0185 - acc: 0.9951 - val_loss: 5.7013 - val_acc: 0.7500\n",
            "Epoch 252/1000\n",
            "39/39 [==============================] - 10s 257ms/step - loss: 0.0174 - acc: 0.9918 - val_loss: 5.0838 - val_acc: 0.7500\n",
            "Epoch 253/1000\n",
            "39/39 [==============================] - 10s 252ms/step - loss: 0.0069 - acc: 0.9984 - val_loss: 5.4142 - val_acc: 0.7500\n",
            "Epoch 254/1000\n",
            "39/39 [==============================] - 5s 118ms/step - loss: 0.0557 - acc: 0.9902 - val_loss: 4.2376 - val_acc: 0.7188\n",
            "Epoch 255/1000\n",
            "39/39 [==============================] - 6s 129ms/step - loss: 0.0354 - acc: 0.9902 - val_loss: 5.4556 - val_acc: 0.7083\n",
            "Epoch 256/1000\n",
            "39/39 [==============================] - 7s 163ms/step - loss: 0.0274 - acc: 0.9902 - val_loss: 5.1901 - val_acc: 0.7500\n",
            "Epoch 257/1000\n",
            "39/39 [==============================] - 5s 118ms/step - loss: 0.0359 - acc: 0.9918 - val_loss: 5.4339 - val_acc: 0.7083\n",
            "Epoch 258/1000\n",
            "39/39 [==============================] - 10s 244ms/step - loss: 0.0165 - acc: 0.9918 - val_loss: 4.4961 - val_acc: 0.7500\n",
            "Epoch 259/1000\n",
            "39/39 [==============================] - 10s 245ms/step - loss: 0.0210 - acc: 0.9935 - val_loss: 4.9819 - val_acc: 0.7292\n",
            "Epoch 260/1000\n",
            "39/39 [==============================] - 5s 120ms/step - loss: 0.0140 - acc: 0.9951 - val_loss: 4.8215 - val_acc: 0.7396\n",
            "Epoch 261/1000\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.0068 - acc: 0.9968 - val_loss: 5.7184 - val_acc: 0.7188\n",
            "Epoch 262/1000\n",
            "39/39 [==============================] - 11s 257ms/step - loss: 0.0399 - acc: 0.9918 - val_loss: 4.7558 - val_acc: 0.7292\n",
            "Epoch 263/1000\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.0717 - acc: 0.9853 - val_loss: 4.8362 - val_acc: 0.7083\n",
            "Epoch 264/1000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 0.0255 - acc: 0.9951 - val_loss: 5.2684 - val_acc: 0.7188\n",
            "Epoch 265/1000\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 0.0179 - acc: 0.9951 - val_loss: 4.6688 - val_acc: 0.6979\n",
            "Epoch 266/1000\n",
            "39/39 [==============================] - 6s 129ms/step - loss: 0.0268 - acc: 0.9902 - val_loss: 5.8780 - val_acc: 0.7292\n",
            "Epoch 267/1000\n",
            "39/39 [==============================] - 10s 255ms/step - loss: 0.0156 - acc: 0.9935 - val_loss: 6.1127 - val_acc: 0.7188\n",
            "Epoch 268/1000\n",
            "39/39 [==============================] - 10s 245ms/step - loss: 0.0094 - acc: 0.9967 - val_loss: 6.2830 - val_acc: 0.7604\n",
            "Epoch 269/1000\n",
            "39/39 [==============================] - 5s 120ms/step - loss: 0.0065 - acc: 0.9967 - val_loss: 6.8474 - val_acc: 0.7500\n",
            "Epoch 270/1000\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.0215 - acc: 0.9935 - val_loss: 5.5083 - val_acc: 0.7500\n",
            "Epoch 271/1000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 0.0819 - acc: 0.9820 - val_loss: 6.6805 - val_acc: 0.7604\n",
            "Epoch 272/1000\n",
            "39/39 [==============================] - 10s 245ms/step - loss: 0.0266 - acc: 0.9918 - val_loss: 6.7130 - val_acc: 0.7500\n",
            "Epoch 273/1000\n",
            "39/39 [==============================] - 6s 129ms/step - loss: 0.0262 - acc: 0.9918 - val_loss: 5.8545 - val_acc: 0.7604\n",
            "Epoch 274/1000\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.0378 - acc: 0.9935 - val_loss: 6.2415 - val_acc: 0.7396\n",
            "Epoch 275/1000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 0.0267 - acc: 0.9918 - val_loss: 5.5801 - val_acc: 0.7604\n",
            "Epoch 276/1000\n",
            "39/39 [==============================] - 5s 118ms/step - loss: 0.0218 - acc: 0.9918 - val_loss: 6.6744 - val_acc: 0.7500\n",
            "Epoch 277/1000\n",
            "39/39 [==============================] - 6s 133ms/step - loss: 0.0285 - acc: 0.9918 - val_loss: 7.8052 - val_acc: 0.7396\n",
            "Epoch 278/1000\n",
            "39/39 [==============================] - 6s 129ms/step - loss: 0.0051 - acc: 0.9984 - val_loss: 7.0051 - val_acc: 0.7500\n",
            "Epoch 279/1000\n",
            "39/39 [==============================] - 10s 252ms/step - loss: 0.0104 - acc: 0.9951 - val_loss: 6.2609 - val_acc: 0.7604\n",
            "Epoch 280/1000\n",
            "39/39 [==============================] - 5s 120ms/step - loss: 0.0070 - acc: 0.9967 - val_loss: 8.7204 - val_acc: 0.7396\n",
            "Epoch 281/1000\n",
            "39/39 [==============================] - 6s 143ms/step - loss: 0.0073 - acc: 0.9967 - val_loss: 8.4789 - val_acc: 0.7708\n",
            "Epoch 282/1000\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 0.0278 - acc: 0.9902 - val_loss: 9.7113 - val_acc: 0.7500\n",
            "Epoch 283/1000\n",
            "39/39 [==============================] - 10s 251ms/step - loss: 0.0119 - acc: 0.9967 - val_loss: 8.2447 - val_acc: 0.7708\n",
            "Epoch 284/1000\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 0.0138 - acc: 0.9951 - val_loss: 9.6798 - val_acc: 0.7500\n",
            "Epoch 285/1000\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 0.0145 - acc: 0.9935 - val_loss: 8.6278 - val_acc: 0.7500\n",
            "Epoch 286/1000\n",
            "39/39 [==============================] - 10s 254ms/step - loss: 0.0354 - acc: 0.9902 - val_loss: 6.6777 - val_acc: 0.7708\n",
            "Epoch 287/1000\n",
            "39/39 [==============================] - 10s 245ms/step - loss: 0.0095 - acc: 0.9951 - val_loss: 8.4006 - val_acc: 0.7500\n",
            "Epoch 288/1000\n",
            "39/39 [==============================] - 5s 118ms/step - loss: 0.0550 - acc: 0.9902 - val_loss: 7.6103 - val_acc: 0.7500\n",
            "Epoch 289/1000\n",
            "39/39 [==============================] - 6s 139ms/step - loss: 0.0251 - acc: 0.9967 - val_loss: 7.4267 - val_acc: 0.7604\n",
            "Epoch 290/1000\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.0249 - acc: 0.9967 - val_loss: 6.4759 - val_acc: 0.7500\n",
            "Epoch 291/1000\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 0.0311 - acc: 0.9951 - val_loss: 7.6055 - val_acc: 0.7604\n",
            "Epoch 292/1000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 0.0143 - acc: 0.9951 - val_loss: 6.8757 - val_acc: 0.7396\n",
            "Epoch 293/1000\n",
            "39/39 [==============================] - 10s 244ms/step - loss: 0.0263 - acc: 0.9888 - val_loss: 6.9986 - val_acc: 0.7500\n",
            "Epoch 294/1000\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 0.0205 - acc: 0.9935 - val_loss: 8.0025 - val_acc: 0.7396\n",
            "Epoch 295/1000\n",
            "39/39 [==============================] - 11s 259ms/step - loss: 0.0079 - acc: 0.9967 - val_loss: 7.2384 - val_acc: 0.7604\n",
            "Epoch 296/1000\n",
            "39/39 [==============================] - 5s 117ms/step - loss: 0.0326 - acc: 0.9918 - val_loss: 7.0361 - val_acc: 0.7604\n",
            "Epoch 297/1000\n",
            "39/39 [==============================] - 11s 258ms/step - loss: 0.0305 - acc: 0.9951 - val_loss: 6.2506 - val_acc: 0.7604\n",
            "Epoch 298/1000\n",
            "39/39 [==============================] - 10s 251ms/step - loss: 0.0320 - acc: 0.9886 - val_loss: 9.5289 - val_acc: 0.7500\n",
            "Epoch 299/1000\n",
            "39/39 [==============================] - 10s 243ms/step - loss: 0.0756 - acc: 0.9869 - val_loss: 5.7915 - val_acc: 0.7396\n",
            "Epoch 300/1000\n",
            "39/39 [==============================] - 5s 118ms/step - loss: 0.0152 - acc: 0.9951 - val_loss: 6.3500 - val_acc: 0.7396\n",
            "Epoch 301/1000\n",
            "39/39 [==============================] - 6s 129ms/step - loss: 0.0151 - acc: 0.9935 - val_loss: 5.4338 - val_acc: 0.7604\n",
            "Epoch 302/1000\n",
            "39/39 [==============================] - 6s 129ms/step - loss: 0.0059 - acc: 0.9967 - val_loss: 6.1909 - val_acc: 0.7292\n",
            "Epoch 303/1000\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.0356 - acc: 0.9918 - val_loss: 7.2175 - val_acc: 0.7500\n",
            "Epoch 304/1000\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.0109 - acc: 0.9984 - val_loss: 6.0628 - val_acc: 0.7708\n",
            "Epoch 305/1000\n",
            "39/39 [==============================] - 10s 243ms/step - loss: 0.0135 - acc: 0.9935 - val_loss: 5.3921 - val_acc: 0.7604\n",
            "Epoch 306/1000\n",
            "39/39 [==============================] - 10s 244ms/step - loss: 0.0179 - acc: 0.9951 - val_loss: 7.1336 - val_acc: 0.7604\n",
            "Epoch 307/1000\n",
            "39/39 [==============================] - 6s 129ms/step - loss: 0.0383 - acc: 0.9918 - val_loss: 7.7131 - val_acc: 0.7500\n",
            "Epoch 308/1000\n",
            "39/39 [==============================] - 10s 245ms/step - loss: 0.0086 - acc: 0.9967 - val_loss: 7.9810 - val_acc: 0.7396\n",
            "Epoch 309/1000\n",
            "39/39 [==============================] - 5s 119ms/step - loss: 0.0510 - acc: 0.9886 - val_loss: 9.6799 - val_acc: 0.7396\n",
            "Epoch 310/1000\n",
            "39/39 [==============================] - 10s 255ms/step - loss: 0.0130 - acc: 0.9935 - val_loss: 7.8176 - val_acc: 0.7396\n",
            "Epoch 311/1000\n",
            "39/39 [==============================] - 6s 131ms/step - loss: 0.0177 - acc: 0.9967 - val_loss: 7.7976 - val_acc: 0.7292\n",
            "Epoch 312/1000\n",
            "39/39 [==============================] - 6s 136ms/step - loss: 0.0106 - acc: 0.9935 - val_loss: 6.6755 - val_acc: 0.7396\n",
            "Epoch 313/1000\n",
            "39/39 [==============================] - 10s 245ms/step - loss: 0.0197 - acc: 0.9951 - val_loss: 8.1283 - val_acc: 0.7292\n",
            "Epoch 314/1000\n",
            "39/39 [==============================] - 10s 244ms/step - loss: 0.0263 - acc: 0.9935 - val_loss: 7.0502 - val_acc: 0.7396\n",
            "Epoch 315/1000\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 0.0443 - acc: 0.9918 - val_loss: 9.1386 - val_acc: 0.7396\n",
            "Epoch 316/1000\n",
            "39/39 [==============================] - 10s 260ms/step - loss: 0.0211 - acc: 0.9918 - val_loss: 9.2153 - val_acc: 0.7396\n",
            "Epoch 317/1000\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.0172 - acc: 0.9902 - val_loss: 8.9819 - val_acc: 0.7396\n",
            "Epoch 318/1000\n",
            "39/39 [==============================] - 6s 137ms/step - loss: 0.0654 - acc: 0.9918 - val_loss: 7.2544 - val_acc: 0.7292\n",
            "Epoch 319/1000\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 0.0119 - acc: 0.9951 - val_loss: 7.6560 - val_acc: 0.7500\n",
            "Epoch 320/1000\n",
            "39/39 [==============================] - 5s 119ms/step - loss: 0.0192 - acc: 0.9918 - val_loss: 7.1018 - val_acc: 0.7500\n",
            "Epoch 321/1000\n",
            "39/39 [==============================] - 6s 129ms/step - loss: 0.0704 - acc: 0.9918 - val_loss: 6.5629 - val_acc: 0.7604\n",
            "Epoch 322/1000\n",
            "39/39 [==============================] - 10s 243ms/step - loss: 0.0546 - acc: 0.9902 - val_loss: 6.1984 - val_acc: 0.7604\n",
            "Epoch 323/1000\n",
            "39/39 [==============================] - 5s 117ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 6.3382 - val_acc: 0.7604\n",
            "Epoch 324/1000\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.0171 - acc: 0.9951 - val_loss: 6.9466 - val_acc: 0.7604\n",
            "Epoch 325/1000\n",
            "39/39 [==============================] - 5s 120ms/step - loss: 0.0296 - acc: 0.9951 - val_loss: 6.5481 - val_acc: 0.7500\n",
            "Epoch 326/1000\n",
            "39/39 [==============================] - 10s 258ms/step - loss: 0.0409 - acc: 0.9918 - val_loss: 7.1253 - val_acc: 0.7604\n",
            "Epoch 327/1000\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.0102 - acc: 0.9951 - val_loss: 6.4808 - val_acc: 0.7500\n",
            "Epoch 328/1000\n",
            "39/39 [==============================] - 5s 128ms/step - loss: 0.0504 - acc: 0.9869 - val_loss: 8.1747 - val_acc: 0.7396\n",
            "Epoch 329/1000\n",
            "39/39 [==============================] - 11s 262ms/step - loss: 0.0276 - acc: 0.9902 - val_loss: 9.0049 - val_acc: 0.7396\n",
            "Epoch 330/1000\n",
            "39/39 [==============================] - 10s 252ms/step - loss: 0.0257 - acc: 0.9951 - val_loss: 9.2279 - val_acc: 0.7292\n",
            "Epoch 331/1000\n",
            "39/39 [==============================] - 10s 242ms/step - loss: 0.0185 - acc: 0.9951 - val_loss: 7.7663 - val_acc: 0.7604\n",
            "Epoch 332/1000\n",
            "39/39 [==============================] - 6s 130ms/step - loss: 0.0109 - acc: 0.9951 - val_loss: 6.3585 - val_acc: 0.7396\n",
            "Epoch 333/1000\n",
            "39/39 [==============================] - 6s 135ms/step - loss: 0.0150 - acc: 0.9935 - val_loss: 5.9301 - val_acc: 0.7083\n",
            "Epoch 334/1000\n",
            "39/39 [==============================] - 5s 133ms/step - loss: 0.0147 - acc: 0.9935 - val_loss: 6.0211 - val_acc: 0.7396\n",
            "Epoch 335/1000\n",
            "39/39 [==============================] - 6s 130ms/step - loss: 0.0640 - acc: 0.9869 - val_loss: 7.2004 - val_acc: 0.7604\n",
            "Epoch 336/1000\n",
            "39/39 [==============================] - 6s 126ms/step - loss: 0.0337 - acc: 0.9918 - val_loss: 8.3316 - val_acc: 0.7396\n",
            "Epoch 337/1000\n",
            "39/39 [==============================] - 5s 118ms/step - loss: 0.0266 - acc: 0.9951 - val_loss: 8.3186 - val_acc: 0.7500\n",
            "Epoch 338/1000\n",
            "39/39 [==============================] - 6s 130ms/step - loss: 0.0119 - acc: 0.9967 - val_loss: 8.0487 - val_acc: 0.7500\n",
            "Epoch 339/1000\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.0200 - acc: 0.9918 - val_loss: 6.2071 - val_acc: 0.7500\n",
            "Epoch 340/1000\n",
            "39/39 [==============================] - 5s 135ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 5.7419 - val_acc: 0.7396\n",
            "Epoch 341/1000\n",
            "39/39 [==============================] - 11s 260ms/step - loss: 0.0863 - acc: 0.9771 - val_loss: 6.0278 - val_acc: 0.7500\n",
            "Epoch 342/1000\n",
            "39/39 [==============================] - 7s 166ms/step - loss: 0.0197 - acc: 0.9984 - val_loss: 5.1070 - val_acc: 0.7708\n",
            "Epoch 343/1000\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.0279 - acc: 0.9869 - val_loss: 6.0205 - val_acc: 0.7500\n",
            "Epoch 344/1000\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.0082 - acc: 0.9951 - val_loss: 5.2491 - val_acc: 0.7500\n",
            "Epoch 345/1000\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.0950 - acc: 0.9902 - val_loss: 6.9282 - val_acc: 0.7396\n",
            "Epoch 346/1000\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.0215 - acc: 0.9936 - val_loss: 6.9588 - val_acc: 0.7604\n",
            "Epoch 347/1000\n",
            "39/39 [==============================] - 5s 117ms/step - loss: 0.0208 - acc: 0.9935 - val_loss: 6.9746 - val_acc: 0.7188\n",
            "Epoch 348/1000\n",
            "39/39 [==============================] - 6s 131ms/step - loss: 0.0212 - acc: 0.9902 - val_loss: 5.8454 - val_acc: 0.7188\n",
            "Epoch 349/1000\n",
            "39/39 [==============================] - 5s 118ms/step - loss: 0.0210 - acc: 0.9951 - val_loss: 6.8866 - val_acc: 0.7292\n",
            "Epoch 350/1000\n",
            "39/39 [==============================] - 6s 130ms/step - loss: 0.0159 - acc: 0.9935 - val_loss: 7.1131 - val_acc: 0.7188\n",
            "Epoch 351/1000\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.0198 - acc: 0.9918 - val_loss: 7.2818 - val_acc: 0.7604\n",
            "Epoch 352/1000\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.0085 - acc: 0.9967 - val_loss: 7.1891 - val_acc: 0.7500\n",
            "Epoch 353/1000\n",
            "39/39 [==============================] - 6s 133ms/step - loss: 0.0361 - acc: 0.9918 - val_loss: 8.3765 - val_acc: 0.7396\n",
            "Epoch 354/1000\n",
            "39/39 [==============================] - 6s 131ms/step - loss: 0.0343 - acc: 0.9918 - val_loss: 6.2667 - val_acc: 0.7500\n",
            "Epoch 355/1000\n",
            "39/39 [==============================] - 10s 255ms/step - loss: 0.0070 - acc: 0.9984 - val_loss: 5.6904 - val_acc: 0.7500\n",
            "Epoch 356/1000\n",
            "39/39 [==============================] - 5s 119ms/step - loss: 0.0274 - acc: 0.9918 - val_loss: 4.4854 - val_acc: 0.7188\n",
            "Epoch 357/1000\n",
            "39/39 [==============================] - 6s 140ms/step - loss: 0.0152 - acc: 0.9951 - val_loss: 5.5122 - val_acc: 0.7396\n",
            "Epoch 358/1000\n",
            "39/39 [==============================] - 5s 121ms/step - loss: 0.0298 - acc: 0.9918 - val_loss: 4.8139 - val_acc: 0.7500\n",
            "Epoch 359/1000\n",
            "39/39 [==============================] - 11s 261ms/step - loss: 0.0506 - acc: 0.9869 - val_loss: 4.7504 - val_acc: 0.7396\n",
            "Epoch 360/1000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 0.0485 - acc: 0.9935 - val_loss: 4.5540 - val_acc: 0.7396\n",
            "Epoch 361/1000\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.0138 - acc: 0.9967 - val_loss: 4.8709 - val_acc: 0.7396\n",
            "Epoch 362/1000\n",
            "39/39 [==============================] - 7s 172ms/step - loss: 0.0610 - acc: 0.9902 - val_loss: 4.5621 - val_acc: 0.7292\n",
            "Epoch 363/1000\n",
            "39/39 [==============================] - 5s 117ms/step - loss: 0.0235 - acc: 0.9951 - val_loss: 4.3835 - val_acc: 0.7604\n",
            "Epoch 364/1000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 0.0481 - acc: 0.9935 - val_loss: 4.5068 - val_acc: 0.7396\n",
            "Epoch 365/1000\n",
            "39/39 [==============================] - 6s 130ms/step - loss: 0.0073 - acc: 0.9967 - val_loss: 4.7535 - val_acc: 0.7500\n",
            "Epoch 366/1000\n",
            "39/39 [==============================] - 6s 135ms/step - loss: 0.0039 - acc: 0.9984 - val_loss: 4.9851 - val_acc: 0.7396\n",
            "Epoch 367/1000\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.0258 - acc: 0.9935 - val_loss: 6.1045 - val_acc: 0.7396\n",
            "Epoch 368/1000\n",
            "39/39 [==============================] - 10s 255ms/step - loss: 0.0514 - acc: 0.9902 - val_loss: 6.0367 - val_acc: 0.7500\n",
            "Epoch 369/1000\n",
            "39/39 [==============================] - 6s 129ms/step - loss: 0.0103 - acc: 0.9951 - val_loss: 5.5674 - val_acc: 0.7396\n",
            "Epoch 370/1000\n",
            "39/39 [==============================] - 6s 138ms/step - loss: 0.0917 - acc: 0.9918 - val_loss: 4.6860 - val_acc: 0.7396\n",
            "Epoch 371/1000\n",
            "39/39 [==============================] - 5s 119ms/step - loss: 0.0098 - acc: 0.9984 - val_loss: 3.2660 - val_acc: 0.7500\n",
            "Epoch 372/1000\n",
            "39/39 [==============================] - 6s 138ms/step - loss: 0.0132 - acc: 0.9951 - val_loss: 3.8814 - val_acc: 0.7292\n",
            "Epoch 373/1000\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 0.0409 - acc: 0.9918 - val_loss: 4.0956 - val_acc: 0.7604\n",
            "Epoch 374/1000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 0.0054 - acc: 0.9984 - val_loss: 4.3470 - val_acc: 0.7604\n",
            "Epoch 375/1000\n",
            "39/39 [==============================] - 10s 256ms/step - loss: 0.0219 - acc: 0.9951 - val_loss: 5.1373 - val_acc: 0.7500\n",
            "Epoch 376/1000\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 0.0171 - acc: 0.9935 - val_loss: 4.8505 - val_acc: 0.7500\n",
            "Epoch 377/1000\n",
            "39/39 [==============================] - 5s 121ms/step - loss: 0.0369 - acc: 0.9918 - val_loss: 4.0455 - val_acc: 0.7396\n",
            "Epoch 378/1000\n",
            "39/39 [==============================] - 6s 130ms/step - loss: 0.0060 - acc: 0.9984 - val_loss: 3.6898 - val_acc: 0.7500\n",
            "Epoch 379/1000\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.0121 - acc: 0.9935 - val_loss: 5.6529 - val_acc: 0.7604\n",
            "Epoch 380/1000\n",
            "39/39 [==============================] - 5s 121ms/step - loss: 0.0089 - acc: 0.9984 - val_loss: 5.9324 - val_acc: 0.7500\n",
            "Epoch 381/1000\n",
            "39/39 [==============================] - 10s 256ms/step - loss: 0.0097 - acc: 0.9935 - val_loss: 5.3641 - val_acc: 0.7604\n",
            "Epoch 382/1000\n",
            "39/39 [==============================] - 10s 245ms/step - loss: 0.0231 - acc: 0.9918 - val_loss: 4.3296 - val_acc: 0.7604\n",
            "Epoch 383/1000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 0.0083 - acc: 0.9967 - val_loss: 6.2678 - val_acc: 0.7396\n",
            "Epoch 384/1000\n",
            "39/39 [==============================] - 6s 143ms/step - loss: 0.0362 - acc: 0.9902 - val_loss: 7.1599 - val_acc: 0.7292\n",
            "Epoch 385/1000\n",
            "39/39 [==============================] - 5s 117ms/step - loss: 0.0077 - acc: 0.9968 - val_loss: 7.9522 - val_acc: 0.7500\n",
            "Epoch 386/1000\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.0033 - acc: 0.9984 - val_loss: 7.1303 - val_acc: 0.7396\n",
            "Epoch 387/1000\n",
            "39/39 [==============================] - 6s 131ms/step - loss: 0.0180 - acc: 0.9935 - val_loss: 5.9600 - val_acc: 0.7500\n",
            "Epoch 388/1000\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 0.0548 - acc: 0.9869 - val_loss: 6.6042 - val_acc: 0.7396\n",
            "Epoch 389/1000\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 6.2275 - val_acc: 0.7396\n",
            "Epoch 390/1000\n",
            "39/39 [==============================] - 6s 129ms/step - loss: 0.0191 - acc: 0.9951 - val_loss: 5.9558 - val_acc: 0.7292\n",
            "Epoch 391/1000\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 0.0478 - acc: 0.9886 - val_loss: 7.6106 - val_acc: 0.7604\n",
            "Epoch 392/1000\n",
            "39/39 [==============================] - 5s 128ms/step - loss: 0.0377 - acc: 0.9918 - val_loss: 7.1910 - val_acc: 0.7396\n",
            "Epoch 393/1000\n",
            "39/39 [==============================] - 10s 244ms/step - loss: 0.0076 - acc: 0.9951 - val_loss: 6.1103 - val_acc: 0.7500\n",
            "Epoch 394/1000\n",
            "39/39 [==============================] - 6s 127ms/step - loss: 0.0044 - acc: 0.9984 - val_loss: 6.1726 - val_acc: 0.7604\n",
            "Epoch 395/1000\n",
            "39/39 [==============================] - 10s 255ms/step - loss: 0.0121 - acc: 0.9951 - val_loss: 6.7325 - val_acc: 0.7188\n",
            "Epoch 396/1000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 9.1513e-04 - acc: 1.0000 - val_loss: 6.5302 - val_acc: 0.7292\n",
            "Epoch 397/1000\n",
            "39/39 [==============================] - 11s 256ms/step - loss: 0.0045 - acc: 0.9984 - val_loss: 7.3961 - val_acc: 0.7396\n",
            "Epoch 398/1000\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.0047 - acc: 0.9984 - val_loss: 5.6293 - val_acc: 0.7812\n",
            "Epoch 399/1000\n",
            "39/39 [==============================] - 5s 119ms/step - loss: 0.0267 - acc: 0.9935 - val_loss: 7.4575 - val_acc: 0.7396\n",
            "Epoch 400/1000\n",
            "39/39 [==============================] - 10s 259ms/step - loss: 0.0148 - acc: 0.9951 - val_loss: 7.6055 - val_acc: 0.7292\n",
            "Epoch 401/1000\n",
            "39/39 [==============================] - 6s 131ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 9.4173 - val_acc: 0.7292\n",
            "Epoch 402/1000\n",
            "39/39 [==============================] - 5s 122ms/step - loss: 0.0124 - acc: 0.9967 - val_loss: 8.8967 - val_acc: 0.7292\n",
            "Epoch 403/1000\n",
            "39/39 [==============================] - 5s 122ms/step - loss: 0.0245 - acc: 0.9918 - val_loss: 9.7718 - val_acc: 0.7396\n",
            "Epoch 404/1000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 0.0074 - acc: 0.9967 - val_loss: 10.0301 - val_acc: 0.7188\n",
            "Epoch 405/1000\n",
            "39/39 [==============================] - 5s 128ms/step - loss: 0.0045 - acc: 0.9967 - val_loss: 9.5930 - val_acc: 0.7396\n",
            "Epoch 406/1000\n",
            "39/39 [==============================] - 10s 255ms/step - loss: 0.0417 - acc: 0.9902 - val_loss: 6.9056 - val_acc: 0.7604\n",
            "Epoch 407/1000\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 0.0129 - acc: 0.9951 - val_loss: 7.6406 - val_acc: 0.7604\n",
            "Epoch 408/1000\n",
            "39/39 [==============================] - 10s 244ms/step - loss: 0.0086 - acc: 0.9967 - val_loss: 9.7753 - val_acc: 0.7396\n",
            "Epoch 409/1000\n",
            "39/39 [==============================] - 6s 129ms/step - loss: 0.0054 - acc: 0.9984 - val_loss: 7.4224 - val_acc: 0.7604\n",
            "Epoch 410/1000\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.0209 - acc: 0.9951 - val_loss: 9.5485 - val_acc: 0.7396\n",
            "Epoch 411/1000\n",
            "39/39 [==============================] - 6s 129ms/step - loss: 0.0341 - acc: 0.9918 - val_loss: 11.6544 - val_acc: 0.7396\n",
            "Epoch 412/1000\n",
            "39/39 [==============================] - 6s 129ms/step - loss: 0.0101 - acc: 0.9967 - val_loss: 10.4484 - val_acc: 0.7500\n",
            "Epoch 413/1000\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.0430 - acc: 0.9902 - val_loss: 8.6248 - val_acc: 0.7396\n",
            "Epoch 414/1000\n",
            "39/39 [==============================] - 5s 117ms/step - loss: 0.0254 - acc: 0.9951 - val_loss: 9.3130 - val_acc: 0.7396\n",
            "Epoch 415/1000\n",
            "39/39 [==============================] - 6s 139ms/step - loss: 0.0034 - acc: 0.9984 - val_loss: 8.7559 - val_acc: 0.7604\n",
            "Epoch 416/1000\n",
            "39/39 [==============================] - 5s 118ms/step - loss: 0.0104 - acc: 0.9984 - val_loss: 7.6065 - val_acc: 0.7500\n",
            "Epoch 417/1000\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 0.0160 - acc: 0.9967 - val_loss: 7.4756 - val_acc: 0.7604\n",
            "Epoch 418/1000\n",
            "39/39 [==============================] - 5s 119ms/step - loss: 0.0134 - acc: 0.9951 - val_loss: 9.0242 - val_acc: 0.7396\n",
            "Epoch 419/1000\n",
            "39/39 [==============================] - 11s 258ms/step - loss: 0.0349 - acc: 0.9935 - val_loss: 9.9143 - val_acc: 0.7292\n",
            "Epoch 420/1000\n",
            "39/39 [==============================] - 5s 119ms/step - loss: 0.0109 - acc: 0.9967 - val_loss: 9.3176 - val_acc: 0.7500\n",
            "Epoch 421/1000\n",
            "39/39 [==============================] - 10s 256ms/step - loss: 0.0053 - acc: 0.9951 - val_loss: 8.5140 - val_acc: 0.7396\n",
            "Epoch 422/1000\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 8.9889 - val_acc: 0.7188\n",
            "Epoch 423/1000\n",
            "39/39 [==============================] - 5s 118ms/step - loss: 0.0960 - acc: 0.9951 - val_loss: 9.9677 - val_acc: 0.7292\n",
            "Epoch 424/1000\n",
            "39/39 [==============================] - 10s 254ms/step - loss: 0.0075 - acc: 0.9967 - val_loss: 9.4415 - val_acc: 0.7292\n",
            "Epoch 425/1000\n",
            "39/39 [==============================] - 6s 130ms/step - loss: 0.0099 - acc: 0.9951 - val_loss: 10.3986 - val_acc: 0.7396\n",
            "Epoch 426/1000\n",
            "39/39 [==============================] - 6s 128ms/step - loss: 0.0113 - acc: 0.9935 - val_loss: 9.7718 - val_acc: 0.7500\n",
            "Epoch 427/1000\n",
            "39/39 [==============================] - 6s 127ms/step - loss: 0.0074 - acc: 0.9984 - val_loss: 10.4927 - val_acc: 0.7500\n",
            "Epoch 428/1000\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 0.0218 - acc: 0.9918 - val_loss: 9.3198 - val_acc: 0.7396\n",
            "Epoch 429/1000\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 9.0962 - val_acc: 0.7396\n",
            "Epoch 430/1000\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 0.0205 - acc: 0.9951 - val_loss: 9.4845 - val_acc: 0.7500\n",
            "Epoch 431/1000\n",
            "39/39 [==============================] - 5s 128ms/step - loss: 0.0062 - acc: 0.9984 - val_loss: 8.8520 - val_acc: 0.7812\n",
            "Epoch 432/1000\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 0.0226 - acc: 0.9918 - val_loss: 11.1259 - val_acc: 0.7396\n",
            "Epoch 433/1000\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 0.0092 - acc: 0.9967 - val_loss: 11.9294 - val_acc: 0.7396\n",
            "Epoch 434/1000\n",
            "39/39 [==============================] - 6s 130ms/step - loss: 0.0175 - acc: 0.9918 - val_loss: 10.9361 - val_acc: 0.7500\n",
            "Epoch 435/1000\n",
            "39/39 [==============================] - 10s 251ms/step - loss: 0.0076 - acc: 0.9984 - val_loss: 9.6394 - val_acc: 0.7604\n",
            "Epoch 436/1000\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 0.0223 - acc: 0.9918 - val_loss: 10.5892 - val_acc: 0.7396\n",
            "Epoch 437/1000\n",
            "39/39 [==============================] - 6s 130ms/step - loss: 0.0614 - acc: 0.9902 - val_loss: 9.1034 - val_acc: 0.7604\n",
            "Epoch 438/1000\n",
            "39/39 [==============================] - 10s 258ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 9.8266 - val_acc: 0.7396\n",
            "Epoch 439/1000\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 0.0291 - acc: 0.9902 - val_loss: 9.6680 - val_acc: 0.7292\n",
            "Epoch 440/1000\n",
            "39/39 [==============================] - 10s 243ms/step - loss: 0.0112 - acc: 0.9951 - val_loss: 9.7693 - val_acc: 0.7292\n",
            "Epoch 441/1000\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 0.0084 - acc: 0.9984 - val_loss: 11.0329 - val_acc: 0.7292\n",
            "Epoch 442/1000\n",
            "39/39 [==============================] - 6s 141ms/step - loss: 0.0322 - acc: 0.9935 - val_loss: 8.6233 - val_acc: 0.7500\n",
            "Epoch 443/1000\n",
            "39/39 [==============================] - 5s 121ms/step - loss: 0.0216 - acc: 0.9967 - val_loss: 7.9999 - val_acc: 0.7396\n",
            "Epoch 444/1000\n",
            "39/39 [==============================] - 5s 120ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 6.9711 - val_acc: 0.7708\n",
            "Epoch 445/1000\n",
            "39/39 [==============================] - 10s 251ms/step - loss: 0.0171 - acc: 0.9951 - val_loss: 9.8835 - val_acc: 0.7188\n",
            "Epoch 446/1000\n",
            "39/39 [==============================] - 5s 119ms/step - loss: 0.0041 - acc: 0.9984 - val_loss: 8.9138 - val_acc: 0.7396\n",
            "Epoch 447/1000\n",
            "39/39 [==============================] - 6s 144ms/step - loss: 0.0037 - acc: 0.9967 - val_loss: 6.2846 - val_acc: 0.7500\n",
            "Epoch 448/1000\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 0.0061 - acc: 0.9984 - val_loss: 7.1089 - val_acc: 0.7396\n",
            "Epoch 449/1000\n",
            "39/39 [==============================] - 5s 119ms/step - loss: 5.3288e-04 - acc: 1.0000 - val_loss: 6.4070 - val_acc: 0.7604\n",
            "Epoch 450/1000\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.0228 - acc: 0.9935 - val_loss: 6.3336 - val_acc: 0.7500\n",
            "Epoch 451/1000\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 0.0225 - acc: 0.9935 - val_loss: 8.2888 - val_acc: 0.7396\n",
            "Epoch 452/1000\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 0.0045 - acc: 0.9984 - val_loss: 7.7420 - val_acc: 0.7292\n",
            "Epoch 453/1000\n",
            "39/39 [==============================] - 6s 139ms/step - loss: 0.0067 - acc: 0.9984 - val_loss: 7.0904 - val_acc: 0.7500\n",
            "Epoch 454/1000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 0.0058 - acc: 0.9967 - val_loss: 6.6703 - val_acc: 0.7708\n",
            "Epoch 455/1000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 0.0309 - acc: 0.9967 - val_loss: 7.6530 - val_acc: 0.7396\n",
            "Epoch 456/1000\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.0113 - acc: 0.9951 - val_loss: 7.3081 - val_acc: 0.7500\n",
            "Epoch 457/1000\n",
            "39/39 [==============================] - 5s 120ms/step - loss: 0.0237 - acc: 0.9918 - val_loss: 6.7496 - val_acc: 0.7500\n",
            "Epoch 458/1000\n",
            "39/39 [==============================] - 6s 146ms/step - loss: 0.0585 - acc: 0.9967 - val_loss: 8.1988 - val_acc: 0.7396\n",
            "Epoch 459/1000\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 2.2215e-04 - acc: 1.0000 - val_loss: 8.4401 - val_acc: 0.7292\n",
            "Epoch 460/1000\n",
            "39/39 [==============================] - 5s 120ms/step - loss: 0.0152 - acc: 0.9967 - val_loss: 7.4676 - val_acc: 0.7500\n",
            "Epoch 461/1000\n",
            "39/39 [==============================] - 6s 130ms/step - loss: 0.0698 - acc: 0.9886 - val_loss: 4.6663 - val_acc: 0.7708\n",
            "Epoch 462/1000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 0.0094 - acc: 0.9951 - val_loss: 4.6412 - val_acc: 0.7500\n",
            "Epoch 463/1000\n",
            "39/39 [==============================] - 10s 260ms/step - loss: 0.0575 - acc: 0.9886 - val_loss: 5.2402 - val_acc: 0.7500\n",
            "Epoch 464/1000\n",
            "39/39 [==============================] - 5s 119ms/step - loss: 0.0113 - acc: 0.9967 - val_loss: 5.0710 - val_acc: 0.7396\n",
            "Epoch 465/1000\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 0.0110 - acc: 0.9951 - val_loss: 6.2001 - val_acc: 0.7396\n",
            "Epoch 466/1000\n",
            "39/39 [==============================] - 10s 258ms/step - loss: 0.0070 - acc: 0.9984 - val_loss: 5.4902 - val_acc: 0.7708\n",
            "Epoch 467/1000\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 5.8356 - val_acc: 0.7396\n",
            "Epoch 468/1000\n",
            "39/39 [==============================] - 6s 126ms/step - loss: 0.0348 - acc: 0.9935 - val_loss: 6.9031 - val_acc: 0.7500\n",
            "Epoch 469/1000\n",
            "39/39 [==============================] - 10s 252ms/step - loss: 0.0066 - acc: 0.9967 - val_loss: 7.2355 - val_acc: 0.7292\n",
            "Epoch 470/1000\n",
            "39/39 [==============================] - 6s 140ms/step - loss: 0.0054 - acc: 0.9984 - val_loss: 7.1679 - val_acc: 0.7396\n",
            "Epoch 471/1000\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.0384 - acc: 0.9886 - val_loss: 5.9925 - val_acc: 0.7396\n",
            "Epoch 472/1000\n",
            "39/39 [==============================] - 6s 141ms/step - loss: 0.0229 - acc: 0.9935 - val_loss: 5.6805 - val_acc: 0.7396\n",
            "Epoch 473/1000\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.0209 - acc: 0.9951 - val_loss: 6.6055 - val_acc: 0.7396\n",
            "Epoch 474/1000\n",
            "39/39 [==============================] - 10s 245ms/step - loss: 0.0124 - acc: 0.9935 - val_loss: 5.1239 - val_acc: 0.7708\n",
            "Epoch 475/1000\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.0181 - acc: 0.9967 - val_loss: 5.0087 - val_acc: 0.7708\n",
            "Epoch 476/1000\n",
            "39/39 [==============================] - 6s 136ms/step - loss: 0.0036 - acc: 0.9984 - val_loss: 6.2006 - val_acc: 0.7396\n",
            "Epoch 477/1000\n",
            "39/39 [==============================] - 10s 244ms/step - loss: 0.0168 - acc: 0.9951 - val_loss: 6.0856 - val_acc: 0.7396\n",
            "Epoch 478/1000\n",
            "39/39 [==============================] - 6s 126ms/step - loss: 0.0022 - acc: 0.9984 - val_loss: 5.2154 - val_acc: 0.7396\n",
            "Epoch 479/1000\n",
            "39/39 [==============================] - 5s 119ms/step - loss: 0.0135 - acc: 0.9967 - val_loss: 5.5543 - val_acc: 0.7396\n",
            "Epoch 480/1000\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 0.0100 - acc: 0.9984 - val_loss: 4.9780 - val_acc: 0.7292\n",
            "Epoch 481/1000\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.0043 - acc: 0.9967 - val_loss: 6.7636 - val_acc: 0.7500\n",
            "Epoch 482/1000\n",
            "39/39 [==============================] - 6s 142ms/step - loss: 0.0088 - acc: 0.9967 - val_loss: 5.3272 - val_acc: 0.7500\n",
            "Epoch 483/1000\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.0390 - acc: 0.9967 - val_loss: 6.0638 - val_acc: 0.7396\n",
            "Epoch 484/1000\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.0047 - acc: 0.9984 - val_loss: 6.0868 - val_acc: 0.7292\n",
            "Epoch 485/1000\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 0.0111 - acc: 0.9984 - val_loss: 6.0223 - val_acc: 0.7292\n",
            "Epoch 486/1000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 0.0094 - acc: 0.9935 - val_loss: 5.3334 - val_acc: 0.7396\n",
            "Epoch 487/1000\n",
            "39/39 [==============================] - 10s 245ms/step - loss: 0.0702 - acc: 0.9967 - val_loss: 6.7576 - val_acc: 0.7396\n",
            "Epoch 488/1000\n",
            "39/39 [==============================] - 5s 122ms/step - loss: 0.0375 - acc: 0.9935 - val_loss: 7.1515 - val_acc: 0.7396\n",
            "Epoch 489/1000\n",
            "39/39 [==============================] - 6s 130ms/step - loss: 0.0097 - acc: 0.9967 - val_loss: 7.8688 - val_acc: 0.7396\n",
            "Epoch 490/1000\n",
            "39/39 [==============================] - 11s 261ms/step - loss: 0.0182 - acc: 0.9951 - val_loss: 8.1190 - val_acc: 0.7604\n",
            "Epoch 491/1000\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.0063 - acc: 0.9984 - val_loss: 8.7074 - val_acc: 0.7500\n",
            "Epoch 492/1000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 0.0154 - acc: 0.9935 - val_loss: 7.9542 - val_acc: 0.7396\n",
            "Epoch 493/1000\n",
            "39/39 [==============================] - 6s 133ms/step - loss: 0.0105 - acc: 0.9967 - val_loss: 8.9745 - val_acc: 0.7500\n",
            "Epoch 494/1000\n",
            "39/39 [==============================] - 10s 257ms/step - loss: 0.0326 - acc: 0.9984 - val_loss: 8.7741 - val_acc: 0.7708\n",
            "Epoch 495/1000\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 0.0043 - acc: 0.9984 - val_loss: 11.9189 - val_acc: 0.7396\n",
            "Epoch 496/1000\n",
            "39/39 [==============================] - 10s 245ms/step - loss: 0.0180 - acc: 0.9951 - val_loss: 9.9882 - val_acc: 0.7604\n",
            "Epoch 497/1000\n",
            "39/39 [==============================] - 10s 245ms/step - loss: 0.0087 - acc: 0.9967 - val_loss: 9.6084 - val_acc: 0.7812\n",
            "Epoch 498/1000\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 0.0214 - acc: 0.9951 - val_loss: 7.2323 - val_acc: 0.7708\n",
            "Epoch 499/1000\n",
            "39/39 [==============================] - 11s 261ms/step - loss: 0.0149 - acc: 0.9984 - val_loss: 7.3840 - val_acc: 0.7708\n",
            "Epoch 500/1000\n",
            "39/39 [==============================] - 10s 252ms/step - loss: 0.0091 - acc: 0.9967 - val_loss: 7.8498 - val_acc: 0.7708\n",
            "Epoch 501/1000\n",
            "39/39 [==============================] - 10s 245ms/step - loss: 0.0045 - acc: 0.9984 - val_loss: 8.2439 - val_acc: 0.7396\n",
            "Epoch 502/1000\n",
            "39/39 [==============================] - 5s 118ms/step - loss: 0.0067 - acc: 0.9984 - val_loss: 7.4235 - val_acc: 0.7604\n",
            "Epoch 503/1000\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.0103 - acc: 0.9935 - val_loss: 8.6316 - val_acc: 0.7396\n",
            "Epoch 504/1000\n",
            "39/39 [==============================] - 10s 244ms/step - loss: 0.0811 - acc: 0.9951 - val_loss: 7.7554 - val_acc: 0.7396\n",
            "Epoch 505/1000\n",
            "39/39 [==============================] - 5s 120ms/step - loss: 0.0192 - acc: 0.9951 - val_loss: 6.1240 - val_acc: 0.7292\n",
            "Epoch 506/1000\n",
            "39/39 [==============================] - 5s 118ms/step - loss: 0.0185 - acc: 0.9984 - val_loss: 5.5941 - val_acc: 0.7708\n",
            "Epoch 507/1000\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.0227 - acc: 0.9935 - val_loss: 6.2745 - val_acc: 0.7396\n",
            "Epoch 508/1000\n",
            "39/39 [==============================] - 10s 257ms/step - loss: 0.0364 - acc: 0.9967 - val_loss: 6.2260 - val_acc: 0.7292\n",
            "Epoch 509/1000\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 0.0066 - acc: 0.9984 - val_loss: 6.3266 - val_acc: 0.7396\n",
            "Epoch 510/1000\n",
            "39/39 [==============================] - 6s 127ms/step - loss: 0.0062 - acc: 0.9984 - val_loss: 6.7959 - val_acc: 0.7500\n",
            "Epoch 511/1000\n",
            "39/39 [==============================] - 11s 265ms/step - loss: 0.0336 - acc: 0.9984 - val_loss: 6.0367 - val_acc: 0.7500\n",
            "Epoch 512/1000\n",
            "39/39 [==============================] - 10s 256ms/step - loss: 0.0271 - acc: 0.9935 - val_loss: 5.6224 - val_acc: 0.7500\n",
            "Epoch 513/1000\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.0569 - acc: 0.9967 - val_loss: 5.7624 - val_acc: 0.7604\n",
            "Epoch 514/1000\n",
            "39/39 [==============================] - 11s 267ms/step - loss: 0.0037 - acc: 0.9984 - val_loss: 7.3607 - val_acc: 0.7500\n",
            "Epoch 515/1000\n",
            "39/39 [==============================] - 6s 152ms/step - loss: 0.0087 - acc: 0.9951 - val_loss: 5.8534 - val_acc: 0.7500\n",
            "Epoch 516/1000\n",
            "39/39 [==============================] - 6s 133ms/step - loss: 0.0136 - acc: 0.9951 - val_loss: 7.6034 - val_acc: 0.7396\n",
            "Epoch 517/1000\n",
            "39/39 [==============================] - 11s 258ms/step - loss: 0.0073 - acc: 0.9951 - val_loss: 5.9423 - val_acc: 0.7500\n",
            "Epoch 518/1000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 0.0141 - acc: 0.9967 - val_loss: 6.3020 - val_acc: 0.7500\n",
            "Epoch 519/1000\n",
            "39/39 [==============================] - 6s 147ms/step - loss: 0.0476 - acc: 0.9951 - val_loss: 5.9005 - val_acc: 0.7292\n",
            "Epoch 520/1000\n",
            "39/39 [==============================] - 6s 128ms/step - loss: 0.0860 - acc: 0.9935 - val_loss: 6.7865 - val_acc: 0.7292\n",
            "Epoch 521/1000\n",
            "39/39 [==============================] - 6s 131ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 5.1863 - val_acc: 0.7396\n",
            "Epoch 522/1000\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 0.0365 - acc: 0.9951 - val_loss: 5.8239 - val_acc: 0.7396\n",
            "Epoch 523/1000\n",
            "39/39 [==============================] - 11s 265ms/step - loss: 0.0097 - acc: 0.9984 - val_loss: 4.8710 - val_acc: 0.7188\n",
            "Epoch 524/1000\n",
            "39/39 [==============================] - 11s 260ms/step - loss: 0.0277 - acc: 0.9935 - val_loss: 6.1693 - val_acc: 0.7500\n",
            "Epoch 525/1000\n",
            "39/39 [==============================] - 10s 256ms/step - loss: 0.0134 - acc: 0.9951 - val_loss: 5.9046 - val_acc: 0.7396\n",
            "Epoch 526/1000\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 0.0096 - acc: 0.9984 - val_loss: 6.4997 - val_acc: 0.7292\n",
            "Epoch 527/1000\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 6.2595 - val_acc: 0.7396\n",
            "Epoch 528/1000\n",
            "39/39 [==============================] - 6s 131ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 5.7567 - val_acc: 0.7188\n",
            "Epoch 529/1000\n",
            "39/39 [==============================] - 5s 120ms/step - loss: 0.0049 - acc: 0.9984 - val_loss: 5.9107 - val_acc: 0.7500\n",
            "Epoch 530/1000\n",
            "39/39 [==============================] - 5s 119ms/step - loss: 0.0072 - acc: 0.9967 - val_loss: 6.0318 - val_acc: 0.7292\n",
            "Epoch 531/1000\n",
            "39/39 [==============================] - 10s 254ms/step - loss: 0.0025 - acc: 0.9984 - val_loss: 6.7763 - val_acc: 0.7292\n",
            "Epoch 532/1000\n",
            "39/39 [==============================] - 6s 130ms/step - loss: 0.0341 - acc: 0.9935 - val_loss: 8.7178 - val_acc: 0.7604\n",
            "Epoch 533/1000\n",
            "39/39 [==============================] - 6s 136ms/step - loss: 0.0099 - acc: 0.9951 - val_loss: 7.8214 - val_acc: 0.7396\n",
            "Epoch 534/1000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 0.0043 - acc: 0.9984 - val_loss: 8.0205 - val_acc: 0.7500\n",
            "Epoch 535/1000\n",
            "39/39 [==============================] - 11s 261ms/step - loss: 0.0031 - acc: 0.9984 - val_loss: 9.5848 - val_acc: 0.7500\n",
            "Epoch 536/1000\n",
            "39/39 [==============================] - 6s 133ms/step - loss: 0.0053 - acc: 0.9967 - val_loss: 7.9552 - val_acc: 0.7708\n",
            "Epoch 537/1000\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.0097 - acc: 0.9984 - val_loss: 8.4524 - val_acc: 0.7500\n",
            "Epoch 538/1000\n",
            "39/39 [==============================] - 6s 140ms/step - loss: 0.0116 - acc: 0.9967 - val_loss: 7.0849 - val_acc: 0.7396\n",
            "Epoch 539/1000\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.0165 - acc: 0.9951 - val_loss: 7.3386 - val_acc: 0.7604\n",
            "Epoch 540/1000\n",
            "39/39 [==============================] - 10s 255ms/step - loss: 0.0135 - acc: 0.9951 - val_loss: 7.5107 - val_acc: 0.7604\n",
            "Epoch 541/1000\n",
            "39/39 [==============================] - 10s 258ms/step - loss: 0.0108 - acc: 0.9951 - val_loss: 6.8257 - val_acc: 0.7500\n",
            "Epoch 542/1000\n",
            "39/39 [==============================] - 6s 131ms/step - loss: 0.0272 - acc: 0.9935 - val_loss: 6.9030 - val_acc: 0.7396\n",
            "Epoch 543/1000\n",
            "39/39 [==============================] - 6s 131ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 6.4264 - val_acc: 0.7500\n",
            "Epoch 544/1000\n",
            "39/39 [==============================] - 6s 133ms/step - loss: 0.0107 - acc: 0.9967 - val_loss: 4.9799 - val_acc: 0.7500\n",
            "Epoch 545/1000\n",
            "39/39 [==============================] - 5s 120ms/step - loss: 0.0198 - acc: 0.9918 - val_loss: 5.4046 - val_acc: 0.7396\n",
            "Epoch 546/1000\n",
            "39/39 [==============================] - 7s 168ms/step - loss: 8.5003e-04 - acc: 1.0000 - val_loss: 4.8792 - val_acc: 0.7500\n",
            "Epoch 547/1000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 0.0151 - acc: 0.9952 - val_loss: 7.2793 - val_acc: 0.7500\n",
            "Epoch 548/1000\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 0.0648 - acc: 0.9951 - val_loss: 7.1204 - val_acc: 0.7500\n",
            "Epoch 549/1000\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 0.0415 - acc: 0.9935 - val_loss: 6.9912 - val_acc: 0.7500\n",
            "Epoch 550/1000\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 0.0255 - acc: 0.9918 - val_loss: 6.3233 - val_acc: 0.7396\n",
            "Epoch 551/1000\n",
            "39/39 [==============================] - 7s 173ms/step - loss: 0.0146 - acc: 0.9984 - val_loss: 5.6058 - val_acc: 0.7500\n",
            "Epoch 552/1000\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.0548 - acc: 0.9951 - val_loss: 5.2440 - val_acc: 0.7396\n",
            "Epoch 553/1000\n",
            "39/39 [==============================] - 10s 244ms/step - loss: 0.0135 - acc: 0.9984 - val_loss: 5.7904 - val_acc: 0.7292\n",
            "Epoch 554/1000\n",
            "39/39 [==============================] - 6s 135ms/step - loss: 0.0251 - acc: 0.9951 - val_loss: 6.3569 - val_acc: 0.7292\n",
            "Epoch 555/1000\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.0262 - acc: 0.9918 - val_loss: 8.6821 - val_acc: 0.7396\n",
            "Epoch 556/1000\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 0.0234 - acc: 0.9951 - val_loss: 8.3861 - val_acc: 0.7500\n",
            "Epoch 557/1000\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 0.0163 - acc: 0.9967 - val_loss: 8.0903 - val_acc: 0.7500\n",
            "Epoch 558/1000\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 0.0197 - acc: 0.9967 - val_loss: 7.6873 - val_acc: 0.7500\n",
            "Epoch 559/1000\n",
            "39/39 [==============================] - 6s 144ms/step - loss: 0.0381 - acc: 0.9935 - val_loss: 5.2125 - val_acc: 0.7500\n",
            "Epoch 560/1000\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.0037 - acc: 0.9967 - val_loss: 6.6048 - val_acc: 0.7708\n",
            "Epoch 561/1000\n",
            "39/39 [==============================] - 10s 244ms/step - loss: 0.0083 - acc: 0.9967 - val_loss: 6.4490 - val_acc: 0.7500\n",
            "Epoch 562/1000\n",
            "39/39 [==============================] - 10s 259ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 6.9713 - val_acc: 0.7396\n",
            "Epoch 563/1000\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 0.0049 - acc: 0.9967 - val_loss: 6.5583 - val_acc: 0.7500\n",
            "Epoch 564/1000\n",
            "39/39 [==============================] - 5s 119ms/step - loss: 0.0065 - acc: 0.9967 - val_loss: 6.8574 - val_acc: 0.7396\n",
            "Epoch 565/1000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 5.9642 - val_acc: 0.7292\n",
            "Epoch 566/1000\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 0.0036 - acc: 0.9984 - val_loss: 6.2191 - val_acc: 0.7500\n",
            "Epoch 567/1000\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.0146 - acc: 0.9951 - val_loss: 5.6330 - val_acc: 0.7396\n",
            "Epoch 568/1000\n",
            "39/39 [==============================] - 10s 257ms/step - loss: 0.0167 - acc: 0.9951 - val_loss: 5.3286 - val_acc: 0.7188\n",
            "Epoch 569/1000\n",
            "39/39 [==============================] - 6s 135ms/step - loss: 0.0279 - acc: 0.9902 - val_loss: 5.7798 - val_acc: 0.7188\n",
            "Epoch 570/1000\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.0023 - acc: 0.9984 - val_loss: 7.2004 - val_acc: 0.7292\n",
            "Epoch 571/1000\n",
            "39/39 [==============================] - 6s 144ms/step - loss: 0.0068 - acc: 0.9984 - val_loss: 5.3149 - val_acc: 0.7604\n",
            "Epoch 572/1000\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 0.0134 - acc: 0.9951 - val_loss: 6.4314 - val_acc: 0.7396\n",
            "Epoch 573/1000\n",
            "39/39 [==============================] - 5s 121ms/step - loss: 0.0109 - acc: 0.9967 - val_loss: 6.4585 - val_acc: 0.7500\n",
            "Epoch 574/1000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 0.0064 - acc: 0.9984 - val_loss: 6.5541 - val_acc: 0.7500\n",
            "Epoch 575/1000\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 0.0213 - acc: 0.9951 - val_loss: 5.6653 - val_acc: 0.7396\n",
            "Epoch 576/1000\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 0.0485 - acc: 0.9951 - val_loss: 5.7631 - val_acc: 0.7396\n",
            "Epoch 577/1000\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.0663 - acc: 0.9935 - val_loss: 5.9723 - val_acc: 0.6667\n",
            "Epoch 578/1000\n",
            "39/39 [==============================] - 10s 257ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 6.4223 - val_acc: 0.6771\n",
            "Epoch 579/1000\n",
            "39/39 [==============================] - 10s 251ms/step - loss: 0.0070 - acc: 0.9951 - val_loss: 6.6879 - val_acc: 0.7292\n",
            "Epoch 580/1000\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 0.0097 - acc: 0.9951 - val_loss: 5.3279 - val_acc: 0.6667\n",
            "Epoch 581/1000\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.0157 - acc: 0.9951 - val_loss: 5.4779 - val_acc: 0.7083\n",
            "Epoch 582/1000\n",
            "39/39 [==============================] - 6s 127ms/step - loss: 0.0041 - acc: 0.9984 - val_loss: 7.1560 - val_acc: 0.7396\n",
            "Epoch 583/1000\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 0.0127 - acc: 0.9967 - val_loss: 6.1811 - val_acc: 0.7188\n",
            "Epoch 584/1000\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.0100 - acc: 0.9984 - val_loss: 6.1028 - val_acc: 0.7188\n",
            "Epoch 585/1000\n",
            "39/39 [==============================] - 5s 120ms/step - loss: 0.0106 - acc: 0.9984 - val_loss: 5.8584 - val_acc: 0.7188\n",
            "Epoch 586/1000\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.0078 - acc: 0.9967 - val_loss: 7.3215 - val_acc: 0.7396\n",
            "Epoch 587/1000\n",
            "39/39 [==============================] - 5s 121ms/step - loss: 0.0182 - acc: 0.9935 - val_loss: 7.9537 - val_acc: 0.7500\n",
            "Epoch 588/1000\n",
            "39/39 [==============================] - 6s 140ms/step - loss: 0.0068 - acc: 0.9967 - val_loss: 8.3297 - val_acc: 0.7292\n",
            "Epoch 589/1000\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.0046 - acc: 0.9967 - val_loss: 8.2006 - val_acc: 0.7396\n",
            "Epoch 590/1000\n",
            "39/39 [==============================] - 10s 255ms/step - loss: 0.0151 - acc: 0.9967 - val_loss: 7.2568 - val_acc: 0.7396\n",
            "Epoch 591/1000\n",
            "39/39 [==============================] - 10s 259ms/step - loss: 0.0098 - acc: 0.9967 - val_loss: 6.4112 - val_acc: 0.7188\n",
            "Epoch 592/1000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 0.0411 - acc: 0.9935 - val_loss: 8.4289 - val_acc: 0.7188\n",
            "Epoch 593/1000\n",
            "39/39 [==============================] - 6s 128ms/step - loss: 0.0651 - acc: 0.9935 - val_loss: 8.2838 - val_acc: 0.7500\n",
            "Epoch 594/1000\n",
            "39/39 [==============================] - 5s 120ms/step - loss: 0.0244 - acc: 0.9951 - val_loss: 7.1507 - val_acc: 0.6771\n",
            "Epoch 595/1000\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 7.0565 - val_acc: 0.6667\n",
            "Epoch 596/1000\n",
            "39/39 [==============================] - 6s 131ms/step - loss: 0.0113 - acc: 0.9967 - val_loss: 6.3951 - val_acc: 0.6771\n",
            "Epoch 597/1000\n",
            "39/39 [==============================] - 5s 121ms/step - loss: 0.0095 - acc: 0.9967 - val_loss: 5.0655 - val_acc: 0.6771\n",
            "Epoch 598/1000\n",
            "39/39 [==============================] - 6s 146ms/step - loss: 0.0018 - acc: 0.9984 - val_loss: 4.8747 - val_acc: 0.6771\n",
            "Epoch 599/1000\n",
            "39/39 [==============================] - 5s 122ms/step - loss: 0.0127 - acc: 0.9967 - val_loss: 5.1143 - val_acc: 0.6875\n",
            "Epoch 600/1000\n",
            "39/39 [==============================] - 6s 133ms/step - loss: 0.0420 - acc: 0.9902 - val_loss: 5.5347 - val_acc: 0.7604\n",
            "Epoch 601/1000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 0.0055 - acc: 0.9967 - val_loss: 5.8884 - val_acc: 0.7292\n",
            "Epoch 602/1000\n",
            "39/39 [==============================] - 6s 130ms/step - loss: 0.0082 - acc: 0.9951 - val_loss: 6.1294 - val_acc: 0.7396\n",
            "Epoch 603/1000\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 5.4287 - val_acc: 0.7396\n",
            "Epoch 604/1000\n",
            "39/39 [==============================] - 6s 153ms/step - loss: 0.0427 - acc: 0.9935 - val_loss: 5.7770 - val_acc: 0.6979\n",
            "Epoch 605/1000\n",
            "39/39 [==============================] - 5s 118ms/step - loss: 0.0164 - acc: 0.9967 - val_loss: 6.5416 - val_acc: 0.7500\n",
            "Epoch 606/1000\n",
            "39/39 [==============================] - 6s 139ms/step - loss: 0.0394 - acc: 0.9918 - val_loss: 8.5058 - val_acc: 0.7188\n",
            "Epoch 607/1000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 0.0077 - acc: 0.9967 - val_loss: 7.8053 - val_acc: 0.7188\n",
            "Epoch 608/1000\n",
            "39/39 [==============================] - 6s 142ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 8.5094 - val_acc: 0.7396\n",
            "Epoch 609/1000\n",
            "39/39 [==============================] - 10s 252ms/step - loss: 0.0154 - acc: 0.9918 - val_loss: 7.9878 - val_acc: 0.7188\n",
            "Epoch 610/1000\n",
            "39/39 [==============================] - 6s 135ms/step - loss: 0.0042 - acc: 0.9984 - val_loss: 7.4608 - val_acc: 0.7083\n",
            "Epoch 611/1000\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.2014 - val_acc: 0.7500\n",
            "Epoch 612/1000\n",
            "39/39 [==============================] - 6s 137ms/step - loss: 0.0258 - acc: 0.9935 - val_loss: 7.5261 - val_acc: 0.7604\n",
            "Epoch 613/1000\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.0074 - acc: 0.9967 - val_loss: 10.0803 - val_acc: 0.7604\n",
            "Epoch 614/1000\n",
            "39/39 [==============================] - 6s 131ms/step - loss: 0.0166 - acc: 0.9967 - val_loss: 10.6122 - val_acc: 0.7292\n",
            "Epoch 615/1000\n",
            "39/39 [==============================] - 5s 122ms/step - loss: 0.0069 - acc: 0.9984 - val_loss: 9.8134 - val_acc: 0.7500\n",
            "Epoch 616/1000\n",
            "39/39 [==============================] - 6s 136ms/step - loss: 0.0034 - acc: 0.9984 - val_loss: 10.4361 - val_acc: 0.7500\n",
            "Epoch 617/1000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 0.0063 - acc: 0.9984 - val_loss: 8.9001 - val_acc: 0.7500\n",
            "Epoch 618/1000\n",
            "39/39 [==============================] - 10s 252ms/step - loss: 0.0171 - acc: 0.9951 - val_loss: 8.6071 - val_acc: 0.7500\n",
            "Epoch 619/1000\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.0502 - acc: 0.9951 - val_loss: 8.1457 - val_acc: 0.7396\n",
            "Epoch 620/1000\n",
            "39/39 [==============================] - 5s 121ms/step - loss: 0.0177 - acc: 0.9984 - val_loss: 9.6311 - val_acc: 0.7500\n",
            "Epoch 621/1000\n",
            "39/39 [==============================] - 11s 261ms/step - loss: 0.0066 - acc: 0.9968 - val_loss: 8.6473 - val_acc: 0.7500\n",
            "Epoch 622/1000\n",
            "39/39 [==============================] - 6s 135ms/step - loss: 0.0054 - acc: 0.9984 - val_loss: 10.3140 - val_acc: 0.7396\n",
            "Epoch 623/1000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 0.0035 - acc: 0.9984 - val_loss: 7.1124 - val_acc: 0.7500\n",
            "Epoch 624/1000\n",
            "39/39 [==============================] - 6s 139ms/step - loss: 0.0069 - acc: 0.9984 - val_loss: 7.7633 - val_acc: 0.7396\n",
            "Epoch 625/1000\n",
            "39/39 [==============================] - 6s 148ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 7.9275 - val_acc: 0.7500\n",
            "Epoch 626/1000\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 0.0051 - acc: 0.9951 - val_loss: 8.9728 - val_acc: 0.7396\n",
            "Epoch 627/1000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 9.9528e-04 - acc: 1.0000 - val_loss: 6.7783 - val_acc: 0.7604\n",
            "Epoch 628/1000\n",
            "39/39 [==============================] - 5s 121ms/step - loss: 0.0164 - acc: 0.9951 - val_loss: 7.5402 - val_acc: 0.7500\n",
            "Epoch 629/1000\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 0.0119 - acc: 0.9951 - val_loss: 8.0801 - val_acc: 0.7500\n",
            "Epoch 630/1000\n",
            "39/39 [==============================] - 6s 145ms/step - loss: 0.0149 - acc: 0.9918 - val_loss: 8.2073 - val_acc: 0.7604\n",
            "Epoch 631/1000\n",
            "39/39 [==============================] - 5s 120ms/step - loss: 0.0052 - acc: 0.9984 - val_loss: 8.6570 - val_acc: 0.7604\n",
            "Epoch 632/1000\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 7.1655 - val_acc: 0.7396\n",
            "Epoch 633/1000\n",
            "39/39 [==============================] - 6s 141ms/step - loss: 0.0018 - acc: 0.9984 - val_loss: 6.8592 - val_acc: 0.7604\n",
            "Epoch 634/1000\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 4.7565e-04 - acc: 1.0000 - val_loss: 7.4309 - val_acc: 0.7292\n",
            "Epoch 635/1000\n",
            "39/39 [==============================] - 6s 130ms/step - loss: 0.0033 - acc: 0.9984 - val_loss: 6.6406 - val_acc: 0.7188\n",
            "Epoch 636/1000\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 5.3380e-04 - acc: 1.0000 - val_loss: 6.3447 - val_acc: 0.7500\n",
            "Epoch 637/1000\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 0.0029 - acc: 0.9984 - val_loss: 6.3549 - val_acc: 0.7396\n",
            "Epoch 638/1000\n",
            "39/39 [==============================] - 6s 145ms/step - loss: 0.0094 - acc: 0.9951 - val_loss: 7.4043 - val_acc: 0.7500\n",
            "Epoch 639/1000\n",
            "39/39 [==============================] - 5s 121ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 7.6982 - val_acc: 0.7396\n",
            "Epoch 640/1000\n",
            "39/39 [==============================] - 10s 255ms/step - loss: 0.0017 - acc: 0.9984 - val_loss: 6.2960 - val_acc: 0.7708\n",
            "Epoch 641/1000\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.0049 - acc: 0.9951 - val_loss: 6.5400 - val_acc: 0.7604\n",
            "Epoch 642/1000\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.0193 - acc: 0.9951 - val_loss: 9.7853 - val_acc: 0.7500\n",
            "Epoch 643/1000\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 2.3612e-04 - acc: 1.0000 - val_loss: 7.9869 - val_acc: 0.7708\n",
            "Epoch 644/1000\n",
            "39/39 [==============================] - 6s 136ms/step - loss: 0.0049 - acc: 0.9967 - val_loss: 8.6415 - val_acc: 0.7292\n",
            "Epoch 645/1000\n",
            "39/39 [==============================] - 6s 128ms/step - loss: 0.0036 - acc: 0.9984 - val_loss: 8.9960 - val_acc: 0.7396\n",
            "Epoch 646/1000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 0.0151 - acc: 0.9967 - val_loss: 8.2841 - val_acc: 0.7500\n",
            "Epoch 647/1000\n",
            "39/39 [==============================] - 6s 136ms/step - loss: 0.0036 - acc: 0.9984 - val_loss: 7.4204 - val_acc: 0.7396\n",
            "Epoch 648/1000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 0.0096 - acc: 0.9967 - val_loss: 8.8022 - val_acc: 0.7604\n",
            "Epoch 649/1000\n",
            "39/39 [==============================] - 11s 262ms/step - loss: 0.0050 - acc: 0.9967 - val_loss: 10.0915 - val_acc: 0.7500\n",
            "Epoch 650/1000\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.0207 - acc: 0.9984 - val_loss: 11.2235 - val_acc: 0.7500\n",
            "Epoch 651/1000\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 0.0073 - acc: 0.9984 - val_loss: 10.3918 - val_acc: 0.7188\n",
            "Epoch 652/1000\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 9.9543e-04 - acc: 1.0000 - val_loss: 9.4191 - val_acc: 0.7396\n",
            "Epoch 653/1000\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.0043 - acc: 0.9967 - val_loss: 8.4144 - val_acc: 0.7292\n",
            "Epoch 654/1000\n",
            "39/39 [==============================] - 11s 268ms/step - loss: 0.0196 - acc: 0.9967 - val_loss: 7.6500 - val_acc: 0.7396\n",
            "Epoch 655/1000\n",
            "39/39 [==============================] - 6s 139ms/step - loss: 0.0830 - acc: 0.9902 - val_loss: 8.7174 - val_acc: 0.7083\n",
            "Epoch 656/1000\n",
            "39/39 [==============================] - 5s 121ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 8.3374 - val_acc: 0.7188\n",
            "Epoch 657/1000\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.0077 - acc: 0.9984 - val_loss: 7.2733 - val_acc: 0.7500\n",
            "Epoch 658/1000\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.0049 - acc: 0.9984 - val_loss: 8.7609 - val_acc: 0.7708\n",
            "Epoch 659/1000\n",
            "39/39 [==============================] - 5s 120ms/step - loss: 7.8407e-04 - acc: 1.0000 - val_loss: 9.0036 - val_acc: 0.7708\n",
            "Epoch 660/1000\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 8.4427 - val_acc: 0.7396\n",
            "Epoch 661/1000\n",
            "39/39 [==============================] - 5s 122ms/step - loss: 0.0173 - acc: 0.9984 - val_loss: 9.6089 - val_acc: 0.7500\n",
            "Epoch 662/1000\n",
            "39/39 [==============================] - 11s 260ms/step - loss: 0.0049 - acc: 0.9967 - val_loss: 7.5128 - val_acc: 0.7500\n",
            "Epoch 663/1000\n",
            "39/39 [==============================] - 7s 169ms/step - loss: 0.0218 - acc: 0.9967 - val_loss: 10.4269 - val_acc: 0.7396\n",
            "Epoch 664/1000\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 4.8873e-04 - acc: 1.0000 - val_loss: 8.5532 - val_acc: 0.7604\n",
            "Epoch 665/1000\n",
            "39/39 [==============================] - 6s 136ms/step - loss: 0.0068 - acc: 0.9967 - val_loss: 8.1109 - val_acc: 0.7500\n",
            "Epoch 666/1000\n",
            "39/39 [==============================] - 6s 143ms/step - loss: 0.0225 - acc: 0.9984 - val_loss: 6.8891 - val_acc: 0.7708\n",
            "Epoch 667/1000\n",
            "39/39 [==============================] - 6s 131ms/step - loss: 0.0124 - acc: 0.9967 - val_loss: 7.1385 - val_acc: 0.7500\n",
            "Epoch 668/1000\n",
            "39/39 [==============================] - 6s 131ms/step - loss: 0.0039 - acc: 0.9984 - val_loss: 10.8101 - val_acc: 0.7500\n",
            "Epoch 669/1000\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.0052 - acc: 0.9984 - val_loss: 8.0911 - val_acc: 0.7188\n",
            "Epoch 670/1000\n",
            "39/39 [==============================] - 11s 260ms/step - loss: 0.0054 - acc: 0.9967 - val_loss: 8.1263 - val_acc: 0.7396\n",
            "Epoch 671/1000\n",
            "39/39 [==============================] - 6s 140ms/step - loss: 0.0039 - acc: 0.9984 - val_loss: 6.9965 - val_acc: 0.7396\n",
            "Epoch 672/1000\n",
            "39/39 [==============================] - 10s 245ms/step - loss: 0.0073 - acc: 0.9984 - val_loss: 8.2831 - val_acc: 0.7396\n",
            "Epoch 673/1000\n",
            "39/39 [==============================] - 11s 263ms/step - loss: 0.0133 - acc: 0.9984 - val_loss: 8.6705 - val_acc: 0.7396\n",
            "Epoch 674/1000\n",
            "39/39 [==============================] - 10s 254ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 7.7558 - val_acc: 0.7604\n",
            "Epoch 675/1000\n",
            "39/39 [==============================] - 6s 131ms/step - loss: 0.0047 - acc: 0.9984 - val_loss: 9.0660 - val_acc: 0.7292\n",
            "Epoch 676/1000\n",
            "39/39 [==============================] - 11s 263ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 7.9536 - val_acc: 0.7396\n",
            "Epoch 677/1000\n",
            "39/39 [==============================] - 6s 129ms/step - loss: 0.0343 - acc: 0.9967 - val_loss: 8.7080 - val_acc: 0.7500\n",
            "Epoch 678/1000\n",
            "39/39 [==============================] - 5s 119ms/step - loss: 0.0035 - acc: 0.9984 - val_loss: 9.3504 - val_acc: 0.7604\n",
            "Epoch 679/1000\n",
            "39/39 [==============================] - 11s 259ms/step - loss: 0.0203 - acc: 0.9951 - val_loss: 7.4594 - val_acc: 0.7500\n",
            "Epoch 680/1000\n",
            "39/39 [==============================] - 10s 255ms/step - loss: 0.0048 - acc: 0.9967 - val_loss: 7.9605 - val_acc: 0.7500\n",
            "Epoch 681/1000\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 0.0246 - acc: 0.9918 - val_loss: 10.3077 - val_acc: 0.7396\n",
            "Epoch 682/1000\n",
            "39/39 [==============================] - 11s 264ms/step - loss: 0.0083 - acc: 0.9967 - val_loss: 8.5489 - val_acc: 0.7500\n",
            "Epoch 683/1000\n",
            "39/39 [==============================] - 6s 135ms/step - loss: 0.0023 - acc: 0.9984 - val_loss: 7.8230 - val_acc: 0.7708\n",
            "Epoch 684/1000\n",
            "39/39 [==============================] - 10s 254ms/step - loss: 0.0196 - acc: 0.9967 - val_loss: 9.5762 - val_acc: 0.7396\n",
            "Epoch 685/1000\n",
            "39/39 [==============================] - 7s 165ms/step - loss: 0.0371 - acc: 0.9951 - val_loss: 7.5125 - val_acc: 0.7396\n",
            "Epoch 686/1000\n",
            "39/39 [==============================] - 6s 133ms/step - loss: 0.0107 - acc: 0.9967 - val_loss: 6.6411 - val_acc: 0.7604\n",
            "Epoch 687/1000\n",
            "39/39 [==============================] - 5s 122ms/step - loss: 0.0172 - acc: 0.9951 - val_loss: 6.4897 - val_acc: 0.7292\n",
            "Epoch 688/1000\n",
            "39/39 [==============================] - 10s 257ms/step - loss: 0.0128 - acc: 0.9967 - val_loss: 6.9198 - val_acc: 0.7292\n",
            "Epoch 689/1000\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 8.1041 - val_acc: 0.7396\n",
            "Epoch 690/1000\n",
            "39/39 [==============================] - 5s 122ms/step - loss: 0.0247 - acc: 0.9951 - val_loss: 6.3401 - val_acc: 0.7292\n",
            "Epoch 691/1000\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 0.0027 - acc: 0.9984 - val_loss: 5.4204 - val_acc: 0.7500\n",
            "Epoch 692/1000\n",
            "39/39 [==============================] - 6s 130ms/step - loss: 0.0074 - acc: 0.9951 - val_loss: 6.9714 - val_acc: 0.7396\n",
            "Epoch 693/1000\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 0.0062 - acc: 0.9967 - val_loss: 7.0672 - val_acc: 0.7604\n",
            "Epoch 694/1000\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 0.0058 - acc: 0.9967 - val_loss: 6.8887 - val_acc: 0.7500\n",
            "Epoch 695/1000\n",
            "39/39 [==============================] - 10s 252ms/step - loss: 0.0068 - acc: 0.9967 - val_loss: 8.3454 - val_acc: 0.7604\n",
            "Epoch 696/1000\n",
            "39/39 [==============================] - 11s 261ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 8.5334 - val_acc: 0.7500\n",
            "Epoch 697/1000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 0.0117 - acc: 0.9951 - val_loss: 9.0848 - val_acc: 0.7604\n",
            "Epoch 698/1000\n",
            "39/39 [==============================] - 5s 121ms/step - loss: 0.0104 - acc: 0.9984 - val_loss: 8.3900 - val_acc: 0.7292\n",
            "Epoch 699/1000\n",
            "39/39 [==============================] - 6s 131ms/step - loss: 0.0119 - acc: 0.9984 - val_loss: 8.9971 - val_acc: 0.7292\n",
            "Epoch 700/1000\n",
            "39/39 [==============================] - 6s 143ms/step - loss: 0.0210 - acc: 0.9967 - val_loss: 8.6746 - val_acc: 0.7500\n",
            "Epoch 701/1000\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 9.2183 - val_acc: 0.7396\n",
            "Epoch 702/1000\n",
            "39/39 [==============================] - 10s 255ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 8.3141 - val_acc: 0.7396\n",
            "Epoch 703/1000\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.0036 - acc: 0.9984 - val_loss: 8.9951 - val_acc: 0.7292\n",
            "Epoch 704/1000\n",
            "39/39 [==============================] - 6s 148ms/step - loss: 0.0208 - acc: 0.9935 - val_loss: 8.9938 - val_acc: 0.7500\n",
            "Epoch 705/1000\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 2.1033e-04 - acc: 1.0000 - val_loss: 9.2095 - val_acc: 0.7396\n",
            "Epoch 706/1000\n",
            "39/39 [==============================] - 5s 119ms/step - loss: 0.0152 - acc: 0.9984 - val_loss: 10.7270 - val_acc: 0.7500\n",
            "Epoch 707/1000\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 0.0034 - acc: 0.9984 - val_loss: 7.6243 - val_acc: 0.7500\n",
            "Epoch 708/1000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 0.0368 - acc: 0.9935 - val_loss: 9.9059 - val_acc: 0.7292\n",
            "Epoch 709/1000\n",
            "39/39 [==============================] - 6s 143ms/step - loss: 0.0014 - acc: 0.9984 - val_loss: 10.5224 - val_acc: 0.7188\n",
            "Epoch 710/1000\n",
            "39/39 [==============================] - 5s 121ms/step - loss: 0.0366 - acc: 0.9951 - val_loss: 9.3058 - val_acc: 0.7188\n",
            "Epoch 711/1000\n",
            "39/39 [==============================] - 10s 262ms/step - loss: 3.0446e-04 - acc: 1.0000 - val_loss: 8.8304 - val_acc: 0.7396\n",
            "Epoch 712/1000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 0.0163 - acc: 0.9984 - val_loss: 8.0943 - val_acc: 0.7396\n",
            "Epoch 713/1000\n",
            "39/39 [==============================] - 11s 260ms/step - loss: 7.0788e-04 - acc: 1.0000 - val_loss: 7.3032 - val_acc: 0.7188\n",
            "Epoch 714/1000\n",
            "39/39 [==============================] - 10s 257ms/step - loss: 0.0184 - acc: 0.9967 - val_loss: 7.6790 - val_acc: 0.7292\n",
            "Epoch 715/1000\n",
            "39/39 [==============================] - 5s 121ms/step - loss: 7.3182e-04 - acc: 1.0000 - val_loss: 7.4846 - val_acc: 0.7292\n",
            "Epoch 716/1000\n",
            "39/39 [==============================] - 6s 137ms/step - loss: 0.0365 - acc: 0.9935 - val_loss: 7.1569 - val_acc: 0.7292\n",
            "Epoch 717/1000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 0.0205 - acc: 0.9951 - val_loss: 6.9194 - val_acc: 0.7292\n",
            "Epoch 718/1000\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.0078 - acc: 0.9984 - val_loss: 7.3488 - val_acc: 0.7188\n",
            "Epoch 719/1000\n",
            "39/39 [==============================] - 10s 256ms/step - loss: 0.0045 - acc: 0.9984 - val_loss: 7.9074 - val_acc: 0.7188\n",
            "Epoch 720/1000\n",
            "39/39 [==============================] - 6s 135ms/step - loss: 0.0176 - acc: 0.9984 - val_loss: 8.3744 - val_acc: 0.7396\n",
            "Epoch 721/1000\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 0.0420 - acc: 0.9951 - val_loss: 8.9314 - val_acc: 0.7396\n",
            "Epoch 722/1000\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 8.8932 - val_acc: 0.7396\n",
            "Epoch 723/1000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 0.0133 - acc: 0.9984 - val_loss: 7.9562 - val_acc: 0.7396\n",
            "Epoch 724/1000\n",
            "39/39 [==============================] - 6s 124ms/step - loss: 0.0072 - acc: 0.9984 - val_loss: 7.3460 - val_acc: 0.7500\n",
            "Epoch 725/1000\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.0310 - acc: 0.9935 - val_loss: 7.6552 - val_acc: 0.7396\n",
            "Epoch 726/1000\n",
            "39/39 [==============================] - 6s 136ms/step - loss: 0.0045 - acc: 0.9967 - val_loss: 8.4660 - val_acc: 0.7396\n",
            "Epoch 727/1000\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 0.0048 - acc: 0.9984 - val_loss: 8.1174 - val_acc: 0.7396\n",
            "Epoch 728/1000\n",
            "39/39 [==============================] - 6s 137ms/step - loss: 0.0418 - acc: 0.9935 - val_loss: 7.2631 - val_acc: 0.7708\n",
            "Epoch 729/1000\n",
            "39/39 [==============================] - 5s 122ms/step - loss: 0.0029 - acc: 0.9984 - val_loss: 8.5178 - val_acc: 0.7396\n",
            "Epoch 730/1000\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.0057 - acc: 0.9984 - val_loss: 9.5141 - val_acc: 0.7500\n",
            "Epoch 731/1000\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.0046 - acc: 0.9967 - val_loss: 9.1711 - val_acc: 0.7396\n",
            "Epoch 732/1000\n",
            "39/39 [==============================] - 6s 131ms/step - loss: 0.0021 - acc: 0.9984 - val_loss: 8.4106 - val_acc: 0.7500\n",
            "Epoch 733/1000\n",
            "39/39 [==============================] - 6s 131ms/step - loss: 0.0175 - acc: 0.9951 - val_loss: 7.6506 - val_acc: 0.7396\n",
            "Epoch 734/1000\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.0532 - acc: 0.9886 - val_loss: 10.8080 - val_acc: 0.7500\n",
            "Epoch 735/1000\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.0054 - acc: 0.9984 - val_loss: 9.9514 - val_acc: 0.7500\n",
            "Epoch 736/1000\n",
            "39/39 [==============================] - 5s 122ms/step - loss: 0.0527 - acc: 0.9918 - val_loss: 8.8108 - val_acc: 0.7500\n",
            "Epoch 737/1000\n",
            "39/39 [==============================] - 6s 133ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 8.0975 - val_acc: 0.7604\n",
            "Epoch 738/1000\n",
            "39/39 [==============================] - 10s 254ms/step - loss: 0.0088 - acc: 0.9967 - val_loss: 8.2438 - val_acc: 0.7396\n",
            "Epoch 739/1000\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 7.1541 - val_acc: 0.7708\n",
            "Epoch 740/1000\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 0.0247 - acc: 0.9967 - val_loss: 7.6802 - val_acc: 0.7396\n",
            "Epoch 741/1000\n",
            "39/39 [==============================] - 11s 260ms/step - loss: 0.0098 - acc: 0.9967 - val_loss: 7.3500 - val_acc: 0.7604\n",
            "Epoch 742/1000\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 0.0448 - acc: 0.9968 - val_loss: 7.4305 - val_acc: 0.7604\n",
            "Epoch 743/1000\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 0.0042 - acc: 0.9984 - val_loss: 6.6219 - val_acc: 0.7500\n",
            "Epoch 744/1000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 0.0047 - acc: 0.9984 - val_loss: 5.9476 - val_acc: 0.7604\n",
            "Epoch 745/1000\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.0090 - acc: 0.9984 - val_loss: 7.4026 - val_acc: 0.7396\n",
            "Epoch 746/1000\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.0396 - acc: 0.9967 - val_loss: 7.4021 - val_acc: 0.7396\n",
            "Epoch 747/1000\n",
            "39/39 [==============================] - 5s 119ms/step - loss: 0.0113 - acc: 0.9967 - val_loss: 7.3562 - val_acc: 0.7396\n",
            "Epoch 748/1000\n",
            "39/39 [==============================] - 6s 142ms/step - loss: 0.0125 - acc: 0.9984 - val_loss: 7.6555 - val_acc: 0.7500\n",
            "Epoch 749/1000\n",
            "39/39 [==============================] - 6s 130ms/step - loss: 0.0040 - acc: 0.9984 - val_loss: 7.6401 - val_acc: 0.7500\n",
            "Epoch 750/1000\n",
            "39/39 [==============================] - 10s 256ms/step - loss: 0.0171 - acc: 0.9935 - val_loss: 7.7050 - val_acc: 0.7396\n",
            "Epoch 751/1000\n",
            "39/39 [==============================] - 6s 129ms/step - loss: 0.0072 - acc: 0.9984 - val_loss: 7.7662 - val_acc: 0.7604\n",
            "Epoch 752/1000\n",
            "39/39 [==============================] - 6s 133ms/step - loss: 0.0062 - acc: 0.9967 - val_loss: 7.2897 - val_acc: 0.7500\n",
            "Epoch 753/1000\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 0.0117 - acc: 0.9984 - val_loss: 9.5332 - val_acc: 0.7396\n",
            "Epoch 754/1000\n",
            "39/39 [==============================] - 5s 120ms/step - loss: 6.9824e-04 - acc: 1.0000 - val_loss: 10.0927 - val_acc: 0.7396\n",
            "Epoch 755/1000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 0.0140 - acc: 0.9951 - val_loss: 7.0169 - val_acc: 0.7396\n",
            "Epoch 756/1000\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.0207 - acc: 0.9951 - val_loss: 6.5853 - val_acc: 0.7292\n",
            "Epoch 757/1000\n",
            "39/39 [==============================] - 6s 133ms/step - loss: 0.0231 - acc: 0.9951 - val_loss: 6.7864 - val_acc: 0.7396\n",
            "Epoch 758/1000\n",
            "39/39 [==============================] - 6s 147ms/step - loss: 0.0040 - acc: 0.9967 - val_loss: 8.5389 - val_acc: 0.7292\n",
            "Epoch 759/1000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 6.6935e-04 - acc: 1.0000 - val_loss: 8.2425 - val_acc: 0.7500\n",
            "Epoch 760/1000\n",
            "39/39 [==============================] - 10s 257ms/step - loss: 0.0235 - acc: 0.9967 - val_loss: 8.1378 - val_acc: 0.7500\n",
            "Epoch 761/1000\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 0.0056 - acc: 0.9984 - val_loss: 8.9480 - val_acc: 0.7396\n",
            "Epoch 762/1000\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.0170 - acc: 0.9967 - val_loss: 9.2082 - val_acc: 0.6979\n",
            "Epoch 763/1000\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.0073 - acc: 0.9967 - val_loss: 10.2441 - val_acc: 0.7500\n",
            "Epoch 764/1000\n",
            "39/39 [==============================] - 10s 252ms/step - loss: 0.0074 - acc: 0.9984 - val_loss: 8.5223 - val_acc: 0.7292\n",
            "Epoch 765/1000\n",
            "39/39 [==============================] - 6s 133ms/step - loss: 0.0240 - acc: 0.9967 - val_loss: 8.7530 - val_acc: 0.7292\n",
            "Epoch 766/1000\n",
            "39/39 [==============================] - 10s 254ms/step - loss: 0.0054 - acc: 0.9951 - val_loss: 9.8463 - val_acc: 0.7500\n",
            "Epoch 767/1000\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 0.0096 - acc: 0.9967 - val_loss: 10.9560 - val_acc: 0.7396\n",
            "Epoch 768/1000\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.0075 - acc: 0.9967 - val_loss: 8.5119 - val_acc: 0.7396\n",
            "Epoch 769/1000\n",
            "39/39 [==============================] - 6s 142ms/step - loss: 0.0204 - acc: 0.9935 - val_loss: 8.5608 - val_acc: 0.7812\n",
            "Epoch 770/1000\n",
            "39/39 [==============================] - 6s 135ms/step - loss: 0.0050 - acc: 0.9967 - val_loss: 9.2546 - val_acc: 0.7396\n",
            "Epoch 771/1000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 0.0076 - acc: 0.9967 - val_loss: 8.5911 - val_acc: 0.7083\n",
            "Epoch 772/1000\n",
            "39/39 [==============================] - 11s 267ms/step - loss: 0.0049 - acc: 0.9984 - val_loss: 9.7957 - val_acc: 0.7812\n",
            "Epoch 773/1000\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 0.0161 - acc: 0.9984 - val_loss: 10.3694 - val_acc: 0.7604\n",
            "Epoch 774/1000\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 0.0412 - acc: 0.9951 - val_loss: 9.9038 - val_acc: 0.7708\n",
            "Epoch 775/1000\n",
            "39/39 [==============================] - 11s 258ms/step - loss: 0.0328 - acc: 0.9967 - val_loss: 9.7441 - val_acc: 0.7500\n",
            "Epoch 776/1000\n",
            "39/39 [==============================] - 10s 252ms/step - loss: 0.0016 - acc: 0.9984 - val_loss: 10.3630 - val_acc: 0.7500\n",
            "Epoch 777/1000\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 0.0179 - acc: 0.9967 - val_loss: 9.5822 - val_acc: 0.7708\n",
            "Epoch 778/1000\n",
            "39/39 [==============================] - 10s 260ms/step - loss: 0.0307 - acc: 0.9951 - val_loss: 10.2510 - val_acc: 0.7292\n",
            "Epoch 779/1000\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.0040 - acc: 0.9967 - val_loss: 9.2917 - val_acc: 0.7604\n",
            "Epoch 780/1000\n",
            "39/39 [==============================] - 5s 121ms/step - loss: 0.0161 - acc: 0.9951 - val_loss: 9.8911 - val_acc: 0.6875\n",
            "Epoch 781/1000\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 8.5715e-04 - acc: 1.0000 - val_loss: 9.2762 - val_acc: 0.7083\n",
            "Epoch 782/1000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 4.3245e-04 - acc: 1.0000 - val_loss: 9.4213 - val_acc: 0.7292\n",
            "Epoch 783/1000\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.0256 - acc: 0.9951 - val_loss: 9.2293 - val_acc: 0.7188\n",
            "Epoch 784/1000\n",
            "39/39 [==============================] - 5s 120ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 9.2604 - val_acc: 0.7292\n",
            "Epoch 785/1000\n",
            "39/39 [==============================] - 6s 144ms/step - loss: 0.0025 - acc: 0.9984 - val_loss: 9.3217 - val_acc: 0.7396\n",
            "Epoch 786/1000\n",
            "39/39 [==============================] - 5s 121ms/step - loss: 0.0052 - acc: 0.9967 - val_loss: 8.4161 - val_acc: 0.7500\n",
            "Epoch 787/1000\n",
            "39/39 [==============================] - 10s 256ms/step - loss: 0.0075 - acc: 0.9967 - val_loss: 9.5996 - val_acc: 0.7292\n",
            "Epoch 788/1000\n",
            "39/39 [==============================] - 6s 131ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 9.5103 - val_acc: 0.7396\n",
            "Epoch 789/1000\n",
            "39/39 [==============================] - 6s 135ms/step - loss: 0.0068 - acc: 0.9967 - val_loss: 8.5826 - val_acc: 0.7500\n",
            "Epoch 790/1000\n",
            "39/39 [==============================] - 6s 129ms/step - loss: 0.0061 - acc: 0.9984 - val_loss: 8.5917 - val_acc: 0.7396\n",
            "Epoch 791/1000\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.0054 - acc: 0.9984 - val_loss: 8.0847 - val_acc: 0.7292\n",
            "Epoch 792/1000\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.0113 - acc: 0.9984 - val_loss: 6.7733 - val_acc: 0.7500\n",
            "Epoch 793/1000\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 7.3403e-04 - acc: 1.0000 - val_loss: 7.3524 - val_acc: 0.7292\n",
            "Epoch 794/1000\n",
            "39/39 [==============================] - 11s 265ms/step - loss: 0.0224 - acc: 0.9967 - val_loss: 6.3301 - val_acc: 0.7604\n",
            "Epoch 795/1000\n",
            "39/39 [==============================] - 10s 256ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 7.2855 - val_acc: 0.7708\n",
            "Epoch 796/1000\n",
            "39/39 [==============================] - 6s 133ms/step - loss: 7.3213e-04 - acc: 1.0000 - val_loss: 10.0997 - val_acc: 0.7396\n",
            "Epoch 797/1000\n",
            "39/39 [==============================] - 6s 147ms/step - loss: 0.0047 - acc: 0.9984 - val_loss: 9.6308 - val_acc: 0.7292\n",
            "Epoch 798/1000\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.0096 - acc: 0.9984 - val_loss: 8.6838 - val_acc: 0.7396\n",
            "Epoch 799/1000\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 0.0223 - acc: 0.9951 - val_loss: 8.9356 - val_acc: 0.7292\n",
            "Epoch 800/1000\n",
            "39/39 [==============================] - 6s 135ms/step - loss: 0.0028 - acc: 0.9984 - val_loss: 7.3296 - val_acc: 0.7292\n",
            "Epoch 801/1000\n",
            "39/39 [==============================] - 10s 252ms/step - loss: 5.6750e-04 - acc: 1.0000 - val_loss: 7.4779 - val_acc: 0.7500\n",
            "Epoch 802/1000\n",
            "39/39 [==============================] - 6s 136ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 8.8524 - val_acc: 0.7188\n",
            "Epoch 803/1000\n",
            "39/39 [==============================] - 6s 137ms/step - loss: 9.1942e-04 - acc: 1.0000 - val_loss: 7.6913 - val_acc: 0.7292\n",
            "Epoch 804/1000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 0.0280 - acc: 0.9951 - val_loss: 6.4415 - val_acc: 0.7188\n",
            "Epoch 805/1000\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.0105 - acc: 0.9984 - val_loss: 6.9482 - val_acc: 0.7396\n",
            "Epoch 806/1000\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 2.6679e-04 - acc: 1.0000 - val_loss: 6.9634 - val_acc: 0.7396\n",
            "Epoch 807/1000\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.0099 - acc: 0.9984 - val_loss: 5.9238 - val_acc: 0.7396\n",
            "Epoch 808/1000\n",
            "39/39 [==============================] - 11s 257ms/step - loss: 0.0090 - acc: 0.9984 - val_loss: 5.5626 - val_acc: 0.7188\n",
            "Epoch 809/1000\n",
            "39/39 [==============================] - 6s 138ms/step - loss: 8.9912e-04 - acc: 1.0000 - val_loss: 5.3283 - val_acc: 0.7188\n",
            "Epoch 810/1000\n",
            "39/39 [==============================] - 5s 122ms/step - loss: 0.0152 - acc: 0.9984 - val_loss: 4.9961 - val_acc: 0.7396\n",
            "Epoch 811/1000\n",
            "39/39 [==============================] - 11s 263ms/step - loss: 0.0908 - acc: 0.9935 - val_loss: 5.1760 - val_acc: 0.7396\n",
            "Epoch 812/1000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 4.7852 - val_acc: 0.7500\n",
            "Epoch 813/1000\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 0.0091 - acc: 0.9984 - val_loss: 5.2622 - val_acc: 0.7604\n",
            "Epoch 814/1000\n",
            "39/39 [==============================] - 10s 255ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 5.6895 - val_acc: 0.7292\n",
            "Epoch 815/1000\n",
            "39/39 [==============================] - 6s 135ms/step - loss: 0.0061 - acc: 0.9967 - val_loss: 6.3194 - val_acc: 0.7292\n",
            "Epoch 816/1000\n",
            "39/39 [==============================] - 11s 265ms/step - loss: 0.0045 - acc: 0.9967 - val_loss: 7.8961 - val_acc: 0.7292\n",
            "Epoch 817/1000\n",
            "39/39 [==============================] - 10s 256ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 7.0550 - val_acc: 0.7292\n",
            "Epoch 818/1000\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.0132 - acc: 0.9951 - val_loss: 8.2832 - val_acc: 0.7396\n",
            "Epoch 819/1000\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.0294 - acc: 0.9935 - val_loss: 8.6636 - val_acc: 0.7188\n",
            "Epoch 820/1000\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 6.5447e-04 - acc: 1.0000 - val_loss: 7.6307 - val_acc: 0.7188\n",
            "Epoch 821/1000\n",
            "39/39 [==============================] - 6s 130ms/step - loss: 0.0021 - acc: 0.9984 - val_loss: 7.8378 - val_acc: 0.7083\n",
            "Epoch 822/1000\n",
            "39/39 [==============================] - 6s 136ms/step - loss: 7.5379e-04 - acc: 1.0000 - val_loss: 6.9853 - val_acc: 0.7188\n",
            "Epoch 823/1000\n",
            "39/39 [==============================] - 11s 261ms/step - loss: 0.0103 - acc: 0.9951 - val_loss: 6.5301 - val_acc: 0.7188\n",
            "Epoch 824/1000\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 6.2176e-04 - acc: 1.0000 - val_loss: 6.8465 - val_acc: 0.7292\n",
            "Epoch 825/1000\n",
            "39/39 [==============================] - 11s 260ms/step - loss: 0.0076 - acc: 0.9984 - val_loss: 7.3758 - val_acc: 0.7500\n",
            "Epoch 826/1000\n",
            "39/39 [==============================] - 10s 259ms/step - loss: 7.4742e-04 - acc: 1.0000 - val_loss: 5.9873 - val_acc: 0.7604\n",
            "Epoch 827/1000\n",
            "39/39 [==============================] - 10s 255ms/step - loss: 0.0231 - acc: 0.9967 - val_loss: 6.4705 - val_acc: 0.7292\n",
            "Epoch 828/1000\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 0.0490 - acc: 0.9951 - val_loss: 6.1420 - val_acc: 0.7396\n",
            "Epoch 829/1000\n",
            "39/39 [==============================] - 11s 261ms/step - loss: 0.0090 - acc: 0.9951 - val_loss: 8.4256 - val_acc: 0.7396\n",
            "Epoch 830/1000\n",
            "39/39 [==============================] - 6s 137ms/step - loss: 1.1222e-04 - acc: 1.0000 - val_loss: 8.7355 - val_acc: 0.7188\n",
            "Epoch 831/1000\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 0.0161 - acc: 0.9967 - val_loss: 8.9039 - val_acc: 0.7188\n",
            "Epoch 832/1000\n",
            "39/39 [==============================] - 11s 266ms/step - loss: 0.0057 - acc: 0.9984 - val_loss: 9.4942 - val_acc: 0.7292\n",
            "Epoch 833/1000\n",
            "39/39 [==============================] - 10s 261ms/step - loss: 0.0095 - acc: 0.9967 - val_loss: 8.1824 - val_acc: 0.7500\n",
            "Epoch 834/1000\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 0.0054 - acc: 0.9984 - val_loss: 8.2746 - val_acc: 0.7188\n",
            "Epoch 835/1000\n",
            "39/39 [==============================] - 11s 266ms/step - loss: 0.0027 - acc: 0.9984 - val_loss: 8.7665 - val_acc: 0.7292\n",
            "Epoch 836/1000\n",
            "39/39 [==============================] - 10s 259ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 9.1089 - val_acc: 0.7292\n",
            "Epoch 837/1000\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 0.0171 - acc: 0.9967 - val_loss: 7.4613 - val_acc: 0.7292\n",
            "Epoch 838/1000\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 0.0209 - acc: 0.9967 - val_loss: 6.8426 - val_acc: 0.7083\n",
            "Epoch 839/1000\n",
            "39/39 [==============================] - 5s 122ms/step - loss: 0.0262 - acc: 0.9967 - val_loss: 8.5271 - val_acc: 0.7083\n",
            "Epoch 840/1000\n",
            "39/39 [==============================] - 10s 255ms/step - loss: 1.1747e-04 - acc: 1.0000 - val_loss: 7.7620 - val_acc: 0.7396\n",
            "Epoch 841/1000\n",
            "39/39 [==============================] - 6s 137ms/step - loss: 0.0022 - acc: 0.9984 - val_loss: 8.8090 - val_acc: 0.7396\n",
            "Epoch 842/1000\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.0063 - acc: 0.9984 - val_loss: 7.4562 - val_acc: 0.7500\n",
            "Epoch 843/1000\n",
            "39/39 [==============================] - 6s 130ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 7.9109 - val_acc: 0.7396\n",
            "Epoch 844/1000\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 0.0133 - acc: 0.9967 - val_loss: 6.4169 - val_acc: 0.7292\n",
            "Epoch 845/1000\n",
            "39/39 [==============================] - 6s 148ms/step - loss: 0.0284 - acc: 0.9984 - val_loss: 6.3930 - val_acc: 0.7708\n",
            "Epoch 846/1000\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 0.0105 - acc: 0.9984 - val_loss: 6.6254 - val_acc: 0.7292\n",
            "Epoch 847/1000\n",
            "39/39 [==============================] - 6s 139ms/step - loss: 0.0054 - acc: 0.9984 - val_loss: 6.9936 - val_acc: 0.7500\n",
            "Epoch 848/1000\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 0.0474 - acc: 0.9935 - val_loss: 6.0116 - val_acc: 0.7188\n",
            "Epoch 849/1000\n",
            "39/39 [==============================] - 11s 261ms/step - loss: 0.0227 - acc: 0.9951 - val_loss: 6.0658 - val_acc: 0.7292\n",
            "Epoch 850/1000\n",
            "39/39 [==============================] - 11s 267ms/step - loss: 0.0468 - acc: 0.9951 - val_loss: 5.5820 - val_acc: 0.7292\n",
            "Epoch 851/1000\n",
            "39/39 [==============================] - 10s 255ms/step - loss: 0.0024 - acc: 0.9984 - val_loss: 5.6024 - val_acc: 0.7188\n",
            "Epoch 852/1000\n",
            "39/39 [==============================] - 6s 133ms/step - loss: 0.0056 - acc: 0.9967 - val_loss: 5.5881 - val_acc: 0.7292\n",
            "Epoch 853/1000\n",
            "39/39 [==============================] - 6s 136ms/step - loss: 0.0250 - acc: 0.9935 - val_loss: 5.4631 - val_acc: 0.7292\n",
            "Epoch 854/1000\n",
            "39/39 [==============================] - 10s 252ms/step - loss: 0.0687 - acc: 0.9967 - val_loss: 5.8861 - val_acc: 0.7083\n",
            "Epoch 855/1000\n",
            "39/39 [==============================] - 6s 133ms/step - loss: 0.0048 - acc: 0.9951 - val_loss: 7.0278 - val_acc: 0.7188\n",
            "Epoch 856/1000\n",
            "39/39 [==============================] - 11s 263ms/step - loss: 0.0080 - acc: 0.9967 - val_loss: 6.1115 - val_acc: 0.7292\n",
            "Epoch 857/1000\n",
            "39/39 [==============================] - 10s 255ms/step - loss: 0.0129 - acc: 0.9967 - val_loss: 6.5000 - val_acc: 0.6979\n",
            "Epoch 858/1000\n",
            "39/39 [==============================] - 10s 251ms/step - loss: 0.0125 - acc: 0.9951 - val_loss: 7.3115 - val_acc: 0.7292\n",
            "Epoch 859/1000\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 7.3163e-04 - acc: 1.0000 - val_loss: 6.6346 - val_acc: 0.6979\n",
            "Epoch 860/1000\n",
            "39/39 [==============================] - 6s 133ms/step - loss: 0.0048 - acc: 0.9984 - val_loss: 5.8123 - val_acc: 0.7292\n",
            "Epoch 861/1000\n",
            "39/39 [==============================] - 10s 258ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 6.2042 - val_acc: 0.7188\n",
            "Epoch 862/1000\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 8.2508e-05 - acc: 1.0000 - val_loss: 6.3012 - val_acc: 0.7083\n",
            "Epoch 863/1000\n",
            "39/39 [==============================] - 11s 273ms/step - loss: 0.0036 - acc: 0.9967 - val_loss: 7.2853 - val_acc: 0.7083\n",
            "Epoch 864/1000\n",
            "39/39 [==============================] - 6s 147ms/step - loss: 0.0015 - acc: 0.9984 - val_loss: 5.7985 - val_acc: 0.7292\n",
            "Epoch 865/1000\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 8.1013e-04 - acc: 1.0000 - val_loss: 6.0933 - val_acc: 0.7188\n",
            "Epoch 866/1000\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.0026 - acc: 0.9984 - val_loss: 6.4389 - val_acc: 0.6979\n",
            "Epoch 867/1000\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.0135 - acc: 0.9984 - val_loss: 5.6141 - val_acc: 0.7083\n",
            "Epoch 868/1000\n",
            "39/39 [==============================] - 11s 262ms/step - loss: 7.1054e-05 - acc: 1.0000 - val_loss: 5.9329 - val_acc: 0.7083\n",
            "Epoch 869/1000\n",
            "39/39 [==============================] - 6s 142ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 5.7509 - val_acc: 0.6979\n",
            "Epoch 870/1000\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 0.0543 - acc: 0.9935 - val_loss: 6.0311 - val_acc: 0.7396\n",
            "Epoch 871/1000\n",
            "39/39 [==============================] - 11s 257ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 6.8462 - val_acc: 0.7188\n",
            "Epoch 872/1000\n",
            "39/39 [==============================] - 10s 252ms/step - loss: 0.0237 - acc: 0.9951 - val_loss: 7.4796 - val_acc: 0.7083\n",
            "Epoch 873/1000\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.0067 - acc: 0.9984 - val_loss: 6.7508 - val_acc: 0.7188\n",
            "Epoch 874/1000\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.0202 - acc: 0.9951 - val_loss: 6.9974 - val_acc: 0.7083\n",
            "Epoch 875/1000\n",
            "39/39 [==============================] - 11s 262ms/step - loss: 0.0238 - acc: 0.9967 - val_loss: 6.4649 - val_acc: 0.7083\n",
            "Epoch 876/1000\n",
            "39/39 [==============================] - 6s 128ms/step - loss: 1.7061e-04 - acc: 1.0000 - val_loss: 6.0423 - val_acc: 0.7292\n",
            "Epoch 877/1000\n",
            "39/39 [==============================] - 11s 263ms/step - loss: 0.0079 - acc: 0.9967 - val_loss: 7.5234 - val_acc: 0.7396\n",
            "Epoch 878/1000\n",
            "39/39 [==============================] - 6s 138ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 6.7463 - val_acc: 0.7083\n",
            "Epoch 879/1000\n",
            "39/39 [==============================] - 10s 252ms/step - loss: 8.5590e-04 - acc: 1.0000 - val_loss: 6.7142 - val_acc: 0.7188\n",
            "Epoch 880/1000\n",
            "39/39 [==============================] - 6s 141ms/step - loss: 2.7260e-04 - acc: 1.0000 - val_loss: 7.5006 - val_acc: 0.7083\n",
            "Epoch 881/1000\n",
            "39/39 [==============================] - 10s 257ms/step - loss: 7.7283e-04 - acc: 1.0000 - val_loss: 7.5550 - val_acc: 0.7188\n",
            "Epoch 882/1000\n",
            "39/39 [==============================] - 6s 125ms/step - loss: 7.2366e-04 - acc: 1.0000 - val_loss: 6.5856 - val_acc: 0.7188\n",
            "Epoch 883/1000\n",
            "39/39 [==============================] - 10s 252ms/step - loss: 0.0034 - acc: 0.9984 - val_loss: 6.6047 - val_acc: 0.7292\n",
            "Epoch 884/1000\n",
            "39/39 [==============================] - 10s 254ms/step - loss: 0.0032 - acc: 0.9984 - val_loss: 5.5911 - val_acc: 0.7083\n",
            "Epoch 885/1000\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 1.2223e-04 - acc: 1.0000 - val_loss: 6.3290 - val_acc: 0.7083\n",
            "Epoch 886/1000\n",
            "39/39 [==============================] - 11s 256ms/step - loss: 2.7392e-04 - acc: 1.0000 - val_loss: 7.5127 - val_acc: 0.7292\n",
            "Epoch 887/1000\n",
            "39/39 [==============================] - 11s 261ms/step - loss: 1.2617e-04 - acc: 1.0000 - val_loss: 7.7750 - val_acc: 0.6979\n",
            "Epoch 888/1000\n",
            "39/39 [==============================] - 10s 256ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 6.9119 - val_acc: 0.7083\n",
            "Epoch 889/1000\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 6.6018e-04 - acc: 1.0000 - val_loss: 7.3249 - val_acc: 0.6979\n",
            "Epoch 890/1000\n",
            "39/39 [==============================] - 6s 137ms/step - loss: 2.2721e-04 - acc: 1.0000 - val_loss: 8.2047 - val_acc: 0.7292\n",
            "Epoch 891/1000\n",
            "39/39 [==============================] - 6s 145ms/step - loss: 0.0090 - acc: 0.9967 - val_loss: 10.0427 - val_acc: 0.7396\n",
            "Epoch 892/1000\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 0.0046 - acc: 0.9984 - val_loss: 8.4858 - val_acc: 0.6979\n",
            "Epoch 893/1000\n",
            "39/39 [==============================] - 6s 137ms/step - loss: 1.4433e-04 - acc: 1.0000 - val_loss: 9.6059 - val_acc: 0.6979\n",
            "Epoch 894/1000\n",
            "39/39 [==============================] - 6s 125ms/step - loss: 0.0086 - acc: 0.9967 - val_loss: 8.1641 - val_acc: 0.7396\n",
            "Epoch 895/1000\n",
            "39/39 [==============================] - 6s 125ms/step - loss: 0.0038 - acc: 0.9967 - val_loss: 8.1383 - val_acc: 0.7396\n",
            "Epoch 896/1000\n",
            "39/39 [==============================] - 6s 140ms/step - loss: 5.8617e-04 - acc: 1.0000 - val_loss: 10.1093 - val_acc: 0.7083\n",
            "Epoch 897/1000\n",
            "39/39 [==============================] - 6s 146ms/step - loss: 0.0168 - acc: 0.9967 - val_loss: 8.7979 - val_acc: 0.6979\n",
            "Epoch 898/1000\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 3.7350e-04 - acc: 1.0000 - val_loss: 7.9558 - val_acc: 0.7292\n",
            "Epoch 899/1000\n",
            "39/39 [==============================] - 10s 251ms/step - loss: 0.0142 - acc: 0.9951 - val_loss: 8.6435 - val_acc: 0.6875\n",
            "Epoch 900/1000\n",
            "39/39 [==============================] - 11s 269ms/step - loss: 4.2485e-04 - acc: 1.0000 - val_loss: 7.1554 - val_acc: 0.7083\n",
            "Epoch 901/1000\n",
            "39/39 [==============================] - 6s 135ms/step - loss: 4.7039e-04 - acc: 1.0000 - val_loss: 9.4560 - val_acc: 0.7188\n",
            "Epoch 902/1000\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 3.3885e-04 - acc: 1.0000 - val_loss: 8.3917 - val_acc: 0.7083\n",
            "Epoch 903/1000\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 0.0241 - acc: 0.9984 - val_loss: 8.0199 - val_acc: 0.7083\n",
            "Epoch 904/1000\n",
            "39/39 [==============================] - 6s 140ms/step - loss: 6.3789e-05 - acc: 1.0000 - val_loss: 8.7179 - val_acc: 0.6979\n",
            "Epoch 905/1000\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 0.0227 - acc: 0.9967 - val_loss: 10.3433 - val_acc: 0.7083\n",
            "Epoch 906/1000\n",
            "39/39 [==============================] - 6s 137ms/step - loss: 0.0033 - acc: 0.9984 - val_loss: 11.2921 - val_acc: 0.7083\n",
            "Epoch 907/1000\n",
            "39/39 [==============================] - 10s 261ms/step - loss: 0.0043 - acc: 0.9984 - val_loss: 10.3928 - val_acc: 0.7083\n",
            "Epoch 908/1000\n",
            "39/39 [==============================] - 6s 135ms/step - loss: 0.0537 - acc: 0.9951 - val_loss: 11.2507 - val_acc: 0.7292\n",
            "Epoch 909/1000\n",
            "39/39 [==============================] - 6s 141ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 11.0261 - val_acc: 0.7083\n",
            "Epoch 910/1000\n",
            "39/39 [==============================] - 5s 121ms/step - loss: 0.0068 - acc: 0.9984 - val_loss: 10.2647 - val_acc: 0.7083\n",
            "Epoch 911/1000\n",
            "39/39 [==============================] - 11s 260ms/step - loss: 0.0014 - acc: 0.9984 - val_loss: 7.8543 - val_acc: 0.7396\n",
            "Epoch 912/1000\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 2.5512e-04 - acc: 1.0000 - val_loss: 7.6016 - val_acc: 0.7188\n",
            "Epoch 913/1000\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 0.0032 - acc: 0.9984 - val_loss: 9.4661 - val_acc: 0.7083\n",
            "Epoch 914/1000\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.0050 - acc: 0.9967 - val_loss: 9.4415 - val_acc: 0.7083\n",
            "Epoch 915/1000\n",
            "39/39 [==============================] - 6s 127ms/step - loss: 1.6137e-05 - acc: 1.0000 - val_loss: 8.2546 - val_acc: 0.7292\n",
            "Epoch 916/1000\n",
            "39/39 [==============================] - 10s 251ms/step - loss: 0.0121 - acc: 0.9951 - val_loss: 9.3902 - val_acc: 0.7188\n",
            "Epoch 917/1000\n",
            "39/39 [==============================] - 10s 245ms/step - loss: 0.0109 - acc: 0.9984 - val_loss: 8.2390 - val_acc: 0.7083\n",
            "Epoch 918/1000\n",
            "39/39 [==============================] - 5s 121ms/step - loss: 0.0018 - acc: 0.9984 - val_loss: 7.5300 - val_acc: 0.6875\n",
            "Epoch 919/1000\n",
            "39/39 [==============================] - 11s 259ms/step - loss: 0.0063 - acc: 0.9984 - val_loss: 7.6648 - val_acc: 0.7188\n",
            "Epoch 920/1000\n",
            "39/39 [==============================] - 10s 264ms/step - loss: 0.0032 - acc: 0.9984 - val_loss: 7.3331 - val_acc: 0.6979\n",
            "Epoch 921/1000\n",
            "39/39 [==============================] - 6s 137ms/step - loss: 0.0264 - acc: 0.9935 - val_loss: 9.5130 - val_acc: 0.7188\n",
            "Epoch 922/1000\n",
            "39/39 [==============================] - 10s 258ms/step - loss: 3.3698e-04 - acc: 1.0000 - val_loss: 9.3227 - val_acc: 0.6979\n",
            "Epoch 923/1000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 0.0562 - acc: 0.9951 - val_loss: 7.4637 - val_acc: 0.7188\n",
            "Epoch 924/1000\n",
            "39/39 [==============================] - 6s 129ms/step - loss: 5.8284e-05 - acc: 1.0000 - val_loss: 8.0545 - val_acc: 0.6979\n",
            "Epoch 925/1000\n",
            "39/39 [==============================] - 6s 135ms/step - loss: 0.0026 - acc: 0.9984 - val_loss: 9.1342 - val_acc: 0.6875\n",
            "Epoch 926/1000\n",
            "39/39 [==============================] - 11s 261ms/step - loss: 0.0116 - acc: 0.9951 - val_loss: 8.0980 - val_acc: 0.7292\n",
            "Epoch 927/1000\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.0067 - acc: 0.9967 - val_loss: 8.8593 - val_acc: 0.7083\n",
            "Epoch 928/1000\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.0016 - acc: 0.9984 - val_loss: 8.8550 - val_acc: 0.6875\n",
            "Epoch 929/1000\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.0036 - acc: 0.9984 - val_loss: 9.2751 - val_acc: 0.7188\n",
            "Epoch 930/1000\n",
            "39/39 [==============================] - 10s 254ms/step - loss: 0.0115 - acc: 0.9984 - val_loss: 8.8988 - val_acc: 0.6979\n",
            "Epoch 931/1000\n",
            "39/39 [==============================] - 6s 137ms/step - loss: 2.2051e-04 - acc: 1.0000 - val_loss: 7.4072 - val_acc: 0.7292\n",
            "Epoch 932/1000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 0.0218 - acc: 0.9935 - val_loss: 8.0630 - val_acc: 0.6979\n",
            "Epoch 933/1000\n",
            "39/39 [==============================] - 11s 260ms/step - loss: 0.0030 - acc: 0.9984 - val_loss: 6.7956 - val_acc: 0.7188\n",
            "Epoch 934/1000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 0.0039 - acc: 0.9984 - val_loss: 8.5544 - val_acc: 0.7083\n",
            "Epoch 935/1000\n",
            "39/39 [==============================] - 11s 259ms/step - loss: 0.0248 - acc: 0.9967 - val_loss: 7.8131 - val_acc: 0.7083\n",
            "Epoch 936/1000\n",
            "39/39 [==============================] - 10s 259ms/step - loss: 9.9310e-04 - acc: 1.0000 - val_loss: 7.3816 - val_acc: 0.7083\n",
            "Epoch 937/1000\n",
            "39/39 [==============================] - 6s 137ms/step - loss: 3.3800e-04 - acc: 1.0000 - val_loss: 7.5299 - val_acc: 0.7292\n",
            "Epoch 938/1000\n",
            "39/39 [==============================] - 11s 256ms/step - loss: 0.0027 - acc: 0.9984 - val_loss: 8.1474 - val_acc: 0.7500\n",
            "Epoch 939/1000\n",
            "39/39 [==============================] - 11s 265ms/step - loss: 0.0317 - acc: 0.9918 - val_loss: 9.6537 - val_acc: 0.7188\n",
            "Epoch 940/1000\n",
            "39/39 [==============================] - 6s 135ms/step - loss: 3.0156e-04 - acc: 1.0000 - val_loss: 8.8518 - val_acc: 0.7396\n",
            "Epoch 941/1000\n",
            "39/39 [==============================] - 6s 128ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 9.4852 - val_acc: 0.7292\n",
            "Epoch 942/1000\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 0.0158 - acc: 0.9984 - val_loss: 9.6798 - val_acc: 0.7500\n",
            "Epoch 943/1000\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 7.1897e-05 - acc: 1.0000 - val_loss: 9.2287 - val_acc: 0.7500\n",
            "Epoch 944/1000\n",
            "39/39 [==============================] - 6s 133ms/step - loss: 0.0016 - acc: 0.9984 - val_loss: 9.3587 - val_acc: 0.7188\n",
            "Epoch 945/1000\n",
            "39/39 [==============================] - 6s 136ms/step - loss: 0.0062 - acc: 0.9984 - val_loss: 10.8872 - val_acc: 0.7188\n",
            "Epoch 946/1000\n",
            "39/39 [==============================] - 6s 136ms/step - loss: 0.0229 - acc: 0.9967 - val_loss: 10.1860 - val_acc: 0.7396\n",
            "Epoch 947/1000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 9.6088 - val_acc: 0.7500\n",
            "Epoch 948/1000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 6.3076e-04 - acc: 1.0000 - val_loss: 9.6581 - val_acc: 0.7396\n",
            "Epoch 949/1000\n",
            "39/39 [==============================] - 11s 262ms/step - loss: 0.0032 - acc: 0.9984 - val_loss: 10.0708 - val_acc: 0.7396\n",
            "Epoch 950/1000\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.0342 - acc: 0.9967 - val_loss: 10.5256 - val_acc: 0.7708\n",
            "Epoch 951/1000\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.0137 - acc: 0.9984 - val_loss: 9.9380 - val_acc: 0.7396\n",
            "Epoch 952/1000\n",
            "39/39 [==============================] - 6s 135ms/step - loss: 0.0246 - acc: 0.9935 - val_loss: 9.0636 - val_acc: 0.7292\n",
            "Epoch 953/1000\n",
            "39/39 [==============================] - 6s 139ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 9.1627 - val_acc: 0.7188\n",
            "Epoch 954/1000\n",
            "39/39 [==============================] - 10s 254ms/step - loss: 0.0015 - acc: 0.9984 - val_loss: 6.7797 - val_acc: 0.7292\n",
            "Epoch 955/1000\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 8.6140e-04 - acc: 1.0000 - val_loss: 7.7381 - val_acc: 0.7292\n",
            "Epoch 956/1000\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 0.0090 - acc: 0.9967 - val_loss: 7.7813 - val_acc: 0.7292\n",
            "Epoch 957/1000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 9.9843e-04 - acc: 1.0000 - val_loss: 7.6155 - val_acc: 0.7188\n",
            "Epoch 958/1000\n",
            "39/39 [==============================] - 6s 146ms/step - loss: 0.0024 - acc: 0.9984 - val_loss: 6.9008 - val_acc: 0.6979\n",
            "Epoch 959/1000\n",
            "39/39 [==============================] - 10s 252ms/step - loss: 0.0177 - acc: 0.9984 - val_loss: 7.3183 - val_acc: 0.6979\n",
            "Epoch 960/1000\n",
            "39/39 [==============================] - 10s 254ms/step - loss: 0.0192 - acc: 0.9967 - val_loss: 6.8665 - val_acc: 0.7083\n",
            "Epoch 961/1000\n",
            "39/39 [==============================] - 11s 266ms/step - loss: 0.0198 - acc: 0.9967 - val_loss: 6.7939 - val_acc: 0.7083\n",
            "Epoch 962/1000\n",
            "39/39 [==============================] - 11s 260ms/step - loss: 2.7981e-04 - acc: 1.0000 - val_loss: 6.6480 - val_acc: 0.7188\n",
            "Epoch 963/1000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 4.9041e-04 - acc: 1.0000 - val_loss: 7.9148 - val_acc: 0.7083\n",
            "Epoch 964/1000\n",
            "39/39 [==============================] - 11s 262ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 7.8908 - val_acc: 0.7292\n",
            "Epoch 965/1000\n",
            "39/39 [==============================] - 11s 260ms/step - loss: 0.0137 - acc: 0.9951 - val_loss: 9.2224 - val_acc: 0.7188\n",
            "Epoch 966/1000\n",
            "39/39 [==============================] - 6s 135ms/step - loss: 0.0163 - acc: 0.9951 - val_loss: 9.0408 - val_acc: 0.7083\n",
            "Epoch 967/1000\n",
            "39/39 [==============================] - 11s 260ms/step - loss: 5.7338e-04 - acc: 1.0000 - val_loss: 8.5286 - val_acc: 0.7083\n",
            "Epoch 968/1000\n",
            "39/39 [==============================] - 11s 264ms/step - loss: 2.0050e-04 - acc: 1.0000 - val_loss: 8.8748 - val_acc: 0.7188\n",
            "Epoch 969/1000\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 8.8001 - val_acc: 0.7188\n",
            "Epoch 970/1000\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 3.5343e-04 - acc: 1.0000 - val_loss: 8.9554 - val_acc: 0.7083\n",
            "Epoch 971/1000\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 9.5506 - val_acc: 0.7604\n",
            "Epoch 972/1000\n",
            "39/39 [==============================] - 6s 136ms/step - loss: 0.0028 - acc: 0.9984 - val_loss: 8.2469 - val_acc: 0.7292\n",
            "Epoch 973/1000\n",
            "39/39 [==============================] - 10s 251ms/step - loss: 0.0161 - acc: 0.9984 - val_loss: 9.5837 - val_acc: 0.7396\n",
            "Epoch 974/1000\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.0076 - acc: 0.9984 - val_loss: 9.9201 - val_acc: 0.7500\n",
            "Epoch 975/1000\n",
            "39/39 [==============================] - 6s 133ms/step - loss: 0.0065 - acc: 0.9967 - val_loss: 8.8458 - val_acc: 0.7396\n",
            "Epoch 976/1000\n",
            "39/39 [==============================] - 6s 139ms/step - loss: 2.3476e-04 - acc: 1.0000 - val_loss: 7.9125 - val_acc: 0.7500\n",
            "Epoch 977/1000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 0.0089 - acc: 0.9967 - val_loss: 7.0407 - val_acc: 0.7188\n",
            "Epoch 978/1000\n",
            "39/39 [==============================] - 6s 141ms/step - loss: 0.0064 - acc: 0.9984 - val_loss: 7.8053 - val_acc: 0.7500\n",
            "Epoch 979/1000\n",
            "39/39 [==============================] - 10s 255ms/step - loss: 4.3588e-04 - acc: 1.0000 - val_loss: 6.9434 - val_acc: 0.7500\n",
            "Epoch 980/1000\n",
            "39/39 [==============================] - 6s 145ms/step - loss: 3.8232e-04 - acc: 1.0000 - val_loss: 8.2439 - val_acc: 0.7396\n",
            "Epoch 981/1000\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.0069 - acc: 0.9984 - val_loss: 8.4229 - val_acc: 0.7396\n",
            "Epoch 982/1000\n",
            "39/39 [==============================] - 10s 256ms/step - loss: 0.0043 - acc: 0.9984 - val_loss: 7.3514 - val_acc: 0.7500\n",
            "Epoch 983/1000\n",
            "39/39 [==============================] - 11s 263ms/step - loss: 0.0039 - acc: 0.9984 - val_loss: 7.3219 - val_acc: 0.7396\n",
            "Epoch 984/1000\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.0098 - acc: 0.9984 - val_loss: 5.9358 - val_acc: 0.7708\n",
            "Epoch 985/1000\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.0279 - acc: 0.9967 - val_loss: 6.1920 - val_acc: 0.7500\n",
            "Epoch 986/1000\n",
            "39/39 [==============================] - 6s 135ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 6.6140 - val_acc: 0.7396\n",
            "Epoch 987/1000\n",
            "39/39 [==============================] - 11s 264ms/step - loss: 8.2938e-04 - acc: 1.0000 - val_loss: 5.4638 - val_acc: 0.7292\n",
            "Epoch 988/1000\n",
            "39/39 [==============================] - 11s 260ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 5.6766 - val_acc: 0.7500\n",
            "Epoch 989/1000\n",
            "39/39 [==============================] - 10s 251ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 6.5705 - val_acc: 0.7292\n",
            "Epoch 990/1000\n",
            "39/39 [==============================] - 10s 251ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 5.9282 - val_acc: 0.7604\n",
            "Epoch 991/1000\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 1.2209e-04 - acc: 1.0000 - val_loss: 6.4988 - val_acc: 0.7500\n",
            "Epoch 992/1000\n",
            "39/39 [==============================] - 6s 139ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 6.0058 - val_acc: 0.7292\n",
            "Epoch 993/1000\n",
            "39/39 [==============================] - 10s 258ms/step - loss: 3.0978e-04 - acc: 1.0000 - val_loss: 6.2339 - val_acc: 0.7188\n",
            "Epoch 994/1000\n",
            "39/39 [==============================] - 5s 132ms/step - loss: 0.0021 - acc: 0.9984 - val_loss: 7.3732 - val_acc: 0.7188\n",
            "Epoch 995/1000\n",
            "39/39 [==============================] - 11s 266ms/step - loss: 0.0043 - acc: 0.9984 - val_loss: 6.9398 - val_acc: 0.7083\n",
            "Epoch 996/1000\n",
            "39/39 [==============================] - 10s 256ms/step - loss: 0.0217 - acc: 0.9951 - val_loss: 7.9918 - val_acc: 0.7292\n",
            "Epoch 997/1000\n",
            "39/39 [==============================] - 5s 130ms/step - loss: 0.0118 - acc: 0.9951 - val_loss: 7.7316 - val_acc: 0.7188\n",
            "Epoch 998/1000\n",
            "39/39 [==============================] - 6s 138ms/step - loss: 0.0175 - acc: 0.9952 - val_loss: 9.1552 - val_acc: 0.7396\n",
            "Epoch 999/1000\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.0081 - acc: 0.9984 - val_loss: 8.1136 - val_acc: 0.7604\n",
            "Epoch 1000/1000\n",
            "39/39 [==============================] - 6s 140ms/step - loss: 0.0036 - acc: 0.9967 - val_loss: 8.9116 - val_acc: 0.7396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot training performance"
      ],
      "metadata": {
        "id": "YFxMJycOpEew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'co', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'k', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'co', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "     "
      ],
      "metadata": {
        "id": "l9PYKbRNpEK8",
        "outputId": "af5a58a9-95f5-45f5-8d64-fe69c44e51a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SAVE model"
      ],
      "metadata": {
        "id": "kNtlq_LZpKNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('./content/drive/My Drive/new', exist_ok=True)\n",
        "model.save('./content/drive/My Drive/new/2Class_UNfreeze_newdata1.h5')"
      ],
      "metadata": {
        "id": "TegSVqblpLEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "KdsdaIgMpMeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"./content/drive/My Drive/new/2Class_UNfreeze_newdata1.h5\")"
      ],
      "metadata": {
        "id": "sZFZ1c_kpMcN",
        "outputId": "1a2cda9d-a765-45a6-8bd9-90c4a3b33fb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4d20cf41-a0d6-4b19-9646-88ebefe27f2b\", \"2Class_UNfreeze_newdata1.h5\", 32850272)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gEfCB1RfpMZ6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}