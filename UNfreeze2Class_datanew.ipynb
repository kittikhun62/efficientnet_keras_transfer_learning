{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO1KD0OXaVLCvyth9lgK3uW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kittikhun62/efficientnet_keras_transfer_learning/blob/master/UNfreeze2Class_datanew.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# import from drive"
      ],
      "metadata": {
        "id": "bB2gfuYWczY-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpXyZ9k5YIJu",
        "outputId": "32e6e101-6ca6-449e-d7ca-adc324fe5833"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (r'/content/drive/My Drive/data - 2 class เพิ่ม 4 paper.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "7mqo2OLAc2pG",
        "outputId": "31250906-5282-4605-ff8d-252d17f9458a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      No                      Name_file  \\\n",
              "0      1                        pore-sb   \n",
              "1      2                        pore-sb   \n",
              "2      3                        pore-sb   \n",
              "3      4                        pore-sb   \n",
              "4      5                        pore-sb   \n",
              "..   ...                            ...   \n",
              "825  826  1-s2.0-S2095268622000210-main   \n",
              "826  827  1-s2.0-S2095268622000210-main   \n",
              "827  828  1-s2.0-S2095268622000210-main   \n",
              "828  829  1-s2.0-S2095268622000210-main   \n",
              "829  830  1-s2.0-S2095268622000210-main   \n",
              "\n",
              "                                            Name_Paper  \\\n",
              "0    Preparation and electrochemical behaviour of b...   \n",
              "1    Preparation and electrochemical behaviour of b...   \n",
              "2    Preparation and electrochemical behaviour of b...   \n",
              "3    Preparation and electrochemical behaviour of b...   \n",
              "4    Preparation and electrochemical behaviour of b...   \n",
              "..                                                 ...   \n",
              "825  Integration of preparation of K, Na-embedded a...   \n",
              "826  Integration of preparation of K, Na-embedded a...   \n",
              "827  Integration of preparation of K, Na-embedded a...   \n",
              "828  Integration of preparation of K, Na-embedded a...   \n",
              "829  Integration of preparation of K, Na-embedded a...   \n",
              "\n",
              "                                               journal  \\\n",
              "0                                  Korean J. Chem. Eng   \n",
              "1                                  Korean J. Chem. Eng   \n",
              "2                                  Korean J. Chem. Eng   \n",
              "3                                  Korean J. Chem. Eng   \n",
              "4                                  Korean J. Chem. Eng   \n",
              "..                                                 ...   \n",
              "825  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "826  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "827  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "828  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "829  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "\n",
              "                                          path_Picture  detail  Class     BET  \\\n",
              "0    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom1  0-800  135.06   \n",
              "1    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom2  0-800  135.06   \n",
              "2    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom3  0-800  135.06   \n",
              "3    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom4  0-800  135.06   \n",
              "4    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom5  0-800  135.06   \n",
              "..                                                 ...     ...    ...     ...   \n",
              "825  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom21  0-800  301.70   \n",
              "826  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom22  0-800  301.70   \n",
              "827  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom23  0-800  301.70   \n",
              "828  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom24  0-800  301.70   \n",
              "829  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom25  0-800  301.70   \n",
              "\n",
              "     Size(mico)  Class_01  \n",
              "0            10         0  \n",
              "1            10         0  \n",
              "2            10         0  \n",
              "3            10         0  \n",
              "4            10         0  \n",
              "..          ...       ...  \n",
              "825          10         0  \n",
              "826          10         0  \n",
              "827          10         0  \n",
              "828          10         0  \n",
              "829          10         0  \n",
              "\n",
              "[830 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-382cb5e9-e28c-40d8-bbf0-2d717d995a54\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>No</th>\n",
              "      <th>Name_file</th>\n",
              "      <th>Name_Paper</th>\n",
              "      <th>journal</th>\n",
              "      <th>path_Picture</th>\n",
              "      <th>detail</th>\n",
              "      <th>Class</th>\n",
              "      <th>BET</th>\n",
              "      <th>Size(mico)</th>\n",
              "      <th>Class_01</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom1</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom2</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom3</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom4</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom5</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>825</th>\n",
              "      <td>826</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom21</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>826</th>\n",
              "      <td>827</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom22</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>827</th>\n",
              "      <td>828</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom23</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>828</th>\n",
              "      <td>829</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom24</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>829</th>\n",
              "      <td>830</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom25</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>830 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-382cb5e9-e28c-40d8-bbf0-2d717d995a54')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-382cb5e9-e28c-40d8-bbf0-2d717d995a54 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-382cb5e9-e28c-40d8-bbf0-2d717d995a54');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports library"
      ],
      "metadata": {
        "id": "VkYa-4LeTbir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "myAsBcVhTW7j"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## hyper parameter\n"
      ],
      "metadata": {
        "id": "T529UM_tVV-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "width = 150\n",
        "height = 150\n",
        "\n",
        "epochs = 1000 #จำนวนรอบในการ Train\n",
        "\n",
        "NUM_TRAIN = 628  # จำนวนภาพ Train\n",
        "NUM_TEST = 101 #จำนวนภาพ Test\n",
        "\n",
        "dropout_rate = 0.3\n",
        "input_shape = (height, width, 3) #ขนาด image enter"
      ],
      "metadata": {
        "id": "zXpmkJ2GVZ1l"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone efficientnet repo"
      ],
      "metadata": {
        "id": "DSSZIFGhUyQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/"
      ],
      "metadata": {
        "id": "nFvKcuBDTj1N",
        "outputId": "40a9fc14-abf6-4a4f-84b3-4a32591a0cf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import efficientnet and load the conv base model"
      ],
      "metadata": {
        "id": "j3EgSOiSZHaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "iI3DQ18HU2TF"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "#EfficientNet สร้างขึ้นสำหรับการจำแนกประเภท ImageNet ประกอบด้วยป้ายกำกับคลาส 1,000 รายการ เรามีเพียง 2 เลเยอร์เท่านั้น ซึ่งหมายความว่าเลเยอร์สองสามเลเยอร์สุดท้ายสำหรับการจำแนกไม่มีประโยชน์สำหรับเรา สามารถยกเว้นได้ขณะโหลดโมเดลโดยระบุอาร์กิวเมนต์ include_top เป็น False และนำไปใช้กับโมเดล ImageNet อื่นๆ ที่มีอยู่ในแอปพลิเคชัน Keras เช่นกัน\n",
        "\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "UmBDAgF_VAjq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "id": "rRXoFFzfU2Oi",
        "outputId": "496e22e3-8208-4974-e7a9-5e8fd6383840",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 75, 75, 32)   864         ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 75, 75, 32)  128         ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_49 (Swish)               (None, 75, 75, 32)   0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_16 (Depthwise  (None, 75, 75, 32)  288         ['swish_49[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 75, 75, 32)  128         ['depthwise_conv2d_16[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_50 (Swish)               (None, 75, 75, 32)   0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_16 (Lambda)             (None, 1, 1, 32)     0           ['swish_50[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 1, 1, 8)      264         ['lambda_16[0][0]']              \n",
            "                                                                                                  \n",
            " swish_51 (Swish)               (None, 1, 1, 8)      0           ['conv2d_66[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 1, 1, 32)     288         ['swish_51[0][0]']               \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 1, 1, 32)     0           ['conv2d_67[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_16 (Multiply)         (None, 75, 75, 32)   0           ['activation_16[0][0]',          \n",
            "                                                                  'swish_50[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 75, 75, 16)   512         ['multiply_16[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 75, 75, 16)  64          ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 75, 75, 96)   1536        ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 75, 75, 96)  384         ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_52 (Swish)               (None, 75, 75, 96)   0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_17 (Depthwise  (None, 38, 38, 96)  864         ['swish_52[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 38, 38, 96)  384         ['depthwise_conv2d_17[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_53 (Swish)               (None, 38, 38, 96)   0           ['batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_17 (Lambda)             (None, 1, 1, 96)     0           ['swish_53[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 1, 1, 4)      388         ['lambda_17[0][0]']              \n",
            "                                                                                                  \n",
            " swish_54 (Swish)               (None, 1, 1, 4)      0           ['conv2d_70[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 1, 1, 96)     480         ['swish_54[0][0]']               \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 1, 1, 96)     0           ['conv2d_71[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_17 (Multiply)         (None, 38, 38, 96)   0           ['activation_17[0][0]',          \n",
            "                                                                  'swish_53[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 38, 38, 24)   2304        ['multiply_17[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 38, 38, 24)  96          ['conv2d_72[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 38, 38, 144)  3456        ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 38, 38, 144)  576        ['conv2d_73[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_55 (Swish)               (None, 38, 38, 144)  0           ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_18 (Depthwise  (None, 38, 38, 144)  1296       ['swish_55[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 38, 38, 144)  576        ['depthwise_conv2d_18[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_56 (Swish)               (None, 38, 38, 144)  0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_18 (Lambda)             (None, 1, 1, 144)    0           ['swish_56[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_18[0][0]']              \n",
            "                                                                                                  \n",
            " swish_57 (Swish)               (None, 1, 1, 6)      0           ['conv2d_74[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_57[0][0]']               \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 1, 1, 144)    0           ['conv2d_75[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_18 (Multiply)         (None, 38, 38, 144)  0           ['activation_18[0][0]',          \n",
            "                                                                  'swish_56[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_18[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 38, 38, 24)  96          ['conv2d_76[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_9 (DropConnect)   (None, 38, 38, 24)   0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 38, 38, 24)   0           ['drop_connect_9[0][0]',         \n",
            "                                                                  'batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 38, 38, 144)  3456        ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 38, 38, 144)  576        ['conv2d_77[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_58 (Swish)               (None, 38, 38, 144)  0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_19 (Depthwise  (None, 19, 19, 144)  3600       ['swish_58[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_19[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_59 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_19 (Lambda)             (None, 1, 1, 144)    0           ['swish_59[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_19[0][0]']              \n",
            "                                                                                                  \n",
            " swish_60 (Swish)               (None, 1, 1, 6)      0           ['conv2d_78[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_60[0][0]']               \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 1, 1, 144)    0           ['conv2d_79[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_19 (Multiply)         (None, 19, 19, 144)  0           ['activation_19[0][0]',          \n",
            "                                                                  'swish_59[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_19[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 19, 19, 40)  160         ['conv2d_80[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 19, 19, 240)  960        ['conv2d_81[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_61 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_20 (Depthwise  (None, 19, 19, 240)  6000       ['swish_61[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_20[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_62 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_20 (Lambda)             (None, 1, 1, 240)    0           ['swish_62[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_20[0][0]']              \n",
            "                                                                                                  \n",
            " swish_63 (Swish)               (None, 1, 1, 10)     0           ['conv2d_82[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_63[0][0]']               \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 1, 1, 240)    0           ['conv2d_83[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_20 (Multiply)         (None, 19, 19, 240)  0           ['activation_20[0][0]',          \n",
            "                                                                  'swish_62[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_20[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 19, 19, 40)  160         ['conv2d_84[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_10 (DropConnect)  (None, 19, 19, 40)   0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 19, 19, 40)   0           ['drop_connect_10[0][0]',        \n",
            "                                                                  'batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, 19, 19, 240)  9600        ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 19, 19, 240)  960        ['conv2d_85[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_64 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_21 (Depthwise  (None, 10, 10, 240)  2160       ['swish_64[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_21[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_65 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_21 (Lambda)             (None, 1, 1, 240)    0           ['swish_65[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_21[0][0]']              \n",
            "                                                                                                  \n",
            " swish_66 (Swish)               (None, 1, 1, 10)     0           ['conv2d_86[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_66[0][0]']               \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 1, 1, 240)    0           ['conv2d_87[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_21 (Multiply)         (None, 10, 10, 240)  0           ['activation_21[0][0]',          \n",
            "                                                                  'swish_65[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_21[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 10, 10, 80)  320         ['conv2d_88[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_89[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_67 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_22 (Depthwise  (None, 10, 10, 480)  4320       ['swish_67[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_22[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_68 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_22 (Lambda)             (None, 1, 1, 480)    0           ['swish_68[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_22[0][0]']              \n",
            "                                                                                                  \n",
            " swish_69 (Swish)               (None, 1, 1, 20)     0           ['conv2d_90[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_69[0][0]']               \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 1, 1, 480)    0           ['conv2d_91[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_22 (Multiply)         (None, 10, 10, 480)  0           ['activation_22[0][0]',          \n",
            "                                                                  'swish_68[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_22[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 10, 10, 80)  320         ['conv2d_92[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_11 (DropConnect)  (None, 10, 10, 80)   0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 10, 10, 80)   0           ['drop_connect_11[0][0]',        \n",
            "                                                                  'batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 10, 10, 480)  38400       ['add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_93[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_70 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_70[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_23 (Depthwise  (None, 10, 10, 480)  4320       ['swish_70[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_23[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_71 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_71[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_23 (Lambda)             (None, 1, 1, 480)    0           ['swish_71[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_94 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_23[0][0]']              \n",
            "                                                                                                  \n",
            " swish_72 (Swish)               (None, 1, 1, 20)     0           ['conv2d_94[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_95 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_72[0][0]']               \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 1, 1, 480)    0           ['conv2d_95[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_23 (Multiply)         (None, 10, 10, 480)  0           ['activation_23[0][0]',          \n",
            "                                                                  'swish_71[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_96 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_23[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_72 (BatchN  (None, 10, 10, 80)  320         ['conv2d_96[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_12 (DropConnect)  (None, 10, 10, 80)   0           ['batch_normalization_72[0][0]'] \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 10, 10, 80)   0           ['drop_connect_12[0][0]',        \n",
            "                                                                  'add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_97 (Conv2D)             (None, 10, 10, 480)  38400       ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_73 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_97[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_73 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_73[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_24 (Depthwise  (None, 10, 10, 480)  12000      ['swish_73[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_74 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_24[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_74 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_74[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_24 (Lambda)             (None, 1, 1, 480)    0           ['swish_74[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_98 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_24[0][0]']              \n",
            "                                                                                                  \n",
            " swish_75 (Swish)               (None, 1, 1, 20)     0           ['conv2d_98[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_99 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_75[0][0]']               \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 1, 1, 480)    0           ['conv2d_99[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_24 (Multiply)         (None, 10, 10, 480)  0           ['activation_24[0][0]',          \n",
            "                                                                  'swish_74[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_100 (Conv2D)            (None, 10, 10, 112)  53760       ['multiply_24[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_75 (BatchN  (None, 10, 10, 112)  448        ['conv2d_100[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_101 (Conv2D)            (None, 10, 10, 672)  75264       ['batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_76 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_101[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_76 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_76[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_25 (Depthwise  (None, 10, 10, 672)  16800      ['swish_76[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_77 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_25[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_77 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_77[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_25 (Lambda)             (None, 1, 1, 672)    0           ['swish_77[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_102 (Conv2D)            (None, 1, 1, 28)     18844       ['lambda_25[0][0]']              \n",
            "                                                                                                  \n",
            " swish_78 (Swish)               (None, 1, 1, 28)     0           ['conv2d_102[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_103 (Conv2D)            (None, 1, 1, 672)    19488       ['swish_78[0][0]']               \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 1, 1, 672)    0           ['conv2d_103[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_25 (Multiply)         (None, 10, 10, 672)  0           ['activation_25[0][0]',          \n",
            "                                                                  'swish_77[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_104 (Conv2D)            (None, 10, 10, 112)  75264       ['multiply_25[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_78 (BatchN  (None, 10, 10, 112)  448        ['conv2d_104[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_13 (DropConnect)  (None, 10, 10, 112)  0           ['batch_normalization_78[0][0]'] \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 10, 10, 112)  0           ['drop_connect_13[0][0]',        \n",
            "                                                                  'batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_105 (Conv2D)            (None, 10, 10, 672)  75264       ['add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_79 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_105[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_79 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_79[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_26 (Depthwise  (None, 10, 10, 672)  16800      ['swish_79[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_80 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_26[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_80 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_80[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_26 (Lambda)             (None, 1, 1, 672)    0           ['swish_80[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_106 (Conv2D)            (None, 1, 1, 28)     18844       ['lambda_26[0][0]']              \n",
            "                                                                                                  \n",
            " swish_81 (Swish)               (None, 1, 1, 28)     0           ['conv2d_106[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_107 (Conv2D)            (None, 1, 1, 672)    19488       ['swish_81[0][0]']               \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 1, 1, 672)    0           ['conv2d_107[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_26 (Multiply)         (None, 10, 10, 672)  0           ['activation_26[0][0]',          \n",
            "                                                                  'swish_80[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_108 (Conv2D)            (None, 10, 10, 112)  75264       ['multiply_26[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_81 (BatchN  (None, 10, 10, 112)  448        ['conv2d_108[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_14 (DropConnect)  (None, 10, 10, 112)  0           ['batch_normalization_81[0][0]'] \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 10, 10, 112)  0           ['drop_connect_14[0][0]',        \n",
            "                                                                  'add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_109 (Conv2D)            (None, 10, 10, 672)  75264       ['add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_82 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_109[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_82 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_82[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_27 (Depthwise  (None, 5, 5, 672)   16800       ['swish_82[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_83 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_27[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_83 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_83[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_27 (Lambda)             (None, 1, 1, 672)    0           ['swish_83[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_110 (Conv2D)            (None, 1, 1, 28)     18844       ['lambda_27[0][0]']              \n",
            "                                                                                                  \n",
            " swish_84 (Swish)               (None, 1, 1, 28)     0           ['conv2d_110[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_111 (Conv2D)            (None, 1, 1, 672)    19488       ['swish_84[0][0]']               \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 1, 1, 672)    0           ['conv2d_111[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_27 (Multiply)         (None, 5, 5, 672)    0           ['activation_27[0][0]',          \n",
            "                                                                  'swish_83[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_112 (Conv2D)            (None, 5, 5, 192)    129024      ['multiply_27[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_84 (BatchN  (None, 5, 5, 192)   768         ['conv2d_112[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_113 (Conv2D)            (None, 5, 5, 1152)   221184      ['batch_normalization_84[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_85 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_113[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_85 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_85[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_28 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_85[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_86 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_28[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_86 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_86[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_28 (Lambda)             (None, 1, 1, 1152)   0           ['swish_86[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_114 (Conv2D)            (None, 1, 1, 48)     55344       ['lambda_28[0][0]']              \n",
            "                                                                                                  \n",
            " swish_87 (Swish)               (None, 1, 1, 48)     0           ['conv2d_114[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_115 (Conv2D)            (None, 1, 1, 1152)   56448       ['swish_87[0][0]']               \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_115[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_28 (Multiply)         (None, 5, 5, 1152)   0           ['activation_28[0][0]',          \n",
            "                                                                  'swish_86[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_116 (Conv2D)            (None, 5, 5, 192)    221184      ['multiply_28[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_87 (BatchN  (None, 5, 5, 192)   768         ['conv2d_116[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_15 (DropConnect)  (None, 5, 5, 192)    0           ['batch_normalization_87[0][0]'] \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 5, 5, 192)    0           ['drop_connect_15[0][0]',        \n",
            "                                                                  'batch_normalization_84[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_117 (Conv2D)            (None, 5, 5, 1152)   221184      ['add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_88 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_117[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_88 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_88[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_29 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_88[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_89 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_29[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_89 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_89[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_29 (Lambda)             (None, 1, 1, 1152)   0           ['swish_89[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_118 (Conv2D)            (None, 1, 1, 48)     55344       ['lambda_29[0][0]']              \n",
            "                                                                                                  \n",
            " swish_90 (Swish)               (None, 1, 1, 48)     0           ['conv2d_118[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_119 (Conv2D)            (None, 1, 1, 1152)   56448       ['swish_90[0][0]']               \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_119[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_29 (Multiply)         (None, 5, 5, 1152)   0           ['activation_29[0][0]',          \n",
            "                                                                  'swish_89[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_120 (Conv2D)            (None, 5, 5, 192)    221184      ['multiply_29[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_90 (BatchN  (None, 5, 5, 192)   768         ['conv2d_120[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_16 (DropConnect)  (None, 5, 5, 192)    0           ['batch_normalization_90[0][0]'] \n",
            "                                                                                                  \n",
            " add_16 (Add)                   (None, 5, 5, 192)    0           ['drop_connect_16[0][0]',        \n",
            "                                                                  'add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_121 (Conv2D)            (None, 5, 5, 1152)   221184      ['add_16[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_91 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_121[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_91 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_91[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_30 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_91[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_92 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_30[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_92 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_92[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_30 (Lambda)             (None, 1, 1, 1152)   0           ['swish_92[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_122 (Conv2D)            (None, 1, 1, 48)     55344       ['lambda_30[0][0]']              \n",
            "                                                                                                  \n",
            " swish_93 (Swish)               (None, 1, 1, 48)     0           ['conv2d_122[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_123 (Conv2D)            (None, 1, 1, 1152)   56448       ['swish_93[0][0]']               \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_123[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_30 (Multiply)         (None, 5, 5, 1152)   0           ['activation_30[0][0]',          \n",
            "                                                                  'swish_92[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_124 (Conv2D)            (None, 5, 5, 192)    221184      ['multiply_30[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_93 (BatchN  (None, 5, 5, 192)   768         ['conv2d_124[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_17 (DropConnect)  (None, 5, 5, 192)    0           ['batch_normalization_93[0][0]'] \n",
            "                                                                                                  \n",
            " add_17 (Add)                   (None, 5, 5, 192)    0           ['drop_connect_17[0][0]',        \n",
            "                                                                  'add_16[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_125 (Conv2D)            (None, 5, 5, 1152)   221184      ['add_17[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_94 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_125[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_94 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_94[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_31 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_94[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_95 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_31[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_95 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_95[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_31 (Lambda)             (None, 1, 1, 1152)   0           ['swish_95[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_126 (Conv2D)            (None, 1, 1, 48)     55344       ['lambda_31[0][0]']              \n",
            "                                                                                                  \n",
            " swish_96 (Swish)               (None, 1, 1, 48)     0           ['conv2d_126[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_127 (Conv2D)            (None, 1, 1, 1152)   56448       ['swish_96[0][0]']               \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_127[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_31 (Multiply)         (None, 5, 5, 1152)   0           ['activation_31[0][0]',          \n",
            "                                                                  'swish_95[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_128 (Conv2D)            (None, 5, 5, 320)    368640      ['multiply_31[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_96 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_128[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_129 (Conv2D)            (None, 5, 5, 1280)   409600      ['batch_normalization_96[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_97 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_129[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_97 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_97[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 4,007,548\n",
            "Non-trainable params: 42,016\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/new/2Class_datanew.h5')\n",
        "\n",
        "from efficientnet.layers import Swish, DropConnect\n",
        "from efficientnet.model import ConvKernalInitializer\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "\n",
        "get_custom_objects().update({\n",
        "    'ConvKernalInitializer': ConvKernalInitializer,\n",
        "    'Swish': Swish,\n",
        "    'DropConnect':DropConnect\n",
        "})"
      ],
      "metadata": {
        "id": "MwNk3sNbc2Qx"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load model \n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/drive/My Drive/new/2Class_datanew.h5')\n",
        "height = width = model.input_shape[1]"
      ],
      "metadata": {
        "id": "4v4nzKQtJZ4z"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/My Drive/new project'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Directories for our training,\n",
        "# validation and test splits\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.makedirs(test_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "UDxvF-b8Jcq1"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, # image input 0-255 --> 0-1 เปลี่ยนค่าสี\n",
        "      rotation_range=40,# หมุนภาพในองศา\n",
        "      width_shift_range=0.2, #เปลี่ยนความกว้าง\n",
        "      height_shift_range=0.2, #ปลี่ยนความสูง\n",
        "      shear_range=0.2, #ทำให้ภาพเบี้ยว\n",
        "      zoom_range=0.2, # Randomly zoom image\n",
        "      horizontal_flip=True, \n",
        "      #โดย Default เมื่อมีการเลื่อนภาพ บิดภาพ หมุนภาพ จะเกิดพื้นที่ว่างที่มุม \n",
        "      #ซึ่งจะมีการเติมภาพให้เต็มโดยใช้เทคนิคแบบ Nearest neighbor ซึ่งเป็นการดึงสีบริเวณใหล้าเคียงมาระบายให้เต็ม แต่เราก็ยังสามารถกำหนดวิธีการ Fill ภาพด้วยเทคนิคอื่นได้จาก Parameter fill_mode\n",
        "      fill_mode='nearest')\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory #ไดเรกเป้าหมาย\n",
        "        train_dir,\n",
        "        # รูปภาพทั้งหมดจะถูกปรับขนาดตามความสูงและความกว้างของเป้าหมาย\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        #เนื่องจากเราใช้ categorical_crossentropy loss เราจึงต้องมีป้ายกำกับตามหมวดหมู่\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory( #การดึงภาพจาก Directory มาเข้าโมเดล \n",
        "        validation_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "     \n",
        "\n"
      ],
      "metadata": {
        "id": "znE38DtIJeN-",
        "outputId": "ed991932-ba08-4238-bd73-a962963a42ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 628 images belonging to 2 classes.\n",
            "Found 101 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multiply_16\n",
        "# set 'multiply_16' and following layers trainable\n",
        "model.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'multiply_16':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False  \n",
        "     "
      ],
      "metadata": {
        "id": "tEaPoHJCJq13"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IC-3EwwkJHGS",
        "outputId": "09c413b3-3221-413b-8ca4-3c1740108323"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 2)                 2562      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,052,126\n",
            "Trainable params: 4,010,110\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "z7ERVUfUJsQq",
        "outputId": "3a1572e2-9bf8-4a68-ac3b-828d3091c6bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-caa7b37242a8>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "39/39 [==============================] - 9s 120ms/step - loss: 0.5158 - acc: 0.7549 - val_loss: 0.6208 - val_acc: 0.6875\n",
            "Epoch 2/1000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.4948 - acc: 0.7614 - val_loss: 0.5993 - val_acc: 0.6562\n",
            "Epoch 3/1000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.4999 - acc: 0.7484 - val_loss: 0.5998 - val_acc: 0.6875\n",
            "Epoch 4/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.4929 - acc: 0.7484 - val_loss: 0.5890 - val_acc: 0.6771\n",
            "Epoch 5/1000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 0.5353 - acc: 0.7271 - val_loss: 0.5932 - val_acc: 0.6875\n",
            "Epoch 6/1000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 0.4890 - acc: 0.7680 - val_loss: 0.6139 - val_acc: 0.6667\n",
            "Epoch 7/1000\n",
            "39/39 [==============================] - 5s 132ms/step - loss: 0.5111 - acc: 0.7467 - val_loss: 0.6092 - val_acc: 0.6667\n",
            "Epoch 8/1000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.5246 - acc: 0.7320 - val_loss: 0.5987 - val_acc: 0.6250\n",
            "Epoch 9/1000\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 0.5054 - acc: 0.7484 - val_loss: 0.6094 - val_acc: 0.6875\n",
            "Epoch 10/1000\n",
            "39/39 [==============================] - 8s 211ms/step - loss: 0.4809 - acc: 0.7582 - val_loss: 0.6081 - val_acc: 0.6979\n",
            "Epoch 11/1000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5230 - acc: 0.7533 - val_loss: 0.6250 - val_acc: 0.6771\n",
            "Epoch 12/1000\n",
            "39/39 [==============================] - 9s 208ms/step - loss: 0.5054 - acc: 0.7614 - val_loss: 0.5941 - val_acc: 0.6875\n",
            "Epoch 13/1000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.5220 - acc: 0.7451 - val_loss: 0.6011 - val_acc: 0.6771\n",
            "Epoch 14/1000\n",
            "39/39 [==============================] - 4s 79ms/step - loss: 0.5128 - acc: 0.7451 - val_loss: 0.5812 - val_acc: 0.6667\n",
            "Epoch 15/1000\n",
            "39/39 [==============================] - 5s 103ms/step - loss: 0.5240 - acc: 0.7467 - val_loss: 0.5872 - val_acc: 0.6562\n",
            "Epoch 16/1000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 0.5403 - acc: 0.7418 - val_loss: 0.6225 - val_acc: 0.7083\n",
            "Epoch 17/1000\n",
            "39/39 [==============================] - 10s 239ms/step - loss: 0.5475 - acc: 0.7288 - val_loss: 0.6274 - val_acc: 0.6979\n",
            "Epoch 18/1000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 0.5038 - acc: 0.7451 - val_loss: 0.5815 - val_acc: 0.6667\n",
            "Epoch 19/1000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5116 - acc: 0.7582 - val_loss: 0.5700 - val_acc: 0.6667\n",
            "Epoch 20/1000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.5161 - acc: 0.7337 - val_loss: 0.6100 - val_acc: 0.6771\n",
            "Epoch 21/1000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.5401 - acc: 0.7320 - val_loss: 0.6041 - val_acc: 0.6562\n",
            "Epoch 22/1000\n",
            "39/39 [==============================] - 9s 209ms/step - loss: 0.5165 - acc: 0.7386 - val_loss: 0.5784 - val_acc: 0.6562\n",
            "Epoch 23/1000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 0.5173 - acc: 0.7320 - val_loss: 0.5803 - val_acc: 0.6771\n",
            "Epoch 24/1000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 0.5305 - acc: 0.7255 - val_loss: 0.5774 - val_acc: 0.6667\n",
            "Epoch 25/1000\n",
            "39/39 [==============================] - 8s 214ms/step - loss: 0.5144 - acc: 0.7418 - val_loss: 0.6108 - val_acc: 0.6667\n",
            "Epoch 26/1000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5295 - acc: 0.7467 - val_loss: 0.5908 - val_acc: 0.6458\n",
            "Epoch 27/1000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5268 - acc: 0.7484 - val_loss: 0.5725 - val_acc: 0.6771\n",
            "Epoch 28/1000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5292 - acc: 0.7141 - val_loss: 0.5978 - val_acc: 0.6458\n",
            "Epoch 29/1000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.4880 - acc: 0.7484 - val_loss: 0.5772 - val_acc: 0.6771\n",
            "Epoch 30/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5331 - acc: 0.7418 - val_loss: 0.6016 - val_acc: 0.6875\n",
            "Epoch 31/1000\n",
            "39/39 [==============================] - 9s 209ms/step - loss: 0.5160 - acc: 0.7533 - val_loss: 0.5927 - val_acc: 0.6458\n",
            "Epoch 32/1000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.5047 - acc: 0.7418 - val_loss: 0.6143 - val_acc: 0.6771\n",
            "Epoch 33/1000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 0.5193 - acc: 0.7304 - val_loss: 0.6151 - val_acc: 0.6771\n",
            "Epoch 34/1000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5092 - acc: 0.7516 - val_loss: 0.5837 - val_acc: 0.6250\n",
            "Epoch 35/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.4926 - acc: 0.7484 - val_loss: 0.5846 - val_acc: 0.6771\n",
            "Epoch 36/1000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.4846 - acc: 0.7740 - val_loss: 0.5976 - val_acc: 0.6979\n",
            "Epoch 37/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5170 - acc: 0.7320 - val_loss: 0.5890 - val_acc: 0.6875\n",
            "Epoch 38/1000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5080 - acc: 0.7631 - val_loss: 0.5929 - val_acc: 0.6771\n",
            "Epoch 39/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5232 - acc: 0.7353 - val_loss: 0.6136 - val_acc: 0.6979\n",
            "Epoch 40/1000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5339 - acc: 0.7598 - val_loss: 0.5836 - val_acc: 0.6667\n",
            "Epoch 41/1000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5213 - acc: 0.7614 - val_loss: 0.5853 - val_acc: 0.6979\n",
            "Epoch 42/1000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 0.5550 - acc: 0.7239 - val_loss: 0.5838 - val_acc: 0.6771\n",
            "Epoch 43/1000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.4996 - acc: 0.7435 - val_loss: 0.6124 - val_acc: 0.6771\n",
            "Epoch 44/1000\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 0.5225 - acc: 0.7271 - val_loss: 0.5949 - val_acc: 0.6771\n",
            "Epoch 45/1000\n",
            "39/39 [==============================] - 4s 80ms/step - loss: 0.5067 - acc: 0.7500 - val_loss: 0.5846 - val_acc: 0.6667\n",
            "Epoch 46/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5018 - acc: 0.7451 - val_loss: 0.6135 - val_acc: 0.6771\n",
            "Epoch 47/1000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.4657 - acc: 0.7631 - val_loss: 0.5993 - val_acc: 0.6458\n",
            "Epoch 48/1000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 0.5034 - acc: 0.7533 - val_loss: 0.6067 - val_acc: 0.6771\n",
            "Epoch 49/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.4981 - acc: 0.7418 - val_loss: 0.6003 - val_acc: 0.6458\n",
            "Epoch 50/1000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.5114 - acc: 0.7386 - val_loss: 0.5969 - val_acc: 0.6458\n",
            "Epoch 51/1000\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 0.5093 - acc: 0.7304 - val_loss: 0.5819 - val_acc: 0.6771\n",
            "Epoch 52/1000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5097 - acc: 0.7402 - val_loss: 0.6142 - val_acc: 0.6771\n",
            "Epoch 53/1000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 0.5097 - acc: 0.7337 - val_loss: 0.5670 - val_acc: 0.6771\n",
            "Epoch 54/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5040 - acc: 0.7255 - val_loss: 0.5924 - val_acc: 0.6667\n",
            "Epoch 55/1000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.5057 - acc: 0.7386 - val_loss: 0.5843 - val_acc: 0.6875\n",
            "Epoch 56/1000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.5139 - acc: 0.7451 - val_loss: 0.6108 - val_acc: 0.6562\n",
            "Epoch 57/1000\n",
            "39/39 [==============================] - 8s 203ms/step - loss: 0.5071 - acc: 0.7435 - val_loss: 0.5850 - val_acc: 0.6979\n",
            "Epoch 58/1000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 0.5315 - acc: 0.7337 - val_loss: 0.5776 - val_acc: 0.6875\n",
            "Epoch 59/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5059 - acc: 0.7516 - val_loss: 0.5829 - val_acc: 0.6667\n",
            "Epoch 60/1000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 0.5106 - acc: 0.7372 - val_loss: 0.5822 - val_acc: 0.6875\n",
            "Epoch 61/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.5210 - acc: 0.7500 - val_loss: 0.6049 - val_acc: 0.6875\n",
            "Epoch 62/1000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.4823 - acc: 0.7435 - val_loss: 0.5917 - val_acc: 0.6875\n",
            "Epoch 63/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.4898 - acc: 0.7500 - val_loss: 0.5785 - val_acc: 0.7083\n",
            "Epoch 64/1000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.4694 - acc: 0.7724 - val_loss: 0.5801 - val_acc: 0.6458\n",
            "Epoch 65/1000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 0.4558 - acc: 0.7761 - val_loss: 0.5738 - val_acc: 0.7083\n",
            "Epoch 66/1000\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.5297 - acc: 0.7388 - val_loss: 0.5945 - val_acc: 0.6771\n",
            "Epoch 67/1000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 0.4987 - acc: 0.7614 - val_loss: 0.5988 - val_acc: 0.6771\n",
            "Epoch 68/1000\n",
            "39/39 [==============================] - 10s 236ms/step - loss: 0.4978 - acc: 0.7451 - val_loss: 0.6278 - val_acc: 0.6771\n",
            "Epoch 69/1000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 0.5142 - acc: 0.7337 - val_loss: 0.5777 - val_acc: 0.6667\n",
            "Epoch 70/1000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5064 - acc: 0.7712 - val_loss: 0.6023 - val_acc: 0.6667\n",
            "Epoch 71/1000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 0.5514 - acc: 0.7026 - val_loss: 0.5881 - val_acc: 0.6458\n",
            "Epoch 72/1000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 0.5156 - acc: 0.7500 - val_loss: 0.6148 - val_acc: 0.6667\n",
            "Epoch 73/1000\n",
            "39/39 [==============================] - 10s 231ms/step - loss: 0.5041 - acc: 0.7386 - val_loss: 0.6164 - val_acc: 0.6667\n",
            "Epoch 74/1000\n",
            "39/39 [==============================] - 6s 145ms/step - loss: 0.5214 - acc: 0.7337 - val_loss: 0.5817 - val_acc: 0.6771\n",
            "Epoch 75/1000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 0.4804 - acc: 0.7696 - val_loss: 0.6064 - val_acc: 0.6771\n",
            "Epoch 76/1000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.5114 - acc: 0.7565 - val_loss: 0.5908 - val_acc: 0.6562\n",
            "Epoch 77/1000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 0.5254 - acc: 0.7549 - val_loss: 0.5818 - val_acc: 0.6146\n",
            "Epoch 78/1000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 0.5011 - acc: 0.7565 - val_loss: 0.5978 - val_acc: 0.6562\n",
            "Epoch 79/1000\n",
            "39/39 [==============================] - 5s 99ms/step - loss: 0.5111 - acc: 0.7647 - val_loss: 0.6003 - val_acc: 0.6667\n",
            "Epoch 80/1000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 0.5078 - acc: 0.7451 - val_loss: 0.5818 - val_acc: 0.6562\n",
            "Epoch 81/1000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.5268 - acc: 0.7386 - val_loss: 0.5982 - val_acc: 0.6354\n",
            "Epoch 82/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5311 - acc: 0.7500 - val_loss: 0.6281 - val_acc: 0.6562\n",
            "Epoch 83/1000\n",
            "39/39 [==============================] - 9s 236ms/step - loss: 0.4654 - acc: 0.7598 - val_loss: 0.5965 - val_acc: 0.6354\n",
            "Epoch 84/1000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.4955 - acc: 0.7386 - val_loss: 0.5986 - val_acc: 0.6667\n",
            "Epoch 85/1000\n",
            "39/39 [==============================] - 5s 120ms/step - loss: 0.5053 - acc: 0.7484 - val_loss: 0.6246 - val_acc: 0.6771\n",
            "Epoch 86/1000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.5181 - acc: 0.7565 - val_loss: 0.6166 - val_acc: 0.6562\n",
            "Epoch 87/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5265 - acc: 0.7451 - val_loss: 0.6021 - val_acc: 0.6979\n",
            "Epoch 88/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5289 - acc: 0.7304 - val_loss: 0.6298 - val_acc: 0.6458\n",
            "Epoch 89/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5229 - acc: 0.7402 - val_loss: 0.6181 - val_acc: 0.6458\n",
            "Epoch 90/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5667 - acc: 0.7010 - val_loss: 0.6279 - val_acc: 0.6562\n",
            "Epoch 91/1000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5038 - acc: 0.7484 - val_loss: 0.6335 - val_acc: 0.6562\n",
            "Epoch 92/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.4916 - acc: 0.7680 - val_loss: 0.6039 - val_acc: 0.6667\n",
            "Epoch 93/1000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 0.5083 - acc: 0.7369 - val_loss: 0.6078 - val_acc: 0.6771\n",
            "Epoch 94/1000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 0.4913 - acc: 0.7647 - val_loss: 0.6082 - val_acc: 0.6771\n",
            "Epoch 95/1000\n",
            "39/39 [==============================] - 4s 80ms/step - loss: 0.5016 - acc: 0.7402 - val_loss: 0.6087 - val_acc: 0.6458\n",
            "Epoch 96/1000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5134 - acc: 0.7484 - val_loss: 0.6183 - val_acc: 0.6562\n",
            "Epoch 97/1000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5157 - acc: 0.7222 - val_loss: 0.6402 - val_acc: 0.6562\n",
            "Epoch 98/1000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5280 - acc: 0.7353 - val_loss: 0.6141 - val_acc: 0.6562\n",
            "Epoch 99/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.4922 - acc: 0.7467 - val_loss: 0.6297 - val_acc: 0.6562\n",
            "Epoch 100/1000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 0.4898 - acc: 0.7598 - val_loss: 0.6386 - val_acc: 0.6562\n",
            "Epoch 101/1000\n",
            "39/39 [==============================] - 9s 209ms/step - loss: 0.5410 - acc: 0.7386 - val_loss: 0.6211 - val_acc: 0.6667\n",
            "Epoch 102/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5125 - acc: 0.7418 - val_loss: 0.6360 - val_acc: 0.6562\n",
            "Epoch 103/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.4882 - acc: 0.7582 - val_loss: 0.6312 - val_acc: 0.6458\n",
            "Epoch 104/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5020 - acc: 0.7435 - val_loss: 0.6390 - val_acc: 0.6562\n",
            "Epoch 105/1000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 0.5344 - acc: 0.7320 - val_loss: 0.6306 - val_acc: 0.6667\n",
            "Epoch 106/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.4887 - acc: 0.7745 - val_loss: 0.6416 - val_acc: 0.6458\n",
            "Epoch 107/1000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.5284 - acc: 0.7598 - val_loss: 0.6253 - val_acc: 0.6562\n",
            "Epoch 108/1000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5431 - acc: 0.7141 - val_loss: 0.6241 - val_acc: 0.6771\n",
            "Epoch 109/1000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 0.5084 - acc: 0.7304 - val_loss: 0.5935 - val_acc: 0.6458\n",
            "Epoch 110/1000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.5479 - acc: 0.7059 - val_loss: 0.6052 - val_acc: 0.6667\n",
            "Epoch 111/1000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 0.5002 - acc: 0.7598 - val_loss: 0.6113 - val_acc: 0.6354\n",
            "Epoch 112/1000\n",
            "39/39 [==============================] - 9s 209ms/step - loss: 0.5017 - acc: 0.7712 - val_loss: 0.5826 - val_acc: 0.6667\n",
            "Epoch 113/1000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.5389 - acc: 0.7386 - val_loss: 0.6013 - val_acc: 0.6562\n",
            "Epoch 114/1000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 0.5102 - acc: 0.7402 - val_loss: 0.5997 - val_acc: 0.6979\n",
            "Epoch 115/1000\n",
            "39/39 [==============================] - 5s 101ms/step - loss: 0.5221 - acc: 0.7239 - val_loss: 0.6174 - val_acc: 0.6875\n",
            "Epoch 116/1000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 0.5351 - acc: 0.7500 - val_loss: 0.6123 - val_acc: 0.6458\n",
            "Epoch 117/1000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.4858 - acc: 0.7565 - val_loss: 0.6072 - val_acc: 0.6562\n",
            "Epoch 118/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5247 - acc: 0.7533 - val_loss: 0.6104 - val_acc: 0.6771\n",
            "Epoch 119/1000\n",
            "39/39 [==============================] - 5s 93ms/step - loss: 0.4946 - acc: 0.7565 - val_loss: 0.6014 - val_acc: 0.6562\n",
            "Epoch 120/1000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 0.4933 - acc: 0.7500 - val_loss: 0.5922 - val_acc: 0.6562\n",
            "Epoch 121/1000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5317 - acc: 0.7484 - val_loss: 0.6045 - val_acc: 0.6667\n",
            "Epoch 122/1000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5394 - acc: 0.7402 - val_loss: 0.6039 - val_acc: 0.6667\n",
            "Epoch 123/1000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5013 - acc: 0.7500 - val_loss: 0.6367 - val_acc: 0.6562\n",
            "Epoch 124/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5148 - acc: 0.7580 - val_loss: 0.5995 - val_acc: 0.6354\n",
            "Epoch 125/1000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5446 - acc: 0.7320 - val_loss: 0.6015 - val_acc: 0.6458\n",
            "Epoch 126/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.5036 - acc: 0.7418 - val_loss: 0.6058 - val_acc: 0.6562\n",
            "Epoch 127/1000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 0.5186 - acc: 0.7451 - val_loss: 0.6086 - val_acc: 0.6562\n",
            "Epoch 128/1000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5207 - acc: 0.7222 - val_loss: 0.6164 - val_acc: 0.6667\n",
            "Epoch 129/1000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 0.4888 - acc: 0.7598 - val_loss: 0.6040 - val_acc: 0.6667\n",
            "Epoch 130/1000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 0.5068 - acc: 0.7549 - val_loss: 0.5845 - val_acc: 0.6562\n",
            "Epoch 131/1000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 0.5308 - acc: 0.7680 - val_loss: 0.5815 - val_acc: 0.6667\n",
            "Epoch 132/1000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.4941 - acc: 0.7596 - val_loss: 0.6015 - val_acc: 0.6458\n",
            "Epoch 133/1000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.5154 - acc: 0.7304 - val_loss: 0.5824 - val_acc: 0.6458\n",
            "Epoch 134/1000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.5209 - acc: 0.7386 - val_loss: 0.6102 - val_acc: 0.6562\n",
            "Epoch 135/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5151 - acc: 0.7467 - val_loss: 0.6178 - val_acc: 0.6562\n",
            "Epoch 136/1000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 0.5178 - acc: 0.7565 - val_loss: 0.6088 - val_acc: 0.6667\n",
            "Epoch 137/1000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5357 - acc: 0.7271 - val_loss: 0.6207 - val_acc: 0.6458\n",
            "Epoch 138/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5049 - acc: 0.7516 - val_loss: 0.6234 - val_acc: 0.6458\n",
            "Epoch 139/1000\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 0.5200 - acc: 0.7386 - val_loss: 0.6337 - val_acc: 0.6458\n",
            "Epoch 140/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5132 - acc: 0.7533 - val_loss: 0.6578 - val_acc: 0.7083\n",
            "Epoch 141/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5157 - acc: 0.7337 - val_loss: 0.6447 - val_acc: 0.6667\n",
            "Epoch 142/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.5451 - acc: 0.7255 - val_loss: 0.6476 - val_acc: 0.6562\n",
            "Epoch 143/1000\n",
            "39/39 [==============================] - 5s 128ms/step - loss: 0.5202 - acc: 0.7533 - val_loss: 0.6207 - val_acc: 0.6562\n",
            "Epoch 144/1000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 0.4947 - acc: 0.7631 - val_loss: 0.6114 - val_acc: 0.6354\n",
            "Epoch 145/1000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.4925 - acc: 0.7631 - val_loss: 0.6020 - val_acc: 0.6562\n",
            "Epoch 146/1000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.5094 - acc: 0.7337 - val_loss: 0.6172 - val_acc: 0.6354\n",
            "Epoch 147/1000\n",
            "39/39 [==============================] - 6s 138ms/step - loss: 0.4878 - acc: 0.7565 - val_loss: 0.6391 - val_acc: 0.6250\n",
            "Epoch 148/1000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 0.4832 - acc: 0.7794 - val_loss: 0.6692 - val_acc: 0.6667\n",
            "Epoch 149/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5310 - acc: 0.7386 - val_loss: 0.6359 - val_acc: 0.6562\n",
            "Epoch 150/1000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 0.4712 - acc: 0.7598 - val_loss: 0.6205 - val_acc: 0.6667\n",
            "Epoch 151/1000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5001 - acc: 0.7680 - val_loss: 0.6225 - val_acc: 0.6562\n",
            "Epoch 152/1000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 0.5386 - acc: 0.7337 - val_loss: 0.6070 - val_acc: 0.6458\n",
            "Epoch 153/1000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.5488 - acc: 0.7206 - val_loss: 0.6088 - val_acc: 0.6250\n",
            "Epoch 154/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5286 - acc: 0.7418 - val_loss: 0.6187 - val_acc: 0.6771\n",
            "Epoch 155/1000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.4921 - acc: 0.7549 - val_loss: 0.6089 - val_acc: 0.6458\n",
            "Epoch 156/1000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.4835 - acc: 0.7745 - val_loss: 0.6093 - val_acc: 0.6458\n",
            "Epoch 157/1000\n",
            "39/39 [==============================] - 5s 122ms/step - loss: 0.5217 - acc: 0.7337 - val_loss: 0.6117 - val_acc: 0.6875\n",
            "Epoch 158/1000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.5173 - acc: 0.7500 - val_loss: 0.6024 - val_acc: 0.6354\n",
            "Epoch 159/1000\n",
            "39/39 [==============================] - 5s 102ms/step - loss: 0.5132 - acc: 0.7500 - val_loss: 0.5967 - val_acc: 0.6562\n",
            "Epoch 160/1000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.5332 - acc: 0.7288 - val_loss: 0.5952 - val_acc: 0.6667\n",
            "Epoch 161/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5317 - acc: 0.7451 - val_loss: 0.6021 - val_acc: 0.6562\n",
            "Epoch 162/1000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 0.5227 - acc: 0.7239 - val_loss: 0.5997 - val_acc: 0.6354\n",
            "Epoch 163/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5375 - acc: 0.7582 - val_loss: 0.5898 - val_acc: 0.6562\n",
            "Epoch 164/1000\n",
            "39/39 [==============================] - 10s 234ms/step - loss: 0.5427 - acc: 0.7255 - val_loss: 0.6115 - val_acc: 0.6771\n",
            "Epoch 165/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5414 - acc: 0.7288 - val_loss: 0.6154 - val_acc: 0.6771\n",
            "Epoch 166/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5157 - acc: 0.7582 - val_loss: 0.5837 - val_acc: 0.6458\n",
            "Epoch 167/1000\n",
            "39/39 [==============================] - 4s 80ms/step - loss: 0.4817 - acc: 0.7516 - val_loss: 0.6243 - val_acc: 0.6667\n",
            "Epoch 168/1000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.4971 - acc: 0.7516 - val_loss: 0.6125 - val_acc: 0.6771\n",
            "Epoch 169/1000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.5252 - acc: 0.7337 - val_loss: 0.6188 - val_acc: 0.6875\n",
            "Epoch 170/1000\n",
            "39/39 [==============================] - 4s 80ms/step - loss: 0.5159 - acc: 0.7141 - val_loss: 0.6307 - val_acc: 0.6667\n",
            "Epoch 171/1000\n",
            "39/39 [==============================] - 10s 236ms/step - loss: 0.5274 - acc: 0.7222 - val_loss: 0.6266 - val_acc: 0.6667\n",
            "Epoch 172/1000\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 0.4914 - acc: 0.7827 - val_loss: 0.6280 - val_acc: 0.6562\n",
            "Epoch 173/1000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.4913 - acc: 0.7614 - val_loss: 0.6088 - val_acc: 0.6667\n",
            "Epoch 174/1000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 0.5543 - acc: 0.7206 - val_loss: 0.5932 - val_acc: 0.6875\n",
            "Epoch 175/1000\n",
            "39/39 [==============================] - 8s 202ms/step - loss: 0.5133 - acc: 0.7582 - val_loss: 0.6166 - val_acc: 0.6667\n",
            "Epoch 176/1000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 0.4689 - acc: 0.7778 - val_loss: 0.6000 - val_acc: 0.6458\n",
            "Epoch 177/1000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.4935 - acc: 0.7565 - val_loss: 0.5893 - val_acc: 0.6562\n",
            "Epoch 178/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5347 - acc: 0.7369 - val_loss: 0.5962 - val_acc: 0.6979\n",
            "Epoch 179/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5433 - acc: 0.7190 - val_loss: 0.6174 - val_acc: 0.6667\n",
            "Epoch 180/1000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5363 - acc: 0.7353 - val_loss: 0.5959 - val_acc: 0.6875\n",
            "Epoch 181/1000\n",
            "39/39 [==============================] - 5s 113ms/step - loss: 0.4878 - acc: 0.7778 - val_loss: 0.5952 - val_acc: 0.6562\n",
            "Epoch 182/1000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 0.5126 - acc: 0.7418 - val_loss: 0.6197 - val_acc: 0.6667\n",
            "Epoch 183/1000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 0.5236 - acc: 0.7516 - val_loss: 0.5966 - val_acc: 0.6979\n",
            "Epoch 184/1000\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 0.4929 - acc: 0.7712 - val_loss: 0.6188 - val_acc: 0.6354\n",
            "Epoch 185/1000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.4965 - acc: 0.7631 - val_loss: 0.6177 - val_acc: 0.6458\n",
            "Epoch 186/1000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5301 - acc: 0.7141 - val_loss: 0.6178 - val_acc: 0.6667\n",
            "Epoch 187/1000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.5824 - acc: 0.7108 - val_loss: 0.6247 - val_acc: 0.6667\n",
            "Epoch 188/1000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.4910 - acc: 0.7614 - val_loss: 0.6227 - val_acc: 0.6667\n",
            "Epoch 189/1000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 0.4930 - acc: 0.7663 - val_loss: 0.6256 - val_acc: 0.6354\n",
            "Epoch 190/1000\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.5281 - acc: 0.7271 - val_loss: 0.5959 - val_acc: 0.6875\n",
            "Epoch 191/1000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 0.5138 - acc: 0.7353 - val_loss: 0.5941 - val_acc: 0.6354\n",
            "Epoch 192/1000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 0.5195 - acc: 0.7614 - val_loss: 0.6038 - val_acc: 0.6875\n",
            "Epoch 193/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5033 - acc: 0.7369 - val_loss: 0.6270 - val_acc: 0.6875\n",
            "Epoch 194/1000\n",
            "39/39 [==============================] - 5s 122ms/step - loss: 0.5297 - acc: 0.7386 - val_loss: 0.6145 - val_acc: 0.6667\n",
            "Epoch 195/1000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5369 - acc: 0.7386 - val_loss: 0.5886 - val_acc: 0.6979\n",
            "Epoch 196/1000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 0.5444 - acc: 0.7222 - val_loss: 0.5931 - val_acc: 0.6562\n",
            "Epoch 197/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5146 - acc: 0.7418 - val_loss: 0.6054 - val_acc: 0.6562\n",
            "Epoch 198/1000\n",
            "39/39 [==============================] - 5s 121ms/step - loss: 0.5080 - acc: 0.7320 - val_loss: 0.5909 - val_acc: 0.6771\n",
            "Epoch 199/1000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5007 - acc: 0.7484 - val_loss: 0.6035 - val_acc: 0.6875\n",
            "Epoch 200/1000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 0.4634 - acc: 0.7663 - val_loss: 0.5964 - val_acc: 0.6354\n",
            "Epoch 201/1000\n",
            "39/39 [==============================] - 6s 144ms/step - loss: 0.5056 - acc: 0.7598 - val_loss: 0.5886 - val_acc: 0.6667\n",
            "Epoch 202/1000\n",
            "39/39 [==============================] - 3s 82ms/step - loss: 0.5120 - acc: 0.7320 - val_loss: 0.6281 - val_acc: 0.6667\n",
            "Epoch 203/1000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 0.5088 - acc: 0.7631 - val_loss: 0.6156 - val_acc: 0.6458\n",
            "Epoch 204/1000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5190 - acc: 0.7565 - val_loss: 0.6029 - val_acc: 0.6562\n",
            "Epoch 205/1000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.4956 - acc: 0.7549 - val_loss: 0.5929 - val_acc: 0.6667\n",
            "Epoch 206/1000\n",
            "39/39 [==============================] - 5s 98ms/step - loss: 0.5128 - acc: 0.7435 - val_loss: 0.6209 - val_acc: 0.6771\n",
            "Epoch 207/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.4904 - acc: 0.7794 - val_loss: 0.6127 - val_acc: 0.6875\n",
            "Epoch 208/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.4991 - acc: 0.7729 - val_loss: 0.6175 - val_acc: 0.6771\n",
            "Epoch 209/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5179 - acc: 0.7418 - val_loss: 0.5840 - val_acc: 0.6458\n",
            "Epoch 210/1000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.4596 - acc: 0.7859 - val_loss: 0.6006 - val_acc: 0.6875\n",
            "Epoch 211/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5128 - acc: 0.7451 - val_loss: 0.6259 - val_acc: 0.6979\n",
            "Epoch 212/1000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5067 - acc: 0.7288 - val_loss: 0.5986 - val_acc: 0.6667\n",
            "Epoch 213/1000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.5645 - acc: 0.7271 - val_loss: 0.5896 - val_acc: 0.6771\n",
            "Epoch 214/1000\n",
            "39/39 [==============================] - 9s 209ms/step - loss: 0.5353 - acc: 0.7435 - val_loss: 0.5971 - val_acc: 0.6667\n",
            "Epoch 215/1000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 0.5314 - acc: 0.7549 - val_loss: 0.6204 - val_acc: 0.6771\n",
            "Epoch 216/1000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5351 - acc: 0.7271 - val_loss: 0.6161 - val_acc: 0.6771\n",
            "Epoch 217/1000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 0.4787 - acc: 0.7598 - val_loss: 0.5936 - val_acc: 0.6562\n",
            "Epoch 218/1000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 0.4834 - acc: 0.7696 - val_loss: 0.6373 - val_acc: 0.6667\n",
            "Epoch 219/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5009 - acc: 0.7614 - val_loss: 0.6005 - val_acc: 0.6771\n",
            "Epoch 220/1000\n",
            "39/39 [==============================] - 4s 104ms/step - loss: 0.5158 - acc: 0.7337 - val_loss: 0.5926 - val_acc: 0.6458\n",
            "Epoch 221/1000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 0.5047 - acc: 0.7614 - val_loss: 0.6002 - val_acc: 0.6458\n",
            "Epoch 222/1000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.5070 - acc: 0.7402 - val_loss: 0.5980 - val_acc: 0.6354\n",
            "Epoch 223/1000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.4878 - acc: 0.7516 - val_loss: 0.6076 - val_acc: 0.6875\n",
            "Epoch 224/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.4708 - acc: 0.7647 - val_loss: 0.6034 - val_acc: 0.6250\n",
            "Epoch 225/1000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 0.4950 - acc: 0.7696 - val_loss: 0.5992 - val_acc: 0.6562\n",
            "Epoch 226/1000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 0.5344 - acc: 0.7402 - val_loss: 0.6106 - val_acc: 0.6667\n",
            "Epoch 227/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5185 - acc: 0.7276 - val_loss: 0.6316 - val_acc: 0.6562\n",
            "Epoch 228/1000\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 0.5249 - acc: 0.7337 - val_loss: 0.6251 - val_acc: 0.6667\n",
            "Epoch 229/1000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 0.5166 - acc: 0.7516 - val_loss: 0.6153 - val_acc: 0.6667\n",
            "Epoch 230/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.4966 - acc: 0.7467 - val_loss: 0.5884 - val_acc: 0.7083\n",
            "Epoch 231/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.4828 - acc: 0.7761 - val_loss: 0.6138 - val_acc: 0.6875\n",
            "Epoch 232/1000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5189 - acc: 0.7353 - val_loss: 0.6146 - val_acc: 0.6771\n",
            "Epoch 233/1000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.4949 - acc: 0.7451 - val_loss: 0.6166 - val_acc: 0.6875\n",
            "Epoch 234/1000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.5065 - acc: 0.7418 - val_loss: 0.6179 - val_acc: 0.6875\n",
            "Epoch 235/1000\n",
            "39/39 [==============================] - 6s 131ms/step - loss: 0.5549 - acc: 0.7239 - val_loss: 0.6183 - val_acc: 0.6875\n",
            "Epoch 236/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.4788 - acc: 0.7663 - val_loss: 0.6205 - val_acc: 0.6875\n",
            "Epoch 237/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5280 - acc: 0.7598 - val_loss: 0.5998 - val_acc: 0.6562\n",
            "Epoch 238/1000\n",
            "39/39 [==============================] - 6s 120ms/step - loss: 0.4993 - acc: 0.7337 - val_loss: 0.6400 - val_acc: 0.6562\n",
            "Epoch 239/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.4935 - acc: 0.7614 - val_loss: 0.6231 - val_acc: 0.6979\n",
            "Epoch 240/1000\n",
            "39/39 [==============================] - 10s 228ms/step - loss: 0.4856 - acc: 0.7565 - val_loss: 0.6044 - val_acc: 0.6354\n",
            "Epoch 241/1000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.5067 - acc: 0.7582 - val_loss: 0.5957 - val_acc: 0.6458\n",
            "Epoch 242/1000\n",
            "39/39 [==============================] - 5s 97ms/step - loss: 0.5461 - acc: 0.7467 - val_loss: 0.6031 - val_acc: 0.6667\n",
            "Epoch 243/1000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5355 - acc: 0.7337 - val_loss: 0.6164 - val_acc: 0.6667\n",
            "Epoch 244/1000\n",
            "39/39 [==============================] - 9s 209ms/step - loss: 0.5089 - acc: 0.7533 - val_loss: 0.6250 - val_acc: 0.6667\n",
            "Epoch 245/1000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.5280 - acc: 0.7500 - val_loss: 0.5763 - val_acc: 0.6667\n",
            "Epoch 246/1000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5397 - acc: 0.7239 - val_loss: 0.6176 - val_acc: 0.6354\n",
            "Epoch 247/1000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.4940 - acc: 0.7451 - val_loss: 0.6343 - val_acc: 0.6458\n",
            "Epoch 248/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5059 - acc: 0.7549 - val_loss: 0.5702 - val_acc: 0.6667\n",
            "Epoch 249/1000\n",
            "39/39 [==============================] - 10s 237ms/step - loss: 0.5327 - acc: 0.7320 - val_loss: 0.6222 - val_acc: 0.6458\n",
            "Epoch 250/1000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.4699 - acc: 0.7794 - val_loss: 0.6034 - val_acc: 0.6667\n",
            "Epoch 251/1000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.5128 - acc: 0.7418 - val_loss: 0.6216 - val_acc: 0.5833\n",
            "Epoch 252/1000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.5139 - acc: 0.7451 - val_loss: 0.6079 - val_acc: 0.6562\n",
            "Epoch 253/1000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5316 - acc: 0.7418 - val_loss: 0.6023 - val_acc: 0.6875\n",
            "Epoch 254/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5352 - acc: 0.7402 - val_loss: 0.6107 - val_acc: 0.6771\n",
            "Epoch 255/1000\n",
            "39/39 [==============================] - 6s 126ms/step - loss: 0.4945 - acc: 0.7696 - val_loss: 0.5956 - val_acc: 0.6354\n",
            "Epoch 256/1000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 0.5092 - acc: 0.7435 - val_loss: 0.5925 - val_acc: 0.6667\n",
            "Epoch 257/1000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.5094 - acc: 0.7614 - val_loss: 0.6067 - val_acc: 0.6458\n",
            "Epoch 258/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.4966 - acc: 0.7582 - val_loss: 0.6202 - val_acc: 0.6667\n",
            "Epoch 259/1000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 0.5225 - acc: 0.7353 - val_loss: 0.5963 - val_acc: 0.6458\n",
            "Epoch 260/1000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5088 - acc: 0.7320 - val_loss: 0.6210 - val_acc: 0.6667\n",
            "Epoch 261/1000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.5086 - acc: 0.7353 - val_loss: 0.5786 - val_acc: 0.6250\n",
            "Epoch 262/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5215 - acc: 0.7386 - val_loss: 0.6044 - val_acc: 0.6042\n",
            "Epoch 263/1000\n",
            "39/39 [==============================] - 5s 103ms/step - loss: 0.5173 - acc: 0.7435 - val_loss: 0.5729 - val_acc: 0.6771\n",
            "Epoch 264/1000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5187 - acc: 0.7565 - val_loss: 0.5847 - val_acc: 0.6354\n",
            "Epoch 265/1000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5013 - acc: 0.7631 - val_loss: 0.5652 - val_acc: 0.6458\n",
            "Epoch 266/1000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.5139 - acc: 0.7565 - val_loss: 0.5822 - val_acc: 0.6250\n",
            "Epoch 267/1000\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 0.5202 - acc: 0.7500 - val_loss: 0.5693 - val_acc: 0.6458\n",
            "Epoch 268/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5296 - acc: 0.7304 - val_loss: 0.5850 - val_acc: 0.6562\n",
            "Epoch 269/1000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.5339 - acc: 0.7141 - val_loss: 0.5984 - val_acc: 0.6979\n",
            "Epoch 270/1000\n",
            "39/39 [==============================] - 9s 209ms/step - loss: 0.5052 - acc: 0.7533 - val_loss: 0.6118 - val_acc: 0.6771\n",
            "Epoch 271/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5275 - acc: 0.7565 - val_loss: 0.5985 - val_acc: 0.6146\n",
            "Epoch 272/1000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.5222 - acc: 0.7435 - val_loss: 0.5809 - val_acc: 0.6458\n",
            "Epoch 273/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5008 - acc: 0.7500 - val_loss: 0.5713 - val_acc: 0.6354\n",
            "Epoch 274/1000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 0.5302 - acc: 0.7369 - val_loss: 0.6018 - val_acc: 0.6771\n",
            "Epoch 275/1000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.5217 - acc: 0.7451 - val_loss: 0.5783 - val_acc: 0.6250\n",
            "Epoch 276/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5444 - acc: 0.7271 - val_loss: 0.5995 - val_acc: 0.6875\n",
            "Epoch 277/1000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5035 - acc: 0.7500 - val_loss: 0.6051 - val_acc: 0.6875\n",
            "Epoch 278/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5566 - acc: 0.7533 - val_loss: 0.6072 - val_acc: 0.6667\n",
            "Epoch 279/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5192 - acc: 0.7337 - val_loss: 0.6214 - val_acc: 0.7083\n",
            "Epoch 280/1000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.5146 - acc: 0.7369 - val_loss: 0.6104 - val_acc: 0.6875\n",
            "Epoch 281/1000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 0.5484 - acc: 0.7108 - val_loss: 0.5861 - val_acc: 0.6979\n",
            "Epoch 282/1000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5086 - acc: 0.7565 - val_loss: 0.5908 - val_acc: 0.6875\n",
            "Epoch 283/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5016 - acc: 0.7467 - val_loss: 0.5950 - val_acc: 0.6562\n",
            "Epoch 284/1000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.4899 - acc: 0.7533 - val_loss: 0.6072 - val_acc: 0.6562\n",
            "Epoch 285/1000\n",
            "39/39 [==============================] - 6s 139ms/step - loss: 0.5215 - acc: 0.7369 - val_loss: 0.5909 - val_acc: 0.7083\n",
            "Epoch 286/1000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5184 - acc: 0.7467 - val_loss: 0.6044 - val_acc: 0.6667\n",
            "Epoch 287/1000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 0.5023 - acc: 0.7663 - val_loss: 0.5736 - val_acc: 0.6562\n",
            "Epoch 288/1000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 0.4892 - acc: 0.7435 - val_loss: 0.5905 - val_acc: 0.6458\n",
            "Epoch 289/1000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5082 - acc: 0.7451 - val_loss: 0.5762 - val_acc: 0.6458\n",
            "Epoch 290/1000\n",
            "39/39 [==============================] - 5s 117ms/step - loss: 0.5123 - acc: 0.7451 - val_loss: 0.5730 - val_acc: 0.6562\n",
            "Epoch 291/1000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.5434 - acc: 0.7435 - val_loss: 0.5897 - val_acc: 0.6562\n",
            "Epoch 292/1000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5295 - acc: 0.7222 - val_loss: 0.5859 - val_acc: 0.6667\n",
            "Epoch 293/1000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5121 - acc: 0.7631 - val_loss: 0.5709 - val_acc: 0.6562\n",
            "Epoch 294/1000\n",
            "39/39 [==============================] - 10s 235ms/step - loss: 0.5128 - acc: 0.7516 - val_loss: 0.5723 - val_acc: 0.6562\n",
            "Epoch 295/1000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 0.5301 - acc: 0.7304 - val_loss: 0.5729 - val_acc: 0.6354\n",
            "Epoch 296/1000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 0.5200 - acc: 0.7467 - val_loss: 0.5587 - val_acc: 0.6562\n",
            "Epoch 297/1000\n",
            "39/39 [==============================] - 5s 95ms/step - loss: 0.5331 - acc: 0.7386 - val_loss: 0.5725 - val_acc: 0.6771\n",
            "Epoch 298/1000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 0.5339 - acc: 0.7582 - val_loss: 0.6004 - val_acc: 0.6458\n",
            "Epoch 299/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5185 - acc: 0.7484 - val_loss: 0.6048 - val_acc: 0.6771\n",
            "Epoch 300/1000\n",
            "39/39 [==============================] - 10s 238ms/step - loss: 0.4951 - acc: 0.7451 - val_loss: 0.6043 - val_acc: 0.6875\n",
            "Epoch 301/1000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5499 - acc: 0.7451 - val_loss: 0.5629 - val_acc: 0.6771\n",
            "Epoch 302/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5314 - acc: 0.7042 - val_loss: 0.6157 - val_acc: 0.6667\n",
            "Epoch 303/1000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.5629 - acc: 0.7533 - val_loss: 0.5824 - val_acc: 0.6979\n",
            "Epoch 304/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5502 - acc: 0.7190 - val_loss: 0.6132 - val_acc: 0.6667\n",
            "Epoch 305/1000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.4944 - acc: 0.7549 - val_loss: 0.5813 - val_acc: 0.6562\n",
            "Epoch 306/1000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.5059 - acc: 0.7467 - val_loss: 0.5872 - val_acc: 0.6354\n",
            "Epoch 307/1000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.4949 - acc: 0.7696 - val_loss: 0.5705 - val_acc: 0.6458\n",
            "Epoch 308/1000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 0.4989 - acc: 0.7598 - val_loss: 0.5906 - val_acc: 0.6875\n",
            "Epoch 309/1000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.4932 - acc: 0.7565 - val_loss: 0.5982 - val_acc: 0.6875\n",
            "Epoch 310/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.4782 - acc: 0.7631 - val_loss: 0.5940 - val_acc: 0.6771\n",
            "Epoch 311/1000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.4634 - acc: 0.7794 - val_loss: 0.5850 - val_acc: 0.6875\n",
            "Epoch 312/1000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.5272 - acc: 0.7484 - val_loss: 0.5790 - val_acc: 0.6667\n",
            "Epoch 313/1000\n",
            "39/39 [==============================] - 5s 115ms/step - loss: 0.5133 - acc: 0.7549 - val_loss: 0.5906 - val_acc: 0.6771\n",
            "Epoch 314/1000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 0.5434 - acc: 0.7337 - val_loss: 0.6162 - val_acc: 0.6458\n",
            "Epoch 315/1000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.5151 - acc: 0.7353 - val_loss: 0.6088 - val_acc: 0.6875\n",
            "Epoch 316/1000\n",
            "39/39 [==============================] - 5s 98ms/step - loss: 0.5126 - acc: 0.7631 - val_loss: 0.6004 - val_acc: 0.6667\n",
            "Epoch 317/1000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5114 - acc: 0.7222 - val_loss: 0.5985 - val_acc: 0.6354\n",
            "Epoch 318/1000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 0.5136 - acc: 0.7696 - val_loss: 0.5747 - val_acc: 0.6458\n",
            "Epoch 319/1000\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 0.5048 - acc: 0.7402 - val_loss: 0.5868 - val_acc: 0.6667\n",
            "Epoch 320/1000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 0.5277 - acc: 0.7222 - val_loss: 0.6153 - val_acc: 0.6667\n",
            "Epoch 321/1000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5534 - acc: 0.7141 - val_loss: 0.6048 - val_acc: 0.6979\n",
            "Epoch 322/1000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.5095 - acc: 0.7271 - val_loss: 0.6104 - val_acc: 0.6979\n",
            "Epoch 323/1000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 0.4940 - acc: 0.7631 - val_loss: 0.6305 - val_acc: 0.6771\n",
            "Epoch 324/1000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5119 - acc: 0.7320 - val_loss: 0.6230 - val_acc: 0.6979\n",
            "Epoch 325/1000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.5229 - acc: 0.7386 - val_loss: 0.6168 - val_acc: 0.6979\n",
            "Epoch 326/1000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5113 - acc: 0.7467 - val_loss: 0.5970 - val_acc: 0.6354\n",
            "Epoch 327/1000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.5141 - acc: 0.7696 - val_loss: 0.5968 - val_acc: 0.6354\n",
            "Epoch 328/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5357 - acc: 0.7271 - val_loss: 0.6039 - val_acc: 0.6979\n",
            "Epoch 329/1000\n",
            "39/39 [==============================] - 10s 237ms/step - loss: 0.5041 - acc: 0.7516 - val_loss: 0.5984 - val_acc: 0.6771\n",
            "Epoch 330/1000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5250 - acc: 0.7451 - val_loss: 0.6290 - val_acc: 0.6875\n",
            "Epoch 331/1000\n",
            "39/39 [==============================] - 5s 102ms/step - loss: 0.4934 - acc: 0.7582 - val_loss: 0.6102 - val_acc: 0.6354\n",
            "Epoch 332/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.4830 - acc: 0.7565 - val_loss: 0.6070 - val_acc: 0.6875\n",
            "Epoch 333/1000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.5339 - acc: 0.7190 - val_loss: 0.5985 - val_acc: 0.6354\n",
            "Epoch 334/1000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5077 - acc: 0.7582 - val_loss: 0.6006 - val_acc: 0.6667\n",
            "Epoch 335/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5163 - acc: 0.7565 - val_loss: 0.5993 - val_acc: 0.6458\n",
            "Epoch 336/1000\n",
            "39/39 [==============================] - 9s 208ms/step - loss: 0.5172 - acc: 0.7418 - val_loss: 0.5977 - val_acc: 0.6875\n",
            "Epoch 337/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5506 - acc: 0.7288 - val_loss: 0.5881 - val_acc: 0.6667\n",
            "Epoch 338/1000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 0.5199 - acc: 0.7386 - val_loss: 0.6146 - val_acc: 0.6875\n",
            "Epoch 339/1000\n",
            "39/39 [==============================] - 5s 114ms/step - loss: 0.4840 - acc: 0.7435 - val_loss: 0.5894 - val_acc: 0.6458\n",
            "Epoch 340/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.5448 - acc: 0.7271 - val_loss: 0.5858 - val_acc: 0.6458\n",
            "Epoch 341/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.4963 - acc: 0.7663 - val_loss: 0.5826 - val_acc: 0.6562\n",
            "Epoch 342/1000\n",
            "39/39 [==============================] - 5s 94ms/step - loss: 0.4855 - acc: 0.7614 - val_loss: 0.5780 - val_acc: 0.6354\n",
            "Epoch 343/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5104 - acc: 0.7500 - val_loss: 0.5954 - val_acc: 0.6979\n",
            "Epoch 344/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.4970 - acc: 0.7418 - val_loss: 0.5972 - val_acc: 0.6979\n",
            "Epoch 345/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5231 - acc: 0.7435 - val_loss: 0.5862 - val_acc: 0.6667\n",
            "Epoch 346/1000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.4945 - acc: 0.7598 - val_loss: 0.5815 - val_acc: 0.6458\n",
            "Epoch 347/1000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 0.4985 - acc: 0.7663 - val_loss: 0.5942 - val_acc: 0.6458\n",
            "Epoch 348/1000\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 0.5155 - acc: 0.7386 - val_loss: 0.6141 - val_acc: 0.6771\n",
            "Epoch 349/1000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.5220 - acc: 0.7353 - val_loss: 0.6039 - val_acc: 0.6667\n",
            "Epoch 350/1000\n",
            "39/39 [==============================] - 6s 141ms/step - loss: 0.4949 - acc: 0.7533 - val_loss: 0.6078 - val_acc: 0.6667\n",
            "Epoch 351/1000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5107 - acc: 0.7369 - val_loss: 0.6145 - val_acc: 0.6354\n",
            "Epoch 352/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.4908 - acc: 0.7533 - val_loss: 0.5898 - val_acc: 0.6667\n",
            "Epoch 353/1000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.5572 - acc: 0.7141 - val_loss: 0.5977 - val_acc: 0.6458\n",
            "Epoch 354/1000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.4986 - acc: 0.7500 - val_loss: 0.5837 - val_acc: 0.6562\n",
            "Epoch 355/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.4935 - acc: 0.7614 - val_loss: 0.6108 - val_acc: 0.6771\n",
            "Epoch 356/1000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 0.5165 - acc: 0.7418 - val_loss: 0.6090 - val_acc: 0.6354\n",
            "Epoch 357/1000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5070 - acc: 0.7549 - val_loss: 0.6088 - val_acc: 0.6354\n",
            "Epoch 358/1000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5053 - acc: 0.7582 - val_loss: 0.5892 - val_acc: 0.6562\n",
            "Epoch 359/1000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.5134 - acc: 0.7353 - val_loss: 0.5924 - val_acc: 0.6458\n",
            "Epoch 360/1000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.5018 - acc: 0.7402 - val_loss: 0.5886 - val_acc: 0.6562\n",
            "Epoch 361/1000\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 0.5159 - acc: 0.7386 - val_loss: 0.5906 - val_acc: 0.6771\n",
            "Epoch 362/1000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.4887 - acc: 0.7876 - val_loss: 0.6251 - val_acc: 0.6771\n",
            "Epoch 363/1000\n",
            "39/39 [==============================] - 5s 102ms/step - loss: 0.5157 - acc: 0.7500 - val_loss: 0.5948 - val_acc: 0.6458\n",
            "Epoch 364/1000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5179 - acc: 0.7549 - val_loss: 0.5971 - val_acc: 0.6562\n",
            "Epoch 365/1000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.4921 - acc: 0.7565 - val_loss: 0.6068 - val_acc: 0.6667\n",
            "Epoch 366/1000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 0.4761 - acc: 0.7843 - val_loss: 0.5731 - val_acc: 0.6354\n",
            "Epoch 367/1000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.5132 - acc: 0.7614 - val_loss: 0.5850 - val_acc: 0.6771\n",
            "Epoch 368/1000\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 0.5241 - acc: 0.7582 - val_loss: 0.5993 - val_acc: 0.6562\n",
            "Epoch 369/1000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5146 - acc: 0.7549 - val_loss: 0.5885 - val_acc: 0.6562\n",
            "Epoch 370/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5438 - acc: 0.7304 - val_loss: 0.5902 - val_acc: 0.6562\n",
            "Epoch 371/1000\n",
            "39/39 [==============================] - 10s 251ms/step - loss: 0.5247 - acc: 0.7451 - val_loss: 0.6085 - val_acc: 0.6458\n",
            "Epoch 372/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.4763 - acc: 0.7451 - val_loss: 0.6002 - val_acc: 0.6667\n",
            "Epoch 373/1000\n",
            "39/39 [==============================] - 9s 232ms/step - loss: 0.5143 - acc: 0.7386 - val_loss: 0.6031 - val_acc: 0.6562\n",
            "Epoch 374/1000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.5255 - acc: 0.7533 - val_loss: 0.5741 - val_acc: 0.6354\n",
            "Epoch 375/1000\n",
            "39/39 [==============================] - 10s 238ms/step - loss: 0.5235 - acc: 0.7353 - val_loss: 0.5911 - val_acc: 0.6562\n",
            "Epoch 376/1000\n",
            "39/39 [==============================] - 9s 233ms/step - loss: 0.5110 - acc: 0.7614 - val_loss: 0.5855 - val_acc: 0.6667\n",
            "Epoch 377/1000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5164 - acc: 0.7353 - val_loss: 0.5799 - val_acc: 0.6562\n",
            "Epoch 378/1000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 0.5603 - acc: 0.7019 - val_loss: 0.5740 - val_acc: 0.6667\n",
            "Epoch 379/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.4732 - acc: 0.7631 - val_loss: 0.5814 - val_acc: 0.6458\n",
            "Epoch 380/1000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.5332 - acc: 0.7386 - val_loss: 0.5781 - val_acc: 0.6354\n",
            "Epoch 381/1000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 0.5129 - acc: 0.7435 - val_loss: 0.5774 - val_acc: 0.6562\n",
            "Epoch 382/1000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.5192 - acc: 0.7369 - val_loss: 0.5966 - val_acc: 0.6562\n",
            "Epoch 383/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.4898 - acc: 0.7712 - val_loss: 0.5697 - val_acc: 0.6667\n",
            "Epoch 384/1000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.5212 - acc: 0.7467 - val_loss: 0.5691 - val_acc: 0.6667\n",
            "Epoch 385/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5361 - acc: 0.7141 - val_loss: 0.5975 - val_acc: 0.6562\n",
            "Epoch 386/1000\n",
            "39/39 [==============================] - 5s 117ms/step - loss: 0.4975 - acc: 0.7386 - val_loss: 0.5937 - val_acc: 0.6667\n",
            "Epoch 387/1000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 0.5487 - acc: 0.7320 - val_loss: 0.5789 - val_acc: 0.6458\n",
            "Epoch 388/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5424 - acc: 0.7386 - val_loss: 0.5916 - val_acc: 0.6771\n",
            "Epoch 389/1000\n",
            "39/39 [==============================] - 5s 101ms/step - loss: 0.5013 - acc: 0.7353 - val_loss: 0.6170 - val_acc: 0.6458\n",
            "Epoch 390/1000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5326 - acc: 0.7369 - val_loss: 0.5829 - val_acc: 0.6667\n",
            "Epoch 391/1000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.5030 - acc: 0.7582 - val_loss: 0.5855 - val_acc: 0.6354\n",
            "Epoch 392/1000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.5171 - acc: 0.7304 - val_loss: 0.5898 - val_acc: 0.6354\n",
            "Epoch 393/1000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.4662 - acc: 0.7761 - val_loss: 0.5856 - val_acc: 0.6458\n",
            "Epoch 394/1000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.5385 - acc: 0.7190 - val_loss: 0.5820 - val_acc: 0.6250\n",
            "Epoch 395/1000\n",
            "39/39 [==============================] - 10s 235ms/step - loss: 0.5511 - acc: 0.7124 - val_loss: 0.6008 - val_acc: 0.6562\n",
            "Epoch 396/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5092 - acc: 0.7451 - val_loss: 0.5794 - val_acc: 0.6354\n",
            "Epoch 397/1000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5442 - acc: 0.7304 - val_loss: 0.5611 - val_acc: 0.6458\n",
            "Epoch 398/1000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.5285 - acc: 0.7353 - val_loss: 0.5856 - val_acc: 0.6771\n",
            "Epoch 399/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5521 - acc: 0.7206 - val_loss: 0.5674 - val_acc: 0.6979\n",
            "Epoch 400/1000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 0.5184 - acc: 0.7533 - val_loss: 0.5817 - val_acc: 0.6354\n",
            "Epoch 401/1000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.4817 - acc: 0.7582 - val_loss: 0.5904 - val_acc: 0.6458\n",
            "Epoch 402/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5020 - acc: 0.7451 - val_loss: 0.5910 - val_acc: 0.6667\n",
            "Epoch 403/1000\n",
            "39/39 [==============================] - 9s 232ms/step - loss: 0.5395 - acc: 0.7304 - val_loss: 0.5966 - val_acc: 0.6771\n",
            "Epoch 404/1000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.5223 - acc: 0.7386 - val_loss: 0.6280 - val_acc: 0.6667\n",
            "Epoch 405/1000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 0.5109 - acc: 0.7631 - val_loss: 0.6186 - val_acc: 0.6458\n",
            "Epoch 406/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5176 - acc: 0.7337 - val_loss: 0.6114 - val_acc: 0.6667\n",
            "Epoch 407/1000\n",
            "39/39 [==============================] - 6s 131ms/step - loss: 0.5227 - acc: 0.7435 - val_loss: 0.5810 - val_acc: 0.6458\n",
            "Epoch 408/1000\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 0.5541 - acc: 0.7369 - val_loss: 0.6094 - val_acc: 0.6562\n",
            "Epoch 409/1000\n",
            "39/39 [==============================] - 10s 233ms/step - loss: 0.5216 - acc: 0.7484 - val_loss: 0.6137 - val_acc: 0.6458\n",
            "Epoch 410/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5105 - acc: 0.7402 - val_loss: 0.5854 - val_acc: 0.6250\n",
            "Epoch 411/1000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.4991 - acc: 0.7631 - val_loss: 0.5920 - val_acc: 0.6458\n",
            "Epoch 412/1000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 0.4986 - acc: 0.7516 - val_loss: 0.5968 - val_acc: 0.6667\n",
            "Epoch 413/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5149 - acc: 0.7386 - val_loss: 0.6138 - val_acc: 0.6667\n",
            "Epoch 414/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.4986 - acc: 0.7353 - val_loss: 0.5916 - val_acc: 0.6771\n",
            "Epoch 415/1000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5170 - acc: 0.7451 - val_loss: 0.6072 - val_acc: 0.6562\n",
            "Epoch 416/1000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.4907 - acc: 0.7549 - val_loss: 0.6015 - val_acc: 0.6250\n",
            "Epoch 417/1000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 0.4991 - acc: 0.7614 - val_loss: 0.6122 - val_acc: 0.6875\n",
            "Epoch 418/1000\n",
            "39/39 [==============================] - 5s 94ms/step - loss: 0.5116 - acc: 0.7533 - val_loss: 0.6080 - val_acc: 0.6146\n",
            "Epoch 419/1000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.4819 - acc: 0.7745 - val_loss: 0.5773 - val_acc: 0.6771\n",
            "Epoch 420/1000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.4943 - acc: 0.7647 - val_loss: 0.5731 - val_acc: 0.6562\n",
            "Epoch 421/1000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5100 - acc: 0.7533 - val_loss: 0.6485 - val_acc: 0.6875\n",
            "Epoch 422/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5370 - acc: 0.7402 - val_loss: 0.6111 - val_acc: 0.6042\n",
            "Epoch 423/1000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5309 - acc: 0.7190 - val_loss: 0.5699 - val_acc: 0.6458\n",
            "Epoch 424/1000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5018 - acc: 0.7614 - val_loss: 0.6087 - val_acc: 0.6250\n",
            "Epoch 425/1000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 0.4978 - acc: 0.7712 - val_loss: 0.6069 - val_acc: 0.6979\n",
            "Epoch 426/1000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.4981 - acc: 0.7402 - val_loss: 0.5895 - val_acc: 0.6250\n",
            "Epoch 427/1000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.4897 - acc: 0.7500 - val_loss: 0.5797 - val_acc: 0.6354\n",
            "Epoch 428/1000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5065 - acc: 0.7549 - val_loss: 0.5858 - val_acc: 0.6250\n",
            "Epoch 429/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5234 - acc: 0.7418 - val_loss: 0.6074 - val_acc: 0.6875\n",
            "Epoch 430/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5200 - acc: 0.7484 - val_loss: 0.5812 - val_acc: 0.6771\n",
            "Epoch 431/1000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.5014 - acc: 0.7843 - val_loss: 0.5913 - val_acc: 0.6250\n",
            "Epoch 432/1000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.5093 - acc: 0.7680 - val_loss: 0.5729 - val_acc: 0.6562\n",
            "Epoch 433/1000\n",
            "39/39 [==============================] - 9s 233ms/step - loss: 0.5260 - acc: 0.7435 - val_loss: 0.5890 - val_acc: 0.6771\n",
            "Epoch 434/1000\n",
            "39/39 [==============================] - 5s 122ms/step - loss: 0.5306 - acc: 0.7288 - val_loss: 0.5843 - val_acc: 0.6771\n",
            "Epoch 435/1000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5662 - acc: 0.6912 - val_loss: 0.5986 - val_acc: 0.6146\n",
            "Epoch 436/1000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.5090 - acc: 0.7288 - val_loss: 0.5877 - val_acc: 0.6667\n",
            "Epoch 437/1000\n",
            "39/39 [==============================] - 5s 101ms/step - loss: 0.5162 - acc: 0.7337 - val_loss: 0.5980 - val_acc: 0.6458\n",
            "Epoch 438/1000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 0.5189 - acc: 0.7565 - val_loss: 0.6107 - val_acc: 0.6562\n",
            "Epoch 439/1000\n",
            "39/39 [==============================] - 6s 121ms/step - loss: 0.4970 - acc: 0.7451 - val_loss: 0.5967 - val_acc: 0.6146\n",
            "Epoch 440/1000\n",
            "39/39 [==============================] - 5s 122ms/step - loss: 0.4861 - acc: 0.7614 - val_loss: 0.6137 - val_acc: 0.6562\n",
            "Epoch 441/1000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.4932 - acc: 0.7663 - val_loss: 0.6219 - val_acc: 0.6562\n",
            "Epoch 442/1000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 0.5192 - acc: 0.7418 - val_loss: 0.6070 - val_acc: 0.6458\n",
            "Epoch 443/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5117 - acc: 0.7386 - val_loss: 0.6171 - val_acc: 0.6667\n",
            "Epoch 444/1000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.4874 - acc: 0.7598 - val_loss: 0.5910 - val_acc: 0.6562\n",
            "Epoch 445/1000\n",
            "39/39 [==============================] - 6s 128ms/step - loss: 0.5195 - acc: 0.7402 - val_loss: 0.5959 - val_acc: 0.6354\n",
            "Epoch 446/1000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5042 - acc: 0.7418 - val_loss: 0.6002 - val_acc: 0.6250\n",
            "Epoch 447/1000\n",
            "39/39 [==============================] - 5s 128ms/step - loss: 0.5765 - acc: 0.6993 - val_loss: 0.6210 - val_acc: 0.6667\n",
            "Epoch 448/1000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.5179 - acc: 0.7353 - val_loss: 0.6158 - val_acc: 0.6458\n",
            "Epoch 449/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.5566 - acc: 0.7402 - val_loss: 0.5866 - val_acc: 0.6354\n",
            "Epoch 450/1000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.4995 - acc: 0.7614 - val_loss: 0.5891 - val_acc: 0.6250\n",
            "Epoch 451/1000\n",
            "39/39 [==============================] - 5s 103ms/step - loss: 0.5421 - acc: 0.7271 - val_loss: 0.5993 - val_acc: 0.6875\n",
            "Epoch 452/1000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.5069 - acc: 0.7418 - val_loss: 0.6108 - val_acc: 0.6146\n",
            "Epoch 453/1000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.4889 - acc: 0.7582 - val_loss: 0.6119 - val_acc: 0.6562\n",
            "Epoch 454/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.4928 - acc: 0.7516 - val_loss: 0.5926 - val_acc: 0.6146\n",
            "Epoch 455/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.4942 - acc: 0.7663 - val_loss: 0.6058 - val_acc: 0.6146\n",
            "Epoch 456/1000\n",
            "39/39 [==============================] - 10s 227ms/step - loss: 0.4816 - acc: 0.7729 - val_loss: 0.5954 - val_acc: 0.6667\n",
            "Epoch 457/1000\n",
            "39/39 [==============================] - 5s 113ms/step - loss: 0.5195 - acc: 0.7435 - val_loss: 0.5967 - val_acc: 0.6146\n",
            "Epoch 458/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5138 - acc: 0.7369 - val_loss: 0.5803 - val_acc: 0.6667\n",
            "Epoch 459/1000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5192 - acc: 0.7353 - val_loss: 0.6073 - val_acc: 0.6250\n",
            "Epoch 460/1000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5126 - acc: 0.7435 - val_loss: 0.6316 - val_acc: 0.6458\n",
            "Epoch 461/1000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.5077 - acc: 0.7680 - val_loss: 0.6122 - val_acc: 0.6146\n",
            "Epoch 462/1000\n",
            "39/39 [==============================] - 10s 236ms/step - loss: 0.5301 - acc: 0.7353 - val_loss: 0.6350 - val_acc: 0.6667\n",
            "Epoch 463/1000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.5009 - acc: 0.7533 - val_loss: 0.6115 - val_acc: 0.6458\n",
            "Epoch 464/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.4731 - acc: 0.7761 - val_loss: 0.6176 - val_acc: 0.6875\n",
            "Epoch 465/1000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.4705 - acc: 0.7843 - val_loss: 0.6208 - val_acc: 0.6667\n",
            "Epoch 466/1000\n",
            "39/39 [==============================] - 10s 241ms/step - loss: 0.4873 - acc: 0.7484 - val_loss: 0.6109 - val_acc: 0.6562\n",
            "Epoch 467/1000\n",
            "39/39 [==============================] - 11s 260ms/step - loss: 0.4720 - acc: 0.7908 - val_loss: 0.6199 - val_acc: 0.6458\n",
            "Epoch 468/1000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 0.5097 - acc: 0.7451 - val_loss: 0.6209 - val_acc: 0.6354\n",
            "Epoch 469/1000\n",
            "39/39 [==============================] - 5s 102ms/step - loss: 0.5163 - acc: 0.7500 - val_loss: 0.6038 - val_acc: 0.6458\n",
            "Epoch 470/1000\n",
            "39/39 [==============================] - 5s 100ms/step - loss: 0.5226 - acc: 0.7484 - val_loss: 0.6053 - val_acc: 0.6771\n",
            "Epoch 471/1000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.5170 - acc: 0.7369 - val_loss: 0.6211 - val_acc: 0.6458\n",
            "Epoch 472/1000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.5507 - acc: 0.7190 - val_loss: 0.6173 - val_acc: 0.6354\n",
            "Epoch 473/1000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5390 - acc: 0.7141 - val_loss: 0.6027 - val_acc: 0.6562\n",
            "Epoch 474/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5001 - acc: 0.7467 - val_loss: 0.6160 - val_acc: 0.6771\n",
            "Epoch 475/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5050 - acc: 0.7435 - val_loss: 0.6204 - val_acc: 0.6458\n",
            "Epoch 476/1000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.5196 - acc: 0.7337 - val_loss: 0.6162 - val_acc: 0.6562\n",
            "Epoch 477/1000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 0.4886 - acc: 0.7745 - val_loss: 0.6124 - val_acc: 0.6771\n",
            "Epoch 478/1000\n",
            "39/39 [==============================] - 10s 235ms/step - loss: 0.5290 - acc: 0.7157 - val_loss: 0.6075 - val_acc: 0.6562\n",
            "Epoch 479/1000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5031 - acc: 0.7549 - val_loss: 0.5885 - val_acc: 0.6667\n",
            "Epoch 480/1000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.4747 - acc: 0.7692 - val_loss: 0.6206 - val_acc: 0.6667\n",
            "Epoch 481/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.4915 - acc: 0.7761 - val_loss: 0.6038 - val_acc: 0.6354\n",
            "Epoch 482/1000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5066 - acc: 0.7614 - val_loss: 0.6122 - val_acc: 0.6562\n",
            "Epoch 483/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5311 - acc: 0.7353 - val_loss: 0.6108 - val_acc: 0.6771\n",
            "Epoch 484/1000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5036 - acc: 0.7631 - val_loss: 0.6183 - val_acc: 0.6771\n",
            "Epoch 485/1000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.5087 - acc: 0.7369 - val_loss: 0.6109 - val_acc: 0.6562\n",
            "Epoch 486/1000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.4802 - acc: 0.7582 - val_loss: 0.5888 - val_acc: 0.6250\n",
            "Epoch 487/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5398 - acc: 0.7288 - val_loss: 0.5973 - val_acc: 0.6771\n",
            "Epoch 488/1000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.5129 - acc: 0.7222 - val_loss: 0.5828 - val_acc: 0.6667\n",
            "Epoch 489/1000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.5130 - acc: 0.7386 - val_loss: 0.5692 - val_acc: 0.6458\n",
            "Epoch 490/1000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5037 - acc: 0.7516 - val_loss: 0.6239 - val_acc: 0.6771\n",
            "Epoch 491/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5159 - acc: 0.7467 - val_loss: 0.5870 - val_acc: 0.6667\n",
            "Epoch 492/1000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5119 - acc: 0.7500 - val_loss: 0.6155 - val_acc: 0.6667\n",
            "Epoch 493/1000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 0.4982 - acc: 0.7467 - val_loss: 0.6179 - val_acc: 0.6771\n",
            "Epoch 494/1000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 0.5054 - acc: 0.7631 - val_loss: 0.6131 - val_acc: 0.6667\n",
            "Epoch 495/1000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.4914 - acc: 0.7435 - val_loss: 0.5940 - val_acc: 0.6354\n",
            "Epoch 496/1000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 0.5085 - acc: 0.7255 - val_loss: 0.6190 - val_acc: 0.6146\n",
            "Epoch 497/1000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 0.5093 - acc: 0.7451 - val_loss: 0.6041 - val_acc: 0.6562\n",
            "Epoch 498/1000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 0.4993 - acc: 0.7598 - val_loss: 0.5771 - val_acc: 0.6875\n",
            "Epoch 499/1000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 0.5133 - acc: 0.7418 - val_loss: 0.6127 - val_acc: 0.6667\n",
            "Epoch 500/1000\n",
            "39/39 [==============================] - 9s 233ms/step - loss: 0.5295 - acc: 0.7353 - val_loss: 0.5968 - val_acc: 0.5938\n",
            "Epoch 501/1000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 0.5285 - acc: 0.7369 - val_loss: 0.6121 - val_acc: 0.6354\n",
            "Epoch 502/1000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 0.5102 - acc: 0.7353 - val_loss: 0.6176 - val_acc: 0.6979\n",
            "Epoch 503/1000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.5263 - acc: 0.7222 - val_loss: 0.5698 - val_acc: 0.6667\n",
            "Epoch 504/1000\n",
            "39/39 [==============================] - 5s 121ms/step - loss: 0.5118 - acc: 0.7404 - val_loss: 0.5947 - val_acc: 0.6875\n",
            "Epoch 505/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.4841 - acc: 0.7647 - val_loss: 0.5894 - val_acc: 0.6771\n",
            "Epoch 506/1000\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 0.4792 - acc: 0.7582 - val_loss: 0.6158 - val_acc: 0.6771\n",
            "Epoch 507/1000\n",
            "39/39 [==============================] - 5s 102ms/step - loss: 0.5196 - acc: 0.7353 - val_loss: 0.6054 - val_acc: 0.6667\n",
            "Epoch 508/1000\n",
            "39/39 [==============================] - 5s 96ms/step - loss: 0.5048 - acc: 0.7500 - val_loss: 0.5899 - val_acc: 0.6250\n",
            "Epoch 509/1000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.4906 - acc: 0.7614 - val_loss: 0.5860 - val_acc: 0.6771\n",
            "Epoch 510/1000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.5073 - acc: 0.7402 - val_loss: 0.5977 - val_acc: 0.6875\n",
            "Epoch 511/1000\n",
            "39/39 [==============================] - 6s 158ms/step - loss: 0.4964 - acc: 0.7533 - val_loss: 0.6166 - val_acc: 0.6875\n",
            "Epoch 512/1000\n",
            "39/39 [==============================] - 10s 242ms/step - loss: 0.4840 - acc: 0.7663 - val_loss: 0.6467 - val_acc: 0.6562\n",
            "Epoch 513/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5382 - acc: 0.7271 - val_loss: 0.6076 - val_acc: 0.6562\n",
            "Epoch 514/1000\n",
            "39/39 [==============================] - 5s 118ms/step - loss: 0.5142 - acc: 0.7402 - val_loss: 0.6155 - val_acc: 0.6667\n",
            "Epoch 515/1000\n",
            "39/39 [==============================] - 10s 241ms/step - loss: 0.5148 - acc: 0.7353 - val_loss: 0.6112 - val_acc: 0.6562\n",
            "Epoch 516/1000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5180 - acc: 0.7451 - val_loss: 0.6113 - val_acc: 0.6771\n",
            "Epoch 517/1000\n",
            "39/39 [==============================] - 11s 258ms/step - loss: 0.5382 - acc: 0.7337 - val_loss: 0.6211 - val_acc: 0.6667\n",
            "Epoch 518/1000\n",
            "39/39 [==============================] - 6s 138ms/step - loss: 0.5236 - acc: 0.7647 - val_loss: 0.6358 - val_acc: 0.6667\n",
            "Epoch 519/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.5179 - acc: 0.7386 - val_loss: 0.6161 - val_acc: 0.6354\n",
            "Epoch 520/1000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5204 - acc: 0.7451 - val_loss: 0.6354 - val_acc: 0.6667\n",
            "Epoch 521/1000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5021 - acc: 0.7729 - val_loss: 0.6053 - val_acc: 0.6667\n",
            "Epoch 522/1000\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 0.5013 - acc: 0.7647 - val_loss: 0.5873 - val_acc: 0.6875\n",
            "Epoch 523/1000\n",
            "39/39 [==============================] - 5s 103ms/step - loss: 0.5357 - acc: 0.7173 - val_loss: 0.5843 - val_acc: 0.6979\n",
            "Epoch 524/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.4997 - acc: 0.7533 - val_loss: 0.6166 - val_acc: 0.6875\n",
            "Epoch 525/1000\n",
            "39/39 [==============================] - 10s 235ms/step - loss: 0.5335 - acc: 0.7549 - val_loss: 0.5986 - val_acc: 0.6771\n",
            "Epoch 526/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5164 - acc: 0.7418 - val_loss: 0.5847 - val_acc: 0.6667\n",
            "Epoch 527/1000\n",
            "39/39 [==============================] - 5s 103ms/step - loss: 0.4816 - acc: 0.7925 - val_loss: 0.5916 - val_acc: 0.6562\n",
            "Epoch 528/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5289 - acc: 0.7304 - val_loss: 0.6027 - val_acc: 0.6875\n",
            "Epoch 529/1000\n",
            "39/39 [==============================] - 5s 103ms/step - loss: 0.5161 - acc: 0.7386 - val_loss: 0.6160 - val_acc: 0.6771\n",
            "Epoch 530/1000\n",
            "39/39 [==============================] - 10s 234ms/step - loss: 0.5088 - acc: 0.7369 - val_loss: 0.6252 - val_acc: 0.6667\n",
            "Epoch 531/1000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 0.5198 - acc: 0.7304 - val_loss: 0.5865 - val_acc: 0.7083\n",
            "Epoch 532/1000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5135 - acc: 0.7516 - val_loss: 0.6046 - val_acc: 0.6875\n",
            "Epoch 533/1000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 0.5283 - acc: 0.7402 - val_loss: 0.6033 - val_acc: 0.6354\n",
            "Epoch 534/1000\n",
            "39/39 [==============================] - 6s 135ms/step - loss: 0.4712 - acc: 0.7565 - val_loss: 0.6155 - val_acc: 0.6771\n",
            "Epoch 535/1000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 0.5335 - acc: 0.7304 - val_loss: 0.6160 - val_acc: 0.6771\n",
            "Epoch 536/1000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.4801 - acc: 0.7712 - val_loss: 0.6020 - val_acc: 0.6771\n",
            "Epoch 537/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5013 - acc: 0.7647 - val_loss: 0.5992 - val_acc: 0.6875\n",
            "Epoch 538/1000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.5180 - acc: 0.7533 - val_loss: 0.6018 - val_acc: 0.6354\n",
            "Epoch 539/1000\n",
            "39/39 [==============================] - 5s 100ms/step - loss: 0.4811 - acc: 0.7549 - val_loss: 0.5904 - val_acc: 0.6562\n",
            "Epoch 540/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.5416 - acc: 0.7222 - val_loss: 0.6052 - val_acc: 0.6667\n",
            "Epoch 541/1000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5149 - acc: 0.7435 - val_loss: 0.5792 - val_acc: 0.6562\n",
            "Epoch 542/1000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.5252 - acc: 0.7582 - val_loss: 0.5955 - val_acc: 0.6458\n",
            "Epoch 543/1000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 0.5453 - acc: 0.7206 - val_loss: 0.5751 - val_acc: 0.6667\n",
            "Epoch 544/1000\n",
            "39/39 [==============================] - 5s 103ms/step - loss: 0.5274 - acc: 0.7533 - val_loss: 0.6198 - val_acc: 0.6667\n",
            "Epoch 545/1000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 0.5365 - acc: 0.7304 - val_loss: 0.5927 - val_acc: 0.6042\n",
            "Epoch 546/1000\n",
            "39/39 [==============================] - 10s 235ms/step - loss: 0.5059 - acc: 0.7353 - val_loss: 0.6097 - val_acc: 0.6250\n",
            "Epoch 547/1000\n",
            "39/39 [==============================] - 6s 135ms/step - loss: 0.5005 - acc: 0.7500 - val_loss: 0.5929 - val_acc: 0.6771\n",
            "Epoch 548/1000\n",
            "39/39 [==============================] - 5s 100ms/step - loss: 0.4785 - acc: 0.7647 - val_loss: 0.5989 - val_acc: 0.6875\n",
            "Epoch 549/1000\n",
            "39/39 [==============================] - 5s 102ms/step - loss: 0.5093 - acc: 0.7565 - val_loss: 0.6289 - val_acc: 0.6667\n",
            "Epoch 550/1000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.5176 - acc: 0.7369 - val_loss: 0.5936 - val_acc: 0.6667\n",
            "Epoch 551/1000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.4727 - acc: 0.7729 - val_loss: 0.6009 - val_acc: 0.6458\n",
            "Epoch 552/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5198 - acc: 0.7500 - val_loss: 0.5896 - val_acc: 0.6979\n",
            "Epoch 553/1000\n",
            "39/39 [==============================] - 9s 232ms/step - loss: 0.4854 - acc: 0.7402 - val_loss: 0.5895 - val_acc: 0.6562\n",
            "Epoch 554/1000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.5085 - acc: 0.7516 - val_loss: 0.5918 - val_acc: 0.6562\n",
            "Epoch 555/1000\n",
            "39/39 [==============================] - 6s 118ms/step - loss: 0.5092 - acc: 0.7500 - val_loss: 0.5910 - val_acc: 0.6458\n",
            "Epoch 556/1000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 0.5196 - acc: 0.7288 - val_loss: 0.5955 - val_acc: 0.6458\n",
            "Epoch 557/1000\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 0.5119 - acc: 0.7549 - val_loss: 0.5849 - val_acc: 0.6875\n",
            "Epoch 558/1000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.4482 - acc: 0.7892 - val_loss: 0.6102 - val_acc: 0.6562\n",
            "Epoch 559/1000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.5292 - acc: 0.7353 - val_loss: 0.6079 - val_acc: 0.6875\n",
            "Epoch 560/1000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5302 - acc: 0.7402 - val_loss: 0.5912 - val_acc: 0.6875\n",
            "Epoch 561/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5475 - acc: 0.7271 - val_loss: 0.6286 - val_acc: 0.6771\n",
            "Epoch 562/1000\n",
            "39/39 [==============================] - 7s 156ms/step - loss: 0.4971 - acc: 0.7631 - val_loss: 0.6153 - val_acc: 0.6875\n",
            "Epoch 563/1000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 0.5323 - acc: 0.7320 - val_loss: 0.6160 - val_acc: 0.6562\n",
            "Epoch 564/1000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.5173 - acc: 0.7549 - val_loss: 0.6318 - val_acc: 0.6979\n",
            "Epoch 565/1000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 0.4940 - acc: 0.7549 - val_loss: 0.6067 - val_acc: 0.6771\n",
            "Epoch 566/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5389 - acc: 0.7239 - val_loss: 0.5892 - val_acc: 0.6458\n",
            "Epoch 567/1000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 0.4938 - acc: 0.7549 - val_loss: 0.5963 - val_acc: 0.6875\n",
            "Epoch 568/1000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 0.5168 - acc: 0.7614 - val_loss: 0.5682 - val_acc: 0.7083\n",
            "Epoch 569/1000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5504 - acc: 0.7304 - val_loss: 0.6198 - val_acc: 0.6771\n",
            "Epoch 570/1000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5094 - acc: 0.7647 - val_loss: 0.6115 - val_acc: 0.6667\n",
            "Epoch 571/1000\n",
            "39/39 [==============================] - 10s 240ms/step - loss: 0.4992 - acc: 0.7369 - val_loss: 0.5951 - val_acc: 0.6458\n",
            "Epoch 572/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.4895 - acc: 0.7582 - val_loss: 0.6007 - val_acc: 0.6875\n",
            "Epoch 573/1000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 0.5490 - acc: 0.7124 - val_loss: 0.6122 - val_acc: 0.6875\n",
            "Epoch 574/1000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 0.5045 - acc: 0.7663 - val_loss: 0.5861 - val_acc: 0.6979\n",
            "Epoch 575/1000\n",
            "39/39 [==============================] - 6s 136ms/step - loss: 0.5006 - acc: 0.7451 - val_loss: 0.6038 - val_acc: 0.6875\n",
            "Epoch 576/1000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 0.4947 - acc: 0.7647 - val_loss: 0.5995 - val_acc: 0.6250\n",
            "Epoch 577/1000\n",
            "39/39 [==============================] - 5s 102ms/step - loss: 0.4858 - acc: 0.7549 - val_loss: 0.6038 - val_acc: 0.6458\n",
            "Epoch 578/1000\n",
            "39/39 [==============================] - 6s 128ms/step - loss: 0.4972 - acc: 0.7484 - val_loss: 0.6135 - val_acc: 0.6458\n",
            "Epoch 579/1000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.4920 - acc: 0.7435 - val_loss: 0.6267 - val_acc: 0.6667\n",
            "Epoch 580/1000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 0.5531 - acc: 0.7190 - val_loss: 0.6350 - val_acc: 0.6562\n",
            "Epoch 581/1000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.4898 - acc: 0.7663 - val_loss: 0.6121 - val_acc: 0.6771\n",
            "Epoch 582/1000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.5266 - acc: 0.7353 - val_loss: 0.5834 - val_acc: 0.6562\n",
            "Epoch 583/1000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.5043 - acc: 0.7500 - val_loss: 0.6241 - val_acc: 0.6771\n",
            "Epoch 584/1000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 0.5555 - acc: 0.7157 - val_loss: 0.6299 - val_acc: 0.6875\n",
            "Epoch 585/1000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5063 - acc: 0.7418 - val_loss: 0.6088 - val_acc: 0.6458\n",
            "Epoch 586/1000\n",
            "39/39 [==============================] - 5s 121ms/step - loss: 0.5485 - acc: 0.7288 - val_loss: 0.5919 - val_acc: 0.6458\n",
            "Epoch 587/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5272 - acc: 0.7418 - val_loss: 0.6060 - val_acc: 0.6458\n",
            "Epoch 588/1000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5065 - acc: 0.7533 - val_loss: 0.6091 - val_acc: 0.6458\n",
            "Epoch 589/1000\n",
            "39/39 [==============================] - 9s 232ms/step - loss: 0.4761 - acc: 0.7712 - val_loss: 0.6019 - val_acc: 0.6458\n",
            "Epoch 590/1000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.5170 - acc: 0.7304 - val_loss: 0.6327 - val_acc: 0.6667\n",
            "Epoch 591/1000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 0.5361 - acc: 0.7271 - val_loss: 0.6222 - val_acc: 0.6458\n",
            "Epoch 592/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.4948 - acc: 0.7533 - val_loss: 0.6172 - val_acc: 0.6458\n",
            "Epoch 593/1000\n",
            "39/39 [==============================] - 6s 148ms/step - loss: 0.5377 - acc: 0.7402 - val_loss: 0.6098 - val_acc: 0.6667\n",
            "Epoch 594/1000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 0.5390 - acc: 0.7157 - val_loss: 0.6119 - val_acc: 0.6458\n",
            "Epoch 595/1000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 0.5138 - acc: 0.7778 - val_loss: 0.6188 - val_acc: 0.6562\n",
            "Epoch 596/1000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 0.4736 - acc: 0.7631 - val_loss: 0.6144 - val_acc: 0.6458\n",
            "Epoch 597/1000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 0.5101 - acc: 0.7565 - val_loss: 0.6068 - val_acc: 0.6562\n",
            "Epoch 598/1000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 0.5125 - acc: 0.7369 - val_loss: 0.6210 - val_acc: 0.6771\n",
            "Epoch 599/1000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 0.5252 - acc: 0.7500 - val_loss: 0.6154 - val_acc: 0.6354\n",
            "Epoch 600/1000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5269 - acc: 0.7467 - val_loss: 0.6112 - val_acc: 0.6875\n",
            "Epoch 601/1000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.5354 - acc: 0.7337 - val_loss: 0.5940 - val_acc: 0.6979\n",
            "Epoch 602/1000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.4987 - acc: 0.7582 - val_loss: 0.5812 - val_acc: 0.6667\n",
            "Epoch 603/1000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 0.4931 - acc: 0.7451 - val_loss: 0.6166 - val_acc: 0.6771\n",
            "Epoch 604/1000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5482 - acc: 0.7288 - val_loss: 0.6040 - val_acc: 0.6562\n",
            "Epoch 605/1000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 0.5123 - acc: 0.7516 - val_loss: 0.6032 - val_acc: 0.6979\n",
            "Epoch 606/1000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5017 - acc: 0.7500 - val_loss: 0.5807 - val_acc: 0.6875\n",
            "Epoch 607/1000\n",
            "39/39 [==============================] - 5s 120ms/step - loss: 0.5016 - acc: 0.7435 - val_loss: 0.6187 - val_acc: 0.6875\n",
            "Epoch 608/1000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5027 - acc: 0.7386 - val_loss: 0.6398 - val_acc: 0.6667\n",
            "Epoch 609/1000\n",
            "39/39 [==============================] - 10s 233ms/step - loss: 0.5242 - acc: 0.7435 - val_loss: 0.6613 - val_acc: 0.6979\n",
            "Epoch 610/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5389 - acc: 0.7239 - val_loss: 0.5968 - val_acc: 0.6250\n",
            "Epoch 611/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5132 - acc: 0.7304 - val_loss: 0.6739 - val_acc: 0.6875\n",
            "Epoch 612/1000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 0.4867 - acc: 0.7533 - val_loss: 0.6076 - val_acc: 0.6562\n",
            "Epoch 613/1000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5135 - acc: 0.7484 - val_loss: 0.6439 - val_acc: 0.6771\n",
            "Epoch 614/1000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.4832 - acc: 0.7663 - val_loss: 0.5968 - val_acc: 0.6875\n",
            "Epoch 615/1000\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 0.4903 - acc: 0.7680 - val_loss: 0.6280 - val_acc: 0.6771\n",
            "Epoch 616/1000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5298 - acc: 0.7451 - val_loss: 0.6155 - val_acc: 0.6562\n",
            "Epoch 617/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5035 - acc: 0.7516 - val_loss: 0.6219 - val_acc: 0.6875\n",
            "Epoch 618/1000\n",
            "39/39 [==============================] - 6s 149ms/step - loss: 0.4868 - acc: 0.7631 - val_loss: 0.6194 - val_acc: 0.6667\n",
            "Epoch 619/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.4948 - acc: 0.7647 - val_loss: 0.6198 - val_acc: 0.6562\n",
            "Epoch 620/1000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5097 - acc: 0.7500 - val_loss: 0.6438 - val_acc: 0.6875\n",
            "Epoch 621/1000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 0.5097 - acc: 0.7206 - val_loss: 0.6306 - val_acc: 0.6667\n",
            "Epoch 622/1000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 0.5241 - acc: 0.7255 - val_loss: 0.5662 - val_acc: 0.6562\n",
            "Epoch 623/1000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 0.5087 - acc: 0.7467 - val_loss: 0.6169 - val_acc: 0.6875\n",
            "Epoch 624/1000\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.5042 - acc: 0.7533 - val_loss: 0.5974 - val_acc: 0.6562\n",
            "Epoch 625/1000\n",
            "39/39 [==============================] - 10s 236ms/step - loss: 0.4936 - acc: 0.7712 - val_loss: 0.5968 - val_acc: 0.6458\n",
            "Epoch 626/1000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 0.5440 - acc: 0.7075 - val_loss: 0.5948 - val_acc: 0.6667\n",
            "Epoch 627/1000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 0.5774 - acc: 0.7092 - val_loss: 0.6208 - val_acc: 0.6771\n",
            "Epoch 628/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.4879 - acc: 0.7516 - val_loss: 0.6036 - val_acc: 0.6458\n",
            "Epoch 629/1000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.4690 - acc: 0.7580 - val_loss: 0.6017 - val_acc: 0.6667\n",
            "Epoch 630/1000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.5304 - acc: 0.7353 - val_loss: 0.5808 - val_acc: 0.6354\n",
            "Epoch 631/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5043 - acc: 0.7598 - val_loss: 0.6036 - val_acc: 0.6354\n",
            "Epoch 632/1000\n",
            "39/39 [==============================] - 5s 119ms/step - loss: 0.4970 - acc: 0.7663 - val_loss: 0.5881 - val_acc: 0.6354\n",
            "Epoch 633/1000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.5042 - acc: 0.7516 - val_loss: 0.5742 - val_acc: 0.6458\n",
            "Epoch 634/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5237 - acc: 0.7239 - val_loss: 0.6058 - val_acc: 0.6354\n",
            "Epoch 635/1000\n",
            "39/39 [==============================] - 5s 103ms/step - loss: 0.5625 - acc: 0.7222 - val_loss: 0.6059 - val_acc: 0.7083\n",
            "Epoch 636/1000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.5087 - acc: 0.7288 - val_loss: 0.5849 - val_acc: 0.6979\n",
            "Epoch 637/1000\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 0.5059 - acc: 0.7533 - val_loss: 0.6152 - val_acc: 0.6458\n",
            "Epoch 638/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5079 - acc: 0.7549 - val_loss: 0.5892 - val_acc: 0.6562\n",
            "Epoch 639/1000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.5164 - acc: 0.7565 - val_loss: 0.5967 - val_acc: 0.6979\n",
            "Epoch 640/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5024 - acc: 0.7565 - val_loss: 0.5994 - val_acc: 0.6250\n",
            "Epoch 641/1000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.5368 - acc: 0.7190 - val_loss: 0.6140 - val_acc: 0.6771\n",
            "Epoch 642/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.4891 - acc: 0.7761 - val_loss: 0.6122 - val_acc: 0.6667\n",
            "Epoch 643/1000\n",
            "39/39 [==============================] - 10s 230ms/step - loss: 0.4891 - acc: 0.7631 - val_loss: 0.6060 - val_acc: 0.6771\n",
            "Epoch 644/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.4915 - acc: 0.7745 - val_loss: 0.6266 - val_acc: 0.6979\n",
            "Epoch 645/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5202 - acc: 0.7418 - val_loss: 0.5947 - val_acc: 0.6458\n",
            "Epoch 646/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5363 - acc: 0.7402 - val_loss: 0.5991 - val_acc: 0.6458\n",
            "Epoch 647/1000\n",
            "39/39 [==============================] - 10s 230ms/step - loss: 0.4838 - acc: 0.7565 - val_loss: 0.6148 - val_acc: 0.6562\n",
            "Epoch 648/1000\n",
            "39/39 [==============================] - 10s 236ms/step - loss: 0.5380 - acc: 0.7304 - val_loss: 0.5985 - val_acc: 0.6458\n",
            "Epoch 649/1000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 0.4932 - acc: 0.7582 - val_loss: 0.6151 - val_acc: 0.7292\n",
            "Epoch 650/1000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.5241 - acc: 0.7435 - val_loss: 0.6279 - val_acc: 0.6875\n",
            "Epoch 651/1000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5364 - acc: 0.7516 - val_loss: 0.6065 - val_acc: 0.6979\n",
            "Epoch 652/1000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 0.5075 - acc: 0.7353 - val_loss: 0.6189 - val_acc: 0.6771\n",
            "Epoch 653/1000\n",
            "39/39 [==============================] - 5s 112ms/step - loss: 0.5013 - acc: 0.7533 - val_loss: 0.6020 - val_acc: 0.6458\n",
            "Epoch 654/1000\n",
            "39/39 [==============================] - 5s 120ms/step - loss: 0.4771 - acc: 0.7745 - val_loss: 0.6359 - val_acc: 0.6667\n",
            "Epoch 655/1000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 0.5519 - acc: 0.7206 - val_loss: 0.6352 - val_acc: 0.6875\n",
            "Epoch 656/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.4893 - acc: 0.7582 - val_loss: 0.6155 - val_acc: 0.6979\n",
            "Epoch 657/1000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.5506 - acc: 0.7304 - val_loss: 0.6126 - val_acc: 0.6667\n",
            "Epoch 658/1000\n",
            "39/39 [==============================] - 5s 102ms/step - loss: 0.5331 - acc: 0.7271 - val_loss: 0.6267 - val_acc: 0.6667\n",
            "Epoch 659/1000\n",
            "39/39 [==============================] - 10s 232ms/step - loss: 0.4755 - acc: 0.7843 - val_loss: 0.6266 - val_acc: 0.6875\n",
            "Epoch 660/1000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.4803 - acc: 0.7794 - val_loss: 0.6029 - val_acc: 0.6458\n",
            "Epoch 661/1000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 0.5444 - acc: 0.7320 - val_loss: 0.6336 - val_acc: 0.6771\n",
            "Epoch 662/1000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 0.5254 - acc: 0.7712 - val_loss: 0.6066 - val_acc: 0.6562\n",
            "Epoch 663/1000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5176 - acc: 0.7255 - val_loss: 0.5990 - val_acc: 0.6771\n",
            "Epoch 664/1000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.4977 - acc: 0.7596 - val_loss: 0.6148 - val_acc: 0.6354\n",
            "Epoch 665/1000\n",
            "39/39 [==============================] - 6s 130ms/step - loss: 0.4955 - acc: 0.7598 - val_loss: 0.6479 - val_acc: 0.6979\n",
            "Epoch 666/1000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 0.5457 - acc: 0.7271 - val_loss: 0.6000 - val_acc: 0.7083\n",
            "Epoch 667/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5332 - acc: 0.7582 - val_loss: 0.6058 - val_acc: 0.6562\n",
            "Epoch 668/1000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.4964 - acc: 0.7500 - val_loss: 0.5764 - val_acc: 0.6875\n",
            "Epoch 669/1000\n",
            "39/39 [==============================] - 6s 137ms/step - loss: 0.5248 - acc: 0.7402 - val_loss: 0.6331 - val_acc: 0.6875\n",
            "Epoch 670/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5522 - acc: 0.7271 - val_loss: 0.5962 - val_acc: 0.6875\n",
            "Epoch 671/1000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5218 - acc: 0.7402 - val_loss: 0.5955 - val_acc: 0.6562\n",
            "Epoch 672/1000\n",
            "39/39 [==============================] - 10s 232ms/step - loss: 0.5043 - acc: 0.7484 - val_loss: 0.6187 - val_acc: 0.6771\n",
            "Epoch 673/1000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 0.5368 - acc: 0.7271 - val_loss: 0.6152 - val_acc: 0.6562\n",
            "Epoch 674/1000\n",
            "39/39 [==============================] - 6s 125ms/step - loss: 0.4813 - acc: 0.7712 - val_loss: 0.6024 - val_acc: 0.6562\n",
            "Epoch 675/1000\n",
            "39/39 [==============================] - 9s 231ms/step - loss: 0.5052 - acc: 0.7631 - val_loss: 0.5890 - val_acc: 0.6667\n",
            "Epoch 676/1000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.4903 - acc: 0.7386 - val_loss: 0.5854 - val_acc: 0.6667\n",
            "Epoch 677/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5264 - acc: 0.7451 - val_loss: 0.6461 - val_acc: 0.6771\n",
            "Epoch 678/1000\n",
            "39/39 [==============================] - 5s 102ms/step - loss: 0.5264 - acc: 0.7484 - val_loss: 0.6252 - val_acc: 0.6458\n",
            "Epoch 679/1000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.5353 - acc: 0.7500 - val_loss: 0.5745 - val_acc: 0.6667\n",
            "Epoch 680/1000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.4882 - acc: 0.7696 - val_loss: 0.6306 - val_acc: 0.6667\n",
            "Epoch 681/1000\n",
            "39/39 [==============================] - 10s 234ms/step - loss: 0.5126 - acc: 0.7598 - val_loss: 0.6020 - val_acc: 0.6562\n",
            "Epoch 682/1000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.5260 - acc: 0.7369 - val_loss: 0.5825 - val_acc: 0.7083\n",
            "Epoch 683/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5152 - acc: 0.7369 - val_loss: 0.6128 - val_acc: 0.6771\n",
            "Epoch 684/1000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.4931 - acc: 0.7516 - val_loss: 0.6120 - val_acc: 0.6562\n",
            "Epoch 685/1000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.5093 - acc: 0.7516 - val_loss: 0.6023 - val_acc: 0.6667\n",
            "Epoch 686/1000\n",
            "39/39 [==============================] - 10s 243ms/step - loss: 0.4978 - acc: 0.7908 - val_loss: 0.6227 - val_acc: 0.6771\n",
            "Epoch 687/1000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 0.5215 - acc: 0.7369 - val_loss: 0.6122 - val_acc: 0.6458\n",
            "Epoch 688/1000\n",
            "39/39 [==============================] - 5s 114ms/step - loss: 0.5253 - acc: 0.7271 - val_loss: 0.6036 - val_acc: 0.6562\n",
            "Epoch 689/1000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.4825 - acc: 0.7549 - val_loss: 0.5900 - val_acc: 0.6562\n",
            "Epoch 690/1000\n",
            "39/39 [==============================] - 9s 208ms/step - loss: 0.5126 - acc: 0.7353 - val_loss: 0.6220 - val_acc: 0.6771\n",
            "Epoch 691/1000\n",
            "39/39 [==============================] - 5s 115ms/step - loss: 0.4814 - acc: 0.7729 - val_loss: 0.5938 - val_acc: 0.6875\n",
            "Epoch 692/1000\n",
            "39/39 [==============================] - 6s 128ms/step - loss: 0.4892 - acc: 0.7533 - val_loss: 0.6000 - val_acc: 0.6771\n",
            "Epoch 693/1000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5304 - acc: 0.7369 - val_loss: 0.6037 - val_acc: 0.6979\n",
            "Epoch 694/1000\n",
            "39/39 [==============================] - 6s 142ms/step - loss: 0.4698 - acc: 0.7565 - val_loss: 0.6035 - val_acc: 0.6771\n",
            "Epoch 695/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5178 - acc: 0.7582 - val_loss: 0.6116 - val_acc: 0.6771\n",
            "Epoch 696/1000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.4996 - acc: 0.7500 - val_loss: 0.5979 - val_acc: 0.6875\n",
            "Epoch 697/1000\n",
            "39/39 [==============================] - 5s 113ms/step - loss: 0.5156 - acc: 0.7500 - val_loss: 0.6339 - val_acc: 0.6667\n",
            "Epoch 698/1000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 0.5090 - acc: 0.7467 - val_loss: 0.5993 - val_acc: 0.6875\n",
            "Epoch 699/1000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5384 - acc: 0.7304 - val_loss: 0.6051 - val_acc: 0.6458\n",
            "Epoch 700/1000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5111 - acc: 0.7500 - val_loss: 0.6335 - val_acc: 0.6667\n",
            "Epoch 701/1000\n",
            "39/39 [==============================] - 6s 139ms/step - loss: 0.5127 - acc: 0.7516 - val_loss: 0.6033 - val_acc: 0.6354\n",
            "Epoch 702/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5348 - acc: 0.7173 - val_loss: 0.6315 - val_acc: 0.6875\n",
            "Epoch 703/1000\n",
            "39/39 [==============================] - 10s 234ms/step - loss: 0.5273 - acc: 0.7402 - val_loss: 0.6272 - val_acc: 0.6979\n",
            "Epoch 704/1000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 0.5117 - acc: 0.7500 - val_loss: 0.6108 - val_acc: 0.6667\n",
            "Epoch 705/1000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 0.5004 - acc: 0.7435 - val_loss: 0.6415 - val_acc: 0.6667\n",
            "Epoch 706/1000\n",
            "39/39 [==============================] - 10s 236ms/step - loss: 0.5483 - acc: 0.7500 - val_loss: 0.6097 - val_acc: 0.6875\n",
            "Epoch 707/1000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5618 - acc: 0.7304 - val_loss: 0.6194 - val_acc: 0.6875\n",
            "Epoch 708/1000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.4821 - acc: 0.7729 - val_loss: 0.6423 - val_acc: 0.6667\n",
            "Epoch 709/1000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.5327 - acc: 0.7173 - val_loss: 0.6047 - val_acc: 0.7083\n",
            "Epoch 710/1000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 0.5246 - acc: 0.7320 - val_loss: 0.5966 - val_acc: 0.6667\n",
            "Epoch 711/1000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.4720 - acc: 0.7647 - val_loss: 0.6106 - val_acc: 0.6771\n",
            "Epoch 712/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5137 - acc: 0.7549 - val_loss: 0.6213 - val_acc: 0.6771\n",
            "Epoch 713/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5438 - acc: 0.7435 - val_loss: 0.5929 - val_acc: 0.6771\n",
            "Epoch 714/1000\n",
            "39/39 [==============================] - 5s 117ms/step - loss: 0.5345 - acc: 0.7369 - val_loss: 0.6077 - val_acc: 0.6979\n",
            "Epoch 715/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5456 - acc: 0.7402 - val_loss: 0.6109 - val_acc: 0.6875\n",
            "Epoch 716/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.4765 - acc: 0.7696 - val_loss: 0.5702 - val_acc: 0.6771\n",
            "Epoch 717/1000\n",
            "39/39 [==============================] - 6s 137ms/step - loss: 0.4842 - acc: 0.7484 - val_loss: 0.6239 - val_acc: 0.6771\n",
            "Epoch 718/1000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.5008 - acc: 0.7467 - val_loss: 0.6174 - val_acc: 0.6771\n",
            "Epoch 719/1000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.5300 - acc: 0.7157 - val_loss: 0.5961 - val_acc: 0.6667\n",
            "Epoch 720/1000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.4866 - acc: 0.7467 - val_loss: 0.6116 - val_acc: 0.6667\n",
            "Epoch 721/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.5332 - acc: 0.7451 - val_loss: 0.6021 - val_acc: 0.6771\n",
            "Epoch 722/1000\n",
            "39/39 [==============================] - 6s 136ms/step - loss: 0.5139 - acc: 0.7467 - val_loss: 0.5810 - val_acc: 0.6667\n",
            "Epoch 723/1000\n",
            "39/39 [==============================] - 5s 102ms/step - loss: 0.5166 - acc: 0.7451 - val_loss: 0.6007 - val_acc: 0.6979\n",
            "Epoch 724/1000\n",
            "39/39 [==============================] - 5s 117ms/step - loss: 0.4937 - acc: 0.7647 - val_loss: 0.6101 - val_acc: 0.6875\n",
            "Epoch 725/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5303 - acc: 0.7304 - val_loss: 0.6165 - val_acc: 0.6771\n",
            "Epoch 726/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5322 - acc: 0.7418 - val_loss: 0.5711 - val_acc: 0.6667\n",
            "Epoch 727/1000\n",
            "39/39 [==============================] - 6s 140ms/step - loss: 0.4804 - acc: 0.7565 - val_loss: 0.6138 - val_acc: 0.6667\n",
            "Epoch 728/1000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5072 - acc: 0.7484 - val_loss: 0.6046 - val_acc: 0.6771\n",
            "Epoch 729/1000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5101 - acc: 0.7337 - val_loss: 0.5790 - val_acc: 0.6875\n",
            "Epoch 730/1000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5759 - acc: 0.7010 - val_loss: 0.5916 - val_acc: 0.6562\n",
            "Epoch 731/1000\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.5218 - acc: 0.7549 - val_loss: 0.6156 - val_acc: 0.6771\n",
            "Epoch 732/1000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.5130 - acc: 0.7533 - val_loss: 0.6001 - val_acc: 0.6979\n",
            "Epoch 733/1000\n",
            "39/39 [==============================] - 5s 99ms/step - loss: 0.5207 - acc: 0.7451 - val_loss: 0.5917 - val_acc: 0.6562\n",
            "Epoch 734/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5555 - acc: 0.7484 - val_loss: 0.6006 - val_acc: 0.6771\n",
            "Epoch 735/1000\n",
            "39/39 [==============================] - 6s 137ms/step - loss: 0.4873 - acc: 0.7696 - val_loss: 0.6239 - val_acc: 0.6667\n",
            "Epoch 736/1000\n",
            "39/39 [==============================] - 5s 103ms/step - loss: 0.4960 - acc: 0.7663 - val_loss: 0.6348 - val_acc: 0.6771\n",
            "Epoch 737/1000\n",
            "39/39 [==============================] - 10s 238ms/step - loss: 0.5108 - acc: 0.7386 - val_loss: 0.6218 - val_acc: 0.6771\n",
            "Epoch 738/1000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.4991 - acc: 0.7565 - val_loss: 0.6314 - val_acc: 0.6979\n",
            "Epoch 739/1000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 0.4857 - acc: 0.7582 - val_loss: 0.6138 - val_acc: 0.6979\n",
            "Epoch 740/1000\n",
            "39/39 [==============================] - 10s 232ms/step - loss: 0.4828 - acc: 0.7663 - val_loss: 0.6068 - val_acc: 0.6979\n",
            "Epoch 741/1000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5027 - acc: 0.7614 - val_loss: 0.6020 - val_acc: 0.6979\n",
            "Epoch 742/1000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.5182 - acc: 0.7369 - val_loss: 0.5942 - val_acc: 0.6875\n",
            "Epoch 743/1000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.5367 - acc: 0.7271 - val_loss: 0.6076 - val_acc: 0.6771\n",
            "Epoch 744/1000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.5252 - acc: 0.7353 - val_loss: 0.6273 - val_acc: 0.6771\n",
            "Epoch 745/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5193 - acc: 0.7173 - val_loss: 0.6259 - val_acc: 0.6771\n",
            "Epoch 746/1000\n",
            "39/39 [==============================] - 5s 102ms/step - loss: 0.5169 - acc: 0.7500 - val_loss: 0.6243 - val_acc: 0.6667\n",
            "Epoch 747/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5108 - acc: 0.7680 - val_loss: 0.5934 - val_acc: 0.6458\n",
            "Epoch 748/1000\n",
            "39/39 [==============================] - 5s 113ms/step - loss: 0.5056 - acc: 0.7337 - val_loss: 0.6277 - val_acc: 0.6771\n",
            "Epoch 749/1000\n",
            "39/39 [==============================] - 6s 130ms/step - loss: 0.5454 - acc: 0.7222 - val_loss: 0.6089 - val_acc: 0.6458\n",
            "Epoch 750/1000\n",
            "39/39 [==============================] - 7s 169ms/step - loss: 0.4805 - acc: 0.7680 - val_loss: 0.6233 - val_acc: 0.6979\n",
            "Epoch 751/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5279 - acc: 0.7402 - val_loss: 0.6459 - val_acc: 0.6667\n",
            "Epoch 752/1000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.4850 - acc: 0.7435 - val_loss: 0.6514 - val_acc: 0.6771\n",
            "Epoch 753/1000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 0.4770 - acc: 0.7827 - val_loss: 0.6013 - val_acc: 0.6979\n",
            "Epoch 754/1000\n",
            "39/39 [==============================] - 5s 102ms/step - loss: 0.5163 - acc: 0.7418 - val_loss: 0.6320 - val_acc: 0.6875\n",
            "Epoch 755/1000\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.4867 - acc: 0.7876 - val_loss: 0.6353 - val_acc: 0.6771\n",
            "Epoch 756/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.4709 - acc: 0.7598 - val_loss: 0.6148 - val_acc: 0.6979\n",
            "Epoch 757/1000\n",
            "39/39 [==============================] - 6s 127ms/step - loss: 0.5249 - acc: 0.7304 - val_loss: 0.6138 - val_acc: 0.6979\n",
            "Epoch 758/1000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.5145 - acc: 0.7386 - val_loss: 0.6182 - val_acc: 0.6458\n",
            "Epoch 759/1000\n",
            "39/39 [==============================] - 6s 138ms/step - loss: 0.5244 - acc: 0.7369 - val_loss: 0.6062 - val_acc: 0.6979\n",
            "Epoch 760/1000\n",
            "39/39 [==============================] - 10s 236ms/step - loss: 0.4958 - acc: 0.7696 - val_loss: 0.6649 - val_acc: 0.6875\n",
            "Epoch 761/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5269 - acc: 0.7451 - val_loss: 0.6362 - val_acc: 0.6771\n",
            "Epoch 762/1000\n",
            "39/39 [==============================] - 5s 120ms/step - loss: 0.5232 - acc: 0.7533 - val_loss: 0.6263 - val_acc: 0.6979\n",
            "Epoch 763/1000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 0.4844 - acc: 0.7712 - val_loss: 0.6697 - val_acc: 0.6979\n",
            "Epoch 764/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5462 - acc: 0.7353 - val_loss: 0.5929 - val_acc: 0.6979\n",
            "Epoch 765/1000\n",
            "39/39 [==============================] - 5s 117ms/step - loss: 0.5257 - acc: 0.7402 - val_loss: 0.6528 - val_acc: 0.6667\n",
            "Epoch 766/1000\n",
            "39/39 [==============================] - 5s 96ms/step - loss: 0.5124 - acc: 0.7402 - val_loss: 0.6225 - val_acc: 0.6771\n",
            "Epoch 767/1000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.4835 - acc: 0.7582 - val_loss: 0.5967 - val_acc: 0.6458\n",
            "Epoch 768/1000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.5444 - acc: 0.7157 - val_loss: 0.5924 - val_acc: 0.6667\n",
            "Epoch 769/1000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.5295 - acc: 0.7369 - val_loss: 0.6114 - val_acc: 0.6771\n",
            "Epoch 770/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.4958 - acc: 0.7451 - val_loss: 0.5891 - val_acc: 0.6979\n",
            "Epoch 771/1000\n",
            "39/39 [==============================] - 5s 117ms/step - loss: 0.5011 - acc: 0.7467 - val_loss: 0.6016 - val_acc: 0.6562\n",
            "Epoch 772/1000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 0.5088 - acc: 0.7402 - val_loss: 0.6149 - val_acc: 0.6875\n",
            "Epoch 773/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5380 - acc: 0.7239 - val_loss: 0.5792 - val_acc: 0.6875\n",
            "Epoch 774/1000\n",
            "39/39 [==============================] - 10s 232ms/step - loss: 0.5096 - acc: 0.7402 - val_loss: 0.5765 - val_acc: 0.6458\n",
            "Epoch 775/1000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5511 - acc: 0.7353 - val_loss: 0.5832 - val_acc: 0.6875\n",
            "Epoch 776/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5110 - acc: 0.7582 - val_loss: 0.5767 - val_acc: 0.6562\n",
            "Epoch 777/1000\n",
            "39/39 [==============================] - 5s 119ms/step - loss: 0.5001 - acc: 0.7680 - val_loss: 0.5851 - val_acc: 0.6979\n",
            "Epoch 778/1000\n",
            "39/39 [==============================] - 9s 235ms/step - loss: 0.5007 - acc: 0.7467 - val_loss: 0.6302 - val_acc: 0.6771\n",
            "Epoch 779/1000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.4835 - acc: 0.7582 - val_loss: 0.5990 - val_acc: 0.6875\n",
            "Epoch 780/1000\n",
            "39/39 [==============================] - 5s 113ms/step - loss: 0.5051 - acc: 0.7696 - val_loss: 0.6133 - val_acc: 0.6875\n",
            "Epoch 781/1000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5199 - acc: 0.7549 - val_loss: 0.5751 - val_acc: 0.6562\n",
            "Epoch 782/1000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.4927 - acc: 0.7516 - val_loss: 0.6159 - val_acc: 0.6667\n",
            "Epoch 783/1000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.5465 - acc: 0.7337 - val_loss: 0.5740 - val_acc: 0.6979\n",
            "Epoch 784/1000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5397 - acc: 0.7141 - val_loss: 0.5755 - val_acc: 0.6562\n",
            "Epoch 785/1000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.5096 - acc: 0.7467 - val_loss: 0.5912 - val_acc: 0.6667\n",
            "Epoch 786/1000\n",
            "39/39 [==============================] - 6s 142ms/step - loss: 0.4932 - acc: 0.7565 - val_loss: 0.5807 - val_acc: 0.6562\n",
            "Epoch 787/1000\n",
            "39/39 [==============================] - 6s 136ms/step - loss: 0.5483 - acc: 0.7386 - val_loss: 0.5801 - val_acc: 0.6875\n",
            "Epoch 788/1000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.5241 - acc: 0.7484 - val_loss: 0.5911 - val_acc: 0.6771\n",
            "Epoch 789/1000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 0.5180 - acc: 0.7402 - val_loss: 0.6179 - val_acc: 0.6771\n",
            "Epoch 790/1000\n",
            "39/39 [==============================] - 10s 237ms/step - loss: 0.5239 - acc: 0.7288 - val_loss: 0.6173 - val_acc: 0.6771\n",
            "Epoch 791/1000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5473 - acc: 0.7173 - val_loss: 0.6188 - val_acc: 0.6771\n",
            "Epoch 792/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5202 - acc: 0.7451 - val_loss: 0.6288 - val_acc: 0.6875\n",
            "Epoch 793/1000\n",
            "39/39 [==============================] - 5s 102ms/step - loss: 0.5275 - acc: 0.7353 - val_loss: 0.6040 - val_acc: 0.6979\n",
            "Epoch 794/1000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5532 - acc: 0.7190 - val_loss: 0.6421 - val_acc: 0.6771\n",
            "Epoch 795/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.4972 - acc: 0.7680 - val_loss: 0.6065 - val_acc: 0.6875\n",
            "Epoch 796/1000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 0.4837 - acc: 0.7614 - val_loss: 0.5845 - val_acc: 0.6667\n",
            "Epoch 797/1000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5266 - acc: 0.7369 - val_loss: 0.5954 - val_acc: 0.6771\n",
            "Epoch 798/1000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.5060 - acc: 0.7712 - val_loss: 0.6122 - val_acc: 0.6667\n",
            "Epoch 799/1000\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 0.4843 - acc: 0.7549 - val_loss: 0.6090 - val_acc: 0.6875\n",
            "Epoch 800/1000\n",
            "39/39 [==============================] - 7s 156ms/step - loss: 0.5081 - acc: 0.7451 - val_loss: 0.5770 - val_acc: 0.7083\n",
            "Epoch 801/1000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.4817 - acc: 0.7614 - val_loss: 0.6123 - val_acc: 0.6771\n",
            "Epoch 802/1000\n",
            "39/39 [==============================] - 5s 118ms/step - loss: 0.5006 - acc: 0.7533 - val_loss: 0.6185 - val_acc: 0.6771\n",
            "Epoch 803/1000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5340 - acc: 0.7222 - val_loss: 0.6240 - val_acc: 0.6771\n",
            "Epoch 804/1000\n",
            "39/39 [==============================] - 10s 245ms/step - loss: 0.5019 - acc: 0.7647 - val_loss: 0.5970 - val_acc: 0.6979\n",
            "Epoch 805/1000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 0.4752 - acc: 0.7729 - val_loss: 0.5948 - val_acc: 0.6458\n",
            "Epoch 806/1000\n",
            "39/39 [==============================] - 5s 117ms/step - loss: 0.4848 - acc: 0.7565 - val_loss: 0.6079 - val_acc: 0.6667\n",
            "Epoch 807/1000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.5022 - acc: 0.7418 - val_loss: 0.5984 - val_acc: 0.7083\n",
            "Epoch 808/1000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 0.5377 - acc: 0.7369 - val_loss: 0.6185 - val_acc: 0.6667\n",
            "Epoch 809/1000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.5271 - acc: 0.7402 - val_loss: 0.5963 - val_acc: 0.6458\n",
            "Epoch 810/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5208 - acc: 0.7418 - val_loss: 0.6075 - val_acc: 0.6771\n",
            "Epoch 811/1000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.5232 - acc: 0.7337 - val_loss: 0.6207 - val_acc: 0.6771\n",
            "Epoch 812/1000\n",
            "39/39 [==============================] - 5s 101ms/step - loss: 0.5063 - acc: 0.7484 - val_loss: 0.6301 - val_acc: 0.6667\n",
            "Epoch 813/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5432 - acc: 0.7108 - val_loss: 0.6216 - val_acc: 0.6875\n",
            "Epoch 814/1000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 0.4952 - acc: 0.7533 - val_loss: 0.5988 - val_acc: 0.6979\n",
            "Epoch 815/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.4934 - acc: 0.7614 - val_loss: 0.6081 - val_acc: 0.6875\n",
            "Epoch 816/1000\n",
            "39/39 [==============================] - 10s 239ms/step - loss: 0.4966 - acc: 0.7614 - val_loss: 0.6428 - val_acc: 0.6875\n",
            "Epoch 817/1000\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 0.5040 - acc: 0.7418 - val_loss: 0.6008 - val_acc: 0.6458\n",
            "Epoch 818/1000\n",
            "39/39 [==============================] - 6s 149ms/step - loss: 0.5097 - acc: 0.7516 - val_loss: 0.5828 - val_acc: 0.6875\n",
            "Epoch 819/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5181 - acc: 0.7565 - val_loss: 0.6252 - val_acc: 0.6458\n",
            "Epoch 820/1000\n",
            "39/39 [==============================] - 10s 239ms/step - loss: 0.5350 - acc: 0.7239 - val_loss: 0.6036 - val_acc: 0.6458\n",
            "Epoch 821/1000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 0.4956 - acc: 0.7598 - val_loss: 0.6172 - val_acc: 0.6667\n",
            "Epoch 822/1000\n",
            "39/39 [==============================] - 10s 237ms/step - loss: 0.5066 - acc: 0.7565 - val_loss: 0.5940 - val_acc: 0.6562\n",
            "Epoch 823/1000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 0.5073 - acc: 0.7516 - val_loss: 0.6020 - val_acc: 0.6562\n",
            "Epoch 824/1000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 0.5191 - acc: 0.7402 - val_loss: 0.5940 - val_acc: 0.6875\n",
            "Epoch 825/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.4936 - acc: 0.7614 - val_loss: 0.6212 - val_acc: 0.6771\n",
            "Epoch 826/1000\n",
            "39/39 [==============================] - 10s 232ms/step - loss: 0.5217 - acc: 0.7663 - val_loss: 0.6164 - val_acc: 0.6875\n",
            "Epoch 827/1000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 0.5182 - acc: 0.7239 - val_loss: 0.6111 - val_acc: 0.6875\n",
            "Epoch 828/1000\n",
            "39/39 [==============================] - 10s 238ms/step - loss: 0.4896 - acc: 0.7631 - val_loss: 0.6217 - val_acc: 0.6875\n",
            "Epoch 829/1000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.5070 - acc: 0.7565 - val_loss: 0.6333 - val_acc: 0.6875\n",
            "Epoch 830/1000\n",
            "39/39 [==============================] - 6s 129ms/step - loss: 0.5345 - acc: 0.7516 - val_loss: 0.6045 - val_acc: 0.6667\n",
            "Epoch 831/1000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 0.5320 - acc: 0.7484 - val_loss: 0.6656 - val_acc: 0.6771\n",
            "Epoch 832/1000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 0.5084 - acc: 0.7451 - val_loss: 0.6132 - val_acc: 0.6875\n",
            "Epoch 833/1000\n",
            "39/39 [==============================] - 5s 94ms/step - loss: 0.5221 - acc: 0.7353 - val_loss: 0.6026 - val_acc: 0.6875\n",
            "Epoch 834/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.4952 - acc: 0.7484 - val_loss: 0.6209 - val_acc: 0.6771\n",
            "Epoch 835/1000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 0.4954 - acc: 0.7631 - val_loss: 0.5800 - val_acc: 0.6875\n",
            "Epoch 836/1000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.4992 - acc: 0.7353 - val_loss: 0.6211 - val_acc: 0.6875\n",
            "Epoch 837/1000\n",
            "39/39 [==============================] - 5s 102ms/step - loss: 0.5238 - acc: 0.7288 - val_loss: 0.6038 - val_acc: 0.6771\n",
            "Epoch 838/1000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.5042 - acc: 0.7549 - val_loss: 0.5746 - val_acc: 0.6979\n",
            "Epoch 839/1000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5005 - acc: 0.7598 - val_loss: 0.5842 - val_acc: 0.6979\n",
            "Epoch 840/1000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 0.4772 - acc: 0.7761 - val_loss: 0.6195 - val_acc: 0.6667\n",
            "Epoch 841/1000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 0.5199 - acc: 0.7533 - val_loss: 0.6181 - val_acc: 0.6667\n",
            "Epoch 842/1000\n",
            "39/39 [==============================] - 10s 234ms/step - loss: 0.4751 - acc: 0.7745 - val_loss: 0.5966 - val_acc: 0.6458\n",
            "Epoch 843/1000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.4966 - acc: 0.7533 - val_loss: 0.5968 - val_acc: 0.6875\n",
            "Epoch 844/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5642 - acc: 0.7157 - val_loss: 0.6223 - val_acc: 0.6562\n",
            "Epoch 845/1000\n",
            "39/39 [==============================] - 10s 256ms/step - loss: 0.5123 - acc: 0.7304 - val_loss: 0.6156 - val_acc: 0.6354\n",
            "Epoch 846/1000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.5022 - acc: 0.7255 - val_loss: 0.5878 - val_acc: 0.6667\n",
            "Epoch 847/1000\n",
            "39/39 [==============================] - 10s 240ms/step - loss: 0.4715 - acc: 0.7794 - val_loss: 0.6037 - val_acc: 0.6562\n",
            "Epoch 848/1000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5479 - acc: 0.7304 - val_loss: 0.6173 - val_acc: 0.6875\n",
            "Epoch 849/1000\n",
            "39/39 [==============================] - 10s 242ms/step - loss: 0.4740 - acc: 0.7663 - val_loss: 0.6365 - val_acc: 0.6875\n",
            "Epoch 850/1000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5055 - acc: 0.7696 - val_loss: 0.6148 - val_acc: 0.6458\n",
            "Epoch 851/1000\n",
            "39/39 [==============================] - 6s 135ms/step - loss: 0.4921 - acc: 0.7386 - val_loss: 0.6864 - val_acc: 0.6667\n",
            "Epoch 852/1000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5088 - acc: 0.7549 - val_loss: 0.6362 - val_acc: 0.6771\n",
            "Epoch 853/1000\n",
            "39/39 [==============================] - 6s 131ms/step - loss: 0.5116 - acc: 0.7320 - val_loss: 0.5981 - val_acc: 0.6354\n",
            "Epoch 854/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5059 - acc: 0.7484 - val_loss: 0.5961 - val_acc: 0.6562\n",
            "Epoch 855/1000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.5201 - acc: 0.7320 - val_loss: 0.6196 - val_acc: 0.6771\n",
            "Epoch 856/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5303 - acc: 0.7418 - val_loss: 0.6517 - val_acc: 0.6771\n",
            "Epoch 857/1000\n",
            "39/39 [==============================] - 5s 100ms/step - loss: 0.4851 - acc: 0.7533 - val_loss: 0.6232 - val_acc: 0.6875\n",
            "Epoch 858/1000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.5171 - acc: 0.7516 - val_loss: 0.6080 - val_acc: 0.6875\n",
            "Epoch 859/1000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.4829 - acc: 0.7565 - val_loss: 0.5815 - val_acc: 0.6979\n",
            "Epoch 860/1000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.5120 - acc: 0.7533 - val_loss: 0.6100 - val_acc: 0.6771\n",
            "Epoch 861/1000\n",
            "39/39 [==============================] - 5s 102ms/step - loss: 0.5138 - acc: 0.7614 - val_loss: 0.6055 - val_acc: 0.6875\n",
            "Epoch 862/1000\n",
            "39/39 [==============================] - 10s 231ms/step - loss: 0.5216 - acc: 0.7631 - val_loss: 0.5822 - val_acc: 0.6875\n",
            "Epoch 863/1000\n",
            "39/39 [==============================] - 5s 115ms/step - loss: 0.5254 - acc: 0.7206 - val_loss: 0.5996 - val_acc: 0.6875\n",
            "Epoch 864/1000\n",
            "39/39 [==============================] - 6s 137ms/step - loss: 0.5088 - acc: 0.7516 - val_loss: 0.6108 - val_acc: 0.6771\n",
            "Epoch 865/1000\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.5027 - acc: 0.7598 - val_loss: 0.6149 - val_acc: 0.6667\n",
            "Epoch 866/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.4552 - acc: 0.7827 - val_loss: 0.6270 - val_acc: 0.6771\n",
            "Epoch 867/1000\n",
            "39/39 [==============================] - 10s 233ms/step - loss: 0.5035 - acc: 0.7418 - val_loss: 0.6206 - val_acc: 0.6771\n",
            "Epoch 868/1000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.4921 - acc: 0.7386 - val_loss: 0.6193 - val_acc: 0.6875\n",
            "Epoch 869/1000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.5398 - acc: 0.7320 - val_loss: 0.6268 - val_acc: 0.6771\n",
            "Epoch 870/1000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 0.5221 - acc: 0.7500 - val_loss: 0.6395 - val_acc: 0.6667\n",
            "Epoch 871/1000\n",
            "39/39 [==============================] - 5s 112ms/step - loss: 0.4990 - acc: 0.7631 - val_loss: 0.5950 - val_acc: 0.6875\n",
            "Epoch 872/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5196 - acc: 0.7500 - val_loss: 0.6099 - val_acc: 0.6667\n",
            "Epoch 873/1000\n",
            "39/39 [==============================] - 10s 238ms/step - loss: 0.4965 - acc: 0.7614 - val_loss: 0.6103 - val_acc: 0.6354\n",
            "Epoch 874/1000\n",
            "39/39 [==============================] - 5s 102ms/step - loss: 0.5422 - acc: 0.7271 - val_loss: 0.5875 - val_acc: 0.6979\n",
            "Epoch 875/1000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 0.4851 - acc: 0.7663 - val_loss: 0.6133 - val_acc: 0.6875\n",
            "Epoch 876/1000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.4883 - acc: 0.7663 - val_loss: 0.5907 - val_acc: 0.6771\n",
            "Epoch 877/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.4627 - acc: 0.7724 - val_loss: 0.6312 - val_acc: 0.6875\n",
            "Epoch 878/1000\n",
            "39/39 [==============================] - 6s 142ms/step - loss: 0.5173 - acc: 0.7467 - val_loss: 0.6036 - val_acc: 0.6667\n",
            "Epoch 879/1000\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 0.5012 - acc: 0.7467 - val_loss: 0.6124 - val_acc: 0.6771\n",
            "Epoch 880/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.4934 - acc: 0.7663 - val_loss: 0.6180 - val_acc: 0.6979\n",
            "Epoch 881/1000\n",
            "39/39 [==============================] - 6s 139ms/step - loss: 0.4838 - acc: 0.7549 - val_loss: 0.6191 - val_acc: 0.6771\n",
            "Epoch 882/1000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5154 - acc: 0.7500 - val_loss: 0.6166 - val_acc: 0.6667\n",
            "Epoch 883/1000\n",
            "39/39 [==============================] - 6s 153ms/step - loss: 0.5299 - acc: 0.7255 - val_loss: 0.5980 - val_acc: 0.7083\n",
            "Epoch 884/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5042 - acc: 0.7680 - val_loss: 0.5859 - val_acc: 0.6979\n",
            "Epoch 885/1000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.4619 - acc: 0.7876 - val_loss: 0.5811 - val_acc: 0.7083\n",
            "Epoch 886/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5453 - acc: 0.7255 - val_loss: 0.6256 - val_acc: 0.6667\n",
            "Epoch 887/1000\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 0.4881 - acc: 0.7533 - val_loss: 0.6004 - val_acc: 0.6875\n",
            "Epoch 888/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5112 - acc: 0.7353 - val_loss: 0.5975 - val_acc: 0.6771\n",
            "Epoch 889/1000\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 0.5085 - acc: 0.7516 - val_loss: 0.5873 - val_acc: 0.6875\n",
            "Epoch 890/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5192 - acc: 0.7484 - val_loss: 0.6348 - val_acc: 0.6562\n",
            "Epoch 891/1000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 0.5192 - acc: 0.7500 - val_loss: 0.5942 - val_acc: 0.6667\n",
            "Epoch 892/1000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.4976 - acc: 0.7516 - val_loss: 0.6214 - val_acc: 0.6667\n",
            "Epoch 893/1000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.4956 - acc: 0.7729 - val_loss: 0.6329 - val_acc: 0.6771\n",
            "Epoch 894/1000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 0.5102 - acc: 0.7402 - val_loss: 0.6062 - val_acc: 0.6875\n",
            "Epoch 895/1000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.4899 - acc: 0.7533 - val_loss: 0.6339 - val_acc: 0.6875\n",
            "Epoch 896/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.4785 - acc: 0.7663 - val_loss: 0.6090 - val_acc: 0.6562\n",
            "Epoch 897/1000\n",
            "39/39 [==============================] - 10s 239ms/step - loss: 0.5231 - acc: 0.7353 - val_loss: 0.6192 - val_acc: 0.6875\n",
            "Epoch 898/1000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.5005 - acc: 0.7516 - val_loss: 0.6130 - val_acc: 0.6562\n",
            "Epoch 899/1000\n",
            "39/39 [==============================] - 9s 232ms/step - loss: 0.5154 - acc: 0.7516 - val_loss: 0.6147 - val_acc: 0.6875\n",
            "Epoch 900/1000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 0.5131 - acc: 0.7500 - val_loss: 0.5954 - val_acc: 0.6875\n",
            "Epoch 901/1000\n",
            "39/39 [==============================] - 10s 241ms/step - loss: 0.5084 - acc: 0.7353 - val_loss: 0.5940 - val_acc: 0.6771\n",
            "Epoch 902/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5239 - acc: 0.7386 - val_loss: 0.5799 - val_acc: 0.6875\n",
            "Epoch 903/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5205 - acc: 0.7516 - val_loss: 0.5856 - val_acc: 0.6875\n",
            "Epoch 904/1000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.4841 - acc: 0.7565 - val_loss: 0.6039 - val_acc: 0.6771\n",
            "Epoch 905/1000\n",
            "39/39 [==============================] - 6s 139ms/step - loss: 0.5147 - acc: 0.7402 - val_loss: 0.6049 - val_acc: 0.6667\n",
            "Epoch 906/1000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.4789 - acc: 0.7696 - val_loss: 0.5730 - val_acc: 0.6875\n",
            "Epoch 907/1000\n",
            "39/39 [==============================] - 10s 238ms/step - loss: 0.4923 - acc: 0.7631 - val_loss: 0.5599 - val_acc: 0.6458\n",
            "Epoch 908/1000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 0.5226 - acc: 0.7614 - val_loss: 0.5823 - val_acc: 0.6875\n",
            "Epoch 909/1000\n",
            "39/39 [==============================] - 10s 237ms/step - loss: 0.4943 - acc: 0.7549 - val_loss: 0.5844 - val_acc: 0.6875\n",
            "Epoch 910/1000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 0.4845 - acc: 0.7516 - val_loss: 0.5966 - val_acc: 0.6771\n",
            "Epoch 911/1000\n",
            "39/39 [==============================] - 10s 233ms/step - loss: 0.5227 - acc: 0.7353 - val_loss: 0.5960 - val_acc: 0.6771\n",
            "Epoch 912/1000\n",
            "39/39 [==============================] - 5s 120ms/step - loss: 0.5209 - acc: 0.7337 - val_loss: 0.5810 - val_acc: 0.6354\n",
            "Epoch 913/1000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.5025 - acc: 0.7386 - val_loss: 0.5559 - val_acc: 0.7083\n",
            "Epoch 914/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5069 - acc: 0.7663 - val_loss: 0.5928 - val_acc: 0.6771\n",
            "Epoch 915/1000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5291 - acc: 0.7288 - val_loss: 0.5519 - val_acc: 0.7083\n",
            "Epoch 916/1000\n",
            "39/39 [==============================] - 5s 117ms/step - loss: 0.5173 - acc: 0.7451 - val_loss: 0.5821 - val_acc: 0.6771\n",
            "Epoch 917/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.4909 - acc: 0.7533 - val_loss: 0.5943 - val_acc: 0.6771\n",
            "Epoch 918/1000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5038 - acc: 0.7369 - val_loss: 0.5797 - val_acc: 0.6875\n",
            "Epoch 919/1000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.4935 - acc: 0.7696 - val_loss: 0.6046 - val_acc: 0.6771\n",
            "Epoch 920/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.5138 - acc: 0.7353 - val_loss: 0.5916 - val_acc: 0.6875\n",
            "Epoch 921/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.4998 - acc: 0.7582 - val_loss: 0.6032 - val_acc: 0.6771\n",
            "Epoch 922/1000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 0.5398 - acc: 0.7516 - val_loss: 0.5915 - val_acc: 0.6875\n",
            "Epoch 923/1000\n",
            "39/39 [==============================] - 5s 97ms/step - loss: 0.4964 - acc: 0.7647 - val_loss: 0.6027 - val_acc: 0.6562\n",
            "Epoch 924/1000\n",
            "39/39 [==============================] - 5s 103ms/step - loss: 0.5003 - acc: 0.7451 - val_loss: 0.6327 - val_acc: 0.6771\n",
            "Epoch 925/1000\n",
            "39/39 [==============================] - 10s 238ms/step - loss: 0.5176 - acc: 0.7320 - val_loss: 0.5994 - val_acc: 0.6875\n",
            "Epoch 926/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5222 - acc: 0.7631 - val_loss: 0.6031 - val_acc: 0.6458\n",
            "Epoch 927/1000\n",
            "39/39 [==============================] - 10s 241ms/step - loss: 0.5205 - acc: 0.7582 - val_loss: 0.5739 - val_acc: 0.6979\n",
            "Epoch 928/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.4753 - acc: 0.7827 - val_loss: 0.6127 - val_acc: 0.6458\n",
            "Epoch 929/1000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 0.4877 - acc: 0.7859 - val_loss: 0.5994 - val_acc: 0.6771\n",
            "Epoch 930/1000\n",
            "39/39 [==============================] - 5s 102ms/step - loss: 0.5358 - acc: 0.7206 - val_loss: 0.5737 - val_acc: 0.6771\n",
            "Epoch 931/1000\n",
            "39/39 [==============================] - 6s 140ms/step - loss: 0.5169 - acc: 0.7288 - val_loss: 0.5758 - val_acc: 0.7083\n",
            "Epoch 932/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.5212 - acc: 0.7582 - val_loss: 0.5957 - val_acc: 0.6875\n",
            "Epoch 933/1000\n",
            "39/39 [==============================] - 10s 235ms/step - loss: 0.5346 - acc: 0.7467 - val_loss: 0.6093 - val_acc: 0.6875\n",
            "Epoch 934/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5284 - acc: 0.7402 - val_loss: 0.6166 - val_acc: 0.6562\n",
            "Epoch 935/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5451 - acc: 0.7222 - val_loss: 0.5954 - val_acc: 0.6875\n",
            "Epoch 936/1000\n",
            "39/39 [==============================] - 10s 231ms/step - loss: 0.5426 - acc: 0.7206 - val_loss: 0.5914 - val_acc: 0.6875\n",
            "Epoch 937/1000\n",
            "39/39 [==============================] - 9s 233ms/step - loss: 0.4957 - acc: 0.7582 - val_loss: 0.6005 - val_acc: 0.6771\n",
            "Epoch 938/1000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 0.5339 - acc: 0.7239 - val_loss: 0.5964 - val_acc: 0.6667\n",
            "Epoch 939/1000\n",
            "39/39 [==============================] - 6s 129ms/step - loss: 0.5092 - acc: 0.7598 - val_loss: 0.5807 - val_acc: 0.6667\n",
            "Epoch 940/1000\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.4931 - acc: 0.7663 - val_loss: 0.5923 - val_acc: 0.6979\n",
            "Epoch 941/1000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5088 - acc: 0.7647 - val_loss: 0.5866 - val_acc: 0.6875\n",
            "Epoch 942/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.4811 - acc: 0.7647 - val_loss: 0.6067 - val_acc: 0.6979\n",
            "Epoch 943/1000\n",
            "39/39 [==============================] - 6s 133ms/step - loss: 0.5599 - acc: 0.7206 - val_loss: 0.5689 - val_acc: 0.6875\n",
            "Epoch 944/1000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.5268 - acc: 0.7356 - val_loss: 0.6219 - val_acc: 0.6875\n",
            "Epoch 945/1000\n",
            "39/39 [==============================] - 10s 243ms/step - loss: 0.5275 - acc: 0.7288 - val_loss: 0.5885 - val_acc: 0.6875\n",
            "Epoch 946/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5023 - acc: 0.7549 - val_loss: 0.5880 - val_acc: 0.6667\n",
            "Epoch 947/1000\n",
            "39/39 [==============================] - 6s 129ms/step - loss: 0.4991 - acc: 0.7484 - val_loss: 0.5815 - val_acc: 0.6875\n",
            "Epoch 948/1000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5112 - acc: 0.7516 - val_loss: 0.6196 - val_acc: 0.7083\n",
            "Epoch 949/1000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5037 - acc: 0.7484 - val_loss: 0.5760 - val_acc: 0.6875\n",
            "Epoch 950/1000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.5030 - acc: 0.7288 - val_loss: 0.5925 - val_acc: 0.6875\n",
            "Epoch 951/1000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5127 - acc: 0.7304 - val_loss: 0.5931 - val_acc: 0.6771\n",
            "Epoch 952/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5281 - acc: 0.7190 - val_loss: 0.5816 - val_acc: 0.6667\n",
            "Epoch 953/1000\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.5386 - acc: 0.7288 - val_loss: 0.5728 - val_acc: 0.6875\n",
            "Epoch 954/1000\n",
            "39/39 [==============================] - 5s 103ms/step - loss: 0.5336 - acc: 0.7533 - val_loss: 0.5709 - val_acc: 0.6875\n",
            "Epoch 955/1000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.4967 - acc: 0.7484 - val_loss: 0.6195 - val_acc: 0.6771\n",
            "Epoch 956/1000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.5072 - acc: 0.7565 - val_loss: 0.6158 - val_acc: 0.6667\n",
            "Epoch 957/1000\n",
            "39/39 [==============================] - 5s 112ms/step - loss: 0.4840 - acc: 0.7696 - val_loss: 0.5918 - val_acc: 0.6667\n",
            "Epoch 958/1000\n",
            "39/39 [==============================] - 6s 144ms/step - loss: 0.4822 - acc: 0.7892 - val_loss: 0.5801 - val_acc: 0.6979\n",
            "Epoch 959/1000\n",
            "39/39 [==============================] - 5s 113ms/step - loss: 0.4852 - acc: 0.7582 - val_loss: 0.5878 - val_acc: 0.6042\n",
            "Epoch 960/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5081 - acc: 0.7516 - val_loss: 0.5782 - val_acc: 0.6875\n",
            "Epoch 961/1000\n",
            "39/39 [==============================] - 10s 230ms/step - loss: 0.5350 - acc: 0.7337 - val_loss: 0.6067 - val_acc: 0.6771\n",
            "Epoch 962/1000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 0.4697 - acc: 0.7908 - val_loss: 0.5761 - val_acc: 0.6875\n",
            "Epoch 963/1000\n",
            "39/39 [==============================] - 6s 127ms/step - loss: 0.5011 - acc: 0.7533 - val_loss: 0.5782 - val_acc: 0.6771\n",
            "Epoch 964/1000\n",
            "39/39 [==============================] - 6s 123ms/step - loss: 0.5158 - acc: 0.7418 - val_loss: 0.5866 - val_acc: 0.6875\n",
            "Epoch 965/1000\n",
            "39/39 [==============================] - 6s 129ms/step - loss: 0.5378 - acc: 0.7467 - val_loss: 0.6083 - val_acc: 0.6667\n",
            "Epoch 966/1000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5033 - acc: 0.7676 - val_loss: 0.5945 - val_acc: 0.6562\n",
            "Epoch 967/1000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 0.5633 - acc: 0.7124 - val_loss: 0.5928 - val_acc: 0.6562\n",
            "Epoch 968/1000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 0.5014 - acc: 0.7582 - val_loss: 0.5956 - val_acc: 0.6875\n",
            "Epoch 969/1000\n",
            "39/39 [==============================] - 10s 236ms/step - loss: 0.5440 - acc: 0.7141 - val_loss: 0.6125 - val_acc: 0.6771\n",
            "Epoch 970/1000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 0.4931 - acc: 0.7549 - val_loss: 0.5969 - val_acc: 0.6771\n",
            "Epoch 971/1000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5244 - acc: 0.7239 - val_loss: 0.5830 - val_acc: 0.6979\n",
            "Epoch 972/1000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 0.4932 - acc: 0.7484 - val_loss: 0.5983 - val_acc: 0.6562\n",
            "Epoch 973/1000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5083 - acc: 0.7451 - val_loss: 0.5830 - val_acc: 0.6979\n",
            "Epoch 974/1000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.5146 - acc: 0.7353 - val_loss: 0.5972 - val_acc: 0.6771\n",
            "Epoch 975/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.4995 - acc: 0.7516 - val_loss: 0.5789 - val_acc: 0.6875\n",
            "Epoch 976/1000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 0.5146 - acc: 0.7516 - val_loss: 0.5973 - val_acc: 0.6771\n",
            "Epoch 977/1000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.4707 - acc: 0.7729 - val_loss: 0.5880 - val_acc: 0.6458\n",
            "Epoch 978/1000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 0.5139 - acc: 0.7467 - val_loss: 0.6106 - val_acc: 0.6667\n",
            "Epoch 979/1000\n",
            "39/39 [==============================] - 10s 239ms/step - loss: 0.5159 - acc: 0.7612 - val_loss: 0.6028 - val_acc: 0.6771\n",
            "Epoch 980/1000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 0.5244 - acc: 0.7271 - val_loss: 0.5900 - val_acc: 0.6562\n",
            "Epoch 981/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5563 - acc: 0.7173 - val_loss: 0.5748 - val_acc: 0.7083\n",
            "Epoch 982/1000\n",
            "39/39 [==============================] - 6s 141ms/step - loss: 0.5067 - acc: 0.7386 - val_loss: 0.5925 - val_acc: 0.6875\n",
            "Epoch 983/1000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5194 - acc: 0.7304 - val_loss: 0.6127 - val_acc: 0.6667\n",
            "Epoch 984/1000\n",
            "39/39 [==============================] - 10s 233ms/step - loss: 0.5491 - acc: 0.7484 - val_loss: 0.5869 - val_acc: 0.6667\n",
            "Epoch 985/1000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5442 - acc: 0.7418 - val_loss: 0.5890 - val_acc: 0.6771\n",
            "Epoch 986/1000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.4974 - acc: 0.7369 - val_loss: 0.5801 - val_acc: 0.6771\n",
            "Epoch 987/1000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5311 - acc: 0.7467 - val_loss: 0.6315 - val_acc: 0.6667\n",
            "Epoch 988/1000\n",
            "39/39 [==============================] - 5s 121ms/step - loss: 0.5306 - acc: 0.7386 - val_loss: 0.6083 - val_acc: 0.6875\n",
            "Epoch 989/1000\n",
            "39/39 [==============================] - 5s 114ms/step - loss: 0.5270 - acc: 0.7598 - val_loss: 0.6136 - val_acc: 0.6771\n",
            "Epoch 990/1000\n",
            "39/39 [==============================] - 5s 95ms/step - loss: 0.5386 - acc: 0.7435 - val_loss: 0.5923 - val_acc: 0.6667\n",
            "Epoch 991/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5103 - acc: 0.7435 - val_loss: 0.6148 - val_acc: 0.6667\n",
            "Epoch 992/1000\n",
            "39/39 [==============================] - 10s 236ms/step - loss: 0.5087 - acc: 0.7484 - val_loss: 0.6255 - val_acc: 0.6771\n",
            "Epoch 993/1000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 0.5285 - acc: 0.7500 - val_loss: 0.6101 - val_acc: 0.6771\n",
            "Epoch 994/1000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 0.5135 - acc: 0.7386 - val_loss: 0.6116 - val_acc: 0.6979\n",
            "Epoch 995/1000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5505 - acc: 0.7255 - val_loss: 0.6017 - val_acc: 0.6562\n",
            "Epoch 996/1000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.4884 - acc: 0.7647 - val_loss: 0.5965 - val_acc: 0.6667\n",
            "Epoch 997/1000\n",
            "39/39 [==============================] - 6s 138ms/step - loss: 0.5161 - acc: 0.7435 - val_loss: 0.5860 - val_acc: 0.6771\n",
            "Epoch 998/1000\n",
            "39/39 [==============================] - 6s 141ms/step - loss: 0.5087 - acc: 0.7418 - val_loss: 0.5828 - val_acc: 0.6667\n",
            "Epoch 999/1000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.5115 - acc: 0.7386 - val_loss: 0.6006 - val_acc: 0.6979\n",
            "Epoch 1000/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.5165 - acc: 0.7582 - val_loss: 0.5793 - val_acc: 0.6771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot training performance"
      ],
      "metadata": {
        "id": "YFxMJycOpEew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'co', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'k', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'co', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "     "
      ],
      "metadata": {
        "id": "l9PYKbRNpEK8",
        "outputId": "e814331d-9316-46ef-d0a7-e282ca22a3c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SAVE model"
      ],
      "metadata": {
        "id": "kNtlq_LZpKNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('./content/drive/My Drive/new', exist_ok=True)\n",
        "model.save('./content/drive/My Drive/new/2Class_UNfreeze_newdata.h5')"
      ],
      "metadata": {
        "id": "TegSVqblpLEZ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "KdsdaIgMpMeG"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"./content/drive/My Drive/new/2Class_UNfreeze_newdata.h5\")"
      ],
      "metadata": {
        "id": "sZFZ1c_kpMcN",
        "outputId": "8ba23ff6-7be0-4c4f-8da6-88c16532214c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_60aa8f7e-f36a-43bc-b7de-699853125104\", \"2Class_UNfreeze_newdata.h5\", 16602472)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gEfCB1RfpMZ6"
      },
      "execution_count": 34,
      "outputs": []
    }
  ]
}