{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPvMuXa4DZD9FxpYYEyzD5m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kittikhun62/efficientnet_keras_transfer_learning/blob/master/UNfreeze2Class_datanew.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# import from drive"
      ],
      "metadata": {
        "id": "bB2gfuYWczY-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpXyZ9k5YIJu",
        "outputId": "efe3d7e2-5413-40c9-c08b-bb0a03ed5e80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (r'/content/drive/My Drive/data - 2 class เพิ่ม 4 paper.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "7mqo2OLAc2pG",
        "outputId": "00e5256c-99dc-4068-aaf2-0024ec9a8133"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      No                      Name_file  \\\n",
              "0      1                        pore-sb   \n",
              "1      2                        pore-sb   \n",
              "2      3                        pore-sb   \n",
              "3      4                        pore-sb   \n",
              "4      5                        pore-sb   \n",
              "..   ...                            ...   \n",
              "825  826  1-s2.0-S2095268622000210-main   \n",
              "826  827  1-s2.0-S2095268622000210-main   \n",
              "827  828  1-s2.0-S2095268622000210-main   \n",
              "828  829  1-s2.0-S2095268622000210-main   \n",
              "829  830  1-s2.0-S2095268622000210-main   \n",
              "\n",
              "                                            Name_Paper  \\\n",
              "0    Preparation and electrochemical behaviour of b...   \n",
              "1    Preparation and electrochemical behaviour of b...   \n",
              "2    Preparation and electrochemical behaviour of b...   \n",
              "3    Preparation and electrochemical behaviour of b...   \n",
              "4    Preparation and electrochemical behaviour of b...   \n",
              "..                                                 ...   \n",
              "825  Integration of preparation of K, Na-embedded a...   \n",
              "826  Integration of preparation of K, Na-embedded a...   \n",
              "827  Integration of preparation of K, Na-embedded a...   \n",
              "828  Integration of preparation of K, Na-embedded a...   \n",
              "829  Integration of preparation of K, Na-embedded a...   \n",
              "\n",
              "                                               journal  \\\n",
              "0                                  Korean J. Chem. Eng   \n",
              "1                                  Korean J. Chem. Eng   \n",
              "2                                  Korean J. Chem. Eng   \n",
              "3                                  Korean J. Chem. Eng   \n",
              "4                                  Korean J. Chem. Eng   \n",
              "..                                                 ...   \n",
              "825  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "826  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "827  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "828  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "829  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "\n",
              "                                          path_Picture  detail  Class     BET  \\\n",
              "0    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom1  0-800  135.06   \n",
              "1    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom2  0-800  135.06   \n",
              "2    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom3  0-800  135.06   \n",
              "3    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom4  0-800  135.06   \n",
              "4    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom5  0-800  135.06   \n",
              "..                                                 ...     ...    ...     ...   \n",
              "825  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom21  0-800  301.70   \n",
              "826  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom22  0-800  301.70   \n",
              "827  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom23  0-800  301.70   \n",
              "828  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom24  0-800  301.70   \n",
              "829  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom25  0-800  301.70   \n",
              "\n",
              "     Size(mico)  Class_01  \n",
              "0            10         0  \n",
              "1            10         0  \n",
              "2            10         0  \n",
              "3            10         0  \n",
              "4            10         0  \n",
              "..          ...       ...  \n",
              "825          10         0  \n",
              "826          10         0  \n",
              "827          10         0  \n",
              "828          10         0  \n",
              "829          10         0  \n",
              "\n",
              "[830 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c57494a-528d-4ea7-9009-05bb121c9036\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>No</th>\n",
              "      <th>Name_file</th>\n",
              "      <th>Name_Paper</th>\n",
              "      <th>journal</th>\n",
              "      <th>path_Picture</th>\n",
              "      <th>detail</th>\n",
              "      <th>Class</th>\n",
              "      <th>BET</th>\n",
              "      <th>Size(mico)</th>\n",
              "      <th>Class_01</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom1</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom2</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom3</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom4</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom5</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>825</th>\n",
              "      <td>826</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom21</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>826</th>\n",
              "      <td>827</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom22</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>827</th>\n",
              "      <td>828</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom23</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>828</th>\n",
              "      <td>829</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom24</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>829</th>\n",
              "      <td>830</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom25</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>830 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c57494a-528d-4ea7-9009-05bb121c9036')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c57494a-528d-4ea7-9009-05bb121c9036 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c57494a-528d-4ea7-9009-05bb121c9036');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports library"
      ],
      "metadata": {
        "id": "VkYa-4LeTbir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "myAsBcVhTW7j"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## hyper parameter\n"
      ],
      "metadata": {
        "id": "T529UM_tVV-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "width = 150\n",
        "height = 150\n",
        "\n",
        "epochs = 2000 #จำนวนรอบในการ Train\n",
        "\n",
        "NUM_TRAIN = 628  # จำนวนภาพ Train\n",
        "NUM_TEST = 101 #จำนวนภาพ Test\n",
        "\n",
        "dropout_rate = 0.3\n",
        "input_shape = (height, width, 3) #ขนาด image enter"
      ],
      "metadata": {
        "id": "zXpmkJ2GVZ1l"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone efficientnet repo"
      ],
      "metadata": {
        "id": "DSSZIFGhUyQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/"
      ],
      "metadata": {
        "id": "nFvKcuBDTj1N",
        "outputId": "1731c41a-e387-430c-bd69-518455819cd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 1079, done.\u001b[K\n",
            "remote: Counting objects: 100% (242/242), done.\u001b[K\n",
            "remote: Compressing objects: 100% (121/121), done.\u001b[K\n",
            "remote: Total 1079 (delta 121), reused 241 (delta 121), pack-reused 837\u001b[K\n",
            "Receiving objects: 100% (1079/1079), 13.94 MiB | 21.90 MiB/s, done.\n",
            "Resolving deltas: 100% (618/618), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import efficientnet and load the conv base model"
      ],
      "metadata": {
        "id": "j3EgSOiSZHaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "iI3DQ18HU2TF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "#EfficientNet สร้างขึ้นสำหรับการจำแนกประเภท ImageNet ประกอบด้วยป้ายกำกับคลาส 1,000 รายการ เรามีเพียง 2 เลเยอร์เท่านั้น ซึ่งหมายความว่าเลเยอร์สองสามเลเยอร์สุดท้ายสำหรับการจำแนกไม่มีประโยชน์สำหรับเรา สามารถยกเว้นได้ขณะโหลดโมเดลโดยระบุอาร์กิวเมนต์ include_top เป็น False และนำไปใช้กับโมเดล ImageNet อื่นๆ ที่มีอยู่ในแอปพลิเคชัน Keras เช่นกัน\n",
        "\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "UmBDAgF_VAjq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "679da488-5e3e-4a37-c61e-0061c8064865"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "id": "rRXoFFzfU2Oi",
        "outputId": "9b96c480-eaf0-4ea5-fc26-22e94bae3913",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 4,007,548\n",
            "Non-trainable params: 42,016\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/new/2Class_datanew.h5')\n",
        "\n",
        "from efficientnet.layers import Swish, DropConnect\n",
        "from efficientnet.model import ConvKernalInitializer\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "\n",
        "get_custom_objects().update({\n",
        "    'ConvKernalInitializer': ConvKernalInitializer,\n",
        "    'Swish': Swish,\n",
        "    'DropConnect':DropConnect\n",
        "})"
      ],
      "metadata": {
        "id": "MwNk3sNbc2Qx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load model \n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/drive/My Drive/new/2Class_datanew.h5')\n",
        "height = width = model.input_shape[1]"
      ],
      "metadata": {
        "id": "4v4nzKQtJZ4z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/My Drive/new project'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Directories for our training,\n",
        "# validation and test splits\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.makedirs(test_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "UDxvF-b8Jcq1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, # image input 0-255 --> 0-1 เปลี่ยนค่าสี\n",
        "      rotation_range=40,# หมุนภาพในองศา\n",
        "      width_shift_range=0.2, #เปลี่ยนความกว้าง\n",
        "      height_shift_range=0.2, #ปลี่ยนความสูง\n",
        "      shear_range=0.2, #ทำให้ภาพเบี้ยว\n",
        "      zoom_range=0.2, # Randomly zoom image\n",
        "      horizontal_flip=True, \n",
        "      #โดย Default เมื่อมีการเลื่อนภาพ บิดภาพ หมุนภาพ จะเกิดพื้นที่ว่างที่มุม \n",
        "      #ซึ่งจะมีการเติมภาพให้เต็มโดยใช้เทคนิคแบบ Nearest neighbor ซึ่งเป็นการดึงสีบริเวณใหล้าเคียงมาระบายให้เต็ม แต่เราก็ยังสามารถกำหนดวิธีการ Fill ภาพด้วยเทคนิคอื่นได้จาก Parameter fill_mode\n",
        "      fill_mode='nearest')\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory #ไดเรกเป้าหมาย\n",
        "        train_dir,\n",
        "        # รูปภาพทั้งหมดจะถูกปรับขนาดตามความสูงและความกว้างของเป้าหมาย\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        #เนื่องจากเราใช้ categorical_crossentropy loss เราจึงต้องมีป้ายกำกับตามหมวดหมู่\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory( #การดึงภาพจาก Directory มาเข้าโมเดล \n",
        "        validation_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "     \n",
        "\n"
      ],
      "metadata": {
        "id": "znE38DtIJeN-",
        "outputId": "ff4c3db3-3b68-469f-a9a3-29151cdb056b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 628 images belonging to 2 classes.\n",
            "Found 101 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multiply_16\n",
        "# set 'multiply_16' and following layers trainable\n",
        "model.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'multiply_16':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False  \n",
        "     "
      ],
      "metadata": {
        "id": "tEaPoHJCJq13"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IC-3EwwkJHGS",
        "outputId": "6fbaba69-d14d-42e9-8166-96c9ea9a1845"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 2)                 2562      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,052,126\n",
            "Trainable params: 4,010,110\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "z7ERVUfUJsQq",
        "outputId": "e7335791-b133-41f4-c81c-7b985dd0f8aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-15-caa7b37242a8>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "39/39 [==============================] - 74s 2s/step - loss: 0.5190 - acc: 0.7500 - val_loss: 0.6107 - val_acc: 0.6771\n",
            "Epoch 2/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.5347 - acc: 0.7369 - val_loss: 0.6132 - val_acc: 0.6562\n",
            "Epoch 3/2000\n",
            "39/39 [==============================] - 9s 204ms/step - loss: 0.5109 - acc: 0.7565 - val_loss: 0.6220 - val_acc: 0.6875\n",
            "Epoch 4/2000\n",
            "39/39 [==============================] - 8s 211ms/step - loss: 0.4955 - acc: 0.7386 - val_loss: 0.6136 - val_acc: 0.6771\n",
            "Epoch 5/2000\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 0.5165 - acc: 0.7614 - val_loss: 0.6250 - val_acc: 0.6562\n",
            "Epoch 6/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5247 - acc: 0.7369 - val_loss: 0.6079 - val_acc: 0.6562\n",
            "Epoch 7/2000\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 0.5192 - acc: 0.7320 - val_loss: 0.6171 - val_acc: 0.6979\n",
            "Epoch 8/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.5347 - acc: 0.7059 - val_loss: 0.6151 - val_acc: 0.6667\n",
            "Epoch 9/2000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 0.5188 - acc: 0.7320 - val_loss: 0.6197 - val_acc: 0.6667\n",
            "Epoch 10/2000\n",
            "39/39 [==============================] - 9s 209ms/step - loss: 0.5092 - acc: 0.7500 - val_loss: 0.6366 - val_acc: 0.6771\n",
            "Epoch 11/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5068 - acc: 0.7533 - val_loss: 0.6233 - val_acc: 0.6771\n",
            "Epoch 12/2000\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.5324 - acc: 0.7288 - val_loss: 0.6323 - val_acc: 0.6979\n",
            "Epoch 13/2000\n",
            "39/39 [==============================] - 4s 78ms/step - loss: 0.5329 - acc: 0.7239 - val_loss: 0.6118 - val_acc: 0.6771\n",
            "Epoch 14/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5122 - acc: 0.7402 - val_loss: 0.6027 - val_acc: 0.6667\n",
            "Epoch 15/2000\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.5066 - acc: 0.7467 - val_loss: 0.6238 - val_acc: 0.6562\n",
            "Epoch 16/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 0.5173 - acc: 0.7369 - val_loss: 0.6474 - val_acc: 0.6979\n",
            "Epoch 17/2000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 0.5336 - acc: 0.7435 - val_loss: 0.6489 - val_acc: 0.6771\n",
            "Epoch 18/2000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 0.5109 - acc: 0.7516 - val_loss: 0.6416 - val_acc: 0.6979\n",
            "Epoch 19/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.5123 - acc: 0.7337 - val_loss: 0.6123 - val_acc: 0.6979\n",
            "Epoch 20/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5175 - acc: 0.7372 - val_loss: 0.6149 - val_acc: 0.6875\n",
            "Epoch 21/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.5246 - acc: 0.7402 - val_loss: 0.6147 - val_acc: 0.6771\n",
            "Epoch 22/2000\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.5030 - acc: 0.7500 - val_loss: 0.6131 - val_acc: 0.6562\n",
            "Epoch 23/2000\n",
            "39/39 [==============================] - 4s 78ms/step - loss: 0.4666 - acc: 0.7810 - val_loss: 0.6030 - val_acc: 0.6667\n",
            "Epoch 24/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.4754 - acc: 0.7859 - val_loss: 0.5828 - val_acc: 0.6771\n",
            "Epoch 25/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.5323 - acc: 0.7337 - val_loss: 0.6067 - val_acc: 0.6771\n",
            "Epoch 26/2000\n",
            "39/39 [==============================] - 8s 202ms/step - loss: 0.5235 - acc: 0.7222 - val_loss: 0.5983 - val_acc: 0.6771\n",
            "Epoch 27/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5394 - acc: 0.7451 - val_loss: 0.6033 - val_acc: 0.6979\n",
            "Epoch 28/2000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 0.4866 - acc: 0.7386 - val_loss: 0.5936 - val_acc: 0.6562\n",
            "Epoch 29/2000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 0.5186 - acc: 0.7533 - val_loss: 0.6169 - val_acc: 0.6667\n",
            "Epoch 30/2000\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 0.4986 - acc: 0.7565 - val_loss: 0.6014 - val_acc: 0.6562\n",
            "Epoch 31/2000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 0.5377 - acc: 0.7239 - val_loss: 0.5919 - val_acc: 0.6771\n",
            "Epoch 32/2000\n",
            "39/39 [==============================] - 8s 201ms/step - loss: 0.5300 - acc: 0.7320 - val_loss: 0.6064 - val_acc: 0.6667\n",
            "Epoch 33/2000\n",
            "39/39 [==============================] - 8s 202ms/step - loss: 0.5319 - acc: 0.7386 - val_loss: 0.5676 - val_acc: 0.6875\n",
            "Epoch 34/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5229 - acc: 0.7337 - val_loss: 0.6153 - val_acc: 0.6562\n",
            "Epoch 35/2000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 0.5372 - acc: 0.7356 - val_loss: 0.6272 - val_acc: 0.6562\n",
            "Epoch 36/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.4928 - acc: 0.7794 - val_loss: 0.5958 - val_acc: 0.6771\n",
            "Epoch 37/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.4856 - acc: 0.7794 - val_loss: 0.6028 - val_acc: 0.6667\n",
            "Epoch 38/2000\n",
            "39/39 [==============================] - 9s 208ms/step - loss: 0.5169 - acc: 0.7484 - val_loss: 0.6205 - val_acc: 0.6458\n",
            "Epoch 39/2000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 0.5323 - acc: 0.7451 - val_loss: 0.6260 - val_acc: 0.6562\n",
            "Epoch 40/2000\n",
            "39/39 [==============================] - 8s 202ms/step - loss: 0.4886 - acc: 0.7614 - val_loss: 0.6125 - val_acc: 0.6667\n",
            "Epoch 41/2000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 0.5387 - acc: 0.7239 - val_loss: 0.6407 - val_acc: 0.6458\n",
            "Epoch 42/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.5032 - acc: 0.7794 - val_loss: 0.6220 - val_acc: 0.6771\n",
            "Epoch 43/2000\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 0.5125 - acc: 0.7467 - val_loss: 0.6144 - val_acc: 0.6667\n",
            "Epoch 44/2000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 0.5084 - acc: 0.7320 - val_loss: 0.6048 - val_acc: 0.6562\n",
            "Epoch 45/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5096 - acc: 0.7631 - val_loss: 0.6326 - val_acc: 0.6562\n",
            "Epoch 46/2000\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 0.5116 - acc: 0.7451 - val_loss: 0.6146 - val_acc: 0.6562\n",
            "Epoch 47/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.5083 - acc: 0.7435 - val_loss: 0.6433 - val_acc: 0.6562\n",
            "Epoch 48/2000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 0.4890 - acc: 0.7778 - val_loss: 0.6138 - val_acc: 0.6458\n",
            "Epoch 49/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5187 - acc: 0.7435 - val_loss: 0.6334 - val_acc: 0.6667\n",
            "Epoch 50/2000\n",
            "39/39 [==============================] - 4s 80ms/step - loss: 0.5192 - acc: 0.7402 - val_loss: 0.6463 - val_acc: 0.6875\n",
            "Epoch 51/2000\n",
            "39/39 [==============================] - 9s 209ms/step - loss: 0.5388 - acc: 0.7288 - val_loss: 0.6267 - val_acc: 0.6667\n",
            "Epoch 52/2000\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 0.5034 - acc: 0.7386 - val_loss: 0.6110 - val_acc: 0.6771\n",
            "Epoch 53/2000\n",
            "39/39 [==============================] - 9s 207ms/step - loss: 0.5122 - acc: 0.7467 - val_loss: 0.5858 - val_acc: 0.6667\n",
            "Epoch 54/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5108 - acc: 0.7516 - val_loss: 0.6296 - val_acc: 0.7083\n",
            "Epoch 55/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.5282 - acc: 0.7173 - val_loss: 0.6174 - val_acc: 0.6458\n",
            "Epoch 56/2000\n",
            "39/39 [==============================] - 9s 208ms/step - loss: 0.5098 - acc: 0.7729 - val_loss: 0.5983 - val_acc: 0.6771\n",
            "Epoch 57/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5010 - acc: 0.7582 - val_loss: 0.5957 - val_acc: 0.6875\n",
            "Epoch 58/2000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 0.5107 - acc: 0.7516 - val_loss: 0.6061 - val_acc: 0.6771\n",
            "Epoch 59/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5103 - acc: 0.7500 - val_loss: 0.6071 - val_acc: 0.6771\n",
            "Epoch 60/2000\n",
            "39/39 [==============================] - 9s 205ms/step - loss: 0.5395 - acc: 0.7418 - val_loss: 0.6161 - val_acc: 0.6562\n",
            "Epoch 61/2000\n",
            "39/39 [==============================] - 8s 211ms/step - loss: 0.5031 - acc: 0.7369 - val_loss: 0.6096 - val_acc: 0.6667\n",
            "Epoch 62/2000\n",
            "39/39 [==============================] - 8s 202ms/step - loss: 0.5261 - acc: 0.7484 - val_loss: 0.6047 - val_acc: 0.6354\n",
            "Epoch 63/2000\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 0.5239 - acc: 0.7484 - val_loss: 0.5895 - val_acc: 0.6979\n",
            "Epoch 64/2000\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.5288 - acc: 0.7402 - val_loss: 0.6240 - val_acc: 0.6771\n",
            "Epoch 65/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.4881 - acc: 0.7680 - val_loss: 0.6091 - val_acc: 0.6979\n",
            "Epoch 66/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.4861 - acc: 0.7516 - val_loss: 0.5837 - val_acc: 0.6875\n",
            "Epoch 67/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.5307 - acc: 0.7206 - val_loss: 0.5854 - val_acc: 0.6562\n",
            "Epoch 68/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.4739 - acc: 0.7631 - val_loss: 0.5973 - val_acc: 0.6562\n",
            "Epoch 69/2000\n",
            "39/39 [==============================] - 8s 212ms/step - loss: 0.4819 - acc: 0.7663 - val_loss: 0.5925 - val_acc: 0.6771\n",
            "Epoch 70/2000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 0.5105 - acc: 0.7467 - val_loss: 0.5954 - val_acc: 0.6354\n",
            "Epoch 71/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5237 - acc: 0.7304 - val_loss: 0.6063 - val_acc: 0.6771\n",
            "Epoch 72/2000\n",
            "39/39 [==============================] - 4s 78ms/step - loss: 0.5152 - acc: 0.7565 - val_loss: 0.5772 - val_acc: 0.6771\n",
            "Epoch 73/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.4755 - acc: 0.7761 - val_loss: 0.5979 - val_acc: 0.6458\n",
            "Epoch 74/2000\n",
            "39/39 [==============================] - 3s 82ms/step - loss: 0.4736 - acc: 0.7745 - val_loss: 0.5926 - val_acc: 0.6562\n",
            "Epoch 75/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5475 - acc: 0.7288 - val_loss: 0.5888 - val_acc: 0.6771\n",
            "Epoch 76/2000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 0.5124 - acc: 0.7320 - val_loss: 0.5949 - val_acc: 0.6771\n",
            "Epoch 77/2000\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 0.5039 - acc: 0.7500 - val_loss: 0.5686 - val_acc: 0.6562\n",
            "Epoch 78/2000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 0.5039 - acc: 0.7549 - val_loss: 0.5854 - val_acc: 0.6667\n",
            "Epoch 79/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5050 - acc: 0.7500 - val_loss: 0.5882 - val_acc: 0.6771\n",
            "Epoch 80/2000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 0.5087 - acc: 0.7402 - val_loss: 0.5742 - val_acc: 0.6562\n",
            "Epoch 81/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.4944 - acc: 0.7451 - val_loss: 0.5985 - val_acc: 0.6667\n",
            "Epoch 82/2000\n",
            "39/39 [==============================] - 4s 79ms/step - loss: 0.5340 - acc: 0.7206 - val_loss: 0.5974 - val_acc: 0.6771\n",
            "Epoch 83/2000\n",
            "39/39 [==============================] - 4s 78ms/step - loss: 0.5622 - acc: 0.7157 - val_loss: 0.6207 - val_acc: 0.6875\n",
            "Epoch 84/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 0.5002 - acc: 0.7500 - val_loss: 0.6047 - val_acc: 0.6771\n",
            "Epoch 85/2000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 0.5308 - acc: 0.7124 - val_loss: 0.6056 - val_acc: 0.6771\n",
            "Epoch 86/2000\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 0.5063 - acc: 0.7533 - val_loss: 0.6224 - val_acc: 0.6667\n",
            "Epoch 87/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.4960 - acc: 0.7451 - val_loss: 0.6010 - val_acc: 0.6562\n",
            "Epoch 88/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5157 - acc: 0.7467 - val_loss: 0.6021 - val_acc: 0.6771\n",
            "Epoch 89/2000\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 0.5672 - acc: 0.6928 - val_loss: 0.5956 - val_acc: 0.6458\n",
            "Epoch 90/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.4948 - acc: 0.7598 - val_loss: 0.6341 - val_acc: 0.6667\n",
            "Epoch 91/2000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 0.5193 - acc: 0.7239 - val_loss: 0.5903 - val_acc: 0.6771\n",
            "Epoch 92/2000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 0.4999 - acc: 0.7614 - val_loss: 0.6105 - val_acc: 0.6771\n",
            "Epoch 93/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5156 - acc: 0.7320 - val_loss: 0.5963 - val_acc: 0.6667\n",
            "Epoch 94/2000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 0.4820 - acc: 0.7451 - val_loss: 0.5913 - val_acc: 0.6667\n",
            "Epoch 95/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5236 - acc: 0.7190 - val_loss: 0.6007 - val_acc: 0.6667\n",
            "Epoch 96/2000\n",
            "39/39 [==============================] - 8s 203ms/step - loss: 0.5279 - acc: 0.7386 - val_loss: 0.6085 - val_acc: 0.6562\n",
            "Epoch 97/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.4870 - acc: 0.7680 - val_loss: 0.5904 - val_acc: 0.6979\n",
            "Epoch 98/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5008 - acc: 0.7418 - val_loss: 0.5812 - val_acc: 0.6458\n",
            "Epoch 99/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5266 - acc: 0.7239 - val_loss: 0.5685 - val_acc: 0.6771\n",
            "Epoch 100/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5181 - acc: 0.7484 - val_loss: 0.5803 - val_acc: 0.6667\n",
            "Epoch 101/2000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 0.4833 - acc: 0.7729 - val_loss: 0.6080 - val_acc: 0.6562\n",
            "Epoch 102/2000\n",
            "39/39 [==============================] - 8s 202ms/step - loss: 0.5008 - acc: 0.7549 - val_loss: 0.6000 - val_acc: 0.6667\n",
            "Epoch 103/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.4854 - acc: 0.7729 - val_loss: 0.5839 - val_acc: 0.7188\n",
            "Epoch 104/2000\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 0.5223 - acc: 0.7353 - val_loss: 0.5990 - val_acc: 0.6979\n",
            "Epoch 105/2000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 0.4929 - acc: 0.7663 - val_loss: 0.5919 - val_acc: 0.6250\n",
            "Epoch 106/2000\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 0.4938 - acc: 0.7663 - val_loss: 0.5866 - val_acc: 0.6667\n",
            "Epoch 107/2000\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 0.4821 - acc: 0.7582 - val_loss: 0.5966 - val_acc: 0.6771\n",
            "Epoch 108/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.5184 - acc: 0.7337 - val_loss: 0.6083 - val_acc: 0.6875\n",
            "Epoch 109/2000\n",
            "39/39 [==============================] - 9s 204ms/step - loss: 0.5152 - acc: 0.7386 - val_loss: 0.5978 - val_acc: 0.6562\n",
            "Epoch 110/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.5094 - acc: 0.7222 - val_loss: 0.5663 - val_acc: 0.6979\n",
            "Epoch 111/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5231 - acc: 0.7320 - val_loss: 0.5706 - val_acc: 0.6250\n",
            "Epoch 112/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.5092 - acc: 0.7582 - val_loss: 0.5812 - val_acc: 0.6458\n",
            "Epoch 113/2000\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.4915 - acc: 0.7663 - val_loss: 0.5857 - val_acc: 0.7083\n",
            "Epoch 114/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5087 - acc: 0.7484 - val_loss: 0.5863 - val_acc: 0.6771\n",
            "Epoch 115/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.4768 - acc: 0.7565 - val_loss: 0.6120 - val_acc: 0.6562\n",
            "Epoch 116/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5124 - acc: 0.7500 - val_loss: 0.5877 - val_acc: 0.6562\n",
            "Epoch 117/2000\n",
            "39/39 [==============================] - 8s 202ms/step - loss: 0.5328 - acc: 0.7402 - val_loss: 0.6023 - val_acc: 0.6562\n",
            "Epoch 118/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5395 - acc: 0.7239 - val_loss: 0.5957 - val_acc: 0.7188\n",
            "Epoch 119/2000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 0.4977 - acc: 0.7288 - val_loss: 0.5999 - val_acc: 0.6979\n",
            "Epoch 120/2000\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.4925 - acc: 0.7418 - val_loss: 0.5906 - val_acc: 0.6875\n",
            "Epoch 121/2000\n",
            "39/39 [==============================] - 9s 208ms/step - loss: 0.5457 - acc: 0.7124 - val_loss: 0.6024 - val_acc: 0.6979\n",
            "Epoch 122/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5307 - acc: 0.7255 - val_loss: 0.5844 - val_acc: 0.6875\n",
            "Epoch 123/2000\n",
            "39/39 [==============================] - 4s 76ms/step - loss: 0.4815 - acc: 0.7712 - val_loss: 0.5823 - val_acc: 0.7188\n",
            "Epoch 124/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.5545 - acc: 0.7206 - val_loss: 0.5877 - val_acc: 0.7083\n",
            "Epoch 125/2000\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 0.5085 - acc: 0.7418 - val_loss: 0.5961 - val_acc: 0.6771\n",
            "Epoch 126/2000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 0.5073 - acc: 0.7484 - val_loss: 0.5859 - val_acc: 0.6667\n",
            "Epoch 127/2000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 0.5378 - acc: 0.7320 - val_loss: 0.5913 - val_acc: 0.6250\n",
            "Epoch 128/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5134 - acc: 0.7451 - val_loss: 0.5734 - val_acc: 0.7083\n",
            "Epoch 129/2000\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.4967 - acc: 0.7533 - val_loss: 0.5927 - val_acc: 0.6979\n",
            "Epoch 130/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.5210 - acc: 0.7484 - val_loss: 0.5804 - val_acc: 0.6458\n",
            "Epoch 131/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5009 - acc: 0.7451 - val_loss: 0.5767 - val_acc: 0.6667\n",
            "Epoch 132/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5260 - acc: 0.7369 - val_loss: 0.5963 - val_acc: 0.6667\n",
            "Epoch 133/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.5332 - acc: 0.7288 - val_loss: 0.5901 - val_acc: 0.7188\n",
            "Epoch 134/2000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 0.5283 - acc: 0.7320 - val_loss: 0.5843 - val_acc: 0.6250\n",
            "Epoch 135/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5149 - acc: 0.7386 - val_loss: 0.5688 - val_acc: 0.6458\n",
            "Epoch 136/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5018 - acc: 0.7500 - val_loss: 0.5535 - val_acc: 0.6667\n",
            "Epoch 137/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5211 - acc: 0.7320 - val_loss: 0.5654 - val_acc: 0.7188\n",
            "Epoch 138/2000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 0.4951 - acc: 0.7729 - val_loss: 0.5978 - val_acc: 0.6458\n",
            "Epoch 139/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5466 - acc: 0.7435 - val_loss: 0.5919 - val_acc: 0.6458\n",
            "Epoch 140/2000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 0.5333 - acc: 0.7369 - val_loss: 0.5786 - val_acc: 0.6458\n",
            "Epoch 141/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5127 - acc: 0.7304 - val_loss: 0.6109 - val_acc: 0.6875\n",
            "Epoch 142/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.4985 - acc: 0.7484 - val_loss: 0.6064 - val_acc: 0.6458\n",
            "Epoch 143/2000\n",
            "39/39 [==============================] - 6s 137ms/step - loss: 0.5042 - acc: 0.7614 - val_loss: 0.6170 - val_acc: 0.6667\n",
            "Epoch 144/2000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 0.4890 - acc: 0.7644 - val_loss: 0.5954 - val_acc: 0.6562\n",
            "Epoch 145/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5105 - acc: 0.7565 - val_loss: 0.6093 - val_acc: 0.6562\n",
            "Epoch 146/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5526 - acc: 0.7141 - val_loss: 0.6090 - val_acc: 0.6354\n",
            "Epoch 147/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.5097 - acc: 0.7533 - val_loss: 0.5943 - val_acc: 0.6667\n",
            "Epoch 148/2000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 0.5291 - acc: 0.7271 - val_loss: 0.6293 - val_acc: 0.6875\n",
            "Epoch 149/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.4889 - acc: 0.7761 - val_loss: 0.6300 - val_acc: 0.6979\n",
            "Epoch 150/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5081 - acc: 0.7435 - val_loss: 0.6290 - val_acc: 0.6562\n",
            "Epoch 151/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.5444 - acc: 0.7157 - val_loss: 0.5987 - val_acc: 0.6354\n",
            "Epoch 152/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.5259 - acc: 0.7288 - val_loss: 0.6067 - val_acc: 0.6042\n",
            "Epoch 153/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.4736 - acc: 0.7516 - val_loss: 0.6322 - val_acc: 0.6667\n",
            "Epoch 154/2000\n",
            "39/39 [==============================] - 4s 104ms/step - loss: 0.5398 - acc: 0.7271 - val_loss: 0.5936 - val_acc: 0.6979\n",
            "Epoch 155/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.5234 - acc: 0.7304 - val_loss: 0.6171 - val_acc: 0.6562\n",
            "Epoch 156/2000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 0.5274 - acc: 0.7353 - val_loss: 0.5998 - val_acc: 0.6875\n",
            "Epoch 157/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5067 - acc: 0.7484 - val_loss: 0.5962 - val_acc: 0.6146\n",
            "Epoch 158/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5263 - acc: 0.7369 - val_loss: 0.6146 - val_acc: 0.6562\n",
            "Epoch 159/2000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 0.5372 - acc: 0.7402 - val_loss: 0.5982 - val_acc: 0.6354\n",
            "Epoch 160/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5264 - acc: 0.7369 - val_loss: 0.6042 - val_acc: 0.6354\n",
            "Epoch 161/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5412 - acc: 0.7206 - val_loss: 0.5997 - val_acc: 0.6667\n",
            "Epoch 162/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.5229 - acc: 0.7239 - val_loss: 0.6076 - val_acc: 0.6458\n",
            "Epoch 163/2000\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 0.5191 - acc: 0.7353 - val_loss: 0.5986 - val_acc: 0.6562\n",
            "Epoch 164/2000\n",
            "39/39 [==============================] - 9s 208ms/step - loss: 0.5468 - acc: 0.7206 - val_loss: 0.6081 - val_acc: 0.6771\n",
            "Epoch 165/2000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 0.5398 - acc: 0.7141 - val_loss: 0.6075 - val_acc: 0.6667\n",
            "Epoch 166/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.5141 - acc: 0.7337 - val_loss: 0.6030 - val_acc: 0.6562\n",
            "Epoch 167/2000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 0.5045 - acc: 0.7582 - val_loss: 0.6422 - val_acc: 0.6979\n",
            "Epoch 168/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.5406 - acc: 0.7369 - val_loss: 0.6206 - val_acc: 0.6667\n",
            "Epoch 169/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 0.5244 - acc: 0.7173 - val_loss: 0.6242 - val_acc: 0.6771\n",
            "Epoch 170/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5003 - acc: 0.7451 - val_loss: 0.6237 - val_acc: 0.7083\n",
            "Epoch 171/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.5231 - acc: 0.7320 - val_loss: 0.5835 - val_acc: 0.6771\n",
            "Epoch 172/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5032 - acc: 0.7353 - val_loss: 0.5937 - val_acc: 0.6562\n",
            "Epoch 173/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.5080 - acc: 0.7402 - val_loss: 0.6240 - val_acc: 0.6979\n",
            "Epoch 174/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.5635 - acc: 0.7092 - val_loss: 0.6059 - val_acc: 0.6771\n",
            "Epoch 175/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5000 - acc: 0.7451 - val_loss: 0.6557 - val_acc: 0.6771\n",
            "Epoch 176/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5129 - acc: 0.7484 - val_loss: 0.5992 - val_acc: 0.6458\n",
            "Epoch 177/2000\n",
            "39/39 [==============================] - 5s 98ms/step - loss: 0.4945 - acc: 0.7337 - val_loss: 0.6138 - val_acc: 0.6667\n",
            "Epoch 178/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.4586 - acc: 0.7810 - val_loss: 0.6085 - val_acc: 0.6667\n",
            "Epoch 179/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 0.5222 - acc: 0.7500 - val_loss: 0.6117 - val_acc: 0.6875\n",
            "Epoch 180/2000\n",
            "39/39 [==============================] - 8s 203ms/step - loss: 0.5316 - acc: 0.7141 - val_loss: 0.5881 - val_acc: 0.6562\n",
            "Epoch 181/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 0.5072 - acc: 0.7402 - val_loss: 0.5816 - val_acc: 0.6875\n",
            "Epoch 182/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.5123 - acc: 0.7582 - val_loss: 0.6151 - val_acc: 0.6771\n",
            "Epoch 183/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5483 - acc: 0.7337 - val_loss: 0.6290 - val_acc: 0.6458\n",
            "Epoch 184/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.4991 - acc: 0.7565 - val_loss: 0.6068 - val_acc: 0.6562\n",
            "Epoch 185/2000\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 0.5493 - acc: 0.7124 - val_loss: 0.6113 - val_acc: 0.6562\n",
            "Epoch 186/2000\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 0.4853 - acc: 0.7663 - val_loss: 0.6086 - val_acc: 0.6667\n",
            "Epoch 187/2000\n",
            "39/39 [==============================] - 9s 204ms/step - loss: 0.5157 - acc: 0.7500 - val_loss: 0.5791 - val_acc: 0.6875\n",
            "Epoch 188/2000\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 0.4762 - acc: 0.7794 - val_loss: 0.6140 - val_acc: 0.6875\n",
            "Epoch 189/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.4769 - acc: 0.7696 - val_loss: 0.5985 - val_acc: 0.6875\n",
            "Epoch 190/2000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 0.5058 - acc: 0.7353 - val_loss: 0.6244 - val_acc: 0.6667\n",
            "Epoch 191/2000\n",
            "39/39 [==============================] - 8s 203ms/step - loss: 0.5259 - acc: 0.7222 - val_loss: 0.6293 - val_acc: 0.6979\n",
            "Epoch 192/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5107 - acc: 0.7533 - val_loss: 0.6098 - val_acc: 0.6875\n",
            "Epoch 193/2000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 0.4950 - acc: 0.7516 - val_loss: 0.6105 - val_acc: 0.6562\n",
            "Epoch 194/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5049 - acc: 0.7337 - val_loss: 0.6309 - val_acc: 0.6771\n",
            "Epoch 195/2000\n",
            "39/39 [==============================] - 8s 211ms/step - loss: 0.5172 - acc: 0.7386 - val_loss: 0.6416 - val_acc: 0.6562\n",
            "Epoch 196/2000\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 0.5204 - acc: 0.7663 - val_loss: 0.6192 - val_acc: 0.6875\n",
            "Epoch 197/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5393 - acc: 0.7059 - val_loss: 0.6162 - val_acc: 0.6875\n",
            "Epoch 198/2000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 0.5271 - acc: 0.7304 - val_loss: 0.6117 - val_acc: 0.6354\n",
            "Epoch 199/2000\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 0.4853 - acc: 0.7500 - val_loss: 0.6145 - val_acc: 0.6146\n",
            "Epoch 200/2000\n",
            "39/39 [==============================] - 4s 80ms/step - loss: 0.5076 - acc: 0.7467 - val_loss: 0.6077 - val_acc: 0.6146\n",
            "Epoch 201/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.4838 - acc: 0.7549 - val_loss: 0.6439 - val_acc: 0.6667\n",
            "Epoch 202/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5311 - acc: 0.7386 - val_loss: 0.6196 - val_acc: 0.6458\n",
            "Epoch 203/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.5242 - acc: 0.7337 - val_loss: 0.6229 - val_acc: 0.6771\n",
            "Epoch 204/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.5306 - acc: 0.7271 - val_loss: 0.6226 - val_acc: 0.6458\n",
            "Epoch 205/2000\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 0.4986 - acc: 0.7516 - val_loss: 0.6249 - val_acc: 0.6458\n",
            "Epoch 206/2000\n",
            "39/39 [==============================] - 5s 98ms/step - loss: 0.5049 - acc: 0.7467 - val_loss: 0.6183 - val_acc: 0.6458\n",
            "Epoch 207/2000\n",
            "39/39 [==============================] - 4s 80ms/step - loss: 0.5185 - acc: 0.7451 - val_loss: 0.6321 - val_acc: 0.6458\n",
            "Epoch 208/2000\n",
            "39/39 [==============================] - 4s 104ms/step - loss: 0.5317 - acc: 0.7353 - val_loss: 0.6480 - val_acc: 0.6667\n",
            "Epoch 209/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 0.5027 - acc: 0.7533 - val_loss: 0.6429 - val_acc: 0.6875\n",
            "Epoch 210/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.4965 - acc: 0.7663 - val_loss: 0.6398 - val_acc: 0.6771\n",
            "Epoch 211/2000\n",
            "39/39 [==============================] - 10s 233ms/step - loss: 0.5261 - acc: 0.7549 - val_loss: 0.6219 - val_acc: 0.6250\n",
            "Epoch 212/2000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 0.5289 - acc: 0.7157 - val_loss: 0.6288 - val_acc: 0.7083\n",
            "Epoch 213/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.4688 - acc: 0.7663 - val_loss: 0.6542 - val_acc: 0.6979\n",
            "Epoch 214/2000\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 0.5048 - acc: 0.7582 - val_loss: 0.6409 - val_acc: 0.6667\n",
            "Epoch 215/2000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 0.5031 - acc: 0.7598 - val_loss: 0.6230 - val_acc: 0.6771\n",
            "Epoch 216/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.4945 - acc: 0.7484 - val_loss: 0.5990 - val_acc: 0.6875\n",
            "Epoch 217/2000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 0.5211 - acc: 0.7467 - val_loss: 0.6484 - val_acc: 0.7083\n",
            "Epoch 218/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 0.5453 - acc: 0.7337 - val_loss: 0.6213 - val_acc: 0.7188\n",
            "Epoch 219/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.5306 - acc: 0.7516 - val_loss: 0.5885 - val_acc: 0.6562\n",
            "Epoch 220/2000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 0.5252 - acc: 0.7386 - val_loss: 0.6147 - val_acc: 0.6771\n",
            "Epoch 221/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 0.4789 - acc: 0.7598 - val_loss: 0.6118 - val_acc: 0.6458\n",
            "Epoch 222/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.5339 - acc: 0.7288 - val_loss: 0.6210 - val_acc: 0.7188\n",
            "Epoch 223/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.5423 - acc: 0.7304 - val_loss: 0.6193 - val_acc: 0.6875\n",
            "Epoch 224/2000\n",
            "39/39 [==============================] - 5s 103ms/step - loss: 0.5096 - acc: 0.7353 - val_loss: 0.6055 - val_acc: 0.6562\n",
            "Epoch 225/2000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 0.5270 - acc: 0.7533 - val_loss: 0.5813 - val_acc: 0.6562\n",
            "Epoch 226/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5669 - acc: 0.7320 - val_loss: 0.5928 - val_acc: 0.7188\n",
            "Epoch 227/2000\n",
            "39/39 [==============================] - 4s 80ms/step - loss: 0.4867 - acc: 0.7614 - val_loss: 0.5934 - val_acc: 0.6875\n",
            "Epoch 228/2000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 0.4990 - acc: 0.7369 - val_loss: 0.5878 - val_acc: 0.6562\n",
            "Epoch 229/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 0.5068 - acc: 0.7598 - val_loss: 0.6175 - val_acc: 0.6771\n",
            "Epoch 230/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5337 - acc: 0.7598 - val_loss: 0.6116 - val_acc: 0.6562\n",
            "Epoch 231/2000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 0.4614 - acc: 0.7598 - val_loss: 0.6036 - val_acc: 0.6667\n",
            "Epoch 232/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5100 - acc: 0.7614 - val_loss: 0.5825 - val_acc: 0.6771\n",
            "Epoch 233/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 0.4844 - acc: 0.7631 - val_loss: 0.5976 - val_acc: 0.6562\n",
            "Epoch 234/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5210 - acc: 0.7500 - val_loss: 0.6315 - val_acc: 0.6771\n",
            "Epoch 235/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.4931 - acc: 0.7614 - val_loss: 0.5937 - val_acc: 0.6875\n",
            "Epoch 236/2000\n",
            "39/39 [==============================] - 9s 205ms/step - loss: 0.4990 - acc: 0.7565 - val_loss: 0.6115 - val_acc: 0.6875\n",
            "Epoch 237/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.5308 - acc: 0.7353 - val_loss: 0.6020 - val_acc: 0.6667\n",
            "Epoch 238/2000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 0.5113 - acc: 0.7288 - val_loss: 0.6132 - val_acc: 0.6771\n",
            "Epoch 239/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 0.5031 - acc: 0.7598 - val_loss: 0.6034 - val_acc: 0.6667\n",
            "Epoch 240/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5464 - acc: 0.7324 - val_loss: 0.5813 - val_acc: 0.6667\n",
            "Epoch 241/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.5177 - acc: 0.7631 - val_loss: 0.6005 - val_acc: 0.6667\n",
            "Epoch 242/2000\n",
            "39/39 [==============================] - 4s 80ms/step - loss: 0.4881 - acc: 0.7582 - val_loss: 0.6266 - val_acc: 0.6354\n",
            "Epoch 243/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5265 - acc: 0.7549 - val_loss: 0.6057 - val_acc: 0.6562\n",
            "Epoch 244/2000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 0.5206 - acc: 0.7598 - val_loss: 0.6119 - val_acc: 0.6562\n",
            "Epoch 245/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5342 - acc: 0.7353 - val_loss: 0.6124 - val_acc: 0.6458\n",
            "Epoch 246/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.5127 - acc: 0.7582 - val_loss: 0.5985 - val_acc: 0.6667\n",
            "Epoch 247/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5381 - acc: 0.7157 - val_loss: 0.6202 - val_acc: 0.6562\n",
            "Epoch 248/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 0.5329 - acc: 0.7255 - val_loss: 0.6388 - val_acc: 0.6667\n",
            "Epoch 249/2000\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 0.5274 - acc: 0.7467 - val_loss: 0.5938 - val_acc: 0.6667\n",
            "Epoch 250/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5077 - acc: 0.7712 - val_loss: 0.6159 - val_acc: 0.6562\n",
            "Epoch 251/2000\n",
            "39/39 [==============================] - 5s 113ms/step - loss: 0.5350 - acc: 0.7337 - val_loss: 0.6194 - val_acc: 0.6458\n",
            "Epoch 252/2000\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 0.5029 - acc: 0.7467 - val_loss: 0.5967 - val_acc: 0.6146\n",
            "Epoch 253/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.4924 - acc: 0.7467 - val_loss: 0.6274 - val_acc: 0.6875\n",
            "Epoch 254/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 0.4910 - acc: 0.7549 - val_loss: 0.5995 - val_acc: 0.6562\n",
            "Epoch 255/2000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 0.5105 - acc: 0.7451 - val_loss: 0.6208 - val_acc: 0.6979\n",
            "Epoch 256/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.5292 - acc: 0.7386 - val_loss: 0.6251 - val_acc: 0.6354\n",
            "Epoch 257/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5156 - acc: 0.7549 - val_loss: 0.6260 - val_acc: 0.6771\n",
            "Epoch 258/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.5546 - acc: 0.6912 - val_loss: 0.5935 - val_acc: 0.6458\n",
            "Epoch 259/2000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 0.4910 - acc: 0.7500 - val_loss: 0.6351 - val_acc: 0.6771\n",
            "Epoch 260/2000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 0.5139 - acc: 0.7451 - val_loss: 0.6264 - val_acc: 0.6771\n",
            "Epoch 261/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.4870 - acc: 0.7500 - val_loss: 0.6084 - val_acc: 0.6562\n",
            "Epoch 262/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5180 - acc: 0.7451 - val_loss: 0.6037 - val_acc: 0.6562\n",
            "Epoch 263/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.5160 - acc: 0.7451 - val_loss: 0.6048 - val_acc: 0.6458\n",
            "Epoch 264/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.4706 - acc: 0.7761 - val_loss: 0.6010 - val_acc: 0.6562\n",
            "Epoch 265/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5141 - acc: 0.7451 - val_loss: 0.6057 - val_acc: 0.6458\n",
            "Epoch 266/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.5214 - acc: 0.7239 - val_loss: 0.6050 - val_acc: 0.6875\n",
            "Epoch 267/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5049 - acc: 0.7549 - val_loss: 0.6113 - val_acc: 0.6771\n",
            "Epoch 268/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.4859 - acc: 0.7467 - val_loss: 0.5966 - val_acc: 0.6875\n",
            "Epoch 269/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 0.4991 - acc: 0.7692 - val_loss: 0.6043 - val_acc: 0.6875\n",
            "Epoch 270/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5410 - acc: 0.7320 - val_loss: 0.6228 - val_acc: 0.6354\n",
            "Epoch 271/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.5377 - acc: 0.7304 - val_loss: 0.5990 - val_acc: 0.6667\n",
            "Epoch 272/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5323 - acc: 0.7598 - val_loss: 0.6062 - val_acc: 0.6875\n",
            "Epoch 273/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.4689 - acc: 0.7876 - val_loss: 0.5923 - val_acc: 0.6458\n",
            "Epoch 274/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.5018 - acc: 0.7500 - val_loss: 0.6092 - val_acc: 0.6979\n",
            "Epoch 275/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5092 - acc: 0.7500 - val_loss: 0.5968 - val_acc: 0.6458\n",
            "Epoch 276/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5133 - acc: 0.7386 - val_loss: 0.6042 - val_acc: 0.6458\n",
            "Epoch 277/2000\n",
            "39/39 [==============================] - 5s 103ms/step - loss: 0.5457 - acc: 0.7451 - val_loss: 0.6219 - val_acc: 0.6667\n",
            "Epoch 278/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5019 - acc: 0.7614 - val_loss: 0.5883 - val_acc: 0.6667\n",
            "Epoch 279/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 0.5251 - acc: 0.7337 - val_loss: 0.5854 - val_acc: 0.6771\n",
            "Epoch 280/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5172 - acc: 0.7402 - val_loss: 0.5837 - val_acc: 0.6667\n",
            "Epoch 281/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5328 - acc: 0.7308 - val_loss: 0.5841 - val_acc: 0.6562\n",
            "Epoch 282/2000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 0.5188 - acc: 0.7386 - val_loss: 0.6204 - val_acc: 0.6562\n",
            "Epoch 283/2000\n",
            "39/39 [==============================] - 9s 233ms/step - loss: 0.5139 - acc: 0.7337 - val_loss: 0.5875 - val_acc: 0.6354\n",
            "Epoch 284/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.4880 - acc: 0.7745 - val_loss: 0.5620 - val_acc: 0.6458\n",
            "Epoch 285/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5440 - acc: 0.7484 - val_loss: 0.5986 - val_acc: 0.6250\n",
            "Epoch 286/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.5244 - acc: 0.7324 - val_loss: 0.6034 - val_acc: 0.6458\n",
            "Epoch 287/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5305 - acc: 0.7304 - val_loss: 0.6269 - val_acc: 0.6458\n",
            "Epoch 288/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.4948 - acc: 0.7712 - val_loss: 0.5893 - val_acc: 0.6667\n",
            "Epoch 289/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.4772 - acc: 0.7827 - val_loss: 0.6245 - val_acc: 0.6562\n",
            "Epoch 290/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5061 - acc: 0.7549 - val_loss: 0.5938 - val_acc: 0.6458\n",
            "Epoch 291/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 0.5502 - acc: 0.7288 - val_loss: 0.5898 - val_acc: 0.5938\n",
            "Epoch 292/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.5079 - acc: 0.7402 - val_loss: 0.6055 - val_acc: 0.6771\n",
            "Epoch 293/2000\n",
            "39/39 [==============================] - 4s 80ms/step - loss: 0.5535 - acc: 0.7190 - val_loss: 0.6154 - val_acc: 0.6667\n",
            "Epoch 294/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.5119 - acc: 0.7386 - val_loss: 0.6003 - val_acc: 0.6354\n",
            "Epoch 295/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5151 - acc: 0.7386 - val_loss: 0.5935 - val_acc: 0.6875\n",
            "Epoch 296/2000\n",
            "39/39 [==============================] - 9s 209ms/step - loss: 0.5059 - acc: 0.7500 - val_loss: 0.5899 - val_acc: 0.6354\n",
            "Epoch 297/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5356 - acc: 0.7484 - val_loss: 0.6100 - val_acc: 0.6667\n",
            "Epoch 298/2000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 0.5184 - acc: 0.7500 - val_loss: 0.5883 - val_acc: 0.6771\n",
            "Epoch 299/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.4858 - acc: 0.7582 - val_loss: 0.5825 - val_acc: 0.6354\n",
            "Epoch 300/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.4915 - acc: 0.7712 - val_loss: 0.6033 - val_acc: 0.6771\n",
            "Epoch 301/2000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 0.5283 - acc: 0.7239 - val_loss: 0.5906 - val_acc: 0.6458\n",
            "Epoch 302/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.5143 - acc: 0.7614 - val_loss: 0.5873 - val_acc: 0.5938\n",
            "Epoch 303/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.4970 - acc: 0.7337 - val_loss: 0.5774 - val_acc: 0.6458\n",
            "Epoch 304/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5352 - acc: 0.7304 - val_loss: 0.5948 - val_acc: 0.6771\n",
            "Epoch 305/2000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.4815 - acc: 0.7859 - val_loss: 0.5940 - val_acc: 0.6667\n",
            "Epoch 306/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.5222 - acc: 0.7516 - val_loss: 0.5908 - val_acc: 0.6250\n",
            "Epoch 307/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5199 - acc: 0.7516 - val_loss: 0.5836 - val_acc: 0.6250\n",
            "Epoch 308/2000\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 0.4870 - acc: 0.7663 - val_loss: 0.6047 - val_acc: 0.6562\n",
            "Epoch 309/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 0.4822 - acc: 0.7745 - val_loss: 0.6023 - val_acc: 0.6771\n",
            "Epoch 310/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.4881 - acc: 0.7680 - val_loss: 0.5721 - val_acc: 0.6562\n",
            "Epoch 311/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 0.5301 - acc: 0.7255 - val_loss: 0.5924 - val_acc: 0.6354\n",
            "Epoch 312/2000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 0.5051 - acc: 0.7516 - val_loss: 0.5708 - val_acc: 0.6562\n",
            "Epoch 313/2000\n",
            "39/39 [==============================] - 8s 211ms/step - loss: 0.4817 - acc: 0.7500 - val_loss: 0.6077 - val_acc: 0.6250\n",
            "Epoch 314/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5225 - acc: 0.7418 - val_loss: 0.5977 - val_acc: 0.6562\n",
            "Epoch 315/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.4805 - acc: 0.7647 - val_loss: 0.5820 - val_acc: 0.6562\n",
            "Epoch 316/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5263 - acc: 0.7239 - val_loss: 0.6291 - val_acc: 0.6875\n",
            "Epoch 317/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5040 - acc: 0.7467 - val_loss: 0.6048 - val_acc: 0.6458\n",
            "Epoch 318/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.4969 - acc: 0.7516 - val_loss: 0.6031 - val_acc: 0.6667\n",
            "Epoch 319/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5030 - acc: 0.7516 - val_loss: 0.6172 - val_acc: 0.6562\n",
            "Epoch 320/2000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 0.5223 - acc: 0.7369 - val_loss: 0.5861 - val_acc: 0.6354\n",
            "Epoch 321/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.4910 - acc: 0.7729 - val_loss: 0.6122 - val_acc: 0.6667\n",
            "Epoch 322/2000\n",
            "39/39 [==============================] - 4s 79ms/step - loss: 0.5145 - acc: 0.7614 - val_loss: 0.6101 - val_acc: 0.6458\n",
            "Epoch 323/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 0.5107 - acc: 0.7533 - val_loss: 0.6111 - val_acc: 0.6875\n",
            "Epoch 324/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 0.5042 - acc: 0.7549 - val_loss: 0.5976 - val_acc: 0.6979\n",
            "Epoch 325/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.4760 - acc: 0.7631 - val_loss: 0.6294 - val_acc: 0.6562\n",
            "Epoch 326/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5216 - acc: 0.7484 - val_loss: 0.6005 - val_acc: 0.6354\n",
            "Epoch 327/2000\n",
            "39/39 [==============================] - 9s 209ms/step - loss: 0.5159 - acc: 0.7271 - val_loss: 0.5862 - val_acc: 0.6354\n",
            "Epoch 328/2000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 0.5222 - acc: 0.7320 - val_loss: 0.5965 - val_acc: 0.6458\n",
            "Epoch 329/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.5312 - acc: 0.7369 - val_loss: 0.5982 - val_acc: 0.6354\n",
            "Epoch 330/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.5052 - acc: 0.7565 - val_loss: 0.6211 - val_acc: 0.6979\n",
            "Epoch 331/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.4892 - acc: 0.7516 - val_loss: 0.6189 - val_acc: 0.6875\n",
            "Epoch 332/2000\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 0.5173 - acc: 0.7435 - val_loss: 0.5839 - val_acc: 0.6562\n",
            "Epoch 333/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.5241 - acc: 0.7435 - val_loss: 0.6344 - val_acc: 0.6771\n",
            "Epoch 334/2000\n",
            "39/39 [==============================] - 9s 209ms/step - loss: 0.5539 - acc: 0.7304 - val_loss: 0.6193 - val_acc: 0.6562\n",
            "Epoch 335/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.5362 - acc: 0.7369 - val_loss: 0.5952 - val_acc: 0.6250\n",
            "Epoch 336/2000\n",
            "39/39 [==============================] - 4s 80ms/step - loss: 0.5044 - acc: 0.7369 - val_loss: 0.6143 - val_acc: 0.6667\n",
            "Epoch 337/2000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 0.5088 - acc: 0.7582 - val_loss: 0.6182 - val_acc: 0.6875\n",
            "Epoch 338/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 0.4805 - acc: 0.7598 - val_loss: 0.5828 - val_acc: 0.6146\n",
            "Epoch 339/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5097 - acc: 0.7420 - val_loss: 0.5587 - val_acc: 0.6562\n",
            "Epoch 340/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.4666 - acc: 0.7647 - val_loss: 0.5895 - val_acc: 0.6771\n",
            "Epoch 341/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.4936 - acc: 0.7451 - val_loss: 0.5786 - val_acc: 0.6250\n",
            "Epoch 342/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.4911 - acc: 0.7533 - val_loss: 0.6055 - val_acc: 0.6771\n",
            "Epoch 343/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.5267 - acc: 0.7680 - val_loss: 0.5960 - val_acc: 0.6667\n",
            "Epoch 344/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.5183 - acc: 0.7451 - val_loss: 0.6283 - val_acc: 0.6979\n",
            "Epoch 345/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.5187 - acc: 0.7304 - val_loss: 0.5881 - val_acc: 0.6250\n",
            "Epoch 346/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5130 - acc: 0.7663 - val_loss: 0.6091 - val_acc: 0.6458\n",
            "Epoch 347/2000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 0.5377 - acc: 0.7565 - val_loss: 0.6103 - val_acc: 0.6875\n",
            "Epoch 348/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5002 - acc: 0.7386 - val_loss: 0.6243 - val_acc: 0.6771\n",
            "Epoch 349/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 0.5023 - acc: 0.7484 - val_loss: 0.6117 - val_acc: 0.6875\n",
            "Epoch 350/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.5136 - acc: 0.7549 - val_loss: 0.6054 - val_acc: 0.6458\n",
            "Epoch 351/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5056 - acc: 0.7647 - val_loss: 0.5957 - val_acc: 0.6667\n",
            "Epoch 352/2000\n",
            "39/39 [==============================] - 10s 232ms/step - loss: 0.5280 - acc: 0.7565 - val_loss: 0.5913 - val_acc: 0.6667\n",
            "Epoch 353/2000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 0.5097 - acc: 0.7729 - val_loss: 0.6078 - val_acc: 0.6146\n",
            "Epoch 354/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 0.4824 - acc: 0.7729 - val_loss: 0.5972 - val_acc: 0.6979\n",
            "Epoch 355/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5121 - acc: 0.7533 - val_loss: 0.6156 - val_acc: 0.6771\n",
            "Epoch 356/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.5012 - acc: 0.7712 - val_loss: 0.6124 - val_acc: 0.6875\n",
            "Epoch 357/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.4914 - acc: 0.7696 - val_loss: 0.5810 - val_acc: 0.6979\n",
            "Epoch 358/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.4968 - acc: 0.7663 - val_loss: 0.5631 - val_acc: 0.6354\n",
            "Epoch 359/2000\n",
            "39/39 [==============================] - 4s 80ms/step - loss: 0.5189 - acc: 0.7369 - val_loss: 0.5788 - val_acc: 0.6354\n",
            "Epoch 360/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 0.4949 - acc: 0.7484 - val_loss: 0.6024 - val_acc: 0.6771\n",
            "Epoch 361/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.5292 - acc: 0.7337 - val_loss: 0.5637 - val_acc: 0.6458\n",
            "Epoch 362/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5424 - acc: 0.7337 - val_loss: 0.6156 - val_acc: 0.6771\n",
            "Epoch 363/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5255 - acc: 0.7647 - val_loss: 0.6141 - val_acc: 0.6458\n",
            "Epoch 364/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 0.4934 - acc: 0.7582 - val_loss: 0.6036 - val_acc: 0.6458\n",
            "Epoch 365/2000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 0.5119 - acc: 0.7435 - val_loss: 0.5846 - val_acc: 0.6146\n",
            "Epoch 366/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5008 - acc: 0.7435 - val_loss: 0.5857 - val_acc: 0.6458\n",
            "Epoch 367/2000\n",
            "39/39 [==============================] - 9s 209ms/step - loss: 0.5399 - acc: 0.7337 - val_loss: 0.5977 - val_acc: 0.6562\n",
            "Epoch 368/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5305 - acc: 0.7239 - val_loss: 0.5805 - val_acc: 0.6354\n",
            "Epoch 369/2000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 0.5079 - acc: 0.7614 - val_loss: 0.5683 - val_acc: 0.6250\n",
            "Epoch 370/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.5103 - acc: 0.7582 - val_loss: 0.5972 - val_acc: 0.6562\n",
            "Epoch 371/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5142 - acc: 0.7467 - val_loss: 0.5936 - val_acc: 0.6250\n",
            "Epoch 372/2000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 0.4940 - acc: 0.7500 - val_loss: 0.5890 - val_acc: 0.6146\n",
            "Epoch 373/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 0.5157 - acc: 0.7614 - val_loss: 0.5938 - val_acc: 0.6562\n",
            "Epoch 374/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 0.5340 - acc: 0.7304 - val_loss: 0.5973 - val_acc: 0.6667\n",
            "Epoch 375/2000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 0.5144 - acc: 0.7598 - val_loss: 0.5896 - val_acc: 0.6771\n",
            "Epoch 376/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 0.5374 - acc: 0.7304 - val_loss: 0.6191 - val_acc: 0.6458\n",
            "Epoch 377/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 0.5381 - acc: 0.7418 - val_loss: 0.6122 - val_acc: 0.6458\n",
            "Epoch 378/2000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 0.5010 - acc: 0.7467 - val_loss: 0.5770 - val_acc: 0.6250\n",
            "Epoch 379/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.4846 - acc: 0.7565 - val_loss: 0.5968 - val_acc: 0.7188\n",
            "Epoch 380/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5172 - acc: 0.7320 - val_loss: 0.5606 - val_acc: 0.6771\n",
            "Epoch 381/2000\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.5338 - acc: 0.7141 - val_loss: 0.6192 - val_acc: 0.6875\n",
            "Epoch 382/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5137 - acc: 0.7484 - val_loss: 0.5845 - val_acc: 0.6979\n",
            "Epoch 383/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.5097 - acc: 0.7467 - val_loss: 0.5719 - val_acc: 0.6354\n",
            "Epoch 384/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.5164 - acc: 0.7484 - val_loss: 0.5997 - val_acc: 0.6458\n",
            "Epoch 385/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 0.4728 - acc: 0.7729 - val_loss: 0.5685 - val_acc: 0.6771\n",
            "Epoch 386/2000\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 0.4722 - acc: 0.7614 - val_loss: 0.6067 - val_acc: 0.6562\n",
            "Epoch 387/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.4967 - acc: 0.7712 - val_loss: 0.5906 - val_acc: 0.6458\n",
            "Epoch 388/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.5009 - acc: 0.7304 - val_loss: 0.6060 - val_acc: 0.6667\n",
            "Epoch 389/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5415 - acc: 0.7451 - val_loss: 0.5896 - val_acc: 0.6875\n",
            "Epoch 390/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.5034 - acc: 0.7451 - val_loss: 0.5865 - val_acc: 0.6771\n",
            "Epoch 391/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5438 - acc: 0.7255 - val_loss: 0.5852 - val_acc: 0.6667\n",
            "Epoch 392/2000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 0.5337 - acc: 0.7386 - val_loss: 0.5805 - val_acc: 0.6667\n",
            "Epoch 393/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.4986 - acc: 0.7484 - val_loss: 0.6350 - val_acc: 0.6875\n",
            "Epoch 394/2000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 0.5249 - acc: 0.7386 - val_loss: 0.6132 - val_acc: 0.6875\n",
            "Epoch 395/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.5271 - acc: 0.7516 - val_loss: 0.5840 - val_acc: 0.6042\n",
            "Epoch 396/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.5331 - acc: 0.7418 - val_loss: 0.6013 - val_acc: 0.6562\n",
            "Epoch 397/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.4962 - acc: 0.7549 - val_loss: 0.6006 - val_acc: 0.6667\n",
            "Epoch 398/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5150 - acc: 0.7353 - val_loss: 0.5748 - val_acc: 0.6667\n",
            "Epoch 399/2000\n",
            "39/39 [==============================] - 5s 113ms/step - loss: 0.5311 - acc: 0.7468 - val_loss: 0.6012 - val_acc: 0.6979\n",
            "Epoch 400/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.4803 - acc: 0.7663 - val_loss: 0.5798 - val_acc: 0.6458\n",
            "Epoch 401/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5045 - acc: 0.7435 - val_loss: 0.6071 - val_acc: 0.6458\n",
            "Epoch 402/2000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 0.5138 - acc: 0.7353 - val_loss: 0.5976 - val_acc: 0.6562\n",
            "Epoch 403/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 0.4859 - acc: 0.7696 - val_loss: 0.6073 - val_acc: 0.6562\n",
            "Epoch 404/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5332 - acc: 0.7304 - val_loss: 0.5942 - val_acc: 0.6458\n",
            "Epoch 405/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5108 - acc: 0.7582 - val_loss: 0.5993 - val_acc: 0.6458\n",
            "Epoch 406/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5329 - acc: 0.7549 - val_loss: 0.6253 - val_acc: 0.6667\n",
            "Epoch 407/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 0.5099 - acc: 0.7565 - val_loss: 0.5966 - val_acc: 0.6458\n",
            "Epoch 408/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 0.4846 - acc: 0.7631 - val_loss: 0.5753 - val_acc: 0.6667\n",
            "Epoch 409/2000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 0.4485 - acc: 0.7696 - val_loss: 0.5851 - val_acc: 0.7083\n",
            "Epoch 410/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.5002 - acc: 0.7402 - val_loss: 0.5611 - val_acc: 0.6562\n",
            "Epoch 411/2000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 0.5102 - acc: 0.7337 - val_loss: 0.5752 - val_acc: 0.6667\n",
            "Epoch 412/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.5333 - acc: 0.7190 - val_loss: 0.5974 - val_acc: 0.6458\n",
            "Epoch 413/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.4874 - acc: 0.7435 - val_loss: 0.5753 - val_acc: 0.6458\n",
            "Epoch 414/2000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 0.5272 - acc: 0.7418 - val_loss: 0.5785 - val_acc: 0.6875\n",
            "Epoch 415/2000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 0.4828 - acc: 0.7745 - val_loss: 0.5854 - val_acc: 0.6979\n",
            "Epoch 416/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5060 - acc: 0.7388 - val_loss: 0.5904 - val_acc: 0.6979\n",
            "Epoch 417/2000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.4952 - acc: 0.7745 - val_loss: 0.6028 - val_acc: 0.6875\n",
            "Epoch 418/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.4910 - acc: 0.7467 - val_loss: 0.5979 - val_acc: 0.6562\n",
            "Epoch 419/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 0.5238 - acc: 0.7271 - val_loss: 0.5888 - val_acc: 0.6667\n",
            "Epoch 420/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.5401 - acc: 0.7484 - val_loss: 0.5838 - val_acc: 0.6458\n",
            "Epoch 421/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.5302 - acc: 0.7288 - val_loss: 0.5803 - val_acc: 0.6875\n",
            "Epoch 422/2000\n",
            "39/39 [==============================] - 5s 122ms/step - loss: 0.5179 - acc: 0.7402 - val_loss: 0.5924 - val_acc: 0.6771\n",
            "Epoch 423/2000\n",
            "39/39 [==============================] - 4s 104ms/step - loss: 0.4889 - acc: 0.7745 - val_loss: 0.6081 - val_acc: 0.6875\n",
            "Epoch 424/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.4910 - acc: 0.7500 - val_loss: 0.5835 - val_acc: 0.6458\n",
            "Epoch 425/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.5180 - acc: 0.7353 - val_loss: 0.5672 - val_acc: 0.6458\n",
            "Epoch 426/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 0.5295 - acc: 0.7337 - val_loss: 0.5892 - val_acc: 0.6354\n",
            "Epoch 427/2000\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 0.4985 - acc: 0.7729 - val_loss: 0.5934 - val_acc: 0.7083\n",
            "Epoch 428/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5193 - acc: 0.7533 - val_loss: 0.5960 - val_acc: 0.6250\n",
            "Epoch 429/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.5062 - acc: 0.7598 - val_loss: 0.5733 - val_acc: 0.7083\n",
            "Epoch 430/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.4973 - acc: 0.7549 - val_loss: 0.5860 - val_acc: 0.6458\n",
            "Epoch 431/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.5385 - acc: 0.7533 - val_loss: 0.5988 - val_acc: 0.6979\n",
            "Epoch 432/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.5200 - acc: 0.7353 - val_loss: 0.5916 - val_acc: 0.6979\n",
            "Epoch 433/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.4981 - acc: 0.7500 - val_loss: 0.6070 - val_acc: 0.6875\n",
            "Epoch 434/2000\n",
            "39/39 [==============================] - 4s 79ms/step - loss: 0.5398 - acc: 0.7386 - val_loss: 0.5919 - val_acc: 0.6250\n",
            "Epoch 435/2000\n",
            "39/39 [==============================] - 5s 114ms/step - loss: 0.5299 - acc: 0.7271 - val_loss: 0.5941 - val_acc: 0.6250\n",
            "Epoch 436/2000\n",
            "39/39 [==============================] - 4s 79ms/step - loss: 0.5044 - acc: 0.7467 - val_loss: 0.5898 - val_acc: 0.6458\n",
            "Epoch 437/2000\n",
            "39/39 [==============================] - 5s 101ms/step - loss: 0.5090 - acc: 0.7386 - val_loss: 0.6065 - val_acc: 0.6979\n",
            "Epoch 438/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.4794 - acc: 0.7761 - val_loss: 0.5925 - val_acc: 0.6458\n",
            "Epoch 439/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5342 - acc: 0.7271 - val_loss: 0.6406 - val_acc: 0.6979\n",
            "Epoch 440/2000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 0.5079 - acc: 0.7500 - val_loss: 0.6040 - val_acc: 0.6667\n",
            "Epoch 441/2000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 0.5102 - acc: 0.7516 - val_loss: 0.6221 - val_acc: 0.6771\n",
            "Epoch 442/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.5122 - acc: 0.7206 - val_loss: 0.5934 - val_acc: 0.6562\n",
            "Epoch 443/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5103 - acc: 0.7386 - val_loss: 0.6167 - val_acc: 0.6562\n",
            "Epoch 444/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5074 - acc: 0.7516 - val_loss: 0.6009 - val_acc: 0.6562\n",
            "Epoch 445/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5164 - acc: 0.7467 - val_loss: 0.5914 - val_acc: 0.6562\n",
            "Epoch 446/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.4931 - acc: 0.7549 - val_loss: 0.6046 - val_acc: 0.6875\n",
            "Epoch 447/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 0.5197 - acc: 0.7565 - val_loss: 0.6177 - val_acc: 0.6979\n",
            "Epoch 448/2000\n",
            "39/39 [==============================] - 4s 80ms/step - loss: 0.5101 - acc: 0.7647 - val_loss: 0.6020 - val_acc: 0.6146\n",
            "Epoch 449/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.4989 - acc: 0.7451 - val_loss: 0.6036 - val_acc: 0.6458\n",
            "Epoch 450/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5025 - acc: 0.7565 - val_loss: 0.6236 - val_acc: 0.6875\n",
            "Epoch 451/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 0.5073 - acc: 0.7631 - val_loss: 0.6038 - val_acc: 0.6458\n",
            "Epoch 452/2000\n",
            "39/39 [==============================] - 5s 101ms/step - loss: 0.5133 - acc: 0.7565 - val_loss: 0.6066 - val_acc: 0.6354\n",
            "Epoch 453/2000\n",
            "39/39 [==============================] - 9s 204ms/step - loss: 0.4924 - acc: 0.7680 - val_loss: 0.6049 - val_acc: 0.6667\n",
            "Epoch 454/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.4780 - acc: 0.7712 - val_loss: 0.6043 - val_acc: 0.6354\n",
            "Epoch 455/2000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 0.5043 - acc: 0.7435 - val_loss: 0.6063 - val_acc: 0.6667\n",
            "Epoch 456/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.4793 - acc: 0.7467 - val_loss: 0.6208 - val_acc: 0.6667\n",
            "Epoch 457/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.5597 - acc: 0.7124 - val_loss: 0.5866 - val_acc: 0.6771\n",
            "Epoch 458/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.4870 - acc: 0.7582 - val_loss: 0.6001 - val_acc: 0.6667\n",
            "Epoch 459/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.4713 - acc: 0.7712 - val_loss: 0.6230 - val_acc: 0.6458\n",
            "Epoch 460/2000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 0.4781 - acc: 0.7647 - val_loss: 0.6154 - val_acc: 0.6667\n",
            "Epoch 461/2000\n",
            "39/39 [==============================] - 4s 78ms/step - loss: 0.5020 - acc: 0.7320 - val_loss: 0.6199 - val_acc: 0.6771\n",
            "Epoch 462/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5137 - acc: 0.7516 - val_loss: 0.5926 - val_acc: 0.6250\n",
            "Epoch 463/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.5065 - acc: 0.7532 - val_loss: 0.6033 - val_acc: 0.6562\n",
            "Epoch 464/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 0.5037 - acc: 0.7467 - val_loss: 0.5831 - val_acc: 0.6354\n",
            "Epoch 465/2000\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.5074 - acc: 0.7582 - val_loss: 0.6016 - val_acc: 0.6771\n",
            "Epoch 466/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.5244 - acc: 0.7304 - val_loss: 0.6226 - val_acc: 0.6458\n",
            "Epoch 467/2000\n",
            "39/39 [==============================] - 4s 80ms/step - loss: 0.4761 - acc: 0.7467 - val_loss: 0.6136 - val_acc: 0.6250\n",
            "Epoch 468/2000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 0.5066 - acc: 0.7565 - val_loss: 0.5990 - val_acc: 0.6667\n",
            "Epoch 469/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5070 - acc: 0.7647 - val_loss: 0.5769 - val_acc: 0.6562\n",
            "Epoch 470/2000\n",
            "39/39 [==============================] - 8s 203ms/step - loss: 0.4907 - acc: 0.7369 - val_loss: 0.5833 - val_acc: 0.6771\n",
            "Epoch 471/2000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 0.4913 - acc: 0.7598 - val_loss: 0.6030 - val_acc: 0.6354\n",
            "Epoch 472/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.4977 - acc: 0.7565 - val_loss: 0.5925 - val_acc: 0.5938\n",
            "Epoch 473/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.5175 - acc: 0.7451 - val_loss: 0.5909 - val_acc: 0.6354\n",
            "Epoch 474/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 0.5066 - acc: 0.7418 - val_loss: 0.5943 - val_acc: 0.6458\n",
            "Epoch 475/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5245 - acc: 0.7565 - val_loss: 0.6012 - val_acc: 0.6354\n",
            "Epoch 476/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.4809 - acc: 0.7663 - val_loss: 0.6118 - val_acc: 0.6562\n",
            "Epoch 477/2000\n",
            "39/39 [==============================] - 6s 131ms/step - loss: 0.5141 - acc: 0.7435 - val_loss: 0.5779 - val_acc: 0.6146\n",
            "Epoch 478/2000\n",
            "39/39 [==============================] - 4s 80ms/step - loss: 0.5207 - acc: 0.7206 - val_loss: 0.5950 - val_acc: 0.6458\n",
            "Epoch 479/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.5256 - acc: 0.7484 - val_loss: 0.5830 - val_acc: 0.6458\n",
            "Epoch 480/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 0.5215 - acc: 0.7516 - val_loss: 0.5789 - val_acc: 0.6458\n",
            "Epoch 481/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5144 - acc: 0.7386 - val_loss: 0.5989 - val_acc: 0.6250\n",
            "Epoch 482/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.4715 - acc: 0.7745 - val_loss: 0.6071 - val_acc: 0.6562\n",
            "Epoch 483/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.5148 - acc: 0.7500 - val_loss: 0.5988 - val_acc: 0.6354\n",
            "Epoch 484/2000\n",
            "39/39 [==============================] - 4s 80ms/step - loss: 0.5062 - acc: 0.7598 - val_loss: 0.6028 - val_acc: 0.6354\n",
            "Epoch 485/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5593 - acc: 0.7124 - val_loss: 0.6336 - val_acc: 0.6562\n",
            "Epoch 486/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.5295 - acc: 0.7484 - val_loss: 0.6118 - val_acc: 0.6562\n",
            "Epoch 487/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 0.5169 - acc: 0.7369 - val_loss: 0.6211 - val_acc: 0.6667\n",
            "Epoch 488/2000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 0.5141 - acc: 0.7386 - val_loss: 0.5953 - val_acc: 0.6667\n",
            "Epoch 489/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.4860 - acc: 0.7564 - val_loss: 0.6111 - val_acc: 0.6667\n",
            "Epoch 490/2000\n",
            "39/39 [==============================] - 6s 124ms/step - loss: 0.5136 - acc: 0.7631 - val_loss: 0.5870 - val_acc: 0.6562\n",
            "Epoch 491/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5237 - acc: 0.7402 - val_loss: 0.5739 - val_acc: 0.6354\n",
            "Epoch 492/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5208 - acc: 0.7320 - val_loss: 0.6033 - val_acc: 0.6875\n",
            "Epoch 493/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.4977 - acc: 0.7565 - val_loss: 0.5990 - val_acc: 0.6250\n",
            "Epoch 494/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.4981 - acc: 0.7451 - val_loss: 0.6015 - val_acc: 0.6250\n",
            "Epoch 495/2000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 0.5356 - acc: 0.7533 - val_loss: 0.6149 - val_acc: 0.6667\n",
            "Epoch 496/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.4922 - acc: 0.7451 - val_loss: 0.5918 - val_acc: 0.6250\n",
            "Epoch 497/2000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.5119 - acc: 0.7418 - val_loss: 0.5846 - val_acc: 0.6979\n",
            "Epoch 498/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.4591 - acc: 0.7810 - val_loss: 0.6502 - val_acc: 0.6562\n",
            "Epoch 499/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.5036 - acc: 0.7500 - val_loss: 0.6241 - val_acc: 0.6771\n",
            "Epoch 500/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.4936 - acc: 0.7614 - val_loss: 0.6170 - val_acc: 0.6771\n",
            "Epoch 501/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 0.4838 - acc: 0.7516 - val_loss: 0.6174 - val_acc: 0.6458\n",
            "Epoch 502/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 0.5114 - acc: 0.7598 - val_loss: 0.6431 - val_acc: 0.6562\n",
            "Epoch 503/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.4964 - acc: 0.7596 - val_loss: 0.6172 - val_acc: 0.6667\n",
            "Epoch 504/2000\n",
            "39/39 [==============================] - 4s 80ms/step - loss: 0.4973 - acc: 0.7663 - val_loss: 0.6249 - val_acc: 0.6562\n",
            "Epoch 505/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 0.5217 - acc: 0.7369 - val_loss: 0.6037 - val_acc: 0.6562\n",
            "Epoch 506/2000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 0.5355 - acc: 0.7402 - val_loss: 0.6007 - val_acc: 0.6250\n",
            "Epoch 507/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.5295 - acc: 0.7340 - val_loss: 0.6022 - val_acc: 0.6771\n",
            "Epoch 508/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.4788 - acc: 0.7647 - val_loss: 0.6237 - val_acc: 0.6667\n",
            "Epoch 509/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5194 - acc: 0.7631 - val_loss: 0.6210 - val_acc: 0.6667\n",
            "Epoch 510/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.5330 - acc: 0.7500 - val_loss: 0.6237 - val_acc: 0.6667\n",
            "Epoch 511/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.5358 - acc: 0.7239 - val_loss: 0.6014 - val_acc: 0.6562\n",
            "Epoch 512/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5296 - acc: 0.7353 - val_loss: 0.6021 - val_acc: 0.6667\n",
            "Epoch 513/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.5443 - acc: 0.7288 - val_loss: 0.6236 - val_acc: 0.6562\n",
            "Epoch 514/2000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 0.5049 - acc: 0.7663 - val_loss: 0.5784 - val_acc: 0.6354\n",
            "Epoch 515/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.4891 - acc: 0.7647 - val_loss: 0.5739 - val_acc: 0.6875\n",
            "Epoch 516/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.4814 - acc: 0.7729 - val_loss: 0.6072 - val_acc: 0.6667\n",
            "Epoch 517/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.5060 - acc: 0.7516 - val_loss: 0.5895 - val_acc: 0.6354\n",
            "Epoch 518/2000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 0.4778 - acc: 0.7582 - val_loss: 0.6009 - val_acc: 0.6667\n",
            "Epoch 519/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5546 - acc: 0.7435 - val_loss: 0.5823 - val_acc: 0.6354\n",
            "Epoch 520/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5492 - acc: 0.7196 - val_loss: 0.5935 - val_acc: 0.6771\n",
            "Epoch 521/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.5196 - acc: 0.7435 - val_loss: 0.6035 - val_acc: 0.6667\n",
            "Epoch 522/2000\n",
            "39/39 [==============================] - 5s 98ms/step - loss: 0.5383 - acc: 0.7320 - val_loss: 0.6064 - val_acc: 0.6250\n",
            "Epoch 523/2000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 0.5523 - acc: 0.6977 - val_loss: 0.6092 - val_acc: 0.6875\n",
            "Epoch 524/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.4924 - acc: 0.7680 - val_loss: 0.6111 - val_acc: 0.6875\n",
            "Epoch 525/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 0.5273 - acc: 0.7467 - val_loss: 0.5835 - val_acc: 0.6979\n",
            "Epoch 526/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.4946 - acc: 0.7598 - val_loss: 0.5924 - val_acc: 0.6771\n",
            "Epoch 527/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.5654 - acc: 0.7271 - val_loss: 0.5920 - val_acc: 0.7083\n",
            "Epoch 528/2000\n",
            "39/39 [==============================] - 5s 102ms/step - loss: 0.5111 - acc: 0.7435 - val_loss: 0.5982 - val_acc: 0.6042\n",
            "Epoch 529/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 0.4991 - acc: 0.7582 - val_loss: 0.6113 - val_acc: 0.6875\n",
            "Epoch 530/2000\n",
            "39/39 [==============================] - 9s 233ms/step - loss: 0.5266 - acc: 0.7582 - val_loss: 0.5841 - val_acc: 0.6562\n",
            "Epoch 531/2000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 0.5170 - acc: 0.7500 - val_loss: 0.6083 - val_acc: 0.6667\n",
            "Epoch 532/2000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 0.5387 - acc: 0.7353 - val_loss: 0.5823 - val_acc: 0.6458\n",
            "Epoch 533/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5345 - acc: 0.7108 - val_loss: 0.5765 - val_acc: 0.6875\n",
            "Epoch 534/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5326 - acc: 0.7402 - val_loss: 0.6013 - val_acc: 0.6667\n",
            "Epoch 535/2000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 0.4648 - acc: 0.7761 - val_loss: 0.5841 - val_acc: 0.6562\n",
            "Epoch 536/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.4987 - acc: 0.7500 - val_loss: 0.6238 - val_acc: 0.6562\n",
            "Epoch 537/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 0.5120 - acc: 0.7418 - val_loss: 0.6078 - val_acc: 0.6250\n",
            "Epoch 538/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5038 - acc: 0.7500 - val_loss: 0.6273 - val_acc: 0.6667\n",
            "Epoch 539/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.4944 - acc: 0.7631 - val_loss: 0.6187 - val_acc: 0.6458\n",
            "Epoch 540/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.4848 - acc: 0.7402 - val_loss: 0.6152 - val_acc: 0.6979\n",
            "Epoch 541/2000\n",
            "39/39 [==============================] - 5s 113ms/step - loss: 0.4979 - acc: 0.7484 - val_loss: 0.5998 - val_acc: 0.6354\n",
            "Epoch 542/2000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 0.4693 - acc: 0.7810 - val_loss: 0.5913 - val_acc: 0.6562\n",
            "Epoch 543/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 0.5225 - acc: 0.7386 - val_loss: 0.6194 - val_acc: 0.6562\n",
            "Epoch 544/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 0.5206 - acc: 0.7467 - val_loss: 0.6068 - val_acc: 0.6667\n",
            "Epoch 545/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5029 - acc: 0.7402 - val_loss: 0.5983 - val_acc: 0.6667\n",
            "Epoch 546/2000\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 0.4889 - acc: 0.7418 - val_loss: 0.6038 - val_acc: 0.6250\n",
            "Epoch 547/2000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 0.4941 - acc: 0.7598 - val_loss: 0.6238 - val_acc: 0.6667\n",
            "Epoch 548/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 0.5437 - acc: 0.7092 - val_loss: 0.6183 - val_acc: 0.6458\n",
            "Epoch 549/2000\n",
            "39/39 [==============================] - 5s 100ms/step - loss: 0.5449 - acc: 0.7418 - val_loss: 0.6076 - val_acc: 0.6562\n",
            "Epoch 550/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5043 - acc: 0.7516 - val_loss: 0.6155 - val_acc: 0.6667\n",
            "Epoch 551/2000\n",
            "39/39 [==============================] - 5s 100ms/step - loss: 0.4925 - acc: 0.7484 - val_loss: 0.5993 - val_acc: 0.6354\n",
            "Epoch 552/2000\n",
            "39/39 [==============================] - 5s 100ms/step - loss: 0.5121 - acc: 0.7647 - val_loss: 0.6034 - val_acc: 0.6250\n",
            "Epoch 553/2000\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 0.5511 - acc: 0.7418 - val_loss: 0.6252 - val_acc: 0.6562\n",
            "Epoch 554/2000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.5030 - acc: 0.7484 - val_loss: 0.5930 - val_acc: 0.6458\n",
            "Epoch 555/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5285 - acc: 0.7304 - val_loss: 0.5754 - val_acc: 0.6458\n",
            "Epoch 556/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.5119 - acc: 0.7516 - val_loss: 0.6058 - val_acc: 0.6250\n",
            "Epoch 557/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 0.5662 - acc: 0.7304 - val_loss: 0.5932 - val_acc: 0.6354\n",
            "Epoch 558/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 0.5435 - acc: 0.7320 - val_loss: 0.6318 - val_acc: 0.6562\n",
            "Epoch 559/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5069 - acc: 0.7435 - val_loss: 0.6106 - val_acc: 0.6562\n",
            "Epoch 560/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.5234 - acc: 0.7386 - val_loss: 0.6116 - val_acc: 0.6667\n",
            "Epoch 561/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5219 - acc: 0.7402 - val_loss: 0.5901 - val_acc: 0.6250\n",
            "Epoch 562/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.4854 - acc: 0.7761 - val_loss: 0.5966 - val_acc: 0.6458\n",
            "Epoch 563/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.4664 - acc: 0.7696 - val_loss: 0.5803 - val_acc: 0.6667\n",
            "Epoch 564/2000\n",
            "39/39 [==============================] - 9s 208ms/step - loss: 0.5132 - acc: 0.7484 - val_loss: 0.6095 - val_acc: 0.6771\n",
            "Epoch 565/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.4805 - acc: 0.7500 - val_loss: 0.6093 - val_acc: 0.6562\n",
            "Epoch 566/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.5423 - acc: 0.7124 - val_loss: 0.6337 - val_acc: 0.6771\n",
            "Epoch 567/2000\n",
            "39/39 [==============================] - 5s 91ms/step - loss: 0.4982 - acc: 0.7794 - val_loss: 0.6499 - val_acc: 0.6667\n",
            "Epoch 568/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.5146 - acc: 0.7598 - val_loss: 0.6256 - val_acc: 0.6771\n",
            "Epoch 569/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.4945 - acc: 0.7549 - val_loss: 0.6210 - val_acc: 0.6771\n",
            "Epoch 570/2000\n",
            "39/39 [==============================] - 5s 114ms/step - loss: 0.5223 - acc: 0.7582 - val_loss: 0.6261 - val_acc: 0.6667\n",
            "Epoch 571/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.4868 - acc: 0.7418 - val_loss: 0.6045 - val_acc: 0.6562\n",
            "Epoch 572/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.5452 - acc: 0.7337 - val_loss: 0.5990 - val_acc: 0.6667\n",
            "Epoch 573/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 0.5255 - acc: 0.7320 - val_loss: 0.6169 - val_acc: 0.6771\n",
            "Epoch 574/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.4921 - acc: 0.7582 - val_loss: 0.6173 - val_acc: 0.6771\n",
            "Epoch 575/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5240 - acc: 0.7418 - val_loss: 0.5905 - val_acc: 0.6979\n",
            "Epoch 576/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5023 - acc: 0.7516 - val_loss: 0.6104 - val_acc: 0.6771\n",
            "Epoch 577/2000\n",
            "39/39 [==============================] - 6s 131ms/step - loss: 0.5028 - acc: 0.7549 - val_loss: 0.6016 - val_acc: 0.6771\n",
            "Epoch 578/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.4957 - acc: 0.7533 - val_loss: 0.6349 - val_acc: 0.6771\n",
            "Epoch 579/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5162 - acc: 0.7320 - val_loss: 0.6072 - val_acc: 0.6979\n",
            "Epoch 580/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5322 - acc: 0.7353 - val_loss: 0.6093 - val_acc: 0.6875\n",
            "Epoch 581/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.5231 - acc: 0.7467 - val_loss: 0.6160 - val_acc: 0.6562\n",
            "Epoch 582/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5048 - acc: 0.7598 - val_loss: 0.6575 - val_acc: 0.6667\n",
            "Epoch 583/2000\n",
            "39/39 [==============================] - 6s 130ms/step - loss: 0.5227 - acc: 0.7484 - val_loss: 0.6391 - val_acc: 0.6667\n",
            "Epoch 584/2000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 0.4708 - acc: 0.7712 - val_loss: 0.6362 - val_acc: 0.6354\n",
            "Epoch 585/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5192 - acc: 0.7320 - val_loss: 0.6209 - val_acc: 0.5833\n",
            "Epoch 586/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5099 - acc: 0.7582 - val_loss: 0.6544 - val_acc: 0.6562\n",
            "Epoch 587/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5595 - acc: 0.7157 - val_loss: 0.6519 - val_acc: 0.6667\n",
            "Epoch 588/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.4981 - acc: 0.7549 - val_loss: 0.6278 - val_acc: 0.6875\n",
            "Epoch 589/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5112 - acc: 0.7500 - val_loss: 0.6617 - val_acc: 0.6562\n",
            "Epoch 590/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.4793 - acc: 0.7663 - val_loss: 0.6308 - val_acc: 0.6667\n",
            "Epoch 591/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.4828 - acc: 0.7500 - val_loss: 0.6276 - val_acc: 0.6562\n",
            "Epoch 592/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5314 - acc: 0.7190 - val_loss: 0.6370 - val_acc: 0.6667\n",
            "Epoch 593/2000\n",
            "39/39 [==============================] - 9s 231ms/step - loss: 0.4945 - acc: 0.7631 - val_loss: 0.6133 - val_acc: 0.6771\n",
            "Epoch 594/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5191 - acc: 0.7451 - val_loss: 0.6398 - val_acc: 0.6875\n",
            "Epoch 595/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5024 - acc: 0.7941 - val_loss: 0.6374 - val_acc: 0.6562\n",
            "Epoch 596/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.5255 - acc: 0.7402 - val_loss: 0.6241 - val_acc: 0.6458\n",
            "Epoch 597/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 0.4988 - acc: 0.7467 - val_loss: 0.6357 - val_acc: 0.6875\n",
            "Epoch 598/2000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.5342 - acc: 0.7451 - val_loss: 0.6213 - val_acc: 0.6667\n",
            "Epoch 599/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.4859 - acc: 0.7712 - val_loss: 0.6299 - val_acc: 0.6354\n",
            "Epoch 600/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5226 - acc: 0.7467 - val_loss: 0.6226 - val_acc: 0.6250\n",
            "Epoch 601/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5129 - acc: 0.7533 - val_loss: 0.6134 - val_acc: 0.6771\n",
            "Epoch 602/2000\n",
            "39/39 [==============================] - 8s 211ms/step - loss: 0.5127 - acc: 0.7614 - val_loss: 0.6185 - val_acc: 0.6250\n",
            "Epoch 603/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.5270 - acc: 0.7271 - val_loss: 0.6321 - val_acc: 0.6250\n",
            "Epoch 604/2000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 0.5481 - acc: 0.7304 - val_loss: 0.6703 - val_acc: 0.6667\n",
            "Epoch 605/2000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 0.5429 - acc: 0.7222 - val_loss: 0.6112 - val_acc: 0.6354\n",
            "Epoch 606/2000\n",
            "39/39 [==============================] - 9s 234ms/step - loss: 0.5064 - acc: 0.7582 - val_loss: 0.6366 - val_acc: 0.6458\n",
            "Epoch 607/2000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 0.4947 - acc: 0.7549 - val_loss: 0.6049 - val_acc: 0.6667\n",
            "Epoch 608/2000\n",
            "39/39 [==============================] - 10s 240ms/step - loss: 0.5437 - acc: 0.7239 - val_loss: 0.6227 - val_acc: 0.6562\n",
            "Epoch 609/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5403 - acc: 0.7092 - val_loss: 0.6228 - val_acc: 0.6979\n",
            "Epoch 610/2000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 0.5012 - acc: 0.7631 - val_loss: 0.6228 - val_acc: 0.6562\n",
            "Epoch 611/2000\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.4702 - acc: 0.7876 - val_loss: 0.6440 - val_acc: 0.6667\n",
            "Epoch 612/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5235 - acc: 0.7108 - val_loss: 0.6280 - val_acc: 0.6771\n",
            "Epoch 613/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.5882 - acc: 0.6961 - val_loss: 0.6439 - val_acc: 0.6875\n",
            "Epoch 614/2000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 0.4802 - acc: 0.7745 - val_loss: 0.6168 - val_acc: 0.6458\n",
            "Epoch 615/2000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 0.5377 - acc: 0.7222 - val_loss: 0.6216 - val_acc: 0.6250\n",
            "Epoch 616/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5276 - acc: 0.7320 - val_loss: 0.6306 - val_acc: 0.6458\n",
            "Epoch 617/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5133 - acc: 0.7353 - val_loss: 0.6296 - val_acc: 0.6667\n",
            "Epoch 618/2000\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.5251 - acc: 0.7549 - val_loss: 0.6222 - val_acc: 0.6771\n",
            "Epoch 619/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 0.5040 - acc: 0.7631 - val_loss: 0.6170 - val_acc: 0.6354\n",
            "Epoch 620/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.4733 - acc: 0.7843 - val_loss: 0.6005 - val_acc: 0.6458\n",
            "Epoch 621/2000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 0.5047 - acc: 0.7565 - val_loss: 0.6143 - val_acc: 0.6667\n",
            "Epoch 622/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 0.4962 - acc: 0.7549 - val_loss: 0.6328 - val_acc: 0.6667\n",
            "Epoch 623/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 0.5072 - acc: 0.7598 - val_loss: 0.6039 - val_acc: 0.6562\n",
            "Epoch 624/2000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 0.5168 - acc: 0.7549 - val_loss: 0.6223 - val_acc: 0.6146\n",
            "Epoch 625/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5356 - acc: 0.7206 - val_loss: 0.6012 - val_acc: 0.6458\n",
            "Epoch 626/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.4990 - acc: 0.7631 - val_loss: 0.6110 - val_acc: 0.6250\n",
            "Epoch 627/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.5096 - acc: 0.7451 - val_loss: 0.6036 - val_acc: 0.6354\n",
            "Epoch 628/2000\n",
            "39/39 [==============================] - 5s 100ms/step - loss: 0.4727 - acc: 0.7484 - val_loss: 0.6275 - val_acc: 0.6875\n",
            "Epoch 629/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5105 - acc: 0.7631 - val_loss: 0.6379 - val_acc: 0.6562\n",
            "Epoch 630/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5231 - acc: 0.7304 - val_loss: 0.6085 - val_acc: 0.6667\n",
            "Epoch 631/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5152 - acc: 0.7500 - val_loss: 0.6276 - val_acc: 0.6458\n",
            "Epoch 632/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.4988 - acc: 0.7712 - val_loss: 0.6237 - val_acc: 0.6354\n",
            "Epoch 633/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 0.5188 - acc: 0.7484 - val_loss: 0.6279 - val_acc: 0.6667\n",
            "Epoch 634/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.4961 - acc: 0.7500 - val_loss: 0.5936 - val_acc: 0.6354\n",
            "Epoch 635/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.4740 - acc: 0.7680 - val_loss: 0.6113 - val_acc: 0.6250\n",
            "Epoch 636/2000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 0.5019 - acc: 0.7549 - val_loss: 0.6292 - val_acc: 0.6667\n",
            "Epoch 637/2000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 0.5277 - acc: 0.7239 - val_loss: 0.6170 - val_acc: 0.6667\n",
            "Epoch 638/2000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.4779 - acc: 0.7794 - val_loss: 0.5846 - val_acc: 0.6771\n",
            "Epoch 639/2000\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.5337 - acc: 0.7418 - val_loss: 0.5979 - val_acc: 0.6250\n",
            "Epoch 640/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.5154 - acc: 0.7124 - val_loss: 0.5812 - val_acc: 0.6458\n",
            "Epoch 641/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.4903 - acc: 0.7582 - val_loss: 0.5967 - val_acc: 0.6771\n",
            "Epoch 642/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5263 - acc: 0.7255 - val_loss: 0.5998 - val_acc: 0.6146\n",
            "Epoch 643/2000\n",
            "39/39 [==============================] - 5s 96ms/step - loss: 0.5171 - acc: 0.7435 - val_loss: 0.6185 - val_acc: 0.6667\n",
            "Epoch 644/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.4821 - acc: 0.7614 - val_loss: 0.5950 - val_acc: 0.6771\n",
            "Epoch 645/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 0.4901 - acc: 0.7647 - val_loss: 0.6188 - val_acc: 0.6771\n",
            "Epoch 646/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.4980 - acc: 0.7467 - val_loss: 0.6112 - val_acc: 0.6562\n",
            "Epoch 647/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5007 - acc: 0.7549 - val_loss: 0.6140 - val_acc: 0.6667\n",
            "Epoch 648/2000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 0.5158 - acc: 0.7484 - val_loss: 0.6144 - val_acc: 0.6562\n",
            "Epoch 649/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5076 - acc: 0.7533 - val_loss: 0.6021 - val_acc: 0.6562\n",
            "Epoch 650/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 0.5067 - acc: 0.7353 - val_loss: 0.5923 - val_acc: 0.6562\n",
            "Epoch 651/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5389 - acc: 0.7467 - val_loss: 0.6030 - val_acc: 0.6354\n",
            "Epoch 652/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.4776 - acc: 0.7712 - val_loss: 0.6189 - val_acc: 0.6562\n",
            "Epoch 653/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.5164 - acc: 0.7402 - val_loss: 0.6406 - val_acc: 0.6667\n",
            "Epoch 654/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.5466 - acc: 0.7124 - val_loss: 0.6220 - val_acc: 0.6562\n",
            "Epoch 655/2000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 0.5153 - acc: 0.7369 - val_loss: 0.6117 - val_acc: 0.6771\n",
            "Epoch 656/2000\n",
            "39/39 [==============================] - 5s 122ms/step - loss: 0.5429 - acc: 0.7484 - val_loss: 0.6143 - val_acc: 0.6875\n",
            "Epoch 657/2000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 0.5153 - acc: 0.7500 - val_loss: 0.6449 - val_acc: 0.6667\n",
            "Epoch 658/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.4964 - acc: 0.7761 - val_loss: 0.6226 - val_acc: 0.6562\n",
            "Epoch 659/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5059 - acc: 0.7631 - val_loss: 0.6164 - val_acc: 0.6667\n",
            "Epoch 660/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 0.4981 - acc: 0.7663 - val_loss: 0.6219 - val_acc: 0.6562\n",
            "Epoch 661/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 0.5284 - acc: 0.7467 - val_loss: 0.6302 - val_acc: 0.6458\n",
            "Epoch 662/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.4732 - acc: 0.7663 - val_loss: 0.6274 - val_acc: 0.6146\n",
            "Epoch 663/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.5384 - acc: 0.7337 - val_loss: 0.6107 - val_acc: 0.6250\n",
            "Epoch 664/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5303 - acc: 0.7647 - val_loss: 0.6022 - val_acc: 0.6146\n",
            "Epoch 665/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5359 - acc: 0.7467 - val_loss: 0.6415 - val_acc: 0.6458\n",
            "Epoch 666/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.5220 - acc: 0.7484 - val_loss: 0.6071 - val_acc: 0.6458\n",
            "Epoch 667/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.4913 - acc: 0.7794 - val_loss: 0.5994 - val_acc: 0.6667\n",
            "Epoch 668/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.5323 - acc: 0.7549 - val_loss: 0.5728 - val_acc: 0.6354\n",
            "Epoch 669/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.4936 - acc: 0.7663 - val_loss: 0.6141 - val_acc: 0.6875\n",
            "Epoch 670/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.4948 - acc: 0.7663 - val_loss: 0.6230 - val_acc: 0.6562\n",
            "Epoch 671/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 0.5360 - acc: 0.7484 - val_loss: 0.6114 - val_acc: 0.6458\n",
            "Epoch 672/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.4953 - acc: 0.7631 - val_loss: 0.6172 - val_acc: 0.6562\n",
            "Epoch 673/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 0.5173 - acc: 0.7369 - val_loss: 0.6011 - val_acc: 0.6562\n",
            "Epoch 674/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.4892 - acc: 0.7631 - val_loss: 0.6141 - val_acc: 0.6562\n",
            "Epoch 675/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.4853 - acc: 0.7500 - val_loss: 0.5991 - val_acc: 0.6562\n",
            "Epoch 676/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.4936 - acc: 0.7484 - val_loss: 0.6018 - val_acc: 0.6458\n",
            "Epoch 677/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 0.4904 - acc: 0.7631 - val_loss: 0.5934 - val_acc: 0.6667\n",
            "Epoch 678/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5059 - acc: 0.7533 - val_loss: 0.5871 - val_acc: 0.6250\n",
            "Epoch 679/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 0.4950 - acc: 0.7533 - val_loss: 0.6229 - val_acc: 0.6771\n",
            "Epoch 680/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.4897 - acc: 0.7565 - val_loss: 0.5871 - val_acc: 0.6458\n",
            "Epoch 681/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.4691 - acc: 0.7516 - val_loss: 0.6072 - val_acc: 0.6354\n",
            "Epoch 682/2000\n",
            "39/39 [==============================] - 5s 101ms/step - loss: 0.5005 - acc: 0.7500 - val_loss: 0.6144 - val_acc: 0.6458\n",
            "Epoch 683/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.4771 - acc: 0.7827 - val_loss: 0.6099 - val_acc: 0.6667\n",
            "Epoch 684/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.4791 - acc: 0.7598 - val_loss: 0.5938 - val_acc: 0.6562\n",
            "Epoch 685/2000\n",
            "39/39 [==============================] - 10s 236ms/step - loss: 0.4988 - acc: 0.7484 - val_loss: 0.5801 - val_acc: 0.7083\n",
            "Epoch 686/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 0.5312 - acc: 0.7533 - val_loss: 0.5835 - val_acc: 0.6875\n",
            "Epoch 687/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5156 - acc: 0.7402 - val_loss: 0.5915 - val_acc: 0.6979\n",
            "Epoch 688/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.5293 - acc: 0.7500 - val_loss: 0.5834 - val_acc: 0.6875\n",
            "Epoch 689/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 0.5214 - acc: 0.7582 - val_loss: 0.6098 - val_acc: 0.6875\n",
            "Epoch 690/2000\n",
            "39/39 [==============================] - 4s 80ms/step - loss: 0.5262 - acc: 0.7255 - val_loss: 0.6208 - val_acc: 0.6771\n",
            "Epoch 691/2000\n",
            "39/39 [==============================] - 10s 231ms/step - loss: 0.5000 - acc: 0.7712 - val_loss: 0.6010 - val_acc: 0.6354\n",
            "Epoch 692/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5565 - acc: 0.7304 - val_loss: 0.5834 - val_acc: 0.6354\n",
            "Epoch 693/2000\n",
            "39/39 [==============================] - 10s 235ms/step - loss: 0.4925 - acc: 0.7647 - val_loss: 0.6122 - val_acc: 0.6667\n",
            "Epoch 694/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.4965 - acc: 0.7320 - val_loss: 0.6200 - val_acc: 0.6562\n",
            "Epoch 695/2000\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 0.4955 - acc: 0.7614 - val_loss: 0.5948 - val_acc: 0.6354\n",
            "Epoch 696/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5030 - acc: 0.7516 - val_loss: 0.5953 - val_acc: 0.6979\n",
            "Epoch 697/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.4859 - acc: 0.7712 - val_loss: 0.6078 - val_acc: 0.6458\n",
            "Epoch 698/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.4755 - acc: 0.7598 - val_loss: 0.6076 - val_acc: 0.6250\n",
            "Epoch 699/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.4751 - acc: 0.7859 - val_loss: 0.6058 - val_acc: 0.6250\n",
            "Epoch 700/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 0.5092 - acc: 0.7435 - val_loss: 0.6040 - val_acc: 0.6146\n",
            "Epoch 701/2000\n",
            "39/39 [==============================] - 5s 100ms/step - loss: 0.5219 - acc: 0.7435 - val_loss: 0.6012 - val_acc: 0.6146\n",
            "Epoch 702/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5352 - acc: 0.7435 - val_loss: 0.6175 - val_acc: 0.6458\n",
            "Epoch 703/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.5320 - acc: 0.7516 - val_loss: 0.6204 - val_acc: 0.5938\n",
            "Epoch 704/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5002 - acc: 0.7582 - val_loss: 0.6077 - val_acc: 0.6562\n",
            "Epoch 705/2000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 0.4689 - acc: 0.7761 - val_loss: 0.5875 - val_acc: 0.6979\n",
            "Epoch 706/2000\n",
            "39/39 [==============================] - 5s 101ms/step - loss: 0.5407 - acc: 0.7304 - val_loss: 0.6037 - val_acc: 0.6667\n",
            "Epoch 707/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5253 - acc: 0.7337 - val_loss: 0.6208 - val_acc: 0.6771\n",
            "Epoch 708/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.4819 - acc: 0.7712 - val_loss: 0.6252 - val_acc: 0.6875\n",
            "Epoch 709/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5083 - acc: 0.7533 - val_loss: 0.5969 - val_acc: 0.6354\n",
            "Epoch 710/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.5005 - acc: 0.7565 - val_loss: 0.6081 - val_acc: 0.6771\n",
            "Epoch 711/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.4894 - acc: 0.7663 - val_loss: 0.6209 - val_acc: 0.6042\n",
            "Epoch 712/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5210 - acc: 0.7239 - val_loss: 0.6194 - val_acc: 0.6250\n",
            "Epoch 713/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 0.4801 - acc: 0.7761 - val_loss: 0.5935 - val_acc: 0.6979\n",
            "Epoch 714/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 0.5002 - acc: 0.7582 - val_loss: 0.6082 - val_acc: 0.6146\n",
            "Epoch 715/2000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 0.5471 - acc: 0.7075 - val_loss: 0.6234 - val_acc: 0.6771\n",
            "Epoch 716/2000\n",
            "39/39 [==============================] - 9s 231ms/step - loss: 0.5480 - acc: 0.7288 - val_loss: 0.5777 - val_acc: 0.6667\n",
            "Epoch 717/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 0.5016 - acc: 0.7565 - val_loss: 0.6032 - val_acc: 0.6250\n",
            "Epoch 718/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 0.5215 - acc: 0.7435 - val_loss: 0.6366 - val_acc: 0.6875\n",
            "Epoch 719/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5059 - acc: 0.7500 - val_loss: 0.6216 - val_acc: 0.6354\n",
            "Epoch 720/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.5133 - acc: 0.7435 - val_loss: 0.6129 - val_acc: 0.6771\n",
            "Epoch 721/2000\n",
            "39/39 [==============================] - 9s 235ms/step - loss: 0.4995 - acc: 0.7761 - val_loss: 0.6514 - val_acc: 0.6667\n",
            "Epoch 722/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 0.5090 - acc: 0.7614 - val_loss: 0.6442 - val_acc: 0.6667\n",
            "Epoch 723/2000\n",
            "39/39 [==============================] - 10s 234ms/step - loss: 0.5038 - acc: 0.7647 - val_loss: 0.6201 - val_acc: 0.6771\n",
            "Epoch 724/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 0.5019 - acc: 0.7614 - val_loss: 0.6011 - val_acc: 0.6354\n",
            "Epoch 725/2000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 0.4821 - acc: 0.7729 - val_loss: 0.5982 - val_acc: 0.6458\n",
            "Epoch 726/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.4995 - acc: 0.7647 - val_loss: 0.6032 - val_acc: 0.6875\n",
            "Epoch 727/2000\n",
            "39/39 [==============================] - 9s 209ms/step - loss: 0.5150 - acc: 0.7402 - val_loss: 0.5980 - val_acc: 0.7083\n",
            "Epoch 728/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5470 - acc: 0.7402 - val_loss: 0.6013 - val_acc: 0.6875\n",
            "Epoch 729/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.5189 - acc: 0.7288 - val_loss: 0.6399 - val_acc: 0.6771\n",
            "Epoch 730/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.4960 - acc: 0.7402 - val_loss: 0.6201 - val_acc: 0.6562\n",
            "Epoch 731/2000\n",
            "39/39 [==============================] - 5s 115ms/step - loss: 0.5351 - acc: 0.7108 - val_loss: 0.6025 - val_acc: 0.6667\n",
            "Epoch 732/2000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 0.4929 - acc: 0.7533 - val_loss: 0.6010 - val_acc: 0.6562\n",
            "Epoch 733/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.4995 - acc: 0.7680 - val_loss: 0.6166 - val_acc: 0.6771\n",
            "Epoch 734/2000\n",
            "39/39 [==============================] - 5s 103ms/step - loss: 0.5211 - acc: 0.7582 - val_loss: 0.6298 - val_acc: 0.6667\n",
            "Epoch 735/2000\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 0.5085 - acc: 0.7582 - val_loss: 0.6203 - val_acc: 0.6771\n",
            "Epoch 736/2000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 0.5416 - acc: 0.7288 - val_loss: 0.6055 - val_acc: 0.6458\n",
            "Epoch 737/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.4835 - acc: 0.7598 - val_loss: 0.5911 - val_acc: 0.7083\n",
            "Epoch 738/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.4915 - acc: 0.7549 - val_loss: 0.6290 - val_acc: 0.6458\n",
            "Epoch 739/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.4895 - acc: 0.7761 - val_loss: 0.6227 - val_acc: 0.6771\n",
            "Epoch 740/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5562 - acc: 0.7059 - val_loss: 0.6132 - val_acc: 0.6562\n",
            "Epoch 741/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.5107 - acc: 0.7729 - val_loss: 0.6129 - val_acc: 0.6562\n",
            "Epoch 742/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.4974 - acc: 0.7680 - val_loss: 0.6075 - val_acc: 0.6667\n",
            "Epoch 743/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5043 - acc: 0.7484 - val_loss: 0.6198 - val_acc: 0.6458\n",
            "Epoch 744/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.5278 - acc: 0.7418 - val_loss: 0.6034 - val_acc: 0.6562\n",
            "Epoch 745/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5412 - acc: 0.7516 - val_loss: 0.6054 - val_acc: 0.6354\n",
            "Epoch 746/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5191 - acc: 0.7533 - val_loss: 0.6246 - val_acc: 0.6667\n",
            "Epoch 747/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.4752 - acc: 0.7663 - val_loss: 0.6385 - val_acc: 0.6458\n",
            "Epoch 748/2000\n",
            "39/39 [==============================] - 9s 233ms/step - loss: 0.4920 - acc: 0.7484 - val_loss: 0.6204 - val_acc: 0.6667\n",
            "Epoch 749/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.5145 - acc: 0.7369 - val_loss: 0.6255 - val_acc: 0.6562\n",
            "Epoch 750/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.5179 - acc: 0.7288 - val_loss: 0.6213 - val_acc: 0.6562\n",
            "Epoch 751/2000\n",
            "39/39 [==============================] - 4s 106ms/step - loss: 0.5123 - acc: 0.7647 - val_loss: 0.5777 - val_acc: 0.6667\n",
            "Epoch 752/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 0.4798 - acc: 0.7647 - val_loss: 0.6203 - val_acc: 0.6562\n",
            "Epoch 753/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.5269 - acc: 0.7435 - val_loss: 0.6020 - val_acc: 0.6667\n",
            "Epoch 754/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.4724 - acc: 0.7696 - val_loss: 0.6226 - val_acc: 0.6875\n",
            "Epoch 755/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5097 - acc: 0.7467 - val_loss: 0.6250 - val_acc: 0.6875\n",
            "Epoch 756/2000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 0.5275 - acc: 0.7516 - val_loss: 0.6201 - val_acc: 0.6562\n",
            "Epoch 757/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.4978 - acc: 0.7451 - val_loss: 0.6478 - val_acc: 0.6875\n",
            "Epoch 758/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.4897 - acc: 0.7680 - val_loss: 0.6202 - val_acc: 0.6771\n",
            "Epoch 759/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5223 - acc: 0.7451 - val_loss: 0.6367 - val_acc: 0.6458\n",
            "Epoch 760/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5161 - acc: 0.7467 - val_loss: 0.6092 - val_acc: 0.6458\n",
            "Epoch 761/2000\n",
            "39/39 [==============================] - 5s 102ms/step - loss: 0.4836 - acc: 0.7647 - val_loss: 0.6168 - val_acc: 0.6562\n",
            "Epoch 762/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.5391 - acc: 0.7598 - val_loss: 0.5901 - val_acc: 0.6771\n",
            "Epoch 763/2000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 0.4854 - acc: 0.7631 - val_loss: 0.6099 - val_acc: 0.6771\n",
            "Epoch 764/2000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 0.5181 - acc: 0.7631 - val_loss: 0.6480 - val_acc: 0.6667\n",
            "Epoch 765/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5321 - acc: 0.7402 - val_loss: 0.6295 - val_acc: 0.6875\n",
            "Epoch 766/2000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 0.5468 - acc: 0.7092 - val_loss: 0.6046 - val_acc: 0.6667\n",
            "Epoch 767/2000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 0.5026 - acc: 0.7435 - val_loss: 0.6431 - val_acc: 0.6771\n",
            "Epoch 768/2000\n",
            "39/39 [==============================] - 5s 101ms/step - loss: 0.5460 - acc: 0.7386 - val_loss: 0.5998 - val_acc: 0.6771\n",
            "Epoch 769/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 0.5070 - acc: 0.7435 - val_loss: 0.6031 - val_acc: 0.6771\n",
            "Epoch 770/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.4783 - acc: 0.7712 - val_loss: 0.6143 - val_acc: 0.6250\n",
            "Epoch 771/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5028 - acc: 0.7598 - val_loss: 0.6285 - val_acc: 0.6458\n",
            "Epoch 772/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5063 - acc: 0.7549 - val_loss: 0.6002 - val_acc: 0.6250\n",
            "Epoch 773/2000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 0.5173 - acc: 0.7320 - val_loss: 0.6587 - val_acc: 0.6667\n",
            "Epoch 774/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5133 - acc: 0.7404 - val_loss: 0.6069 - val_acc: 0.6562\n",
            "Epoch 775/2000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 0.4695 - acc: 0.7892 - val_loss: 0.6074 - val_acc: 0.6146\n",
            "Epoch 776/2000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 0.5113 - acc: 0.7516 - val_loss: 0.6144 - val_acc: 0.6667\n",
            "Epoch 777/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5526 - acc: 0.7141 - val_loss: 0.6121 - val_acc: 0.6562\n",
            "Epoch 778/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.5072 - acc: 0.7402 - val_loss: 0.6046 - val_acc: 0.6562\n",
            "Epoch 779/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5381 - acc: 0.7500 - val_loss: 0.6148 - val_acc: 0.6667\n",
            "Epoch 780/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.5129 - acc: 0.7533 - val_loss: 0.6089 - val_acc: 0.6771\n",
            "Epoch 781/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 0.5048 - acc: 0.7337 - val_loss: 0.6408 - val_acc: 0.6875\n",
            "Epoch 782/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 0.4876 - acc: 0.7631 - val_loss: 0.6347 - val_acc: 0.6667\n",
            "Epoch 783/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5014 - acc: 0.7451 - val_loss: 0.5995 - val_acc: 0.6875\n",
            "Epoch 784/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.5229 - acc: 0.7304 - val_loss: 0.6190 - val_acc: 0.6875\n",
            "Epoch 785/2000\n",
            "39/39 [==============================] - 5s 98ms/step - loss: 0.4946 - acc: 0.7598 - val_loss: 0.5921 - val_acc: 0.6771\n",
            "Epoch 786/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5247 - acc: 0.7320 - val_loss: 0.6167 - val_acc: 0.6667\n",
            "Epoch 787/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.4915 - acc: 0.7631 - val_loss: 0.6308 - val_acc: 0.6458\n",
            "Epoch 788/2000\n",
            "39/39 [==============================] - 9s 232ms/step - loss: 0.4934 - acc: 0.7680 - val_loss: 0.6059 - val_acc: 0.6562\n",
            "Epoch 789/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.4749 - acc: 0.7821 - val_loss: 0.5820 - val_acc: 0.6354\n",
            "Epoch 790/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 0.4995 - acc: 0.7712 - val_loss: 0.6421 - val_acc: 0.6979\n",
            "Epoch 791/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5512 - acc: 0.7451 - val_loss: 0.6684 - val_acc: 0.6667\n",
            "Epoch 792/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5009 - acc: 0.7598 - val_loss: 0.6171 - val_acc: 0.6562\n",
            "Epoch 793/2000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 0.5117 - acc: 0.7320 - val_loss: 0.6288 - val_acc: 0.6667\n",
            "Epoch 794/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5289 - acc: 0.7451 - val_loss: 0.6180 - val_acc: 0.6667\n",
            "Epoch 795/2000\n",
            "39/39 [==============================] - 9s 231ms/step - loss: 0.4903 - acc: 0.7647 - val_loss: 0.6271 - val_acc: 0.6458\n",
            "Epoch 796/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5123 - acc: 0.7418 - val_loss: 0.5921 - val_acc: 0.7083\n",
            "Epoch 797/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.4923 - acc: 0.7745 - val_loss: 0.6031 - val_acc: 0.6875\n",
            "Epoch 798/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5091 - acc: 0.7663 - val_loss: 0.6325 - val_acc: 0.6771\n",
            "Epoch 799/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5150 - acc: 0.7304 - val_loss: 0.6369 - val_acc: 0.6771\n",
            "Epoch 800/2000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 0.5139 - acc: 0.7663 - val_loss: 0.6180 - val_acc: 0.6562\n",
            "Epoch 801/2000\n",
            "39/39 [==============================] - 5s 112ms/step - loss: 0.5234 - acc: 0.7337 - val_loss: 0.6024 - val_acc: 0.6979\n",
            "Epoch 802/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.5124 - acc: 0.7549 - val_loss: 0.6265 - val_acc: 0.6875\n",
            "Epoch 803/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.5211 - acc: 0.7255 - val_loss: 0.6307 - val_acc: 0.6562\n",
            "Epoch 804/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.5430 - acc: 0.7337 - val_loss: 0.6410 - val_acc: 0.6875\n",
            "Epoch 805/2000\n",
            "39/39 [==============================] - 9s 208ms/step - loss: 0.5115 - acc: 0.7500 - val_loss: 0.6488 - val_acc: 0.6771\n",
            "Epoch 806/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 0.5146 - acc: 0.7369 - val_loss: 0.6303 - val_acc: 0.6562\n",
            "Epoch 807/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5086 - acc: 0.7614 - val_loss: 0.6126 - val_acc: 0.6354\n",
            "Epoch 808/2000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 0.5102 - acc: 0.7500 - val_loss: 0.6293 - val_acc: 0.6562\n",
            "Epoch 809/2000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 0.5446 - acc: 0.7402 - val_loss: 0.6039 - val_acc: 0.6667\n",
            "Epoch 810/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 0.5117 - acc: 0.7647 - val_loss: 0.6059 - val_acc: 0.6771\n",
            "Epoch 811/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.5035 - acc: 0.7647 - val_loss: 0.6320 - val_acc: 0.6458\n",
            "Epoch 812/2000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 0.4986 - acc: 0.7500 - val_loss: 0.6090 - val_acc: 0.7083\n",
            "Epoch 813/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 0.5008 - acc: 0.7565 - val_loss: 0.6167 - val_acc: 0.6562\n",
            "Epoch 814/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 0.5150 - acc: 0.7304 - val_loss: 0.6218 - val_acc: 0.6875\n",
            "Epoch 815/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 0.4995 - acc: 0.7386 - val_loss: 0.5876 - val_acc: 0.6771\n",
            "Epoch 816/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.5059 - acc: 0.7304 - val_loss: 0.6141 - val_acc: 0.6667\n",
            "Epoch 817/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5063 - acc: 0.7596 - val_loss: 0.6147 - val_acc: 0.6875\n",
            "Epoch 818/2000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 0.5230 - acc: 0.7582 - val_loss: 0.6402 - val_acc: 0.6771\n",
            "Epoch 819/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5148 - acc: 0.7484 - val_loss: 0.6043 - val_acc: 0.7083\n",
            "Epoch 820/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.5111 - acc: 0.7663 - val_loss: 0.6111 - val_acc: 0.6562\n",
            "Epoch 821/2000\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 0.5176 - acc: 0.7533 - val_loss: 0.6025 - val_acc: 0.6771\n",
            "Epoch 822/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5020 - acc: 0.7614 - val_loss: 0.6029 - val_acc: 0.6771\n",
            "Epoch 823/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.4989 - acc: 0.7598 - val_loss: 0.5994 - val_acc: 0.6875\n",
            "Epoch 824/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.4852 - acc: 0.7745 - val_loss: 0.6021 - val_acc: 0.6667\n",
            "Epoch 825/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 0.5015 - acc: 0.7451 - val_loss: 0.6313 - val_acc: 0.6562\n",
            "Epoch 826/2000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 0.5127 - acc: 0.7484 - val_loss: 0.5871 - val_acc: 0.6771\n",
            "Epoch 827/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5104 - acc: 0.7696 - val_loss: 0.6059 - val_acc: 0.6562\n",
            "Epoch 828/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.5530 - acc: 0.7451 - val_loss: 0.5979 - val_acc: 0.6354\n",
            "Epoch 829/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5307 - acc: 0.7533 - val_loss: 0.6138 - val_acc: 0.6458\n",
            "Epoch 830/2000\n",
            "39/39 [==============================] - 5s 117ms/step - loss: 0.4928 - acc: 0.7516 - val_loss: 0.6076 - val_acc: 0.6771\n",
            "Epoch 831/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.5032 - acc: 0.7467 - val_loss: 0.6273 - val_acc: 0.6875\n",
            "Epoch 832/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.5489 - acc: 0.7157 - val_loss: 0.6148 - val_acc: 0.6771\n",
            "Epoch 833/2000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 0.5039 - acc: 0.7320 - val_loss: 0.5807 - val_acc: 0.6562\n",
            "Epoch 834/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 0.4949 - acc: 0.7745 - val_loss: 0.6096 - val_acc: 0.6771\n",
            "Epoch 835/2000\n",
            "39/39 [==============================] - 6s 143ms/step - loss: 0.5168 - acc: 0.7582 - val_loss: 0.6111 - val_acc: 0.6875\n",
            "Epoch 836/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 0.5173 - acc: 0.7761 - val_loss: 0.6170 - val_acc: 0.6771\n",
            "Epoch 837/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5481 - acc: 0.7435 - val_loss: 0.5872 - val_acc: 0.6771\n",
            "Epoch 838/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.4987 - acc: 0.7467 - val_loss: 0.6091 - val_acc: 0.6875\n",
            "Epoch 839/2000\n",
            "39/39 [==============================] - 5s 93ms/step - loss: 0.5246 - acc: 0.7288 - val_loss: 0.6056 - val_acc: 0.6458\n",
            "Epoch 840/2000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 0.4959 - acc: 0.7549 - val_loss: 0.6176 - val_acc: 0.6771\n",
            "Epoch 841/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5126 - acc: 0.7516 - val_loss: 0.5827 - val_acc: 0.6771\n",
            "Epoch 842/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 0.4868 - acc: 0.7647 - val_loss: 0.6096 - val_acc: 0.6562\n",
            "Epoch 843/2000\n",
            "39/39 [==============================] - 6s 140ms/step - loss: 0.5007 - acc: 0.7565 - val_loss: 0.5838 - val_acc: 0.6562\n",
            "Epoch 844/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.4818 - acc: 0.7794 - val_loss: 0.5787 - val_acc: 0.6875\n",
            "Epoch 845/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5383 - acc: 0.7304 - val_loss: 0.5780 - val_acc: 0.6771\n",
            "Epoch 846/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 0.5310 - acc: 0.7157 - val_loss: 0.5761 - val_acc: 0.6667\n",
            "Epoch 847/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5491 - acc: 0.7386 - val_loss: 0.6082 - val_acc: 0.6979\n",
            "Epoch 848/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.5599 - acc: 0.7206 - val_loss: 0.6016 - val_acc: 0.6771\n",
            "Epoch 849/2000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 0.5173 - acc: 0.7451 - val_loss: 0.5960 - val_acc: 0.6562\n",
            "Epoch 850/2000\n",
            "39/39 [==============================] - 5s 99ms/step - loss: 0.5032 - acc: 0.7288 - val_loss: 0.6093 - val_acc: 0.6667\n",
            "Epoch 851/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5001 - acc: 0.7500 - val_loss: 0.6044 - val_acc: 0.6875\n",
            "Epoch 852/2000\n",
            "39/39 [==============================] - 5s 117ms/step - loss: 0.4951 - acc: 0.7500 - val_loss: 0.6199 - val_acc: 0.6979\n",
            "Epoch 853/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5146 - acc: 0.7467 - val_loss: 0.6237 - val_acc: 0.6667\n",
            "Epoch 854/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5065 - acc: 0.7418 - val_loss: 0.5780 - val_acc: 0.6667\n",
            "Epoch 855/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5060 - acc: 0.7647 - val_loss: 0.6035 - val_acc: 0.6667\n",
            "Epoch 856/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5306 - acc: 0.7402 - val_loss: 0.5816 - val_acc: 0.6667\n",
            "Epoch 857/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.4592 - acc: 0.7614 - val_loss: 0.6189 - val_acc: 0.6771\n",
            "Epoch 858/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5097 - acc: 0.7614 - val_loss: 0.5965 - val_acc: 0.6562\n",
            "Epoch 859/2000\n",
            "39/39 [==============================] - 9s 232ms/step - loss: 0.5040 - acc: 0.7435 - val_loss: 0.5969 - val_acc: 0.6354\n",
            "Epoch 860/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5125 - acc: 0.7386 - val_loss: 0.5818 - val_acc: 0.6771\n",
            "Epoch 861/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5077 - acc: 0.7565 - val_loss: 0.5989 - val_acc: 0.6875\n",
            "Epoch 862/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 0.5029 - acc: 0.7451 - val_loss: 0.6082 - val_acc: 0.6562\n",
            "Epoch 863/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.5374 - acc: 0.7418 - val_loss: 0.5937 - val_acc: 0.6771\n",
            "Epoch 864/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.5394 - acc: 0.7222 - val_loss: 0.5928 - val_acc: 0.6354\n",
            "Epoch 865/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5034 - acc: 0.7614 - val_loss: 0.6039 - val_acc: 0.6458\n",
            "Epoch 866/2000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 0.5304 - acc: 0.7222 - val_loss: 0.5801 - val_acc: 0.6562\n",
            "Epoch 867/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 0.5124 - acc: 0.7369 - val_loss: 0.5882 - val_acc: 0.6979\n",
            "Epoch 868/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5114 - acc: 0.7647 - val_loss: 0.5912 - val_acc: 0.6562\n",
            "Epoch 869/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5138 - acc: 0.7467 - val_loss: 0.5949 - val_acc: 0.6562\n",
            "Epoch 870/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.5180 - acc: 0.7451 - val_loss: 0.6032 - val_acc: 0.6667\n",
            "Epoch 871/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 0.5279 - acc: 0.7320 - val_loss: 0.6142 - val_acc: 0.6667\n",
            "Epoch 872/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.4800 - acc: 0.7418 - val_loss: 0.6402 - val_acc: 0.6771\n",
            "Epoch 873/2000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 0.4966 - acc: 0.7549 - val_loss: 0.5804 - val_acc: 0.6875\n",
            "Epoch 874/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 0.4970 - acc: 0.7467 - val_loss: 0.6036 - val_acc: 0.6667\n",
            "Epoch 875/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.4854 - acc: 0.7484 - val_loss: 0.6290 - val_acc: 0.6667\n",
            "Epoch 876/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.4906 - acc: 0.7549 - val_loss: 0.6096 - val_acc: 0.6250\n",
            "Epoch 877/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5072 - acc: 0.7647 - val_loss: 0.6051 - val_acc: 0.6667\n",
            "Epoch 878/2000\n",
            "39/39 [==============================] - 10s 232ms/step - loss: 0.5284 - acc: 0.7418 - val_loss: 0.6066 - val_acc: 0.6250\n",
            "Epoch 879/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.5175 - acc: 0.7451 - val_loss: 0.5886 - val_acc: 0.6562\n",
            "Epoch 880/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.5046 - acc: 0.7418 - val_loss: 0.6342 - val_acc: 0.6667\n",
            "Epoch 881/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5254 - acc: 0.7484 - val_loss: 0.5950 - val_acc: 0.6458\n",
            "Epoch 882/2000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.4969 - acc: 0.7549 - val_loss: 0.5828 - val_acc: 0.6667\n",
            "Epoch 883/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 0.5546 - acc: 0.7337 - val_loss: 0.5749 - val_acc: 0.6562\n",
            "Epoch 884/2000\n",
            "39/39 [==============================] - 4s 104ms/step - loss: 0.5244 - acc: 0.7255 - val_loss: 0.6053 - val_acc: 0.6562\n",
            "Epoch 885/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.4971 - acc: 0.7549 - val_loss: 0.6081 - val_acc: 0.6667\n",
            "Epoch 886/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5195 - acc: 0.7353 - val_loss: 0.6152 - val_acc: 0.6771\n",
            "Epoch 887/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5722 - acc: 0.7157 - val_loss: 0.5997 - val_acc: 0.6875\n",
            "Epoch 888/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.4965 - acc: 0.7614 - val_loss: 0.5898 - val_acc: 0.6875\n",
            "Epoch 889/2000\n",
            "39/39 [==============================] - 5s 100ms/step - loss: 0.5188 - acc: 0.7516 - val_loss: 0.6054 - val_acc: 0.6667\n",
            "Epoch 890/2000\n",
            "39/39 [==============================] - 4s 104ms/step - loss: 0.4927 - acc: 0.7582 - val_loss: 0.6058 - val_acc: 0.6562\n",
            "Epoch 891/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 0.5013 - acc: 0.7598 - val_loss: 0.6003 - val_acc: 0.6875\n",
            "Epoch 892/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5177 - acc: 0.7500 - val_loss: 0.6156 - val_acc: 0.6771\n",
            "Epoch 893/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.5174 - acc: 0.7467 - val_loss: 0.6130 - val_acc: 0.6458\n",
            "Epoch 894/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5236 - acc: 0.7369 - val_loss: 0.6031 - val_acc: 0.6458\n",
            "Epoch 895/2000\n",
            "39/39 [==============================] - 6s 133ms/step - loss: 0.5425 - acc: 0.7340 - val_loss: 0.6105 - val_acc: 0.6562\n",
            "Epoch 896/2000\n",
            "39/39 [==============================] - 9s 231ms/step - loss: 0.5233 - acc: 0.7304 - val_loss: 0.5764 - val_acc: 0.6562\n",
            "Epoch 897/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5122 - acc: 0.7386 - val_loss: 0.5731 - val_acc: 0.6771\n",
            "Epoch 898/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.4719 - acc: 0.7712 - val_loss: 0.5826 - val_acc: 0.6562\n",
            "Epoch 899/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.4966 - acc: 0.7467 - val_loss: 0.5989 - val_acc: 0.6771\n",
            "Epoch 900/2000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 0.5253 - acc: 0.7304 - val_loss: 0.5904 - val_acc: 0.6562\n",
            "Epoch 901/2000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 0.5476 - acc: 0.7271 - val_loss: 0.5848 - val_acc: 0.6667\n",
            "Epoch 902/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.5273 - acc: 0.7549 - val_loss: 0.6004 - val_acc: 0.6979\n",
            "Epoch 903/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.5213 - acc: 0.7435 - val_loss: 0.5952 - val_acc: 0.6771\n",
            "Epoch 904/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.5172 - acc: 0.7467 - val_loss: 0.5986 - val_acc: 0.6667\n",
            "Epoch 905/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5484 - acc: 0.7386 - val_loss: 0.5866 - val_acc: 0.6354\n",
            "Epoch 906/2000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 0.5093 - acc: 0.7402 - val_loss: 0.6155 - val_acc: 0.6771\n",
            "Epoch 907/2000\n",
            "39/39 [==============================] - 6s 133ms/step - loss: 0.5221 - acc: 0.7337 - val_loss: 0.5882 - val_acc: 0.6875\n",
            "Epoch 908/2000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 0.5055 - acc: 0.7810 - val_loss: 0.6040 - val_acc: 0.6458\n",
            "Epoch 909/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5008 - acc: 0.7435 - val_loss: 0.5898 - val_acc: 0.6354\n",
            "Epoch 910/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.4946 - acc: 0.7533 - val_loss: 0.5887 - val_acc: 0.6354\n",
            "Epoch 911/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 0.5076 - acc: 0.7598 - val_loss: 0.5868 - val_acc: 0.6562\n",
            "Epoch 912/2000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 0.5517 - acc: 0.7190 - val_loss: 0.5874 - val_acc: 0.6354\n",
            "Epoch 913/2000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 0.4853 - acc: 0.7778 - val_loss: 0.5927 - val_acc: 0.6979\n",
            "Epoch 914/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5066 - acc: 0.7631 - val_loss: 0.5891 - val_acc: 0.6875\n",
            "Epoch 915/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.4599 - acc: 0.7990 - val_loss: 0.5823 - val_acc: 0.7083\n",
            "Epoch 916/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.5000 - acc: 0.7353 - val_loss: 0.6092 - val_acc: 0.6667\n",
            "Epoch 917/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5349 - acc: 0.7239 - val_loss: 0.5833 - val_acc: 0.6875\n",
            "Epoch 918/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5227 - acc: 0.7271 - val_loss: 0.5713 - val_acc: 0.6354\n",
            "Epoch 919/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5216 - acc: 0.7337 - val_loss: 0.5805 - val_acc: 0.6458\n",
            "Epoch 920/2000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.5021 - acc: 0.7549 - val_loss: 0.6007 - val_acc: 0.6979\n",
            "Epoch 921/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.5018 - acc: 0.7549 - val_loss: 0.5825 - val_acc: 0.7083\n",
            "Epoch 922/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5051 - acc: 0.7500 - val_loss: 0.5983 - val_acc: 0.6667\n",
            "Epoch 923/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.5225 - acc: 0.7206 - val_loss: 0.6056 - val_acc: 0.6667\n",
            "Epoch 924/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5255 - acc: 0.7533 - val_loss: 0.5855 - val_acc: 0.6562\n",
            "Epoch 925/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5300 - acc: 0.7353 - val_loss: 0.5954 - val_acc: 0.6875\n",
            "Epoch 926/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.4930 - acc: 0.7565 - val_loss: 0.5730 - val_acc: 0.6354\n",
            "Epoch 927/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5345 - acc: 0.7402 - val_loss: 0.5788 - val_acc: 0.6458\n",
            "Epoch 928/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.5152 - acc: 0.7467 - val_loss: 0.5653 - val_acc: 0.6562\n",
            "Epoch 929/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 0.4837 - acc: 0.7745 - val_loss: 0.5696 - val_acc: 0.7083\n",
            "Epoch 930/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.4893 - acc: 0.7484 - val_loss: 0.6025 - val_acc: 0.6562\n",
            "Epoch 931/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.5028 - acc: 0.7500 - val_loss: 0.5862 - val_acc: 0.6562\n",
            "Epoch 932/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5101 - acc: 0.7255 - val_loss: 0.5639 - val_acc: 0.6771\n",
            "Epoch 933/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.5332 - acc: 0.7451 - val_loss: 0.5880 - val_acc: 0.6875\n",
            "Epoch 934/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5254 - acc: 0.7467 - val_loss: 0.6005 - val_acc: 0.6875\n",
            "Epoch 935/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.4801 - acc: 0.7810 - val_loss: 0.5840 - val_acc: 0.6667\n",
            "Epoch 936/2000\n",
            "39/39 [==============================] - 5s 103ms/step - loss: 0.5110 - acc: 0.7467 - val_loss: 0.6102 - val_acc: 0.6667\n",
            "Epoch 937/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5167 - acc: 0.7614 - val_loss: 0.6140 - val_acc: 0.6458\n",
            "Epoch 938/2000\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 0.5171 - acc: 0.7500 - val_loss: 0.5944 - val_acc: 0.6979\n",
            "Epoch 939/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.5290 - acc: 0.7271 - val_loss: 0.5948 - val_acc: 0.6562\n",
            "Epoch 940/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.5220 - acc: 0.7549 - val_loss: 0.6149 - val_acc: 0.6771\n",
            "Epoch 941/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.4663 - acc: 0.7614 - val_loss: 0.5876 - val_acc: 0.6667\n",
            "Epoch 942/2000\n",
            "39/39 [==============================] - 6s 131ms/step - loss: 0.5076 - acc: 0.7696 - val_loss: 0.5949 - val_acc: 0.6667\n",
            "Epoch 943/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 0.5258 - acc: 0.7304 - val_loss: 0.5947 - val_acc: 0.6458\n",
            "Epoch 944/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.5139 - acc: 0.7467 - val_loss: 0.5904 - val_acc: 0.6667\n",
            "Epoch 945/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5203 - acc: 0.7435 - val_loss: 0.6297 - val_acc: 0.6771\n",
            "Epoch 946/2000\n",
            "39/39 [==============================] - 5s 112ms/step - loss: 0.4874 - acc: 0.7631 - val_loss: 0.6245 - val_acc: 0.6667\n",
            "Epoch 947/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.5284 - acc: 0.7304 - val_loss: 0.5651 - val_acc: 0.7083\n",
            "Epoch 948/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.4996 - acc: 0.7761 - val_loss: 0.5921 - val_acc: 0.6458\n",
            "Epoch 949/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.5077 - acc: 0.7467 - val_loss: 0.5941 - val_acc: 0.6771\n",
            "Epoch 950/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5045 - acc: 0.7565 - val_loss: 0.5942 - val_acc: 0.6875\n",
            "Epoch 951/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.4931 - acc: 0.7500 - val_loss: 0.5858 - val_acc: 0.6979\n",
            "Epoch 952/2000\n",
            "39/39 [==============================] - 6s 137ms/step - loss: 0.5312 - acc: 0.7533 - val_loss: 0.5891 - val_acc: 0.6146\n",
            "Epoch 953/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5375 - acc: 0.7206 - val_loss: 0.5933 - val_acc: 0.6771\n",
            "Epoch 954/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.5077 - acc: 0.7255 - val_loss: 0.5659 - val_acc: 0.6771\n",
            "Epoch 955/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 0.4879 - acc: 0.7484 - val_loss: 0.6003 - val_acc: 0.6875\n",
            "Epoch 956/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.4767 - acc: 0.7647 - val_loss: 0.5777 - val_acc: 0.6667\n",
            "Epoch 957/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.5340 - acc: 0.7288 - val_loss: 0.6017 - val_acc: 0.6562\n",
            "Epoch 958/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 0.4805 - acc: 0.7794 - val_loss: 0.6115 - val_acc: 0.6875\n",
            "Epoch 959/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5590 - acc: 0.7190 - val_loss: 0.5959 - val_acc: 0.6771\n",
            "Epoch 960/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.5196 - acc: 0.7516 - val_loss: 0.5962 - val_acc: 0.6771\n",
            "Epoch 961/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.5215 - acc: 0.7451 - val_loss: 0.6354 - val_acc: 0.6771\n",
            "Epoch 962/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.5385 - acc: 0.7418 - val_loss: 0.6090 - val_acc: 0.6562\n",
            "Epoch 963/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.5028 - acc: 0.7386 - val_loss: 0.6104 - val_acc: 0.6667\n",
            "Epoch 964/2000\n",
            "39/39 [==============================] - 9s 209ms/step - loss: 0.4893 - acc: 0.7614 - val_loss: 0.6339 - val_acc: 0.6667\n",
            "Epoch 965/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5015 - acc: 0.7484 - val_loss: 0.6100 - val_acc: 0.6667\n",
            "Epoch 966/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.5325 - acc: 0.7484 - val_loss: 0.6304 - val_acc: 0.6875\n",
            "Epoch 967/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.5186 - acc: 0.7565 - val_loss: 0.5963 - val_acc: 0.6667\n",
            "Epoch 968/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5040 - acc: 0.7484 - val_loss: 0.5897 - val_acc: 0.6979\n",
            "Epoch 969/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.4766 - acc: 0.7565 - val_loss: 0.6199 - val_acc: 0.6979\n",
            "Epoch 970/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.4785 - acc: 0.7614 - val_loss: 0.6253 - val_acc: 0.6771\n",
            "Epoch 971/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5250 - acc: 0.7288 - val_loss: 0.6211 - val_acc: 0.6875\n",
            "Epoch 972/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5062 - acc: 0.7549 - val_loss: 0.6206 - val_acc: 0.6979\n",
            "Epoch 973/2000\n",
            "39/39 [==============================] - 9s 232ms/step - loss: 0.5405 - acc: 0.7206 - val_loss: 0.6316 - val_acc: 0.6667\n",
            "Epoch 974/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.4938 - acc: 0.7484 - val_loss: 0.6249 - val_acc: 0.6667\n",
            "Epoch 975/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.4968 - acc: 0.7516 - val_loss: 0.6124 - val_acc: 0.6562\n",
            "Epoch 976/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.4877 - acc: 0.7680 - val_loss: 0.6091 - val_acc: 0.6875\n",
            "Epoch 977/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5020 - acc: 0.7418 - val_loss: 0.5932 - val_acc: 0.6354\n",
            "Epoch 978/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.5420 - acc: 0.7157 - val_loss: 0.6040 - val_acc: 0.6771\n",
            "Epoch 979/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5265 - acc: 0.7206 - val_loss: 0.5904 - val_acc: 0.6354\n",
            "Epoch 980/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5328 - acc: 0.7484 - val_loss: 0.6129 - val_acc: 0.6771\n",
            "Epoch 981/2000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 0.4639 - acc: 0.7696 - val_loss: 0.5781 - val_acc: 0.6875\n",
            "Epoch 982/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5090 - acc: 0.7533 - val_loss: 0.6119 - val_acc: 0.6875\n",
            "Epoch 983/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.4881 - acc: 0.7598 - val_loss: 0.6075 - val_acc: 0.6771\n",
            "Epoch 984/2000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 0.4689 - acc: 0.7810 - val_loss: 0.5831 - val_acc: 0.6979\n",
            "Epoch 985/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.4808 - acc: 0.7761 - val_loss: 0.6336 - val_acc: 0.6667\n",
            "Epoch 986/2000\n",
            "39/39 [==============================] - 10s 233ms/step - loss: 0.5194 - acc: 0.7386 - val_loss: 0.5907 - val_acc: 0.6562\n",
            "Epoch 987/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5650 - acc: 0.7435 - val_loss: 0.6114 - val_acc: 0.6667\n",
            "Epoch 988/2000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 0.5361 - acc: 0.7418 - val_loss: 0.5877 - val_acc: 0.6771\n",
            "Epoch 989/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5022 - acc: 0.7467 - val_loss: 0.5884 - val_acc: 0.6771\n",
            "Epoch 990/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5564 - acc: 0.7124 - val_loss: 0.5879 - val_acc: 0.6875\n",
            "Epoch 991/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.4952 - acc: 0.7647 - val_loss: 0.6111 - val_acc: 0.6771\n",
            "Epoch 992/2000\n",
            "39/39 [==============================] - 5s 101ms/step - loss: 0.4685 - acc: 0.7676 - val_loss: 0.5902 - val_acc: 0.6979\n",
            "Epoch 993/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.4907 - acc: 0.7516 - val_loss: 0.6256 - val_acc: 0.6771\n",
            "Epoch 994/2000\n",
            "39/39 [==============================] - 9s 208ms/step - loss: 0.5363 - acc: 0.7435 - val_loss: 0.5876 - val_acc: 0.6771\n",
            "Epoch 995/2000\n",
            "39/39 [==============================] - 9s 209ms/step - loss: 0.5335 - acc: 0.7467 - val_loss: 0.6141 - val_acc: 0.7083\n",
            "Epoch 996/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.5023 - acc: 0.7549 - val_loss: 0.5998 - val_acc: 0.6458\n",
            "Epoch 997/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.5171 - acc: 0.7271 - val_loss: 0.6261 - val_acc: 0.6667\n",
            "Epoch 998/2000\n",
            "39/39 [==============================] - 5s 117ms/step - loss: 0.4949 - acc: 0.7500 - val_loss: 0.5872 - val_acc: 0.6250\n",
            "Epoch 999/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.4983 - acc: 0.7663 - val_loss: 0.6254 - val_acc: 0.6979\n",
            "Epoch 1000/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5020 - acc: 0.7435 - val_loss: 0.5912 - val_acc: 0.6667\n",
            "Epoch 1001/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.4850 - acc: 0.7647 - val_loss: 0.5728 - val_acc: 0.6667\n",
            "Epoch 1002/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 0.5195 - acc: 0.7418 - val_loss: 0.5876 - val_acc: 0.6667\n",
            "Epoch 1003/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5013 - acc: 0.7614 - val_loss: 0.6283 - val_acc: 0.6667\n",
            "Epoch 1004/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5174 - acc: 0.7516 - val_loss: 0.6697 - val_acc: 0.6875\n",
            "Epoch 1005/2000\n",
            "39/39 [==============================] - 5s 113ms/step - loss: 0.5337 - acc: 0.7320 - val_loss: 0.6255 - val_acc: 0.7083\n",
            "Epoch 1006/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.5080 - acc: 0.7386 - val_loss: 0.5925 - val_acc: 0.6458\n",
            "Epoch 1007/2000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 0.5306 - acc: 0.7565 - val_loss: 0.5940 - val_acc: 0.6562\n",
            "Epoch 1008/2000\n",
            "39/39 [==============================] - 5s 120ms/step - loss: 0.5441 - acc: 0.7173 - val_loss: 0.6231 - val_acc: 0.6458\n",
            "Epoch 1009/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.4948 - acc: 0.7647 - val_loss: 0.6162 - val_acc: 0.6875\n",
            "Epoch 1010/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.5051 - acc: 0.7516 - val_loss: 0.5908 - val_acc: 0.6354\n",
            "Epoch 1011/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 0.5091 - acc: 0.7582 - val_loss: 0.6220 - val_acc: 0.6562\n",
            "Epoch 1012/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 0.5178 - acc: 0.7418 - val_loss: 0.6275 - val_acc: 0.6562\n",
            "Epoch 1013/2000\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.4979 - acc: 0.7892 - val_loss: 0.6002 - val_acc: 0.6771\n",
            "Epoch 1014/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.5186 - acc: 0.7484 - val_loss: 0.6230 - val_acc: 0.6667\n",
            "Epoch 1015/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.5073 - acc: 0.7451 - val_loss: 0.6125 - val_acc: 0.6667\n",
            "Epoch 1016/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.4987 - acc: 0.7582 - val_loss: 0.6036 - val_acc: 0.6354\n",
            "Epoch 1017/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.4920 - acc: 0.7533 - val_loss: 0.5952 - val_acc: 0.6875\n",
            "Epoch 1018/2000\n",
            "39/39 [==============================] - 10s 235ms/step - loss: 0.5180 - acc: 0.7614 - val_loss: 0.6017 - val_acc: 0.6667\n",
            "Epoch 1019/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.4831 - acc: 0.7712 - val_loss: 0.6025 - val_acc: 0.6667\n",
            "Epoch 1020/2000\n",
            "39/39 [==============================] - 10s 236ms/step - loss: 0.5076 - acc: 0.7369 - val_loss: 0.6516 - val_acc: 0.6771\n",
            "Epoch 1021/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.4599 - acc: 0.7859 - val_loss: 0.6251 - val_acc: 0.6875\n",
            "Epoch 1022/2000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 0.4836 - acc: 0.7843 - val_loss: 0.6179 - val_acc: 0.7083\n",
            "Epoch 1023/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5243 - acc: 0.7516 - val_loss: 0.6353 - val_acc: 0.6875\n",
            "Epoch 1024/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.4964 - acc: 0.7516 - val_loss: 0.6298 - val_acc: 0.6667\n",
            "Epoch 1025/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 0.4720 - acc: 0.7745 - val_loss: 0.6222 - val_acc: 0.6458\n",
            "Epoch 1026/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5259 - acc: 0.7549 - val_loss: 0.6558 - val_acc: 0.6458\n",
            "Epoch 1027/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.4979 - acc: 0.7647 - val_loss: 0.6376 - val_acc: 0.6667\n",
            "Epoch 1028/2000\n",
            "39/39 [==============================] - 5s 103ms/step - loss: 0.5330 - acc: 0.7288 - val_loss: 0.6260 - val_acc: 0.6458\n",
            "Epoch 1029/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.4818 - acc: 0.7596 - val_loss: 0.6113 - val_acc: 0.6458\n",
            "Epoch 1030/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.5076 - acc: 0.7631 - val_loss: 0.6009 - val_acc: 0.6354\n",
            "Epoch 1031/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.4868 - acc: 0.7582 - val_loss: 0.6100 - val_acc: 0.6458\n",
            "Epoch 1032/2000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 0.5420 - acc: 0.7320 - val_loss: 0.5867 - val_acc: 0.6667\n",
            "Epoch 1033/2000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.4971 - acc: 0.7288 - val_loss: 0.5938 - val_acc: 0.6458\n",
            "Epoch 1034/2000\n",
            "39/39 [==============================] - 5s 100ms/step - loss: 0.4953 - acc: 0.7516 - val_loss: 0.6242 - val_acc: 0.6875\n",
            "Epoch 1035/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5420 - acc: 0.7124 - val_loss: 0.5986 - val_acc: 0.6458\n",
            "Epoch 1036/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5239 - acc: 0.7222 - val_loss: 0.6107 - val_acc: 0.6562\n",
            "Epoch 1037/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5192 - acc: 0.7271 - val_loss: 0.6038 - val_acc: 0.6667\n",
            "Epoch 1038/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.4981 - acc: 0.7500 - val_loss: 0.5992 - val_acc: 0.6458\n",
            "Epoch 1039/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5132 - acc: 0.7435 - val_loss: 0.5996 - val_acc: 0.6458\n",
            "Epoch 1040/2000\n",
            "39/39 [==============================] - 9s 233ms/step - loss: 0.5136 - acc: 0.7404 - val_loss: 0.6131 - val_acc: 0.6771\n",
            "Epoch 1041/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5027 - acc: 0.7500 - val_loss: 0.6261 - val_acc: 0.6667\n",
            "Epoch 1042/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5125 - acc: 0.7516 - val_loss: 0.6025 - val_acc: 0.6354\n",
            "Epoch 1043/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5070 - acc: 0.7402 - val_loss: 0.6195 - val_acc: 0.6562\n",
            "Epoch 1044/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5104 - acc: 0.7712 - val_loss: 0.6021 - val_acc: 0.6771\n",
            "Epoch 1045/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.4861 - acc: 0.7761 - val_loss: 0.5915 - val_acc: 0.6771\n",
            "Epoch 1046/2000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 0.5241 - acc: 0.7533 - val_loss: 0.6105 - val_acc: 0.6667\n",
            "Epoch 1047/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5134 - acc: 0.7206 - val_loss: 0.6419 - val_acc: 0.6771\n",
            "Epoch 1048/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.5027 - acc: 0.7516 - val_loss: 0.6086 - val_acc: 0.6667\n",
            "Epoch 1049/2000\n",
            "39/39 [==============================] - 6s 136ms/step - loss: 0.5120 - acc: 0.7484 - val_loss: 0.6108 - val_acc: 0.6667\n",
            "Epoch 1050/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5097 - acc: 0.7533 - val_loss: 0.5976 - val_acc: 0.6771\n",
            "Epoch 1051/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.5075 - acc: 0.7549 - val_loss: 0.6196 - val_acc: 0.6354\n",
            "Epoch 1052/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 0.4807 - acc: 0.7712 - val_loss: 0.6369 - val_acc: 0.6667\n",
            "Epoch 1053/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.5290 - acc: 0.7451 - val_loss: 0.6416 - val_acc: 0.6667\n",
            "Epoch 1054/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5196 - acc: 0.7353 - val_loss: 0.6310 - val_acc: 0.6667\n",
            "Epoch 1055/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.4981 - acc: 0.7565 - val_loss: 0.6115 - val_acc: 0.6354\n",
            "Epoch 1056/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.5290 - acc: 0.7304 - val_loss: 0.6562 - val_acc: 0.6771\n",
            "Epoch 1057/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5407 - acc: 0.7418 - val_loss: 0.6165 - val_acc: 0.6771\n",
            "Epoch 1058/2000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 0.5342 - acc: 0.7206 - val_loss: 0.6184 - val_acc: 0.6458\n",
            "Epoch 1059/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5302 - acc: 0.7451 - val_loss: 0.6341 - val_acc: 0.6667\n",
            "Epoch 1060/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 0.4980 - acc: 0.7484 - val_loss: 0.6078 - val_acc: 0.6979\n",
            "Epoch 1061/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5166 - acc: 0.7386 - val_loss: 0.5939 - val_acc: 0.6771\n",
            "Epoch 1062/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.5300 - acc: 0.7173 - val_loss: 0.5891 - val_acc: 0.7083\n",
            "Epoch 1063/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5117 - acc: 0.7582 - val_loss: 0.6049 - val_acc: 0.6250\n",
            "Epoch 1064/2000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 0.5441 - acc: 0.7353 - val_loss: 0.5916 - val_acc: 0.6875\n",
            "Epoch 1065/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5053 - acc: 0.7565 - val_loss: 0.6056 - val_acc: 0.6458\n",
            "Epoch 1066/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.4758 - acc: 0.7876 - val_loss: 0.5654 - val_acc: 0.6979\n",
            "Epoch 1067/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 0.5189 - acc: 0.7598 - val_loss: 0.5896 - val_acc: 0.6354\n",
            "Epoch 1068/2000\n",
            "39/39 [==============================] - 6s 125ms/step - loss: 0.5026 - acc: 0.7402 - val_loss: 0.6065 - val_acc: 0.6458\n",
            "Epoch 1069/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.4937 - acc: 0.7631 - val_loss: 0.5887 - val_acc: 0.6458\n",
            "Epoch 1070/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5444 - acc: 0.7386 - val_loss: 0.5819 - val_acc: 0.6562\n",
            "Epoch 1071/2000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 0.5294 - acc: 0.7467 - val_loss: 0.6402 - val_acc: 0.6667\n",
            "Epoch 1072/2000\n",
            "39/39 [==============================] - 6s 133ms/step - loss: 0.5243 - acc: 0.7516 - val_loss: 0.6004 - val_acc: 0.6667\n",
            "Epoch 1073/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.4938 - acc: 0.7549 - val_loss: 0.6058 - val_acc: 0.6771\n",
            "Epoch 1074/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.5076 - acc: 0.7549 - val_loss: 0.5876 - val_acc: 0.6458\n",
            "Epoch 1075/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.5062 - acc: 0.7582 - val_loss: 0.5868 - val_acc: 0.6562\n",
            "Epoch 1076/2000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 0.4910 - acc: 0.7696 - val_loss: 0.5964 - val_acc: 0.6667\n",
            "Epoch 1077/2000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 0.5042 - acc: 0.7516 - val_loss: 0.6195 - val_acc: 0.6250\n",
            "Epoch 1078/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.4678 - acc: 0.7925 - val_loss: 0.5981 - val_acc: 0.6354\n",
            "Epoch 1079/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.4953 - acc: 0.7680 - val_loss: 0.6082 - val_acc: 0.6562\n",
            "Epoch 1080/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.4923 - acc: 0.7451 - val_loss: 0.6281 - val_acc: 0.6458\n",
            "Epoch 1081/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5204 - acc: 0.7353 - val_loss: 0.6280 - val_acc: 0.6458\n",
            "Epoch 1082/2000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 0.4892 - acc: 0.7533 - val_loss: 0.6369 - val_acc: 0.6562\n",
            "Epoch 1083/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5132 - acc: 0.7353 - val_loss: 0.5887 - val_acc: 0.6771\n",
            "Epoch 1084/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.4987 - acc: 0.7467 - val_loss: 0.5886 - val_acc: 0.6562\n",
            "Epoch 1085/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.4830 - acc: 0.7614 - val_loss: 0.6181 - val_acc: 0.6458\n",
            "Epoch 1086/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.4873 - acc: 0.7582 - val_loss: 0.5947 - val_acc: 0.6667\n",
            "Epoch 1087/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 0.5195 - acc: 0.7467 - val_loss: 0.6195 - val_acc: 0.6458\n",
            "Epoch 1088/2000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 0.5129 - acc: 0.7271 - val_loss: 0.6190 - val_acc: 0.6771\n",
            "Epoch 1089/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5260 - acc: 0.7337 - val_loss: 0.6056 - val_acc: 0.6458\n",
            "Epoch 1090/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.4868 - acc: 0.7565 - val_loss: 0.6088 - val_acc: 0.6875\n",
            "Epoch 1091/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5519 - acc: 0.7239 - val_loss: 0.6067 - val_acc: 0.6354\n",
            "Epoch 1092/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5019 - acc: 0.7598 - val_loss: 0.5949 - val_acc: 0.6771\n",
            "Epoch 1093/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.5125 - acc: 0.7533 - val_loss: 0.6128 - val_acc: 0.6875\n",
            "Epoch 1094/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 0.4990 - acc: 0.7549 - val_loss: 0.6180 - val_acc: 0.6771\n",
            "Epoch 1095/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5099 - acc: 0.7533 - val_loss: 0.6064 - val_acc: 0.6354\n",
            "Epoch 1096/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5498 - acc: 0.7435 - val_loss: 0.6120 - val_acc: 0.6562\n",
            "Epoch 1097/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.5675 - acc: 0.7141 - val_loss: 0.6074 - val_acc: 0.6458\n",
            "Epoch 1098/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.5016 - acc: 0.7467 - val_loss: 0.6077 - val_acc: 0.6875\n",
            "Epoch 1099/2000\n",
            "39/39 [==============================] - 5s 118ms/step - loss: 0.5377 - acc: 0.7206 - val_loss: 0.6349 - val_acc: 0.6667\n",
            "Epoch 1100/2000\n",
            "39/39 [==============================] - 5s 99ms/step - loss: 0.5359 - acc: 0.7467 - val_loss: 0.6241 - val_acc: 0.6562\n",
            "Epoch 1101/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5095 - acc: 0.7418 - val_loss: 0.6076 - val_acc: 0.6250\n",
            "Epoch 1102/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.4919 - acc: 0.7484 - val_loss: 0.6099 - val_acc: 0.6250\n",
            "Epoch 1103/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.4938 - acc: 0.7500 - val_loss: 0.6187 - val_acc: 0.6458\n",
            "Epoch 1104/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5200 - acc: 0.7451 - val_loss: 0.6435 - val_acc: 0.6458\n",
            "Epoch 1105/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5099 - acc: 0.7533 - val_loss: 0.6170 - val_acc: 0.6667\n",
            "Epoch 1106/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.4992 - acc: 0.7598 - val_loss: 0.5898 - val_acc: 0.6667\n",
            "Epoch 1107/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5146 - acc: 0.7369 - val_loss: 0.6177 - val_acc: 0.6250\n",
            "Epoch 1108/2000\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 0.5178 - acc: 0.7288 - val_loss: 0.6367 - val_acc: 0.6875\n",
            "Epoch 1109/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5618 - acc: 0.7386 - val_loss: 0.6194 - val_acc: 0.6562\n",
            "Epoch 1110/2000\n",
            "39/39 [==============================] - 5s 122ms/step - loss: 0.5008 - acc: 0.7435 - val_loss: 0.6134 - val_acc: 0.6979\n",
            "Epoch 1111/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.5181 - acc: 0.7582 - val_loss: 0.6053 - val_acc: 0.6875\n",
            "Epoch 1112/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5344 - acc: 0.7337 - val_loss: 0.6159 - val_acc: 0.6979\n",
            "Epoch 1113/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.5083 - acc: 0.7451 - val_loss: 0.6330 - val_acc: 0.6562\n",
            "Epoch 1114/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.5125 - acc: 0.7353 - val_loss: 0.6013 - val_acc: 0.6562\n",
            "Epoch 1115/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5315 - acc: 0.7386 - val_loss: 0.5941 - val_acc: 0.6667\n",
            "Epoch 1116/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.4849 - acc: 0.7565 - val_loss: 0.6197 - val_acc: 0.6562\n",
            "Epoch 1117/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.4889 - acc: 0.7794 - val_loss: 0.6160 - val_acc: 0.6562\n",
            "Epoch 1118/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 0.4926 - acc: 0.7876 - val_loss: 0.6088 - val_acc: 0.6667\n",
            "Epoch 1119/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 0.4705 - acc: 0.7810 - val_loss: 0.5923 - val_acc: 0.6667\n",
            "Epoch 1120/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5158 - acc: 0.7516 - val_loss: 0.5957 - val_acc: 0.6667\n",
            "Epoch 1121/2000\n",
            "39/39 [==============================] - 6s 133ms/step - loss: 0.5410 - acc: 0.7320 - val_loss: 0.6115 - val_acc: 0.6458\n",
            "Epoch 1122/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 0.4740 - acc: 0.7729 - val_loss: 0.6155 - val_acc: 0.6458\n",
            "Epoch 1123/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.4974 - acc: 0.7680 - val_loss: 0.6454 - val_acc: 0.6562\n",
            "Epoch 1124/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.5152 - acc: 0.7598 - val_loss: 0.6113 - val_acc: 0.6771\n",
            "Epoch 1125/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.4900 - acc: 0.7712 - val_loss: 0.5999 - val_acc: 0.6875\n",
            "Epoch 1126/2000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 0.5349 - acc: 0.7386 - val_loss: 0.5901 - val_acc: 0.6667\n",
            "Epoch 1127/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 0.5065 - acc: 0.7598 - val_loss: 0.6020 - val_acc: 0.6562\n",
            "Epoch 1128/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5376 - acc: 0.7124 - val_loss: 0.5932 - val_acc: 0.6354\n",
            "Epoch 1129/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5223 - acc: 0.7402 - val_loss: 0.5964 - val_acc: 0.6562\n",
            "Epoch 1130/2000\n",
            "39/39 [==============================] - 5s 113ms/step - loss: 0.4955 - acc: 0.7680 - val_loss: 0.6115 - val_acc: 0.6458\n",
            "Epoch 1131/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.5176 - acc: 0.7467 - val_loss: 0.6045 - val_acc: 0.6667\n",
            "Epoch 1132/2000\n",
            "39/39 [==============================] - 9s 235ms/step - loss: 0.5236 - acc: 0.7369 - val_loss: 0.6113 - val_acc: 0.6250\n",
            "Epoch 1133/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.5327 - acc: 0.7533 - val_loss: 0.6211 - val_acc: 0.6771\n",
            "Epoch 1134/2000\n",
            "39/39 [==============================] - 10s 226ms/step - loss: 0.5094 - acc: 0.7435 - val_loss: 0.6087 - val_acc: 0.6771\n",
            "Epoch 1135/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 0.5209 - acc: 0.7271 - val_loss: 0.5932 - val_acc: 0.6458\n",
            "Epoch 1136/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5290 - acc: 0.7418 - val_loss: 0.5897 - val_acc: 0.6875\n",
            "Epoch 1137/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.5365 - acc: 0.7304 - val_loss: 0.6117 - val_acc: 0.6667\n",
            "Epoch 1138/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.4778 - acc: 0.7614 - val_loss: 0.6043 - val_acc: 0.6667\n",
            "Epoch 1139/2000\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.4859 - acc: 0.7778 - val_loss: 0.6162 - val_acc: 0.6771\n",
            "Epoch 1140/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.5015 - acc: 0.7549 - val_loss: 0.5998 - val_acc: 0.6771\n",
            "Epoch 1141/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.5394 - acc: 0.7353 - val_loss: 0.5970 - val_acc: 0.6667\n",
            "Epoch 1142/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.4827 - acc: 0.7647 - val_loss: 0.5933 - val_acc: 0.6667\n",
            "Epoch 1143/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.5204 - acc: 0.7435 - val_loss: 0.5799 - val_acc: 0.6667\n",
            "Epoch 1144/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.4839 - acc: 0.7941 - val_loss: 0.5851 - val_acc: 0.6562\n",
            "Epoch 1145/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.5199 - acc: 0.7500 - val_loss: 0.6010 - val_acc: 0.6875\n",
            "Epoch 1146/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.5105 - acc: 0.7435 - val_loss: 0.6032 - val_acc: 0.6354\n",
            "Epoch 1147/2000\n",
            "39/39 [==============================] - 10s 231ms/step - loss: 0.5505 - acc: 0.7157 - val_loss: 0.5949 - val_acc: 0.6562\n",
            "Epoch 1148/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 0.5566 - acc: 0.7059 - val_loss: 0.5896 - val_acc: 0.6562\n",
            "Epoch 1149/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5169 - acc: 0.7533 - val_loss: 0.5938 - val_acc: 0.6562\n",
            "Epoch 1150/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5136 - acc: 0.7549 - val_loss: 0.6041 - val_acc: 0.6458\n",
            "Epoch 1151/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5052 - acc: 0.7353 - val_loss: 0.5812 - val_acc: 0.6458\n",
            "Epoch 1152/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.4995 - acc: 0.7745 - val_loss: 0.5959 - val_acc: 0.6458\n",
            "Epoch 1153/2000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 0.4924 - acc: 0.7565 - val_loss: 0.6075 - val_acc: 0.6667\n",
            "Epoch 1154/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5463 - acc: 0.7402 - val_loss: 0.5846 - val_acc: 0.6667\n",
            "Epoch 1155/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.5611 - acc: 0.7320 - val_loss: 0.5806 - val_acc: 0.6562\n",
            "Epoch 1156/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5020 - acc: 0.7516 - val_loss: 0.5914 - val_acc: 0.6667\n",
            "Epoch 1157/2000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.5297 - acc: 0.7369 - val_loss: 0.6072 - val_acc: 0.6250\n",
            "Epoch 1158/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5273 - acc: 0.7222 - val_loss: 0.6141 - val_acc: 0.6771\n",
            "Epoch 1159/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.4805 - acc: 0.7631 - val_loss: 0.6042 - val_acc: 0.6875\n",
            "Epoch 1160/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.5391 - acc: 0.7337 - val_loss: 0.6054 - val_acc: 0.6667\n",
            "Epoch 1161/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.4924 - acc: 0.7582 - val_loss: 0.6104 - val_acc: 0.6875\n",
            "Epoch 1162/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.4846 - acc: 0.7663 - val_loss: 0.6005 - val_acc: 0.6562\n",
            "Epoch 1163/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5175 - acc: 0.7533 - val_loss: 0.6050 - val_acc: 0.6771\n",
            "Epoch 1164/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 0.5188 - acc: 0.7418 - val_loss: 0.5848 - val_acc: 0.6562\n",
            "Epoch 1165/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.4921 - acc: 0.7663 - val_loss: 0.5881 - val_acc: 0.6562\n",
            "Epoch 1166/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.4951 - acc: 0.7696 - val_loss: 0.5830 - val_acc: 0.6667\n",
            "Epoch 1167/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.5002 - acc: 0.7598 - val_loss: 0.5940 - val_acc: 0.6458\n",
            "Epoch 1168/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5588 - acc: 0.7222 - val_loss: 0.5829 - val_acc: 0.6562\n",
            "Epoch 1169/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5356 - acc: 0.7337 - val_loss: 0.6011 - val_acc: 0.6875\n",
            "Epoch 1170/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 0.4910 - acc: 0.7859 - val_loss: 0.6059 - val_acc: 0.6562\n",
            "Epoch 1171/2000\n",
            "39/39 [==============================] - 4s 104ms/step - loss: 0.4998 - acc: 0.7435 - val_loss: 0.6272 - val_acc: 0.6979\n",
            "Epoch 1172/2000\n",
            "39/39 [==============================] - 10s 237ms/step - loss: 0.4912 - acc: 0.7680 - val_loss: 0.6054 - val_acc: 0.6875\n",
            "Epoch 1173/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.4867 - acc: 0.7647 - val_loss: 0.5901 - val_acc: 0.6354\n",
            "Epoch 1174/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.4626 - acc: 0.7729 - val_loss: 0.5945 - val_acc: 0.6667\n",
            "Epoch 1175/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.4978 - acc: 0.7402 - val_loss: 0.6082 - val_acc: 0.6458\n",
            "Epoch 1176/2000\n",
            "39/39 [==============================] - 5s 119ms/step - loss: 0.5157 - acc: 0.7369 - val_loss: 0.6117 - val_acc: 0.6562\n",
            "Epoch 1177/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5013 - acc: 0.7435 - val_loss: 0.6173 - val_acc: 0.6667\n",
            "Epoch 1178/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5050 - acc: 0.7565 - val_loss: 0.6157 - val_acc: 0.6667\n",
            "Epoch 1179/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5082 - acc: 0.7516 - val_loss: 0.6220 - val_acc: 0.6771\n",
            "Epoch 1180/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5118 - acc: 0.7337 - val_loss: 0.6075 - val_acc: 0.6875\n",
            "Epoch 1181/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.4995 - acc: 0.7549 - val_loss: 0.5850 - val_acc: 0.6771\n",
            "Epoch 1182/2000\n",
            "39/39 [==============================] - 9s 231ms/step - loss: 0.5270 - acc: 0.7386 - val_loss: 0.6098 - val_acc: 0.6250\n",
            "Epoch 1183/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5212 - acc: 0.7631 - val_loss: 0.5987 - val_acc: 0.6458\n",
            "Epoch 1184/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.4966 - acc: 0.7500 - val_loss: 0.5837 - val_acc: 0.6875\n",
            "Epoch 1185/2000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 0.5017 - acc: 0.7663 - val_loss: 0.6278 - val_acc: 0.6771\n",
            "Epoch 1186/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.4987 - acc: 0.7353 - val_loss: 0.6153 - val_acc: 0.6771\n",
            "Epoch 1187/2000\n",
            "39/39 [==============================] - 9s 234ms/step - loss: 0.5347 - acc: 0.7304 - val_loss: 0.5887 - val_acc: 0.6875\n",
            "Epoch 1188/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5101 - acc: 0.7353 - val_loss: 0.6090 - val_acc: 0.6562\n",
            "Epoch 1189/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 0.5252 - acc: 0.7369 - val_loss: 0.6050 - val_acc: 0.6562\n",
            "Epoch 1190/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5417 - acc: 0.7451 - val_loss: 0.5752 - val_acc: 0.6250\n",
            "Epoch 1191/2000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 0.5087 - acc: 0.7500 - val_loss: 0.5895 - val_acc: 0.6562\n",
            "Epoch 1192/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5304 - acc: 0.7418 - val_loss: 0.5896 - val_acc: 0.6875\n",
            "Epoch 1193/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 0.4954 - acc: 0.7663 - val_loss: 0.6027 - val_acc: 0.6667\n",
            "Epoch 1194/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5027 - acc: 0.7598 - val_loss: 0.6044 - val_acc: 0.6979\n",
            "Epoch 1195/2000\n",
            "39/39 [==============================] - 5s 114ms/step - loss: 0.5056 - acc: 0.7598 - val_loss: 0.6306 - val_acc: 0.6667\n",
            "Epoch 1196/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.5308 - acc: 0.7369 - val_loss: 0.5965 - val_acc: 0.6146\n",
            "Epoch 1197/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5442 - acc: 0.7386 - val_loss: 0.5959 - val_acc: 0.6250\n",
            "Epoch 1198/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.5265 - acc: 0.7255 - val_loss: 0.5911 - val_acc: 0.6875\n",
            "Epoch 1199/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5338 - acc: 0.7500 - val_loss: 0.5706 - val_acc: 0.6458\n",
            "Epoch 1200/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.4959 - acc: 0.7533 - val_loss: 0.6017 - val_acc: 0.6250\n",
            "Epoch 1201/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.5075 - acc: 0.7516 - val_loss: 0.5905 - val_acc: 0.6979\n",
            "Epoch 1202/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5127 - acc: 0.7386 - val_loss: 0.5669 - val_acc: 0.6562\n",
            "Epoch 1203/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5084 - acc: 0.7467 - val_loss: 0.5929 - val_acc: 0.6250\n",
            "Epoch 1204/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5221 - acc: 0.7582 - val_loss: 0.6005 - val_acc: 0.6354\n",
            "Epoch 1205/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5172 - acc: 0.7402 - val_loss: 0.5886 - val_acc: 0.6667\n",
            "Epoch 1206/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5271 - acc: 0.7418 - val_loss: 0.6251 - val_acc: 0.6771\n",
            "Epoch 1207/2000\n",
            "39/39 [==============================] - 9s 235ms/step - loss: 0.5403 - acc: 0.7190 - val_loss: 0.6210 - val_acc: 0.6875\n",
            "Epoch 1208/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.4938 - acc: 0.7631 - val_loss: 0.6265 - val_acc: 0.6562\n",
            "Epoch 1209/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.4874 - acc: 0.7647 - val_loss: 0.6156 - val_acc: 0.6771\n",
            "Epoch 1210/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5058 - acc: 0.7369 - val_loss: 0.5968 - val_acc: 0.6562\n",
            "Epoch 1211/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.5221 - acc: 0.7436 - val_loss: 0.5957 - val_acc: 0.6562\n",
            "Epoch 1212/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5370 - acc: 0.7418 - val_loss: 0.6201 - val_acc: 0.6771\n",
            "Epoch 1213/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.5040 - acc: 0.7451 - val_loss: 0.5977 - val_acc: 0.6667\n",
            "Epoch 1214/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5014 - acc: 0.7533 - val_loss: 0.6070 - val_acc: 0.6667\n",
            "Epoch 1215/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 0.5202 - acc: 0.7516 - val_loss: 0.5867 - val_acc: 0.6562\n",
            "Epoch 1216/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5463 - acc: 0.7288 - val_loss: 0.5662 - val_acc: 0.6354\n",
            "Epoch 1217/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.4963 - acc: 0.7516 - val_loss: 0.5797 - val_acc: 0.6458\n",
            "Epoch 1218/2000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 0.4998 - acc: 0.7451 - val_loss: 0.5744 - val_acc: 0.6667\n",
            "Epoch 1219/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5419 - acc: 0.7402 - val_loss: 0.5958 - val_acc: 0.6667\n",
            "Epoch 1220/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5146 - acc: 0.7369 - val_loss: 0.6369 - val_acc: 0.6771\n",
            "Epoch 1221/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5336 - acc: 0.7418 - val_loss: 0.5889 - val_acc: 0.6458\n",
            "Epoch 1222/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 0.5007 - acc: 0.7500 - val_loss: 0.5774 - val_acc: 0.6979\n",
            "Epoch 1223/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5326 - acc: 0.7190 - val_loss: 0.5808 - val_acc: 0.6458\n",
            "Epoch 1224/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 0.5351 - acc: 0.7435 - val_loss: 0.5965 - val_acc: 0.6979\n",
            "Epoch 1225/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.5145 - acc: 0.7467 - val_loss: 0.5775 - val_acc: 0.6562\n",
            "Epoch 1226/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5201 - acc: 0.7369 - val_loss: 0.5738 - val_acc: 0.6562\n",
            "Epoch 1227/2000\n",
            "39/39 [==============================] - 10s 234ms/step - loss: 0.5040 - acc: 0.7565 - val_loss: 0.5828 - val_acc: 0.6979\n",
            "Epoch 1228/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.4697 - acc: 0.7745 - val_loss: 0.5882 - val_acc: 0.6667\n",
            "Epoch 1229/2000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 0.5087 - acc: 0.7304 - val_loss: 0.5828 - val_acc: 0.6771\n",
            "Epoch 1230/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5241 - acc: 0.7451 - val_loss: 0.6005 - val_acc: 0.6771\n",
            "Epoch 1231/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5070 - acc: 0.7451 - val_loss: 0.5983 - val_acc: 0.6458\n",
            "Epoch 1232/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.4862 - acc: 0.7810 - val_loss: 0.5896 - val_acc: 0.6667\n",
            "Epoch 1233/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.4996 - acc: 0.7582 - val_loss: 0.6307 - val_acc: 0.6771\n",
            "Epoch 1234/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.5264 - acc: 0.7435 - val_loss: 0.5987 - val_acc: 0.6667\n",
            "Epoch 1235/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5092 - acc: 0.7516 - val_loss: 0.5974 - val_acc: 0.6354\n",
            "Epoch 1236/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.4973 - acc: 0.7484 - val_loss: 0.6316 - val_acc: 0.6771\n",
            "Epoch 1237/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5116 - acc: 0.7369 - val_loss: 0.6064 - val_acc: 0.6771\n",
            "Epoch 1238/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.4700 - acc: 0.7794 - val_loss: 0.6230 - val_acc: 0.6667\n",
            "Epoch 1239/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5063 - acc: 0.7516 - val_loss: 0.6178 - val_acc: 0.6667\n",
            "Epoch 1240/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5050 - acc: 0.7533 - val_loss: 0.5946 - val_acc: 0.6667\n",
            "Epoch 1241/2000\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 0.4845 - acc: 0.7533 - val_loss: 0.5844 - val_acc: 0.7083\n",
            "Epoch 1242/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.5670 - acc: 0.7190 - val_loss: 0.6004 - val_acc: 0.6458\n",
            "Epoch 1243/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.4854 - acc: 0.7516 - val_loss: 0.6221 - val_acc: 0.6667\n",
            "Epoch 1244/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.5146 - acc: 0.7369 - val_loss: 0.5832 - val_acc: 0.6562\n",
            "Epoch 1245/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5162 - acc: 0.7369 - val_loss: 0.5911 - val_acc: 0.6875\n",
            "Epoch 1246/2000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 0.4810 - acc: 0.7647 - val_loss: 0.5786 - val_acc: 0.6875\n",
            "Epoch 1247/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 0.5416 - acc: 0.7435 - val_loss: 0.5752 - val_acc: 0.6458\n",
            "Epoch 1248/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.4823 - acc: 0.7696 - val_loss: 0.5988 - val_acc: 0.6979\n",
            "Epoch 1249/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5172 - acc: 0.7451 - val_loss: 0.5797 - val_acc: 0.6875\n",
            "Epoch 1250/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5229 - acc: 0.7337 - val_loss: 0.5933 - val_acc: 0.6771\n",
            "Epoch 1251/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5125 - acc: 0.7692 - val_loss: 0.6163 - val_acc: 0.6667\n",
            "Epoch 1252/2000\n",
            "39/39 [==============================] - 9s 233ms/step - loss: 0.4877 - acc: 0.7729 - val_loss: 0.5890 - val_acc: 0.6667\n",
            "Epoch 1253/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 0.4753 - acc: 0.7712 - val_loss: 0.5909 - val_acc: 0.6458\n",
            "Epoch 1254/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 0.5497 - acc: 0.7239 - val_loss: 0.5887 - val_acc: 0.6875\n",
            "Epoch 1255/2000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.5086 - acc: 0.7631 - val_loss: 0.5837 - val_acc: 0.6667\n",
            "Epoch 1256/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5004 - acc: 0.7761 - val_loss: 0.5609 - val_acc: 0.6771\n",
            "Epoch 1257/2000\n",
            "39/39 [==============================] - 9s 232ms/step - loss: 0.5396 - acc: 0.7500 - val_loss: 0.5720 - val_acc: 0.6979\n",
            "Epoch 1258/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5415 - acc: 0.7353 - val_loss: 0.6006 - val_acc: 0.6979\n",
            "Epoch 1259/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5330 - acc: 0.7206 - val_loss: 0.5773 - val_acc: 0.6562\n",
            "Epoch 1260/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.4945 - acc: 0.7533 - val_loss: 0.5999 - val_acc: 0.6562\n",
            "Epoch 1261/2000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 0.5236 - acc: 0.7484 - val_loss: 0.5982 - val_acc: 0.6875\n",
            "Epoch 1262/2000\n",
            "39/39 [==============================] - 9s 232ms/step - loss: 0.5240 - acc: 0.7582 - val_loss: 0.6146 - val_acc: 0.6562\n",
            "Epoch 1263/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.4855 - acc: 0.7745 - val_loss: 0.6069 - val_acc: 0.6979\n",
            "Epoch 1264/2000\n",
            "39/39 [==============================] - 10s 228ms/step - loss: 0.4879 - acc: 0.7582 - val_loss: 0.6002 - val_acc: 0.6562\n",
            "Epoch 1265/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5085 - acc: 0.7516 - val_loss: 0.6022 - val_acc: 0.6562\n",
            "Epoch 1266/2000\n",
            "39/39 [==============================] - 10s 230ms/step - loss: 0.5247 - acc: 0.7288 - val_loss: 0.5957 - val_acc: 0.6979\n",
            "Epoch 1267/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5403 - acc: 0.7369 - val_loss: 0.5930 - val_acc: 0.6771\n",
            "Epoch 1268/2000\n",
            "39/39 [==============================] - 10s 226ms/step - loss: 0.4948 - acc: 0.7533 - val_loss: 0.6033 - val_acc: 0.6771\n",
            "Epoch 1269/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.4907 - acc: 0.7680 - val_loss: 0.6511 - val_acc: 0.6771\n",
            "Epoch 1270/2000\n",
            "39/39 [==============================] - 5s 95ms/step - loss: 0.5161 - acc: 0.7320 - val_loss: 0.6314 - val_acc: 0.6667\n",
            "Epoch 1271/2000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.5056 - acc: 0.7516 - val_loss: 0.6105 - val_acc: 0.6875\n",
            "Epoch 1272/2000\n",
            "39/39 [==============================] - 10s 235ms/step - loss: 0.5314 - acc: 0.7124 - val_loss: 0.6194 - val_acc: 0.6458\n",
            "Epoch 1273/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5477 - acc: 0.7288 - val_loss: 0.6055 - val_acc: 0.6875\n",
            "Epoch 1274/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.5211 - acc: 0.7549 - val_loss: 0.6064 - val_acc: 0.6667\n",
            "Epoch 1275/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5054 - acc: 0.7467 - val_loss: 0.5886 - val_acc: 0.6562\n",
            "Epoch 1276/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5180 - acc: 0.7696 - val_loss: 0.5929 - val_acc: 0.6458\n",
            "Epoch 1277/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5065 - acc: 0.7500 - val_loss: 0.5938 - val_acc: 0.6562\n",
            "Epoch 1278/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.5105 - acc: 0.7467 - val_loss: 0.6146 - val_acc: 0.6458\n",
            "Epoch 1279/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.4838 - acc: 0.7712 - val_loss: 0.5975 - val_acc: 0.6771\n",
            "Epoch 1280/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5216 - acc: 0.7647 - val_loss: 0.6091 - val_acc: 0.6771\n",
            "Epoch 1281/2000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 0.5154 - acc: 0.7369 - val_loss: 0.5848 - val_acc: 0.6458\n",
            "Epoch 1282/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.4966 - acc: 0.7680 - val_loss: 0.6266 - val_acc: 0.6667\n",
            "Epoch 1283/2000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 0.4883 - acc: 0.7712 - val_loss: 0.5916 - val_acc: 0.6562\n",
            "Epoch 1284/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.5124 - acc: 0.7533 - val_loss: 0.5776 - val_acc: 0.6562\n",
            "Epoch 1285/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5119 - acc: 0.7484 - val_loss: 0.6274 - val_acc: 0.6667\n",
            "Epoch 1286/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5128 - acc: 0.7353 - val_loss: 0.6093 - val_acc: 0.6771\n",
            "Epoch 1287/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5024 - acc: 0.7451 - val_loss: 0.6242 - val_acc: 0.6875\n",
            "Epoch 1288/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5365 - acc: 0.7402 - val_loss: 0.6060 - val_acc: 0.6458\n",
            "Epoch 1289/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5447 - acc: 0.7353 - val_loss: 0.6320 - val_acc: 0.6667\n",
            "Epoch 1290/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5115 - acc: 0.7729 - val_loss: 0.5936 - val_acc: 0.6458\n",
            "Epoch 1291/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5011 - acc: 0.7598 - val_loss: 0.5900 - val_acc: 0.6771\n",
            "Epoch 1292/2000\n",
            "39/39 [==============================] - 9s 232ms/step - loss: 0.5414 - acc: 0.7696 - val_loss: 0.5869 - val_acc: 0.6458\n",
            "Epoch 1293/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.4675 - acc: 0.7647 - val_loss: 0.5988 - val_acc: 0.6979\n",
            "Epoch 1294/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.4963 - acc: 0.7631 - val_loss: 0.6429 - val_acc: 0.6667\n",
            "Epoch 1295/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.4882 - acc: 0.7631 - val_loss: 0.6020 - val_acc: 0.6458\n",
            "Epoch 1296/2000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 0.5024 - acc: 0.7614 - val_loss: 0.5931 - val_acc: 0.7083\n",
            "Epoch 1297/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.5298 - acc: 0.7533 - val_loss: 0.6040 - val_acc: 0.6771\n",
            "Epoch 1298/2000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.4960 - acc: 0.7582 - val_loss: 0.5760 - val_acc: 0.6667\n",
            "Epoch 1299/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.4908 - acc: 0.7663 - val_loss: 0.5878 - val_acc: 0.6771\n",
            "Epoch 1300/2000\n",
            "39/39 [==============================] - 5s 96ms/step - loss: 0.4883 - acc: 0.7696 - val_loss: 0.5881 - val_acc: 0.6458\n",
            "Epoch 1301/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5164 - acc: 0.7239 - val_loss: 0.5890 - val_acc: 0.6979\n",
            "Epoch 1302/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 0.5160 - acc: 0.7386 - val_loss: 0.6096 - val_acc: 0.6771\n",
            "Epoch 1303/2000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.5069 - acc: 0.7353 - val_loss: 0.5822 - val_acc: 0.6562\n",
            "Epoch 1304/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5149 - acc: 0.7467 - val_loss: 0.5907 - val_acc: 0.6458\n",
            "Epoch 1305/2000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 0.5349 - acc: 0.7614 - val_loss: 0.5869 - val_acc: 0.6875\n",
            "Epoch 1306/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.5016 - acc: 0.7369 - val_loss: 0.6053 - val_acc: 0.6458\n",
            "Epoch 1307/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.4872 - acc: 0.7533 - val_loss: 0.6021 - val_acc: 0.6354\n",
            "Epoch 1308/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.4898 - acc: 0.7696 - val_loss: 0.5819 - val_acc: 0.6667\n",
            "Epoch 1309/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.5297 - acc: 0.7337 - val_loss: 0.5836 - val_acc: 0.6458\n",
            "Epoch 1310/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5188 - acc: 0.7467 - val_loss: 0.6191 - val_acc: 0.6667\n",
            "Epoch 1311/2000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.5454 - acc: 0.7304 - val_loss: 0.5912 - val_acc: 0.6458\n",
            "Epoch 1312/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5505 - acc: 0.7288 - val_loss: 0.6099 - val_acc: 0.6771\n",
            "Epoch 1313/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5243 - acc: 0.7402 - val_loss: 0.5929 - val_acc: 0.6771\n",
            "Epoch 1314/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.4868 - acc: 0.7663 - val_loss: 0.5852 - val_acc: 0.6562\n",
            "Epoch 1315/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5212 - acc: 0.7533 - val_loss: 0.5899 - val_acc: 0.6562\n",
            "Epoch 1316/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 0.5215 - acc: 0.7304 - val_loss: 0.5894 - val_acc: 0.6771\n",
            "Epoch 1317/2000\n",
            "39/39 [==============================] - 10s 235ms/step - loss: 0.5273 - acc: 0.7435 - val_loss: 0.5885 - val_acc: 0.6979\n",
            "Epoch 1318/2000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.5366 - acc: 0.7372 - val_loss: 0.5835 - val_acc: 0.7083\n",
            "Epoch 1319/2000\n",
            "39/39 [==============================] - 9s 232ms/step - loss: 0.5205 - acc: 0.7729 - val_loss: 0.5997 - val_acc: 0.6875\n",
            "Epoch 1320/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5122 - acc: 0.7435 - val_loss: 0.5886 - val_acc: 0.6562\n",
            "Epoch 1321/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5236 - acc: 0.7516 - val_loss: 0.5968 - val_acc: 0.6562\n",
            "Epoch 1322/2000\n",
            "39/39 [==============================] - 9s 231ms/step - loss: 0.5480 - acc: 0.7369 - val_loss: 0.5915 - val_acc: 0.6458\n",
            "Epoch 1323/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5369 - acc: 0.7288 - val_loss: 0.6256 - val_acc: 0.6667\n",
            "Epoch 1324/2000\n",
            "39/39 [==============================] - 10s 235ms/step - loss: 0.5102 - acc: 0.7484 - val_loss: 0.5744 - val_acc: 0.6667\n",
            "Epoch 1325/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5355 - acc: 0.7386 - val_loss: 0.6356 - val_acc: 0.6771\n",
            "Epoch 1326/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 0.4751 - acc: 0.7663 - val_loss: 0.6071 - val_acc: 0.6771\n",
            "Epoch 1327/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5238 - acc: 0.7435 - val_loss: 0.5981 - val_acc: 0.6458\n",
            "Epoch 1328/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5179 - acc: 0.7369 - val_loss: 0.6002 - val_acc: 0.6979\n",
            "Epoch 1329/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 0.5290 - acc: 0.7451 - val_loss: 0.5849 - val_acc: 0.6562\n",
            "Epoch 1330/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 0.4878 - acc: 0.7614 - val_loss: 0.5974 - val_acc: 0.6354\n",
            "Epoch 1331/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5160 - acc: 0.7533 - val_loss: 0.6085 - val_acc: 0.6562\n",
            "Epoch 1332/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5435 - acc: 0.7304 - val_loss: 0.6370 - val_acc: 0.6667\n",
            "Epoch 1333/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.4866 - acc: 0.7663 - val_loss: 0.5902 - val_acc: 0.6771\n",
            "Epoch 1334/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.4787 - acc: 0.7533 - val_loss: 0.6113 - val_acc: 0.6562\n",
            "Epoch 1335/2000\n",
            "39/39 [==============================] - 10s 234ms/step - loss: 0.4799 - acc: 0.7533 - val_loss: 0.6205 - val_acc: 0.6771\n",
            "Epoch 1336/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.5305 - acc: 0.7418 - val_loss: 0.6054 - val_acc: 0.6771\n",
            "Epoch 1337/2000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 0.5288 - acc: 0.7467 - val_loss: 0.6178 - val_acc: 0.6667\n",
            "Epoch 1338/2000\n",
            "39/39 [==============================] - 10s 242ms/step - loss: 0.5325 - acc: 0.7239 - val_loss: 0.6179 - val_acc: 0.6667\n",
            "Epoch 1339/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5270 - acc: 0.7549 - val_loss: 0.5947 - val_acc: 0.6875\n",
            "Epoch 1340/2000\n",
            "39/39 [==============================] - 9s 234ms/step - loss: 0.5371 - acc: 0.7451 - val_loss: 0.5960 - val_acc: 0.6458\n",
            "Epoch 1341/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5141 - acc: 0.7548 - val_loss: 0.5909 - val_acc: 0.6562\n",
            "Epoch 1342/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5370 - acc: 0.7271 - val_loss: 0.5992 - val_acc: 0.6979\n",
            "Epoch 1343/2000\n",
            "39/39 [==============================] - 10s 236ms/step - loss: 0.4990 - acc: 0.7614 - val_loss: 0.6088 - val_acc: 0.6771\n",
            "Epoch 1344/2000\n",
            "39/39 [==============================] - 5s 128ms/step - loss: 0.4811 - acc: 0.7582 - val_loss: 0.6246 - val_acc: 0.6771\n",
            "Epoch 1345/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5120 - acc: 0.7222 - val_loss: 0.6041 - val_acc: 0.6979\n",
            "Epoch 1346/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 0.5268 - acc: 0.7680 - val_loss: 0.6219 - val_acc: 0.6667\n",
            "Epoch 1347/2000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.5390 - acc: 0.7304 - val_loss: 0.6177 - val_acc: 0.6562\n",
            "Epoch 1348/2000\n",
            "39/39 [==============================] - 10s 240ms/step - loss: 0.5300 - acc: 0.7614 - val_loss: 0.6126 - val_acc: 0.6354\n",
            "Epoch 1349/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.4739 - acc: 0.7614 - val_loss: 0.6174 - val_acc: 0.6354\n",
            "Epoch 1350/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5157 - acc: 0.7614 - val_loss: 0.5999 - val_acc: 0.6875\n",
            "Epoch 1351/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5239 - acc: 0.7436 - val_loss: 0.5909 - val_acc: 0.6458\n",
            "Epoch 1352/2000\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.5363 - acc: 0.7418 - val_loss: 0.6470 - val_acc: 0.6667\n",
            "Epoch 1353/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 0.5456 - acc: 0.7467 - val_loss: 0.5964 - val_acc: 0.6875\n",
            "Epoch 1354/2000\n",
            "39/39 [==============================] - 5s 99ms/step - loss: 0.5033 - acc: 0.7484 - val_loss: 0.6259 - val_acc: 0.6458\n",
            "Epoch 1355/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5053 - acc: 0.7631 - val_loss: 0.5831 - val_acc: 0.6875\n",
            "Epoch 1356/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5045 - acc: 0.7663 - val_loss: 0.6024 - val_acc: 0.6458\n",
            "Epoch 1357/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.4917 - acc: 0.7647 - val_loss: 0.5989 - val_acc: 0.6458\n",
            "Epoch 1358/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 0.4898 - acc: 0.7614 - val_loss: 0.6010 - val_acc: 0.6875\n",
            "Epoch 1359/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 0.5041 - acc: 0.7582 - val_loss: 0.5982 - val_acc: 0.6458\n",
            "Epoch 1360/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 0.5114 - acc: 0.7500 - val_loss: 0.6161 - val_acc: 0.6875\n",
            "Epoch 1361/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.4792 - acc: 0.7680 - val_loss: 0.6314 - val_acc: 0.6875\n",
            "Epoch 1362/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5129 - acc: 0.7386 - val_loss: 0.6244 - val_acc: 0.6875\n",
            "Epoch 1363/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5562 - acc: 0.7190 - val_loss: 0.6110 - val_acc: 0.6250\n",
            "Epoch 1364/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.5038 - acc: 0.7647 - val_loss: 0.6179 - val_acc: 0.6667\n",
            "Epoch 1365/2000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 0.4833 - acc: 0.7680 - val_loss: 0.6213 - val_acc: 0.6354\n",
            "Epoch 1366/2000\n",
            "39/39 [==============================] - 10s 232ms/step - loss: 0.5100 - acc: 0.7516 - val_loss: 0.6392 - val_acc: 0.6771\n",
            "Epoch 1367/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5054 - acc: 0.7255 - val_loss: 0.6148 - val_acc: 0.6875\n",
            "Epoch 1368/2000\n",
            "39/39 [==============================] - 5s 97ms/step - loss: 0.5187 - acc: 0.7549 - val_loss: 0.6020 - val_acc: 0.6771\n",
            "Epoch 1369/2000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 0.5128 - acc: 0.7337 - val_loss: 0.6444 - val_acc: 0.6771\n",
            "Epoch 1370/2000\n",
            "39/39 [==============================] - 9s 234ms/step - loss: 0.4795 - acc: 0.7598 - val_loss: 0.6212 - val_acc: 0.6562\n",
            "Epoch 1371/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.4761 - acc: 0.7745 - val_loss: 0.5926 - val_acc: 0.6771\n",
            "Epoch 1372/2000\n",
            "39/39 [==============================] - 5s 112ms/step - loss: 0.4865 - acc: 0.7467 - val_loss: 0.5834 - val_acc: 0.6562\n",
            "Epoch 1373/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.4912 - acc: 0.7614 - val_loss: 0.6097 - val_acc: 0.6562\n",
            "Epoch 1374/2000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 0.5321 - acc: 0.7582 - val_loss: 0.5866 - val_acc: 0.6979\n",
            "Epoch 1375/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5134 - acc: 0.7369 - val_loss: 0.6243 - val_acc: 0.6875\n",
            "Epoch 1376/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5101 - acc: 0.7271 - val_loss: 0.5904 - val_acc: 0.6458\n",
            "Epoch 1377/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5199 - acc: 0.7337 - val_loss: 0.5986 - val_acc: 0.6562\n",
            "Epoch 1378/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.4954 - acc: 0.7712 - val_loss: 0.6258 - val_acc: 0.6771\n",
            "Epoch 1379/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.4868 - acc: 0.7696 - val_loss: 0.6034 - val_acc: 0.6562\n",
            "Epoch 1380/2000\n",
            "39/39 [==============================] - 5s 128ms/step - loss: 0.4976 - acc: 0.7516 - val_loss: 0.6168 - val_acc: 0.6771\n",
            "Epoch 1381/2000\n",
            "39/39 [==============================] - 9s 233ms/step - loss: 0.5615 - acc: 0.7222 - val_loss: 0.6168 - val_acc: 0.6771\n",
            "Epoch 1382/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.4832 - acc: 0.7761 - val_loss: 0.5931 - val_acc: 0.6667\n",
            "Epoch 1383/2000\n",
            "39/39 [==============================] - 10s 235ms/step - loss: 0.4951 - acc: 0.7631 - val_loss: 0.6153 - val_acc: 0.6562\n",
            "Epoch 1384/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5070 - acc: 0.7565 - val_loss: 0.6138 - val_acc: 0.6875\n",
            "Epoch 1385/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.5170 - acc: 0.7533 - val_loss: 0.5943 - val_acc: 0.6667\n",
            "Epoch 1386/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5028 - acc: 0.7876 - val_loss: 0.6222 - val_acc: 0.6771\n",
            "Epoch 1387/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 0.5386 - acc: 0.7337 - val_loss: 0.6083 - val_acc: 0.6875\n",
            "Epoch 1388/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.4976 - acc: 0.7549 - val_loss: 0.5904 - val_acc: 0.6771\n",
            "Epoch 1389/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5024 - acc: 0.7614 - val_loss: 0.6078 - val_acc: 0.6771\n",
            "Epoch 1390/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.4943 - acc: 0.7435 - val_loss: 0.6027 - val_acc: 0.6667\n",
            "Epoch 1391/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.4951 - acc: 0.7680 - val_loss: 0.6066 - val_acc: 0.6771\n",
            "Epoch 1392/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.5069 - acc: 0.7402 - val_loss: 0.5986 - val_acc: 0.6667\n",
            "Epoch 1393/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5541 - acc: 0.7320 - val_loss: 0.6021 - val_acc: 0.6875\n",
            "Epoch 1394/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5073 - acc: 0.7516 - val_loss: 0.5887 - val_acc: 0.6875\n",
            "Epoch 1395/2000\n",
            "39/39 [==============================] - 9s 232ms/step - loss: 0.4930 - acc: 0.7614 - val_loss: 0.6058 - val_acc: 0.6875\n",
            "Epoch 1396/2000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 0.5359 - acc: 0.7402 - val_loss: 0.6137 - val_acc: 0.6667\n",
            "Epoch 1397/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.4998 - acc: 0.7500 - val_loss: 0.6198 - val_acc: 0.6562\n",
            "Epoch 1398/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.4899 - acc: 0.7582 - val_loss: 0.5843 - val_acc: 0.6771\n",
            "Epoch 1399/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.4795 - acc: 0.7598 - val_loss: 0.5921 - val_acc: 0.6354\n",
            "Epoch 1400/2000\n",
            "39/39 [==============================] - 5s 113ms/step - loss: 0.4925 - acc: 0.7647 - val_loss: 0.6053 - val_acc: 0.6771\n",
            "Epoch 1401/2000\n",
            "39/39 [==============================] - 4s 104ms/step - loss: 0.4928 - acc: 0.7549 - val_loss: 0.5773 - val_acc: 0.6562\n",
            "Epoch 1402/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5099 - acc: 0.7386 - val_loss: 0.6149 - val_acc: 0.6458\n",
            "Epoch 1403/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 0.5346 - acc: 0.7533 - val_loss: 0.5956 - val_acc: 0.6667\n",
            "Epoch 1404/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5098 - acc: 0.7533 - val_loss: 0.6136 - val_acc: 0.6562\n",
            "Epoch 1405/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5025 - acc: 0.7435 - val_loss: 0.6086 - val_acc: 0.6458\n",
            "Epoch 1406/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5084 - acc: 0.7598 - val_loss: 0.5873 - val_acc: 0.6771\n",
            "Epoch 1407/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5038 - acc: 0.7631 - val_loss: 0.6246 - val_acc: 0.6771\n",
            "Epoch 1408/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.4902 - acc: 0.7745 - val_loss: 0.5941 - val_acc: 0.6562\n",
            "Epoch 1409/2000\n",
            "39/39 [==============================] - 9s 236ms/step - loss: 0.5147 - acc: 0.7647 - val_loss: 0.5766 - val_acc: 0.6771\n",
            "Epoch 1410/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5076 - acc: 0.7565 - val_loss: 0.5921 - val_acc: 0.7083\n",
            "Epoch 1411/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5121 - acc: 0.7614 - val_loss: 0.6043 - val_acc: 0.6458\n",
            "Epoch 1412/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5264 - acc: 0.7353 - val_loss: 0.5915 - val_acc: 0.6875\n",
            "Epoch 1413/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.5129 - acc: 0.7337 - val_loss: 0.5829 - val_acc: 0.6458\n",
            "Epoch 1414/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.5276 - acc: 0.7320 - val_loss: 0.5864 - val_acc: 0.6667\n",
            "Epoch 1415/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.4819 - acc: 0.7712 - val_loss: 0.5791 - val_acc: 0.6458\n",
            "Epoch 1416/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.4954 - acc: 0.7451 - val_loss: 0.5803 - val_acc: 0.6667\n",
            "Epoch 1417/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 0.5396 - acc: 0.7288 - val_loss: 0.5973 - val_acc: 0.6771\n",
            "Epoch 1418/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.4974 - acc: 0.7761 - val_loss: 0.5802 - val_acc: 0.6667\n",
            "Epoch 1419/2000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 0.5157 - acc: 0.7451 - val_loss: 0.5763 - val_acc: 0.6354\n",
            "Epoch 1420/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5085 - acc: 0.7337 - val_loss: 0.5801 - val_acc: 0.6458\n",
            "Epoch 1421/2000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 0.5204 - acc: 0.7614 - val_loss: 0.5611 - val_acc: 0.6875\n",
            "Epoch 1422/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.4831 - acc: 0.7467 - val_loss: 0.6128 - val_acc: 0.6771\n",
            "Epoch 1423/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5172 - acc: 0.7484 - val_loss: 0.5883 - val_acc: 0.6667\n",
            "Epoch 1424/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5426 - acc: 0.7075 - val_loss: 0.5980 - val_acc: 0.6875\n",
            "Epoch 1425/2000\n",
            "39/39 [==============================] - 4s 105ms/step - loss: 0.5140 - acc: 0.7631 - val_loss: 0.5760 - val_acc: 0.6771\n",
            "Epoch 1426/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.4913 - acc: 0.7631 - val_loss: 0.5806 - val_acc: 0.6771\n",
            "Epoch 1427/2000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 0.5275 - acc: 0.7255 - val_loss: 0.5861 - val_acc: 0.6771\n",
            "Epoch 1428/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5071 - acc: 0.7304 - val_loss: 0.5692 - val_acc: 0.6979\n",
            "Epoch 1429/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5141 - acc: 0.7271 - val_loss: 0.5828 - val_acc: 0.6667\n",
            "Epoch 1430/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 0.5430 - acc: 0.7549 - val_loss: 0.5938 - val_acc: 0.6771\n",
            "Epoch 1431/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.5029 - acc: 0.7598 - val_loss: 0.5848 - val_acc: 0.6979\n",
            "Epoch 1432/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 0.5062 - acc: 0.7549 - val_loss: 0.6100 - val_acc: 0.6667\n",
            "Epoch 1433/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.4919 - acc: 0.7386 - val_loss: 0.5753 - val_acc: 0.6667\n",
            "Epoch 1434/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.5237 - acc: 0.7778 - val_loss: 0.5909 - val_acc: 0.6458\n",
            "Epoch 1435/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 0.5031 - acc: 0.7614 - val_loss: 0.5877 - val_acc: 0.6354\n",
            "Epoch 1436/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5434 - acc: 0.7271 - val_loss: 0.5792 - val_acc: 0.6562\n",
            "Epoch 1437/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5526 - acc: 0.7369 - val_loss: 0.6033 - val_acc: 0.6771\n",
            "Epoch 1438/2000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 0.4981 - acc: 0.7614 - val_loss: 0.6074 - val_acc: 0.6562\n",
            "Epoch 1439/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.5277 - acc: 0.7614 - val_loss: 0.5767 - val_acc: 0.6458\n",
            "Epoch 1440/2000\n",
            "39/39 [==============================] - 5s 98ms/step - loss: 0.5093 - acc: 0.7582 - val_loss: 0.5957 - val_acc: 0.6979\n",
            "Epoch 1441/2000\n",
            "39/39 [==============================] - 5s 122ms/step - loss: 0.4992 - acc: 0.7549 - val_loss: 0.5999 - val_acc: 0.6667\n",
            "Epoch 1442/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5217 - acc: 0.7582 - val_loss: 0.5766 - val_acc: 0.6562\n",
            "Epoch 1443/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5333 - acc: 0.7386 - val_loss: 0.6046 - val_acc: 0.6771\n",
            "Epoch 1444/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.4987 - acc: 0.7451 - val_loss: 0.5875 - val_acc: 0.6771\n",
            "Epoch 1445/2000\n",
            "39/39 [==============================] - 5s 112ms/step - loss: 0.4976 - acc: 0.7484 - val_loss: 0.6025 - val_acc: 0.6562\n",
            "Epoch 1446/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.4659 - acc: 0.7794 - val_loss: 0.5970 - val_acc: 0.6979\n",
            "Epoch 1447/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5049 - acc: 0.7320 - val_loss: 0.6174 - val_acc: 0.6875\n",
            "Epoch 1448/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.4785 - acc: 0.7692 - val_loss: 0.5843 - val_acc: 0.6979\n",
            "Epoch 1449/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.4775 - acc: 0.7614 - val_loss: 0.5950 - val_acc: 0.6562\n",
            "Epoch 1450/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.4682 - acc: 0.7696 - val_loss: 0.5951 - val_acc: 0.6562\n",
            "Epoch 1451/2000\n",
            "39/39 [==============================] - 9s 231ms/step - loss: 0.4855 - acc: 0.7680 - val_loss: 0.5993 - val_acc: 0.6771\n",
            "Epoch 1452/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.5167 - acc: 0.7288 - val_loss: 0.6134 - val_acc: 0.6771\n",
            "Epoch 1453/2000\n",
            "39/39 [==============================] - 5s 114ms/step - loss: 0.4818 - acc: 0.7582 - val_loss: 0.5867 - val_acc: 0.6562\n",
            "Epoch 1454/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5350 - acc: 0.7304 - val_loss: 0.5635 - val_acc: 0.6458\n",
            "Epoch 1455/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.5082 - acc: 0.7647 - val_loss: 0.6050 - val_acc: 0.6354\n",
            "Epoch 1456/2000\n",
            "39/39 [==============================] - 9s 232ms/step - loss: 0.4971 - acc: 0.7484 - val_loss: 0.5986 - val_acc: 0.6562\n",
            "Epoch 1457/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5532 - acc: 0.7271 - val_loss: 0.5983 - val_acc: 0.6979\n",
            "Epoch 1458/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5129 - acc: 0.7337 - val_loss: 0.6300 - val_acc: 0.6458\n",
            "Epoch 1459/2000\n",
            "39/39 [==============================] - 5s 103ms/step - loss: 0.5076 - acc: 0.7353 - val_loss: 0.5970 - val_acc: 0.6562\n",
            "Epoch 1460/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 0.4937 - acc: 0.7680 - val_loss: 0.6035 - val_acc: 0.6562\n",
            "Epoch 1461/2000\n",
            "39/39 [==============================] - 9s 231ms/step - loss: 0.5524 - acc: 0.7565 - val_loss: 0.6228 - val_acc: 0.6875\n",
            "Epoch 1462/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5176 - acc: 0.7533 - val_loss: 0.6394 - val_acc: 0.6875\n",
            "Epoch 1463/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5047 - acc: 0.7549 - val_loss: 0.5912 - val_acc: 0.6458\n",
            "Epoch 1464/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 0.5276 - acc: 0.7533 - val_loss: 0.6124 - val_acc: 0.6771\n",
            "Epoch 1465/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.5378 - acc: 0.7239 - val_loss: 0.6030 - val_acc: 0.6771\n",
            "Epoch 1466/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.5376 - acc: 0.7353 - val_loss: 0.5906 - val_acc: 0.6979\n",
            "Epoch 1467/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.4819 - acc: 0.7565 - val_loss: 0.6160 - val_acc: 0.6875\n",
            "Epoch 1468/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5003 - acc: 0.7435 - val_loss: 0.6088 - val_acc: 0.6667\n",
            "Epoch 1469/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 0.5095 - acc: 0.7565 - val_loss: 0.5997 - val_acc: 0.6875\n",
            "Epoch 1470/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 0.4999 - acc: 0.7484 - val_loss: 0.6074 - val_acc: 0.6875\n",
            "Epoch 1471/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.4995 - acc: 0.7484 - val_loss: 0.6252 - val_acc: 0.6042\n",
            "Epoch 1472/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5437 - acc: 0.7304 - val_loss: 0.6100 - val_acc: 0.6562\n",
            "Epoch 1473/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.4743 - acc: 0.7761 - val_loss: 0.6400 - val_acc: 0.6771\n",
            "Epoch 1474/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5065 - acc: 0.7533 - val_loss: 0.6071 - val_acc: 0.6875\n",
            "Epoch 1475/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.4996 - acc: 0.7516 - val_loss: 0.5965 - val_acc: 0.6979\n",
            "Epoch 1476/2000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 0.4929 - acc: 0.7549 - val_loss: 0.6204 - val_acc: 0.6667\n",
            "Epoch 1477/2000\n",
            "39/39 [==============================] - 5s 100ms/step - loss: 0.5101 - acc: 0.7255 - val_loss: 0.6133 - val_acc: 0.6875\n",
            "Epoch 1478/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5201 - acc: 0.7582 - val_loss: 0.6060 - val_acc: 0.6458\n",
            "Epoch 1479/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5174 - acc: 0.7696 - val_loss: 0.6081 - val_acc: 0.6771\n",
            "Epoch 1480/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 0.5397 - acc: 0.7157 - val_loss: 0.6066 - val_acc: 0.6667\n",
            "Epoch 1481/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5385 - acc: 0.7288 - val_loss: 0.5919 - val_acc: 0.6667\n",
            "Epoch 1482/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5740 - acc: 0.7173 - val_loss: 0.5802 - val_acc: 0.6250\n",
            "Epoch 1483/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.4902 - acc: 0.7663 - val_loss: 0.6082 - val_acc: 0.6771\n",
            "Epoch 1484/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.4856 - acc: 0.7712 - val_loss: 0.6083 - val_acc: 0.6771\n",
            "Epoch 1485/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.5237 - acc: 0.7402 - val_loss: 0.6222 - val_acc: 0.6771\n",
            "Epoch 1486/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5015 - acc: 0.7614 - val_loss: 0.6163 - val_acc: 0.6979\n",
            "Epoch 1487/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5067 - acc: 0.7663 - val_loss: 0.6212 - val_acc: 0.6667\n",
            "Epoch 1488/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 0.5246 - acc: 0.7435 - val_loss: 0.6014 - val_acc: 0.6771\n",
            "Epoch 1489/2000\n",
            "39/39 [==============================] - 9s 231ms/step - loss: 0.4961 - acc: 0.7467 - val_loss: 0.5859 - val_acc: 0.6562\n",
            "Epoch 1490/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.5401 - acc: 0.7222 - val_loss: 0.6149 - val_acc: 0.6979\n",
            "Epoch 1491/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.5094 - acc: 0.7435 - val_loss: 0.5959 - val_acc: 0.6667\n",
            "Epoch 1492/2000\n",
            "39/39 [==============================] - 10s 239ms/step - loss: 0.5454 - acc: 0.7386 - val_loss: 0.5900 - val_acc: 0.6354\n",
            "Epoch 1493/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5056 - acc: 0.7565 - val_loss: 0.5958 - val_acc: 0.6458\n",
            "Epoch 1494/2000\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.5348 - acc: 0.7320 - val_loss: 0.6152 - val_acc: 0.6875\n",
            "Epoch 1495/2000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.5222 - acc: 0.7549 - val_loss: 0.6076 - val_acc: 0.6562\n",
            "Epoch 1496/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.5223 - acc: 0.7304 - val_loss: 0.6188 - val_acc: 0.6458\n",
            "Epoch 1497/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5372 - acc: 0.7533 - val_loss: 0.6335 - val_acc: 0.6771\n",
            "Epoch 1498/2000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 0.5164 - acc: 0.7337 - val_loss: 0.6281 - val_acc: 0.6875\n",
            "Epoch 1499/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5197 - acc: 0.7337 - val_loss: 0.5767 - val_acc: 0.6875\n",
            "Epoch 1500/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.4897 - acc: 0.7729 - val_loss: 0.5988 - val_acc: 0.6458\n",
            "Epoch 1501/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 0.4973 - acc: 0.7369 - val_loss: 0.5927 - val_acc: 0.6562\n",
            "Epoch 1502/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.5152 - acc: 0.7402 - val_loss: 0.5864 - val_acc: 0.6667\n",
            "Epoch 1503/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.5300 - acc: 0.7353 - val_loss: 0.6331 - val_acc: 0.6875\n",
            "Epoch 1504/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5289 - acc: 0.7549 - val_loss: 0.6045 - val_acc: 0.6562\n",
            "Epoch 1505/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 0.5561 - acc: 0.7255 - val_loss: 0.6003 - val_acc: 0.6771\n",
            "Epoch 1506/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5008 - acc: 0.7745 - val_loss: 0.6337 - val_acc: 0.6771\n",
            "Epoch 1507/2000\n",
            "39/39 [==============================] - 9s 234ms/step - loss: 0.4790 - acc: 0.7663 - val_loss: 0.6009 - val_acc: 0.6562\n",
            "Epoch 1508/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5266 - acc: 0.7435 - val_loss: 0.6049 - val_acc: 0.6562\n",
            "Epoch 1509/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.5235 - acc: 0.7549 - val_loss: 0.6403 - val_acc: 0.6771\n",
            "Epoch 1510/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5067 - acc: 0.7680 - val_loss: 0.5875 - val_acc: 0.6458\n",
            "Epoch 1511/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5269 - acc: 0.7435 - val_loss: 0.6018 - val_acc: 0.6354\n",
            "Epoch 1512/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.5241 - acc: 0.7548 - val_loss: 0.5999 - val_acc: 0.6667\n",
            "Epoch 1513/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.5245 - acc: 0.7386 - val_loss: 0.6175 - val_acc: 0.6562\n",
            "Epoch 1514/2000\n",
            "39/39 [==============================] - 10s 235ms/step - loss: 0.4820 - acc: 0.7745 - val_loss: 0.6023 - val_acc: 0.6562\n",
            "Epoch 1515/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.5171 - acc: 0.7320 - val_loss: 0.6136 - val_acc: 0.6562\n",
            "Epoch 1516/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5241 - acc: 0.7206 - val_loss: 0.6210 - val_acc: 0.6875\n",
            "Epoch 1517/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5221 - acc: 0.7320 - val_loss: 0.6158 - val_acc: 0.6458\n",
            "Epoch 1518/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5195 - acc: 0.7516 - val_loss: 0.6125 - val_acc: 0.6562\n",
            "Epoch 1519/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5227 - acc: 0.7255 - val_loss: 0.5998 - val_acc: 0.6562\n",
            "Epoch 1520/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.5036 - acc: 0.7614 - val_loss: 0.6232 - val_acc: 0.6562\n",
            "Epoch 1521/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.4978 - acc: 0.7631 - val_loss: 0.6194 - val_acc: 0.6458\n",
            "Epoch 1522/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.5025 - acc: 0.7467 - val_loss: 0.5856 - val_acc: 0.6562\n",
            "Epoch 1523/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5099 - acc: 0.7418 - val_loss: 0.6341 - val_acc: 0.6354\n",
            "Epoch 1524/2000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 0.5200 - acc: 0.7533 - val_loss: 0.6058 - val_acc: 0.6458\n",
            "Epoch 1525/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.5474 - acc: 0.7386 - val_loss: 0.6259 - val_acc: 0.6771\n",
            "Epoch 1526/2000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 0.5047 - acc: 0.7598 - val_loss: 0.6145 - val_acc: 0.6667\n",
            "Epoch 1527/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 0.5173 - acc: 0.7484 - val_loss: 0.6252 - val_acc: 0.6771\n",
            "Epoch 1528/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.5178 - acc: 0.7500 - val_loss: 0.6228 - val_acc: 0.6875\n",
            "Epoch 1529/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.5073 - acc: 0.7516 - val_loss: 0.6049 - val_acc: 0.6667\n",
            "Epoch 1530/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5146 - acc: 0.7304 - val_loss: 0.5949 - val_acc: 0.6667\n",
            "Epoch 1531/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.4860 - acc: 0.7712 - val_loss: 0.6160 - val_acc: 0.6562\n",
            "Epoch 1532/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.5393 - acc: 0.7239 - val_loss: 0.6003 - val_acc: 0.6458\n",
            "Epoch 1533/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5128 - acc: 0.7565 - val_loss: 0.6128 - val_acc: 0.6354\n",
            "Epoch 1534/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5144 - acc: 0.7320 - val_loss: 0.6290 - val_acc: 0.6458\n",
            "Epoch 1535/2000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 0.5015 - acc: 0.7647 - val_loss: 0.6075 - val_acc: 0.5938\n",
            "Epoch 1536/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.5150 - acc: 0.7598 - val_loss: 0.6360 - val_acc: 0.6667\n",
            "Epoch 1537/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.5324 - acc: 0.7386 - val_loss: 0.6403 - val_acc: 0.6771\n",
            "Epoch 1538/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5188 - acc: 0.7435 - val_loss: 0.6319 - val_acc: 0.6771\n",
            "Epoch 1539/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.4553 - acc: 0.7778 - val_loss: 0.6191 - val_acc: 0.6562\n",
            "Epoch 1540/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.4891 - acc: 0.7533 - val_loss: 0.6095 - val_acc: 0.6667\n",
            "Epoch 1541/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.4792 - acc: 0.7778 - val_loss: 0.6504 - val_acc: 0.6667\n",
            "Epoch 1542/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.5238 - acc: 0.7451 - val_loss: 0.6312 - val_acc: 0.6771\n",
            "Epoch 1543/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5070 - acc: 0.7696 - val_loss: 0.6238 - val_acc: 0.6458\n",
            "Epoch 1544/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.5179 - acc: 0.7500 - val_loss: 0.6161 - val_acc: 0.6667\n",
            "Epoch 1545/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 0.5330 - acc: 0.7451 - val_loss: 0.6370 - val_acc: 0.6771\n",
            "Epoch 1546/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.4739 - acc: 0.7745 - val_loss: 0.6128 - val_acc: 0.6458\n",
            "Epoch 1547/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5186 - acc: 0.7451 - val_loss: 0.5893 - val_acc: 0.6458\n",
            "Epoch 1548/2000\n",
            "39/39 [==============================] - 10s 238ms/step - loss: 0.5266 - acc: 0.7614 - val_loss: 0.5866 - val_acc: 0.6667\n",
            "Epoch 1549/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5443 - acc: 0.6961 - val_loss: 0.6154 - val_acc: 0.6667\n",
            "Epoch 1550/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5031 - acc: 0.7565 - val_loss: 0.6059 - val_acc: 0.6458\n",
            "Epoch 1551/2000\n",
            "39/39 [==============================] - 6s 137ms/step - loss: 0.5076 - acc: 0.7549 - val_loss: 0.6262 - val_acc: 0.6667\n",
            "Epoch 1552/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5143 - acc: 0.7500 - val_loss: 0.6246 - val_acc: 0.6979\n",
            "Epoch 1553/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5007 - acc: 0.7582 - val_loss: 0.5857 - val_acc: 0.6667\n",
            "Epoch 1554/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5242 - acc: 0.7418 - val_loss: 0.6175 - val_acc: 0.6354\n",
            "Epoch 1555/2000\n",
            "39/39 [==============================] - 5s 112ms/step - loss: 0.5112 - acc: 0.7271 - val_loss: 0.6139 - val_acc: 0.6562\n",
            "Epoch 1556/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5345 - acc: 0.7353 - val_loss: 0.6090 - val_acc: 0.6458\n",
            "Epoch 1557/2000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 0.4870 - acc: 0.7582 - val_loss: 0.6263 - val_acc: 0.6667\n",
            "Epoch 1558/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5085 - acc: 0.7353 - val_loss: 0.6040 - val_acc: 0.6562\n",
            "Epoch 1559/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.5289 - acc: 0.7516 - val_loss: 0.6225 - val_acc: 0.6875\n",
            "Epoch 1560/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 0.5115 - acc: 0.7484 - val_loss: 0.5912 - val_acc: 0.6562\n",
            "Epoch 1561/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5092 - acc: 0.7565 - val_loss: 0.6255 - val_acc: 0.6250\n",
            "Epoch 1562/2000\n",
            "39/39 [==============================] - 9s 233ms/step - loss: 0.4796 - acc: 0.7712 - val_loss: 0.6061 - val_acc: 0.6354\n",
            "Epoch 1563/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.5079 - acc: 0.7696 - val_loss: 0.6101 - val_acc: 0.6979\n",
            "Epoch 1564/2000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 0.5339 - acc: 0.7598 - val_loss: 0.6073 - val_acc: 0.6354\n",
            "Epoch 1565/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.5366 - acc: 0.7190 - val_loss: 0.6100 - val_acc: 0.7083\n",
            "Epoch 1566/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5184 - acc: 0.7467 - val_loss: 0.6198 - val_acc: 0.6354\n",
            "Epoch 1567/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5412 - acc: 0.7451 - val_loss: 0.6309 - val_acc: 0.6458\n",
            "Epoch 1568/2000\n",
            "39/39 [==============================] - 5s 100ms/step - loss: 0.5153 - acc: 0.7533 - val_loss: 0.6336 - val_acc: 0.6562\n",
            "Epoch 1569/2000\n",
            "39/39 [==============================] - 5s 119ms/step - loss: 0.5497 - acc: 0.7239 - val_loss: 0.6613 - val_acc: 0.6771\n",
            "Epoch 1570/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.5320 - acc: 0.7582 - val_loss: 0.6336 - val_acc: 0.6354\n",
            "Epoch 1571/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5113 - acc: 0.7304 - val_loss: 0.6388 - val_acc: 0.6667\n",
            "Epoch 1572/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5271 - acc: 0.7549 - val_loss: 0.6194 - val_acc: 0.6771\n",
            "Epoch 1573/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.5057 - acc: 0.7500 - val_loss: 0.5825 - val_acc: 0.6354\n",
            "Epoch 1574/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 0.5175 - acc: 0.7402 - val_loss: 0.6126 - val_acc: 0.6771\n",
            "Epoch 1575/2000\n",
            "39/39 [==============================] - 5s 121ms/step - loss: 0.5019 - acc: 0.7467 - val_loss: 0.6254 - val_acc: 0.6458\n",
            "Epoch 1576/2000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 0.4777 - acc: 0.7647 - val_loss: 0.5947 - val_acc: 0.6458\n",
            "Epoch 1577/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5006 - acc: 0.7418 - val_loss: 0.6092 - val_acc: 0.6562\n",
            "Epoch 1578/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5254 - acc: 0.7239 - val_loss: 0.6044 - val_acc: 0.6667\n",
            "Epoch 1579/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.4851 - acc: 0.7451 - val_loss: 0.5975 - val_acc: 0.6667\n",
            "Epoch 1580/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5169 - acc: 0.7386 - val_loss: 0.5983 - val_acc: 0.6667\n",
            "Epoch 1581/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 0.5087 - acc: 0.7271 - val_loss: 0.6036 - val_acc: 0.6458\n",
            "Epoch 1582/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.4975 - acc: 0.7451 - val_loss: 0.6275 - val_acc: 0.6667\n",
            "Epoch 1583/2000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 0.4778 - acc: 0.7908 - val_loss: 0.6250 - val_acc: 0.6875\n",
            "Epoch 1584/2000\n",
            "39/39 [==============================] - 5s 112ms/step - loss: 0.5016 - acc: 0.7778 - val_loss: 0.6311 - val_acc: 0.6667\n",
            "Epoch 1585/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5261 - acc: 0.7337 - val_loss: 0.6012 - val_acc: 0.6562\n",
            "Epoch 1586/2000\n",
            "39/39 [==============================] - 9s 232ms/step - loss: 0.5369 - acc: 0.7288 - val_loss: 0.6203 - val_acc: 0.6875\n",
            "Epoch 1587/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.4980 - acc: 0.7467 - val_loss: 0.5964 - val_acc: 0.6562\n",
            "Epoch 1588/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5315 - acc: 0.7353 - val_loss: 0.6460 - val_acc: 0.6667\n",
            "Epoch 1589/2000\n",
            "39/39 [==============================] - 10s 231ms/step - loss: 0.5192 - acc: 0.7239 - val_loss: 0.5961 - val_acc: 0.6771\n",
            "Epoch 1590/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5445 - acc: 0.7353 - val_loss: 0.6135 - val_acc: 0.6875\n",
            "Epoch 1591/2000\n",
            "39/39 [==============================] - 10s 238ms/step - loss: 0.4937 - acc: 0.7549 - val_loss: 0.6340 - val_acc: 0.6667\n",
            "Epoch 1592/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5256 - acc: 0.7435 - val_loss: 0.6195 - val_acc: 0.6562\n",
            "Epoch 1593/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.4957 - acc: 0.7500 - val_loss: 0.6097 - val_acc: 0.6771\n",
            "Epoch 1594/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.5481 - acc: 0.7369 - val_loss: 0.6034 - val_acc: 0.6771\n",
            "Epoch 1595/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 0.5155 - acc: 0.7435 - val_loss: 0.5920 - val_acc: 0.6667\n",
            "Epoch 1596/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.4945 - acc: 0.7663 - val_loss: 0.5888 - val_acc: 0.6667\n",
            "Epoch 1597/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.5037 - acc: 0.7549 - val_loss: 0.6190 - val_acc: 0.6667\n",
            "Epoch 1598/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.5297 - acc: 0.7337 - val_loss: 0.5906 - val_acc: 0.6562\n",
            "Epoch 1599/2000\n",
            "39/39 [==============================] - 9s 235ms/step - loss: 0.5173 - acc: 0.7222 - val_loss: 0.6061 - val_acc: 0.6771\n",
            "Epoch 1600/2000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 0.5117 - acc: 0.7598 - val_loss: 0.5823 - val_acc: 0.6979\n",
            "Epoch 1601/2000\n",
            "39/39 [==============================] - 5s 119ms/step - loss: 0.5263 - acc: 0.7467 - val_loss: 0.6362 - val_acc: 0.6562\n",
            "Epoch 1602/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.5039 - acc: 0.7565 - val_loss: 0.5857 - val_acc: 0.6771\n",
            "Epoch 1603/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.4981 - acc: 0.7418 - val_loss: 0.6176 - val_acc: 0.6771\n",
            "Epoch 1604/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.4873 - acc: 0.7533 - val_loss: 0.6086 - val_acc: 0.6562\n",
            "Epoch 1605/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.5109 - acc: 0.7614 - val_loss: 0.6265 - val_acc: 0.6875\n",
            "Epoch 1606/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5231 - acc: 0.7451 - val_loss: 0.5994 - val_acc: 0.6250\n",
            "Epoch 1607/2000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 0.5058 - acc: 0.7582 - val_loss: 0.6311 - val_acc: 0.6458\n",
            "Epoch 1608/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5176 - acc: 0.7320 - val_loss: 0.6011 - val_acc: 0.6667\n",
            "Epoch 1609/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5051 - acc: 0.7484 - val_loss: 0.5789 - val_acc: 0.6354\n",
            "Epoch 1610/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5320 - acc: 0.7141 - val_loss: 0.6029 - val_acc: 0.6667\n",
            "Epoch 1611/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.5479 - acc: 0.7435 - val_loss: 0.6173 - val_acc: 0.6458\n",
            "Epoch 1612/2000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 0.4682 - acc: 0.7859 - val_loss: 0.5988 - val_acc: 0.6250\n",
            "Epoch 1613/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.5389 - acc: 0.7337 - val_loss: 0.6190 - val_acc: 0.6562\n",
            "Epoch 1614/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 0.5009 - acc: 0.7451 - val_loss: 0.6238 - val_acc: 0.6458\n",
            "Epoch 1615/2000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.5031 - acc: 0.7402 - val_loss: 0.5995 - val_acc: 0.6771\n",
            "Epoch 1616/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.5611 - acc: 0.7435 - val_loss: 0.6247 - val_acc: 0.6667\n",
            "Epoch 1617/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 0.5359 - acc: 0.7451 - val_loss: 0.6007 - val_acc: 0.6562\n",
            "Epoch 1618/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.4981 - acc: 0.7582 - val_loss: 0.6075 - val_acc: 0.6979\n",
            "Epoch 1619/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5131 - acc: 0.7467 - val_loss: 0.6010 - val_acc: 0.6562\n",
            "Epoch 1620/2000\n",
            "39/39 [==============================] - 5s 121ms/step - loss: 0.4728 - acc: 0.7810 - val_loss: 0.6450 - val_acc: 0.6667\n",
            "Epoch 1621/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.4556 - acc: 0.7745 - val_loss: 0.5938 - val_acc: 0.6667\n",
            "Epoch 1622/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.4943 - acc: 0.7680 - val_loss: 0.6132 - val_acc: 0.6979\n",
            "Epoch 1623/2000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 0.5224 - acc: 0.7435 - val_loss: 0.6095 - val_acc: 0.6667\n",
            "Epoch 1624/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.5362 - acc: 0.7173 - val_loss: 0.6163 - val_acc: 0.6562\n",
            "Epoch 1625/2000\n",
            "39/39 [==============================] - 5s 112ms/step - loss: 0.4980 - acc: 0.7631 - val_loss: 0.5849 - val_acc: 0.6771\n",
            "Epoch 1626/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 0.5025 - acc: 0.7680 - val_loss: 0.6108 - val_acc: 0.6562\n",
            "Epoch 1627/2000\n",
            "39/39 [==============================] - 10s 225ms/step - loss: 0.4960 - acc: 0.7680 - val_loss: 0.5875 - val_acc: 0.6562\n",
            "Epoch 1628/2000\n",
            "39/39 [==============================] - 6s 142ms/step - loss: 0.5008 - acc: 0.7631 - val_loss: 0.5914 - val_acc: 0.6667\n",
            "Epoch 1629/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5145 - acc: 0.7500 - val_loss: 0.6388 - val_acc: 0.6667\n",
            "Epoch 1630/2000\n",
            "39/39 [==============================] - 9s 232ms/step - loss: 0.5271 - acc: 0.7484 - val_loss: 0.5904 - val_acc: 0.6771\n",
            "Epoch 1631/2000\n",
            "39/39 [==============================] - 6s 142ms/step - loss: 0.5310 - acc: 0.7500 - val_loss: 0.6034 - val_acc: 0.6562\n",
            "Epoch 1632/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5035 - acc: 0.7467 - val_loss: 0.6255 - val_acc: 0.6667\n",
            "Epoch 1633/2000\n",
            "39/39 [==============================] - 9s 231ms/step - loss: 0.4719 - acc: 0.7614 - val_loss: 0.6266 - val_acc: 0.6771\n",
            "Epoch 1634/2000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 0.4829 - acc: 0.7533 - val_loss: 0.6169 - val_acc: 0.6458\n",
            "Epoch 1635/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 0.5050 - acc: 0.7451 - val_loss: 0.6050 - val_acc: 0.6875\n",
            "Epoch 1636/2000\n",
            "39/39 [==============================] - 10s 241ms/step - loss: 0.5567 - acc: 0.7179 - val_loss: 0.5877 - val_acc: 0.6771\n",
            "Epoch 1637/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.4825 - acc: 0.7729 - val_loss: 0.5899 - val_acc: 0.6562\n",
            "Epoch 1638/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.5304 - acc: 0.7614 - val_loss: 0.6312 - val_acc: 0.6667\n",
            "Epoch 1639/2000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 0.5186 - acc: 0.7402 - val_loss: 0.5949 - val_acc: 0.6458\n",
            "Epoch 1640/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5328 - acc: 0.7239 - val_loss: 0.5976 - val_acc: 0.6562\n",
            "Epoch 1641/2000\n",
            "39/39 [==============================] - 10s 241ms/step - loss: 0.5192 - acc: 0.7255 - val_loss: 0.6199 - val_acc: 0.6875\n",
            "Epoch 1642/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5217 - acc: 0.7484 - val_loss: 0.6171 - val_acc: 0.6771\n",
            "Epoch 1643/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5169 - acc: 0.7386 - val_loss: 0.5947 - val_acc: 0.6875\n",
            "Epoch 1644/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 0.5502 - acc: 0.7239 - val_loss: 0.5940 - val_acc: 0.6354\n",
            "Epoch 1645/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5329 - acc: 0.7451 - val_loss: 0.5577 - val_acc: 0.6562\n",
            "Epoch 1646/2000\n",
            "39/39 [==============================] - 9s 233ms/step - loss: 0.5275 - acc: 0.7402 - val_loss: 0.5988 - val_acc: 0.6667\n",
            "Epoch 1647/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.5468 - acc: 0.7288 - val_loss: 0.6312 - val_acc: 0.6771\n",
            "Epoch 1648/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.5331 - acc: 0.7451 - val_loss: 0.6504 - val_acc: 0.6562\n",
            "Epoch 1649/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5156 - acc: 0.7516 - val_loss: 0.6023 - val_acc: 0.6771\n",
            "Epoch 1650/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 0.5224 - acc: 0.7467 - val_loss: 0.6098 - val_acc: 0.6562\n",
            "Epoch 1651/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5315 - acc: 0.7435 - val_loss: 0.6012 - val_acc: 0.6667\n",
            "Epoch 1652/2000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 0.4730 - acc: 0.7696 - val_loss: 0.6397 - val_acc: 0.6667\n",
            "Epoch 1653/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 0.5007 - acc: 0.7647 - val_loss: 0.5995 - val_acc: 0.6667\n",
            "Epoch 1654/2000\n",
            "39/39 [==============================] - 5s 112ms/step - loss: 0.4918 - acc: 0.7663 - val_loss: 0.6436 - val_acc: 0.6562\n",
            "Epoch 1655/2000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 0.5006 - acc: 0.7418 - val_loss: 0.5984 - val_acc: 0.7083\n",
            "Epoch 1656/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 0.4917 - acc: 0.7549 - val_loss: 0.6001 - val_acc: 0.6979\n",
            "Epoch 1657/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.4950 - acc: 0.7680 - val_loss: 0.6619 - val_acc: 0.6771\n",
            "Epoch 1658/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.5074 - acc: 0.7516 - val_loss: 0.6210 - val_acc: 0.6771\n",
            "Epoch 1659/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.5154 - acc: 0.7402 - val_loss: 0.6111 - val_acc: 0.6562\n",
            "Epoch 1660/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5058 - acc: 0.7582 - val_loss: 0.6000 - val_acc: 0.6667\n",
            "Epoch 1661/2000\n",
            "39/39 [==============================] - 10s 244ms/step - loss: 0.5164 - acc: 0.7500 - val_loss: 0.6318 - val_acc: 0.6771\n",
            "Epoch 1662/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5314 - acc: 0.7353 - val_loss: 0.6010 - val_acc: 0.6875\n",
            "Epoch 1663/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.4959 - acc: 0.7582 - val_loss: 0.5982 - val_acc: 0.6771\n",
            "Epoch 1664/2000\n",
            "39/39 [==============================] - 5s 115ms/step - loss: 0.5296 - acc: 0.7451 - val_loss: 0.6119 - val_acc: 0.6979\n",
            "Epoch 1665/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.5102 - acc: 0.7516 - val_loss: 0.6071 - val_acc: 0.6354\n",
            "Epoch 1666/2000\n",
            "39/39 [==============================] - 10s 236ms/step - loss: 0.4932 - acc: 0.7500 - val_loss: 0.6120 - val_acc: 0.6667\n",
            "Epoch 1667/2000\n",
            "39/39 [==============================] - 5s 117ms/step - loss: 0.5048 - acc: 0.7337 - val_loss: 0.6195 - val_acc: 0.6771\n",
            "Epoch 1668/2000\n",
            "39/39 [==============================] - 10s 230ms/step - loss: 0.4733 - acc: 0.7827 - val_loss: 0.5889 - val_acc: 0.6562\n",
            "Epoch 1669/2000\n",
            "39/39 [==============================] - 5s 115ms/step - loss: 0.5193 - acc: 0.7582 - val_loss: 0.5931 - val_acc: 0.6875\n",
            "Epoch 1670/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5143 - acc: 0.7353 - val_loss: 0.6046 - val_acc: 0.6562\n",
            "Epoch 1671/2000\n",
            "39/39 [==============================] - 5s 120ms/step - loss: 0.5379 - acc: 0.7141 - val_loss: 0.6181 - val_acc: 0.6667\n",
            "Epoch 1672/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5117 - acc: 0.7467 - val_loss: 0.6028 - val_acc: 0.6875\n",
            "Epoch 1673/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5136 - acc: 0.7435 - val_loss: 0.5848 - val_acc: 0.6771\n",
            "Epoch 1674/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5058 - acc: 0.7516 - val_loss: 0.6152 - val_acc: 0.6562\n",
            "Epoch 1675/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5088 - acc: 0.7516 - val_loss: 0.5773 - val_acc: 0.6875\n",
            "Epoch 1676/2000\n",
            "39/39 [==============================] - 9s 235ms/step - loss: 0.5168 - acc: 0.7451 - val_loss: 0.6357 - val_acc: 0.6771\n",
            "Epoch 1677/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.4874 - acc: 0.7647 - val_loss: 0.6047 - val_acc: 0.6667\n",
            "Epoch 1678/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.5098 - acc: 0.7647 - val_loss: 0.5906 - val_acc: 0.6875\n",
            "Epoch 1679/2000\n",
            "39/39 [==============================] - 10s 242ms/step - loss: 0.5199 - acc: 0.7190 - val_loss: 0.5997 - val_acc: 0.6875\n",
            "Epoch 1680/2000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 0.4837 - acc: 0.7631 - val_loss: 0.6087 - val_acc: 0.6667\n",
            "Epoch 1681/2000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 0.4989 - acc: 0.7549 - val_loss: 0.5984 - val_acc: 0.6354\n",
            "Epoch 1682/2000\n",
            "39/39 [==============================] - 10s 239ms/step - loss: 0.5349 - acc: 0.7484 - val_loss: 0.5947 - val_acc: 0.6771\n",
            "Epoch 1683/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5171 - acc: 0.7516 - val_loss: 0.6084 - val_acc: 0.6458\n",
            "Epoch 1684/2000\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.4903 - acc: 0.7663 - val_loss: 0.6065 - val_acc: 0.6667\n",
            "Epoch 1685/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.4712 - acc: 0.7582 - val_loss: 0.6108 - val_acc: 0.6771\n",
            "Epoch 1686/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5101 - acc: 0.7582 - val_loss: 0.6309 - val_acc: 0.6667\n",
            "Epoch 1687/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.4767 - acc: 0.7663 - val_loss: 0.6034 - val_acc: 0.6771\n",
            "Epoch 1688/2000\n",
            "39/39 [==============================] - 10s 235ms/step - loss: 0.4864 - acc: 0.7533 - val_loss: 0.5844 - val_acc: 0.6667\n",
            "Epoch 1689/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.5189 - acc: 0.7369 - val_loss: 0.6130 - val_acc: 0.6458\n",
            "Epoch 1690/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.5209 - acc: 0.7484 - val_loss: 0.6124 - val_acc: 0.6562\n",
            "Epoch 1691/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5418 - acc: 0.7206 - val_loss: 0.5743 - val_acc: 0.6771\n",
            "Epoch 1692/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 0.5003 - acc: 0.7418 - val_loss: 0.5769 - val_acc: 0.6667\n",
            "Epoch 1693/2000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 0.4986 - acc: 0.7451 - val_loss: 0.5917 - val_acc: 0.6562\n",
            "Epoch 1694/2000\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.5236 - acc: 0.7660 - val_loss: 0.5777 - val_acc: 0.6667\n",
            "Epoch 1695/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.4926 - acc: 0.7533 - val_loss: 0.5636 - val_acc: 0.6875\n",
            "Epoch 1696/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5282 - acc: 0.7598 - val_loss: 0.5544 - val_acc: 0.6562\n",
            "Epoch 1697/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5050 - acc: 0.7484 - val_loss: 0.5838 - val_acc: 0.6667\n",
            "Epoch 1698/2000\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 0.4839 - acc: 0.7598 - val_loss: 0.5747 - val_acc: 0.6771\n",
            "Epoch 1699/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.4943 - acc: 0.7549 - val_loss: 0.5725 - val_acc: 0.6771\n",
            "Epoch 1700/2000\n",
            "39/39 [==============================] - 9s 232ms/step - loss: 0.5109 - acc: 0.7533 - val_loss: 0.5724 - val_acc: 0.6771\n",
            "Epoch 1701/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5468 - acc: 0.7157 - val_loss: 0.5810 - val_acc: 0.6458\n",
            "Epoch 1702/2000\n",
            "39/39 [==============================] - 6s 130ms/step - loss: 0.4982 - acc: 0.7369 - val_loss: 0.5648 - val_acc: 0.6771\n",
            "Epoch 1703/2000\n",
            "39/39 [==============================] - 9s 234ms/step - loss: 0.5371 - acc: 0.7304 - val_loss: 0.5729 - val_acc: 0.6667\n",
            "Epoch 1704/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.5500 - acc: 0.7239 - val_loss: 0.5965 - val_acc: 0.6562\n",
            "Epoch 1705/2000\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.5112 - acc: 0.7565 - val_loss: 0.5738 - val_acc: 0.6875\n",
            "Epoch 1706/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.5001 - acc: 0.7533 - val_loss: 0.5716 - val_acc: 0.6875\n",
            "Epoch 1707/2000\n",
            "39/39 [==============================] - 10s 231ms/step - loss: 0.4730 - acc: 0.7647 - val_loss: 0.5745 - val_acc: 0.6875\n",
            "Epoch 1708/2000\n",
            "39/39 [==============================] - 9s 233ms/step - loss: 0.4848 - acc: 0.7712 - val_loss: 0.5908 - val_acc: 0.6667\n",
            "Epoch 1709/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 0.5372 - acc: 0.7435 - val_loss: 0.5918 - val_acc: 0.6875\n",
            "Epoch 1710/2000\n",
            "39/39 [==============================] - 7s 154ms/step - loss: 0.5063 - acc: 0.7451 - val_loss: 0.5920 - val_acc: 0.6458\n",
            "Epoch 1711/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.5466 - acc: 0.7288 - val_loss: 0.5971 - val_acc: 0.6562\n",
            "Epoch 1712/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 0.4976 - acc: 0.7663 - val_loss: 0.6213 - val_acc: 0.6771\n",
            "Epoch 1713/2000\n",
            "39/39 [==============================] - 6s 139ms/step - loss: 0.4906 - acc: 0.7435 - val_loss: 0.6025 - val_acc: 0.6562\n",
            "Epoch 1714/2000\n",
            "39/39 [==============================] - 10s 234ms/step - loss: 0.5329 - acc: 0.7271 - val_loss: 0.5800 - val_acc: 0.6875\n",
            "Epoch 1715/2000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 0.4969 - acc: 0.7402 - val_loss: 0.5835 - val_acc: 0.6771\n",
            "Epoch 1716/2000\n",
            "39/39 [==============================] - 5s 114ms/step - loss: 0.5121 - acc: 0.7484 - val_loss: 0.5966 - val_acc: 0.6458\n",
            "Epoch 1717/2000\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 0.5593 - acc: 0.7141 - val_loss: 0.5855 - val_acc: 0.6562\n",
            "Epoch 1718/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5107 - acc: 0.7451 - val_loss: 0.5719 - val_acc: 0.6771\n",
            "Epoch 1719/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 0.4953 - acc: 0.7614 - val_loss: 0.5757 - val_acc: 0.6667\n",
            "Epoch 1720/2000\n",
            "39/39 [==============================] - 5s 97ms/step - loss: 0.5046 - acc: 0.7435 - val_loss: 0.5809 - val_acc: 0.6146\n",
            "Epoch 1721/2000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 0.4979 - acc: 0.7614 - val_loss: 0.6200 - val_acc: 0.6667\n",
            "Epoch 1722/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5092 - acc: 0.7533 - val_loss: 0.5837 - val_acc: 0.6667\n",
            "Epoch 1723/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5375 - acc: 0.7386 - val_loss: 0.5715 - val_acc: 0.6771\n",
            "Epoch 1724/2000\n",
            "39/39 [==============================] - 10s 239ms/step - loss: 0.5141 - acc: 0.7516 - val_loss: 0.5935 - val_acc: 0.6354\n",
            "Epoch 1725/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.5224 - acc: 0.7516 - val_loss: 0.5984 - val_acc: 0.6667\n",
            "Epoch 1726/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.5147 - acc: 0.7337 - val_loss: 0.5898 - val_acc: 0.6562\n",
            "Epoch 1727/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 0.4947 - acc: 0.7712 - val_loss: 0.5958 - val_acc: 0.6562\n",
            "Epoch 1728/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.5366 - acc: 0.7222 - val_loss: 0.6038 - val_acc: 0.6667\n",
            "Epoch 1729/2000\n",
            "39/39 [==============================] - 5s 113ms/step - loss: 0.5396 - acc: 0.7271 - val_loss: 0.5786 - val_acc: 0.6354\n",
            "Epoch 1730/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5003 - acc: 0.7402 - val_loss: 0.5685 - val_acc: 0.6562\n",
            "Epoch 1731/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.4937 - acc: 0.7533 - val_loss: 0.6055 - val_acc: 0.6771\n",
            "Epoch 1732/2000\n",
            "39/39 [==============================] - 10s 243ms/step - loss: 0.4805 - acc: 0.7565 - val_loss: 0.6211 - val_acc: 0.6771\n",
            "Epoch 1733/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5008 - acc: 0.7565 - val_loss: 0.6076 - val_acc: 0.6771\n",
            "Epoch 1734/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5237 - acc: 0.7565 - val_loss: 0.5949 - val_acc: 0.6458\n",
            "Epoch 1735/2000\n",
            "39/39 [==============================] - 9s 234ms/step - loss: 0.5833 - acc: 0.7108 - val_loss: 0.6039 - val_acc: 0.6562\n",
            "Epoch 1736/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.4837 - acc: 0.7712 - val_loss: 0.6306 - val_acc: 0.6667\n",
            "Epoch 1737/2000\n",
            "39/39 [==============================] - 10s 240ms/step - loss: 0.5047 - acc: 0.7598 - val_loss: 0.5913 - val_acc: 0.6875\n",
            "Epoch 1738/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5421 - acc: 0.7353 - val_loss: 0.5923 - val_acc: 0.6354\n",
            "Epoch 1739/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.5120 - acc: 0.7549 - val_loss: 0.5951 - val_acc: 0.6458\n",
            "Epoch 1740/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5193 - acc: 0.7206 - val_loss: 0.5911 - val_acc: 0.6771\n",
            "Epoch 1741/2000\n",
            "39/39 [==============================] - 9s 234ms/step - loss: 0.5141 - acc: 0.7582 - val_loss: 0.6275 - val_acc: 0.6458\n",
            "Epoch 1742/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.5155 - acc: 0.7500 - val_loss: 0.6009 - val_acc: 0.6667\n",
            "Epoch 1743/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.4938 - acc: 0.7778 - val_loss: 0.5867 - val_acc: 0.6667\n",
            "Epoch 1744/2000\n",
            "39/39 [==============================] - 5s 113ms/step - loss: 0.4985 - acc: 0.7533 - val_loss: 0.5790 - val_acc: 0.6562\n",
            "Epoch 1745/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5318 - acc: 0.7484 - val_loss: 0.6155 - val_acc: 0.6562\n",
            "Epoch 1746/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.4946 - acc: 0.7647 - val_loss: 0.5889 - val_acc: 0.6667\n",
            "Epoch 1747/2000\n",
            "39/39 [==============================] - 5s 98ms/step - loss: 0.4923 - acc: 0.7729 - val_loss: 0.5920 - val_acc: 0.6667\n",
            "Epoch 1748/2000\n",
            "39/39 [==============================] - 10s 222ms/step - loss: 0.5259 - acc: 0.7500 - val_loss: 0.5685 - val_acc: 0.6667\n",
            "Epoch 1749/2000\n",
            "39/39 [==============================] - 10s 237ms/step - loss: 0.5150 - acc: 0.7516 - val_loss: 0.5867 - val_acc: 0.6667\n",
            "Epoch 1750/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.5273 - acc: 0.7353 - val_loss: 0.5810 - val_acc: 0.6354\n",
            "Epoch 1751/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 0.5395 - acc: 0.7353 - val_loss: 0.6132 - val_acc: 0.6562\n",
            "Epoch 1752/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.5134 - acc: 0.7500 - val_loss: 0.6058 - val_acc: 0.6667\n",
            "Epoch 1753/2000\n",
            "39/39 [==============================] - 5s 92ms/step - loss: 0.5353 - acc: 0.7304 - val_loss: 0.5821 - val_acc: 0.6667\n",
            "Epoch 1754/2000\n",
            "39/39 [==============================] - 10s 229ms/step - loss: 0.5587 - acc: 0.7141 - val_loss: 0.6108 - val_acc: 0.6562\n",
            "Epoch 1755/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5220 - acc: 0.7320 - val_loss: 0.6179 - val_acc: 0.6458\n",
            "Epoch 1756/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.5098 - acc: 0.7565 - val_loss: 0.5839 - val_acc: 0.6875\n",
            "Epoch 1757/2000\n",
            "39/39 [==============================] - 10s 230ms/step - loss: 0.5403 - acc: 0.7500 - val_loss: 0.6068 - val_acc: 0.6667\n",
            "Epoch 1758/2000\n",
            "39/39 [==============================] - 9s 232ms/step - loss: 0.4982 - acc: 0.7614 - val_loss: 0.6078 - val_acc: 0.6562\n",
            "Epoch 1759/2000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 0.4989 - acc: 0.7761 - val_loss: 0.5952 - val_acc: 0.6458\n",
            "Epoch 1760/2000\n",
            "39/39 [==============================] - 10s 240ms/step - loss: 0.5152 - acc: 0.7467 - val_loss: 0.6060 - val_acc: 0.6562\n",
            "Epoch 1761/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 0.4889 - acc: 0.7565 - val_loss: 0.5971 - val_acc: 0.6771\n",
            "Epoch 1762/2000\n",
            "39/39 [==============================] - 5s 113ms/step - loss: 0.4990 - acc: 0.7778 - val_loss: 0.5854 - val_acc: 0.6354\n",
            "Epoch 1763/2000\n",
            "39/39 [==============================] - 10s 237ms/step - loss: 0.5230 - acc: 0.7484 - val_loss: 0.5862 - val_acc: 0.6562\n",
            "Epoch 1764/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5208 - acc: 0.7778 - val_loss: 0.5986 - val_acc: 0.6458\n",
            "Epoch 1765/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5180 - acc: 0.7369 - val_loss: 0.6047 - val_acc: 0.6562\n",
            "Epoch 1766/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.5352 - acc: 0.7222 - val_loss: 0.6211 - val_acc: 0.6562\n",
            "Epoch 1767/2000\n",
            "39/39 [==============================] - 5s 122ms/step - loss: 0.5195 - acc: 0.7582 - val_loss: 0.5858 - val_acc: 0.6562\n",
            "Epoch 1768/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.5238 - acc: 0.7467 - val_loss: 0.6130 - val_acc: 0.6458\n",
            "Epoch 1769/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.4937 - acc: 0.7680 - val_loss: 0.5907 - val_acc: 0.6875\n",
            "Epoch 1770/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5252 - acc: 0.7549 - val_loss: 0.6227 - val_acc: 0.6458\n",
            "Epoch 1771/2000\n",
            "39/39 [==============================] - 5s 94ms/step - loss: 0.5348 - acc: 0.7353 - val_loss: 0.6013 - val_acc: 0.6667\n",
            "Epoch 1772/2000\n",
            "39/39 [==============================] - 5s 112ms/step - loss: 0.4954 - acc: 0.7696 - val_loss: 0.5947 - val_acc: 0.6562\n",
            "Epoch 1773/2000\n",
            "39/39 [==============================] - 10s 237ms/step - loss: 0.5203 - acc: 0.7369 - val_loss: 0.6114 - val_acc: 0.6667\n",
            "Epoch 1774/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.4977 - acc: 0.7484 - val_loss: 0.6513 - val_acc: 0.6562\n",
            "Epoch 1775/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5307 - acc: 0.7222 - val_loss: 0.6129 - val_acc: 0.6875\n",
            "Epoch 1776/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5011 - acc: 0.7647 - val_loss: 0.6283 - val_acc: 0.6667\n",
            "Epoch 1777/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5119 - acc: 0.7582 - val_loss: 0.6122 - val_acc: 0.6667\n",
            "Epoch 1778/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.5348 - acc: 0.7304 - val_loss: 0.6227 - val_acc: 0.6771\n",
            "Epoch 1779/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 0.5166 - acc: 0.7516 - val_loss: 0.5897 - val_acc: 0.6875\n",
            "Epoch 1780/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 0.5116 - acc: 0.7271 - val_loss: 0.5872 - val_acc: 0.6562\n",
            "Epoch 1781/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.4829 - acc: 0.7614 - val_loss: 0.5968 - val_acc: 0.6354\n",
            "Epoch 1782/2000\n",
            "39/39 [==============================] - 9s 232ms/step - loss: 0.5061 - acc: 0.7516 - val_loss: 0.6232 - val_acc: 0.6562\n",
            "Epoch 1783/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 0.4892 - acc: 0.7582 - val_loss: 0.5985 - val_acc: 0.6667\n",
            "Epoch 1784/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5014 - acc: 0.7745 - val_loss: 0.5843 - val_acc: 0.6667\n",
            "Epoch 1785/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.4873 - acc: 0.7647 - val_loss: 0.5917 - val_acc: 0.6458\n",
            "Epoch 1786/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.5005 - acc: 0.7369 - val_loss: 0.6062 - val_acc: 0.6562\n",
            "Epoch 1787/2000\n",
            "39/39 [==============================] - 10s 234ms/step - loss: 0.5363 - acc: 0.7418 - val_loss: 0.5690 - val_acc: 0.6667\n",
            "Epoch 1788/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.5363 - acc: 0.7304 - val_loss: 0.6384 - val_acc: 0.6771\n",
            "Epoch 1789/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 0.5268 - acc: 0.7369 - val_loss: 0.6176 - val_acc: 0.6771\n",
            "Epoch 1790/2000\n",
            "39/39 [==============================] - 10s 233ms/step - loss: 0.5002 - acc: 0.7614 - val_loss: 0.5975 - val_acc: 0.6562\n",
            "Epoch 1791/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.4865 - acc: 0.7647 - val_loss: 0.5978 - val_acc: 0.6771\n",
            "Epoch 1792/2000\n",
            "39/39 [==============================] - 10s 238ms/step - loss: 0.5381 - acc: 0.7435 - val_loss: 0.5806 - val_acc: 0.6667\n",
            "Epoch 1793/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5007 - acc: 0.7500 - val_loss: 0.6176 - val_acc: 0.6667\n",
            "Epoch 1794/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.5389 - acc: 0.7435 - val_loss: 0.6153 - val_acc: 0.6458\n",
            "Epoch 1795/2000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 0.4912 - acc: 0.7756 - val_loss: 0.6446 - val_acc: 0.6458\n",
            "Epoch 1796/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5565 - acc: 0.7304 - val_loss: 0.6248 - val_acc: 0.6458\n",
            "Epoch 1797/2000\n",
            "39/39 [==============================] - 10s 241ms/step - loss: 0.4852 - acc: 0.7628 - val_loss: 0.6193 - val_acc: 0.6667\n",
            "Epoch 1798/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5006 - acc: 0.7582 - val_loss: 0.6074 - val_acc: 0.6562\n",
            "Epoch 1799/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 0.5397 - acc: 0.7206 - val_loss: 0.6495 - val_acc: 0.6458\n",
            "Epoch 1800/2000\n",
            "39/39 [==============================] - 10s 240ms/step - loss: 0.4863 - acc: 0.7788 - val_loss: 0.6119 - val_acc: 0.6458\n",
            "Epoch 1801/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.5262 - acc: 0.7435 - val_loss: 0.6265 - val_acc: 0.6354\n",
            "Epoch 1802/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5172 - acc: 0.7369 - val_loss: 0.6178 - val_acc: 0.6771\n",
            "Epoch 1803/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.4929 - acc: 0.7680 - val_loss: 0.6083 - val_acc: 0.6771\n",
            "Epoch 1804/2000\n",
            "39/39 [==============================] - 9s 234ms/step - loss: 0.4633 - acc: 0.7712 - val_loss: 0.6504 - val_acc: 0.6562\n",
            "Epoch 1805/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5032 - acc: 0.7484 - val_loss: 0.6138 - val_acc: 0.6354\n",
            "Epoch 1806/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5088 - acc: 0.7353 - val_loss: 0.6519 - val_acc: 0.6458\n",
            "Epoch 1807/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.5282 - acc: 0.7222 - val_loss: 0.6330 - val_acc: 0.6562\n",
            "Epoch 1808/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.4855 - acc: 0.7598 - val_loss: 0.6145 - val_acc: 0.6667\n",
            "Epoch 1809/2000\n",
            "39/39 [==============================] - 10s 241ms/step - loss: 0.5182 - acc: 0.7451 - val_loss: 0.6405 - val_acc: 0.6562\n",
            "Epoch 1810/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.4866 - acc: 0.7712 - val_loss: 0.6191 - val_acc: 0.6354\n",
            "Epoch 1811/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5175 - acc: 0.7288 - val_loss: 0.6368 - val_acc: 0.6458\n",
            "Epoch 1812/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.4973 - acc: 0.7696 - val_loss: 0.6029 - val_acc: 0.6354\n",
            "Epoch 1813/2000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 0.4804 - acc: 0.7712 - val_loss: 0.5961 - val_acc: 0.6667\n",
            "Epoch 1814/2000\n",
            "39/39 [==============================] - 9s 231ms/step - loss: 0.5136 - acc: 0.7418 - val_loss: 0.6408 - val_acc: 0.6562\n",
            "Epoch 1815/2000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 0.5109 - acc: 0.7484 - val_loss: 0.6353 - val_acc: 0.6562\n",
            "Epoch 1816/2000\n",
            "39/39 [==============================] - 10s 241ms/step - loss: 0.5196 - acc: 0.7451 - val_loss: 0.6150 - val_acc: 0.6667\n",
            "Epoch 1817/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 0.5462 - acc: 0.7206 - val_loss: 0.6170 - val_acc: 0.6354\n",
            "Epoch 1818/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 0.5132 - acc: 0.7533 - val_loss: 0.6574 - val_acc: 0.6458\n",
            "Epoch 1819/2000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 0.5750 - acc: 0.7271 - val_loss: 0.6285 - val_acc: 0.6667\n",
            "Epoch 1820/2000\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.5020 - acc: 0.7598 - val_loss: 0.6297 - val_acc: 0.6771\n",
            "Epoch 1821/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.5068 - acc: 0.7173 - val_loss: 0.6414 - val_acc: 0.6875\n",
            "Epoch 1822/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5087 - acc: 0.7631 - val_loss: 0.6393 - val_acc: 0.6667\n",
            "Epoch 1823/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5587 - acc: 0.7075 - val_loss: 0.6587 - val_acc: 0.6562\n",
            "Epoch 1824/2000\n",
            "39/39 [==============================] - 10s 239ms/step - loss: 0.4975 - acc: 0.7467 - val_loss: 0.6602 - val_acc: 0.6667\n",
            "Epoch 1825/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 0.4730 - acc: 0.7745 - val_loss: 0.6348 - val_acc: 0.6562\n",
            "Epoch 1826/2000\n",
            "39/39 [==============================] - 5s 113ms/step - loss: 0.4881 - acc: 0.7614 - val_loss: 0.6788 - val_acc: 0.6875\n",
            "Epoch 1827/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5398 - acc: 0.7271 - val_loss: 0.6587 - val_acc: 0.6875\n",
            "Epoch 1828/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.4803 - acc: 0.7696 - val_loss: 0.6038 - val_acc: 0.6667\n",
            "Epoch 1829/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.5470 - acc: 0.7320 - val_loss: 0.6169 - val_acc: 0.6562\n",
            "Epoch 1830/2000\n",
            "39/39 [==============================] - 10s 240ms/step - loss: 0.4936 - acc: 0.7565 - val_loss: 0.6015 - val_acc: 0.6562\n",
            "Epoch 1831/2000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 0.5173 - acc: 0.7435 - val_loss: 0.5986 - val_acc: 0.6562\n",
            "Epoch 1832/2000\n",
            "39/39 [==============================] - 10s 233ms/step - loss: 0.5123 - acc: 0.7402 - val_loss: 0.5892 - val_acc: 0.6771\n",
            "Epoch 1833/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5121 - acc: 0.7386 - val_loss: 0.6158 - val_acc: 0.6562\n",
            "Epoch 1834/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5230 - acc: 0.7582 - val_loss: 0.5943 - val_acc: 0.6667\n",
            "Epoch 1835/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.5258 - acc: 0.7320 - val_loss: 0.6078 - val_acc: 0.6667\n",
            "Epoch 1836/2000\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.5194 - acc: 0.7598 - val_loss: 0.6290 - val_acc: 0.6562\n",
            "Epoch 1837/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.4535 - acc: 0.7827 - val_loss: 0.6100 - val_acc: 0.6562\n",
            "Epoch 1838/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 0.5130 - acc: 0.7418 - val_loss: 0.6078 - val_acc: 0.6771\n",
            "Epoch 1839/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5028 - acc: 0.7680 - val_loss: 0.5940 - val_acc: 0.6354\n",
            "Epoch 1840/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.4982 - acc: 0.7565 - val_loss: 0.5924 - val_acc: 0.6771\n",
            "Epoch 1841/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.4840 - acc: 0.7533 - val_loss: 0.5851 - val_acc: 0.6667\n",
            "Epoch 1842/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.4793 - acc: 0.7745 - val_loss: 0.6278 - val_acc: 0.6562\n",
            "Epoch 1843/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 0.4784 - acc: 0.7647 - val_loss: 0.6062 - val_acc: 0.6667\n",
            "Epoch 1844/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 0.5379 - acc: 0.7484 - val_loss: 0.6113 - val_acc: 0.6562\n",
            "Epoch 1845/2000\n",
            "39/39 [==============================] - 9s 236ms/step - loss: 0.5062 - acc: 0.7614 - val_loss: 0.6014 - val_acc: 0.6458\n",
            "Epoch 1846/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.5177 - acc: 0.7724 - val_loss: 0.6241 - val_acc: 0.6458\n",
            "Epoch 1847/2000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 0.5069 - acc: 0.7663 - val_loss: 0.6139 - val_acc: 0.6667\n",
            "Epoch 1848/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.5202 - acc: 0.7631 - val_loss: 0.6006 - val_acc: 0.6354\n",
            "Epoch 1849/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.5006 - acc: 0.7533 - val_loss: 0.5926 - val_acc: 0.6458\n",
            "Epoch 1850/2000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 0.5474 - acc: 0.7435 - val_loss: 0.5946 - val_acc: 0.6458\n",
            "Epoch 1851/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.5251 - acc: 0.7402 - val_loss: 0.5895 - val_acc: 0.6250\n",
            "Epoch 1852/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 0.5205 - acc: 0.7402 - val_loss: 0.5806 - val_acc: 0.6354\n",
            "Epoch 1853/2000\n",
            "39/39 [==============================] - 10s 228ms/step - loss: 0.4922 - acc: 0.7631 - val_loss: 0.6194 - val_acc: 0.6562\n",
            "Epoch 1854/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 0.4848 - acc: 0.7614 - val_loss: 0.5887 - val_acc: 0.6562\n",
            "Epoch 1855/2000\n",
            "39/39 [==============================] - 9s 232ms/step - loss: 0.4967 - acc: 0.7778 - val_loss: 0.5627 - val_acc: 0.6562\n",
            "Epoch 1856/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5118 - acc: 0.7402 - val_loss: 0.5733 - val_acc: 0.6458\n",
            "Epoch 1857/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.5505 - acc: 0.7500 - val_loss: 0.5989 - val_acc: 0.6562\n",
            "Epoch 1858/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.5179 - acc: 0.7418 - val_loss: 0.6002 - val_acc: 0.6562\n",
            "Epoch 1859/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.5569 - acc: 0.7304 - val_loss: 0.6062 - val_acc: 0.6562\n",
            "Epoch 1860/2000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 0.4945 - acc: 0.7549 - val_loss: 0.6136 - val_acc: 0.6562\n",
            "Epoch 1861/2000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 0.4743 - acc: 0.7696 - val_loss: 0.5873 - val_acc: 0.6667\n",
            "Epoch 1862/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5421 - acc: 0.7337 - val_loss: 0.5878 - val_acc: 0.6771\n",
            "Epoch 1863/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.5278 - acc: 0.7451 - val_loss: 0.5872 - val_acc: 0.6667\n",
            "Epoch 1864/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5214 - acc: 0.7484 - val_loss: 0.6005 - val_acc: 0.6875\n",
            "Epoch 1865/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5443 - acc: 0.7402 - val_loss: 0.5913 - val_acc: 0.6667\n",
            "Epoch 1866/2000\n",
            "39/39 [==============================] - 5s 100ms/step - loss: 0.5234 - acc: 0.7353 - val_loss: 0.6300 - val_acc: 0.6667\n",
            "Epoch 1867/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5109 - acc: 0.7386 - val_loss: 0.5996 - val_acc: 0.6771\n",
            "Epoch 1868/2000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 0.5198 - acc: 0.7500 - val_loss: 0.6048 - val_acc: 0.6667\n",
            "Epoch 1869/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.4724 - acc: 0.7827 - val_loss: 0.5878 - val_acc: 0.6875\n",
            "Epoch 1870/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5022 - acc: 0.7696 - val_loss: 0.6280 - val_acc: 0.6667\n",
            "Epoch 1871/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.4633 - acc: 0.7696 - val_loss: 0.5891 - val_acc: 0.6667\n",
            "Epoch 1872/2000\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 0.5652 - acc: 0.7320 - val_loss: 0.5907 - val_acc: 0.6667\n",
            "Epoch 1873/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 0.5089 - acc: 0.7467 - val_loss: 0.6064 - val_acc: 0.6562\n",
            "Epoch 1874/2000\n",
            "39/39 [==============================] - 5s 99ms/step - loss: 0.5316 - acc: 0.7320 - val_loss: 0.6079 - val_acc: 0.6562\n",
            "Epoch 1875/2000\n",
            "39/39 [==============================] - 5s 101ms/step - loss: 0.4927 - acc: 0.7516 - val_loss: 0.6162 - val_acc: 0.6562\n",
            "Epoch 1876/2000\n",
            "39/39 [==============================] - 10s 239ms/step - loss: 0.4965 - acc: 0.7614 - val_loss: 0.6058 - val_acc: 0.6458\n",
            "Epoch 1877/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.4964 - acc: 0.7631 - val_loss: 0.5993 - val_acc: 0.6458\n",
            "Epoch 1878/2000\n",
            "39/39 [==============================] - 10s 238ms/step - loss: 0.5345 - acc: 0.7418 - val_loss: 0.5873 - val_acc: 0.6667\n",
            "Epoch 1879/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5102 - acc: 0.7729 - val_loss: 0.6138 - val_acc: 0.6458\n",
            "Epoch 1880/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.4835 - acc: 0.7533 - val_loss: 0.6120 - val_acc: 0.6250\n",
            "Epoch 1881/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.5509 - acc: 0.7288 - val_loss: 0.6020 - val_acc: 0.6667\n",
            "Epoch 1882/2000\n",
            "39/39 [==============================] - 5s 119ms/step - loss: 0.5065 - acc: 0.7500 - val_loss: 0.6039 - val_acc: 0.6354\n",
            "Epoch 1883/2000\n",
            "39/39 [==============================] - 9s 231ms/step - loss: 0.4730 - acc: 0.7631 - val_loss: 0.5922 - val_acc: 0.6771\n",
            "Epoch 1884/2000\n",
            "39/39 [==============================] - 5s 112ms/step - loss: 0.4996 - acc: 0.7729 - val_loss: 0.6122 - val_acc: 0.6667\n",
            "Epoch 1885/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5167 - acc: 0.7418 - val_loss: 0.5793 - val_acc: 0.6875\n",
            "Epoch 1886/2000\n",
            "39/39 [==============================] - 5s 115ms/step - loss: 0.5561 - acc: 0.7222 - val_loss: 0.5989 - val_acc: 0.6979\n",
            "Epoch 1887/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5037 - acc: 0.7500 - val_loss: 0.6091 - val_acc: 0.6667\n",
            "Epoch 1888/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 0.5070 - acc: 0.7598 - val_loss: 0.6098 - val_acc: 0.6562\n",
            "Epoch 1889/2000\n",
            "39/39 [==============================] - 5s 101ms/step - loss: 0.5130 - acc: 0.7386 - val_loss: 0.6328 - val_acc: 0.6562\n",
            "Epoch 1890/2000\n",
            "39/39 [==============================] - 10s 237ms/step - loss: 0.5424 - acc: 0.7157 - val_loss: 0.6026 - val_acc: 0.6562\n",
            "Epoch 1891/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 0.5143 - acc: 0.7451 - val_loss: 0.6275 - val_acc: 0.6458\n",
            "Epoch 1892/2000\n",
            "39/39 [==============================] - 5s 115ms/step - loss: 0.4804 - acc: 0.7598 - val_loss: 0.5949 - val_acc: 0.6458\n",
            "Epoch 1893/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.4922 - acc: 0.7810 - val_loss: 0.6082 - val_acc: 0.6667\n",
            "Epoch 1894/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.4811 - acc: 0.7614 - val_loss: 0.5957 - val_acc: 0.6562\n",
            "Epoch 1895/2000\n",
            "39/39 [==============================] - 9s 233ms/step - loss: 0.5176 - acc: 0.7402 - val_loss: 0.5942 - val_acc: 0.6667\n",
            "Epoch 1896/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 0.5461 - acc: 0.7320 - val_loss: 0.6079 - val_acc: 0.6458\n",
            "Epoch 1897/2000\n",
            "39/39 [==============================] - 10s 241ms/step - loss: 0.4869 - acc: 0.7647 - val_loss: 0.5940 - val_acc: 0.6667\n",
            "Epoch 1898/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.4693 - acc: 0.7712 - val_loss: 0.6136 - val_acc: 0.6562\n",
            "Epoch 1899/2000\n",
            "39/39 [==============================] - 10s 234ms/step - loss: 0.5181 - acc: 0.7516 - val_loss: 0.6019 - val_acc: 0.6771\n",
            "Epoch 1900/2000\n",
            "39/39 [==============================] - 4s 105ms/step - loss: 0.5138 - acc: 0.7598 - val_loss: 0.5976 - val_acc: 0.6042\n",
            "Epoch 1901/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.4977 - acc: 0.7500 - val_loss: 0.6195 - val_acc: 0.6875\n",
            "Epoch 1902/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5144 - acc: 0.7418 - val_loss: 0.6381 - val_acc: 0.6458\n",
            "Epoch 1903/2000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 0.5413 - acc: 0.7035 - val_loss: 0.5970 - val_acc: 0.6771\n",
            "Epoch 1904/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5067 - acc: 0.7500 - val_loss: 0.6288 - val_acc: 0.6875\n",
            "Epoch 1905/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5100 - acc: 0.7500 - val_loss: 0.6105 - val_acc: 0.6562\n",
            "Epoch 1906/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.4712 - acc: 0.7549 - val_loss: 0.6027 - val_acc: 0.6562\n",
            "Epoch 1907/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.4927 - acc: 0.7729 - val_loss: 0.6040 - val_acc: 0.6667\n",
            "Epoch 1908/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 0.5183 - acc: 0.7467 - val_loss: 0.5978 - val_acc: 0.6771\n",
            "Epoch 1909/2000\n",
            "39/39 [==============================] - 10s 229ms/step - loss: 0.5147 - acc: 0.7451 - val_loss: 0.6106 - val_acc: 0.6562\n",
            "Epoch 1910/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.5138 - acc: 0.7549 - val_loss: 0.6006 - val_acc: 0.6562\n",
            "Epoch 1911/2000\n",
            "39/39 [==============================] - 10s 235ms/step - loss: 0.5087 - acc: 0.7353 - val_loss: 0.6143 - val_acc: 0.6562\n",
            "Epoch 1912/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 0.5061 - acc: 0.7533 - val_loss: 0.6112 - val_acc: 0.6562\n",
            "Epoch 1913/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5353 - acc: 0.7288 - val_loss: 0.5782 - val_acc: 0.6458\n",
            "Epoch 1914/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 0.5092 - acc: 0.7420 - val_loss: 0.6107 - val_acc: 0.6562\n",
            "Epoch 1915/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5187 - acc: 0.7827 - val_loss: 0.5905 - val_acc: 0.6667\n",
            "Epoch 1916/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.4935 - acc: 0.7712 - val_loss: 0.6094 - val_acc: 0.6562\n",
            "Epoch 1917/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 0.5416 - acc: 0.7451 - val_loss: 0.5883 - val_acc: 0.6250\n",
            "Epoch 1918/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.5420 - acc: 0.7467 - val_loss: 0.6069 - val_acc: 0.6771\n",
            "Epoch 1919/2000\n",
            "39/39 [==============================] - 10s 226ms/step - loss: 0.4960 - acc: 0.7756 - val_loss: 0.5911 - val_acc: 0.6875\n",
            "Epoch 1920/2000\n",
            "39/39 [==============================] - 10s 242ms/step - loss: 0.5268 - acc: 0.7402 - val_loss: 0.6043 - val_acc: 0.6667\n",
            "Epoch 1921/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.5487 - acc: 0.7435 - val_loss: 0.5755 - val_acc: 0.6875\n",
            "Epoch 1922/2000\n",
            "39/39 [==============================] - 5s 131ms/step - loss: 0.5226 - acc: 0.7304 - val_loss: 0.6235 - val_acc: 0.6667\n",
            "Epoch 1923/2000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 0.4880 - acc: 0.7467 - val_loss: 0.5975 - val_acc: 0.6875\n",
            "Epoch 1924/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5249 - acc: 0.7292 - val_loss: 0.5960 - val_acc: 0.6562\n",
            "Epoch 1925/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.4886 - acc: 0.7500 - val_loss: 0.5993 - val_acc: 0.6875\n",
            "Epoch 1926/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.5095 - acc: 0.7565 - val_loss: 0.5789 - val_acc: 0.6875\n",
            "Epoch 1927/2000\n",
            "39/39 [==============================] - 6s 145ms/step - loss: 0.4621 - acc: 0.7810 - val_loss: 0.6281 - val_acc: 0.6562\n",
            "Epoch 1928/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.5164 - acc: 0.7582 - val_loss: 0.6039 - val_acc: 0.6146\n",
            "Epoch 1929/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.5324 - acc: 0.7386 - val_loss: 0.6033 - val_acc: 0.6562\n",
            "Epoch 1930/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 0.4725 - acc: 0.7827 - val_loss: 0.6077 - val_acc: 0.6667\n",
            "Epoch 1931/2000\n",
            "39/39 [==============================] - 6s 130ms/step - loss: 0.4693 - acc: 0.7729 - val_loss: 0.6014 - val_acc: 0.6458\n",
            "Epoch 1932/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 0.5056 - acc: 0.7598 - val_loss: 0.6000 - val_acc: 0.6667\n",
            "Epoch 1933/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.5352 - acc: 0.7369 - val_loss: 0.5925 - val_acc: 0.6771\n",
            "Epoch 1934/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 0.5047 - acc: 0.7582 - val_loss: 0.5886 - val_acc: 0.6667\n",
            "Epoch 1935/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.5022 - acc: 0.7418 - val_loss: 0.6197 - val_acc: 0.6458\n",
            "Epoch 1936/2000\n",
            "39/39 [==============================] - 10s 233ms/step - loss: 0.4806 - acc: 0.7631 - val_loss: 0.6066 - val_acc: 0.6667\n",
            "Epoch 1937/2000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 0.5077 - acc: 0.7565 - val_loss: 0.6366 - val_acc: 0.6458\n",
            "Epoch 1938/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5034 - acc: 0.7484 - val_loss: 0.6069 - val_acc: 0.6875\n",
            "Epoch 1939/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5090 - acc: 0.7696 - val_loss: 0.6246 - val_acc: 0.6458\n",
            "Epoch 1940/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.4902 - acc: 0.7631 - val_loss: 0.6217 - val_acc: 0.6667\n",
            "Epoch 1941/2000\n",
            "39/39 [==============================] - 5s 122ms/step - loss: 0.5062 - acc: 0.7582 - val_loss: 0.6207 - val_acc: 0.6771\n",
            "Epoch 1942/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.5251 - acc: 0.7402 - val_loss: 0.6336 - val_acc: 0.6667\n",
            "Epoch 1943/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.5188 - acc: 0.7418 - val_loss: 0.6382 - val_acc: 0.6562\n",
            "Epoch 1944/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.4904 - acc: 0.7467 - val_loss: 0.6075 - val_acc: 0.6250\n",
            "Epoch 1945/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 0.5227 - acc: 0.7337 - val_loss: 0.5896 - val_acc: 0.6562\n",
            "Epoch 1946/2000\n",
            "39/39 [==============================] - 9s 233ms/step - loss: 0.5353 - acc: 0.7663 - val_loss: 0.6054 - val_acc: 0.6146\n",
            "Epoch 1947/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5233 - acc: 0.7467 - val_loss: 0.5963 - val_acc: 0.6562\n",
            "Epoch 1948/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.5174 - acc: 0.7614 - val_loss: 0.5924 - val_acc: 0.6354\n",
            "Epoch 1949/2000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 0.4967 - acc: 0.7614 - val_loss: 0.6004 - val_acc: 0.6562\n",
            "Epoch 1950/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 0.5138 - acc: 0.7500 - val_loss: 0.6136 - val_acc: 0.6771\n",
            "Epoch 1951/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 0.5054 - acc: 0.7467 - val_loss: 0.6230 - val_acc: 0.6771\n",
            "Epoch 1952/2000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 0.5321 - acc: 0.7239 - val_loss: 0.6240 - val_acc: 0.6771\n",
            "Epoch 1953/2000\n",
            "39/39 [==============================] - 5s 98ms/step - loss: 0.5409 - acc: 0.7255 - val_loss: 0.6167 - val_acc: 0.6562\n",
            "Epoch 1954/2000\n",
            "39/39 [==============================] - 6s 140ms/step - loss: 0.5010 - acc: 0.7598 - val_loss: 0.5997 - val_acc: 0.6667\n",
            "Epoch 1955/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 0.4868 - acc: 0.7761 - val_loss: 0.6012 - val_acc: 0.6667\n",
            "Epoch 1956/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5134 - acc: 0.7451 - val_loss: 0.6074 - val_acc: 0.6667\n",
            "Epoch 1957/2000\n",
            "39/39 [==============================] - 10s 239ms/step - loss: 0.5136 - acc: 0.7435 - val_loss: 0.6229 - val_acc: 0.6458\n",
            "Epoch 1958/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.5176 - acc: 0.7435 - val_loss: 0.6140 - val_acc: 0.6667\n",
            "Epoch 1959/2000\n",
            "39/39 [==============================] - 10s 228ms/step - loss: 0.4849 - acc: 0.7696 - val_loss: 0.6104 - val_acc: 0.6562\n",
            "Epoch 1960/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.4961 - acc: 0.7500 - val_loss: 0.6274 - val_acc: 0.6667\n",
            "Epoch 1961/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.5195 - acc: 0.7467 - val_loss: 0.6318 - val_acc: 0.6771\n",
            "Epoch 1962/2000\n",
            "39/39 [==============================] - 9s 233ms/step - loss: 0.5310 - acc: 0.7190 - val_loss: 0.5925 - val_acc: 0.6354\n",
            "Epoch 1963/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.4928 - acc: 0.7598 - val_loss: 0.5905 - val_acc: 0.6458\n",
            "Epoch 1964/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.4673 - acc: 0.7712 - val_loss: 0.6032 - val_acc: 0.6354\n",
            "Epoch 1965/2000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 0.5350 - acc: 0.7288 - val_loss: 0.5808 - val_acc: 0.6667\n",
            "Epoch 1966/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 0.5001 - acc: 0.7516 - val_loss: 0.5638 - val_acc: 0.6562\n",
            "Epoch 1967/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.5262 - acc: 0.7549 - val_loss: 0.5798 - val_acc: 0.6146\n",
            "Epoch 1968/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5210 - acc: 0.7451 - val_loss: 0.5959 - val_acc: 0.6354\n",
            "Epoch 1969/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.4974 - acc: 0.7549 - val_loss: 0.6095 - val_acc: 0.6667\n",
            "Epoch 1970/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5362 - acc: 0.7565 - val_loss: 0.5833 - val_acc: 0.6667\n",
            "Epoch 1971/2000\n",
            "39/39 [==============================] - 10s 239ms/step - loss: 0.5141 - acc: 0.7680 - val_loss: 0.5979 - val_acc: 0.6667\n",
            "Epoch 1972/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 0.4897 - acc: 0.7565 - val_loss: 0.6026 - val_acc: 0.6875\n",
            "Epoch 1973/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 0.5020 - acc: 0.7680 - val_loss: 0.6000 - val_acc: 0.6771\n",
            "Epoch 1974/2000\n",
            "39/39 [==============================] - 10s 239ms/step - loss: 0.5042 - acc: 0.7614 - val_loss: 0.5778 - val_acc: 0.6667\n",
            "Epoch 1975/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5364 - acc: 0.7288 - val_loss: 0.5846 - val_acc: 0.6458\n",
            "Epoch 1976/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 0.5433 - acc: 0.7222 - val_loss: 0.5959 - val_acc: 0.6771\n",
            "Epoch 1977/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 0.5057 - acc: 0.7516 - val_loss: 0.6037 - val_acc: 0.6979\n",
            "Epoch 1978/2000\n",
            "39/39 [==============================] - 10s 239ms/step - loss: 0.5161 - acc: 0.7451 - val_loss: 0.6097 - val_acc: 0.6562\n",
            "Epoch 1979/2000\n",
            "39/39 [==============================] - 5s 113ms/step - loss: 0.5069 - acc: 0.7320 - val_loss: 0.5872 - val_acc: 0.6771\n",
            "Epoch 1980/2000\n",
            "39/39 [==============================] - 10s 234ms/step - loss: 0.5088 - acc: 0.7614 - val_loss: 0.6318 - val_acc: 0.6562\n",
            "Epoch 1981/2000\n",
            "39/39 [==============================] - 9s 233ms/step - loss: 0.5234 - acc: 0.7468 - val_loss: 0.6204 - val_acc: 0.6667\n",
            "Epoch 1982/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 0.4809 - acc: 0.7663 - val_loss: 0.6088 - val_acc: 0.6458\n",
            "Epoch 1983/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 0.5568 - acc: 0.7206 - val_loss: 0.6419 - val_acc: 0.6458\n",
            "Epoch 1984/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.5505 - acc: 0.7157 - val_loss: 0.6328 - val_acc: 0.6771\n",
            "Epoch 1985/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 0.4791 - acc: 0.7761 - val_loss: 0.6196 - val_acc: 0.6146\n",
            "Epoch 1986/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 0.4972 - acc: 0.7484 - val_loss: 0.6221 - val_acc: 0.6354\n",
            "Epoch 1987/2000\n",
            "39/39 [==============================] - 10s 235ms/step - loss: 0.4872 - acc: 0.7598 - val_loss: 0.6352 - val_acc: 0.6771\n",
            "Epoch 1988/2000\n",
            "39/39 [==============================] - 9s 234ms/step - loss: 0.5449 - acc: 0.7222 - val_loss: 0.6238 - val_acc: 0.6458\n",
            "Epoch 1989/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 0.4819 - acc: 0.7712 - val_loss: 0.6071 - val_acc: 0.6562\n",
            "Epoch 1990/2000\n",
            "39/39 [==============================] - 10s 238ms/step - loss: 0.4999 - acc: 0.7631 - val_loss: 0.5952 - val_acc: 0.6354\n",
            "Epoch 1991/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5263 - acc: 0.7353 - val_loss: 0.6003 - val_acc: 0.6458\n",
            "Epoch 1992/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.5202 - acc: 0.7369 - val_loss: 0.6101 - val_acc: 0.6667\n",
            "Epoch 1993/2000\n",
            "39/39 [==============================] - 10s 236ms/step - loss: 0.5000 - acc: 0.7516 - val_loss: 0.5948 - val_acc: 0.6771\n",
            "Epoch 1994/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5283 - acc: 0.7353 - val_loss: 0.6055 - val_acc: 0.6771\n",
            "Epoch 1995/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.4791 - acc: 0.7549 - val_loss: 0.6178 - val_acc: 0.6667\n",
            "Epoch 1996/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 0.5177 - acc: 0.7582 - val_loss: 0.6127 - val_acc: 0.6667\n",
            "Epoch 1997/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 0.5110 - acc: 0.7467 - val_loss: 0.6162 - val_acc: 0.6562\n",
            "Epoch 1998/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.5381 - acc: 0.7500 - val_loss: 0.6056 - val_acc: 0.6354\n",
            "Epoch 1999/2000\n",
            "39/39 [==============================] - 6s 141ms/step - loss: 0.5181 - acc: 0.7582 - val_loss: 0.6183 - val_acc: 0.6562\n",
            "Epoch 2000/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 0.4940 - acc: 0.7533 - val_loss: 0.6042 - val_acc: 0.6562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot training performance"
      ],
      "metadata": {
        "id": "YFxMJycOpEew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'co', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'k', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'co', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "     "
      ],
      "metadata": {
        "id": "l9PYKbRNpEK8",
        "outputId": "8cd38a36-677e-4a0f-b40c-ebe1b381d2e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SAVE model"
      ],
      "metadata": {
        "id": "kNtlq_LZpKNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('./content/drive/My Drive/new', exist_ok=True)\n",
        "model.save('./content/drive/My Drive/new/2Class_UNfreeze_newdata.h5')"
      ],
      "metadata": {
        "id": "TegSVqblpLEZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "KdsdaIgMpMeG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"./content/drive/My Drive/new/2Class_UNfreeze_newdata.h5\")"
      ],
      "metadata": {
        "id": "sZFZ1c_kpMcN",
        "outputId": "654833ed-ed15-47bd-92fa-fc70113080d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e73bb77f-3775-4c9a-b79c-471f58e95ec5\", \"2Class_UNfreeze_newdata.h5\", 16602472)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gEfCB1RfpMZ6"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}