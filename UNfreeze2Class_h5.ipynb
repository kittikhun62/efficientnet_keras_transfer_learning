{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNsBunsu+uGK3ZfP7JT+XN8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kittikhun62/efficientnet_keras_transfer_learning/blob/master/UNfreeze2Class_h5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# import from drive"
      ],
      "metadata": {
        "id": "bB2gfuYWczY-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpXyZ9k5YIJu",
        "outputId": "fb953f8a-e13f-4177-e1f4-e531cddfa88c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (r'/content/drive/My Drive/data - 2 class.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "7mqo2OLAc2pG",
        "outputId": "27316e89-6d5e-4a4a-b498-947d93a0134e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      No                      Name_file  \\\n",
              "0      1                        pore-sb   \n",
              "1      2                        pore-sb   \n",
              "2      3                        pore-sb   \n",
              "3      4                        pore-sb   \n",
              "4      5                        pore-sb   \n",
              "..   ...                            ...   \n",
              "795  796  1-s2.0-S2095268622000210-main   \n",
              "796  797  1-s2.0-S2095268622000210-main   \n",
              "797  798  1-s2.0-S2095268622000210-main   \n",
              "798  799  1-s2.0-S2095268622000210-main   \n",
              "799  800  1-s2.0-S2095268622000210-main   \n",
              "\n",
              "                                            Name_Paper  \\\n",
              "0    Preparation and electrochemical behaviour of b...   \n",
              "1    Preparation and electrochemical behaviour of b...   \n",
              "2    Preparation and electrochemical behaviour of b...   \n",
              "3    Preparation and electrochemical behaviour of b...   \n",
              "4    Preparation and electrochemical behaviour of b...   \n",
              "..                                                 ...   \n",
              "795  Integration of preparation of K, Na-embedded a...   \n",
              "796  Integration of preparation of K, Na-embedded a...   \n",
              "797  Integration of preparation of K, Na-embedded a...   \n",
              "798  Integration of preparation of K, Na-embedded a...   \n",
              "799  Integration of preparation of K, Na-embedded a...   \n",
              "\n",
              "                                               journal  \\\n",
              "0                                  Korean J. Chem. Eng   \n",
              "1                                  Korean J. Chem. Eng   \n",
              "2                                  Korean J. Chem. Eng   \n",
              "3                                  Korean J. Chem. Eng   \n",
              "4                                  Korean J. Chem. Eng   \n",
              "..                                                 ...   \n",
              "795  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "796  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "797  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "798  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "799  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "\n",
              "                                          path_Picture  detail  Class     BET  \\\n",
              "0    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom1  0-800  135.06   \n",
              "1    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom2  0-800  135.06   \n",
              "2    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom3  0-800  135.06   \n",
              "3    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom4  0-800  135.06   \n",
              "4    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom5  0-800  135.06   \n",
              "..                                                 ...     ...    ...     ...   \n",
              "795  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom21  0-800  301.70   \n",
              "796  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom22  0-800  301.70   \n",
              "797  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom23  0-800  301.70   \n",
              "798  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom24  0-800  301.70   \n",
              "799  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom25  0-800  301.70   \n",
              "\n",
              "     Size(mico)  \n",
              "0            10  \n",
              "1            10  \n",
              "2            10  \n",
              "3            10  \n",
              "4            10  \n",
              "..          ...  \n",
              "795          10  \n",
              "796          10  \n",
              "797          10  \n",
              "798          10  \n",
              "799          10  \n",
              "\n",
              "[800 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-308014db-f518-48ce-8e88-0466a4e0fb11\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>No</th>\n",
              "      <th>Name_file</th>\n",
              "      <th>Name_Paper</th>\n",
              "      <th>journal</th>\n",
              "      <th>path_Picture</th>\n",
              "      <th>detail</th>\n",
              "      <th>Class</th>\n",
              "      <th>BET</th>\n",
              "      <th>Size(mico)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom1</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom2</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom3</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom4</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom5</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>795</th>\n",
              "      <td>796</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom21</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>796</th>\n",
              "      <td>797</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom22</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>797</th>\n",
              "      <td>798</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom23</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>798</th>\n",
              "      <td>799</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom24</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799</th>\n",
              "      <td>800</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom25</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>800 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-308014db-f518-48ce-8e88-0466a4e0fb11')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-308014db-f518-48ce-8e88-0466a4e0fb11 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-308014db-f518-48ce-8e88-0466a4e0fb11');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports library"
      ],
      "metadata": {
        "id": "VkYa-4LeTbir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "myAsBcVhTW7j"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## hyper parameter\n"
      ],
      "metadata": {
        "id": "T529UM_tVV-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "width = 150\n",
        "height = 150\n",
        "\n",
        "epochs = 1000 #จำนวนรอบในการ Train\n",
        "\n",
        "NUM_TRAIN = 598  # จำนวนภาพ Train\n",
        "NUM_TEST = 101 #จำนวนภาพ Test\n",
        "\n",
        "dropout_rate = 0.3\n",
        "input_shape = (height, width, 3) #ขนาด image enter"
      ],
      "metadata": {
        "id": "zXpmkJ2GVZ1l"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone efficientnet repo"
      ],
      "metadata": {
        "id": "DSSZIFGhUyQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/"
      ],
      "metadata": {
        "id": "nFvKcuBDTj1N",
        "outputId": "cb940a22-b1fc-4632-baa5-151992045aab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 837, done.\u001b[K\n",
            "remote: Counting objects: 100% (359/359), done.\u001b[K\n",
            "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
            "remote: Total 837 (delta 255), reused 328 (delta 235), pack-reused 478\u001b[K\n",
            "Receiving objects: 100% (837/837), 13.82 MiB | 38.55 MiB/s, done.\n",
            "Resolving deltas: 100% (495/495), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import efficientnet and load the conv base model"
      ],
      "metadata": {
        "id": "j3EgSOiSZHaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "iI3DQ18HU2TF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "#EfficientNet สร้างขึ้นสำหรับการจำแนกประเภท ImageNet ประกอบด้วยป้ายกำกับคลาส 1,000 รายการ เรามีเพียง 2 เลเยอร์เท่านั้น ซึ่งหมายความว่าเลเยอร์สองสามเลเยอร์สุดท้ายสำหรับการจำแนกไม่มีประโยชน์สำหรับเรา สามารถยกเว้นได้ขณะโหลดโมเดลโดยระบุอาร์กิวเมนต์ include_top เป็น False และนำไปใช้กับโมเดล ImageNet อื่นๆ ที่มีอยู่ในแอปพลิเคชัน Keras เช่นกัน\n",
        "\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "UmBDAgF_VAjq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b9f16fc-699d-4e29-de08-6d1a5548dade"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "id": "rRXoFFzfU2Oi",
        "outputId": "b9fbf97a-951e-42c8-ced5-b2e7f0a163a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 4,007,548\n",
            "Non-trainable params: 42,016\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/new/2Class.h5')\n",
        "\n",
        "from efficientnet.layers import Swish, DropConnect\n",
        "from efficientnet.model import ConvKernalInitializer\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "\n",
        "get_custom_objects().update({\n",
        "    'ConvKernalInitializer': ConvKernalInitializer,\n",
        "    'Swish': Swish,\n",
        "    'DropConnect':DropConnect\n",
        "})"
      ],
      "metadata": {
        "id": "MwNk3sNbc2Qx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load model \n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/drive/My Drive/new/2Class.h5')\n",
        "height = width = model.input_shape[1]"
      ],
      "metadata": {
        "id": "4v4nzKQtJZ4z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/My Drive/new project'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Directories for our training,\n",
        "# validation and test splits\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.makedirs(test_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "UDxvF-b8Jcq1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, # image input 0-255 --> 0-1 เปลี่ยนค่าสี\n",
        "      rotation_range=40,# หมุนภาพในองศา\n",
        "      width_shift_range=0.2, #เปลี่ยนความกว้าง\n",
        "      height_shift_range=0.2, #ปลี่ยนความสูง\n",
        "      shear_range=0.2, #ทำให้ภาพเบี้ยว\n",
        "      zoom_range=0.2, # Randomly zoom image\n",
        "      horizontal_flip=True, \n",
        "      #โดย Default เมื่อมีการเลื่อนภาพ บิดภาพ หมุนภาพ จะเกิดพื้นที่ว่างที่มุม \n",
        "      #ซึ่งจะมีการเติมภาพให้เต็มโดยใช้เทคนิคแบบ Nearest neighbor ซึ่งเป็นการดึงสีบริเวณใหล้าเคียงมาระบายให้เต็ม แต่เราก็ยังสามารถกำหนดวิธีการ Fill ภาพด้วยเทคนิคอื่นได้จาก Parameter fill_mode\n",
        "      fill_mode='nearest')\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory #ไดเรกเป้าหมาย\n",
        "        train_dir,\n",
        "        # รูปภาพทั้งหมดจะถูกปรับขนาดตามความสูงและความกว้างของเป้าหมาย\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        #เนื่องจากเราใช้ categorical_crossentropy loss เราจึงต้องมีป้ายกำกับตามหมวดหมู่\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory( #การดึงภาพจาก Directory มาเข้าโมเดล \n",
        "        validation_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "     \n",
        "\n"
      ],
      "metadata": {
        "id": "znE38DtIJeN-",
        "outputId": "b8047dc7-86c7-49e6-b0cf-06330711e3cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 598 images belonging to 2 classes.\n",
            "Found 101 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multiply_16\n",
        "# set 'multiply_16' and following layers trainable\n",
        "model.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'multiply_16':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False  \n",
        "     "
      ],
      "metadata": {
        "id": "tEaPoHJCJq13"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "IC-3EwwkJHGS",
        "outputId": "7c010934-f383-42b7-d2f3-6917e117623e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 2)                 2562      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,052,126\n",
            "Trainable params: 4,010,110\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "z7ERVUfUJsQq",
        "outputId": "ede173d4-9691-4fd4-8bcc-9818be1a22cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-caa7b37242a8>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "37/37 [==============================] - 48s 955ms/step - loss: 0.5632 - acc: 0.7251 - val_loss: 0.7091 - val_acc: 0.5417\n",
            "Epoch 2/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5404 - acc: 0.7182 - val_loss: 0.7097 - val_acc: 0.5938\n",
            "Epoch 3/1000\n",
            "37/37 [==============================] - 3s 70ms/step - loss: 0.5619 - acc: 0.7216 - val_loss: 0.7105 - val_acc: 0.5208\n",
            "Epoch 4/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5637 - acc: 0.7113 - val_loss: 0.7029 - val_acc: 0.6042\n",
            "Epoch 5/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.5468 - acc: 0.7423 - val_loss: 0.7131 - val_acc: 0.5833\n",
            "Epoch 6/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.5270 - acc: 0.7337 - val_loss: 0.7056 - val_acc: 0.5938\n",
            "Epoch 7/1000\n",
            "37/37 [==============================] - 3s 70ms/step - loss: 0.5274 - acc: 0.7320 - val_loss: 0.7135 - val_acc: 0.5312\n",
            "Epoch 8/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.5523 - acc: 0.7320 - val_loss: 0.7108 - val_acc: 0.5729\n",
            "Epoch 9/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.5297 - acc: 0.7251 - val_loss: 0.7022 - val_acc: 0.5938\n",
            "Epoch 10/1000\n",
            "37/37 [==============================] - 8s 202ms/step - loss: 0.5474 - acc: 0.7302 - val_loss: 0.7201 - val_acc: 0.5833\n",
            "Epoch 11/1000\n",
            "37/37 [==============================] - 8s 207ms/step - loss: 0.5667 - acc: 0.7131 - val_loss: 0.7212 - val_acc: 0.5938\n",
            "Epoch 12/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5449 - acc: 0.7010 - val_loss: 0.6991 - val_acc: 0.6042\n",
            "Epoch 13/1000\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.5334 - acc: 0.7285 - val_loss: 0.7168 - val_acc: 0.5625\n",
            "Epoch 14/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.5414 - acc: 0.7388 - val_loss: 0.7203 - val_acc: 0.5417\n",
            "Epoch 15/1000\n",
            "37/37 [==============================] - 8s 207ms/step - loss: 0.5236 - acc: 0.7354 - val_loss: 0.7126 - val_acc: 0.5729\n",
            "Epoch 16/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5508 - acc: 0.7234 - val_loss: 0.7149 - val_acc: 0.5625\n",
            "Epoch 17/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5370 - acc: 0.7216 - val_loss: 0.7132 - val_acc: 0.5417\n",
            "Epoch 18/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.5325 - acc: 0.7354 - val_loss: 0.7203 - val_acc: 0.5833\n",
            "Epoch 19/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5300 - acc: 0.7268 - val_loss: 0.7150 - val_acc: 0.5521\n",
            "Epoch 20/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5503 - acc: 0.7268 - val_loss: 0.7211 - val_acc: 0.5417\n",
            "Epoch 21/1000\n",
            "37/37 [==============================] - 8s 204ms/step - loss: 0.5505 - acc: 0.7045 - val_loss: 0.7106 - val_acc: 0.5833\n",
            "Epoch 22/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.5278 - acc: 0.7354 - val_loss: 0.7150 - val_acc: 0.5521\n",
            "Epoch 23/1000\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.5360 - acc: 0.7320 - val_loss: 0.7173 - val_acc: 0.5729\n",
            "Epoch 24/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5452 - acc: 0.7148 - val_loss: 0.7247 - val_acc: 0.5729\n",
            "Epoch 25/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5299 - acc: 0.7148 - val_loss: 0.7040 - val_acc: 0.5833\n",
            "Epoch 26/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5337 - acc: 0.7423 - val_loss: 0.7097 - val_acc: 0.5833\n",
            "Epoch 27/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5398 - acc: 0.7216 - val_loss: 0.7115 - val_acc: 0.5938\n",
            "Epoch 28/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5214 - acc: 0.7354 - val_loss: 0.7143 - val_acc: 0.5833\n",
            "Epoch 29/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.5188 - acc: 0.7371 - val_loss: 0.7223 - val_acc: 0.5625\n",
            "Epoch 30/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5196 - acc: 0.7148 - val_loss: 0.7120 - val_acc: 0.5312\n",
            "Epoch 31/1000\n",
            "37/37 [==============================] - 8s 208ms/step - loss: 0.5518 - acc: 0.7234 - val_loss: 0.6979 - val_acc: 0.5833\n",
            "Epoch 32/1000\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.5342 - acc: 0.7131 - val_loss: 0.7035 - val_acc: 0.5625\n",
            "Epoch 33/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5585 - acc: 0.7045 - val_loss: 0.7074 - val_acc: 0.5833\n",
            "Epoch 34/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.5562 - acc: 0.7096 - val_loss: 0.7004 - val_acc: 0.6042\n",
            "Epoch 35/1000\n",
            "37/37 [==============================] - 4s 80ms/step - loss: 0.5292 - acc: 0.7199 - val_loss: 0.7059 - val_acc: 0.5208\n",
            "Epoch 36/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5087 - acc: 0.7440 - val_loss: 0.6838 - val_acc: 0.5625\n",
            "Epoch 37/1000\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 0.5475 - acc: 0.7337 - val_loss: 0.7103 - val_acc: 0.5521\n",
            "Epoch 38/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5503 - acc: 0.7010 - val_loss: 0.7138 - val_acc: 0.5417\n",
            "Epoch 39/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5278 - acc: 0.7331 - val_loss: 0.7045 - val_acc: 0.5729\n",
            "Epoch 40/1000\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.5220 - acc: 0.7371 - val_loss: 0.7010 - val_acc: 0.5938\n",
            "Epoch 41/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5135 - acc: 0.7354 - val_loss: 0.6989 - val_acc: 0.5521\n",
            "Epoch 42/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5563 - acc: 0.6959 - val_loss: 0.7014 - val_acc: 0.5312\n",
            "Epoch 43/1000\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 0.5358 - acc: 0.7371 - val_loss: 0.7026 - val_acc: 0.5833\n",
            "Epoch 44/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5743 - acc: 0.7078 - val_loss: 0.6974 - val_acc: 0.5417\n",
            "Epoch 45/1000\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 0.5285 - acc: 0.7354 - val_loss: 0.7012 - val_acc: 0.5208\n",
            "Epoch 46/1000\n",
            "37/37 [==============================] - 8s 206ms/step - loss: 0.5387 - acc: 0.7405 - val_loss: 0.6889 - val_acc: 0.5417\n",
            "Epoch 47/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.5429 - acc: 0.7268 - val_loss: 0.6809 - val_acc: 0.5521\n",
            "Epoch 48/1000\n",
            "37/37 [==============================] - 8s 207ms/step - loss: 0.5253 - acc: 0.7354 - val_loss: 0.6872 - val_acc: 0.6042\n",
            "Epoch 49/1000\n",
            "37/37 [==============================] - 8s 207ms/step - loss: 0.5253 - acc: 0.7337 - val_loss: 0.6970 - val_acc: 0.5417\n",
            "Epoch 50/1000\n",
            "37/37 [==============================] - 8s 223ms/step - loss: 0.5269 - acc: 0.7302 - val_loss: 0.6854 - val_acc: 0.5625\n",
            "Epoch 51/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5046 - acc: 0.7457 - val_loss: 0.7057 - val_acc: 0.5625\n",
            "Epoch 52/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5344 - acc: 0.7216 - val_loss: 0.7154 - val_acc: 0.5938\n",
            "Epoch 53/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.5128 - acc: 0.7354 - val_loss: 0.7065 - val_acc: 0.6042\n",
            "Epoch 54/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5405 - acc: 0.7285 - val_loss: 0.7157 - val_acc: 0.5833\n",
            "Epoch 55/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.5466 - acc: 0.7096 - val_loss: 0.6973 - val_acc: 0.6042\n",
            "Epoch 56/1000\n",
            "37/37 [==============================] - 8s 207ms/step - loss: 0.5350 - acc: 0.7216 - val_loss: 0.6954 - val_acc: 0.5938\n",
            "Epoch 57/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.5522 - acc: 0.6993 - val_loss: 0.6878 - val_acc: 0.5938\n",
            "Epoch 58/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5391 - acc: 0.7388 - val_loss: 0.7059 - val_acc: 0.5729\n",
            "Epoch 59/1000\n",
            "37/37 [==============================] - 4s 109ms/step - loss: 0.5042 - acc: 0.7405 - val_loss: 0.6919 - val_acc: 0.5938\n",
            "Epoch 60/1000\n",
            "37/37 [==============================] - 8s 207ms/step - loss: 0.5667 - acc: 0.6821 - val_loss: 0.6982 - val_acc: 0.6042\n",
            "Epoch 61/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5373 - acc: 0.7388 - val_loss: 0.6961 - val_acc: 0.5833\n",
            "Epoch 62/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5332 - acc: 0.7199 - val_loss: 0.7012 - val_acc: 0.5833\n",
            "Epoch 63/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.5243 - acc: 0.7199 - val_loss: 0.6981 - val_acc: 0.5833\n",
            "Epoch 64/1000\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.5392 - acc: 0.7096 - val_loss: 0.6928 - val_acc: 0.5938\n",
            "Epoch 65/1000\n",
            "37/37 [==============================] - 3s 83ms/step - loss: 0.5259 - acc: 0.7491 - val_loss: 0.6893 - val_acc: 0.5312\n",
            "Epoch 66/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.5225 - acc: 0.7302 - val_loss: 0.6935 - val_acc: 0.5521\n",
            "Epoch 67/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5501 - acc: 0.7337 - val_loss: 0.7017 - val_acc: 0.5938\n",
            "Epoch 68/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5294 - acc: 0.7354 - val_loss: 0.6969 - val_acc: 0.5312\n",
            "Epoch 69/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.5462 - acc: 0.7320 - val_loss: 0.6918 - val_acc: 0.5938\n",
            "Epoch 70/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.5120 - acc: 0.7491 - val_loss: 0.6987 - val_acc: 0.5729\n",
            "Epoch 71/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5427 - acc: 0.7182 - val_loss: 0.6909 - val_acc: 0.5417\n",
            "Epoch 72/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.5480 - acc: 0.7148 - val_loss: 0.6872 - val_acc: 0.5938\n",
            "Epoch 73/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.5352 - acc: 0.7182 - val_loss: 0.7108 - val_acc: 0.5729\n",
            "Epoch 74/1000\n",
            "37/37 [==============================] - 9s 216ms/step - loss: 0.5396 - acc: 0.7302 - val_loss: 0.7282 - val_acc: 0.5625\n",
            "Epoch 75/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5172 - acc: 0.7474 - val_loss: 0.7157 - val_acc: 0.5521\n",
            "Epoch 76/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5217 - acc: 0.7268 - val_loss: 0.7005 - val_acc: 0.5208\n",
            "Epoch 77/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5223 - acc: 0.7371 - val_loss: 0.7041 - val_acc: 0.5833\n",
            "Epoch 78/1000\n",
            "37/37 [==============================] - 3s 83ms/step - loss: 0.5280 - acc: 0.7320 - val_loss: 0.7143 - val_acc: 0.5417\n",
            "Epoch 79/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5494 - acc: 0.7199 - val_loss: 0.7047 - val_acc: 0.5938\n",
            "Epoch 80/1000\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 0.5430 - acc: 0.7337 - val_loss: 0.6990 - val_acc: 0.5729\n",
            "Epoch 81/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.4892 - acc: 0.7629 - val_loss: 0.6919 - val_acc: 0.5625\n",
            "Epoch 82/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.5347 - acc: 0.7302 - val_loss: 0.6868 - val_acc: 0.5938\n",
            "Epoch 83/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5078 - acc: 0.7474 - val_loss: 0.7169 - val_acc: 0.5521\n",
            "Epoch 84/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5515 - acc: 0.7182 - val_loss: 0.6980 - val_acc: 0.5521\n",
            "Epoch 85/1000\n",
            "37/37 [==============================] - 8s 206ms/step - loss: 0.4827 - acc: 0.7595 - val_loss: 0.6929 - val_acc: 0.5417\n",
            "Epoch 86/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.5353 - acc: 0.7337 - val_loss: 0.6971 - val_acc: 0.5521\n",
            "Epoch 87/1000\n",
            "37/37 [==============================] - 4s 80ms/step - loss: 0.5462 - acc: 0.7165 - val_loss: 0.6869 - val_acc: 0.5625\n",
            "Epoch 88/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.5720 - acc: 0.6993 - val_loss: 0.7032 - val_acc: 0.5729\n",
            "Epoch 89/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5301 - acc: 0.7440 - val_loss: 0.7072 - val_acc: 0.5625\n",
            "Epoch 90/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.5440 - acc: 0.7199 - val_loss: 0.6816 - val_acc: 0.6146\n",
            "Epoch 91/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.5292 - acc: 0.7182 - val_loss: 0.7059 - val_acc: 0.5521\n",
            "Epoch 92/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5147 - acc: 0.7577 - val_loss: 0.7124 - val_acc: 0.5833\n",
            "Epoch 93/1000\n",
            "37/37 [==============================] - 9s 215ms/step - loss: 0.5467 - acc: 0.7182 - val_loss: 0.6881 - val_acc: 0.6146\n",
            "Epoch 94/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.5371 - acc: 0.7182 - val_loss: 0.7072 - val_acc: 0.5729\n",
            "Epoch 95/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.5449 - acc: 0.7182 - val_loss: 0.6732 - val_acc: 0.5833\n",
            "Epoch 96/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5423 - acc: 0.7096 - val_loss: 0.7052 - val_acc: 0.5417\n",
            "Epoch 97/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5410 - acc: 0.7320 - val_loss: 0.6912 - val_acc: 0.5625\n",
            "Epoch 98/1000\n",
            "37/37 [==============================] - 4s 81ms/step - loss: 0.5594 - acc: 0.7113 - val_loss: 0.7029 - val_acc: 0.5833\n",
            "Epoch 99/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5325 - acc: 0.6924 - val_loss: 0.7140 - val_acc: 0.5833\n",
            "Epoch 100/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.5536 - acc: 0.7165 - val_loss: 0.6888 - val_acc: 0.6146\n",
            "Epoch 101/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.4955 - acc: 0.7509 - val_loss: 0.6982 - val_acc: 0.5938\n",
            "Epoch 102/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.5888 - acc: 0.6701 - val_loss: 0.7033 - val_acc: 0.5625\n",
            "Epoch 103/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.5280 - acc: 0.7405 - val_loss: 0.7033 - val_acc: 0.5729\n",
            "Epoch 104/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5701 - acc: 0.6976 - val_loss: 0.6861 - val_acc: 0.6146\n",
            "Epoch 105/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.5369 - acc: 0.7131 - val_loss: 0.7062 - val_acc: 0.5625\n",
            "Epoch 106/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5325 - acc: 0.7337 - val_loss: 0.6915 - val_acc: 0.5833\n",
            "Epoch 107/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.5124 - acc: 0.7577 - val_loss: 0.7093 - val_acc: 0.5833\n",
            "Epoch 108/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.5035 - acc: 0.7337 - val_loss: 0.6926 - val_acc: 0.5938\n",
            "Epoch 109/1000\n",
            "37/37 [==============================] - 9s 215ms/step - loss: 0.5477 - acc: 0.7027 - val_loss: 0.7020 - val_acc: 0.6146\n",
            "Epoch 110/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5320 - acc: 0.7182 - val_loss: 0.6766 - val_acc: 0.6042\n",
            "Epoch 111/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.5159 - acc: 0.7405 - val_loss: 0.6954 - val_acc: 0.6042\n",
            "Epoch 112/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5185 - acc: 0.7165 - val_loss: 0.6986 - val_acc: 0.5729\n",
            "Epoch 113/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.5373 - acc: 0.7251 - val_loss: 0.7074 - val_acc: 0.5625\n",
            "Epoch 114/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5127 - acc: 0.7285 - val_loss: 0.7022 - val_acc: 0.5833\n",
            "Epoch 115/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.5493 - acc: 0.7148 - val_loss: 0.7013 - val_acc: 0.5938\n",
            "Epoch 116/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5203 - acc: 0.7302 - val_loss: 0.6981 - val_acc: 0.5938\n",
            "Epoch 117/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5645 - acc: 0.7062 - val_loss: 0.6773 - val_acc: 0.6042\n",
            "Epoch 118/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5281 - acc: 0.7371 - val_loss: 0.6953 - val_acc: 0.5417\n",
            "Epoch 119/1000\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.5339 - acc: 0.7423 - val_loss: 0.6927 - val_acc: 0.6042\n",
            "Epoch 120/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5440 - acc: 0.7285 - val_loss: 0.6991 - val_acc: 0.5938\n",
            "Epoch 121/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5108 - acc: 0.7440 - val_loss: 0.7124 - val_acc: 0.5833\n",
            "Epoch 122/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5387 - acc: 0.7268 - val_loss: 0.7125 - val_acc: 0.6042\n",
            "Epoch 123/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.5440 - acc: 0.7234 - val_loss: 0.6840 - val_acc: 0.6042\n",
            "Epoch 124/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.5306 - acc: 0.7247 - val_loss: 0.6948 - val_acc: 0.5938\n",
            "Epoch 125/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.5192 - acc: 0.7423 - val_loss: 0.6999 - val_acc: 0.5833\n",
            "Epoch 126/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5192 - acc: 0.7509 - val_loss: 0.6969 - val_acc: 0.5938\n",
            "Epoch 127/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5646 - acc: 0.6873 - val_loss: 0.6818 - val_acc: 0.5729\n",
            "Epoch 128/1000\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.5413 - acc: 0.7199 - val_loss: 0.6961 - val_acc: 0.5729\n",
            "Epoch 129/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5666 - acc: 0.6976 - val_loss: 0.6923 - val_acc: 0.5833\n",
            "Epoch 130/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5606 - acc: 0.7216 - val_loss: 0.6990 - val_acc: 0.5833\n",
            "Epoch 131/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5173 - acc: 0.7320 - val_loss: 0.7088 - val_acc: 0.5833\n",
            "Epoch 132/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.5271 - acc: 0.7491 - val_loss: 0.6788 - val_acc: 0.5938\n",
            "Epoch 133/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.5487 - acc: 0.7199 - val_loss: 0.6935 - val_acc: 0.5938\n",
            "Epoch 134/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5347 - acc: 0.7302 - val_loss: 0.6977 - val_acc: 0.5833\n",
            "Epoch 135/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5425 - acc: 0.7079 - val_loss: 0.6717 - val_acc: 0.6250\n",
            "Epoch 136/1000\n",
            "37/37 [==============================] - 3s 84ms/step - loss: 0.5339 - acc: 0.7440 - val_loss: 0.6853 - val_acc: 0.6042\n",
            "Epoch 137/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5424 - acc: 0.7216 - val_loss: 0.6829 - val_acc: 0.5729\n",
            "Epoch 138/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.5149 - acc: 0.7491 - val_loss: 0.7024 - val_acc: 0.5938\n",
            "Epoch 139/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.5462 - acc: 0.7302 - val_loss: 0.7087 - val_acc: 0.5729\n",
            "Epoch 140/1000\n",
            "37/37 [==============================] - 9s 220ms/step - loss: 0.5252 - acc: 0.7354 - val_loss: 0.6751 - val_acc: 0.6042\n",
            "Epoch 141/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.5195 - acc: 0.7388 - val_loss: 0.6920 - val_acc: 0.5938\n",
            "Epoch 142/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5401 - acc: 0.7182 - val_loss: 0.6772 - val_acc: 0.6042\n",
            "Epoch 143/1000\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.5320 - acc: 0.7423 - val_loss: 0.7001 - val_acc: 0.5833\n",
            "Epoch 144/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5150 - acc: 0.7526 - val_loss: 0.6988 - val_acc: 0.5833\n",
            "Epoch 145/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.5361 - acc: 0.7165 - val_loss: 0.6847 - val_acc: 0.5208\n",
            "Epoch 146/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5252 - acc: 0.7302 - val_loss: 0.7031 - val_acc: 0.5938\n",
            "Epoch 147/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5359 - acc: 0.7337 - val_loss: 0.6936 - val_acc: 0.5833\n",
            "Epoch 148/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.4956 - acc: 0.7680 - val_loss: 0.6976 - val_acc: 0.5833\n",
            "Epoch 149/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.5663 - acc: 0.7216 - val_loss: 0.6805 - val_acc: 0.6042\n",
            "Epoch 150/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5391 - acc: 0.7251 - val_loss: 0.6905 - val_acc: 0.6042\n",
            "Epoch 151/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.4899 - acc: 0.7784 - val_loss: 0.6892 - val_acc: 0.6042\n",
            "Epoch 152/1000\n",
            "37/37 [==============================] - 8s 208ms/step - loss: 0.5161 - acc: 0.7749 - val_loss: 0.6730 - val_acc: 0.6146\n",
            "Epoch 153/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.5111 - acc: 0.7560 - val_loss: 0.6786 - val_acc: 0.5938\n",
            "Epoch 154/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5357 - acc: 0.7268 - val_loss: 0.6673 - val_acc: 0.6042\n",
            "Epoch 155/1000\n",
            "37/37 [==============================] - 4s 82ms/step - loss: 0.4956 - acc: 0.7405 - val_loss: 0.6948 - val_acc: 0.6042\n",
            "Epoch 156/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.5281 - acc: 0.7337 - val_loss: 0.6894 - val_acc: 0.6042\n",
            "Epoch 157/1000\n",
            "37/37 [==============================] - 8s 204ms/step - loss: 0.5350 - acc: 0.7234 - val_loss: 0.7025 - val_acc: 0.5729\n",
            "Epoch 158/1000\n",
            "37/37 [==============================] - 3s 83ms/step - loss: 0.5559 - acc: 0.7182 - val_loss: 0.6929 - val_acc: 0.5833\n",
            "Epoch 159/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5155 - acc: 0.7320 - val_loss: 0.6742 - val_acc: 0.6146\n",
            "Epoch 160/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5638 - acc: 0.6976 - val_loss: 0.6907 - val_acc: 0.5938\n",
            "Epoch 161/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.4963 - acc: 0.7457 - val_loss: 0.7016 - val_acc: 0.5833\n",
            "Epoch 162/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5290 - acc: 0.7388 - val_loss: 0.6907 - val_acc: 0.5938\n",
            "Epoch 163/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5103 - acc: 0.7405 - val_loss: 0.6906 - val_acc: 0.6042\n",
            "Epoch 164/1000\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.5452 - acc: 0.7251 - val_loss: 0.6887 - val_acc: 0.5938\n",
            "Epoch 165/1000\n",
            "37/37 [==============================] - 8s 206ms/step - loss: 0.5004 - acc: 0.7629 - val_loss: 0.6782 - val_acc: 0.6146\n",
            "Epoch 166/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5271 - acc: 0.7182 - val_loss: 0.6757 - val_acc: 0.6146\n",
            "Epoch 167/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.5361 - acc: 0.7113 - val_loss: 0.7012 - val_acc: 0.5521\n",
            "Epoch 168/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.4911 - acc: 0.7612 - val_loss: 0.6934 - val_acc: 0.5833\n",
            "Epoch 169/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5594 - acc: 0.7062 - val_loss: 0.7000 - val_acc: 0.5521\n",
            "Epoch 170/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5195 - acc: 0.7405 - val_loss: 0.6871 - val_acc: 0.5833\n",
            "Epoch 171/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.4869 - acc: 0.7577 - val_loss: 0.6920 - val_acc: 0.6042\n",
            "Epoch 172/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5171 - acc: 0.7405 - val_loss: 0.6831 - val_acc: 0.5938\n",
            "Epoch 173/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.5432 - acc: 0.7148 - val_loss: 0.6868 - val_acc: 0.6042\n",
            "Epoch 174/1000\n",
            "37/37 [==============================] - 8s 208ms/step - loss: 0.5361 - acc: 0.7131 - val_loss: 0.6937 - val_acc: 0.6146\n",
            "Epoch 175/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.5189 - acc: 0.7234 - val_loss: 0.7067 - val_acc: 0.5833\n",
            "Epoch 176/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.5468 - acc: 0.7388 - val_loss: 0.6972 - val_acc: 0.6042\n",
            "Epoch 177/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5295 - acc: 0.7302 - val_loss: 0.6840 - val_acc: 0.6042\n",
            "Epoch 178/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.5480 - acc: 0.7234 - val_loss: 0.7064 - val_acc: 0.5521\n",
            "Epoch 179/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.5094 - acc: 0.7440 - val_loss: 0.6881 - val_acc: 0.5625\n",
            "Epoch 180/1000\n",
            "37/37 [==============================] - 4s 109ms/step - loss: 0.5359 - acc: 0.7113 - val_loss: 0.6904 - val_acc: 0.5938\n",
            "Epoch 181/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.5239 - acc: 0.7440 - val_loss: 0.6948 - val_acc: 0.5833\n",
            "Epoch 182/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5421 - acc: 0.7268 - val_loss: 0.6950 - val_acc: 0.5833\n",
            "Epoch 183/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.5259 - acc: 0.7234 - val_loss: 0.7031 - val_acc: 0.5938\n",
            "Epoch 184/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5240 - acc: 0.7491 - val_loss: 0.7178 - val_acc: 0.5729\n",
            "Epoch 185/1000\n",
            "37/37 [==============================] - 9s 217ms/step - loss: 0.5057 - acc: 0.7457 - val_loss: 0.6959 - val_acc: 0.6042\n",
            "Epoch 186/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.5371 - acc: 0.7251 - val_loss: 0.6854 - val_acc: 0.5729\n",
            "Epoch 187/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.5065 - acc: 0.7371 - val_loss: 0.6885 - val_acc: 0.6042\n",
            "Epoch 188/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5436 - acc: 0.7371 - val_loss: 0.6930 - val_acc: 0.5625\n",
            "Epoch 189/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.5432 - acc: 0.7165 - val_loss: 0.7126 - val_acc: 0.5938\n",
            "Epoch 190/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5192 - acc: 0.7302 - val_loss: 0.6807 - val_acc: 0.6042\n",
            "Epoch 191/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.4887 - acc: 0.7749 - val_loss: 0.6859 - val_acc: 0.6042\n",
            "Epoch 192/1000\n",
            "37/37 [==============================] - 9s 219ms/step - loss: 0.5434 - acc: 0.7199 - val_loss: 0.6784 - val_acc: 0.6250\n",
            "Epoch 193/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.5238 - acc: 0.7148 - val_loss: 0.6941 - val_acc: 0.6146\n",
            "Epoch 194/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5203 - acc: 0.7251 - val_loss: 0.6917 - val_acc: 0.5833\n",
            "Epoch 195/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.5359 - acc: 0.7302 - val_loss: 0.6945 - val_acc: 0.5833\n",
            "Epoch 196/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.5489 - acc: 0.7302 - val_loss: 0.6612 - val_acc: 0.6042\n",
            "Epoch 197/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5160 - acc: 0.7371 - val_loss: 0.6853 - val_acc: 0.5729\n",
            "Epoch 198/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.5230 - acc: 0.7354 - val_loss: 0.6823 - val_acc: 0.6250\n",
            "Epoch 199/1000\n",
            "37/37 [==============================] - 4s 80ms/step - loss: 0.5003 - acc: 0.7474 - val_loss: 0.6932 - val_acc: 0.6042\n",
            "Epoch 200/1000\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.5358 - acc: 0.7320 - val_loss: 0.6775 - val_acc: 0.6042\n",
            "Epoch 201/1000\n",
            "37/37 [==============================] - 8s 208ms/step - loss: 0.5040 - acc: 0.7663 - val_loss: 0.6924 - val_acc: 0.6146\n",
            "Epoch 202/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5329 - acc: 0.7354 - val_loss: 0.6997 - val_acc: 0.6042\n",
            "Epoch 203/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.5470 - acc: 0.7302 - val_loss: 0.6769 - val_acc: 0.6354\n",
            "Epoch 204/1000\n",
            "37/37 [==============================] - 9s 218ms/step - loss: 0.5365 - acc: 0.7337 - val_loss: 0.7158 - val_acc: 0.5833\n",
            "Epoch 205/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.5287 - acc: 0.7371 - val_loss: 0.6902 - val_acc: 0.5729\n",
            "Epoch 206/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.5219 - acc: 0.7440 - val_loss: 0.6905 - val_acc: 0.5729\n",
            "Epoch 207/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.5074 - acc: 0.7509 - val_loss: 0.6956 - val_acc: 0.6042\n",
            "Epoch 208/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5212 - acc: 0.7354 - val_loss: 0.6920 - val_acc: 0.5729\n",
            "Epoch 209/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.5429 - acc: 0.7285 - val_loss: 0.6982 - val_acc: 0.5625\n",
            "Epoch 210/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5089 - acc: 0.7405 - val_loss: 0.7077 - val_acc: 0.5833\n",
            "Epoch 211/1000\n",
            "37/37 [==============================] - 4s 81ms/step - loss: 0.5548 - acc: 0.6993 - val_loss: 0.6765 - val_acc: 0.5938\n",
            "Epoch 212/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.5507 - acc: 0.6993 - val_loss: 0.6913 - val_acc: 0.5729\n",
            "Epoch 213/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.5434 - acc: 0.7388 - val_loss: 0.6714 - val_acc: 0.5625\n",
            "Epoch 214/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5188 - acc: 0.7629 - val_loss: 0.6938 - val_acc: 0.6042\n",
            "Epoch 215/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.5559 - acc: 0.7337 - val_loss: 0.6971 - val_acc: 0.5833\n",
            "Epoch 216/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.4845 - acc: 0.7715 - val_loss: 0.6835 - val_acc: 0.5833\n",
            "Epoch 217/1000\n",
            "37/37 [==============================] - 10s 241ms/step - loss: 0.5279 - acc: 0.7423 - val_loss: 0.6817 - val_acc: 0.5938\n",
            "Epoch 218/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.4943 - acc: 0.7612 - val_loss: 0.6988 - val_acc: 0.5833\n",
            "Epoch 219/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5330 - acc: 0.7199 - val_loss: 0.6953 - val_acc: 0.5833\n",
            "Epoch 220/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5407 - acc: 0.7251 - val_loss: 0.7057 - val_acc: 0.5833\n",
            "Epoch 221/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5416 - acc: 0.7096 - val_loss: 0.6885 - val_acc: 0.5729\n",
            "Epoch 222/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5262 - acc: 0.7285 - val_loss: 0.6885 - val_acc: 0.5833\n",
            "Epoch 223/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5419 - acc: 0.7234 - val_loss: 0.6803 - val_acc: 0.5938\n",
            "Epoch 224/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.5260 - acc: 0.7337 - val_loss: 0.6926 - val_acc: 0.5625\n",
            "Epoch 225/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5396 - acc: 0.7320 - val_loss: 0.6879 - val_acc: 0.5938\n",
            "Epoch 226/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5312 - acc: 0.7388 - val_loss: 0.7007 - val_acc: 0.5625\n",
            "Epoch 227/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.5348 - acc: 0.7285 - val_loss: 0.7061 - val_acc: 0.5729\n",
            "Epoch 228/1000\n",
            "37/37 [==============================] - 9s 219ms/step - loss: 0.5650 - acc: 0.7128 - val_loss: 0.6857 - val_acc: 0.5833\n",
            "Epoch 229/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.5178 - acc: 0.7354 - val_loss: 0.6897 - val_acc: 0.5833\n",
            "Epoch 230/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.5478 - acc: 0.7113 - val_loss: 0.6878 - val_acc: 0.5938\n",
            "Epoch 231/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5229 - acc: 0.7113 - val_loss: 0.6898 - val_acc: 0.5938\n",
            "Epoch 232/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 0.5726 - acc: 0.7131 - val_loss: 0.7003 - val_acc: 0.5938\n",
            "Epoch 233/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.5600 - acc: 0.7045 - val_loss: 0.7097 - val_acc: 0.5833\n",
            "Epoch 234/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.5628 - acc: 0.7234 - val_loss: 0.6999 - val_acc: 0.6042\n",
            "Epoch 235/1000\n",
            "37/37 [==============================] - 4s 78ms/step - loss: 0.5359 - acc: 0.7234 - val_loss: 0.7010 - val_acc: 0.5938\n",
            "Epoch 236/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5351 - acc: 0.7148 - val_loss: 0.6747 - val_acc: 0.5417\n",
            "Epoch 237/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.5109 - acc: 0.7354 - val_loss: 0.6807 - val_acc: 0.5833\n",
            "Epoch 238/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5263 - acc: 0.7234 - val_loss: 0.6925 - val_acc: 0.5729\n",
            "Epoch 239/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.5127 - acc: 0.7526 - val_loss: 0.6904 - val_acc: 0.5312\n",
            "Epoch 240/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5364 - acc: 0.7337 - val_loss: 0.6941 - val_acc: 0.5833\n",
            "Epoch 241/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5123 - acc: 0.7405 - val_loss: 0.6905 - val_acc: 0.5833\n",
            "Epoch 242/1000\n",
            "37/37 [==============================] - 4s 80ms/step - loss: 0.5303 - acc: 0.7337 - val_loss: 0.6748 - val_acc: 0.6042\n",
            "Epoch 243/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5394 - acc: 0.7268 - val_loss: 0.7024 - val_acc: 0.5938\n",
            "Epoch 244/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5215 - acc: 0.7474 - val_loss: 0.6799 - val_acc: 0.5938\n",
            "Epoch 245/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.5060 - acc: 0.7337 - val_loss: 0.6994 - val_acc: 0.6042\n",
            "Epoch 246/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5384 - acc: 0.7371 - val_loss: 0.6843 - val_acc: 0.6146\n",
            "Epoch 247/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.5199 - acc: 0.7251 - val_loss: 0.6902 - val_acc: 0.6042\n",
            "Epoch 248/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.5546 - acc: 0.7199 - val_loss: 0.7005 - val_acc: 0.5833\n",
            "Epoch 249/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5381 - acc: 0.7423 - val_loss: 0.6963 - val_acc: 0.5833\n",
            "Epoch 250/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5130 - acc: 0.7474 - val_loss: 0.6757 - val_acc: 0.5938\n",
            "Epoch 251/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5334 - acc: 0.7320 - val_loss: 0.6791 - val_acc: 0.6146\n",
            "Epoch 252/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.5231 - acc: 0.7354 - val_loss: 0.7025 - val_acc: 0.5625\n",
            "Epoch 253/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.5293 - acc: 0.7182 - val_loss: 0.6790 - val_acc: 0.5833\n",
            "Epoch 254/1000\n",
            "37/37 [==============================] - 5s 107ms/step - loss: 0.5423 - acc: 0.7199 - val_loss: 0.6717 - val_acc: 0.6042\n",
            "Epoch 255/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.5114 - acc: 0.7646 - val_loss: 0.7069 - val_acc: 0.5729\n",
            "Epoch 256/1000\n",
            "37/37 [==============================] - 3s 83ms/step - loss: 0.5460 - acc: 0.7320 - val_loss: 0.6911 - val_acc: 0.6146\n",
            "Epoch 257/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5615 - acc: 0.7302 - val_loss: 0.6515 - val_acc: 0.5938\n",
            "Epoch 258/1000\n",
            "37/37 [==============================] - 4s 80ms/step - loss: 0.5337 - acc: 0.7354 - val_loss: 0.6926 - val_acc: 0.5625\n",
            "Epoch 259/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5288 - acc: 0.7234 - val_loss: 0.6727 - val_acc: 0.5833\n",
            "Epoch 260/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5292 - acc: 0.7457 - val_loss: 0.6857 - val_acc: 0.5833\n",
            "Epoch 261/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5271 - acc: 0.7044 - val_loss: 0.6973 - val_acc: 0.5625\n",
            "Epoch 262/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.5270 - acc: 0.7388 - val_loss: 0.6842 - val_acc: 0.5833\n",
            "Epoch 263/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5194 - acc: 0.7491 - val_loss: 0.7000 - val_acc: 0.5938\n",
            "Epoch 264/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.5331 - acc: 0.7216 - val_loss: 0.6857 - val_acc: 0.5729\n",
            "Epoch 265/1000\n",
            "37/37 [==============================] - 4s 81ms/step - loss: 0.5124 - acc: 0.7491 - val_loss: 0.6887 - val_acc: 0.5625\n",
            "Epoch 266/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5490 - acc: 0.7199 - val_loss: 0.6807 - val_acc: 0.5938\n",
            "Epoch 267/1000\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.5370 - acc: 0.7509 - val_loss: 0.6982 - val_acc: 0.5625\n",
            "Epoch 268/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5295 - acc: 0.7268 - val_loss: 0.6827 - val_acc: 0.5625\n",
            "Epoch 269/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.5405 - acc: 0.7302 - val_loss: 0.6676 - val_acc: 0.5938\n",
            "Epoch 270/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5157 - acc: 0.7595 - val_loss: 0.6999 - val_acc: 0.5833\n",
            "Epoch 271/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5359 - acc: 0.7354 - val_loss: 0.6994 - val_acc: 0.5833\n",
            "Epoch 272/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.4826 - acc: 0.7543 - val_loss: 0.6899 - val_acc: 0.6042\n",
            "Epoch 273/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.5306 - acc: 0.7096 - val_loss: 0.6865 - val_acc: 0.6042\n",
            "Epoch 274/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5361 - acc: 0.7354 - val_loss: 0.6869 - val_acc: 0.6042\n",
            "Epoch 275/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.4946 - acc: 0.7732 - val_loss: 0.6847 - val_acc: 0.5833\n",
            "Epoch 276/1000\n",
            "37/37 [==============================] - 9s 217ms/step - loss: 0.5321 - acc: 0.7268 - val_loss: 0.6718 - val_acc: 0.5938\n",
            "Epoch 277/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.4959 - acc: 0.7509 - val_loss: 0.6860 - val_acc: 0.5729\n",
            "Epoch 278/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5633 - acc: 0.6993 - val_loss: 0.6856 - val_acc: 0.5729\n",
            "Epoch 279/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5346 - acc: 0.7234 - val_loss: 0.6999 - val_acc: 0.5833\n",
            "Epoch 280/1000\n",
            "37/37 [==============================] - 9s 215ms/step - loss: 0.5080 - acc: 0.7509 - val_loss: 0.6749 - val_acc: 0.6146\n",
            "Epoch 281/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.5186 - acc: 0.7337 - val_loss: 0.6812 - val_acc: 0.5729\n",
            "Epoch 282/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5111 - acc: 0.7337 - val_loss: 0.6769 - val_acc: 0.5833\n",
            "Epoch 283/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5320 - acc: 0.7268 - val_loss: 0.6887 - val_acc: 0.5625\n",
            "Epoch 284/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5198 - acc: 0.7440 - val_loss: 0.6826 - val_acc: 0.5729\n",
            "Epoch 285/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5307 - acc: 0.7423 - val_loss: 0.6704 - val_acc: 0.5833\n",
            "Epoch 286/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5388 - acc: 0.7405 - val_loss: 0.6898 - val_acc: 0.6042\n",
            "Epoch 287/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.4996 - acc: 0.7663 - val_loss: 0.6817 - val_acc: 0.5833\n",
            "Epoch 288/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.5109 - acc: 0.7491 - val_loss: 0.6906 - val_acc: 0.5833\n",
            "Epoch 289/1000\n",
            "37/37 [==============================] - 5s 110ms/step - loss: 0.5341 - acc: 0.7128 - val_loss: 0.6716 - val_acc: 0.6146\n",
            "Epoch 290/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5316 - acc: 0.7285 - val_loss: 0.6735 - val_acc: 0.5833\n",
            "Epoch 291/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.5085 - acc: 0.7526 - val_loss: 0.6817 - val_acc: 0.6146\n",
            "Epoch 292/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5087 - acc: 0.7577 - val_loss: 0.6879 - val_acc: 0.6042\n",
            "Epoch 293/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5132 - acc: 0.7405 - val_loss: 0.6936 - val_acc: 0.5729\n",
            "Epoch 294/1000\n",
            "37/37 [==============================] - 9s 216ms/step - loss: 0.5110 - acc: 0.7405 - val_loss: 0.6766 - val_acc: 0.5833\n",
            "Epoch 295/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.5201 - acc: 0.7423 - val_loss: 0.6725 - val_acc: 0.6042\n",
            "Epoch 296/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5224 - acc: 0.7182 - val_loss: 0.6893 - val_acc: 0.5729\n",
            "Epoch 297/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.5237 - acc: 0.7251 - val_loss: 0.6685 - val_acc: 0.5938\n",
            "Epoch 298/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5355 - acc: 0.7234 - val_loss: 0.6709 - val_acc: 0.6042\n",
            "Epoch 299/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5112 - acc: 0.7474 - val_loss: 0.6719 - val_acc: 0.5938\n",
            "Epoch 300/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.5200 - acc: 0.7285 - val_loss: 0.6616 - val_acc: 0.6354\n",
            "Epoch 301/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.4955 - acc: 0.7595 - val_loss: 0.6639 - val_acc: 0.5833\n",
            "Epoch 302/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5149 - acc: 0.7491 - val_loss: 0.6869 - val_acc: 0.5625\n",
            "Epoch 303/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5643 - acc: 0.7148 - val_loss: 0.6732 - val_acc: 0.5521\n",
            "Epoch 304/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.4926 - acc: 0.7595 - val_loss: 0.6729 - val_acc: 0.6042\n",
            "Epoch 305/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5083 - acc: 0.7509 - val_loss: 0.6807 - val_acc: 0.5833\n",
            "Epoch 306/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5051 - acc: 0.7388 - val_loss: 0.6704 - val_acc: 0.5729\n",
            "Epoch 307/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5236 - acc: 0.7388 - val_loss: 0.6825 - val_acc: 0.5625\n",
            "Epoch 308/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5145 - acc: 0.7440 - val_loss: 0.6773 - val_acc: 0.5833\n",
            "Epoch 309/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.5617 - acc: 0.6959 - val_loss: 0.6758 - val_acc: 0.5625\n",
            "Epoch 310/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5101 - acc: 0.7457 - val_loss: 0.6570 - val_acc: 0.5938\n",
            "Epoch 311/1000\n",
            "37/37 [==============================] - 5s 106ms/step - loss: 0.5146 - acc: 0.7354 - val_loss: 0.6743 - val_acc: 0.5729\n",
            "Epoch 312/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5042 - acc: 0.7680 - val_loss: 0.6729 - val_acc: 0.5521\n",
            "Epoch 313/1000\n",
            "37/37 [==============================] - 4s 79ms/step - loss: 0.4997 - acc: 0.7612 - val_loss: 0.6840 - val_acc: 0.5521\n",
            "Epoch 314/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.5281 - acc: 0.7388 - val_loss: 0.6733 - val_acc: 0.5625\n",
            "Epoch 315/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.5267 - acc: 0.7457 - val_loss: 0.6822 - val_acc: 0.5521\n",
            "Epoch 316/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5183 - acc: 0.7560 - val_loss: 0.6641 - val_acc: 0.5938\n",
            "Epoch 317/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.5094 - acc: 0.7474 - val_loss: 0.6708 - val_acc: 0.5625\n",
            "Epoch 318/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5143 - acc: 0.7440 - val_loss: 0.6586 - val_acc: 0.5938\n",
            "Epoch 319/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5329 - acc: 0.7354 - val_loss: 0.6697 - val_acc: 0.6042\n",
            "Epoch 320/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5298 - acc: 0.7423 - val_loss: 0.6699 - val_acc: 0.5938\n",
            "Epoch 321/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.4774 - acc: 0.7766 - val_loss: 0.6939 - val_acc: 0.6042\n",
            "Epoch 322/1000\n",
            "37/37 [==============================] - 4s 79ms/step - loss: 0.5292 - acc: 0.7234 - val_loss: 0.6581 - val_acc: 0.6250\n",
            "Epoch 323/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.5201 - acc: 0.7440 - val_loss: 0.6738 - val_acc: 0.5625\n",
            "Epoch 324/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.5391 - acc: 0.7285 - val_loss: 0.6760 - val_acc: 0.6250\n",
            "Epoch 325/1000\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.5372 - acc: 0.7337 - val_loss: 0.6825 - val_acc: 0.6042\n",
            "Epoch 326/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5478 - acc: 0.7199 - val_loss: 0.6875 - val_acc: 0.6042\n",
            "Epoch 327/1000\n",
            "37/37 [==============================] - 9s 217ms/step - loss: 0.5174 - acc: 0.7474 - val_loss: 0.6910 - val_acc: 0.6042\n",
            "Epoch 328/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5410 - acc: 0.7165 - val_loss: 0.6842 - val_acc: 0.5625\n",
            "Epoch 329/1000\n",
            "37/37 [==============================] - 9s 219ms/step - loss: 0.5115 - acc: 0.7457 - val_loss: 0.6850 - val_acc: 0.6042\n",
            "Epoch 330/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.4986 - acc: 0.7405 - val_loss: 0.6808 - val_acc: 0.6146\n",
            "Epoch 331/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.4915 - acc: 0.7646 - val_loss: 0.6967 - val_acc: 0.5729\n",
            "Epoch 332/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.5394 - acc: 0.7388 - val_loss: 0.6715 - val_acc: 0.5833\n",
            "Epoch 333/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5489 - acc: 0.7199 - val_loss: 0.6865 - val_acc: 0.6042\n",
            "Epoch 334/1000\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.5117 - acc: 0.7405 - val_loss: 0.6725 - val_acc: 0.5625\n",
            "Epoch 335/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.5595 - acc: 0.7045 - val_loss: 0.6944 - val_acc: 0.5938\n",
            "Epoch 336/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.5296 - acc: 0.7491 - val_loss: 0.6859 - val_acc: 0.6042\n",
            "Epoch 337/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.4805 - acc: 0.7732 - val_loss: 0.6893 - val_acc: 0.5938\n",
            "Epoch 338/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.5546 - acc: 0.7234 - val_loss: 0.6808 - val_acc: 0.5729\n",
            "Epoch 339/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5470 - acc: 0.7182 - val_loss: 0.6670 - val_acc: 0.5938\n",
            "Epoch 340/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.5242 - acc: 0.7388 - val_loss: 0.6713 - val_acc: 0.5938\n",
            "Epoch 341/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5132 - acc: 0.7526 - val_loss: 0.6779 - val_acc: 0.5729\n",
            "Epoch 342/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5084 - acc: 0.7577 - val_loss: 0.6786 - val_acc: 0.5521\n",
            "Epoch 343/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5271 - acc: 0.7165 - val_loss: 0.6830 - val_acc: 0.6042\n",
            "Epoch 344/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5206 - acc: 0.7491 - val_loss: 0.6819 - val_acc: 0.6042\n",
            "Epoch 345/1000\n",
            "37/37 [==============================] - 9s 219ms/step - loss: 0.5024 - acc: 0.7423 - val_loss: 0.6826 - val_acc: 0.5938\n",
            "Epoch 346/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.5204 - acc: 0.7388 - val_loss: 0.6817 - val_acc: 0.6042\n",
            "Epoch 347/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5210 - acc: 0.7354 - val_loss: 0.6875 - val_acc: 0.5625\n",
            "Epoch 348/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.5001 - acc: 0.7491 - val_loss: 0.6728 - val_acc: 0.6042\n",
            "Epoch 349/1000\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.5510 - acc: 0.7199 - val_loss: 0.6784 - val_acc: 0.5625\n",
            "Epoch 350/1000\n",
            "37/37 [==============================] - 5s 111ms/step - loss: 0.5181 - acc: 0.7388 - val_loss: 0.6699 - val_acc: 0.5729\n",
            "Epoch 351/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5436 - acc: 0.7216 - val_loss: 0.6820 - val_acc: 0.5938\n",
            "Epoch 352/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5344 - acc: 0.7354 - val_loss: 0.6748 - val_acc: 0.6042\n",
            "Epoch 353/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5282 - acc: 0.7251 - val_loss: 0.6596 - val_acc: 0.6042\n",
            "Epoch 354/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.5139 - acc: 0.7234 - val_loss: 0.6948 - val_acc: 0.6042\n",
            "Epoch 355/1000\n",
            "37/37 [==============================] - 4s 82ms/step - loss: 0.5053 - acc: 0.7388 - val_loss: 0.6632 - val_acc: 0.6146\n",
            "Epoch 356/1000\n",
            "37/37 [==============================] - 9s 218ms/step - loss: 0.5381 - acc: 0.7285 - val_loss: 0.6845 - val_acc: 0.5938\n",
            "Epoch 357/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5348 - acc: 0.7423 - val_loss: 0.6922 - val_acc: 0.5833\n",
            "Epoch 358/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5210 - acc: 0.7474 - val_loss: 0.6891 - val_acc: 0.5833\n",
            "Epoch 359/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5313 - acc: 0.7337 - val_loss: 0.6809 - val_acc: 0.5938\n",
            "Epoch 360/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5151 - acc: 0.7474 - val_loss: 0.6722 - val_acc: 0.6042\n",
            "Epoch 361/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5063 - acc: 0.7440 - val_loss: 0.6761 - val_acc: 0.6042\n",
            "Epoch 362/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.4861 - acc: 0.7612 - val_loss: 0.6782 - val_acc: 0.5625\n",
            "Epoch 363/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.5331 - acc: 0.7320 - val_loss: 0.6851 - val_acc: 0.6042\n",
            "Epoch 364/1000\n",
            "37/37 [==============================] - 5s 112ms/step - loss: 0.5127 - acc: 0.7251 - val_loss: 0.6731 - val_acc: 0.5938\n",
            "Epoch 365/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5017 - acc: 0.7543 - val_loss: 0.6689 - val_acc: 0.6354\n",
            "Epoch 366/1000\n",
            "37/37 [==============================] - 9s 219ms/step - loss: 0.5133 - acc: 0.7405 - val_loss: 0.6851 - val_acc: 0.6146\n",
            "Epoch 367/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.5283 - acc: 0.7457 - val_loss: 0.6951 - val_acc: 0.6042\n",
            "Epoch 368/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5400 - acc: 0.7337 - val_loss: 0.6760 - val_acc: 0.6042\n",
            "Epoch 369/1000\n",
            "37/37 [==============================] - 5s 102ms/step - loss: 0.4973 - acc: 0.7698 - val_loss: 0.6828 - val_acc: 0.5833\n",
            "Epoch 370/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5160 - acc: 0.7474 - val_loss: 0.6899 - val_acc: 0.5833\n",
            "Epoch 371/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5378 - acc: 0.7354 - val_loss: 0.6670 - val_acc: 0.6042\n",
            "Epoch 372/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.5320 - acc: 0.7096 - val_loss: 0.6856 - val_acc: 0.6042\n",
            "Epoch 373/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.5337 - acc: 0.7268 - val_loss: 0.6941 - val_acc: 0.6042\n",
            "Epoch 374/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5049 - acc: 0.7526 - val_loss: 0.6819 - val_acc: 0.6146\n",
            "Epoch 375/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5348 - acc: 0.7354 - val_loss: 0.6876 - val_acc: 0.5938\n",
            "Epoch 376/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.4995 - acc: 0.7491 - val_loss: 0.6824 - val_acc: 0.5938\n",
            "Epoch 377/1000\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.5753 - acc: 0.6838 - val_loss: 0.6690 - val_acc: 0.5938\n",
            "Epoch 378/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5258 - acc: 0.7268 - val_loss: 0.6871 - val_acc: 0.5833\n",
            "Epoch 379/1000\n",
            "37/37 [==============================] - 9s 218ms/step - loss: 0.4969 - acc: 0.7551 - val_loss: 0.6771 - val_acc: 0.6250\n",
            "Epoch 380/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5172 - acc: 0.7457 - val_loss: 0.7008 - val_acc: 0.5938\n",
            "Epoch 381/1000\n",
            "37/37 [==============================] - 5s 110ms/step - loss: 0.5142 - acc: 0.7629 - val_loss: 0.6649 - val_acc: 0.6042\n",
            "Epoch 382/1000\n",
            "37/37 [==============================] - 9s 218ms/step - loss: 0.5158 - acc: 0.7388 - val_loss: 0.6775 - val_acc: 0.6042\n",
            "Epoch 383/1000\n",
            "37/37 [==============================] - 6s 147ms/step - loss: 0.5151 - acc: 0.7423 - val_loss: 0.6758 - val_acc: 0.6146\n",
            "Epoch 384/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5325 - acc: 0.7302 - val_loss: 0.6805 - val_acc: 0.5833\n",
            "Epoch 385/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.5491 - acc: 0.7280 - val_loss: 0.6942 - val_acc: 0.5833\n",
            "Epoch 386/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.4843 - acc: 0.7646 - val_loss: 0.6893 - val_acc: 0.5833\n",
            "Epoch 387/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.5164 - acc: 0.7629 - val_loss: 0.6776 - val_acc: 0.5938\n",
            "Epoch 388/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5489 - acc: 0.7027 - val_loss: 0.6855 - val_acc: 0.5729\n",
            "Epoch 389/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5116 - acc: 0.7302 - val_loss: 0.6898 - val_acc: 0.5625\n",
            "Epoch 390/1000\n",
            "37/37 [==============================] - 4s 82ms/step - loss: 0.4984 - acc: 0.7715 - val_loss: 0.6865 - val_acc: 0.6146\n",
            "Epoch 391/1000\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.5289 - acc: 0.7268 - val_loss: 0.6812 - val_acc: 0.5938\n",
            "Epoch 392/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5413 - acc: 0.7182 - val_loss: 0.6688 - val_acc: 0.6042\n",
            "Epoch 393/1000\n",
            "37/37 [==============================] - 9s 217ms/step - loss: 0.5574 - acc: 0.7131 - val_loss: 0.6742 - val_acc: 0.6042\n",
            "Epoch 394/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5157 - acc: 0.7423 - val_loss: 0.6753 - val_acc: 0.6146\n",
            "Epoch 395/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.5390 - acc: 0.7234 - val_loss: 0.6628 - val_acc: 0.6250\n",
            "Epoch 396/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.5149 - acc: 0.7354 - val_loss: 0.6782 - val_acc: 0.5938\n",
            "Epoch 397/1000\n",
            "37/37 [==============================] - 5s 114ms/step - loss: 0.5305 - acc: 0.7423 - val_loss: 0.6764 - val_acc: 0.6146\n",
            "Epoch 398/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5132 - acc: 0.7629 - val_loss: 0.6569 - val_acc: 0.5625\n",
            "Epoch 399/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.5056 - acc: 0.7543 - val_loss: 0.6677 - val_acc: 0.5521\n",
            "Epoch 400/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5239 - acc: 0.7457 - val_loss: 0.6657 - val_acc: 0.5938\n",
            "Epoch 401/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.5184 - acc: 0.7131 - val_loss: 0.6672 - val_acc: 0.6042\n",
            "Epoch 402/1000\n",
            "37/37 [==============================] - 9s 218ms/step - loss: 0.5475 - acc: 0.7113 - val_loss: 0.6816 - val_acc: 0.5833\n",
            "Epoch 403/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5117 - acc: 0.7388 - val_loss: 0.6706 - val_acc: 0.5625\n",
            "Epoch 404/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5288 - acc: 0.7423 - val_loss: 0.6657 - val_acc: 0.6146\n",
            "Epoch 405/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.5133 - acc: 0.7577 - val_loss: 0.6694 - val_acc: 0.6042\n",
            "Epoch 406/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5074 - acc: 0.7509 - val_loss: 0.6852 - val_acc: 0.5938\n",
            "Epoch 407/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5453 - acc: 0.7131 - val_loss: 0.6692 - val_acc: 0.5833\n",
            "Epoch 408/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5241 - acc: 0.7595 - val_loss: 0.6764 - val_acc: 0.5729\n",
            "Epoch 409/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5100 - acc: 0.7440 - val_loss: 0.6673 - val_acc: 0.5833\n",
            "Epoch 410/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5089 - acc: 0.7474 - val_loss: 0.6892 - val_acc: 0.5729\n",
            "Epoch 411/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.4892 - acc: 0.7560 - val_loss: 0.6688 - val_acc: 0.6042\n",
            "Epoch 412/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5065 - acc: 0.7784 - val_loss: 0.6648 - val_acc: 0.5729\n",
            "Epoch 413/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.4978 - acc: 0.7474 - val_loss: 0.6734 - val_acc: 0.5521\n",
            "Epoch 414/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5069 - acc: 0.7526 - val_loss: 0.6654 - val_acc: 0.6146\n",
            "Epoch 415/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.5291 - acc: 0.7371 - val_loss: 0.6809 - val_acc: 0.5938\n",
            "Epoch 416/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.4970 - acc: 0.7148 - val_loss: 0.6833 - val_acc: 0.6042\n",
            "Epoch 417/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5097 - acc: 0.7509 - val_loss: 0.6863 - val_acc: 0.5833\n",
            "Epoch 418/1000\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.5127 - acc: 0.7440 - val_loss: 0.6822 - val_acc: 0.5938\n",
            "Epoch 419/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.5066 - acc: 0.7423 - val_loss: 0.6688 - val_acc: 0.6146\n",
            "Epoch 420/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5054 - acc: 0.7457 - val_loss: 0.6788 - val_acc: 0.6042\n",
            "Epoch 421/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.5053 - acc: 0.7405 - val_loss: 0.6758 - val_acc: 0.5938\n",
            "Epoch 422/1000\n",
            "37/37 [==============================] - 4s 82ms/step - loss: 0.5256 - acc: 0.7440 - val_loss: 0.6758 - val_acc: 0.5625\n",
            "Epoch 423/1000\n",
            "37/37 [==============================] - 9s 219ms/step - loss: 0.5413 - acc: 0.7354 - val_loss: 0.6786 - val_acc: 0.5938\n",
            "Epoch 424/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.5169 - acc: 0.7509 - val_loss: 0.6763 - val_acc: 0.6250\n",
            "Epoch 425/1000\n",
            "37/37 [==============================] - 4s 80ms/step - loss: 0.5397 - acc: 0.7526 - val_loss: 0.6857 - val_acc: 0.5417\n",
            "Epoch 426/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5293 - acc: 0.7045 - val_loss: 0.6943 - val_acc: 0.5833\n",
            "Epoch 427/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.4929 - acc: 0.7526 - val_loss: 0.6681 - val_acc: 0.5938\n",
            "Epoch 428/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5441 - acc: 0.7148 - val_loss: 0.6786 - val_acc: 0.5938\n",
            "Epoch 429/1000\n",
            "37/37 [==============================] - 9s 220ms/step - loss: 0.5254 - acc: 0.7302 - val_loss: 0.6692 - val_acc: 0.6042\n",
            "Epoch 430/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5396 - acc: 0.7165 - val_loss: 0.6746 - val_acc: 0.5833\n",
            "Epoch 431/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5218 - acc: 0.7457 - val_loss: 0.6889 - val_acc: 0.5729\n",
            "Epoch 432/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.4985 - acc: 0.7405 - val_loss: 0.6876 - val_acc: 0.5938\n",
            "Epoch 433/1000\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.4960 - acc: 0.7543 - val_loss: 0.6907 - val_acc: 0.6146\n",
            "Epoch 434/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5220 - acc: 0.7595 - val_loss: 0.6897 - val_acc: 0.5625\n",
            "Epoch 435/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.5090 - acc: 0.7354 - val_loss: 0.6928 - val_acc: 0.5833\n",
            "Epoch 436/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.4879 - acc: 0.7526 - val_loss: 0.6813 - val_acc: 0.5729\n",
            "Epoch 437/1000\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 0.5267 - acc: 0.7251 - val_loss: 0.6658 - val_acc: 0.6146\n",
            "Epoch 438/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5194 - acc: 0.7405 - val_loss: 0.6732 - val_acc: 0.6146\n",
            "Epoch 439/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5273 - acc: 0.7354 - val_loss: 0.6904 - val_acc: 0.6042\n",
            "Epoch 440/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.5175 - acc: 0.7251 - val_loss: 0.6864 - val_acc: 0.6146\n",
            "Epoch 441/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.5040 - acc: 0.7646 - val_loss: 0.6749 - val_acc: 0.6146\n",
            "Epoch 442/1000\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 0.5433 - acc: 0.7234 - val_loss: 0.7007 - val_acc: 0.5938\n",
            "Epoch 443/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5051 - acc: 0.7491 - val_loss: 0.6902 - val_acc: 0.6042\n",
            "Epoch 444/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.5295 - acc: 0.7466 - val_loss: 0.6935 - val_acc: 0.6042\n",
            "Epoch 445/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5291 - acc: 0.7148 - val_loss: 0.6923 - val_acc: 0.6146\n",
            "Epoch 446/1000\n",
            "37/37 [==============================] - 4s 80ms/step - loss: 0.4965 - acc: 0.7629 - val_loss: 0.6755 - val_acc: 0.6458\n",
            "Epoch 447/1000\n",
            "37/37 [==============================] - 9s 216ms/step - loss: 0.5545 - acc: 0.7251 - val_loss: 0.6814 - val_acc: 0.6146\n",
            "Epoch 448/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.5306 - acc: 0.7432 - val_loss: 0.6666 - val_acc: 0.6250\n",
            "Epoch 449/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.5456 - acc: 0.7320 - val_loss: 0.6896 - val_acc: 0.6042\n",
            "Epoch 450/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.4953 - acc: 0.7405 - val_loss: 0.6963 - val_acc: 0.5833\n",
            "Epoch 451/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.4955 - acc: 0.7698 - val_loss: 0.6781 - val_acc: 0.5938\n",
            "Epoch 452/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.4865 - acc: 0.7715 - val_loss: 0.6575 - val_acc: 0.5729\n",
            "Epoch 453/1000\n",
            "37/37 [==============================] - 5s 107ms/step - loss: 0.5191 - acc: 0.7423 - val_loss: 0.6843 - val_acc: 0.5833\n",
            "Epoch 454/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.5479 - acc: 0.7182 - val_loss: 0.6623 - val_acc: 0.6042\n",
            "Epoch 455/1000\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.5184 - acc: 0.7337 - val_loss: 0.6775 - val_acc: 0.5417\n",
            "Epoch 456/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5191 - acc: 0.7337 - val_loss: 0.6733 - val_acc: 0.6042\n",
            "Epoch 457/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.5158 - acc: 0.7337 - val_loss: 0.6881 - val_acc: 0.6042\n",
            "Epoch 458/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5478 - acc: 0.7320 - val_loss: 0.6902 - val_acc: 0.5938\n",
            "Epoch 459/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5737 - acc: 0.7148 - val_loss: 0.6913 - val_acc: 0.6042\n",
            "Epoch 460/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.4818 - acc: 0.7543 - val_loss: 0.6958 - val_acc: 0.5938\n",
            "Epoch 461/1000\n",
            "37/37 [==============================] - 5s 104ms/step - loss: 0.5278 - acc: 0.7405 - val_loss: 0.6644 - val_acc: 0.6250\n",
            "Epoch 462/1000\n",
            "37/37 [==============================] - 9s 217ms/step - loss: 0.5225 - acc: 0.7199 - val_loss: 0.6920 - val_acc: 0.6042\n",
            "Epoch 463/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5218 - acc: 0.7405 - val_loss: 0.6773 - val_acc: 0.5625\n",
            "Epoch 464/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5117 - acc: 0.7371 - val_loss: 0.6888 - val_acc: 0.6250\n",
            "Epoch 465/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.4913 - acc: 0.7474 - val_loss: 0.6858 - val_acc: 0.5729\n",
            "Epoch 466/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5365 - acc: 0.7268 - val_loss: 0.6825 - val_acc: 0.6250\n",
            "Epoch 467/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5046 - acc: 0.7337 - val_loss: 0.7028 - val_acc: 0.5938\n",
            "Epoch 468/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5257 - acc: 0.7509 - val_loss: 0.6774 - val_acc: 0.6042\n",
            "Epoch 469/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.5302 - acc: 0.7491 - val_loss: 0.6835 - val_acc: 0.5938\n",
            "Epoch 470/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5382 - acc: 0.7062 - val_loss: 0.6906 - val_acc: 0.6042\n",
            "Epoch 471/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.5398 - acc: 0.7234 - val_loss: 0.6784 - val_acc: 0.6042\n",
            "Epoch 472/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5066 - acc: 0.7526 - val_loss: 0.6885 - val_acc: 0.6042\n",
            "Epoch 473/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.5331 - acc: 0.7440 - val_loss: 0.6931 - val_acc: 0.5938\n",
            "Epoch 474/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.5430 - acc: 0.7165 - val_loss: 0.6782 - val_acc: 0.6354\n",
            "Epoch 475/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5166 - acc: 0.7440 - val_loss: 0.6754 - val_acc: 0.6250\n",
            "Epoch 476/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.4875 - acc: 0.7577 - val_loss: 0.6794 - val_acc: 0.5938\n",
            "Epoch 477/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5301 - acc: 0.7302 - val_loss: 0.6967 - val_acc: 0.5938\n",
            "Epoch 478/1000\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 0.5467 - acc: 0.7131 - val_loss: 0.6836 - val_acc: 0.6042\n",
            "Epoch 479/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.5062 - acc: 0.7646 - val_loss: 0.6786 - val_acc: 0.6250\n",
            "Epoch 480/1000\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 0.4822 - acc: 0.7698 - val_loss: 0.6976 - val_acc: 0.5625\n",
            "Epoch 481/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5071 - acc: 0.7320 - val_loss: 0.6842 - val_acc: 0.6146\n",
            "Epoch 482/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5284 - acc: 0.7337 - val_loss: 0.6937 - val_acc: 0.6146\n",
            "Epoch 483/1000\n",
            "37/37 [==============================] - 5s 108ms/step - loss: 0.5329 - acc: 0.7182 - val_loss: 0.6821 - val_acc: 0.6146\n",
            "Epoch 484/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5055 - acc: 0.7560 - val_loss: 0.6689 - val_acc: 0.6354\n",
            "Epoch 485/1000\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.5417 - acc: 0.7216 - val_loss: 0.6816 - val_acc: 0.6042\n",
            "Epoch 486/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5204 - acc: 0.7405 - val_loss: 0.6796 - val_acc: 0.5833\n",
            "Epoch 487/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5245 - acc: 0.7491 - val_loss: 0.6801 - val_acc: 0.6146\n",
            "Epoch 488/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5314 - acc: 0.7337 - val_loss: 0.6827 - val_acc: 0.6042\n",
            "Epoch 489/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.5100 - acc: 0.7320 - val_loss: 0.6797 - val_acc: 0.6042\n",
            "Epoch 490/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5162 - acc: 0.7405 - val_loss: 0.6778 - val_acc: 0.5938\n",
            "Epoch 491/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5332 - acc: 0.7234 - val_loss: 0.6694 - val_acc: 0.6250\n",
            "Epoch 492/1000\n",
            "37/37 [==============================] - 5s 113ms/step - loss: 0.5246 - acc: 0.7543 - val_loss: 0.6726 - val_acc: 0.5833\n",
            "Epoch 493/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.5574 - acc: 0.7165 - val_loss: 0.6831 - val_acc: 0.5625\n",
            "Epoch 494/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5169 - acc: 0.7440 - val_loss: 0.6694 - val_acc: 0.6250\n",
            "Epoch 495/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5281 - acc: 0.7320 - val_loss: 0.6806 - val_acc: 0.6146\n",
            "Epoch 496/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.4994 - acc: 0.7560 - val_loss: 0.6754 - val_acc: 0.6250\n",
            "Epoch 497/1000\n",
            "37/37 [==============================] - 4s 81ms/step - loss: 0.5197 - acc: 0.7388 - val_loss: 0.6845 - val_acc: 0.5938\n",
            "Epoch 498/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5177 - acc: 0.7526 - val_loss: 0.6808 - val_acc: 0.6042\n",
            "Epoch 499/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5363 - acc: 0.7302 - val_loss: 0.6688 - val_acc: 0.6146\n",
            "Epoch 500/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.5085 - acc: 0.7509 - val_loss: 0.6723 - val_acc: 0.6146\n",
            "Epoch 501/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5131 - acc: 0.7491 - val_loss: 0.6780 - val_acc: 0.6042\n",
            "Epoch 502/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.5200 - acc: 0.7577 - val_loss: 0.6621 - val_acc: 0.6250\n",
            "Epoch 503/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5411 - acc: 0.7148 - val_loss: 0.6712 - val_acc: 0.6146\n",
            "Epoch 504/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5195 - acc: 0.7354 - val_loss: 0.6743 - val_acc: 0.6146\n",
            "Epoch 505/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5057 - acc: 0.7423 - val_loss: 0.6525 - val_acc: 0.6146\n",
            "Epoch 506/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5026 - acc: 0.7560 - val_loss: 0.6679 - val_acc: 0.5938\n",
            "Epoch 507/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.5242 - acc: 0.7268 - val_loss: 0.6728 - val_acc: 0.6146\n",
            "Epoch 508/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5362 - acc: 0.7285 - val_loss: 0.6749 - val_acc: 0.5625\n",
            "Epoch 509/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5746 - acc: 0.7131 - val_loss: 0.6620 - val_acc: 0.6250\n",
            "Epoch 510/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5360 - acc: 0.7405 - val_loss: 0.6887 - val_acc: 0.6042\n",
            "Epoch 511/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5394 - acc: 0.7399 - val_loss: 0.6823 - val_acc: 0.6042\n",
            "Epoch 512/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5560 - acc: 0.7165 - val_loss: 0.6741 - val_acc: 0.6146\n",
            "Epoch 513/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.4994 - acc: 0.7526 - val_loss: 0.6858 - val_acc: 0.6042\n",
            "Epoch 514/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.5235 - acc: 0.7440 - val_loss: 0.6821 - val_acc: 0.5833\n",
            "Epoch 515/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.5393 - acc: 0.7354 - val_loss: 0.6949 - val_acc: 0.6042\n",
            "Epoch 516/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.5492 - acc: 0.7216 - val_loss: 0.6903 - val_acc: 0.6042\n",
            "Epoch 517/1000\n",
            "37/37 [==============================] - 5s 106ms/step - loss: 0.5547 - acc: 0.7354 - val_loss: 0.6829 - val_acc: 0.6250\n",
            "Epoch 518/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5631 - acc: 0.7182 - val_loss: 0.6849 - val_acc: 0.6042\n",
            "Epoch 519/1000\n",
            "37/37 [==============================] - 5s 102ms/step - loss: 0.4833 - acc: 0.7629 - val_loss: 0.6780 - val_acc: 0.6250\n",
            "Epoch 520/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.4909 - acc: 0.7543 - val_loss: 0.6855 - val_acc: 0.6146\n",
            "Epoch 521/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5259 - acc: 0.7297 - val_loss: 0.6858 - val_acc: 0.6042\n",
            "Epoch 522/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.5442 - acc: 0.7285 - val_loss: 0.6936 - val_acc: 0.5938\n",
            "Epoch 523/1000\n",
            "37/37 [==============================] - 5s 110ms/step - loss: 0.5120 - acc: 0.7234 - val_loss: 0.6786 - val_acc: 0.6042\n",
            "Epoch 524/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5019 - acc: 0.7629 - val_loss: 0.6714 - val_acc: 0.6146\n",
            "Epoch 525/1000\n",
            "37/37 [==============================] - 9s 245ms/step - loss: 0.5393 - acc: 0.7216 - val_loss: 0.6745 - val_acc: 0.6250\n",
            "Epoch 526/1000\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.5239 - acc: 0.7371 - val_loss: 0.6960 - val_acc: 0.6042\n",
            "Epoch 527/1000\n",
            "37/37 [==============================] - 5s 112ms/step - loss: 0.5196 - acc: 0.7405 - val_loss: 0.6780 - val_acc: 0.6458\n",
            "Epoch 528/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.5563 - acc: 0.7062 - val_loss: 0.6782 - val_acc: 0.5938\n",
            "Epoch 529/1000\n",
            "37/37 [==============================] - 9s 217ms/step - loss: 0.5153 - acc: 0.7268 - val_loss: 0.6720 - val_acc: 0.6250\n",
            "Epoch 530/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.5472 - acc: 0.7297 - val_loss: 0.6855 - val_acc: 0.6042\n",
            "Epoch 531/1000\n",
            "37/37 [==============================] - 9s 218ms/step - loss: 0.5225 - acc: 0.7354 - val_loss: 0.6656 - val_acc: 0.6458\n",
            "Epoch 532/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.5091 - acc: 0.7612 - val_loss: 0.6928 - val_acc: 0.6146\n",
            "Epoch 533/1000\n",
            "37/37 [==============================] - 9s 218ms/step - loss: 0.5321 - acc: 0.7423 - val_loss: 0.6732 - val_acc: 0.6354\n",
            "Epoch 534/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5378 - acc: 0.7320 - val_loss: 0.6887 - val_acc: 0.6042\n",
            "Epoch 535/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5059 - acc: 0.7474 - val_loss: 0.6940 - val_acc: 0.6042\n",
            "Epoch 536/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.5117 - acc: 0.7365 - val_loss: 0.6938 - val_acc: 0.6354\n",
            "Epoch 537/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.4848 - acc: 0.7560 - val_loss: 0.6875 - val_acc: 0.6354\n",
            "Epoch 538/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5352 - acc: 0.7337 - val_loss: 0.6791 - val_acc: 0.6146\n",
            "Epoch 539/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.5151 - acc: 0.7526 - val_loss: 0.6920 - val_acc: 0.6146\n",
            "Epoch 540/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5038 - acc: 0.7509 - val_loss: 0.6961 - val_acc: 0.5938\n",
            "Epoch 541/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.4783 - acc: 0.7955 - val_loss: 0.6798 - val_acc: 0.6146\n",
            "Epoch 542/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.4904 - acc: 0.7646 - val_loss: 0.6656 - val_acc: 0.6146\n",
            "Epoch 543/1000\n",
            "37/37 [==============================] - 3s 83ms/step - loss: 0.5287 - acc: 0.7354 - val_loss: 0.6926 - val_acc: 0.5938\n",
            "Epoch 544/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5346 - acc: 0.7302 - val_loss: 0.6694 - val_acc: 0.6146\n",
            "Epoch 545/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.5269 - acc: 0.7182 - val_loss: 0.6738 - val_acc: 0.6146\n",
            "Epoch 546/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5166 - acc: 0.7423 - val_loss: 0.6884 - val_acc: 0.5938\n",
            "Epoch 547/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.5172 - acc: 0.7474 - val_loss: 0.6869 - val_acc: 0.6354\n",
            "Epoch 548/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5247 - acc: 0.7148 - val_loss: 0.6665 - val_acc: 0.6250\n",
            "Epoch 549/1000\n",
            "37/37 [==============================] - 5s 113ms/step - loss: 0.5274 - acc: 0.7285 - val_loss: 0.6830 - val_acc: 0.5938\n",
            "Epoch 550/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5224 - acc: 0.7526 - val_loss: 0.6806 - val_acc: 0.6146\n",
            "Epoch 551/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5575 - acc: 0.7268 - val_loss: 0.6568 - val_acc: 0.6354\n",
            "Epoch 552/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.5050 - acc: 0.7680 - val_loss: 0.6625 - val_acc: 0.6146\n",
            "Epoch 553/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5133 - acc: 0.7509 - val_loss: 0.6708 - val_acc: 0.6042\n",
            "Epoch 554/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5209 - acc: 0.7251 - val_loss: 0.6657 - val_acc: 0.6146\n",
            "Epoch 555/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5097 - acc: 0.7474 - val_loss: 0.6696 - val_acc: 0.6042\n",
            "Epoch 556/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.4894 - acc: 0.7440 - val_loss: 0.6547 - val_acc: 0.6354\n",
            "Epoch 557/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.4879 - acc: 0.7646 - val_loss: 0.6544 - val_acc: 0.6146\n",
            "Epoch 558/1000\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 0.5240 - acc: 0.7182 - val_loss: 0.6877 - val_acc: 0.5938\n",
            "Epoch 559/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5270 - acc: 0.7423 - val_loss: 0.6841 - val_acc: 0.6042\n",
            "Epoch 560/1000\n",
            "37/37 [==============================] - 5s 106ms/step - loss: 0.5426 - acc: 0.7113 - val_loss: 0.6629 - val_acc: 0.6250\n",
            "Epoch 561/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5208 - acc: 0.7388 - val_loss: 0.6644 - val_acc: 0.6250\n",
            "Epoch 562/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5059 - acc: 0.7680 - val_loss: 0.6824 - val_acc: 0.6146\n",
            "Epoch 563/1000\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.5455 - acc: 0.7405 - val_loss: 0.6982 - val_acc: 0.6250\n",
            "Epoch 564/1000\n",
            "37/37 [==============================] - 3s 83ms/step - loss: 0.5110 - acc: 0.7680 - val_loss: 0.6776 - val_acc: 0.6250\n",
            "Epoch 565/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5246 - acc: 0.7423 - val_loss: 0.6678 - val_acc: 0.6458\n",
            "Epoch 566/1000\n",
            "37/37 [==============================] - 5s 110ms/step - loss: 0.5352 - acc: 0.7148 - val_loss: 0.6726 - val_acc: 0.6146\n",
            "Epoch 567/1000\n",
            "37/37 [==============================] - 9s 214ms/step - loss: 0.4895 - acc: 0.7371 - val_loss: 0.6910 - val_acc: 0.5938\n",
            "Epoch 568/1000\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 0.5245 - acc: 0.7405 - val_loss: 0.6932 - val_acc: 0.5938\n",
            "Epoch 569/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5408 - acc: 0.7148 - val_loss: 0.6803 - val_acc: 0.6042\n",
            "Epoch 570/1000\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.4920 - acc: 0.7560 - val_loss: 0.6694 - val_acc: 0.6146\n",
            "Epoch 571/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.5208 - acc: 0.7354 - val_loss: 0.6726 - val_acc: 0.6146\n",
            "Epoch 572/1000\n",
            "37/37 [==============================] - 4s 82ms/step - loss: 0.4946 - acc: 0.7388 - val_loss: 0.6614 - val_acc: 0.6146\n",
            "Epoch 573/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5100 - acc: 0.7354 - val_loss: 0.6723 - val_acc: 0.6042\n",
            "Epoch 574/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.5009 - acc: 0.7663 - val_loss: 0.6849 - val_acc: 0.5833\n",
            "Epoch 575/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.4991 - acc: 0.7629 - val_loss: 0.6615 - val_acc: 0.6146\n",
            "Epoch 576/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.5064 - acc: 0.7302 - val_loss: 0.6837 - val_acc: 0.5938\n",
            "Epoch 577/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.5254 - acc: 0.7423 - val_loss: 0.6641 - val_acc: 0.6042\n",
            "Epoch 578/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.4966 - acc: 0.7595 - val_loss: 0.6730 - val_acc: 0.6042\n",
            "Epoch 579/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5342 - acc: 0.7113 - val_loss: 0.6621 - val_acc: 0.6354\n",
            "Epoch 580/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.5142 - acc: 0.7320 - val_loss: 0.6914 - val_acc: 0.6146\n",
            "Epoch 581/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.5037 - acc: 0.7423 - val_loss: 0.6744 - val_acc: 0.5938\n",
            "Epoch 582/1000\n",
            "37/37 [==============================] - 3s 83ms/step - loss: 0.5167 - acc: 0.7423 - val_loss: 0.6595 - val_acc: 0.6250\n",
            "Epoch 583/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.4737 - acc: 0.7732 - val_loss: 0.6828 - val_acc: 0.5938\n",
            "Epoch 584/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5265 - acc: 0.7230 - val_loss: 0.6513 - val_acc: 0.6354\n",
            "Epoch 585/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.5142 - acc: 0.7474 - val_loss: 0.6835 - val_acc: 0.5938\n",
            "Epoch 586/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5272 - acc: 0.7440 - val_loss: 0.6601 - val_acc: 0.6250\n",
            "Epoch 587/1000\n",
            "37/37 [==============================] - 9s 218ms/step - loss: 0.5154 - acc: 0.7491 - val_loss: 0.6741 - val_acc: 0.5938\n",
            "Epoch 588/1000\n",
            "37/37 [==============================] - 9s 239ms/step - loss: 0.5136 - acc: 0.7663 - val_loss: 0.6777 - val_acc: 0.5938\n",
            "Epoch 589/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5203 - acc: 0.7509 - val_loss: 0.6791 - val_acc: 0.5938\n",
            "Epoch 590/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.5110 - acc: 0.7302 - val_loss: 0.6736 - val_acc: 0.6250\n",
            "Epoch 591/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.5435 - acc: 0.7216 - val_loss: 0.6783 - val_acc: 0.6146\n",
            "Epoch 592/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5409 - acc: 0.7216 - val_loss: 0.6686 - val_acc: 0.5833\n",
            "Epoch 593/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.4882 - acc: 0.7595 - val_loss: 0.6577 - val_acc: 0.6354\n",
            "Epoch 594/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5237 - acc: 0.7354 - val_loss: 0.6823 - val_acc: 0.6042\n",
            "Epoch 595/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5173 - acc: 0.7440 - val_loss: 0.6778 - val_acc: 0.6250\n",
            "Epoch 596/1000\n",
            "37/37 [==============================] - 4s 82ms/step - loss: 0.4998 - acc: 0.7577 - val_loss: 0.6745 - val_acc: 0.6250\n",
            "Epoch 597/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.5495 - acc: 0.7405 - val_loss: 0.6593 - val_acc: 0.6250\n",
            "Epoch 598/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.5381 - acc: 0.7474 - val_loss: 0.6756 - val_acc: 0.6250\n",
            "Epoch 599/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.5275 - acc: 0.7131 - val_loss: 0.6664 - val_acc: 0.5729\n",
            "Epoch 600/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.5464 - acc: 0.7268 - val_loss: 0.6718 - val_acc: 0.5938\n",
            "Epoch 601/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5112 - acc: 0.7320 - val_loss: 0.6842 - val_acc: 0.5938\n",
            "Epoch 602/1000\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 0.5087 - acc: 0.7405 - val_loss: 0.6819 - val_acc: 0.5833\n",
            "Epoch 603/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.4863 - acc: 0.7595 - val_loss: 0.6719 - val_acc: 0.6042\n",
            "Epoch 604/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.5064 - acc: 0.7663 - val_loss: 0.6809 - val_acc: 0.6250\n",
            "Epoch 605/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.5467 - acc: 0.7285 - val_loss: 0.6689 - val_acc: 0.6250\n",
            "Epoch 606/1000\n",
            "37/37 [==============================] - 5s 105ms/step - loss: 0.5215 - acc: 0.7354 - val_loss: 0.6771 - val_acc: 0.6250\n",
            "Epoch 607/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5030 - acc: 0.7457 - val_loss: 0.6636 - val_acc: 0.6042\n",
            "Epoch 608/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5420 - acc: 0.7320 - val_loss: 0.6545 - val_acc: 0.6250\n",
            "Epoch 609/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5499 - acc: 0.7079 - val_loss: 0.6818 - val_acc: 0.6146\n",
            "Epoch 610/1000\n",
            "37/37 [==============================] - 8s 223ms/step - loss: 0.5196 - acc: 0.7302 - val_loss: 0.6862 - val_acc: 0.6042\n",
            "Epoch 611/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.5168 - acc: 0.7251 - val_loss: 0.6699 - val_acc: 0.6250\n",
            "Epoch 612/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.5299 - acc: 0.7337 - val_loss: 0.6890 - val_acc: 0.5938\n",
            "Epoch 613/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.5098 - acc: 0.7405 - val_loss: 0.6790 - val_acc: 0.6042\n",
            "Epoch 614/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5296 - acc: 0.7440 - val_loss: 0.6751 - val_acc: 0.6250\n",
            "Epoch 615/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.5389 - acc: 0.7131 - val_loss: 0.6750 - val_acc: 0.6250\n",
            "Epoch 616/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5066 - acc: 0.7698 - val_loss: 0.6782 - val_acc: 0.5729\n",
            "Epoch 617/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5072 - acc: 0.7629 - val_loss: 0.6829 - val_acc: 0.5833\n",
            "Epoch 618/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5121 - acc: 0.7560 - val_loss: 0.6753 - val_acc: 0.6458\n",
            "Epoch 619/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5078 - acc: 0.7526 - val_loss: 0.6784 - val_acc: 0.6146\n",
            "Epoch 620/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.5386 - acc: 0.7268 - val_loss: 0.6907 - val_acc: 0.6250\n",
            "Epoch 621/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5132 - acc: 0.7405 - val_loss: 0.6793 - val_acc: 0.6146\n",
            "Epoch 622/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5262 - acc: 0.7474 - val_loss: 0.6882 - val_acc: 0.6146\n",
            "Epoch 623/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.5207 - acc: 0.7440 - val_loss: 0.6822 - val_acc: 0.5938\n",
            "Epoch 624/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.5144 - acc: 0.7457 - val_loss: 0.6673 - val_acc: 0.6250\n",
            "Epoch 625/1000\n",
            "37/37 [==============================] - 5s 116ms/step - loss: 0.5002 - acc: 0.7551 - val_loss: 0.6715 - val_acc: 0.6250\n",
            "Epoch 626/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5191 - acc: 0.7491 - val_loss: 0.6932 - val_acc: 0.6146\n",
            "Epoch 627/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.4964 - acc: 0.7526 - val_loss: 0.6819 - val_acc: 0.6042\n",
            "Epoch 628/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.5148 - acc: 0.7526 - val_loss: 0.6886 - val_acc: 0.6354\n",
            "Epoch 629/1000\n",
            "37/37 [==============================] - 9s 242ms/step - loss: 0.5144 - acc: 0.7543 - val_loss: 0.6797 - val_acc: 0.6354\n",
            "Epoch 630/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5063 - acc: 0.7543 - val_loss: 0.6697 - val_acc: 0.6146\n",
            "Epoch 631/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.5098 - acc: 0.7423 - val_loss: 0.6682 - val_acc: 0.5938\n",
            "Epoch 632/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.5473 - acc: 0.7251 - val_loss: 0.6765 - val_acc: 0.6042\n",
            "Epoch 633/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.5154 - acc: 0.7491 - val_loss: 0.6935 - val_acc: 0.6042\n",
            "Epoch 634/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5245 - acc: 0.7405 - val_loss: 0.6637 - val_acc: 0.6354\n",
            "Epoch 635/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5308 - acc: 0.7423 - val_loss: 0.6772 - val_acc: 0.6458\n",
            "Epoch 636/1000\n",
            "37/37 [==============================] - 9s 216ms/step - loss: 0.5010 - acc: 0.7577 - val_loss: 0.6823 - val_acc: 0.6354\n",
            "Epoch 637/1000\n",
            "37/37 [==============================] - 9s 239ms/step - loss: 0.4838 - acc: 0.7818 - val_loss: 0.7034 - val_acc: 0.6146\n",
            "Epoch 638/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5039 - acc: 0.7612 - val_loss: 0.6727 - val_acc: 0.6250\n",
            "Epoch 639/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5043 - acc: 0.7423 - val_loss: 0.6752 - val_acc: 0.6146\n",
            "Epoch 640/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.4956 - acc: 0.7577 - val_loss: 0.6864 - val_acc: 0.5938\n",
            "Epoch 641/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5101 - acc: 0.7440 - val_loss: 0.6925 - val_acc: 0.6250\n",
            "Epoch 642/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.5180 - acc: 0.7595 - val_loss: 0.6933 - val_acc: 0.6354\n",
            "Epoch 643/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.4972 - acc: 0.7526 - val_loss: 0.6664 - val_acc: 0.6458\n",
            "Epoch 644/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5246 - acc: 0.7680 - val_loss: 0.6778 - val_acc: 0.6458\n",
            "Epoch 645/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5259 - acc: 0.7560 - val_loss: 0.6772 - val_acc: 0.6250\n",
            "Epoch 646/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.5000 - acc: 0.7457 - val_loss: 0.7013 - val_acc: 0.6250\n",
            "Epoch 647/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5389 - acc: 0.7405 - val_loss: 0.6764 - val_acc: 0.6146\n",
            "Epoch 648/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.5051 - acc: 0.7432 - val_loss: 0.6940 - val_acc: 0.6250\n",
            "Epoch 649/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5231 - acc: 0.7388 - val_loss: 0.6883 - val_acc: 0.6250\n",
            "Epoch 650/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5018 - acc: 0.7405 - val_loss: 0.6881 - val_acc: 0.5729\n",
            "Epoch 651/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.5439 - acc: 0.7199 - val_loss: 0.6743 - val_acc: 0.6146\n",
            "Epoch 652/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.5201 - acc: 0.7382 - val_loss: 0.6889 - val_acc: 0.5938\n",
            "Epoch 653/1000\n",
            "37/37 [==============================] - 9s 220ms/step - loss: 0.5300 - acc: 0.7251 - val_loss: 0.6735 - val_acc: 0.6146\n",
            "Epoch 654/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5290 - acc: 0.7354 - val_loss: 0.6751 - val_acc: 0.6146\n",
            "Epoch 655/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5075 - acc: 0.7595 - val_loss: 0.6861 - val_acc: 0.6250\n",
            "Epoch 656/1000\n",
            "37/37 [==============================] - 5s 115ms/step - loss: 0.5067 - acc: 0.7440 - val_loss: 0.6718 - val_acc: 0.6250\n",
            "Epoch 657/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.4865 - acc: 0.7698 - val_loss: 0.6719 - val_acc: 0.6042\n",
            "Epoch 658/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5104 - acc: 0.7646 - val_loss: 0.6796 - val_acc: 0.5938\n",
            "Epoch 659/1000\n",
            "37/37 [==============================] - 5s 109ms/step - loss: 0.5245 - acc: 0.7337 - val_loss: 0.6907 - val_acc: 0.6042\n",
            "Epoch 660/1000\n",
            "37/37 [==============================] - 9s 217ms/step - loss: 0.5088 - acc: 0.7526 - val_loss: 0.6972 - val_acc: 0.5938\n",
            "Epoch 661/1000\n",
            "37/37 [==============================] - 4s 110ms/step - loss: 0.4718 - acc: 0.7663 - val_loss: 0.6910 - val_acc: 0.6042\n",
            "Epoch 662/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.5272 - acc: 0.7320 - val_loss: 0.6930 - val_acc: 0.6354\n",
            "Epoch 663/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.5106 - acc: 0.7646 - val_loss: 0.6879 - val_acc: 0.6458\n",
            "Epoch 664/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5170 - acc: 0.7423 - val_loss: 0.7012 - val_acc: 0.6146\n",
            "Epoch 665/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5078 - acc: 0.7560 - val_loss: 0.6657 - val_acc: 0.6250\n",
            "Epoch 666/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.5428 - acc: 0.7371 - val_loss: 0.6716 - val_acc: 0.6146\n",
            "Epoch 667/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.5120 - acc: 0.7388 - val_loss: 0.6872 - val_acc: 0.6458\n",
            "Epoch 668/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5313 - acc: 0.7199 - val_loss: 0.6886 - val_acc: 0.5833\n",
            "Epoch 669/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5290 - acc: 0.7354 - val_loss: 0.6638 - val_acc: 0.6250\n",
            "Epoch 670/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.5075 - acc: 0.7474 - val_loss: 0.6930 - val_acc: 0.6250\n",
            "Epoch 671/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5333 - acc: 0.7251 - val_loss: 0.6764 - val_acc: 0.6458\n",
            "Epoch 672/1000\n",
            "37/37 [==============================] - 3s 83ms/step - loss: 0.5394 - acc: 0.7079 - val_loss: 0.6826 - val_acc: 0.6354\n",
            "Epoch 673/1000\n",
            "37/37 [==============================] - 9s 219ms/step - loss: 0.4984 - acc: 0.7577 - val_loss: 0.6921 - val_acc: 0.5833\n",
            "Epoch 674/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5292 - acc: 0.7182 - val_loss: 0.6734 - val_acc: 0.6250\n",
            "Epoch 675/1000\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 0.5414 - acc: 0.7337 - val_loss: 0.6875 - val_acc: 0.6250\n",
            "Epoch 676/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5334 - acc: 0.7096 - val_loss: 0.6681 - val_acc: 0.6354\n",
            "Epoch 677/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.4744 - acc: 0.7784 - val_loss: 0.6774 - val_acc: 0.6354\n",
            "Epoch 678/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5407 - acc: 0.7371 - val_loss: 0.6904 - val_acc: 0.6250\n",
            "Epoch 679/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.5479 - acc: 0.7148 - val_loss: 0.6780 - val_acc: 0.6146\n",
            "Epoch 680/1000\n",
            "37/37 [==============================] - 5s 115ms/step - loss: 0.5156 - acc: 0.7388 - val_loss: 0.6716 - val_acc: 0.6354\n",
            "Epoch 681/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.4858 - acc: 0.7663 - val_loss: 0.6751 - val_acc: 0.6250\n",
            "Epoch 682/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.5515 - acc: 0.7096 - val_loss: 0.6754 - val_acc: 0.6354\n",
            "Epoch 683/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.5391 - acc: 0.7268 - val_loss: 0.6628 - val_acc: 0.6562\n",
            "Epoch 684/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5271 - acc: 0.7251 - val_loss: 0.6672 - val_acc: 0.6458\n",
            "Epoch 685/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5067 - acc: 0.7474 - val_loss: 0.6696 - val_acc: 0.6354\n",
            "Epoch 686/1000\n",
            "37/37 [==============================] - 9s 219ms/step - loss: 0.4975 - acc: 0.7595 - val_loss: 0.6695 - val_acc: 0.6458\n",
            "Epoch 687/1000\n",
            "37/37 [==============================] - 5s 112ms/step - loss: 0.5354 - acc: 0.7302 - val_loss: 0.6780 - val_acc: 0.5938\n",
            "Epoch 688/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.5100 - acc: 0.7491 - val_loss: 0.6641 - val_acc: 0.5938\n",
            "Epoch 689/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5149 - acc: 0.7509 - val_loss: 0.6735 - val_acc: 0.6354\n",
            "Epoch 690/1000\n",
            "37/37 [==============================] - 4s 82ms/step - loss: 0.5152 - acc: 0.7234 - val_loss: 0.6780 - val_acc: 0.6042\n",
            "Epoch 691/1000\n",
            "37/37 [==============================] - 9s 218ms/step - loss: 0.5036 - acc: 0.7509 - val_loss: 0.6768 - val_acc: 0.6354\n",
            "Epoch 692/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5349 - acc: 0.7251 - val_loss: 0.6790 - val_acc: 0.6354\n",
            "Epoch 693/1000\n",
            "37/37 [==============================] - 9s 241ms/step - loss: 0.5162 - acc: 0.7457 - val_loss: 0.6623 - val_acc: 0.6250\n",
            "Epoch 694/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5179 - acc: 0.7405 - val_loss: 0.6739 - val_acc: 0.6458\n",
            "Epoch 695/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5215 - acc: 0.7199 - val_loss: 0.6816 - val_acc: 0.6250\n",
            "Epoch 696/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.5157 - acc: 0.7268 - val_loss: 0.6873 - val_acc: 0.5833\n",
            "Epoch 697/1000\n",
            "37/37 [==============================] - 5s 113ms/step - loss: 0.5115 - acc: 0.7612 - val_loss: 0.6670 - val_acc: 0.6354\n",
            "Epoch 698/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5180 - acc: 0.7285 - val_loss: 0.7027 - val_acc: 0.6146\n",
            "Epoch 699/1000\n",
            "37/37 [==============================] - 4s 82ms/step - loss: 0.4901 - acc: 0.7526 - val_loss: 0.6667 - val_acc: 0.6146\n",
            "Epoch 700/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.5141 - acc: 0.7457 - val_loss: 0.6817 - val_acc: 0.6354\n",
            "Epoch 701/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5344 - acc: 0.7337 - val_loss: 0.6820 - val_acc: 0.6354\n",
            "Epoch 702/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.5444 - acc: 0.7285 - val_loss: 0.6760 - val_acc: 0.6354\n",
            "Epoch 703/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.5222 - acc: 0.7371 - val_loss: 0.6786 - val_acc: 0.6458\n",
            "Epoch 704/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5352 - acc: 0.7165 - val_loss: 0.6867 - val_acc: 0.6042\n",
            "Epoch 705/1000\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.5124 - acc: 0.7526 - val_loss: 0.6818 - val_acc: 0.6354\n",
            "Epoch 706/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.5125 - acc: 0.7251 - val_loss: 0.6945 - val_acc: 0.6146\n",
            "Epoch 707/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.4905 - acc: 0.7595 - val_loss: 0.6616 - val_acc: 0.6250\n",
            "Epoch 708/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.5057 - acc: 0.7543 - val_loss: 0.6556 - val_acc: 0.6146\n",
            "Epoch 709/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.5238 - acc: 0.7474 - val_loss: 0.6893 - val_acc: 0.6146\n",
            "Epoch 710/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5162 - acc: 0.7302 - val_loss: 0.6851 - val_acc: 0.5833\n",
            "Epoch 711/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5062 - acc: 0.7491 - val_loss: 0.6613 - val_acc: 0.6042\n",
            "Epoch 712/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5090 - acc: 0.7320 - val_loss: 0.6681 - val_acc: 0.6354\n",
            "Epoch 713/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.4926 - acc: 0.7801 - val_loss: 0.6772 - val_acc: 0.6042\n",
            "Epoch 714/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5172 - acc: 0.7388 - val_loss: 0.6611 - val_acc: 0.6354\n",
            "Epoch 715/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5368 - acc: 0.7371 - val_loss: 0.6694 - val_acc: 0.6146\n",
            "Epoch 716/1000\n",
            "37/37 [==============================] - 9s 218ms/step - loss: 0.5203 - acc: 0.7199 - val_loss: 0.6784 - val_acc: 0.6354\n",
            "Epoch 717/1000\n",
            "37/37 [==============================] - 9s 243ms/step - loss: 0.5016 - acc: 0.7474 - val_loss: 0.6971 - val_acc: 0.6042\n",
            "Epoch 718/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5254 - acc: 0.7302 - val_loss: 0.6708 - val_acc: 0.6354\n",
            "Epoch 719/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.5113 - acc: 0.7534 - val_loss: 0.6797 - val_acc: 0.6250\n",
            "Epoch 720/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5294 - acc: 0.7474 - val_loss: 0.6891 - val_acc: 0.5833\n",
            "Epoch 721/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5181 - acc: 0.7474 - val_loss: 0.6783 - val_acc: 0.5833\n",
            "Epoch 722/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5242 - acc: 0.7405 - val_loss: 0.6686 - val_acc: 0.6042\n",
            "Epoch 723/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.5452 - acc: 0.7251 - val_loss: 0.6883 - val_acc: 0.6250\n",
            "Epoch 724/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5037 - acc: 0.7466 - val_loss: 0.6642 - val_acc: 0.6458\n",
            "Epoch 725/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5132 - acc: 0.7526 - val_loss: 0.6859 - val_acc: 0.6354\n",
            "Epoch 726/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.5301 - acc: 0.7457 - val_loss: 0.6891 - val_acc: 0.6250\n",
            "Epoch 727/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5019 - acc: 0.7629 - val_loss: 0.6802 - val_acc: 0.6250\n",
            "Epoch 728/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.5545 - acc: 0.6907 - val_loss: 0.6931 - val_acc: 0.6250\n",
            "Epoch 729/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.5009 - acc: 0.7612 - val_loss: 0.6460 - val_acc: 0.6562\n",
            "Epoch 730/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5028 - acc: 0.7354 - val_loss: 0.6910 - val_acc: 0.6354\n",
            "Epoch 731/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5006 - acc: 0.7371 - val_loss: 0.6717 - val_acc: 0.6458\n",
            "Epoch 732/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5000 - acc: 0.7234 - val_loss: 0.6940 - val_acc: 0.6250\n",
            "Epoch 733/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5437 - acc: 0.7388 - val_loss: 0.6648 - val_acc: 0.6458\n",
            "Epoch 734/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5347 - acc: 0.7388 - val_loss: 0.6756 - val_acc: 0.6354\n",
            "Epoch 735/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.5062 - acc: 0.7543 - val_loss: 0.6822 - val_acc: 0.6354\n",
            "Epoch 736/1000\n",
            "37/37 [==============================] - 9s 217ms/step - loss: 0.5114 - acc: 0.7354 - val_loss: 0.6800 - val_acc: 0.6354\n",
            "Epoch 737/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5206 - acc: 0.7491 - val_loss: 0.6741 - val_acc: 0.6042\n",
            "Epoch 738/1000\n",
            "37/37 [==============================] - 4s 81ms/step - loss: 0.5270 - acc: 0.7320 - val_loss: 0.6901 - val_acc: 0.5938\n",
            "Epoch 739/1000\n",
            "37/37 [==============================] - 9s 216ms/step - loss: 0.5200 - acc: 0.7268 - val_loss: 0.6773 - val_acc: 0.6354\n",
            "Epoch 740/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5080 - acc: 0.7440 - val_loss: 0.6932 - val_acc: 0.6146\n",
            "Epoch 741/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.4962 - acc: 0.7577 - val_loss: 0.6829 - val_acc: 0.6250\n",
            "Epoch 742/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5297 - acc: 0.7251 - val_loss: 0.6647 - val_acc: 0.6354\n",
            "Epoch 743/1000\n",
            "37/37 [==============================] - 4s 110ms/step - loss: 0.5098 - acc: 0.7646 - val_loss: 0.6800 - val_acc: 0.6250\n",
            "Epoch 744/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5358 - acc: 0.7457 - val_loss: 0.6659 - val_acc: 0.6354\n",
            "Epoch 745/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.5300 - acc: 0.7285 - val_loss: 0.6890 - val_acc: 0.6146\n",
            "Epoch 746/1000\n",
            "37/37 [==============================] - 5s 115ms/step - loss: 0.5206 - acc: 0.7234 - val_loss: 0.6942 - val_acc: 0.6250\n",
            "Epoch 747/1000\n",
            "37/37 [==============================] - 4s 82ms/step - loss: 0.5604 - acc: 0.7234 - val_loss: 0.6829 - val_acc: 0.6250\n",
            "Epoch 748/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5049 - acc: 0.7612 - val_loss: 0.6829 - val_acc: 0.6146\n",
            "Epoch 749/1000\n",
            "37/37 [==============================] - 9s 239ms/step - loss: 0.4702 - acc: 0.7698 - val_loss: 0.6769 - val_acc: 0.6146\n",
            "Epoch 750/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5190 - acc: 0.7371 - val_loss: 0.6717 - val_acc: 0.6146\n",
            "Epoch 751/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5039 - acc: 0.7526 - val_loss: 0.6702 - val_acc: 0.6146\n",
            "Epoch 752/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5049 - acc: 0.7440 - val_loss: 0.6950 - val_acc: 0.6250\n",
            "Epoch 753/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5408 - acc: 0.7285 - val_loss: 0.6811 - val_acc: 0.6354\n",
            "Epoch 754/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.5172 - acc: 0.7423 - val_loss: 0.6902 - val_acc: 0.6250\n",
            "Epoch 755/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.4818 - acc: 0.7749 - val_loss: 0.6834 - val_acc: 0.6458\n",
            "Epoch 756/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5252 - acc: 0.7371 - val_loss: 0.6834 - val_acc: 0.6354\n",
            "Epoch 757/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.5149 - acc: 0.7423 - val_loss: 0.6881 - val_acc: 0.6354\n",
            "Epoch 758/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.4963 - acc: 0.7584 - val_loss: 0.6859 - val_acc: 0.6458\n",
            "Epoch 759/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.4854 - acc: 0.7732 - val_loss: 0.6720 - val_acc: 0.6354\n",
            "Epoch 760/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5106 - acc: 0.7440 - val_loss: 0.7003 - val_acc: 0.6458\n",
            "Epoch 761/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5822 - acc: 0.7010 - val_loss: 0.6934 - val_acc: 0.6250\n",
            "Epoch 762/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.4990 - acc: 0.7526 - val_loss: 0.6645 - val_acc: 0.6667\n",
            "Epoch 763/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.4840 - acc: 0.7663 - val_loss: 0.6728 - val_acc: 0.6458\n",
            "Epoch 764/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.4880 - acc: 0.7629 - val_loss: 0.6634 - val_acc: 0.6458\n",
            "Epoch 765/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.5076 - acc: 0.7629 - val_loss: 0.6956 - val_acc: 0.6250\n",
            "Epoch 766/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.5288 - acc: 0.7405 - val_loss: 0.6870 - val_acc: 0.6146\n",
            "Epoch 767/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5225 - acc: 0.7491 - val_loss: 0.6814 - val_acc: 0.6250\n",
            "Epoch 768/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.4879 - acc: 0.7595 - val_loss: 0.6542 - val_acc: 0.6562\n",
            "Epoch 769/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5074 - acc: 0.7715 - val_loss: 0.6732 - val_acc: 0.6042\n",
            "Epoch 770/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5147 - acc: 0.7732 - val_loss: 0.6762 - val_acc: 0.6146\n",
            "Epoch 771/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5132 - acc: 0.7543 - val_loss: 0.6678 - val_acc: 0.6146\n",
            "Epoch 772/1000\n",
            "37/37 [==============================] - 5s 107ms/step - loss: 0.5043 - acc: 0.7715 - val_loss: 0.6731 - val_acc: 0.6250\n",
            "Epoch 773/1000\n",
            "37/37 [==============================] - 9s 219ms/step - loss: 0.5045 - acc: 0.7440 - val_loss: 0.6765 - val_acc: 0.6250\n",
            "Epoch 774/1000\n",
            "37/37 [==============================] - 5s 113ms/step - loss: 0.5369 - acc: 0.7365 - val_loss: 0.6967 - val_acc: 0.6042\n",
            "Epoch 775/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.5182 - acc: 0.7423 - val_loss: 0.6677 - val_acc: 0.6250\n",
            "Epoch 776/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.5149 - acc: 0.7474 - val_loss: 0.6752 - val_acc: 0.6458\n",
            "Epoch 777/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.5611 - acc: 0.7302 - val_loss: 0.6840 - val_acc: 0.6250\n",
            "Epoch 778/1000\n",
            "37/37 [==============================] - 8s 223ms/step - loss: 0.5131 - acc: 0.7646 - val_loss: 0.6839 - val_acc: 0.6250\n",
            "Epoch 779/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.4989 - acc: 0.7457 - val_loss: 0.6623 - val_acc: 0.6250\n",
            "Epoch 780/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5131 - acc: 0.7474 - val_loss: 0.6658 - val_acc: 0.6354\n",
            "Epoch 781/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5052 - acc: 0.7457 - val_loss: 0.6757 - val_acc: 0.6250\n",
            "Epoch 782/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5539 - acc: 0.7165 - val_loss: 0.6795 - val_acc: 0.6354\n",
            "Epoch 783/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.5497 - acc: 0.7096 - val_loss: 0.6785 - val_acc: 0.6146\n",
            "Epoch 784/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5122 - acc: 0.7509 - val_loss: 0.6730 - val_acc: 0.6354\n",
            "Epoch 785/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5327 - acc: 0.7302 - val_loss: 0.6840 - val_acc: 0.6250\n",
            "Epoch 786/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5269 - acc: 0.7382 - val_loss: 0.6954 - val_acc: 0.6250\n",
            "Epoch 787/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5111 - acc: 0.7302 - val_loss: 0.6904 - val_acc: 0.6250\n",
            "Epoch 788/1000\n",
            "37/37 [==============================] - 9s 241ms/step - loss: 0.5065 - acc: 0.7382 - val_loss: 0.6691 - val_acc: 0.6250\n",
            "Epoch 789/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5241 - acc: 0.7526 - val_loss: 0.6788 - val_acc: 0.6146\n",
            "Epoch 790/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.5431 - acc: 0.7440 - val_loss: 0.6625 - val_acc: 0.6250\n",
            "Epoch 791/1000\n",
            "37/37 [==============================] - 9s 242ms/step - loss: 0.5148 - acc: 0.7474 - val_loss: 0.6660 - val_acc: 0.6354\n",
            "Epoch 792/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.4946 - acc: 0.7612 - val_loss: 0.6520 - val_acc: 0.6562\n",
            "Epoch 793/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5278 - acc: 0.7302 - val_loss: 0.6764 - val_acc: 0.6250\n",
            "Epoch 794/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5145 - acc: 0.7509 - val_loss: 0.6639 - val_acc: 0.6458\n",
            "Epoch 795/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.5134 - acc: 0.7474 - val_loss: 0.6672 - val_acc: 0.6354\n",
            "Epoch 796/1000\n",
            "37/37 [==============================] - 6s 137ms/step - loss: 0.5226 - acc: 0.7251 - val_loss: 0.6513 - val_acc: 0.6458\n",
            "Epoch 797/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5489 - acc: 0.7268 - val_loss: 0.6681 - val_acc: 0.6250\n",
            "Epoch 798/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.5171 - acc: 0.7440 - val_loss: 0.6580 - val_acc: 0.5938\n",
            "Epoch 799/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5013 - acc: 0.7509 - val_loss: 0.6663 - val_acc: 0.5625\n",
            "Epoch 800/1000\n",
            "37/37 [==============================] - 5s 116ms/step - loss: 0.5278 - acc: 0.7543 - val_loss: 0.6744 - val_acc: 0.6354\n",
            "Epoch 801/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.4945 - acc: 0.7646 - val_loss: 0.6792 - val_acc: 0.6250\n",
            "Epoch 802/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.5103 - acc: 0.7612 - val_loss: 0.6585 - val_acc: 0.6354\n",
            "Epoch 803/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5070 - acc: 0.7440 - val_loss: 0.6621 - val_acc: 0.6354\n",
            "Epoch 804/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.5382 - acc: 0.7337 - val_loss: 0.6637 - val_acc: 0.6354\n",
            "Epoch 805/1000\n",
            "37/37 [==============================] - 9s 241ms/step - loss: 0.4959 - acc: 0.7509 - val_loss: 0.6748 - val_acc: 0.6042\n",
            "Epoch 806/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5360 - acc: 0.7113 - val_loss: 0.6739 - val_acc: 0.6458\n",
            "Epoch 807/1000\n",
            "37/37 [==============================] - 6s 146ms/step - loss: 0.5336 - acc: 0.7199 - val_loss: 0.6923 - val_acc: 0.6354\n",
            "Epoch 808/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.4968 - acc: 0.7474 - val_loss: 0.6943 - val_acc: 0.6354\n",
            "Epoch 809/1000\n",
            "37/37 [==============================] - 6s 142ms/step - loss: 0.4825 - acc: 0.7680 - val_loss: 0.6859 - val_acc: 0.6250\n",
            "Epoch 810/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5081 - acc: 0.7285 - val_loss: 0.6836 - val_acc: 0.6042\n",
            "Epoch 811/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5217 - acc: 0.7457 - val_loss: 0.6858 - val_acc: 0.6250\n",
            "Epoch 812/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5451 - acc: 0.7216 - val_loss: 0.6689 - val_acc: 0.6667\n",
            "Epoch 813/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.5225 - acc: 0.7474 - val_loss: 0.6864 - val_acc: 0.6250\n",
            "Epoch 814/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.4905 - acc: 0.7732 - val_loss: 0.6640 - val_acc: 0.6458\n",
            "Epoch 815/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.5030 - acc: 0.7423 - val_loss: 0.6913 - val_acc: 0.6250\n",
            "Epoch 816/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.4942 - acc: 0.7784 - val_loss: 0.6769 - val_acc: 0.6354\n",
            "Epoch 817/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.4783 - acc: 0.7612 - val_loss: 0.6867 - val_acc: 0.6458\n",
            "Epoch 818/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.5370 - acc: 0.7423 - val_loss: 0.6843 - val_acc: 0.6250\n",
            "Epoch 819/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.5104 - acc: 0.7491 - val_loss: 0.6848 - val_acc: 0.6146\n",
            "Epoch 820/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5054 - acc: 0.7526 - val_loss: 0.6661 - val_acc: 0.5938\n",
            "Epoch 821/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.5061 - acc: 0.7354 - val_loss: 0.6677 - val_acc: 0.6250\n",
            "Epoch 822/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.5180 - acc: 0.7405 - val_loss: 0.6586 - val_acc: 0.6771\n",
            "Epoch 823/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.4900 - acc: 0.7766 - val_loss: 0.6713 - val_acc: 0.6354\n",
            "Epoch 824/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5326 - acc: 0.7251 - val_loss: 0.6857 - val_acc: 0.6250\n",
            "Epoch 825/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.5261 - acc: 0.7251 - val_loss: 0.6828 - val_acc: 0.6250\n",
            "Epoch 826/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.5161 - acc: 0.7405 - val_loss: 0.6896 - val_acc: 0.6250\n",
            "Epoch 827/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.5182 - acc: 0.7440 - val_loss: 0.6704 - val_acc: 0.6146\n",
            "Epoch 828/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.5013 - acc: 0.7612 - val_loss: 0.6834 - val_acc: 0.6146\n",
            "Epoch 829/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5135 - acc: 0.7354 - val_loss: 0.6841 - val_acc: 0.6042\n",
            "Epoch 830/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5293 - acc: 0.7268 - val_loss: 0.6712 - val_acc: 0.6250\n",
            "Epoch 831/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.4592 - acc: 0.7869 - val_loss: 0.6669 - val_acc: 0.6250\n",
            "Epoch 832/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5331 - acc: 0.7165 - val_loss: 0.6851 - val_acc: 0.6250\n",
            "Epoch 833/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.5253 - acc: 0.7268 - val_loss: 0.6781 - val_acc: 0.6250\n",
            "Epoch 834/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.5433 - acc: 0.7354 - val_loss: 0.6744 - val_acc: 0.6667\n",
            "Epoch 835/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5044 - acc: 0.7337 - val_loss: 0.7088 - val_acc: 0.6354\n",
            "Epoch 836/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.5348 - acc: 0.7199 - val_loss: 0.6570 - val_acc: 0.6458\n",
            "Epoch 837/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5270 - acc: 0.7251 - val_loss: 0.6766 - val_acc: 0.6458\n",
            "Epoch 838/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5305 - acc: 0.7388 - val_loss: 0.6758 - val_acc: 0.6354\n",
            "Epoch 839/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5088 - acc: 0.7663 - val_loss: 0.6669 - val_acc: 0.6458\n",
            "Epoch 840/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5378 - acc: 0.7302 - val_loss: 0.6627 - val_acc: 0.6354\n",
            "Epoch 841/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5005 - acc: 0.7423 - val_loss: 0.6812 - val_acc: 0.6250\n",
            "Epoch 842/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.4920 - acc: 0.7474 - val_loss: 0.6673 - val_acc: 0.6458\n",
            "Epoch 843/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5074 - acc: 0.7457 - val_loss: 0.6605 - val_acc: 0.6354\n",
            "Epoch 844/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.5050 - acc: 0.7337 - val_loss: 0.6703 - val_acc: 0.6250\n",
            "Epoch 845/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.4752 - acc: 0.7732 - val_loss: 0.6618 - val_acc: 0.6146\n",
            "Epoch 846/1000\n",
            "37/37 [==============================] - 5s 120ms/step - loss: 0.5437 - acc: 0.7302 - val_loss: 0.6707 - val_acc: 0.6458\n",
            "Epoch 847/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5250 - acc: 0.7165 - val_loss: 0.6644 - val_acc: 0.6458\n",
            "Epoch 848/1000\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.4980 - acc: 0.7612 - val_loss: 0.6720 - val_acc: 0.6146\n",
            "Epoch 849/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5004 - acc: 0.7423 - val_loss: 0.6723 - val_acc: 0.6250\n",
            "Epoch 850/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5284 - acc: 0.7320 - val_loss: 0.6770 - val_acc: 0.6354\n",
            "Epoch 851/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5196 - acc: 0.7216 - val_loss: 0.6884 - val_acc: 0.6250\n",
            "Epoch 852/1000\n",
            "37/37 [==============================] - 5s 112ms/step - loss: 0.5252 - acc: 0.7182 - val_loss: 0.6657 - val_acc: 0.6354\n",
            "Epoch 853/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.5201 - acc: 0.7320 - val_loss: 0.6558 - val_acc: 0.6354\n",
            "Epoch 854/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.4888 - acc: 0.7612 - val_loss: 0.6780 - val_acc: 0.6146\n",
            "Epoch 855/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.4956 - acc: 0.7543 - val_loss: 0.6764 - val_acc: 0.6146\n",
            "Epoch 856/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.4984 - acc: 0.7440 - val_loss: 0.6795 - val_acc: 0.6250\n",
            "Epoch 857/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.5216 - acc: 0.7320 - val_loss: 0.6624 - val_acc: 0.6042\n",
            "Epoch 858/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.4979 - acc: 0.7595 - val_loss: 0.6770 - val_acc: 0.6354\n",
            "Epoch 859/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5129 - acc: 0.7577 - val_loss: 0.6518 - val_acc: 0.6250\n",
            "Epoch 860/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.4978 - acc: 0.7560 - val_loss: 0.6754 - val_acc: 0.6146\n",
            "Epoch 861/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5083 - acc: 0.7440 - val_loss: 0.6759 - val_acc: 0.5938\n",
            "Epoch 862/1000\n",
            "37/37 [==============================] - 9s 220ms/step - loss: 0.5093 - acc: 0.7440 - val_loss: 0.6786 - val_acc: 0.6042\n",
            "Epoch 863/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.5058 - acc: 0.7388 - val_loss: 0.6509 - val_acc: 0.6667\n",
            "Epoch 864/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5129 - acc: 0.7646 - val_loss: 0.6730 - val_acc: 0.6354\n",
            "Epoch 865/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.4809 - acc: 0.7595 - val_loss: 0.6695 - val_acc: 0.6146\n",
            "Epoch 866/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.5367 - acc: 0.7268 - val_loss: 0.6687 - val_acc: 0.6458\n",
            "Epoch 867/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5147 - acc: 0.7457 - val_loss: 0.6818 - val_acc: 0.6146\n",
            "Epoch 868/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5026 - acc: 0.7388 - val_loss: 0.6574 - val_acc: 0.6354\n",
            "Epoch 869/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5288 - acc: 0.7457 - val_loss: 0.6539 - val_acc: 0.6354\n",
            "Epoch 870/1000\n",
            "37/37 [==============================] - 6s 145ms/step - loss: 0.5399 - acc: 0.7371 - val_loss: 0.6695 - val_acc: 0.6458\n",
            "Epoch 871/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5149 - acc: 0.7595 - val_loss: 0.6583 - val_acc: 0.6354\n",
            "Epoch 872/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5481 - acc: 0.7199 - val_loss: 0.6703 - val_acc: 0.5938\n",
            "Epoch 873/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.5070 - acc: 0.7543 - val_loss: 0.6721 - val_acc: 0.5938\n",
            "Epoch 874/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5065 - acc: 0.7457 - val_loss: 0.6643 - val_acc: 0.6250\n",
            "Epoch 875/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5047 - acc: 0.7371 - val_loss: 0.6563 - val_acc: 0.6146\n",
            "Epoch 876/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5396 - acc: 0.7234 - val_loss: 0.6593 - val_acc: 0.6042\n",
            "Epoch 877/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.4940 - acc: 0.7732 - val_loss: 0.6834 - val_acc: 0.6042\n",
            "Epoch 878/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.5087 - acc: 0.7405 - val_loss: 0.6798 - val_acc: 0.5938\n",
            "Epoch 879/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5104 - acc: 0.7371 - val_loss: 0.6819 - val_acc: 0.6042\n",
            "Epoch 880/1000\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 0.5154 - acc: 0.7320 - val_loss: 0.6814 - val_acc: 0.6250\n",
            "Epoch 881/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5101 - acc: 0.7663 - val_loss: 0.6627 - val_acc: 0.6458\n",
            "Epoch 882/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5567 - acc: 0.7199 - val_loss: 0.6703 - val_acc: 0.5938\n",
            "Epoch 883/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.5119 - acc: 0.7199 - val_loss: 0.6668 - val_acc: 0.6250\n",
            "Epoch 884/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.5304 - acc: 0.7491 - val_loss: 0.6611 - val_acc: 0.6146\n",
            "Epoch 885/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.5161 - acc: 0.7354 - val_loss: 0.6689 - val_acc: 0.6146\n",
            "Epoch 886/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5177 - acc: 0.7405 - val_loss: 0.6602 - val_acc: 0.6354\n",
            "Epoch 887/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5287 - acc: 0.7371 - val_loss: 0.6498 - val_acc: 0.6458\n",
            "Epoch 888/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.5260 - acc: 0.7354 - val_loss: 0.6545 - val_acc: 0.6042\n",
            "Epoch 889/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5059 - acc: 0.7337 - val_loss: 0.6548 - val_acc: 0.6354\n",
            "Epoch 890/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.4984 - acc: 0.7663 - val_loss: 0.6551 - val_acc: 0.6354\n",
            "Epoch 891/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.5490 - acc: 0.7079 - val_loss: 0.6633 - val_acc: 0.6354\n",
            "Epoch 892/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.4858 - acc: 0.7715 - val_loss: 0.6527 - val_acc: 0.6354\n",
            "Epoch 893/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.4865 - acc: 0.7698 - val_loss: 0.6495 - val_acc: 0.6354\n",
            "Epoch 894/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.5184 - acc: 0.7457 - val_loss: 0.6716 - val_acc: 0.6250\n",
            "Epoch 895/1000\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.5323 - acc: 0.7113 - val_loss: 0.6571 - val_acc: 0.5938\n",
            "Epoch 896/1000\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.5277 - acc: 0.7216 - val_loss: 0.6485 - val_acc: 0.6250\n",
            "Epoch 897/1000\n",
            "37/37 [==============================] - 9s 216ms/step - loss: 0.4959 - acc: 0.7474 - val_loss: 0.6574 - val_acc: 0.5938\n",
            "Epoch 898/1000\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 0.5142 - acc: 0.7268 - val_loss: 0.6524 - val_acc: 0.6458\n",
            "Epoch 899/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.5260 - acc: 0.7526 - val_loss: 0.6671 - val_acc: 0.6146\n",
            "Epoch 900/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5237 - acc: 0.7285 - val_loss: 0.6589 - val_acc: 0.6250\n",
            "Epoch 901/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.5160 - acc: 0.7509 - val_loss: 0.6450 - val_acc: 0.6562\n",
            "Epoch 902/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.4907 - acc: 0.7663 - val_loss: 0.6522 - val_acc: 0.6354\n",
            "Epoch 903/1000\n",
            "37/37 [==============================] - 5s 109ms/step - loss: 0.5168 - acc: 0.7405 - val_loss: 0.6513 - val_acc: 0.6458\n",
            "Epoch 904/1000\n",
            "37/37 [==============================] - 9s 216ms/step - loss: 0.5439 - acc: 0.7148 - val_loss: 0.6754 - val_acc: 0.6146\n",
            "Epoch 905/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.5239 - acc: 0.7526 - val_loss: 0.6504 - val_acc: 0.6458\n",
            "Epoch 906/1000\n",
            "37/37 [==============================] - 9s 243ms/step - loss: 0.5027 - acc: 0.7199 - val_loss: 0.6471 - val_acc: 0.6458\n",
            "Epoch 907/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5290 - acc: 0.7405 - val_loss: 0.6424 - val_acc: 0.6458\n",
            "Epoch 908/1000\n",
            "37/37 [==============================] - 5s 109ms/step - loss: 0.5020 - acc: 0.7663 - val_loss: 0.6594 - val_acc: 0.6250\n",
            "Epoch 909/1000\n",
            "37/37 [==============================] - 9s 215ms/step - loss: 0.5459 - acc: 0.7457 - val_loss: 0.6642 - val_acc: 0.6354\n",
            "Epoch 910/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.5035 - acc: 0.7388 - val_loss: 0.6582 - val_acc: 0.5417\n",
            "Epoch 911/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.5139 - acc: 0.7405 - val_loss: 0.6483 - val_acc: 0.6354\n",
            "Epoch 912/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.5416 - acc: 0.7148 - val_loss: 0.6715 - val_acc: 0.6250\n",
            "Epoch 913/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.4887 - acc: 0.7663 - val_loss: 0.6563 - val_acc: 0.6354\n",
            "Epoch 914/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.5020 - acc: 0.7423 - val_loss: 0.6715 - val_acc: 0.6250\n",
            "Epoch 915/1000\n",
            "37/37 [==============================] - 4s 109ms/step - loss: 0.5334 - acc: 0.7165 - val_loss: 0.6512 - val_acc: 0.6458\n",
            "Epoch 916/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.4941 - acc: 0.7543 - val_loss: 0.6825 - val_acc: 0.6354\n",
            "Epoch 917/1000\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.5121 - acc: 0.7457 - val_loss: 0.6632 - val_acc: 0.6458\n",
            "Epoch 918/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.4960 - acc: 0.7388 - val_loss: 0.6777 - val_acc: 0.6146\n",
            "Epoch 919/1000\n",
            "37/37 [==============================] - 4s 82ms/step - loss: 0.5094 - acc: 0.7371 - val_loss: 0.6686 - val_acc: 0.6250\n",
            "Epoch 920/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5230 - acc: 0.7423 - val_loss: 0.6659 - val_acc: 0.6354\n",
            "Epoch 921/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5076 - acc: 0.7405 - val_loss: 0.6652 - val_acc: 0.6354\n",
            "Epoch 922/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.4968 - acc: 0.7543 - val_loss: 0.6616 - val_acc: 0.6250\n",
            "Epoch 923/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5198 - acc: 0.7423 - val_loss: 0.6709 - val_acc: 0.6146\n",
            "Epoch 924/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.4976 - acc: 0.7543 - val_loss: 0.6499 - val_acc: 0.6354\n",
            "Epoch 925/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5214 - acc: 0.7491 - val_loss: 0.6699 - val_acc: 0.6250\n",
            "Epoch 926/1000\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 0.5367 - acc: 0.7251 - val_loss: 0.6673 - val_acc: 0.6146\n",
            "Epoch 927/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5302 - acc: 0.7268 - val_loss: 0.6714 - val_acc: 0.6250\n",
            "Epoch 928/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.5313 - acc: 0.7491 - val_loss: 0.6566 - val_acc: 0.5833\n",
            "Epoch 929/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5077 - acc: 0.7440 - val_loss: 0.6778 - val_acc: 0.6146\n",
            "Epoch 930/1000\n",
            "37/37 [==============================] - 5s 116ms/step - loss: 0.5339 - acc: 0.7199 - val_loss: 0.6656 - val_acc: 0.6354\n",
            "Epoch 931/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5307 - acc: 0.7388 - val_loss: 0.6567 - val_acc: 0.6354\n",
            "Epoch 932/1000\n",
            "37/37 [==============================] - 5s 113ms/step - loss: 0.5006 - acc: 0.7663 - val_loss: 0.6679 - val_acc: 0.6250\n",
            "Epoch 933/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.4987 - acc: 0.7801 - val_loss: 0.6714 - val_acc: 0.6146\n",
            "Epoch 934/1000\n",
            "37/37 [==============================] - 9s 242ms/step - loss: 0.4922 - acc: 0.7663 - val_loss: 0.6553 - val_acc: 0.6354\n",
            "Epoch 935/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5450 - acc: 0.7320 - val_loss: 0.6600 - val_acc: 0.6354\n",
            "Epoch 936/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.5307 - acc: 0.7320 - val_loss: 0.6746 - val_acc: 0.6146\n",
            "Epoch 937/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5170 - acc: 0.7457 - val_loss: 0.6623 - val_acc: 0.6354\n",
            "Epoch 938/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5381 - acc: 0.7285 - val_loss: 0.6602 - val_acc: 0.6250\n",
            "Epoch 939/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.4845 - acc: 0.7818 - val_loss: 0.6645 - val_acc: 0.6250\n",
            "Epoch 940/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.5683 - acc: 0.7440 - val_loss: 0.6429 - val_acc: 0.6354\n",
            "Epoch 941/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5333 - acc: 0.7457 - val_loss: 0.6758 - val_acc: 0.6146\n",
            "Epoch 942/1000\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.5130 - acc: 0.7371 - val_loss: 0.6601 - val_acc: 0.6250\n",
            "Epoch 943/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5361 - acc: 0.7354 - val_loss: 0.6668 - val_acc: 0.6354\n",
            "Epoch 944/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.5179 - acc: 0.7268 - val_loss: 0.6527 - val_acc: 0.6250\n",
            "Epoch 945/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5019 - acc: 0.7646 - val_loss: 0.6521 - val_acc: 0.6458\n",
            "Epoch 946/1000\n",
            "37/37 [==============================] - 5s 116ms/step - loss: 0.5290 - acc: 0.7440 - val_loss: 0.6723 - val_acc: 0.6146\n",
            "Epoch 947/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5338 - acc: 0.7423 - val_loss: 0.6625 - val_acc: 0.6250\n",
            "Epoch 948/1000\n",
            "37/37 [==============================] - 9s 242ms/step - loss: 0.5365 - acc: 0.7354 - val_loss: 0.6538 - val_acc: 0.6458\n",
            "Epoch 949/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.5273 - acc: 0.7285 - val_loss: 0.6589 - val_acc: 0.6250\n",
            "Epoch 950/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.4816 - acc: 0.7680 - val_loss: 0.6642 - val_acc: 0.6250\n",
            "Epoch 951/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.5056 - acc: 0.7405 - val_loss: 0.6396 - val_acc: 0.6562\n",
            "Epoch 952/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5050 - acc: 0.7440 - val_loss: 0.6626 - val_acc: 0.6250\n",
            "Epoch 953/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5173 - acc: 0.7405 - val_loss: 0.6688 - val_acc: 0.6146\n",
            "Epoch 954/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5049 - acc: 0.7680 - val_loss: 0.6532 - val_acc: 0.6042\n",
            "Epoch 955/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.5171 - acc: 0.7440 - val_loss: 0.6456 - val_acc: 0.6354\n",
            "Epoch 956/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5343 - acc: 0.7371 - val_loss: 0.6568 - val_acc: 0.6354\n",
            "Epoch 957/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.5037 - acc: 0.7629 - val_loss: 0.6633 - val_acc: 0.6250\n",
            "Epoch 958/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.5317 - acc: 0.7165 - val_loss: 0.6715 - val_acc: 0.6250\n",
            "Epoch 959/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5286 - acc: 0.7337 - val_loss: 0.6609 - val_acc: 0.6354\n",
            "Epoch 960/1000\n",
            "37/37 [==============================] - 5s 116ms/step - loss: 0.5305 - acc: 0.7405 - val_loss: 0.6597 - val_acc: 0.6354\n",
            "Epoch 961/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.4816 - acc: 0.7749 - val_loss: 0.6432 - val_acc: 0.6562\n",
            "Epoch 962/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.4881 - acc: 0.7784 - val_loss: 0.6533 - val_acc: 0.6354\n",
            "Epoch 963/1000\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.4983 - acc: 0.7560 - val_loss: 0.6406 - val_acc: 0.5938\n",
            "Epoch 964/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.5352 - acc: 0.7371 - val_loss: 0.6583 - val_acc: 0.6354\n",
            "Epoch 965/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5366 - acc: 0.7302 - val_loss: 0.6465 - val_acc: 0.6458\n",
            "Epoch 966/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.5191 - acc: 0.7388 - val_loss: 0.6421 - val_acc: 0.6562\n",
            "Epoch 967/1000\n",
            "37/37 [==============================] - 9s 246ms/step - loss: 0.5117 - acc: 0.7509 - val_loss: 0.6581 - val_acc: 0.6667\n",
            "Epoch 968/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.5352 - acc: 0.7457 - val_loss: 0.6628 - val_acc: 0.6250\n",
            "Epoch 969/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5243 - acc: 0.7337 - val_loss: 0.6613 - val_acc: 0.6250\n",
            "Epoch 970/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5232 - acc: 0.7337 - val_loss: 0.6640 - val_acc: 0.6250\n",
            "Epoch 971/1000\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.5188 - acc: 0.7474 - val_loss: 0.6521 - val_acc: 0.6354\n",
            "Epoch 972/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5310 - acc: 0.7388 - val_loss: 0.6550 - val_acc: 0.6458\n",
            "Epoch 973/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.5289 - acc: 0.7491 - val_loss: 0.6708 - val_acc: 0.6354\n",
            "Epoch 974/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5079 - acc: 0.7577 - val_loss: 0.6640 - val_acc: 0.6354\n",
            "Epoch 975/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5348 - acc: 0.7251 - val_loss: 0.6762 - val_acc: 0.6146\n",
            "Epoch 976/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.4970 - acc: 0.7595 - val_loss: 0.6632 - val_acc: 0.6250\n",
            "Epoch 977/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5277 - acc: 0.7268 - val_loss: 0.6778 - val_acc: 0.6146\n",
            "Epoch 978/1000\n",
            "37/37 [==============================] - 9s 218ms/step - loss: 0.4859 - acc: 0.7577 - val_loss: 0.6551 - val_acc: 0.6354\n",
            "Epoch 979/1000\n",
            "37/37 [==============================] - 5s 111ms/step - loss: 0.4972 - acc: 0.7801 - val_loss: 0.6666 - val_acc: 0.6250\n",
            "Epoch 980/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5117 - acc: 0.7432 - val_loss: 0.6625 - val_acc: 0.5833\n",
            "Epoch 981/1000\n",
            "37/37 [==============================] - 9s 246ms/step - loss: 0.4990 - acc: 0.7577 - val_loss: 0.6727 - val_acc: 0.6250\n",
            "Epoch 982/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.4949 - acc: 0.7526 - val_loss: 0.6508 - val_acc: 0.6042\n",
            "Epoch 983/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.5447 - acc: 0.7113 - val_loss: 0.6728 - val_acc: 0.6146\n",
            "Epoch 984/1000\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.5266 - acc: 0.7182 - val_loss: 0.6471 - val_acc: 0.6354\n",
            "Epoch 985/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.4942 - acc: 0.7560 - val_loss: 0.6432 - val_acc: 0.6458\n",
            "Epoch 986/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.5128 - acc: 0.7320 - val_loss: 0.6430 - val_acc: 0.6458\n",
            "Epoch 987/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5255 - acc: 0.7405 - val_loss: 0.6461 - val_acc: 0.6458\n",
            "Epoch 988/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.5072 - acc: 0.7457 - val_loss: 0.6548 - val_acc: 0.6250\n",
            "Epoch 989/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5161 - acc: 0.7337 - val_loss: 0.6585 - val_acc: 0.6354\n",
            "Epoch 990/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5235 - acc: 0.7526 - val_loss: 0.6428 - val_acc: 0.6458\n",
            "Epoch 991/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5187 - acc: 0.7457 - val_loss: 0.6563 - val_acc: 0.6354\n",
            "Epoch 992/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.4854 - acc: 0.7509 - val_loss: 0.6793 - val_acc: 0.6146\n",
            "Epoch 993/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.4833 - acc: 0.7595 - val_loss: 0.6657 - val_acc: 0.6146\n",
            "Epoch 994/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.4982 - acc: 0.7560 - val_loss: 0.6649 - val_acc: 0.6250\n",
            "Epoch 995/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5226 - acc: 0.7457 - val_loss: 0.6535 - val_acc: 0.6458\n",
            "Epoch 996/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.5017 - acc: 0.7337 - val_loss: 0.6618 - val_acc: 0.6458\n",
            "Epoch 997/1000\n",
            "37/37 [==============================] - 5s 115ms/step - loss: 0.5119 - acc: 0.7371 - val_loss: 0.6571 - val_acc: 0.6458\n",
            "Epoch 998/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5118 - acc: 0.7577 - val_loss: 0.6743 - val_acc: 0.6562\n",
            "Epoch 999/1000\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 0.4912 - acc: 0.7543 - val_loss: 0.6656 - val_acc: 0.6458\n",
            "Epoch 1000/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.5055 - acc: 0.7852 - val_loss: 0.6754 - val_acc: 0.6250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot training performance"
      ],
      "metadata": {
        "id": "YFxMJycOpEew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'co', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'k', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'co', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "     "
      ],
      "metadata": {
        "id": "l9PYKbRNpEK8",
        "outputId": "981b978c-14ad-4036-c4ee-73580c73bdb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SAVE model"
      ],
      "metadata": {
        "id": "kNtlq_LZpKNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('./content/drive/My Drive/new', exist_ok=True)\n",
        "model.save('./content/drive/My Drive/new/2Class_UNfreeze_1000.h5')"
      ],
      "metadata": {
        "id": "TegSVqblpLEZ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "KdsdaIgMpMeG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"./content/drive/My Drive/new/2Class_UNfreeze_1000.h5\")"
      ],
      "metadata": {
        "id": "sZFZ1c_kpMcN",
        "outputId": "3e6ac809-ceff-40ac-ef9b-f47376b13088",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e1c821cc-0848-4f6a-ae9a-276eed5124cf\", \"2Class_UNfreeze_1000.h5\", 16604952)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gEfCB1RfpMZ6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}