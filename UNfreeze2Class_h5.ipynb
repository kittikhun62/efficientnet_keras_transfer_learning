{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMhhqryGEO9H+wrAzIu1QZd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kittikhun62/efficientnet_keras_transfer_learning/blob/master/UNfreeze2Class_h5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# import from drive"
      ],
      "metadata": {
        "id": "bB2gfuYWczY-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpXyZ9k5YIJu",
        "outputId": "d62ab0eb-211f-4627-cab0-a4bd502efaba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (r'/content/drive/My Drive/data - 2 class.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        },
        "id": "7mqo2OLAc2pG",
        "outputId": "06307737-8745-4b4f-e9d6-f8fce2255bf1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      No                      Name_file  \\\n",
              "0      1                        pore-sb   \n",
              "1      2                        pore-sb   \n",
              "2      3                        pore-sb   \n",
              "3      4                        pore-sb   \n",
              "4      5                        pore-sb   \n",
              "..   ...                            ...   \n",
              "795  796  1-s2.0-S2095268622000210-main   \n",
              "796  797  1-s2.0-S2095268622000210-main   \n",
              "797  798  1-s2.0-S2095268622000210-main   \n",
              "798  799  1-s2.0-S2095268622000210-main   \n",
              "799  800  1-s2.0-S2095268622000210-main   \n",
              "\n",
              "                                            Name_Paper  \\\n",
              "0    Preparation and electrochemical behaviour of b...   \n",
              "1    Preparation and electrochemical behaviour of b...   \n",
              "2    Preparation and electrochemical behaviour of b...   \n",
              "3    Preparation and electrochemical behaviour of b...   \n",
              "4    Preparation and electrochemical behaviour of b...   \n",
              "..                                                 ...   \n",
              "795  Integration of preparation of K, Na-embedded a...   \n",
              "796  Integration of preparation of K, Na-embedded a...   \n",
              "797  Integration of preparation of K, Na-embedded a...   \n",
              "798  Integration of preparation of K, Na-embedded a...   \n",
              "799  Integration of preparation of K, Na-embedded a...   \n",
              "\n",
              "                                               journal  \\\n",
              "0                                  Korean J. Chem. Eng   \n",
              "1                                  Korean J. Chem. Eng   \n",
              "2                                  Korean J. Chem. Eng   \n",
              "3                                  Korean J. Chem. Eng   \n",
              "4                                  Korean J. Chem. Eng   \n",
              "..                                                 ...   \n",
              "795  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "796  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "797  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "798  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "799  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "\n",
              "                                          path_Picture  detail  Class     BET  \\\n",
              "0    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom1  0-800  135.06   \n",
              "1    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom2  0-800  135.06   \n",
              "2    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom3  0-800  135.06   \n",
              "3    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom4  0-800  135.06   \n",
              "4    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom5  0-800  135.06   \n",
              "..                                                 ...     ...    ...     ...   \n",
              "795  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom21  0-800  301.70   \n",
              "796  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom22  0-800  301.70   \n",
              "797  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom23  0-800  301.70   \n",
              "798  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom24  0-800  301.70   \n",
              "799  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom25  0-800  301.70   \n",
              "\n",
              "     Size(mico)  \n",
              "0            10  \n",
              "1            10  \n",
              "2            10  \n",
              "3            10  \n",
              "4            10  \n",
              "..          ...  \n",
              "795          10  \n",
              "796          10  \n",
              "797          10  \n",
              "798          10  \n",
              "799          10  \n",
              "\n",
              "[800 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d4e987b2-2c19-424f-935e-e8465b5f9300\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>No</th>\n",
              "      <th>Name_file</th>\n",
              "      <th>Name_Paper</th>\n",
              "      <th>journal</th>\n",
              "      <th>path_Picture</th>\n",
              "      <th>detail</th>\n",
              "      <th>Class</th>\n",
              "      <th>BET</th>\n",
              "      <th>Size(mico)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom1</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom2</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom3</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom4</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom5</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>795</th>\n",
              "      <td>796</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom21</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>796</th>\n",
              "      <td>797</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom22</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>797</th>\n",
              "      <td>798</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom23</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>798</th>\n",
              "      <td>799</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom24</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799</th>\n",
              "      <td>800</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom25</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>800 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4e987b2-2c19-424f-935e-e8465b5f9300')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d4e987b2-2c19-424f-935e-e8465b5f9300 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d4e987b2-2c19-424f-935e-e8465b5f9300');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports library"
      ],
      "metadata": {
        "id": "VkYa-4LeTbir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "myAsBcVhTW7j"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## hyper parameter\n"
      ],
      "metadata": {
        "id": "T529UM_tVV-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "width = 150\n",
        "height = 150\n",
        "\n",
        "epochs = 1000 #จำนวนรอบในการ Train\n",
        "\n",
        "NUM_TRAIN = 598  # จำนวนภาพ Train\n",
        "NUM_TEST = 101 #จำนวนภาพ Test\n",
        "\n",
        "dropout_rate = 0.3\n",
        "input_shape = (height, width, 3) #ขนาด image enter"
      ],
      "metadata": {
        "id": "zXpmkJ2GVZ1l"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone efficientnet repo"
      ],
      "metadata": {
        "id": "DSSZIFGhUyQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/"
      ],
      "metadata": {
        "id": "nFvKcuBDTj1N",
        "outputId": "87baea14-6b48-466a-cbcb-0652b614a783",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 837, done.\u001b[K\n",
            "remote: Counting objects: 100% (359/359), done.\u001b[K\n",
            "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
            "remote: Total 837 (delta 255), reused 328 (delta 235), pack-reused 478\u001b[K\n",
            "Receiving objects: 100% (837/837), 13.82 MiB | 9.88 MiB/s, done.\n",
            "Resolving deltas: 100% (495/495), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import efficientnet and load the conv base model"
      ],
      "metadata": {
        "id": "j3EgSOiSZHaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "iI3DQ18HU2TF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "#EfficientNet สร้างขึ้นสำหรับการจำแนกประเภท ImageNet ประกอบด้วยป้ายกำกับคลาส 1,000 รายการ เรามีเพียง 2 เลเยอร์เท่านั้น ซึ่งหมายความว่าเลเยอร์สองสามเลเยอร์สุดท้ายสำหรับการจำแนกไม่มีประโยชน์สำหรับเรา สามารถยกเว้นได้ขณะโหลดโมเดลโดยระบุอาร์กิวเมนต์ include_top เป็น False และนำไปใช้กับโมเดล ImageNet อื่นๆ ที่มีอยู่ในแอปพลิเคชัน Keras เช่นกัน\n",
        "\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "UmBDAgF_VAjq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64218247-dcbd-41c8-cf11-fa795ef89d14"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "id": "rRXoFFzfU2Oi",
        "outputId": "60bff559-4942-4f56-9f4d-fa1afc4dee90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 4,007,548\n",
            "Non-trainable params: 42,016\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/new/2Class.h5')\n",
        "\n",
        "from efficientnet.layers import Swish, DropConnect\n",
        "from efficientnet.model import ConvKernalInitializer\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "\n",
        "get_custom_objects().update({\n",
        "    'ConvKernalInitializer': ConvKernalInitializer,\n",
        "    'Swish': Swish,\n",
        "    'DropConnect':DropConnect\n",
        "})"
      ],
      "metadata": {
        "id": "MwNk3sNbc2Qx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load model \n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/drive/My Drive/new/2Class.h5')\n",
        "height = width = model.input_shape[1]"
      ],
      "metadata": {
        "id": "4v4nzKQtJZ4z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/My Drive/new project'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Directories for our training,\n",
        "# validation and test splits\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.makedirs(test_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "UDxvF-b8Jcq1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, # image input 0-255 --> 0-1 เปลี่ยนค่าสี\n",
        "      rotation_range=40,# หมุนภาพในองศา\n",
        "      width_shift_range=0.2, #เปลี่ยนความกว้าง\n",
        "      height_shift_range=0.2, #ปลี่ยนความสูง\n",
        "      shear_range=0.2, #ทำให้ภาพเบี้ยว\n",
        "      zoom_range=0.2, # Randomly zoom image\n",
        "      horizontal_flip=True, \n",
        "      #โดย Default เมื่อมีการเลื่อนภาพ บิดภาพ หมุนภาพ จะเกิดพื้นที่ว่างที่มุม \n",
        "      #ซึ่งจะมีการเติมภาพให้เต็มโดยใช้เทคนิคแบบ Nearest neighbor ซึ่งเป็นการดึงสีบริเวณใหล้าเคียงมาระบายให้เต็ม แต่เราก็ยังสามารถกำหนดวิธีการ Fill ภาพด้วยเทคนิคอื่นได้จาก Parameter fill_mode\n",
        "      fill_mode='nearest')\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory #ไดเรกเป้าหมาย\n",
        "        train_dir,\n",
        "        # รูปภาพทั้งหมดจะถูกปรับขนาดตามความสูงและความกว้างของเป้าหมาย\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        #เนื่องจากเราใช้ categorical_crossentropy loss เราจึงต้องมีป้ายกำกับตามหมวดหมู่\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory( #การดึงภาพจาก Directory มาเข้าโมเดล \n",
        "        validation_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "     \n",
        "\n"
      ],
      "metadata": {
        "id": "znE38DtIJeN-",
        "outputId": "bd2d04f1-05b7-4e4a-97d0-4666d239f054",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 598 images belonging to 2 classes.\n",
            "Found 101 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multiply_16\n",
        "# set 'multiply_16' and following layers trainable\n",
        "conv_base.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'multiply_16':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False  \n",
        "     "
      ],
      "metadata": {
        "id": "tEaPoHJCJq13"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "z7ERVUfUJsQq",
        "outputId": "205af013-1f81-432a-ec64-9a7f1c8ca408",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-caa7b37242a8>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "37/37 [==============================] - 88s 2s/step - loss: 0.5416 - acc: 0.7182 - val_loss: 0.6937 - val_acc: 0.6146\n",
            "Epoch 2/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.5312 - acc: 0.7199 - val_loss: 0.7096 - val_acc: 0.5729\n",
            "Epoch 3/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.5474 - acc: 0.7268 - val_loss: 0.7057 - val_acc: 0.5625\n",
            "Epoch 4/1000\n",
            "37/37 [==============================] - 4s 82ms/step - loss: 0.5487 - acc: 0.7251 - val_loss: 0.7020 - val_acc: 0.6042\n",
            "Epoch 5/1000\n",
            "37/37 [==============================] - 8s 206ms/step - loss: 0.5562 - acc: 0.7113 - val_loss: 0.6959 - val_acc: 0.6042\n",
            "Epoch 6/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5444 - acc: 0.7182 - val_loss: 0.6966 - val_acc: 0.6146\n",
            "Epoch 7/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5269 - acc: 0.7337 - val_loss: 0.7108 - val_acc: 0.5938\n",
            "Epoch 8/1000\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.5420 - acc: 0.6924 - val_loss: 0.7106 - val_acc: 0.5521\n",
            "Epoch 9/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5311 - acc: 0.7354 - val_loss: 0.7180 - val_acc: 0.5833\n",
            "Epoch 10/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5370 - acc: 0.7423 - val_loss: 0.7149 - val_acc: 0.5833\n",
            "Epoch 11/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5151 - acc: 0.7474 - val_loss: 0.6977 - val_acc: 0.5938\n",
            "Epoch 12/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5451 - acc: 0.7079 - val_loss: 0.7074 - val_acc: 0.5938\n",
            "Epoch 13/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5443 - acc: 0.7491 - val_loss: 0.7056 - val_acc: 0.5521\n",
            "Epoch 14/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.5538 - acc: 0.7182 - val_loss: 0.7083 - val_acc: 0.5938\n",
            "Epoch 15/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5546 - acc: 0.7062 - val_loss: 0.7028 - val_acc: 0.5938\n",
            "Epoch 16/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5490 - acc: 0.7096 - val_loss: 0.6977 - val_acc: 0.6042\n",
            "Epoch 17/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5261 - acc: 0.7371 - val_loss: 0.7101 - val_acc: 0.5833\n",
            "Epoch 18/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.5317 - acc: 0.7165 - val_loss: 0.7136 - val_acc: 0.5729\n",
            "Epoch 19/1000\n",
            "37/37 [==============================] - 5s 110ms/step - loss: 0.5182 - acc: 0.7543 - val_loss: 0.7109 - val_acc: 0.5625\n",
            "Epoch 20/1000\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.5261 - acc: 0.7268 - val_loss: 0.7142 - val_acc: 0.5833\n",
            "Epoch 21/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5434 - acc: 0.7371 - val_loss: 0.7159 - val_acc: 0.5729\n",
            "Epoch 22/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5667 - acc: 0.7010 - val_loss: 0.6999 - val_acc: 0.5833\n",
            "Epoch 23/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.5329 - acc: 0.7234 - val_loss: 0.7028 - val_acc: 0.5729\n",
            "Epoch 24/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5281 - acc: 0.7302 - val_loss: 0.7126 - val_acc: 0.5833\n",
            "Epoch 25/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.5416 - acc: 0.7337 - val_loss: 0.7043 - val_acc: 0.5417\n",
            "Epoch 26/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5712 - acc: 0.6907 - val_loss: 0.7032 - val_acc: 0.6042\n",
            "Epoch 27/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5292 - acc: 0.7388 - val_loss: 0.7152 - val_acc: 0.5938\n",
            "Epoch 28/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5252 - acc: 0.7302 - val_loss: 0.7082 - val_acc: 0.5833\n",
            "Epoch 29/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.5205 - acc: 0.7474 - val_loss: 0.7020 - val_acc: 0.5938\n",
            "Epoch 30/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5249 - acc: 0.7285 - val_loss: 0.7070 - val_acc: 0.5938\n",
            "Epoch 31/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5484 - acc: 0.7148 - val_loss: 0.7112 - val_acc: 0.5938\n",
            "Epoch 32/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5520 - acc: 0.7320 - val_loss: 0.7264 - val_acc: 0.5729\n",
            "Epoch 33/1000\n",
            "37/37 [==============================] - 8s 224ms/step - loss: 0.5423 - acc: 0.7234 - val_loss: 0.7126 - val_acc: 0.5938\n",
            "Epoch 34/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.5266 - acc: 0.7182 - val_loss: 0.7223 - val_acc: 0.5833\n",
            "Epoch 35/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.5133 - acc: 0.7491 - val_loss: 0.7149 - val_acc: 0.5729\n",
            "Epoch 36/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5519 - acc: 0.7234 - val_loss: 0.7134 - val_acc: 0.5729\n",
            "Epoch 37/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5274 - acc: 0.7285 - val_loss: 0.7042 - val_acc: 0.5312\n",
            "Epoch 38/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.5564 - acc: 0.7062 - val_loss: 0.7020 - val_acc: 0.5625\n",
            "Epoch 39/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5221 - acc: 0.7371 - val_loss: 0.7112 - val_acc: 0.5833\n",
            "Epoch 40/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5611 - acc: 0.7199 - val_loss: 0.6999 - val_acc: 0.5833\n",
            "Epoch 41/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5284 - acc: 0.7440 - val_loss: 0.7087 - val_acc: 0.5833\n",
            "Epoch 42/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5448 - acc: 0.7199 - val_loss: 0.7048 - val_acc: 0.5833\n",
            "Epoch 43/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5613 - acc: 0.7131 - val_loss: 0.7192 - val_acc: 0.5833\n",
            "Epoch 44/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.5277 - acc: 0.7297 - val_loss: 0.6979 - val_acc: 0.5729\n",
            "Epoch 45/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5190 - acc: 0.7388 - val_loss: 0.7220 - val_acc: 0.5729\n",
            "Epoch 46/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.5323 - acc: 0.7182 - val_loss: 0.7113 - val_acc: 0.5938\n",
            "Epoch 47/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5741 - acc: 0.7010 - val_loss: 0.7167 - val_acc: 0.5833\n",
            "Epoch 48/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.5525 - acc: 0.7165 - val_loss: 0.7084 - val_acc: 0.5833\n",
            "Epoch 49/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5250 - acc: 0.7251 - val_loss: 0.7130 - val_acc: 0.5938\n",
            "Epoch 50/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.5355 - acc: 0.7216 - val_loss: 0.6994 - val_acc: 0.6042\n",
            "Epoch 51/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5532 - acc: 0.7268 - val_loss: 0.6973 - val_acc: 0.5938\n",
            "Epoch 52/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5611 - acc: 0.7113 - val_loss: 0.7048 - val_acc: 0.5938\n",
            "Epoch 53/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5349 - acc: 0.7199 - val_loss: 0.6948 - val_acc: 0.5938\n",
            "Epoch 54/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5009 - acc: 0.7595 - val_loss: 0.7244 - val_acc: 0.5729\n",
            "Epoch 55/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5327 - acc: 0.7251 - val_loss: 0.7060 - val_acc: 0.5833\n",
            "Epoch 56/1000\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.5463 - acc: 0.7302 - val_loss: 0.6929 - val_acc: 0.6146\n",
            "Epoch 57/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.5230 - acc: 0.7234 - val_loss: 0.7122 - val_acc: 0.5833\n",
            "Epoch 58/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5358 - acc: 0.7268 - val_loss: 0.6934 - val_acc: 0.5938\n",
            "Epoch 59/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5248 - acc: 0.7148 - val_loss: 0.7049 - val_acc: 0.5938\n",
            "Epoch 60/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5312 - acc: 0.7354 - val_loss: 0.7000 - val_acc: 0.5625\n",
            "Epoch 61/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5412 - acc: 0.7199 - val_loss: 0.7012 - val_acc: 0.5833\n",
            "Epoch 62/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.5299 - acc: 0.7113 - val_loss: 0.6976 - val_acc: 0.5625\n",
            "Epoch 63/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.5487 - acc: 0.7388 - val_loss: 0.6931 - val_acc: 0.5833\n",
            "Epoch 64/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5304 - acc: 0.7285 - val_loss: 0.6879 - val_acc: 0.6146\n",
            "Epoch 65/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5238 - acc: 0.7268 - val_loss: 0.7066 - val_acc: 0.5833\n",
            "Epoch 66/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5545 - acc: 0.7113 - val_loss: 0.6942 - val_acc: 0.5833\n",
            "Epoch 67/1000\n",
            "37/37 [==============================] - 9s 239ms/step - loss: 0.5396 - acc: 0.7371 - val_loss: 0.7096 - val_acc: 0.5104\n",
            "Epoch 68/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5363 - acc: 0.7251 - val_loss: 0.7022 - val_acc: 0.5833\n",
            "Epoch 69/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5322 - acc: 0.7337 - val_loss: 0.6929 - val_acc: 0.5938\n",
            "Epoch 70/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.5193 - acc: 0.7388 - val_loss: 0.6845 - val_acc: 0.5417\n",
            "Epoch 71/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.5404 - acc: 0.7113 - val_loss: 0.7083 - val_acc: 0.5729\n",
            "Epoch 72/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5079 - acc: 0.7543 - val_loss: 0.6974 - val_acc: 0.5938\n",
            "Epoch 73/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.5958 - acc: 0.6873 - val_loss: 0.6905 - val_acc: 0.5729\n",
            "Epoch 74/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5334 - acc: 0.7234 - val_loss: 0.6889 - val_acc: 0.5938\n",
            "Epoch 75/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5208 - acc: 0.7268 - val_loss: 0.7001 - val_acc: 0.5833\n",
            "Epoch 76/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5116 - acc: 0.7388 - val_loss: 0.6890 - val_acc: 0.5938\n",
            "Epoch 77/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5527 - acc: 0.7268 - val_loss: 0.6815 - val_acc: 0.6042\n",
            "Epoch 78/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.4692 - acc: 0.7715 - val_loss: 0.6909 - val_acc: 0.5729\n",
            "Epoch 79/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.5526 - acc: 0.6856 - val_loss: 0.6952 - val_acc: 0.5938\n",
            "Epoch 80/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.5197 - acc: 0.7491 - val_loss: 0.7003 - val_acc: 0.5729\n",
            "Epoch 81/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5130 - acc: 0.7491 - val_loss: 0.6846 - val_acc: 0.5625\n",
            "Epoch 82/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.5370 - acc: 0.7234 - val_loss: 0.6888 - val_acc: 0.5833\n",
            "Epoch 83/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5085 - acc: 0.7577 - val_loss: 0.6948 - val_acc: 0.6042\n",
            "Epoch 84/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.5357 - acc: 0.7128 - val_loss: 0.6902 - val_acc: 0.5938\n",
            "Epoch 85/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.4946 - acc: 0.7766 - val_loss: 0.6875 - val_acc: 0.6042\n",
            "Epoch 86/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5218 - acc: 0.7354 - val_loss: 0.7068 - val_acc: 0.6042\n",
            "Epoch 87/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.5261 - acc: 0.7285 - val_loss: 0.7038 - val_acc: 0.5729\n",
            "Epoch 88/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5614 - acc: 0.7027 - val_loss: 0.6885 - val_acc: 0.5938\n",
            "Epoch 89/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.5291 - acc: 0.7474 - val_loss: 0.6967 - val_acc: 0.5833\n",
            "Epoch 90/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5051 - acc: 0.7560 - val_loss: 0.6843 - val_acc: 0.6042\n",
            "Epoch 91/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5350 - acc: 0.7251 - val_loss: 0.6784 - val_acc: 0.5417\n",
            "Epoch 92/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.5178 - acc: 0.7457 - val_loss: 0.6961 - val_acc: 0.5833\n",
            "Epoch 93/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5112 - acc: 0.7474 - val_loss: 0.6668 - val_acc: 0.6146\n",
            "Epoch 94/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5710 - acc: 0.7079 - val_loss: 0.6921 - val_acc: 0.6042\n",
            "Epoch 95/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5189 - acc: 0.7302 - val_loss: 0.6887 - val_acc: 0.5938\n",
            "Epoch 96/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.5350 - acc: 0.7234 - val_loss: 0.6900 - val_acc: 0.6042\n",
            "Epoch 97/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5540 - acc: 0.7148 - val_loss: 0.6918 - val_acc: 0.6042\n",
            "Epoch 98/1000\n",
            "37/37 [==============================] - 3s 83ms/step - loss: 0.5269 - acc: 0.7457 - val_loss: 0.6876 - val_acc: 0.6250\n",
            "Epoch 99/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.5047 - acc: 0.7543 - val_loss: 0.7009 - val_acc: 0.5938\n",
            "Epoch 100/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.5708 - acc: 0.7302 - val_loss: 0.7142 - val_acc: 0.5833\n",
            "Epoch 101/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5628 - acc: 0.7148 - val_loss: 0.7020 - val_acc: 0.5833\n",
            "Epoch 102/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5566 - acc: 0.7062 - val_loss: 0.7031 - val_acc: 0.6042\n",
            "Epoch 103/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5340 - acc: 0.7216 - val_loss: 0.7078 - val_acc: 0.5938\n",
            "Epoch 104/1000\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.5365 - acc: 0.7457 - val_loss: 0.7077 - val_acc: 0.5729\n",
            "Epoch 105/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5871 - acc: 0.6804 - val_loss: 0.6822 - val_acc: 0.6146\n",
            "Epoch 106/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.5219 - acc: 0.7096 - val_loss: 0.6838 - val_acc: 0.5833\n",
            "Epoch 107/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.5313 - acc: 0.7148 - val_loss: 0.6967 - val_acc: 0.6146\n",
            "Epoch 108/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5690 - acc: 0.6959 - val_loss: 0.7040 - val_acc: 0.5833\n",
            "Epoch 109/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.4882 - acc: 0.7595 - val_loss: 0.6976 - val_acc: 0.5938\n",
            "Epoch 110/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5220 - acc: 0.7483 - val_loss: 0.6990 - val_acc: 0.5938\n",
            "Epoch 111/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.4959 - acc: 0.7543 - val_loss: 0.6818 - val_acc: 0.6146\n",
            "Epoch 112/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.5551 - acc: 0.7268 - val_loss: 0.6917 - val_acc: 0.6146\n",
            "Epoch 113/1000\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 0.5119 - acc: 0.7405 - val_loss: 0.7123 - val_acc: 0.5833\n",
            "Epoch 114/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.5128 - acc: 0.7405 - val_loss: 0.7024 - val_acc: 0.5938\n",
            "Epoch 115/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.5216 - acc: 0.7337 - val_loss: 0.6791 - val_acc: 0.6042\n",
            "Epoch 116/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5198 - acc: 0.7474 - val_loss: 0.6947 - val_acc: 0.5938\n",
            "Epoch 117/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5014 - acc: 0.7526 - val_loss: 0.6890 - val_acc: 0.6042\n",
            "Epoch 118/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5051 - acc: 0.7612 - val_loss: 0.7056 - val_acc: 0.5729\n",
            "Epoch 119/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5287 - acc: 0.7491 - val_loss: 0.6961 - val_acc: 0.6146\n",
            "Epoch 120/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.5356 - acc: 0.7251 - val_loss: 0.7027 - val_acc: 0.5833\n",
            "Epoch 121/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5569 - acc: 0.7285 - val_loss: 0.6842 - val_acc: 0.6146\n",
            "Epoch 122/1000\n",
            "37/37 [==============================] - 8s 208ms/step - loss: 0.5442 - acc: 0.7096 - val_loss: 0.6971 - val_acc: 0.5729\n",
            "Epoch 123/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5341 - acc: 0.7251 - val_loss: 0.6973 - val_acc: 0.6042\n",
            "Epoch 124/1000\n",
            "37/37 [==============================] - 3s 84ms/step - loss: 0.5312 - acc: 0.7268 - val_loss: 0.6994 - val_acc: 0.5833\n",
            "Epoch 125/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.4988 - acc: 0.7584 - val_loss: 0.6955 - val_acc: 0.5938\n",
            "Epoch 126/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5210 - acc: 0.7509 - val_loss: 0.6802 - val_acc: 0.6042\n",
            "Epoch 127/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5207 - acc: 0.7457 - val_loss: 0.7030 - val_acc: 0.5729\n",
            "Epoch 128/1000\n",
            "37/37 [==============================] - 4s 75ms/step - loss: 0.5470 - acc: 0.7096 - val_loss: 0.6789 - val_acc: 0.5938\n",
            "Epoch 129/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5459 - acc: 0.7148 - val_loss: 0.6888 - val_acc: 0.5833\n",
            "Epoch 130/1000\n",
            "37/37 [==============================] - 9s 220ms/step - loss: 0.5604 - acc: 0.6976 - val_loss: 0.7064 - val_acc: 0.5729\n",
            "Epoch 131/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.5289 - acc: 0.7199 - val_loss: 0.6994 - val_acc: 0.5938\n",
            "Epoch 132/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5140 - acc: 0.7285 - val_loss: 0.7058 - val_acc: 0.6042\n",
            "Epoch 133/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.5169 - acc: 0.7612 - val_loss: 0.6887 - val_acc: 0.6146\n",
            "Epoch 134/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5332 - acc: 0.7251 - val_loss: 0.6983 - val_acc: 0.5833\n",
            "Epoch 135/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.5401 - acc: 0.7285 - val_loss: 0.6853 - val_acc: 0.5833\n",
            "Epoch 136/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5253 - acc: 0.7285 - val_loss: 0.6861 - val_acc: 0.5833\n",
            "Epoch 137/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5292 - acc: 0.7405 - val_loss: 0.6826 - val_acc: 0.5625\n",
            "Epoch 138/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5137 - acc: 0.7423 - val_loss: 0.6897 - val_acc: 0.5521\n",
            "Epoch 139/1000\n",
            "37/37 [==============================] - 3s 84ms/step - loss: 0.5379 - acc: 0.7405 - val_loss: 0.6848 - val_acc: 0.5938\n",
            "Epoch 140/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.5572 - acc: 0.7165 - val_loss: 0.6772 - val_acc: 0.5938\n",
            "Epoch 141/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.5458 - acc: 0.7371 - val_loss: 0.6954 - val_acc: 0.5729\n",
            "Epoch 142/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.5493 - acc: 0.7027 - val_loss: 0.6855 - val_acc: 0.6042\n",
            "Epoch 143/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.5603 - acc: 0.7234 - val_loss: 0.6743 - val_acc: 0.5521\n",
            "Epoch 144/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5454 - acc: 0.7302 - val_loss: 0.7017 - val_acc: 0.5417\n",
            "Epoch 145/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.4835 - acc: 0.7543 - val_loss: 0.7015 - val_acc: 0.5833\n",
            "Epoch 146/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.5188 - acc: 0.7371 - val_loss: 0.7000 - val_acc: 0.5729\n",
            "Epoch 147/1000\n",
            "37/37 [==============================] - 9s 217ms/step - loss: 0.5385 - acc: 0.7131 - val_loss: 0.7060 - val_acc: 0.5729\n",
            "Epoch 148/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.5208 - acc: 0.7491 - val_loss: 0.6876 - val_acc: 0.5938\n",
            "Epoch 149/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5221 - acc: 0.7285 - val_loss: 0.6810 - val_acc: 0.5938\n",
            "Epoch 150/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5174 - acc: 0.7457 - val_loss: 0.6704 - val_acc: 0.6042\n",
            "Epoch 151/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.5323 - acc: 0.7440 - val_loss: 0.6963 - val_acc: 0.6042\n",
            "Epoch 152/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5125 - acc: 0.7216 - val_loss: 0.6971 - val_acc: 0.5833\n",
            "Epoch 153/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.5274 - acc: 0.7388 - val_loss: 0.6870 - val_acc: 0.5938\n",
            "Epoch 154/1000\n",
            "37/37 [==============================] - 8s 208ms/step - loss: 0.5230 - acc: 0.7285 - val_loss: 0.6846 - val_acc: 0.6042\n",
            "Epoch 155/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5023 - acc: 0.7612 - val_loss: 0.6867 - val_acc: 0.5521\n",
            "Epoch 156/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.5065 - acc: 0.7543 - val_loss: 0.7017 - val_acc: 0.5833\n",
            "Epoch 157/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.5167 - acc: 0.7543 - val_loss: 0.7082 - val_acc: 0.5833\n",
            "Epoch 158/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.5479 - acc: 0.7337 - val_loss: 0.6850 - val_acc: 0.6250\n",
            "Epoch 159/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5083 - acc: 0.7560 - val_loss: 0.7064 - val_acc: 0.5938\n",
            "Epoch 160/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5242 - acc: 0.7388 - val_loss: 0.6987 - val_acc: 0.5938\n",
            "Epoch 161/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5460 - acc: 0.7062 - val_loss: 0.7024 - val_acc: 0.5938\n",
            "Epoch 162/1000\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.5337 - acc: 0.7423 - val_loss: 0.6781 - val_acc: 0.6146\n",
            "Epoch 163/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5397 - acc: 0.7251 - val_loss: 0.6926 - val_acc: 0.6042\n",
            "Epoch 164/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.5167 - acc: 0.7371 - val_loss: 0.7200 - val_acc: 0.5938\n",
            "Epoch 165/1000\n",
            "37/37 [==============================] - 9s 216ms/step - loss: 0.5189 - acc: 0.7526 - val_loss: 0.6998 - val_acc: 0.5833\n",
            "Epoch 166/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5146 - acc: 0.7302 - val_loss: 0.7008 - val_acc: 0.5729\n",
            "Epoch 167/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5411 - acc: 0.7216 - val_loss: 0.6860 - val_acc: 0.5625\n",
            "Epoch 168/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5324 - acc: 0.7251 - val_loss: 0.6754 - val_acc: 0.6042\n",
            "Epoch 169/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5332 - acc: 0.7320 - val_loss: 0.7031 - val_acc: 0.5833\n",
            "Epoch 170/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.4981 - acc: 0.7509 - val_loss: 0.7002 - val_acc: 0.6042\n",
            "Epoch 171/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5325 - acc: 0.7268 - val_loss: 0.7078 - val_acc: 0.5938\n",
            "Epoch 172/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.5618 - acc: 0.7062 - val_loss: 0.6790 - val_acc: 0.6250\n",
            "Epoch 173/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.5327 - acc: 0.7457 - val_loss: 0.7138 - val_acc: 0.6042\n",
            "Epoch 174/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5338 - acc: 0.7113 - val_loss: 0.7089 - val_acc: 0.6042\n",
            "Epoch 175/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5332 - acc: 0.7320 - val_loss: 0.7034 - val_acc: 0.5938\n",
            "Epoch 176/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.5456 - acc: 0.7199 - val_loss: 0.6788 - val_acc: 0.6146\n",
            "Epoch 177/1000\n",
            "37/37 [==============================] - 5s 114ms/step - loss: 0.5425 - acc: 0.7302 - val_loss: 0.6874 - val_acc: 0.5938\n",
            "Epoch 178/1000\n",
            "37/37 [==============================] - 8s 208ms/step - loss: 0.5099 - acc: 0.7474 - val_loss: 0.7045 - val_acc: 0.5833\n",
            "Epoch 179/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5259 - acc: 0.7405 - val_loss: 0.7005 - val_acc: 0.6042\n",
            "Epoch 180/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.5329 - acc: 0.7423 - val_loss: 0.7057 - val_acc: 0.6042\n",
            "Epoch 181/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5243 - acc: 0.7371 - val_loss: 0.7096 - val_acc: 0.6042\n",
            "Epoch 182/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5313 - acc: 0.7509 - val_loss: 0.6919 - val_acc: 0.5938\n",
            "Epoch 183/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5245 - acc: 0.7371 - val_loss: 0.6949 - val_acc: 0.5938\n",
            "Epoch 184/1000\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.5357 - acc: 0.7285 - val_loss: 0.6869 - val_acc: 0.6146\n",
            "Epoch 185/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.5267 - acc: 0.7285 - val_loss: 0.6850 - val_acc: 0.5938\n",
            "Epoch 186/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.4732 - acc: 0.7354 - val_loss: 0.7063 - val_acc: 0.6042\n",
            "Epoch 187/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5521 - acc: 0.7251 - val_loss: 0.6789 - val_acc: 0.6042\n",
            "Epoch 188/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5298 - acc: 0.7405 - val_loss: 0.6993 - val_acc: 0.6042\n",
            "Epoch 189/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.4879 - acc: 0.7595 - val_loss: 0.7004 - val_acc: 0.6042\n",
            "Epoch 190/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5291 - acc: 0.7337 - val_loss: 0.7114 - val_acc: 0.6042\n",
            "Epoch 191/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5322 - acc: 0.7268 - val_loss: 0.6698 - val_acc: 0.6354\n",
            "Epoch 192/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5184 - acc: 0.7491 - val_loss: 0.7044 - val_acc: 0.5833\n",
            "Epoch 193/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5220 - acc: 0.7457 - val_loss: 0.6879 - val_acc: 0.5729\n",
            "Epoch 194/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.5318 - acc: 0.7423 - val_loss: 0.7028 - val_acc: 0.5729\n",
            "Epoch 195/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5389 - acc: 0.7405 - val_loss: 0.6970 - val_acc: 0.5938\n",
            "Epoch 196/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5307 - acc: 0.7079 - val_loss: 0.6938 - val_acc: 0.5938\n",
            "Epoch 197/1000\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 0.5157 - acc: 0.7354 - val_loss: 0.7006 - val_acc: 0.6146\n",
            "Epoch 198/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.5335 - acc: 0.7268 - val_loss: 0.6664 - val_acc: 0.6146\n",
            "Epoch 199/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.5238 - acc: 0.7354 - val_loss: 0.6910 - val_acc: 0.5833\n",
            "Epoch 200/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.5332 - acc: 0.7388 - val_loss: 0.6792 - val_acc: 0.6250\n",
            "Epoch 201/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5202 - acc: 0.7285 - val_loss: 0.6906 - val_acc: 0.6146\n",
            "Epoch 202/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5491 - acc: 0.7234 - val_loss: 0.7050 - val_acc: 0.5938\n",
            "Epoch 203/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5114 - acc: 0.7388 - val_loss: 0.7106 - val_acc: 0.6042\n",
            "Epoch 204/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.4982 - acc: 0.7646 - val_loss: 0.6774 - val_acc: 0.6250\n",
            "Epoch 205/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.5358 - acc: 0.7388 - val_loss: 0.7042 - val_acc: 0.6042\n",
            "Epoch 206/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5111 - acc: 0.7388 - val_loss: 0.7153 - val_acc: 0.5938\n",
            "Epoch 207/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5053 - acc: 0.7354 - val_loss: 0.6952 - val_acc: 0.6250\n",
            "Epoch 208/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5475 - acc: 0.7045 - val_loss: 0.6971 - val_acc: 0.6146\n",
            "Epoch 209/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5627 - acc: 0.7182 - val_loss: 0.6960 - val_acc: 0.6146\n",
            "Epoch 210/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5476 - acc: 0.7165 - val_loss: 0.7033 - val_acc: 0.5938\n",
            "Epoch 211/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5287 - acc: 0.7320 - val_loss: 0.6840 - val_acc: 0.6146\n",
            "Epoch 212/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5334 - acc: 0.7440 - val_loss: 0.7072 - val_acc: 0.5938\n",
            "Epoch 213/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.5114 - acc: 0.7337 - val_loss: 0.6909 - val_acc: 0.6146\n",
            "Epoch 214/1000\n",
            "37/37 [==============================] - 10s 245ms/step - loss: 0.5456 - acc: 0.7216 - val_loss: 0.6941 - val_acc: 0.5833\n",
            "Epoch 215/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.5393 - acc: 0.7216 - val_loss: 0.6991 - val_acc: 0.6042\n",
            "Epoch 216/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5241 - acc: 0.7268 - val_loss: 0.6841 - val_acc: 0.6146\n",
            "Epoch 217/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.5203 - acc: 0.7371 - val_loss: 0.6889 - val_acc: 0.6042\n",
            "Epoch 218/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5111 - acc: 0.7354 - val_loss: 0.6920 - val_acc: 0.6146\n",
            "Epoch 219/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.5315 - acc: 0.7268 - val_loss: 0.6927 - val_acc: 0.5938\n",
            "Epoch 220/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5249 - acc: 0.7423 - val_loss: 0.7016 - val_acc: 0.6042\n",
            "Epoch 221/1000\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.5180 - acc: 0.7354 - val_loss: 0.6842 - val_acc: 0.6146\n",
            "Epoch 222/1000\n",
            "37/37 [==============================] - 4s 82ms/step - loss: 0.5015 - acc: 0.7680 - val_loss: 0.7055 - val_acc: 0.5938\n",
            "Epoch 223/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.5195 - acc: 0.7354 - val_loss: 0.6920 - val_acc: 0.6146\n",
            "Epoch 224/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5329 - acc: 0.7388 - val_loss: 0.7006 - val_acc: 0.6042\n",
            "Epoch 225/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5387 - acc: 0.7268 - val_loss: 0.6945 - val_acc: 0.6146\n",
            "Epoch 226/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5446 - acc: 0.7010 - val_loss: 0.6781 - val_acc: 0.5938\n",
            "Epoch 227/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.5286 - acc: 0.7526 - val_loss: 0.6936 - val_acc: 0.6042\n",
            "Epoch 228/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.5511 - acc: 0.6976 - val_loss: 0.6974 - val_acc: 0.6146\n",
            "Epoch 229/1000\n",
            "37/37 [==============================] - 5s 114ms/step - loss: 0.5422 - acc: 0.7337 - val_loss: 0.7028 - val_acc: 0.5938\n",
            "Epoch 230/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5321 - acc: 0.7337 - val_loss: 0.6864 - val_acc: 0.6146\n",
            "Epoch 231/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5019 - acc: 0.7560 - val_loss: 0.6878 - val_acc: 0.6146\n",
            "Epoch 232/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5366 - acc: 0.7337 - val_loss: 0.7004 - val_acc: 0.5833\n",
            "Epoch 233/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5222 - acc: 0.7337 - val_loss: 0.6792 - val_acc: 0.6146\n",
            "Epoch 234/1000\n",
            "37/37 [==============================] - 5s 108ms/step - loss: 0.5364 - acc: 0.7474 - val_loss: 0.6981 - val_acc: 0.6042\n",
            "Epoch 235/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.5189 - acc: 0.7234 - val_loss: 0.6933 - val_acc: 0.5833\n",
            "Epoch 236/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.5430 - acc: 0.7079 - val_loss: 0.6778 - val_acc: 0.6250\n",
            "Epoch 237/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5368 - acc: 0.7182 - val_loss: 0.6792 - val_acc: 0.6250\n",
            "Epoch 238/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.5557 - acc: 0.7268 - val_loss: 0.6817 - val_acc: 0.5833\n",
            "Epoch 239/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.5465 - acc: 0.7216 - val_loss: 0.6817 - val_acc: 0.5833\n",
            "Epoch 240/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5352 - acc: 0.7423 - val_loss: 0.6737 - val_acc: 0.5625\n",
            "Epoch 241/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.5183 - acc: 0.7234 - val_loss: 0.6775 - val_acc: 0.5833\n",
            "Epoch 242/1000\n",
            "37/37 [==============================] - 4s 110ms/step - loss: 0.5467 - acc: 0.7182 - val_loss: 0.6796 - val_acc: 0.5833\n",
            "Epoch 243/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5545 - acc: 0.7216 - val_loss: 0.6857 - val_acc: 0.6042\n",
            "Epoch 244/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5462 - acc: 0.7405 - val_loss: 0.6787 - val_acc: 0.5938\n",
            "Epoch 245/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5329 - acc: 0.7165 - val_loss: 0.6740 - val_acc: 0.5312\n",
            "Epoch 246/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5143 - acc: 0.7715 - val_loss: 0.6774 - val_acc: 0.5938\n",
            "Epoch 247/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5161 - acc: 0.7371 - val_loss: 0.6771 - val_acc: 0.6042\n",
            "Epoch 248/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.5382 - acc: 0.7182 - val_loss: 0.6941 - val_acc: 0.6042\n",
            "Epoch 249/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5155 - acc: 0.7423 - val_loss: 0.6695 - val_acc: 0.6250\n",
            "Epoch 250/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5293 - acc: 0.7354 - val_loss: 0.6774 - val_acc: 0.6146\n",
            "Epoch 251/1000\n",
            "37/37 [==============================] - 4s 80ms/step - loss: 0.5315 - acc: 0.7145 - val_loss: 0.6872 - val_acc: 0.5938\n",
            "Epoch 252/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5331 - acc: 0.7388 - val_loss: 0.6668 - val_acc: 0.5312\n",
            "Epoch 253/1000\n",
            "37/37 [==============================] - 8s 208ms/step - loss: 0.5459 - acc: 0.7113 - val_loss: 0.6691 - val_acc: 0.6146\n",
            "Epoch 254/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5070 - acc: 0.7405 - val_loss: 0.6776 - val_acc: 0.5625\n",
            "Epoch 255/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.5238 - acc: 0.7423 - val_loss: 0.6794 - val_acc: 0.5729\n",
            "Epoch 256/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5450 - acc: 0.7182 - val_loss: 0.6623 - val_acc: 0.6146\n",
            "Epoch 257/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5516 - acc: 0.7302 - val_loss: 0.6664 - val_acc: 0.6146\n",
            "Epoch 258/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.5353 - acc: 0.7268 - val_loss: 0.6797 - val_acc: 0.5833\n",
            "Epoch 259/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5058 - acc: 0.7698 - val_loss: 0.6892 - val_acc: 0.5938\n",
            "Epoch 260/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.4962 - acc: 0.7449 - val_loss: 0.6876 - val_acc: 0.6042\n",
            "Epoch 261/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.5081 - acc: 0.7348 - val_loss: 0.6827 - val_acc: 0.6250\n",
            "Epoch 262/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5325 - acc: 0.7388 - val_loss: 0.6876 - val_acc: 0.6042\n",
            "Epoch 263/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.5336 - acc: 0.7388 - val_loss: 0.6897 - val_acc: 0.6042\n",
            "Epoch 264/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.5733 - acc: 0.7062 - val_loss: 0.6781 - val_acc: 0.6146\n",
            "Epoch 265/1000\n",
            "37/37 [==============================] - 4s 80ms/step - loss: 0.5318 - acc: 0.6976 - val_loss: 0.6657 - val_acc: 0.5938\n",
            "Epoch 266/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.4995 - acc: 0.7560 - val_loss: 0.6794 - val_acc: 0.6146\n",
            "Epoch 267/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5471 - acc: 0.7285 - val_loss: 0.6574 - val_acc: 0.6250\n",
            "Epoch 268/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5335 - acc: 0.7216 - val_loss: 0.6848 - val_acc: 0.5938\n",
            "Epoch 269/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5172 - acc: 0.7337 - val_loss: 0.6857 - val_acc: 0.6146\n",
            "Epoch 270/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5428 - acc: 0.7096 - val_loss: 0.6859 - val_acc: 0.5938\n",
            "Epoch 271/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.4973 - acc: 0.7749 - val_loss: 0.6747 - val_acc: 0.6146\n",
            "Epoch 272/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5502 - acc: 0.7268 - val_loss: 0.6780 - val_acc: 0.6250\n",
            "Epoch 273/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5260 - acc: 0.7388 - val_loss: 0.6776 - val_acc: 0.5833\n",
            "Epoch 274/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5280 - acc: 0.7251 - val_loss: 0.6706 - val_acc: 0.6146\n",
            "Epoch 275/1000\n",
            "37/37 [==============================] - 4s 110ms/step - loss: 0.5699 - acc: 0.6856 - val_loss: 0.6856 - val_acc: 0.5938\n",
            "Epoch 276/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5305 - acc: 0.7440 - val_loss: 0.6847 - val_acc: 0.5833\n",
            "Epoch 277/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5160 - acc: 0.7371 - val_loss: 0.6748 - val_acc: 0.6250\n",
            "Epoch 278/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.5291 - acc: 0.7320 - val_loss: 0.6727 - val_acc: 0.6250\n",
            "Epoch 279/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.4960 - acc: 0.7457 - val_loss: 0.6841 - val_acc: 0.6146\n",
            "Epoch 280/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.5434 - acc: 0.7199 - val_loss: 0.6662 - val_acc: 0.6146\n",
            "Epoch 281/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.5110 - acc: 0.7526 - val_loss: 0.6836 - val_acc: 0.6042\n",
            "Epoch 282/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5302 - acc: 0.7302 - val_loss: 0.6649 - val_acc: 0.6250\n",
            "Epoch 283/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5373 - acc: 0.7216 - val_loss: 0.6950 - val_acc: 0.6042\n",
            "Epoch 284/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.5703 - acc: 0.6856 - val_loss: 0.6728 - val_acc: 0.6146\n",
            "Epoch 285/1000\n",
            "37/37 [==============================] - 4s 79ms/step - loss: 0.4983 - acc: 0.7595 - val_loss: 0.6779 - val_acc: 0.6146\n",
            "Epoch 286/1000\n",
            "37/37 [==============================] - 9s 218ms/step - loss: 0.5393 - acc: 0.7320 - val_loss: 0.6770 - val_acc: 0.6146\n",
            "Epoch 287/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5181 - acc: 0.7165 - val_loss: 0.6772 - val_acc: 0.6250\n",
            "Epoch 288/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.4823 - acc: 0.7818 - val_loss: 0.6626 - val_acc: 0.6146\n",
            "Epoch 289/1000\n",
            "37/37 [==============================] - 9s 217ms/step - loss: 0.5404 - acc: 0.7251 - val_loss: 0.6703 - val_acc: 0.6250\n",
            "Epoch 290/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.5516 - acc: 0.7354 - val_loss: 0.6870 - val_acc: 0.5833\n",
            "Epoch 291/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5109 - acc: 0.7440 - val_loss: 0.6791 - val_acc: 0.6146\n",
            "Epoch 292/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.4753 - acc: 0.7663 - val_loss: 0.6709 - val_acc: 0.6146\n",
            "Epoch 293/1000\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.5241 - acc: 0.7371 - val_loss: 0.6791 - val_acc: 0.6146\n",
            "Epoch 294/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.5115 - acc: 0.7551 - val_loss: 0.6812 - val_acc: 0.6042\n",
            "Epoch 295/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5276 - acc: 0.7405 - val_loss: 0.6726 - val_acc: 0.6250\n",
            "Epoch 296/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.4944 - acc: 0.7629 - val_loss: 0.6889 - val_acc: 0.6146\n",
            "Epoch 297/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.5260 - acc: 0.7251 - val_loss: 0.6631 - val_acc: 0.6354\n",
            "Epoch 298/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5634 - acc: 0.7216 - val_loss: 0.6603 - val_acc: 0.6250\n",
            "Epoch 299/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5088 - acc: 0.7474 - val_loss: 0.6783 - val_acc: 0.6146\n",
            "Epoch 300/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5237 - acc: 0.7285 - val_loss: 0.6784 - val_acc: 0.6146\n",
            "Epoch 301/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.4905 - acc: 0.7543 - val_loss: 0.6472 - val_acc: 0.6354\n",
            "Epoch 302/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5220 - acc: 0.7302 - val_loss: 0.6835 - val_acc: 0.6146\n",
            "Epoch 303/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.5488 - acc: 0.7027 - val_loss: 0.6734 - val_acc: 0.6146\n",
            "Epoch 304/1000\n",
            "37/37 [==============================] - 9s 239ms/step - loss: 0.5018 - acc: 0.7320 - val_loss: 0.6752 - val_acc: 0.6146\n",
            "Epoch 305/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.5171 - acc: 0.7251 - val_loss: 0.6645 - val_acc: 0.6354\n",
            "Epoch 306/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5368 - acc: 0.7062 - val_loss: 0.6749 - val_acc: 0.6146\n",
            "Epoch 307/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5221 - acc: 0.7423 - val_loss: 0.6861 - val_acc: 0.6146\n",
            "Epoch 308/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.5177 - acc: 0.7612 - val_loss: 0.6618 - val_acc: 0.6250\n",
            "Epoch 309/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.5141 - acc: 0.7405 - val_loss: 0.6759 - val_acc: 0.5938\n",
            "Epoch 310/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5218 - acc: 0.7474 - val_loss: 0.6791 - val_acc: 0.6146\n",
            "Epoch 311/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5401 - acc: 0.7302 - val_loss: 0.6589 - val_acc: 0.6354\n",
            "Epoch 312/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.4926 - acc: 0.7612 - val_loss: 0.6898 - val_acc: 0.6042\n",
            "Epoch 313/1000\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.5418 - acc: 0.7509 - val_loss: 0.6887 - val_acc: 0.6042\n",
            "Epoch 314/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5170 - acc: 0.7388 - val_loss: 0.6943 - val_acc: 0.6042\n",
            "Epoch 315/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5121 - acc: 0.7354 - val_loss: 0.6989 - val_acc: 0.5938\n",
            "Epoch 316/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5239 - acc: 0.7405 - val_loss: 0.6680 - val_acc: 0.6250\n",
            "Epoch 317/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5046 - acc: 0.7509 - val_loss: 0.6933 - val_acc: 0.5938\n",
            "Epoch 318/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5414 - acc: 0.7388 - val_loss: 0.6719 - val_acc: 0.6146\n",
            "Epoch 319/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.5222 - acc: 0.7526 - val_loss: 0.6773 - val_acc: 0.6146\n",
            "Epoch 320/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5615 - acc: 0.7251 - val_loss: 0.6864 - val_acc: 0.6042\n",
            "Epoch 321/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5235 - acc: 0.7474 - val_loss: 0.6765 - val_acc: 0.6250\n",
            "Epoch 322/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.4927 - acc: 0.7715 - val_loss: 0.6786 - val_acc: 0.5833\n",
            "Epoch 323/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.5189 - acc: 0.7320 - val_loss: 0.6877 - val_acc: 0.6042\n",
            "Epoch 324/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5154 - acc: 0.7491 - val_loss: 0.6742 - val_acc: 0.6146\n",
            "Epoch 325/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5182 - acc: 0.7526 - val_loss: 0.6841 - val_acc: 0.6146\n",
            "Epoch 326/1000\n",
            "37/37 [==============================] - 3s 84ms/step - loss: 0.5099 - acc: 0.7577 - val_loss: 0.6628 - val_acc: 0.6354\n",
            "Epoch 327/1000\n",
            "37/37 [==============================] - 4s 82ms/step - loss: 0.4932 - acc: 0.7715 - val_loss: 0.6918 - val_acc: 0.5938\n",
            "Epoch 328/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5191 - acc: 0.7646 - val_loss: 0.6608 - val_acc: 0.6250\n",
            "Epoch 329/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5290 - acc: 0.7388 - val_loss: 0.6752 - val_acc: 0.6146\n",
            "Epoch 330/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5198 - acc: 0.7474 - val_loss: 0.6696 - val_acc: 0.6042\n",
            "Epoch 331/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.5448 - acc: 0.7131 - val_loss: 0.6705 - val_acc: 0.6146\n",
            "Epoch 332/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.5401 - acc: 0.7216 - val_loss: 0.6649 - val_acc: 0.6146\n",
            "Epoch 333/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5314 - acc: 0.7268 - val_loss: 0.6838 - val_acc: 0.5938\n",
            "Epoch 334/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.4755 - acc: 0.7715 - val_loss: 0.6565 - val_acc: 0.6146\n",
            "Epoch 335/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5326 - acc: 0.7268 - val_loss: 0.6628 - val_acc: 0.6354\n",
            "Epoch 336/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5022 - acc: 0.7474 - val_loss: 0.6861 - val_acc: 0.5938\n",
            "Epoch 337/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5663 - acc: 0.7113 - val_loss: 0.6774 - val_acc: 0.6146\n",
            "Epoch 338/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.5403 - acc: 0.7337 - val_loss: 0.6859 - val_acc: 0.6146\n",
            "Epoch 339/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5469 - acc: 0.7096 - val_loss: 0.6678 - val_acc: 0.6354\n",
            "Epoch 340/1000\n",
            "37/37 [==============================] - 4s 110ms/step - loss: 0.5437 - acc: 0.7285 - val_loss: 0.6800 - val_acc: 0.6146\n",
            "Epoch 341/1000\n",
            "37/37 [==============================] - 4s 78ms/step - loss: 0.5147 - acc: 0.7543 - val_loss: 0.6962 - val_acc: 0.6042\n",
            "Epoch 342/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.5318 - acc: 0.7405 - val_loss: 0.6892 - val_acc: 0.5938\n",
            "Epoch 343/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.5248 - acc: 0.7268 - val_loss: 0.6749 - val_acc: 0.6146\n",
            "Epoch 344/1000\n",
            "37/37 [==============================] - 4s 79ms/step - loss: 0.5267 - acc: 0.7509 - val_loss: 0.6663 - val_acc: 0.6250\n",
            "Epoch 345/1000\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.5278 - acc: 0.7331 - val_loss: 0.6947 - val_acc: 0.5938\n",
            "Epoch 346/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5284 - acc: 0.7371 - val_loss: 0.6845 - val_acc: 0.6146\n",
            "Epoch 347/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5123 - acc: 0.7234 - val_loss: 0.6842 - val_acc: 0.6146\n",
            "Epoch 348/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5428 - acc: 0.7148 - val_loss: 0.6519 - val_acc: 0.6354\n",
            "Epoch 349/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5160 - acc: 0.7388 - val_loss: 0.6886 - val_acc: 0.6042\n",
            "Epoch 350/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5395 - acc: 0.7062 - val_loss: 0.6899 - val_acc: 0.5938\n",
            "Epoch 351/1000\n",
            "37/37 [==============================] - 9s 219ms/step - loss: 0.5283 - acc: 0.7388 - val_loss: 0.6805 - val_acc: 0.6146\n",
            "Epoch 352/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.5214 - acc: 0.7285 - val_loss: 0.6748 - val_acc: 0.6250\n",
            "Epoch 353/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5298 - acc: 0.7405 - val_loss: 0.6815 - val_acc: 0.6250\n",
            "Epoch 354/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5039 - acc: 0.7405 - val_loss: 0.6851 - val_acc: 0.6042\n",
            "Epoch 355/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5297 - acc: 0.7216 - val_loss: 0.6885 - val_acc: 0.6042\n",
            "Epoch 356/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5252 - acc: 0.7577 - val_loss: 0.6890 - val_acc: 0.6042\n",
            "Epoch 357/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5158 - acc: 0.7732 - val_loss: 0.6930 - val_acc: 0.5938\n",
            "Epoch 358/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5269 - acc: 0.7337 - val_loss: 0.6930 - val_acc: 0.5938\n",
            "Epoch 359/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5211 - acc: 0.7251 - val_loss: 0.6808 - val_acc: 0.6146\n",
            "Epoch 360/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.5101 - acc: 0.7629 - val_loss: 0.6835 - val_acc: 0.6146\n",
            "Epoch 361/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.5266 - acc: 0.7354 - val_loss: 0.6721 - val_acc: 0.6250\n",
            "Epoch 362/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.5190 - acc: 0.7388 - val_loss: 0.6807 - val_acc: 0.6146\n",
            "Epoch 363/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5260 - acc: 0.7354 - val_loss: 0.6678 - val_acc: 0.6354\n",
            "Epoch 364/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.5347 - acc: 0.7165 - val_loss: 0.6672 - val_acc: 0.6354\n",
            "Epoch 365/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5134 - acc: 0.7474 - val_loss: 0.7004 - val_acc: 0.5938\n",
            "Epoch 366/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5510 - acc: 0.7131 - val_loss: 0.7036 - val_acc: 0.6042\n",
            "Epoch 367/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.5110 - acc: 0.7405 - val_loss: 0.6769 - val_acc: 0.6146\n",
            "Epoch 368/1000\n",
            "37/37 [==============================] - 5s 105ms/step - loss: 0.5046 - acc: 0.7474 - val_loss: 0.6669 - val_acc: 0.6250\n",
            "Epoch 369/1000\n",
            "37/37 [==============================] - 3s 84ms/step - loss: 0.5490 - acc: 0.7234 - val_loss: 0.6765 - val_acc: 0.6146\n",
            "Epoch 370/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.5669 - acc: 0.7182 - val_loss: 0.6716 - val_acc: 0.6250\n",
            "Epoch 371/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5128 - acc: 0.7302 - val_loss: 0.6904 - val_acc: 0.6042\n",
            "Epoch 372/1000\n",
            "37/37 [==============================] - 5s 110ms/step - loss: 0.5050 - acc: 0.7491 - val_loss: 0.6807 - val_acc: 0.6042\n",
            "Epoch 373/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5213 - acc: 0.7216 - val_loss: 0.6795 - val_acc: 0.6146\n",
            "Epoch 374/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.5069 - acc: 0.7491 - val_loss: 0.6890 - val_acc: 0.6042\n",
            "Epoch 375/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.4865 - acc: 0.7457 - val_loss: 0.6812 - val_acc: 0.6042\n",
            "Epoch 376/1000\n",
            "37/37 [==============================] - 6s 147ms/step - loss: 0.5243 - acc: 0.7371 - val_loss: 0.6816 - val_acc: 0.6354\n",
            "Epoch 377/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5087 - acc: 0.7680 - val_loss: 0.6899 - val_acc: 0.6146\n",
            "Epoch 378/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.4964 - acc: 0.7801 - val_loss: 0.6800 - val_acc: 0.6146\n",
            "Epoch 379/1000\n",
            "37/37 [==============================] - 4s 109ms/step - loss: 0.4977 - acc: 0.7348 - val_loss: 0.6727 - val_acc: 0.6354\n",
            "Epoch 380/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5268 - acc: 0.6959 - val_loss: 0.6816 - val_acc: 0.6250\n",
            "Epoch 381/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5208 - acc: 0.7354 - val_loss: 0.6793 - val_acc: 0.6146\n",
            "Epoch 382/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.4863 - acc: 0.7405 - val_loss: 0.6720 - val_acc: 0.6146\n",
            "Epoch 383/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5114 - acc: 0.7405 - val_loss: 0.6775 - val_acc: 0.6354\n",
            "Epoch 384/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.5214 - acc: 0.7405 - val_loss: 0.6913 - val_acc: 0.6354\n",
            "Epoch 385/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5100 - acc: 0.7337 - val_loss: 0.6851 - val_acc: 0.6250\n",
            "Epoch 386/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.5080 - acc: 0.7509 - val_loss: 0.6938 - val_acc: 0.6146\n",
            "Epoch 387/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.5079 - acc: 0.7595 - val_loss: 0.6851 - val_acc: 0.6146\n",
            "Epoch 388/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5411 - acc: 0.7405 - val_loss: 0.6895 - val_acc: 0.6250\n",
            "Epoch 389/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5304 - acc: 0.7526 - val_loss: 0.6820 - val_acc: 0.6250\n",
            "Epoch 390/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5057 - acc: 0.7423 - val_loss: 0.6894 - val_acc: 0.6146\n",
            "Epoch 391/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5246 - acc: 0.7320 - val_loss: 0.6705 - val_acc: 0.6458\n",
            "Epoch 392/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.4966 - acc: 0.7577 - val_loss: 0.6648 - val_acc: 0.6354\n",
            "Epoch 393/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5330 - acc: 0.7234 - val_loss: 0.6782 - val_acc: 0.6146\n",
            "Epoch 394/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.5448 - acc: 0.7216 - val_loss: 0.6835 - val_acc: 0.5938\n",
            "Epoch 395/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.5216 - acc: 0.7474 - val_loss: 0.6761 - val_acc: 0.6042\n",
            "Epoch 396/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.5394 - acc: 0.7131 - val_loss: 0.6739 - val_acc: 0.6250\n",
            "Epoch 397/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.4990 - acc: 0.7509 - val_loss: 0.6803 - val_acc: 0.6042\n",
            "Epoch 398/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5240 - acc: 0.7302 - val_loss: 0.6828 - val_acc: 0.6042\n",
            "Epoch 399/1000\n",
            "37/37 [==============================] - 8s 224ms/step - loss: 0.5121 - acc: 0.7388 - val_loss: 0.6736 - val_acc: 0.6458\n",
            "Epoch 400/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.5344 - acc: 0.7354 - val_loss: 0.6643 - val_acc: 0.6250\n",
            "Epoch 401/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5420 - acc: 0.7165 - val_loss: 0.6622 - val_acc: 0.6354\n",
            "Epoch 402/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.5412 - acc: 0.7148 - val_loss: 0.6858 - val_acc: 0.6354\n",
            "Epoch 403/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5131 - acc: 0.7371 - val_loss: 0.6798 - val_acc: 0.6146\n",
            "Epoch 404/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5043 - acc: 0.7509 - val_loss: 0.6767 - val_acc: 0.6146\n",
            "Epoch 405/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5036 - acc: 0.7509 - val_loss: 0.6728 - val_acc: 0.6354\n",
            "Epoch 406/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5104 - acc: 0.7818 - val_loss: 0.6804 - val_acc: 0.6042\n",
            "Epoch 407/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.4982 - acc: 0.7560 - val_loss: 0.6653 - val_acc: 0.6250\n",
            "Epoch 408/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5302 - acc: 0.7526 - val_loss: 0.6961 - val_acc: 0.6146\n",
            "Epoch 409/1000\n",
            "37/37 [==============================] - 3s 83ms/step - loss: 0.5127 - acc: 0.7371 - val_loss: 0.6755 - val_acc: 0.6250\n",
            "Epoch 410/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5486 - acc: 0.7251 - val_loss: 0.6738 - val_acc: 0.6354\n",
            "Epoch 411/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5122 - acc: 0.7526 - val_loss: 0.6752 - val_acc: 0.6042\n",
            "Epoch 412/1000\n",
            "37/37 [==============================] - 4s 80ms/step - loss: 0.5139 - acc: 0.7371 - val_loss: 0.6609 - val_acc: 0.6250\n",
            "Epoch 413/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.4966 - acc: 0.7715 - val_loss: 0.6758 - val_acc: 0.6250\n",
            "Epoch 414/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5172 - acc: 0.7354 - val_loss: 0.6783 - val_acc: 0.6146\n",
            "Epoch 415/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5353 - acc: 0.7199 - val_loss: 0.6816 - val_acc: 0.6250\n",
            "Epoch 416/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5281 - acc: 0.7543 - val_loss: 0.6728 - val_acc: 0.6146\n",
            "Epoch 417/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.5067 - acc: 0.7268 - val_loss: 0.6843 - val_acc: 0.6146\n",
            "Epoch 418/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.5310 - acc: 0.7165 - val_loss: 0.6688 - val_acc: 0.6146\n",
            "Epoch 419/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.5293 - acc: 0.7405 - val_loss: 0.6602 - val_acc: 0.6250\n",
            "Epoch 420/1000\n",
            "37/37 [==============================] - 4s 82ms/step - loss: 0.5443 - acc: 0.7148 - val_loss: 0.6738 - val_acc: 0.6042\n",
            "Epoch 421/1000\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.5198 - acc: 0.7371 - val_loss: 0.6589 - val_acc: 0.6250\n",
            "Epoch 422/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5044 - acc: 0.7560 - val_loss: 0.6752 - val_acc: 0.6146\n",
            "Epoch 423/1000\n",
            "37/37 [==============================] - 4s 80ms/step - loss: 0.5091 - acc: 0.7320 - val_loss: 0.6561 - val_acc: 0.6354\n",
            "Epoch 424/1000\n",
            "37/37 [==============================] - 5s 105ms/step - loss: 0.5147 - acc: 0.7251 - val_loss: 0.6774 - val_acc: 0.6042\n",
            "Epoch 425/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5274 - acc: 0.7320 - val_loss: 0.6731 - val_acc: 0.6146\n",
            "Epoch 426/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5532 - acc: 0.7113 - val_loss: 0.6850 - val_acc: 0.6354\n",
            "Epoch 427/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5142 - acc: 0.7560 - val_loss: 0.6869 - val_acc: 0.6250\n",
            "Epoch 428/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5337 - acc: 0.7234 - val_loss: 0.6831 - val_acc: 0.6146\n",
            "Epoch 429/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.5079 - acc: 0.7440 - val_loss: 0.6991 - val_acc: 0.6146\n",
            "Epoch 430/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5169 - acc: 0.7577 - val_loss: 0.6696 - val_acc: 0.6458\n",
            "Epoch 431/1000\n",
            "37/37 [==============================] - 5s 99ms/step - loss: 0.5232 - acc: 0.7302 - val_loss: 0.6897 - val_acc: 0.6250\n",
            "Epoch 432/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.5694 - acc: 0.7113 - val_loss: 0.6712 - val_acc: 0.6458\n",
            "Epoch 433/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.5261 - acc: 0.7268 - val_loss: 0.6978 - val_acc: 0.6146\n",
            "Epoch 434/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.4979 - acc: 0.7732 - val_loss: 0.6758 - val_acc: 0.6250\n",
            "Epoch 435/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5323 - acc: 0.7474 - val_loss: 0.6701 - val_acc: 0.6354\n",
            "Epoch 436/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.4965 - acc: 0.7354 - val_loss: 0.6736 - val_acc: 0.6146\n",
            "Epoch 437/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5389 - acc: 0.7045 - val_loss: 0.6908 - val_acc: 0.6250\n",
            "Epoch 438/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.4916 - acc: 0.7852 - val_loss: 0.6702 - val_acc: 0.6562\n",
            "Epoch 439/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5030 - acc: 0.7337 - val_loss: 0.6957 - val_acc: 0.6146\n",
            "Epoch 440/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.4955 - acc: 0.7577 - val_loss: 0.6822 - val_acc: 0.6458\n",
            "Epoch 441/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5044 - acc: 0.7577 - val_loss: 0.6738 - val_acc: 0.6458\n",
            "Epoch 442/1000\n",
            "37/37 [==============================] - 3s 84ms/step - loss: 0.4907 - acc: 0.7483 - val_loss: 0.6683 - val_acc: 0.6458\n",
            "Epoch 443/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5074 - acc: 0.7405 - val_loss: 0.6875 - val_acc: 0.6354\n",
            "Epoch 444/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5325 - acc: 0.7148 - val_loss: 0.6884 - val_acc: 0.5938\n",
            "Epoch 445/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5535 - acc: 0.7354 - val_loss: 0.6765 - val_acc: 0.6146\n",
            "Epoch 446/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.5142 - acc: 0.7337 - val_loss: 0.6972 - val_acc: 0.6146\n",
            "Epoch 447/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5184 - acc: 0.7612 - val_loss: 0.6929 - val_acc: 0.5938\n",
            "Epoch 448/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.5301 - acc: 0.7405 - val_loss: 0.6677 - val_acc: 0.6146\n",
            "Epoch 449/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.5054 - acc: 0.7595 - val_loss: 0.6937 - val_acc: 0.6042\n",
            "Epoch 450/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5069 - acc: 0.7405 - val_loss: 0.6845 - val_acc: 0.6042\n",
            "Epoch 451/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.4873 - acc: 0.7543 - val_loss: 0.6818 - val_acc: 0.6146\n",
            "Epoch 452/1000\n",
            "37/37 [==============================] - 8s 223ms/step - loss: 0.5259 - acc: 0.7388 - val_loss: 0.6799 - val_acc: 0.6146\n",
            "Epoch 453/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5019 - acc: 0.7560 - val_loss: 0.6611 - val_acc: 0.6250\n",
            "Epoch 454/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5067 - acc: 0.7440 - val_loss: 0.6712 - val_acc: 0.6354\n",
            "Epoch 455/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5298 - acc: 0.7285 - val_loss: 0.6882 - val_acc: 0.6146\n",
            "Epoch 456/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5158 - acc: 0.7440 - val_loss: 0.6663 - val_acc: 0.6458\n",
            "Epoch 457/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5045 - acc: 0.7371 - val_loss: 0.6732 - val_acc: 0.6146\n",
            "Epoch 458/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5482 - acc: 0.7131 - val_loss: 0.6765 - val_acc: 0.6146\n",
            "Epoch 459/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5189 - acc: 0.7285 - val_loss: 0.6694 - val_acc: 0.6250\n",
            "Epoch 460/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5274 - acc: 0.7371 - val_loss: 0.6750 - val_acc: 0.6146\n",
            "Epoch 461/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.5199 - acc: 0.7405 - val_loss: 0.6836 - val_acc: 0.6146\n",
            "Epoch 462/1000\n",
            "37/37 [==============================] - 5s 108ms/step - loss: 0.5034 - acc: 0.7560 - val_loss: 0.6614 - val_acc: 0.6562\n",
            "Epoch 463/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5324 - acc: 0.7320 - val_loss: 0.6532 - val_acc: 0.6458\n",
            "Epoch 464/1000\n",
            "37/37 [==============================] - 6s 145ms/step - loss: 0.5376 - acc: 0.7216 - val_loss: 0.6907 - val_acc: 0.6250\n",
            "Epoch 465/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.5217 - acc: 0.7457 - val_loss: 0.6750 - val_acc: 0.6354\n",
            "Epoch 466/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.5260 - acc: 0.7337 - val_loss: 0.6811 - val_acc: 0.6146\n",
            "Epoch 467/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.5407 - acc: 0.7199 - val_loss: 0.6984 - val_acc: 0.6146\n",
            "Epoch 468/1000\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.5246 - acc: 0.7491 - val_loss: 0.6755 - val_acc: 0.6354\n",
            "Epoch 469/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5263 - acc: 0.7457 - val_loss: 0.6739 - val_acc: 0.6458\n",
            "Epoch 470/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5438 - acc: 0.7285 - val_loss: 0.6707 - val_acc: 0.6354\n",
            "Epoch 471/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5152 - acc: 0.7526 - val_loss: 0.6929 - val_acc: 0.6146\n",
            "Epoch 472/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.5670 - acc: 0.7010 - val_loss: 0.6778 - val_acc: 0.6354\n",
            "Epoch 473/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.4901 - acc: 0.7457 - val_loss: 0.6522 - val_acc: 0.6562\n",
            "Epoch 474/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5078 - acc: 0.7534 - val_loss: 0.6796 - val_acc: 0.6458\n",
            "Epoch 475/1000\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 0.5323 - acc: 0.7423 - val_loss: 0.6872 - val_acc: 0.6146\n",
            "Epoch 476/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5385 - acc: 0.7371 - val_loss: 0.6632 - val_acc: 0.6250\n",
            "Epoch 477/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5121 - acc: 0.7457 - val_loss: 0.6647 - val_acc: 0.6250\n",
            "Epoch 478/1000\n",
            "37/37 [==============================] - 9s 217ms/step - loss: 0.5437 - acc: 0.7213 - val_loss: 0.6743 - val_acc: 0.6042\n",
            "Epoch 479/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.5266 - acc: 0.7096 - val_loss: 0.7047 - val_acc: 0.6146\n",
            "Epoch 480/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5006 - acc: 0.7577 - val_loss: 0.6967 - val_acc: 0.6250\n",
            "Epoch 481/1000\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.5046 - acc: 0.7646 - val_loss: 0.6930 - val_acc: 0.6042\n",
            "Epoch 482/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.5406 - acc: 0.7251 - val_loss: 0.6979 - val_acc: 0.6146\n",
            "Epoch 483/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.4970 - acc: 0.7543 - val_loss: 0.7129 - val_acc: 0.6042\n",
            "Epoch 484/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.4979 - acc: 0.7405 - val_loss: 0.7102 - val_acc: 0.6042\n",
            "Epoch 485/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.5660 - acc: 0.7079 - val_loss: 0.6835 - val_acc: 0.6458\n",
            "Epoch 486/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.4995 - acc: 0.7474 - val_loss: 0.7052 - val_acc: 0.6250\n",
            "Epoch 487/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5263 - acc: 0.7388 - val_loss: 0.7042 - val_acc: 0.6354\n",
            "Epoch 488/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.5126 - acc: 0.7371 - val_loss: 0.7038 - val_acc: 0.6146\n",
            "Epoch 489/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.5275 - acc: 0.7079 - val_loss: 0.6933 - val_acc: 0.6250\n",
            "Epoch 490/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.4962 - acc: 0.7457 - val_loss: 0.6829 - val_acc: 0.6250\n",
            "Epoch 491/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.5265 - acc: 0.7337 - val_loss: 0.6765 - val_acc: 0.6458\n",
            "Epoch 492/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.5325 - acc: 0.7371 - val_loss: 0.6703 - val_acc: 0.6354\n",
            "Epoch 493/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.5222 - acc: 0.7612 - val_loss: 0.6881 - val_acc: 0.6250\n",
            "Epoch 494/1000\n",
            "37/37 [==============================] - 10s 251ms/step - loss: 0.5163 - acc: 0.7595 - val_loss: 0.6878 - val_acc: 0.6146\n",
            "Epoch 495/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5185 - acc: 0.7612 - val_loss: 0.6814 - val_acc: 0.6250\n",
            "Epoch 496/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5005 - acc: 0.7457 - val_loss: 0.7055 - val_acc: 0.6146\n",
            "Epoch 497/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.5478 - acc: 0.7354 - val_loss: 0.6830 - val_acc: 0.6458\n",
            "Epoch 498/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5339 - acc: 0.7045 - val_loss: 0.6640 - val_acc: 0.6458\n",
            "Epoch 499/1000\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.5081 - acc: 0.7405 - val_loss: 0.6763 - val_acc: 0.6146\n",
            "Epoch 500/1000\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.5268 - acc: 0.7268 - val_loss: 0.6910 - val_acc: 0.6042\n",
            "Epoch 501/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.5243 - acc: 0.7423 - val_loss: 0.6907 - val_acc: 0.6146\n",
            "Epoch 502/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5410 - acc: 0.7474 - val_loss: 0.6952 - val_acc: 0.6458\n",
            "Epoch 503/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.5619 - acc: 0.7302 - val_loss: 0.6903 - val_acc: 0.6146\n",
            "Epoch 504/1000\n",
            "37/37 [==============================] - 9s 217ms/step - loss: 0.5551 - acc: 0.7096 - val_loss: 0.6787 - val_acc: 0.5938\n",
            "Epoch 505/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.5383 - acc: 0.7320 - val_loss: 0.6957 - val_acc: 0.6146\n",
            "Epoch 506/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5064 - acc: 0.7388 - val_loss: 0.6837 - val_acc: 0.6146\n",
            "Epoch 507/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5240 - acc: 0.7268 - val_loss: 0.6802 - val_acc: 0.6458\n",
            "Epoch 508/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.5124 - acc: 0.7526 - val_loss: 0.6750 - val_acc: 0.6146\n",
            "Epoch 509/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.5183 - acc: 0.7337 - val_loss: 0.6791 - val_acc: 0.6250\n",
            "Epoch 510/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.5179 - acc: 0.7405 - val_loss: 0.6785 - val_acc: 0.6354\n",
            "Epoch 511/1000\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.5073 - acc: 0.7680 - val_loss: 0.6696 - val_acc: 0.6667\n",
            "Epoch 512/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5143 - acc: 0.7405 - val_loss: 0.6745 - val_acc: 0.6250\n",
            "Epoch 513/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5126 - acc: 0.7440 - val_loss: 0.6780 - val_acc: 0.6354\n",
            "Epoch 514/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5253 - acc: 0.7388 - val_loss: 0.6961 - val_acc: 0.6146\n",
            "Epoch 515/1000\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 0.5074 - acc: 0.7491 - val_loss: 0.6640 - val_acc: 0.6458\n",
            "Epoch 516/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5458 - acc: 0.7285 - val_loss: 0.6787 - val_acc: 0.6146\n",
            "Epoch 517/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5052 - acc: 0.7440 - val_loss: 0.6788 - val_acc: 0.6250\n",
            "Epoch 518/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5207 - acc: 0.7371 - val_loss: 0.6827 - val_acc: 0.6354\n",
            "Epoch 519/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5045 - acc: 0.7543 - val_loss: 0.6674 - val_acc: 0.6250\n",
            "Epoch 520/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5273 - acc: 0.7423 - val_loss: 0.6719 - val_acc: 0.6250\n",
            "Epoch 521/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.4997 - acc: 0.7612 - val_loss: 0.6704 - val_acc: 0.6354\n",
            "Epoch 522/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5339 - acc: 0.7216 - val_loss: 0.6572 - val_acc: 0.6458\n",
            "Epoch 523/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.4868 - acc: 0.7320 - val_loss: 0.6733 - val_acc: 0.6250\n",
            "Epoch 524/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5295 - acc: 0.7509 - val_loss: 0.6770 - val_acc: 0.6042\n",
            "Epoch 525/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5339 - acc: 0.7337 - val_loss: 0.6940 - val_acc: 0.6042\n",
            "Epoch 526/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5177 - acc: 0.7354 - val_loss: 0.6632 - val_acc: 0.6250\n",
            "Epoch 527/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.5086 - acc: 0.7457 - val_loss: 0.6760 - val_acc: 0.6250\n",
            "Epoch 528/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.5254 - acc: 0.7457 - val_loss: 0.7038 - val_acc: 0.6146\n",
            "Epoch 529/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5046 - acc: 0.7354 - val_loss: 0.6994 - val_acc: 0.5938\n",
            "Epoch 530/1000\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.5296 - acc: 0.7354 - val_loss: 0.6825 - val_acc: 0.6042\n",
            "Epoch 531/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.5018 - acc: 0.7337 - val_loss: 0.6795 - val_acc: 0.5833\n",
            "Epoch 532/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5064 - acc: 0.7405 - val_loss: 0.6854 - val_acc: 0.6042\n",
            "Epoch 533/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.4828 - acc: 0.7509 - val_loss: 0.6703 - val_acc: 0.6458\n",
            "Epoch 534/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.5421 - acc: 0.7337 - val_loss: 0.6815 - val_acc: 0.6042\n",
            "Epoch 535/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.5074 - acc: 0.7457 - val_loss: 0.6738 - val_acc: 0.6146\n",
            "Epoch 536/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.4851 - acc: 0.7766 - val_loss: 0.6684 - val_acc: 0.6458\n",
            "Epoch 537/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.5172 - acc: 0.7405 - val_loss: 0.6812 - val_acc: 0.6458\n",
            "Epoch 538/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5154 - acc: 0.7483 - val_loss: 0.6926 - val_acc: 0.6146\n",
            "Epoch 539/1000\n",
            "37/37 [==============================] - 5s 117ms/step - loss: 0.5255 - acc: 0.7491 - val_loss: 0.6764 - val_acc: 0.6458\n",
            "Epoch 540/1000\n",
            "37/37 [==============================] - 3s 84ms/step - loss: 0.5271 - acc: 0.7509 - val_loss: 0.6955 - val_acc: 0.6146\n",
            "Epoch 541/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5168 - acc: 0.7491 - val_loss: 0.6780 - val_acc: 0.6146\n",
            "Epoch 542/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5139 - acc: 0.7405 - val_loss: 0.6772 - val_acc: 0.6354\n",
            "Epoch 543/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.4932 - acc: 0.7646 - val_loss: 0.6672 - val_acc: 0.6146\n",
            "Epoch 544/1000\n",
            "37/37 [==============================] - 9s 214ms/step - loss: 0.5149 - acc: 0.7491 - val_loss: 0.6724 - val_acc: 0.6562\n",
            "Epoch 545/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.5461 - acc: 0.7268 - val_loss: 0.6653 - val_acc: 0.6458\n",
            "Epoch 546/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5197 - acc: 0.7268 - val_loss: 0.6800 - val_acc: 0.6146\n",
            "Epoch 547/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5201 - acc: 0.7440 - val_loss: 0.6602 - val_acc: 0.6146\n",
            "Epoch 548/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5314 - acc: 0.7337 - val_loss: 0.6750 - val_acc: 0.5729\n",
            "Epoch 549/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5514 - acc: 0.7371 - val_loss: 0.6781 - val_acc: 0.6146\n",
            "Epoch 550/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.4887 - acc: 0.7749 - val_loss: 0.6644 - val_acc: 0.6250\n",
            "Epoch 551/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.5291 - acc: 0.7474 - val_loss: 0.6446 - val_acc: 0.6562\n",
            "Epoch 552/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.5023 - acc: 0.7560 - val_loss: 0.6803 - val_acc: 0.6250\n",
            "Epoch 553/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.5224 - acc: 0.7405 - val_loss: 0.6802 - val_acc: 0.6250\n",
            "Epoch 554/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5482 - acc: 0.7096 - val_loss: 0.6675 - val_acc: 0.6250\n",
            "Epoch 555/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.5131 - acc: 0.7474 - val_loss: 0.6859 - val_acc: 0.6250\n",
            "Epoch 556/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.4912 - acc: 0.7852 - val_loss: 0.6695 - val_acc: 0.6458\n",
            "Epoch 557/1000\n",
            "37/37 [==============================] - 5s 116ms/step - loss: 0.5238 - acc: 0.7165 - val_loss: 0.6774 - val_acc: 0.6458\n",
            "Epoch 558/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5217 - acc: 0.7509 - val_loss: 0.6729 - val_acc: 0.6458\n",
            "Epoch 559/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5109 - acc: 0.7543 - val_loss: 0.6739 - val_acc: 0.6458\n",
            "Epoch 560/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5216 - acc: 0.7320 - val_loss: 0.7024 - val_acc: 0.6354\n",
            "Epoch 561/1000\n",
            "37/37 [==============================] - 9s 220ms/step - loss: 0.5228 - acc: 0.7457 - val_loss: 0.6826 - val_acc: 0.6562\n",
            "Epoch 562/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5354 - acc: 0.7302 - val_loss: 0.6800 - val_acc: 0.6250\n",
            "Epoch 563/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.4976 - acc: 0.7577 - val_loss: 0.6859 - val_acc: 0.6250\n",
            "Epoch 564/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.5174 - acc: 0.7423 - val_loss: 0.6694 - val_acc: 0.6458\n",
            "Epoch 565/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5290 - acc: 0.7285 - val_loss: 0.6685 - val_acc: 0.6458\n",
            "Epoch 566/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5462 - acc: 0.7216 - val_loss: 0.6636 - val_acc: 0.6250\n",
            "Epoch 567/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.5248 - acc: 0.7234 - val_loss: 0.6731 - val_acc: 0.6146\n",
            "Epoch 568/1000\n",
            "37/37 [==============================] - 5s 108ms/step - loss: 0.5106 - acc: 0.7595 - val_loss: 0.6740 - val_acc: 0.6354\n",
            "Epoch 569/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.5333 - acc: 0.7388 - val_loss: 0.6619 - val_acc: 0.6250\n",
            "Epoch 570/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.5264 - acc: 0.7423 - val_loss: 0.6684 - val_acc: 0.6354\n",
            "Epoch 571/1000\n",
            "37/37 [==============================] - 6s 146ms/step - loss: 0.4861 - acc: 0.7543 - val_loss: 0.6744 - val_acc: 0.6250\n",
            "Epoch 572/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.5275 - acc: 0.7234 - val_loss: 0.6608 - val_acc: 0.6250\n",
            "Epoch 573/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.4988 - acc: 0.7474 - val_loss: 0.6695 - val_acc: 0.5833\n",
            "Epoch 574/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5339 - acc: 0.7251 - val_loss: 0.6523 - val_acc: 0.6354\n",
            "Epoch 575/1000\n",
            "37/37 [==============================] - 4s 82ms/step - loss: 0.5159 - acc: 0.7440 - val_loss: 0.6575 - val_acc: 0.6562\n",
            "Epoch 576/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.4898 - acc: 0.7629 - val_loss: 0.6752 - val_acc: 0.5833\n",
            "Epoch 577/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.5103 - acc: 0.7405 - val_loss: 0.6673 - val_acc: 0.6042\n",
            "Epoch 578/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5007 - acc: 0.7612 - val_loss: 0.6739 - val_acc: 0.6250\n",
            "Epoch 579/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.4868 - acc: 0.7577 - val_loss: 0.6643 - val_acc: 0.6042\n",
            "Epoch 580/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5263 - acc: 0.7148 - val_loss: 0.6680 - val_acc: 0.6146\n",
            "Epoch 581/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.5186 - acc: 0.7234 - val_loss: 0.6723 - val_acc: 0.6042\n",
            "Epoch 582/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5248 - acc: 0.7268 - val_loss: 0.6570 - val_acc: 0.6354\n",
            "Epoch 583/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5326 - acc: 0.7405 - val_loss: 0.6647 - val_acc: 0.6354\n",
            "Epoch 584/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.4861 - acc: 0.7491 - val_loss: 0.6809 - val_acc: 0.6146\n",
            "Epoch 585/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.5110 - acc: 0.7612 - val_loss: 0.6648 - val_acc: 0.6250\n",
            "Epoch 586/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.4901 - acc: 0.7612 - val_loss: 0.6563 - val_acc: 0.6250\n",
            "Epoch 587/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.5028 - acc: 0.7491 - val_loss: 0.6780 - val_acc: 0.6146\n",
            "Epoch 588/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.4674 - acc: 0.7715 - val_loss: 0.6468 - val_acc: 0.6250\n",
            "Epoch 589/1000\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.5156 - acc: 0.7457 - val_loss: 0.6645 - val_acc: 0.6250\n",
            "Epoch 590/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5283 - acc: 0.7297 - val_loss: 0.6775 - val_acc: 0.6042\n",
            "Epoch 591/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.5511 - acc: 0.7079 - val_loss: 0.6667 - val_acc: 0.6146\n",
            "Epoch 592/1000\n",
            "37/37 [==============================] - 9s 215ms/step - loss: 0.4989 - acc: 0.7491 - val_loss: 0.6851 - val_acc: 0.6042\n",
            "Epoch 593/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.5023 - acc: 0.7491 - val_loss: 0.6668 - val_acc: 0.6250\n",
            "Epoch 594/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5097 - acc: 0.7491 - val_loss: 0.6589 - val_acc: 0.6250\n",
            "Epoch 595/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5088 - acc: 0.7543 - val_loss: 0.6761 - val_acc: 0.6146\n",
            "Epoch 596/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.5443 - acc: 0.7285 - val_loss: 0.6697 - val_acc: 0.6250\n",
            "Epoch 597/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5091 - acc: 0.7543 - val_loss: 0.6637 - val_acc: 0.6146\n",
            "Epoch 598/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5294 - acc: 0.7423 - val_loss: 0.6656 - val_acc: 0.6562\n",
            "Epoch 599/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5376 - acc: 0.7216 - val_loss: 0.6721 - val_acc: 0.6354\n",
            "Epoch 600/1000\n",
            "37/37 [==============================] - 6s 139ms/step - loss: 0.5254 - acc: 0.7354 - val_loss: 0.6821 - val_acc: 0.6146\n",
            "Epoch 601/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.4880 - acc: 0.7646 - val_loss: 0.6744 - val_acc: 0.6250\n",
            "Epoch 602/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.4959 - acc: 0.7371 - val_loss: 0.6634 - val_acc: 0.6146\n",
            "Epoch 603/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5479 - acc: 0.7113 - val_loss: 0.6501 - val_acc: 0.6250\n",
            "Epoch 604/1000\n",
            "37/37 [==============================] - 4s 82ms/step - loss: 0.5680 - acc: 0.7045 - val_loss: 0.6552 - val_acc: 0.6354\n",
            "Epoch 605/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.4937 - acc: 0.7577 - val_loss: 0.6659 - val_acc: 0.6250\n",
            "Epoch 606/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.5093 - acc: 0.7560 - val_loss: 0.6580 - val_acc: 0.6250\n",
            "Epoch 607/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.4921 - acc: 0.7766 - val_loss: 0.6598 - val_acc: 0.6458\n",
            "Epoch 608/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5306 - acc: 0.7148 - val_loss: 0.6594 - val_acc: 0.6354\n",
            "Epoch 609/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5031 - acc: 0.7302 - val_loss: 0.6823 - val_acc: 0.6354\n",
            "Epoch 610/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5343 - acc: 0.7268 - val_loss: 0.6741 - val_acc: 0.6042\n",
            "Epoch 611/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.5205 - acc: 0.7491 - val_loss: 0.6729 - val_acc: 0.6250\n",
            "Epoch 612/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.4929 - acc: 0.7560 - val_loss: 0.6594 - val_acc: 0.6250\n",
            "Epoch 613/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5141 - acc: 0.7491 - val_loss: 0.6641 - val_acc: 0.6042\n",
            "Epoch 614/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.4913 - acc: 0.7491 - val_loss: 0.6649 - val_acc: 0.6042\n",
            "Epoch 615/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5229 - acc: 0.7509 - val_loss: 0.6757 - val_acc: 0.6250\n",
            "Epoch 616/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.5270 - acc: 0.7491 - val_loss: 0.6670 - val_acc: 0.6458\n",
            "Epoch 617/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.5360 - acc: 0.7113 - val_loss: 0.6653 - val_acc: 0.6042\n",
            "Epoch 618/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.5177 - acc: 0.7405 - val_loss: 0.6588 - val_acc: 0.6354\n",
            "Epoch 619/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5274 - acc: 0.7474 - val_loss: 0.6645 - val_acc: 0.6354\n",
            "Epoch 620/1000\n",
            "37/37 [==============================] - 9s 219ms/step - loss: 0.5029 - acc: 0.7543 - val_loss: 0.6679 - val_acc: 0.6042\n",
            "Epoch 621/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5069 - acc: 0.7509 - val_loss: 0.6540 - val_acc: 0.6562\n",
            "Epoch 622/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5265 - acc: 0.7423 - val_loss: 0.6667 - val_acc: 0.6354\n",
            "Epoch 623/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.4913 - acc: 0.7457 - val_loss: 0.6706 - val_acc: 0.6562\n",
            "Epoch 624/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.5058 - acc: 0.7560 - val_loss: 0.6771 - val_acc: 0.6250\n",
            "Epoch 625/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.5712 - acc: 0.6907 - val_loss: 0.6675 - val_acc: 0.6354\n",
            "Epoch 626/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5304 - acc: 0.7491 - val_loss: 0.6802 - val_acc: 0.6146\n",
            "Epoch 627/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.5142 - acc: 0.7474 - val_loss: 0.6451 - val_acc: 0.6354\n",
            "Epoch 628/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5141 - acc: 0.7474 - val_loss: 0.6501 - val_acc: 0.6250\n",
            "Epoch 629/1000\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.5236 - acc: 0.7388 - val_loss: 0.6735 - val_acc: 0.6146\n",
            "Epoch 630/1000\n",
            "37/37 [==============================] - 9s 219ms/step - loss: 0.4949 - acc: 0.7491 - val_loss: 0.6804 - val_acc: 0.6042\n",
            "Epoch 631/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.4787 - acc: 0.7629 - val_loss: 0.6612 - val_acc: 0.6250\n",
            "Epoch 632/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.5126 - acc: 0.7526 - val_loss: 0.6731 - val_acc: 0.6458\n",
            "Epoch 633/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.5406 - acc: 0.7371 - val_loss: 0.6593 - val_acc: 0.6250\n",
            "Epoch 634/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5313 - acc: 0.7440 - val_loss: 0.6544 - val_acc: 0.6146\n",
            "Epoch 635/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.5174 - acc: 0.7182 - val_loss: 0.6562 - val_acc: 0.6354\n",
            "Epoch 636/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.5203 - acc: 0.7320 - val_loss: 0.6670 - val_acc: 0.6354\n",
            "Epoch 637/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5311 - acc: 0.7440 - val_loss: 0.6648 - val_acc: 0.6250\n",
            "Epoch 638/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.5163 - acc: 0.7337 - val_loss: 0.6417 - val_acc: 0.6354\n",
            "Epoch 639/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5199 - acc: 0.7423 - val_loss: 0.6423 - val_acc: 0.6250\n",
            "Epoch 640/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5149 - acc: 0.7577 - val_loss: 0.6591 - val_acc: 0.6146\n",
            "Epoch 641/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.5280 - acc: 0.7337 - val_loss: 0.6744 - val_acc: 0.6146\n",
            "Epoch 642/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5666 - acc: 0.7182 - val_loss: 0.6626 - val_acc: 0.6042\n",
            "Epoch 643/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5035 - acc: 0.7423 - val_loss: 0.6637 - val_acc: 0.6250\n",
            "Epoch 644/1000\n",
            "37/37 [==============================] - 3s 83ms/step - loss: 0.5677 - acc: 0.7079 - val_loss: 0.6760 - val_acc: 0.6146\n",
            "Epoch 645/1000\n",
            "37/37 [==============================] - 10s 243ms/step - loss: 0.5024 - acc: 0.7371 - val_loss: 0.6840 - val_acc: 0.6250\n",
            "Epoch 646/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.5166 - acc: 0.7302 - val_loss: 0.6761 - val_acc: 0.6146\n",
            "Epoch 647/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.4903 - acc: 0.7629 - val_loss: 0.6659 - val_acc: 0.6250\n",
            "Epoch 648/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5534 - acc: 0.7165 - val_loss: 0.6627 - val_acc: 0.6458\n",
            "Epoch 649/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5255 - acc: 0.7251 - val_loss: 0.6669 - val_acc: 0.6250\n",
            "Epoch 650/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5067 - acc: 0.7560 - val_loss: 0.6517 - val_acc: 0.6146\n",
            "Epoch 651/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.5123 - acc: 0.7491 - val_loss: 0.6431 - val_acc: 0.6354\n",
            "Epoch 652/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5062 - acc: 0.7405 - val_loss: 0.6553 - val_acc: 0.6562\n",
            "Epoch 653/1000\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.4993 - acc: 0.7526 - val_loss: 0.6596 - val_acc: 0.6354\n",
            "Epoch 654/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5093 - acc: 0.7440 - val_loss: 0.6587 - val_acc: 0.6458\n",
            "Epoch 655/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5289 - acc: 0.7405 - val_loss: 0.6708 - val_acc: 0.6146\n",
            "Epoch 656/1000\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 0.4836 - acc: 0.7715 - val_loss: 0.6516 - val_acc: 0.6146\n",
            "Epoch 657/1000\n",
            "37/37 [==============================] - 5s 114ms/step - loss: 0.5552 - acc: 0.7182 - val_loss: 0.6540 - val_acc: 0.5938\n",
            "Epoch 658/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5423 - acc: 0.7230 - val_loss: 0.6593 - val_acc: 0.6042\n",
            "Epoch 659/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5327 - acc: 0.7165 - val_loss: 0.6635 - val_acc: 0.6250\n",
            "Epoch 660/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.5050 - acc: 0.7577 - val_loss: 0.6539 - val_acc: 0.6458\n",
            "Epoch 661/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5088 - acc: 0.7595 - val_loss: 0.6589 - val_acc: 0.6146\n",
            "Epoch 662/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.5144 - acc: 0.7526 - val_loss: 0.6527 - val_acc: 0.6250\n",
            "Epoch 663/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5454 - acc: 0.7251 - val_loss: 0.6657 - val_acc: 0.6250\n",
            "Epoch 664/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5258 - acc: 0.7337 - val_loss: 0.6491 - val_acc: 0.6458\n",
            "Epoch 665/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5259 - acc: 0.7302 - val_loss: 0.6453 - val_acc: 0.6458\n",
            "Epoch 666/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5098 - acc: 0.7405 - val_loss: 0.6404 - val_acc: 0.6354\n",
            "Epoch 667/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.4960 - acc: 0.7577 - val_loss: 0.6625 - val_acc: 0.6354\n",
            "Epoch 668/1000\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 0.5176 - acc: 0.7474 - val_loss: 0.6582 - val_acc: 0.6458\n",
            "Epoch 669/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5074 - acc: 0.7577 - val_loss: 0.6600 - val_acc: 0.6042\n",
            "Epoch 670/1000\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.5132 - acc: 0.7526 - val_loss: 0.6608 - val_acc: 0.6042\n",
            "Epoch 671/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.5264 - acc: 0.7509 - val_loss: 0.6560 - val_acc: 0.6250\n",
            "Epoch 672/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.5061 - acc: 0.7577 - val_loss: 0.6596 - val_acc: 0.6146\n",
            "Epoch 673/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.4905 - acc: 0.7526 - val_loss: 0.6491 - val_acc: 0.6250\n",
            "Epoch 674/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5412 - acc: 0.7234 - val_loss: 0.6556 - val_acc: 0.6354\n",
            "Epoch 675/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.5235 - acc: 0.7440 - val_loss: 0.6675 - val_acc: 0.6354\n",
            "Epoch 676/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.4976 - acc: 0.7560 - val_loss: 0.6782 - val_acc: 0.6146\n",
            "Epoch 677/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5198 - acc: 0.7371 - val_loss: 0.6636 - val_acc: 0.6354\n",
            "Epoch 678/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5169 - acc: 0.7457 - val_loss: 0.6670 - val_acc: 0.6250\n",
            "Epoch 679/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5120 - acc: 0.7509 - val_loss: 0.6574 - val_acc: 0.6250\n",
            "Epoch 680/1000\n",
            "37/37 [==============================] - 3s 84ms/step - loss: 0.5199 - acc: 0.7371 - val_loss: 0.6658 - val_acc: 0.6458\n",
            "Epoch 681/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.5315 - acc: 0.7216 - val_loss: 0.6553 - val_acc: 0.6562\n",
            "Epoch 682/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5011 - acc: 0.7560 - val_loss: 0.6699 - val_acc: 0.6354\n",
            "Epoch 683/1000\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 0.5419 - acc: 0.7388 - val_loss: 0.6570 - val_acc: 0.6250\n",
            "Epoch 684/1000\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.5152 - acc: 0.7354 - val_loss: 0.6559 - val_acc: 0.6354\n",
            "Epoch 685/1000\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 0.5019 - acc: 0.7491 - val_loss: 0.6553 - val_acc: 0.6354\n",
            "Epoch 686/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5298 - acc: 0.7165 - val_loss: 0.6695 - val_acc: 0.5938\n",
            "Epoch 687/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.5089 - acc: 0.7474 - val_loss: 0.6784 - val_acc: 0.6354\n",
            "Epoch 688/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.5215 - acc: 0.7302 - val_loss: 0.6683 - val_acc: 0.6250\n",
            "Epoch 689/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5132 - acc: 0.7543 - val_loss: 0.6828 - val_acc: 0.6354\n",
            "Epoch 690/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5168 - acc: 0.7577 - val_loss: 0.6742 - val_acc: 0.6458\n",
            "Epoch 691/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.4923 - acc: 0.7612 - val_loss: 0.6550 - val_acc: 0.6458\n",
            "Epoch 692/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.5465 - acc: 0.7405 - val_loss: 0.6644 - val_acc: 0.6146\n",
            "Epoch 693/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.5360 - acc: 0.7354 - val_loss: 0.6784 - val_acc: 0.6250\n",
            "Epoch 694/1000\n",
            "37/37 [==============================] - 5s 110ms/step - loss: 0.4951 - acc: 0.7457 - val_loss: 0.6769 - val_acc: 0.6250\n",
            "Epoch 695/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5282 - acc: 0.7354 - val_loss: 0.6766 - val_acc: 0.6354\n",
            "Epoch 696/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5202 - acc: 0.7251 - val_loss: 0.6731 - val_acc: 0.6354\n",
            "Epoch 697/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5057 - acc: 0.7736 - val_loss: 0.6797 - val_acc: 0.6667\n",
            "Epoch 698/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.5514 - acc: 0.7285 - val_loss: 0.6719 - val_acc: 0.6458\n",
            "Epoch 699/1000\n",
            "37/37 [==============================] - 9s 243ms/step - loss: 0.4996 - acc: 0.7629 - val_loss: 0.6857 - val_acc: 0.6458\n",
            "Epoch 700/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5397 - acc: 0.7337 - val_loss: 0.6943 - val_acc: 0.6458\n",
            "Epoch 701/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.4821 - acc: 0.7509 - val_loss: 0.6873 - val_acc: 0.6250\n",
            "Epoch 702/1000\n",
            "37/37 [==============================] - 9s 217ms/step - loss: 0.5541 - acc: 0.7354 - val_loss: 0.6822 - val_acc: 0.6562\n",
            "Epoch 703/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5181 - acc: 0.7560 - val_loss: 0.6859 - val_acc: 0.6562\n",
            "Epoch 704/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.5484 - acc: 0.7560 - val_loss: 0.7065 - val_acc: 0.6458\n",
            "Epoch 705/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.4880 - acc: 0.7663 - val_loss: 0.6947 - val_acc: 0.6250\n",
            "Epoch 706/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5194 - acc: 0.7423 - val_loss: 0.6646 - val_acc: 0.6458\n",
            "Epoch 707/1000\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 0.5179 - acc: 0.7423 - val_loss: 0.6646 - val_acc: 0.6562\n",
            "Epoch 708/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.4808 - acc: 0.7612 - val_loss: 0.6752 - val_acc: 0.6250\n",
            "Epoch 709/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5437 - acc: 0.7268 - val_loss: 0.6816 - val_acc: 0.6146\n",
            "Epoch 710/1000\n",
            "37/37 [==============================] - 9s 220ms/step - loss: 0.5164 - acc: 0.7612 - val_loss: 0.6693 - val_acc: 0.6458\n",
            "Epoch 711/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5018 - acc: 0.7509 - val_loss: 0.6784 - val_acc: 0.6354\n",
            "Epoch 712/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5218 - acc: 0.7320 - val_loss: 0.6925 - val_acc: 0.6250\n",
            "Epoch 713/1000\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 0.5294 - acc: 0.7182 - val_loss: 0.6982 - val_acc: 0.6146\n",
            "Epoch 714/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.4811 - acc: 0.7818 - val_loss: 0.6868 - val_acc: 0.6146\n",
            "Epoch 715/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.5264 - acc: 0.7509 - val_loss: 0.6772 - val_acc: 0.6354\n",
            "Epoch 716/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5059 - acc: 0.7749 - val_loss: 0.6885 - val_acc: 0.6354\n",
            "Epoch 717/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.5253 - acc: 0.7216 - val_loss: 0.6833 - val_acc: 0.6146\n",
            "Epoch 718/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5320 - acc: 0.7320 - val_loss: 0.6726 - val_acc: 0.6354\n",
            "Epoch 719/1000\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.4985 - acc: 0.7612 - val_loss: 0.6795 - val_acc: 0.6146\n",
            "Epoch 720/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5090 - acc: 0.7285 - val_loss: 0.6836 - val_acc: 0.6146\n",
            "Epoch 721/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.5143 - acc: 0.7388 - val_loss: 0.6827 - val_acc: 0.6146\n",
            "Epoch 722/1000\n",
            "37/37 [==============================] - 6s 145ms/step - loss: 0.4978 - acc: 0.7618 - val_loss: 0.6731 - val_acc: 0.6250\n",
            "Epoch 723/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.5143 - acc: 0.7577 - val_loss: 0.6702 - val_acc: 0.6354\n",
            "Epoch 724/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.5336 - acc: 0.7595 - val_loss: 0.6758 - val_acc: 0.6354\n",
            "Epoch 725/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5263 - acc: 0.7491 - val_loss: 0.6707 - val_acc: 0.6146\n",
            "Epoch 726/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.5124 - acc: 0.7457 - val_loss: 0.6759 - val_acc: 0.6250\n",
            "Epoch 727/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.4958 - acc: 0.7680 - val_loss: 0.6812 - val_acc: 0.6146\n",
            "Epoch 728/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5044 - acc: 0.7646 - val_loss: 0.6666 - val_acc: 0.6250\n",
            "Epoch 729/1000\n",
            "37/37 [==============================] - 9s 216ms/step - loss: 0.5046 - acc: 0.7423 - val_loss: 0.6386 - val_acc: 0.6562\n",
            "Epoch 730/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.5025 - acc: 0.7543 - val_loss: 0.6718 - val_acc: 0.6250\n",
            "Epoch 731/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5169 - acc: 0.7165 - val_loss: 0.6618 - val_acc: 0.6562\n",
            "Epoch 732/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.5441 - acc: 0.7062 - val_loss: 0.6877 - val_acc: 0.6146\n",
            "Epoch 733/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5040 - acc: 0.7646 - val_loss: 0.6833 - val_acc: 0.5625\n",
            "Epoch 734/1000\n",
            "37/37 [==============================] - 5s 105ms/step - loss: 0.4980 - acc: 0.7646 - val_loss: 0.6753 - val_acc: 0.5729\n",
            "Epoch 735/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.5485 - acc: 0.7148 - val_loss: 0.6851 - val_acc: 0.6042\n",
            "Epoch 736/1000\n",
            "37/37 [==============================] - 10s 251ms/step - loss: 0.5083 - acc: 0.7388 - val_loss: 0.6944 - val_acc: 0.6042\n",
            "Epoch 737/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.5096 - acc: 0.7646 - val_loss: 0.6926 - val_acc: 0.6146\n",
            "Epoch 738/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.5148 - acc: 0.7405 - val_loss: 0.6869 - val_acc: 0.6042\n",
            "Epoch 739/1000\n",
            "37/37 [==============================] - 9s 242ms/step - loss: 0.5020 - acc: 0.7348 - val_loss: 0.6667 - val_acc: 0.6354\n",
            "Epoch 740/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.4871 - acc: 0.7595 - val_loss: 0.6732 - val_acc: 0.5833\n",
            "Epoch 741/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5373 - acc: 0.7285 - val_loss: 0.6685 - val_acc: 0.6354\n",
            "Epoch 742/1000\n",
            "37/37 [==============================] - 4s 80ms/step - loss: 0.5065 - acc: 0.7457 - val_loss: 0.6709 - val_acc: 0.6146\n",
            "Epoch 743/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.5732 - acc: 0.7165 - val_loss: 0.6589 - val_acc: 0.5938\n",
            "Epoch 744/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.5347 - acc: 0.7405 - val_loss: 0.6641 - val_acc: 0.6354\n",
            "Epoch 745/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.5332 - acc: 0.7560 - val_loss: 0.6815 - val_acc: 0.6250\n",
            "Epoch 746/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.5565 - acc: 0.7251 - val_loss: 0.6872 - val_acc: 0.6250\n",
            "Epoch 747/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.4980 - acc: 0.7784 - val_loss: 0.6781 - val_acc: 0.6458\n",
            "Epoch 748/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5305 - acc: 0.7388 - val_loss: 0.6948 - val_acc: 0.6354\n",
            "Epoch 749/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5025 - acc: 0.7612 - val_loss: 0.6906 - val_acc: 0.6250\n",
            "Epoch 750/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5097 - acc: 0.7457 - val_loss: 0.6801 - val_acc: 0.6250\n",
            "Epoch 751/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.5028 - acc: 0.7595 - val_loss: 0.6758 - val_acc: 0.6042\n",
            "Epoch 752/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5010 - acc: 0.7509 - val_loss: 0.6824 - val_acc: 0.6250\n",
            "Epoch 753/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.4925 - acc: 0.7663 - val_loss: 0.7029 - val_acc: 0.6250\n",
            "Epoch 754/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5161 - acc: 0.7388 - val_loss: 0.6850 - val_acc: 0.6354\n",
            "Epoch 755/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.5507 - acc: 0.7182 - val_loss: 0.6803 - val_acc: 0.6354\n",
            "Epoch 756/1000\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 0.5050 - acc: 0.7354 - val_loss: 0.6702 - val_acc: 0.6562\n",
            "Epoch 757/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5342 - acc: 0.7595 - val_loss: 0.6680 - val_acc: 0.6562\n",
            "Epoch 758/1000\n",
            "37/37 [==============================] - 9s 244ms/step - loss: 0.5276 - acc: 0.7234 - val_loss: 0.6708 - val_acc: 0.6354\n",
            "Epoch 759/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5309 - acc: 0.7320 - val_loss: 0.6767 - val_acc: 0.6458\n",
            "Epoch 760/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.4840 - acc: 0.7663 - val_loss: 0.6814 - val_acc: 0.6354\n",
            "Epoch 761/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.5235 - acc: 0.7491 - val_loss: 0.6816 - val_acc: 0.6250\n",
            "Epoch 762/1000\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.5381 - acc: 0.7096 - val_loss: 0.6614 - val_acc: 0.6354\n",
            "Epoch 763/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5501 - acc: 0.7216 - val_loss: 0.6865 - val_acc: 0.6146\n",
            "Epoch 764/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5071 - acc: 0.7801 - val_loss: 0.6600 - val_acc: 0.6458\n",
            "Epoch 765/1000\n",
            "37/37 [==============================] - 9s 219ms/step - loss: 0.4964 - acc: 0.7577 - val_loss: 0.6734 - val_acc: 0.6146\n",
            "Epoch 766/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5002 - acc: 0.7423 - val_loss: 0.6779 - val_acc: 0.6458\n",
            "Epoch 767/1000\n",
            "37/37 [==============================] - 9s 219ms/step - loss: 0.5342 - acc: 0.7337 - val_loss: 0.6653 - val_acc: 0.6042\n",
            "Epoch 768/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.5151 - acc: 0.7680 - val_loss: 0.6549 - val_acc: 0.6354\n",
            "Epoch 769/1000\n",
            "37/37 [==============================] - 4s 109ms/step - loss: 0.5159 - acc: 0.7551 - val_loss: 0.6582 - val_acc: 0.6042\n",
            "Epoch 770/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5118 - acc: 0.7388 - val_loss: 0.6742 - val_acc: 0.6146\n",
            "Epoch 771/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5131 - acc: 0.7354 - val_loss: 0.6849 - val_acc: 0.6250\n",
            "Epoch 772/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.5120 - acc: 0.7560 - val_loss: 0.6781 - val_acc: 0.6146\n",
            "Epoch 773/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.4963 - acc: 0.7543 - val_loss: 0.6722 - val_acc: 0.6354\n",
            "Epoch 774/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.5681 - acc: 0.7062 - val_loss: 0.6668 - val_acc: 0.6354\n",
            "Epoch 775/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.5031 - acc: 0.7354 - val_loss: 0.6816 - val_acc: 0.6250\n",
            "Epoch 776/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5120 - acc: 0.7474 - val_loss: 0.6623 - val_acc: 0.6354\n",
            "Epoch 777/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5113 - acc: 0.7337 - val_loss: 0.6686 - val_acc: 0.6562\n",
            "Epoch 778/1000\n",
            "37/37 [==============================] - 9s 245ms/step - loss: 0.5469 - acc: 0.7251 - val_loss: 0.6941 - val_acc: 0.6458\n",
            "Epoch 779/1000\n",
            "37/37 [==============================] - 3s 84ms/step - loss: 0.5226 - acc: 0.7320 - val_loss: 0.6690 - val_acc: 0.6562\n",
            "Epoch 780/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.4946 - acc: 0.7440 - val_loss: 0.6939 - val_acc: 0.6354\n",
            "Epoch 781/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.4801 - acc: 0.7715 - val_loss: 0.6859 - val_acc: 0.6354\n",
            "Epoch 782/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.5417 - acc: 0.7337 - val_loss: 0.6855 - val_acc: 0.6458\n",
            "Epoch 783/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5158 - acc: 0.7096 - val_loss: 0.6938 - val_acc: 0.6146\n",
            "Epoch 784/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5273 - acc: 0.7199 - val_loss: 0.6864 - val_acc: 0.6562\n",
            "Epoch 785/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.4992 - acc: 0.7560 - val_loss: 0.6850 - val_acc: 0.6667\n",
            "Epoch 786/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5332 - acc: 0.7371 - val_loss: 0.6880 - val_acc: 0.6667\n",
            "Epoch 787/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.5434 - acc: 0.7096 - val_loss: 0.6992 - val_acc: 0.6250\n",
            "Epoch 788/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.4909 - acc: 0.7698 - val_loss: 0.6830 - val_acc: 0.6667\n",
            "Epoch 789/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.5033 - acc: 0.7560 - val_loss: 0.6821 - val_acc: 0.6667\n",
            "Epoch 790/1000\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 0.5071 - acc: 0.7405 - val_loss: 0.7092 - val_acc: 0.6250\n",
            "Epoch 791/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.5149 - acc: 0.7234 - val_loss: 0.6875 - val_acc: 0.6458\n",
            "Epoch 792/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.4709 - acc: 0.7698 - val_loss: 0.6779 - val_acc: 0.6354\n",
            "Epoch 793/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.5029 - acc: 0.7560 - val_loss: 0.6715 - val_acc: 0.6354\n",
            "Epoch 794/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.4879 - acc: 0.7474 - val_loss: 0.6825 - val_acc: 0.6354\n",
            "Epoch 795/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.4949 - acc: 0.7526 - val_loss: 0.6927 - val_acc: 0.6250\n",
            "Epoch 796/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5216 - acc: 0.7320 - val_loss: 0.6644 - val_acc: 0.6667\n",
            "Epoch 797/1000\n",
            "37/37 [==============================] - 5s 111ms/step - loss: 0.4892 - acc: 0.7663 - val_loss: 0.6762 - val_acc: 0.6667\n",
            "Epoch 798/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.4847 - acc: 0.7543 - val_loss: 0.6906 - val_acc: 0.6458\n",
            "Epoch 799/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.4537 - acc: 0.7818 - val_loss: 0.6993 - val_acc: 0.6146\n",
            "Epoch 800/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5279 - acc: 0.7474 - val_loss: 0.6730 - val_acc: 0.6250\n",
            "Epoch 801/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5016 - acc: 0.7543 - val_loss: 0.6853 - val_acc: 0.6458\n",
            "Epoch 802/1000\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 0.5266 - acc: 0.7388 - val_loss: 0.6902 - val_acc: 0.6562\n",
            "Epoch 803/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5563 - acc: 0.7251 - val_loss: 0.6807 - val_acc: 0.6562\n",
            "Epoch 804/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.5038 - acc: 0.7474 - val_loss: 0.6917 - val_acc: 0.6458\n",
            "Epoch 805/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.5062 - acc: 0.7526 - val_loss: 0.6758 - val_acc: 0.6458\n",
            "Epoch 806/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5302 - acc: 0.7440 - val_loss: 0.6782 - val_acc: 0.6250\n",
            "Epoch 807/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5153 - acc: 0.7354 - val_loss: 0.6766 - val_acc: 0.6354\n",
            "Epoch 808/1000\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 0.5319 - acc: 0.7302 - val_loss: 0.6723 - val_acc: 0.6354\n",
            "Epoch 809/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.5444 - acc: 0.7165 - val_loss: 0.6800 - val_acc: 0.6250\n",
            "Epoch 810/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.4732 - acc: 0.7766 - val_loss: 0.6657 - val_acc: 0.6458\n",
            "Epoch 811/1000\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.5507 - acc: 0.7182 - val_loss: 0.6712 - val_acc: 0.6354\n",
            "Epoch 812/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.4867 - acc: 0.7646 - val_loss: 0.6734 - val_acc: 0.6250\n",
            "Epoch 813/1000\n",
            "37/37 [==============================] - 9s 241ms/step - loss: 0.5035 - acc: 0.7509 - val_loss: 0.6726 - val_acc: 0.6146\n",
            "Epoch 814/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.4946 - acc: 0.7491 - val_loss: 0.6858 - val_acc: 0.6250\n",
            "Epoch 815/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5311 - acc: 0.7234 - val_loss: 0.6876 - val_acc: 0.6250\n",
            "Epoch 816/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5046 - acc: 0.7663 - val_loss: 0.6816 - val_acc: 0.6250\n",
            "Epoch 817/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5007 - acc: 0.7388 - val_loss: 0.6741 - val_acc: 0.6354\n",
            "Epoch 818/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.5038 - acc: 0.7491 - val_loss: 0.6624 - val_acc: 0.6458\n",
            "Epoch 819/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5006 - acc: 0.7457 - val_loss: 0.6856 - val_acc: 0.6354\n",
            "Epoch 820/1000\n",
            "37/37 [==============================] - 6s 154ms/step - loss: 0.5409 - acc: 0.7285 - val_loss: 0.6705 - val_acc: 0.6354\n",
            "Epoch 821/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.4853 - acc: 0.7784 - val_loss: 0.6743 - val_acc: 0.6354\n",
            "Epoch 822/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5068 - acc: 0.7526 - val_loss: 0.6736 - val_acc: 0.6458\n",
            "Epoch 823/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5029 - acc: 0.7784 - val_loss: 0.6776 - val_acc: 0.6458\n",
            "Epoch 824/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.4947 - acc: 0.7543 - val_loss: 0.6959 - val_acc: 0.6146\n",
            "Epoch 825/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.4921 - acc: 0.7543 - val_loss: 0.6778 - val_acc: 0.6354\n",
            "Epoch 826/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5383 - acc: 0.7423 - val_loss: 0.6910 - val_acc: 0.6250\n",
            "Epoch 827/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.4805 - acc: 0.7663 - val_loss: 0.6838 - val_acc: 0.6458\n",
            "Epoch 828/1000\n",
            "37/37 [==============================] - 8s 226ms/step - loss: 0.5077 - acc: 0.7388 - val_loss: 0.6607 - val_acc: 0.6562\n",
            "Epoch 829/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.4941 - acc: 0.7646 - val_loss: 0.7007 - val_acc: 0.6146\n",
            "Epoch 830/1000\n",
            "37/37 [==============================] - 6s 144ms/step - loss: 0.5054 - acc: 0.7543 - val_loss: 0.6651 - val_acc: 0.6458\n",
            "Epoch 831/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5167 - acc: 0.7337 - val_loss: 0.6781 - val_acc: 0.6458\n",
            "Epoch 832/1000\n",
            "37/37 [==============================] - 5s 110ms/step - loss: 0.4989 - acc: 0.7474 - val_loss: 0.6883 - val_acc: 0.6146\n",
            "Epoch 833/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5286 - acc: 0.7423 - val_loss: 0.6779 - val_acc: 0.6458\n",
            "Epoch 834/1000\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.5103 - acc: 0.7457 - val_loss: 0.6823 - val_acc: 0.6562\n",
            "Epoch 835/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5189 - acc: 0.7801 - val_loss: 0.7013 - val_acc: 0.6458\n",
            "Epoch 836/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.5039 - acc: 0.7320 - val_loss: 0.6885 - val_acc: 0.6354\n",
            "Epoch 837/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5005 - acc: 0.7399 - val_loss: 0.6615 - val_acc: 0.6250\n",
            "Epoch 838/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.5527 - acc: 0.7165 - val_loss: 0.6951 - val_acc: 0.6042\n",
            "Epoch 839/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5242 - acc: 0.7423 - val_loss: 0.6606 - val_acc: 0.6771\n",
            "Epoch 840/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5326 - acc: 0.7440 - val_loss: 0.7029 - val_acc: 0.6354\n",
            "Epoch 841/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5257 - acc: 0.7405 - val_loss: 0.6798 - val_acc: 0.6354\n",
            "Epoch 842/1000\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.5286 - acc: 0.7388 - val_loss: 0.6701 - val_acc: 0.6250\n",
            "Epoch 843/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.4785 - acc: 0.7715 - val_loss: 0.6834 - val_acc: 0.6250\n",
            "Epoch 844/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5182 - acc: 0.7405 - val_loss: 0.6683 - val_acc: 0.6354\n",
            "Epoch 845/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5353 - acc: 0.7251 - val_loss: 0.6738 - val_acc: 0.6354\n",
            "Epoch 846/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.4960 - acc: 0.7560 - val_loss: 0.6677 - val_acc: 0.6354\n",
            "Epoch 847/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5007 - acc: 0.7543 - val_loss: 0.6692 - val_acc: 0.6250\n",
            "Epoch 848/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.4900 - acc: 0.7629 - val_loss: 0.6881 - val_acc: 0.6354\n",
            "Epoch 849/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5259 - acc: 0.7113 - val_loss: 0.6723 - val_acc: 0.6250\n",
            "Epoch 850/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.4942 - acc: 0.7663 - val_loss: 0.6759 - val_acc: 0.6354\n",
            "Epoch 851/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.4732 - acc: 0.7818 - val_loss: 0.6809 - val_acc: 0.6250\n",
            "Epoch 852/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.5103 - acc: 0.7509 - val_loss: 0.6618 - val_acc: 0.6354\n",
            "Epoch 853/1000\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.5330 - acc: 0.7337 - val_loss: 0.6933 - val_acc: 0.6354\n",
            "Epoch 854/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 0.5278 - acc: 0.7268 - val_loss: 0.6832 - val_acc: 0.6146\n",
            "Epoch 855/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5092 - acc: 0.7629 - val_loss: 0.6706 - val_acc: 0.6354\n",
            "Epoch 856/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5285 - acc: 0.7199 - val_loss: 0.6826 - val_acc: 0.6250\n",
            "Epoch 857/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.5293 - acc: 0.7268 - val_loss: 0.6904 - val_acc: 0.6354\n",
            "Epoch 858/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.5272 - acc: 0.7285 - val_loss: 0.7035 - val_acc: 0.6146\n",
            "Epoch 859/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.5189 - acc: 0.7337 - val_loss: 0.6745 - val_acc: 0.6354\n",
            "Epoch 860/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5096 - acc: 0.7577 - val_loss: 0.6716 - val_acc: 0.6562\n",
            "Epoch 861/1000\n",
            "37/37 [==============================] - 9s 242ms/step - loss: 0.5113 - acc: 0.7577 - val_loss: 0.7036 - val_acc: 0.6250\n",
            "Epoch 862/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.4975 - acc: 0.7595 - val_loss: 0.6891 - val_acc: 0.6146\n",
            "Epoch 863/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5002 - acc: 0.7784 - val_loss: 0.6937 - val_acc: 0.6354\n",
            "Epoch 864/1000\n",
            "37/37 [==============================] - 9s 243ms/step - loss: 0.5191 - acc: 0.7474 - val_loss: 0.6721 - val_acc: 0.6250\n",
            "Epoch 865/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5098 - acc: 0.7405 - val_loss: 0.6965 - val_acc: 0.6458\n",
            "Epoch 866/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 0.5263 - acc: 0.7388 - val_loss: 0.6820 - val_acc: 0.6562\n",
            "Epoch 867/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5210 - acc: 0.7234 - val_loss: 0.6716 - val_acc: 0.6354\n",
            "Epoch 868/1000\n",
            "37/37 [==============================] - 10s 249ms/step - loss: 0.5147 - acc: 0.7388 - val_loss: 0.6837 - val_acc: 0.6146\n",
            "Epoch 869/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.5199 - acc: 0.7543 - val_loss: 0.6843 - val_acc: 0.6146\n",
            "Epoch 870/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.5004 - acc: 0.7732 - val_loss: 0.6777 - val_acc: 0.6354\n",
            "Epoch 871/1000\n",
            "37/37 [==============================] - 5s 109ms/step - loss: 0.4980 - acc: 0.7491 - val_loss: 0.6604 - val_acc: 0.6354\n",
            "Epoch 872/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.4983 - acc: 0.7629 - val_loss: 0.6871 - val_acc: 0.6146\n",
            "Epoch 873/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5181 - acc: 0.7440 - val_loss: 0.6713 - val_acc: 0.6667\n",
            "Epoch 874/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5271 - acc: 0.7216 - val_loss: 0.6788 - val_acc: 0.6458\n",
            "Epoch 875/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.5198 - acc: 0.7302 - val_loss: 0.6805 - val_acc: 0.6354\n",
            "Epoch 876/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5393 - acc: 0.7320 - val_loss: 0.6780 - val_acc: 0.6562\n",
            "Epoch 877/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5210 - acc: 0.7388 - val_loss: 0.6634 - val_acc: 0.6458\n",
            "Epoch 878/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.5158 - acc: 0.7216 - val_loss: 0.6836 - val_acc: 0.6458\n",
            "Epoch 879/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5238 - acc: 0.7457 - val_loss: 0.6852 - val_acc: 0.6042\n",
            "Epoch 880/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.5071 - acc: 0.7457 - val_loss: 0.6867 - val_acc: 0.6146\n",
            "Epoch 881/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.5076 - acc: 0.7354 - val_loss: 0.6735 - val_acc: 0.6458\n",
            "Epoch 882/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5162 - acc: 0.7457 - val_loss: 0.6664 - val_acc: 0.6562\n",
            "Epoch 883/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.4902 - acc: 0.7526 - val_loss: 0.6849 - val_acc: 0.6354\n",
            "Epoch 884/1000\n",
            "37/37 [==============================] - 5s 110ms/step - loss: 0.4768 - acc: 0.7715 - val_loss: 0.6638 - val_acc: 0.6667\n",
            "Epoch 885/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.5114 - acc: 0.7629 - val_loss: 0.6755 - val_acc: 0.6146\n",
            "Epoch 886/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5382 - acc: 0.7371 - val_loss: 0.6615 - val_acc: 0.6458\n",
            "Epoch 887/1000\n",
            "37/37 [==============================] - 10s 253ms/step - loss: 0.5207 - acc: 0.7474 - val_loss: 0.6863 - val_acc: 0.6250\n",
            "Epoch 888/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.4928 - acc: 0.7646 - val_loss: 0.6698 - val_acc: 0.6667\n",
            "Epoch 889/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5222 - acc: 0.7268 - val_loss: 0.6716 - val_acc: 0.6354\n",
            "Epoch 890/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.5119 - acc: 0.7440 - val_loss: 0.6676 - val_acc: 0.6250\n",
            "Epoch 891/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.5282 - acc: 0.7457 - val_loss: 0.6722 - val_acc: 0.6354\n",
            "Epoch 892/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5367 - acc: 0.7302 - val_loss: 0.6728 - val_acc: 0.6562\n",
            "Epoch 893/1000\n",
            "37/37 [==============================] - 10s 252ms/step - loss: 0.4781 - acc: 0.7698 - val_loss: 0.6777 - val_acc: 0.6250\n",
            "Epoch 894/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5104 - acc: 0.7320 - val_loss: 0.6777 - val_acc: 0.6146\n",
            "Epoch 895/1000\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.5187 - acc: 0.7457 - val_loss: 0.6512 - val_acc: 0.6354\n",
            "Epoch 896/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5005 - acc: 0.7663 - val_loss: 0.6628 - val_acc: 0.6354\n",
            "Epoch 897/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.5433 - acc: 0.7113 - val_loss: 0.6690 - val_acc: 0.6250\n",
            "Epoch 898/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5090 - acc: 0.7595 - val_loss: 0.6600 - val_acc: 0.6354\n",
            "Epoch 899/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5170 - acc: 0.7405 - val_loss: 0.6434 - val_acc: 0.6771\n",
            "Epoch 900/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5121 - acc: 0.7440 - val_loss: 0.6677 - val_acc: 0.6562\n",
            "Epoch 901/1000\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.5310 - acc: 0.7423 - val_loss: 0.6800 - val_acc: 0.6250\n",
            "Epoch 902/1000\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.5187 - acc: 0.7457 - val_loss: 0.6680 - val_acc: 0.6562\n",
            "Epoch 903/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5211 - acc: 0.7612 - val_loss: 0.6934 - val_acc: 0.6250\n",
            "Epoch 904/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.5676 - acc: 0.7285 - val_loss: 0.6672 - val_acc: 0.6458\n",
            "Epoch 905/1000\n",
            "37/37 [==============================] - 9s 247ms/step - loss: 0.5040 - acc: 0.7595 - val_loss: 0.6822 - val_acc: 0.6562\n",
            "Epoch 906/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5187 - acc: 0.7457 - val_loss: 0.6648 - val_acc: 0.6667\n",
            "Epoch 907/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.5251 - acc: 0.7405 - val_loss: 0.6499 - val_acc: 0.6354\n",
            "Epoch 908/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5505 - acc: 0.7371 - val_loss: 0.6665 - val_acc: 0.6458\n",
            "Epoch 909/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5109 - acc: 0.7457 - val_loss: 0.6625 - val_acc: 0.6250\n",
            "Epoch 910/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5214 - acc: 0.7491 - val_loss: 0.6788 - val_acc: 0.6146\n",
            "Epoch 911/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5314 - acc: 0.7354 - val_loss: 0.6708 - val_acc: 0.6250\n",
            "Epoch 912/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5295 - acc: 0.7320 - val_loss: 0.6754 - val_acc: 0.6250\n",
            "Epoch 913/1000\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.4674 - acc: 0.7852 - val_loss: 0.6692 - val_acc: 0.6562\n",
            "Epoch 914/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.5139 - acc: 0.7423 - val_loss: 0.6845 - val_acc: 0.6042\n",
            "Epoch 915/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5259 - acc: 0.7371 - val_loss: 0.6567 - val_acc: 0.6354\n",
            "Epoch 916/1000\n",
            "37/37 [==============================] - 5s 106ms/step - loss: 0.5255 - acc: 0.7302 - val_loss: 0.6770 - val_acc: 0.6042\n",
            "Epoch 917/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.4959 - acc: 0.7577 - val_loss: 0.6613 - val_acc: 0.6458\n",
            "Epoch 918/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5233 - acc: 0.7595 - val_loss: 0.6705 - val_acc: 0.6354\n",
            "Epoch 919/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.5350 - acc: 0.7234 - val_loss: 0.6759 - val_acc: 0.6250\n",
            "Epoch 920/1000\n",
            "37/37 [==============================] - 4s 109ms/step - loss: 0.5219 - acc: 0.7416 - val_loss: 0.6758 - val_acc: 0.6458\n",
            "Epoch 921/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.4989 - acc: 0.7491 - val_loss: 0.6851 - val_acc: 0.6146\n",
            "Epoch 922/1000\n",
            "37/37 [==============================] - 5s 110ms/step - loss: 0.4936 - acc: 0.7534 - val_loss: 0.6801 - val_acc: 0.6354\n",
            "Epoch 923/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5350 - acc: 0.7268 - val_loss: 0.6636 - val_acc: 0.6354\n",
            "Epoch 924/1000\n",
            "37/37 [==============================] - 5s 105ms/step - loss: 0.4971 - acc: 0.7491 - val_loss: 0.6628 - val_acc: 0.6667\n",
            "Epoch 925/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5120 - acc: 0.7560 - val_loss: 0.6765 - val_acc: 0.6042\n",
            "Epoch 926/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5094 - acc: 0.7474 - val_loss: 0.6438 - val_acc: 0.6667\n",
            "Epoch 927/1000\n",
            "37/37 [==============================] - 9s 250ms/step - loss: 0.5112 - acc: 0.7268 - val_loss: 0.6619 - val_acc: 0.6250\n",
            "Epoch 928/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5140 - acc: 0.7302 - val_loss: 0.6842 - val_acc: 0.6042\n",
            "Epoch 929/1000\n",
            "37/37 [==============================] - 9s 242ms/step - loss: 0.5078 - acc: 0.7337 - val_loss: 0.6574 - val_acc: 0.6354\n",
            "Epoch 930/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.4877 - acc: 0.7646 - val_loss: 0.6654 - val_acc: 0.6146\n",
            "Epoch 931/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5564 - acc: 0.7182 - val_loss: 0.6739 - val_acc: 0.6354\n",
            "Epoch 932/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5289 - acc: 0.7457 - val_loss: 0.6523 - val_acc: 0.6667\n",
            "Epoch 933/1000\n",
            "37/37 [==============================] - 5s 109ms/step - loss: 0.5225 - acc: 0.7354 - val_loss: 0.6717 - val_acc: 0.6146\n",
            "Epoch 934/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.4912 - acc: 0.7595 - val_loss: 0.6515 - val_acc: 0.6250\n",
            "Epoch 935/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.5390 - acc: 0.7423 - val_loss: 0.6723 - val_acc: 0.6354\n",
            "Epoch 936/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.5087 - acc: 0.7234 - val_loss: 0.6391 - val_acc: 0.6667\n",
            "Epoch 937/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.4910 - acc: 0.7560 - val_loss: 0.6633 - val_acc: 0.6250\n",
            "Epoch 938/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5328 - acc: 0.7457 - val_loss: 0.6653 - val_acc: 0.6146\n",
            "Epoch 939/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5281 - acc: 0.7199 - val_loss: 0.6585 - val_acc: 0.6146\n",
            "Epoch 940/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.4990 - acc: 0.7577 - val_loss: 0.6310 - val_acc: 0.6146\n",
            "Epoch 941/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.4989 - acc: 0.7646 - val_loss: 0.6520 - val_acc: 0.6250\n",
            "Epoch 942/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.5078 - acc: 0.7509 - val_loss: 0.6641 - val_acc: 0.6146\n",
            "Epoch 943/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.5040 - acc: 0.7423 - val_loss: 0.6538 - val_acc: 0.6354\n",
            "Epoch 944/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5021 - acc: 0.7474 - val_loss: 0.6827 - val_acc: 0.6250\n",
            "Epoch 945/1000\n",
            "37/37 [==============================] - 6s 144ms/step - loss: 0.5203 - acc: 0.7320 - val_loss: 0.6803 - val_acc: 0.6042\n",
            "Epoch 946/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.4867 - acc: 0.7680 - val_loss: 0.6615 - val_acc: 0.6250\n",
            "Epoch 947/1000\n",
            "37/37 [==============================] - 9s 218ms/step - loss: 0.4719 - acc: 0.7663 - val_loss: 0.6516 - val_acc: 0.6458\n",
            "Epoch 948/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5417 - acc: 0.7251 - val_loss: 0.6528 - val_acc: 0.6562\n",
            "Epoch 949/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 0.5056 - acc: 0.7509 - val_loss: 0.6510 - val_acc: 0.6354\n",
            "Epoch 950/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.5179 - acc: 0.7251 - val_loss: 0.6650 - val_acc: 0.6146\n",
            "Epoch 951/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.5100 - acc: 0.7749 - val_loss: 0.6541 - val_acc: 0.6146\n",
            "Epoch 952/1000\n",
            "37/37 [==============================] - 9s 239ms/step - loss: 0.5228 - acc: 0.7354 - val_loss: 0.6560 - val_acc: 0.6458\n",
            "Epoch 953/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.4992 - acc: 0.7560 - val_loss: 0.6677 - val_acc: 0.6458\n",
            "Epoch 954/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.4899 - acc: 0.7612 - val_loss: 0.6506 - val_acc: 0.6667\n",
            "Epoch 955/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.4906 - acc: 0.7526 - val_loss: 0.6557 - val_acc: 0.6354\n",
            "Epoch 956/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.5046 - acc: 0.7491 - val_loss: 0.6452 - val_acc: 0.6667\n",
            "Epoch 957/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.4976 - acc: 0.7629 - val_loss: 0.6553 - val_acc: 0.6354\n",
            "Epoch 958/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.5332 - acc: 0.7337 - val_loss: 0.6711 - val_acc: 0.6146\n",
            "Epoch 959/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5146 - acc: 0.7474 - val_loss: 0.6728 - val_acc: 0.6250\n",
            "Epoch 960/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.4947 - acc: 0.7526 - val_loss: 0.6708 - val_acc: 0.6250\n",
            "Epoch 961/1000\n",
            "37/37 [==============================] - 9s 243ms/step - loss: 0.5057 - acc: 0.7491 - val_loss: 0.6685 - val_acc: 0.6146\n",
            "Epoch 962/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5168 - acc: 0.7543 - val_loss: 0.6752 - val_acc: 0.6146\n",
            "Epoch 963/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.5026 - acc: 0.7526 - val_loss: 0.6591 - val_acc: 0.6250\n",
            "Epoch 964/1000\n",
            "37/37 [==============================] - 9s 247ms/step - loss: 0.5047 - acc: 0.7474 - val_loss: 0.6622 - val_acc: 0.6250\n",
            "Epoch 965/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5265 - acc: 0.7388 - val_loss: 0.6654 - val_acc: 0.6562\n",
            "Epoch 966/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5222 - acc: 0.7612 - val_loss: 0.6688 - val_acc: 0.6562\n",
            "Epoch 967/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5174 - acc: 0.7423 - val_loss: 0.6665 - val_acc: 0.6250\n",
            "Epoch 968/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.4950 - acc: 0.7612 - val_loss: 0.6755 - val_acc: 0.6458\n",
            "Epoch 969/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.4987 - acc: 0.7474 - val_loss: 0.6552 - val_acc: 0.6562\n",
            "Epoch 970/1000\n",
            "37/37 [==============================] - 10s 239ms/step - loss: 0.5076 - acc: 0.7423 - val_loss: 0.6669 - val_acc: 0.6458\n",
            "Epoch 971/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5526 - acc: 0.7131 - val_loss: 0.6829 - val_acc: 0.6458\n",
            "Epoch 972/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.5226 - acc: 0.7337 - val_loss: 0.6745 - val_acc: 0.6562\n",
            "Epoch 973/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5010 - acc: 0.7698 - val_loss: 0.6868 - val_acc: 0.6354\n",
            "Epoch 974/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.5027 - acc: 0.7526 - val_loss: 0.6729 - val_acc: 0.6250\n",
            "Epoch 975/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5172 - acc: 0.7268 - val_loss: 0.6677 - val_acc: 0.6562\n",
            "Epoch 976/1000\n",
            "37/37 [==============================] - 5s 98ms/step - loss: 0.5197 - acc: 0.7337 - val_loss: 0.6822 - val_acc: 0.6042\n",
            "Epoch 977/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5268 - acc: 0.7543 - val_loss: 0.6804 - val_acc: 0.6146\n",
            "Epoch 978/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5412 - acc: 0.7354 - val_loss: 0.6652 - val_acc: 0.6667\n",
            "Epoch 979/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5124 - acc: 0.7491 - val_loss: 0.6512 - val_acc: 0.6562\n",
            "Epoch 980/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5185 - acc: 0.7440 - val_loss: 0.6691 - val_acc: 0.6458\n",
            "Epoch 981/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5135 - acc: 0.7285 - val_loss: 0.6770 - val_acc: 0.6354\n",
            "Epoch 982/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5147 - acc: 0.7423 - val_loss: 0.6669 - val_acc: 0.6354\n",
            "Epoch 983/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.5055 - acc: 0.7320 - val_loss: 0.6615 - val_acc: 0.6458\n",
            "Epoch 984/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5117 - acc: 0.7457 - val_loss: 0.6589 - val_acc: 0.6562\n",
            "Epoch 985/1000\n",
            "37/37 [==============================] - 9s 242ms/step - loss: 0.5060 - acc: 0.7199 - val_loss: 0.6905 - val_acc: 0.6354\n",
            "Epoch 986/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.5218 - acc: 0.7337 - val_loss: 0.6810 - val_acc: 0.6146\n",
            "Epoch 987/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5428 - acc: 0.7354 - val_loss: 0.6818 - val_acc: 0.6250\n",
            "Epoch 988/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.4959 - acc: 0.7595 - val_loss: 0.6842 - val_acc: 0.6458\n",
            "Epoch 989/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.4787 - acc: 0.7715 - val_loss: 0.6643 - val_acc: 0.6354\n",
            "Epoch 990/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5326 - acc: 0.7354 - val_loss: 0.6736 - val_acc: 0.6250\n",
            "Epoch 991/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5119 - acc: 0.7440 - val_loss: 0.6812 - val_acc: 0.6354\n",
            "Epoch 992/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5051 - acc: 0.7457 - val_loss: 0.6558 - val_acc: 0.6667\n",
            "Epoch 993/1000\n",
            "37/37 [==============================] - 5s 113ms/step - loss: 0.5241 - acc: 0.7320 - val_loss: 0.6648 - val_acc: 0.6250\n",
            "Epoch 994/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5353 - acc: 0.7457 - val_loss: 0.6536 - val_acc: 0.6354\n",
            "Epoch 995/1000\n",
            "37/37 [==============================] - 9s 243ms/step - loss: 0.5047 - acc: 0.7182 - val_loss: 0.6633 - val_acc: 0.6250\n",
            "Epoch 996/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5017 - acc: 0.7423 - val_loss: 0.6872 - val_acc: 0.6354\n",
            "Epoch 997/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5030 - acc: 0.7612 - val_loss: 0.6908 - val_acc: 0.6458\n",
            "Epoch 998/1000\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.5150 - acc: 0.7440 - val_loss: 0.6892 - val_acc: 0.6458\n",
            "Epoch 999/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.4994 - acc: 0.7560 - val_loss: 0.6800 - val_acc: 0.6354\n",
            "Epoch 1000/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.5140 - acc: 0.7457 - val_loss: 0.6700 - val_acc: 0.6354\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot training performance"
      ],
      "metadata": {
        "id": "YFxMJycOpEew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'co', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'k', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'co', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "     "
      ],
      "metadata": {
        "id": "l9PYKbRNpEK8",
        "outputId": "b37b179e-15a6-42db-9a61-0f58c46d8985",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SAVE model"
      ],
      "metadata": {
        "id": "kNtlq_LZpKNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('./content/drive/My Drive/new', exist_ok=True)\n",
        "model.save('./content/drive/My Drive/new/2Class_UNfreeze_1000.h5')"
      ],
      "metadata": {
        "id": "TegSVqblpLEZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "KdsdaIgMpMeG"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"./content/drive/My Drive/new/2Class_UNfreeze_1000.h5\")"
      ],
      "metadata": {
        "id": "sZFZ1c_kpMcN",
        "outputId": "37b49da7-86f4-40b6-b46a-bef5ef5bbde1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_646f0a82-e984-4659-ae9c-7a9e961f97d7\", \"2Class_UNfreeze_1000.h5\", 16604936)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gEfCB1RfpMZ6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}