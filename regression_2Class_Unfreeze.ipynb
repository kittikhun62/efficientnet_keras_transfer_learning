{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kittikhun62/efficientnet_keras_transfer_learning/blob/master/regression_2Class_Unfreeze.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#เรียกใช้ CSV"
      ],
      "metadata": {
        "id": "ow7eWoNw6U-c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z8o_VVNXzcL8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_2Fe8u81d5r",
        "outputId": "7576155e-7872-4279-8d24-da34eb784a97"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "5qxePnnn7TGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "D-hCRloc3t39"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "YZWXwjXeGxZP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#กำหนดค่าพารามิเตอร์\n"
      ],
      "metadata": {
        "id": "RooqSdBc7QHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "width = 150\n",
        "height = 150\n",
        "\n",
        "epochs = 2000 #จำนวนรอบในการ Train\n",
        "\n",
        "NUM_TRAIN = 628  # จำนวนภาพ Train\n",
        "NUM_TEST = 101 #จำนวนภาพ Test\n",
        "\n",
        "dropout_rate = 0.3\n",
        "input_shape = (height, width, 3) #ขนาด image enter"
      ],
      "metadata": {
        "id": "thDb7U9B3xOo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clone efficientnet repo\n"
      ],
      "metadata": {
        "id": "pumGmy6f3eSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7iy2f8n16p0",
        "outputId": "4dc369ab-d4e0-49b5-f126-b1fb1e3c493c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 1082, done.\u001b[K\n",
            "remote: Counting objects: 100% (245/245), done.\u001b[K\n",
            "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
            "remote: Total 1082 (delta 122), reused 241 (delta 121), pack-reused 837\u001b[K\n",
            "Receiving objects: 100% (1082/1082), 14.09 MiB | 35.53 MiB/s, done.\n",
            "Resolving deltas: 100% (619/619), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "tjZBRnfo3bN0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "r8BN74_JJdfj",
        "outputId": "cff7e923-721a-47dc-d871-78ae39e3976e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#load model\n"
      ],
      "metadata": {
        "id": "PdNWyD-QYkzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/new/regression.h5')\n",
        "\n",
        "from efficientnet.layers import Swish, DropConnect\n",
        "from efficientnet.model import ConvKernalInitializer\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "\n",
        "get_custom_objects().update({\n",
        "    'ConvKernalInitializer': ConvKernalInitializer,\n",
        "    'Swish': Swish,\n",
        "    'DropConnect':DropConnect\n",
        "})"
      ],
      "metadata": {
        "id": "_gPnx2UvYf5A"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load model \n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/drive/My Drive/new/regression.h5')\n",
        "height = width = model.input_shape[1]"
      ],
      "metadata": {
        "id": "Nu93WzFUYm9e"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "gp5EbyyXYvc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6e5dcb4-13af-44de-e84a-e21c9f16253d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 2)                 2562      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,052,129\n",
            "Trainable params: 2,565\n",
            "Non-trainable params: 4,049,564\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (f'/content/drive/My Drive/data - 2 class เพิ่ม 4 paper.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "q1Dc131_Y3uA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "a284a705-94a5-405f-f852-f0694953a671"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      No                      Name_file  \\\n",
              "0      1                        pore-sb   \n",
              "1      2                        pore-sb   \n",
              "2      3                        pore-sb   \n",
              "3      4                        pore-sb   \n",
              "4      5                        pore-sb   \n",
              "..   ...                            ...   \n",
              "825  826  1-s2.0-S2095268622000210-main   \n",
              "826  827  1-s2.0-S2095268622000210-main   \n",
              "827  828  1-s2.0-S2095268622000210-main   \n",
              "828  829  1-s2.0-S2095268622000210-main   \n",
              "829  830  1-s2.0-S2095268622000210-main   \n",
              "\n",
              "                                            Name_Paper  \\\n",
              "0    Preparation and electrochemical behaviour of b...   \n",
              "1    Preparation and electrochemical behaviour of b...   \n",
              "2    Preparation and electrochemical behaviour of b...   \n",
              "3    Preparation and electrochemical behaviour of b...   \n",
              "4    Preparation and electrochemical behaviour of b...   \n",
              "..                                                 ...   \n",
              "825  Integration of preparation of K, Na-embedded a...   \n",
              "826  Integration of preparation of K, Na-embedded a...   \n",
              "827  Integration of preparation of K, Na-embedded a...   \n",
              "828  Integration of preparation of K, Na-embedded a...   \n",
              "829  Integration of preparation of K, Na-embedded a...   \n",
              "\n",
              "                                               journal  \\\n",
              "0                                  Korean J. Chem. Eng   \n",
              "1                                  Korean J. Chem. Eng   \n",
              "2                                  Korean J. Chem. Eng   \n",
              "3                                  Korean J. Chem. Eng   \n",
              "4                                  Korean J. Chem. Eng   \n",
              "..                                                 ...   \n",
              "825  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "826  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "827  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "828  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "829  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "\n",
              "                                          path_Picture  detail  Class     BET  \\\n",
              "0    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom1  0-800  135.06   \n",
              "1    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom2  0-800  135.06   \n",
              "2    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom3  0-800  135.06   \n",
              "3    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom4  0-800  135.06   \n",
              "4    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom5  0-800  135.06   \n",
              "..                                                 ...     ...    ...     ...   \n",
              "825  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom21  0-800  301.70   \n",
              "826  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom22  0-800  301.70   \n",
              "827  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom23  0-800  301.70   \n",
              "828  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom24  0-800  301.70   \n",
              "829  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom25  0-800  301.70   \n",
              "\n",
              "     Size(mico)  Class_01  \n",
              "0            10         0  \n",
              "1            10         0  \n",
              "2            10         0  \n",
              "3            10         0  \n",
              "4            10         0  \n",
              "..          ...       ...  \n",
              "825          10         0  \n",
              "826          10         0  \n",
              "827          10         0  \n",
              "828          10         0  \n",
              "829          10         0  \n",
              "\n",
              "[830 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a35eeb50-a17f-4899-b14f-64fbfa8c2df9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>No</th>\n",
              "      <th>Name_file</th>\n",
              "      <th>Name_Paper</th>\n",
              "      <th>journal</th>\n",
              "      <th>path_Picture</th>\n",
              "      <th>detail</th>\n",
              "      <th>Class</th>\n",
              "      <th>BET</th>\n",
              "      <th>Size(mico)</th>\n",
              "      <th>Class_01</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom1</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom2</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom3</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom4</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom5</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>825</th>\n",
              "      <td>826</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom21</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>826</th>\n",
              "      <td>827</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom22</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>827</th>\n",
              "      <td>828</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom23</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>828</th>\n",
              "      <td>829</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom24</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>829</th>\n",
              "      <td>830</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom25</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>830 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a35eeb50-a17f-4899-b14f-64fbfa8c2df9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a35eeb50-a17f-4899-b14f-64fbfa8c2df9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a35eeb50-a17f-4899-b14f-64fbfa8c2df9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "FdYoTgJ19LRv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val = df[df['No'].between(629,729)]\n",
        "train = df[df['No'].between(1,628)]"
      ],
      "metadata": {
        "id": "Z1zBw01Gl8Ac"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = '/content/drive/My Drive/new project'\n",
        "os.chdir(DATA_PATH)\n",
        "train_dir = os.path.join(DATA_PATH, 'train')\n",
        "print(train_dir)\n",
        "validation_dir = os.path.join(DATA_PATH, 'validation')\n",
        "print(validation_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QL0g-8iOnMC4",
        "outputId": "dd6409ff-7f1f-4163-bd23-171518a8abdf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/new project/train\n",
            "/content/drive/My Drive/new project/validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Train"
      ],
      "metadata": {
        "id": "bWEnlTSwazL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "xGPrsn9no_pa"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe = train,\n",
        "        directory = train_dir,\n",
        "        x_col = 'path_Picture',\n",
        "        y_col = 'BET',\n",
        "        class_mode = 'other',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)\n",
        "\n",
        "validation_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe = val,\n",
        "        directory = validation_dir,\n",
        "        x_col = 'path_Picture',\n",
        "        y_col = 'BET',\n",
        "        class_mode = 'other',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nVlmAszntK_",
        "outputId": "931de4a9-4da7-4239-8ec2-75bd7fec4545"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 628 validated image filenames.\n",
            "Found 101 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multiply_16\n",
        "# set 'multiply_16' and following layers trainable\n",
        "model.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'multiply_16':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False  "
      ],
      "metadata": {
        "id": "RY14olxmJj92"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzCdn3X4Jm_E",
        "outputId": "3a3e0fc2-6b20-40d5-b0f3-5af44f701013"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 2)                 2562      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,052,129\n",
            "Trainable params: 4,010,113\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "N6qUmmF856ZE",
        "outputId": "48eb893d-7b32-4ae5-c81f-e6cc93885fb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-caa7b37242a8>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "39/39 [==============================] - 66s 1s/step - loss: 610459.3750 - mae: 618.2576 - val_loss: 225805.9375 - val_mae: 460.3938\n",
            "Epoch 2/2000\n",
            "39/39 [==============================] - 8s 196ms/step - loss: 605211.1250 - mae: 614.6361 - val_loss: 224030.0469 - val_mae: 458.5414\n",
            "Epoch 3/2000\n",
            "39/39 [==============================] - 3s 73ms/step - loss: 599477.0000 - mae: 614.0308 - val_loss: 225621.1719 - val_mae: 460.5603\n",
            "Epoch 4/2000\n",
            "39/39 [==============================] - 3s 73ms/step - loss: 607318.0000 - mae: 616.5051 - val_loss: 227359.7031 - val_mae: 462.1809\n",
            "Epoch 5/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 603592.0625 - mae: 614.7473 - val_loss: 227152.9375 - val_mae: 461.2732\n",
            "Epoch 6/2000\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 600157.2500 - mae: 611.0198 - val_loss: 221484.8281 - val_mae: 455.0559\n",
            "Epoch 7/2000\n",
            "39/39 [==============================] - 8s 202ms/step - loss: 605990.1875 - mae: 616.4464 - val_loss: 227848.0781 - val_mae: 462.1352\n",
            "Epoch 8/2000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 601215.3750 - mae: 613.9273 - val_loss: 226998.2031 - val_mae: 461.3645\n",
            "Epoch 9/2000\n",
            "39/39 [==============================] - 4s 106ms/step - loss: 603788.0000 - mae: 615.4796 - val_loss: 230663.1250 - val_mae: 465.4331\n",
            "Epoch 10/2000\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 602649.3750 - mae: 614.4814 - val_loss: 227214.4531 - val_mae: 461.3646\n",
            "Epoch 11/2000\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 601135.8125 - mae: 612.6705 - val_loss: 224357.8750 - val_mae: 457.8112\n",
            "Epoch 12/2000\n",
            "39/39 [==============================] - 4s 76ms/step - loss: 607316.3750 - mae: 617.7706 - val_loss: 225751.5469 - val_mae: 458.4982\n",
            "Epoch 13/2000\n",
            "39/39 [==============================] - 3s 72ms/step - loss: 601474.8125 - mae: 614.1922 - val_loss: 227883.0469 - val_mae: 461.6458\n",
            "Epoch 14/2000\n",
            "39/39 [==============================] - 4s 77ms/step - loss: 599753.3750 - mae: 615.7416 - val_loss: 224119.3281 - val_mae: 457.0926\n",
            "Epoch 15/2000\n",
            "39/39 [==============================] - 4s 77ms/step - loss: 606254.3125 - mae: 617.7648 - val_loss: 225072.0156 - val_mae: 458.1003\n",
            "Epoch 16/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 586525.3750 - mae: 608.7851 - val_loss: 224351.0781 - val_mae: 456.6197\n",
            "Epoch 17/2000\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 595218.3125 - mae: 613.3654 - val_loss: 227723.1719 - val_mae: 461.0833\n",
            "Epoch 18/2000\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 594384.1875 - mae: 613.0675 - val_loss: 230926.5000 - val_mae: 464.6650\n",
            "Epoch 19/2000\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 595806.6875 - mae: 611.1562 - val_loss: 224176.8906 - val_mae: 456.7717\n",
            "Epoch 20/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 599872.4375 - mae: 614.8836 - val_loss: 226632.4531 - val_mae: 459.0521\n",
            "Epoch 21/2000\n",
            "39/39 [==============================] - 3s 72ms/step - loss: 600368.6875 - mae: 615.3319 - val_loss: 230902.3750 - val_mae: 463.6947\n",
            "Epoch 22/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 596601.4375 - mae: 614.2261 - val_loss: 228640.0000 - val_mae: 461.3646\n",
            "Epoch 23/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 594051.5625 - mae: 612.3268 - val_loss: 225943.8750 - val_mae: 458.0042\n",
            "Epoch 24/2000\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 590937.0625 - mae: 610.2896 - val_loss: 230323.0781 - val_mae: 463.3958\n",
            "Epoch 25/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 592453.3125 - mae: 609.7376 - val_loss: 224412.9375 - val_mae: 455.6673\n",
            "Epoch 26/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 596687.5000 - mae: 615.1404 - val_loss: 227688.5781 - val_mae: 459.3333\n",
            "Epoch 27/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 602590.6250 - mae: 618.1736 - val_loss: 230681.7500 - val_mae: 463.3958\n",
            "Epoch 28/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 592393.5625 - mae: 612.4734 - val_loss: 225074.0625 - val_mae: 456.5550\n",
            "Epoch 29/2000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 590471.4375 - mae: 610.8448 - val_loss: 226629.1719 - val_mae: 457.9316\n",
            "Epoch 30/2000\n",
            "39/39 [==============================] - 9s 207ms/step - loss: 586362.8750 - mae: 610.1608 - val_loss: 229958.1875 - val_mae: 461.6458\n",
            "Epoch 31/2000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 601155.1250 - mae: 616.7491 - val_loss: 225767.7500 - val_mae: 456.1567\n",
            "Epoch 32/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 592422.8750 - mae: 612.1440 - val_loss: 231382.3750 - val_mae: 462.8033\n",
            "Epoch 33/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 592513.8750 - mae: 612.0545 - val_loss: 227433.5625 - val_mae: 458.1633\n",
            "Epoch 34/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 598726.6250 - mae: 616.4396 - val_loss: 227641.3125 - val_mae: 457.5833\n",
            "Epoch 35/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 583813.1250 - mae: 608.6646 - val_loss: 225818.2500 - val_mae: 456.3843\n",
            "Epoch 36/2000\n",
            "39/39 [==============================] - 4s 77ms/step - loss: 588111.8125 - mae: 609.6628 - val_loss: 230086.3281 - val_mae: 461.0833\n",
            "Epoch 37/2000\n",
            "39/39 [==============================] - 4s 77ms/step - loss: 588765.9375 - mae: 612.9393 - val_loss: 229453.6250 - val_mae: 459.6146\n",
            "Epoch 38/2000\n",
            "39/39 [==============================] - 9s 208ms/step - loss: 599178.5625 - mae: 617.7069 - val_loss: 231899.1719 - val_mae: 462.5932\n",
            "Epoch 39/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 593842.7500 - mae: 612.6366 - val_loss: 223915.3281 - val_mae: 453.2994\n",
            "Epoch 40/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 600309.1250 - mae: 618.4846 - val_loss: 234799.7500 - val_mae: 466.3150\n",
            "Epoch 41/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 590379.6875 - mae: 612.0952 - val_loss: 229467.2344 - val_mae: 459.8185\n",
            "Epoch 42/2000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 582316.4375 - mae: 609.1642 - val_loss: 225180.0469 - val_mae: 454.1862\n",
            "Epoch 43/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 584260.2500 - mae: 609.6726 - val_loss: 225615.7500 - val_mae: 454.4443\n",
            "Epoch 44/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 588190.5000 - mae: 610.0005 - val_loss: 227039.1094 - val_mae: 455.7206\n",
            "Epoch 45/2000\n",
            "39/39 [==============================] - 8s 202ms/step - loss: 595957.8750 - mae: 616.1175 - val_loss: 230202.0469 - val_mae: 459.3333\n",
            "Epoch 46/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 586678.7500 - mae: 610.8495 - val_loss: 225958.2969 - val_mae: 454.3734\n",
            "Epoch 47/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 590317.1250 - mae: 614.3080 - val_loss: 230479.3750 - val_mae: 459.3333\n",
            "Epoch 48/2000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 593335.5000 - mae: 615.0334 - val_loss: 229252.5000 - val_mae: 457.9864\n",
            "Epoch 49/2000\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 590080.4375 - mae: 613.1157 - val_loss: 227677.9531 - val_mae: 455.6613\n",
            "Epoch 50/2000\n",
            "39/39 [==============================] - 4s 77ms/step - loss: 580387.8125 - mae: 607.4135 - val_loss: 233801.8750 - val_mae: 462.6534\n",
            "Epoch 51/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 596230.5625 - mae: 617.5631 - val_loss: 235003.4375 - val_mae: 464.4153\n",
            "Epoch 52/2000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 585054.8750 - mae: 609.5139 - val_loss: 231186.1719 - val_mae: 459.3333\n",
            "Epoch 53/2000\n",
            "39/39 [==============================] - 8s 200ms/step - loss: 591931.9375 - mae: 614.6208 - val_loss: 228538.5625 - val_mae: 455.8943\n",
            "Epoch 54/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 583809.2500 - mae: 610.3472 - val_loss: 229385.9219 - val_mae: 457.3510\n",
            "Epoch 55/2000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 591045.6250 - mae: 615.9493 - val_loss: 231621.6250 - val_mae: 459.3333\n",
            "Epoch 56/2000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 588212.7500 - mae: 613.9702 - val_loss: 229984.9219 - val_mae: 457.6078\n",
            "Epoch 57/2000\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 579843.6875 - mae: 608.9073 - val_loss: 230436.6875 - val_mae: 457.8781\n",
            "Epoch 58/2000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 588570.5625 - mae: 613.0614 - val_loss: 231929.6094 - val_mae: 459.8976\n",
            "Epoch 59/2000\n",
            "39/39 [==============================] - 4s 78ms/step - loss: 588290.9375 - mae: 613.7973 - val_loss: 233556.2656 - val_mae: 461.3646\n",
            "Epoch 60/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 586712.4375 - mae: 612.6964 - val_loss: 230852.1719 - val_mae: 457.8413\n",
            "Epoch 61/2000\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 581551.5000 - mae: 610.9724 - val_loss: 232503.9219 - val_mae: 459.3333\n",
            "Epoch 62/2000\n",
            "39/39 [==============================] - 8s 203ms/step - loss: 572741.8125 - mae: 607.1683 - val_loss: 232987.2344 - val_mae: 459.6146\n",
            "Epoch 63/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 587712.1250 - mae: 613.7195 - val_loss: 231116.8750 - val_mae: 457.0208\n",
            "Epoch 64/2000\n",
            "39/39 [==============================] - 8s 212ms/step - loss: 579986.6250 - mae: 611.7314 - val_loss: 229722.5469 - val_mae: 455.4809\n",
            "Epoch 65/2000\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 580225.3125 - mae: 608.6942 - val_loss: 230876.9375 - val_mae: 457.2188\n",
            "Epoch 66/2000\n",
            "39/39 [==============================] - 9s 207ms/step - loss: 580992.8125 - mae: 612.9971 - val_loss: 233013.8750 - val_mae: 459.8014\n",
            "Epoch 67/2000\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 585202.3125 - mae: 612.9659 - val_loss: 231807.6719 - val_mae: 457.7585\n",
            "Epoch 68/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 579727.0000 - mae: 610.7544 - val_loss: 228681.1719 - val_mae: 453.8473\n",
            "Epoch 69/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 580266.5625 - mae: 610.3049 - val_loss: 228810.5469 - val_mae: 453.8237\n",
            "Epoch 70/2000\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 576371.1250 - mae: 609.8351 - val_loss: 232892.6250 - val_mae: 459.1918\n",
            "Epoch 71/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 578426.0625 - mae: 610.0015 - val_loss: 238287.7656 - val_mae: 465.0175\n",
            "Epoch 72/2000\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 576058.7500 - mae: 610.9924 - val_loss: 235786.0156 - val_mae: 460.9665\n",
            "Epoch 73/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 571304.5000 - mae: 606.0187 - val_loss: 235954.4219 - val_mae: 461.6458\n",
            "Epoch 74/2000\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 586576.9375 - mae: 615.7651 - val_loss: 235783.2031 - val_mae: 461.3646\n",
            "Epoch 75/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 575656.1875 - mae: 608.4192 - val_loss: 234936.6875 - val_mae: 459.6146\n",
            "Epoch 76/2000\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 575985.1875 - mae: 609.1093 - val_loss: 232731.2500 - val_mae: 457.3722\n",
            "Epoch 77/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 572642.7500 - mae: 608.6314 - val_loss: 243923.2656 - val_mae: 471.1230\n",
            "Epoch 78/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 576518.6250 - mae: 608.5287 - val_loss: 230327.4531 - val_mae: 453.8951\n",
            "Epoch 79/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 584613.1875 - mae: 615.1700 - val_loss: 235150.0000 - val_mae: 459.9307\n",
            "Epoch 80/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 580833.8750 - mae: 612.0431 - val_loss: 235719.6875 - val_mae: 459.6146\n",
            "Epoch 81/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 576173.4375 - mae: 611.3279 - val_loss: 227975.4531 - val_mae: 451.2419\n",
            "Epoch 82/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 573711.2500 - mae: 609.2586 - val_loss: 228102.3750 - val_mae: 451.2061\n",
            "Epoch 83/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 579270.6250 - mae: 614.1737 - val_loss: 234716.0469 - val_mae: 459.0399\n",
            "Epoch 84/2000\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 578526.2500 - mae: 611.3976 - val_loss: 234234.0469 - val_mae: 457.5596\n",
            "Epoch 85/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 572509.3750 - mae: 609.3013 - val_loss: 233708.0000 - val_mae: 456.9851\n",
            "Epoch 86/2000\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 570215.5000 - mae: 609.8583 - val_loss: 238475.7656 - val_mae: 461.4110\n",
            "Epoch 87/2000\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 579269.7500 - mae: 612.3147 - val_loss: 240736.0156 - val_mae: 464.8401\n",
            "Epoch 88/2000\n",
            "39/39 [==============================] - 5s 102ms/step - loss: 574820.8750 - mae: 610.5248 - val_loss: 241950.8750 - val_mae: 465.2860\n",
            "Epoch 89/2000\n",
            "39/39 [==============================] - 4s 78ms/step - loss: 579344.0000 - mae: 613.0502 - val_loss: 234979.5000 - val_mae: 457.5013\n",
            "Epoch 90/2000\n",
            "39/39 [==============================] - 9s 209ms/step - loss: 573380.5625 - mae: 609.2369 - val_loss: 237312.7969 - val_mae: 459.6146\n",
            "Epoch 91/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 580129.7500 - mae: 613.7379 - val_loss: 237471.2344 - val_mae: 459.6145\n",
            "Epoch 92/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 563677.6875 - mae: 605.6058 - val_loss: 239866.5469 - val_mae: 463.3958\n",
            "Epoch 93/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 580031.0000 - mae: 614.2004 - val_loss: 240018.0625 - val_mae: 463.3958\n",
            "Epoch 94/2000\n",
            "39/39 [==============================] - 8s 201ms/step - loss: 574113.3125 - mae: 611.9479 - val_loss: 236687.4844 - val_mae: 457.5833\n",
            "Epoch 95/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 574345.1250 - mae: 610.4128 - val_loss: 235541.6094 - val_mae: 457.1510\n",
            "Epoch 96/2000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 575812.1875 - mae: 612.7313 - val_loss: 239227.8281 - val_mae: 461.3646\n",
            "Epoch 97/2000\n",
            "39/39 [==============================] - 4s 79ms/step - loss: 575541.9375 - mae: 612.4189 - val_loss: 240397.6719 - val_mae: 461.5383\n",
            "Epoch 98/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 573896.0625 - mae: 612.3226 - val_loss: 238283.3750 - val_mae: 459.3333\n",
            "Epoch 99/2000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 566127.2500 - mae: 605.7611 - val_loss: 235564.6875 - val_mae: 455.6368\n",
            "Epoch 100/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 575791.9375 - mae: 614.1553 - val_loss: 239532.4531 - val_mae: 461.0833\n",
            "Epoch 101/2000\n",
            "39/39 [==============================] - 4s 79ms/step - loss: 572846.0000 - mae: 611.3522 - val_loss: 240051.9531 - val_mae: 461.3646\n",
            "Epoch 102/2000\n",
            "39/39 [==============================] - 8s 203ms/step - loss: 575875.8125 - mae: 613.1522 - val_loss: 239871.7500 - val_mae: 461.0833\n",
            "Epoch 103/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 567191.3125 - mae: 611.1749 - val_loss: 237855.6250 - val_mae: 457.3021\n",
            "Epoch 104/2000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 571785.4375 - mae: 611.5981 - val_loss: 236929.6094 - val_mae: 457.0478\n",
            "Epoch 105/2000\n",
            "39/39 [==============================] - 8s 203ms/step - loss: 574236.2500 - mae: 612.7173 - val_loss: 240714.7969 - val_mae: 461.3646\n",
            "Epoch 106/2000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 568255.8750 - mae: 611.3599 - val_loss: 238726.3125 - val_mae: 457.5833\n",
            "Epoch 107/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 566383.0000 - mae: 608.6618 - val_loss: 245598.7969 - val_mae: 467.4657\n",
            "Epoch 108/2000\n",
            "39/39 [==============================] - 8s 211ms/step - loss: 568862.7500 - mae: 608.6659 - val_loss: 242472.1250 - val_mae: 463.3958\n",
            "Epoch 109/2000\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 577093.6250 - mae: 616.2672 - val_loss: 244721.4375 - val_mae: 465.4583\n",
            "Epoch 110/2000\n",
            "39/39 [==============================] - 9s 204ms/step - loss: 564320.2500 - mae: 609.1974 - val_loss: 234568.8594 - val_mae: 452.8723\n",
            "Epoch 111/2000\n",
            "39/39 [==============================] - 8s 202ms/step - loss: 573314.3750 - mae: 612.9684 - val_loss: 241401.0469 - val_mae: 461.0833\n",
            "Epoch 112/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 571633.7500 - mae: 614.5135 - val_loss: 246491.2031 - val_mae: 465.8412\n",
            "Epoch 113/2000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 571626.0625 - mae: 612.8111 - val_loss: 235037.3750 - val_mae: 452.8018\n",
            "Epoch 114/2000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 572162.9375 - mae: 612.8328 - val_loss: 235551.8594 - val_mae: 453.0582\n",
            "Epoch 115/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 569926.3125 - mae: 611.8968 - val_loss: 238732.7031 - val_mae: 456.9189\n",
            "Epoch 116/2000\n",
            "39/39 [==============================] - 9s 209ms/step - loss: 568474.4375 - mae: 613.2949 - val_loss: 235865.7656 - val_mae: 453.0117\n",
            "Epoch 117/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 573457.3125 - mae: 614.2683 - val_loss: 240650.0781 - val_mae: 459.2076\n",
            "Epoch 118/2000\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 561568.0000 - mae: 609.2092 - val_loss: 241771.8906 - val_mae: 459.3333\n",
            "Epoch 119/2000\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 557433.2500 - mae: 605.5424 - val_loss: 238179.6875 - val_mae: 454.8412\n",
            "Epoch 120/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 562313.5000 - mae: 609.8878 - val_loss: 246760.2500 - val_mae: 465.5866\n",
            "Epoch 121/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 566784.1250 - mae: 610.0287 - val_loss: 241303.3750 - val_mae: 459.1620\n",
            "Epoch 122/2000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 551480.1250 - mae: 604.6668 - val_loss: 242457.6719 - val_mae: 459.3333\n",
            "Epoch 123/2000\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 569572.1250 - mae: 613.2586 - val_loss: 244005.6406 - val_mae: 459.8070\n",
            "Epoch 124/2000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 559520.1875 - mae: 608.2377 - val_loss: 243165.2031 - val_mae: 459.6146\n",
            "Epoch 125/2000\n",
            "39/39 [==============================] - 8s 203ms/step - loss: 575303.5625 - mae: 618.9880 - val_loss: 239522.3906 - val_mae: 455.0556\n",
            "Epoch 126/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 559055.5625 - mae: 607.2583 - val_loss: 249261.1250 - val_mae: 466.1602\n",
            "Epoch 127/2000\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 566350.2500 - mae: 613.5452 - val_loss: 245967.3906 - val_mae: 461.8826\n",
            "Epoch 128/2000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 562059.5625 - mae: 610.0980 - val_loss: 241734.9219 - val_mae: 458.5217\n",
            "Epoch 129/2000\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 557196.0625 - mae: 607.1525 - val_loss: 246099.6719 - val_mae: 463.3958\n",
            "Epoch 130/2000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 566203.4375 - mae: 612.3524 - val_loss: 247239.8750 - val_mae: 463.3022\n",
            "Epoch 131/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 566016.9375 - mae: 611.4720 - val_loss: 249985.0156 - val_mae: 467.7409\n",
            "Epoch 132/2000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 565293.0625 - mae: 612.1310 - val_loss: 244254.2031 - val_mae: 459.3333\n",
            "Epoch 133/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 562073.2500 - mae: 610.4427 - val_loss: 247976.6250 - val_mae: 463.7010\n",
            "Epoch 134/2000\n",
            "39/39 [==============================] - 4s 80ms/step - loss: 561408.5000 - mae: 610.3208 - val_loss: 246970.6250 - val_mae: 461.6805\n",
            "Epoch 135/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 568432.2500 - mae: 615.9453 - val_loss: 244785.2500 - val_mae: 459.3333\n",
            "Epoch 136/2000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 571101.9375 - mae: 617.8436 - val_loss: 248393.8594 - val_mae: 463.3697\n",
            "Epoch 137/2000\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 564939.7500 - mae: 612.9147 - val_loss: 246338.3281 - val_mae: 461.3646\n",
            "Epoch 138/2000\n",
            "39/39 [==============================] - 4s 76ms/step - loss: 565951.6875 - mae: 612.9861 - val_loss: 250462.7344 - val_mae: 466.0687\n",
            "Epoch 139/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 561955.2500 - mae: 610.8617 - val_loss: 243584.4531 - val_mae: 458.3987\n",
            "Epoch 140/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 567184.8125 - mae: 614.9766 - val_loss: 248497.0781 - val_mae: 462.0287\n",
            "Epoch 141/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 556027.0625 - mae: 608.0739 - val_loss: 243930.3281 - val_mae: 458.3761\n",
            "Epoch 142/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 557060.5000 - mae: 610.4096 - val_loss: 243293.4844 - val_mae: 456.6146\n",
            "Epoch 143/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 563360.4375 - mae: 612.6987 - val_loss: 244998.6250 - val_mae: 458.9157\n",
            "Epoch 144/2000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 557836.0000 - mae: 611.6695 - val_loss: 244826.1719 - val_mae: 458.6226\n",
            "Epoch 145/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 566119.8125 - mae: 614.4606 - val_loss: 244175.0000 - val_mae: 456.8625\n",
            "Epoch 146/2000\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 555196.3750 - mae: 610.1410 - val_loss: 244358.6250 - val_mae: 456.8510\n",
            "Epoch 147/2000\n",
            "39/39 [==============================] - 5s 95ms/step - loss: 559956.8750 - mae: 611.2651 - val_loss: 243025.6250 - val_mae: 454.5269\n",
            "Epoch 148/2000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 555033.9375 - mae: 608.9774 - val_loss: 243201.1719 - val_mae: 454.5160\n",
            "Epoch 149/2000\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 554237.6875 - mae: 609.7492 - val_loss: 247059.1719 - val_mae: 459.0521\n",
            "Epoch 150/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 559722.1250 - mae: 612.2564 - val_loss: 241380.6406 - val_mae: 452.2477\n",
            "Epoch 151/2000\n",
            "39/39 [==============================] - 8s 200ms/step - loss: 560731.6875 - mae: 612.0002 - val_loss: 244891.1719 - val_mae: 456.5142\n",
            "Epoch 152/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 557284.9375 - mae: 609.4365 - val_loss: 249151.3594 - val_mae: 461.3646\n",
            "Epoch 153/2000\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 559461.7500 - mae: 611.7559 - val_loss: 253713.4531 - val_mae: 464.7365\n",
            "Epoch 154/2000\n",
            "39/39 [==============================] - 5s 102ms/step - loss: 559973.1875 - mae: 615.3665 - val_loss: 247245.1250 - val_mae: 457.3021\n",
            "Epoch 155/2000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 556657.7500 - mae: 611.0696 - val_loss: 252692.0781 - val_mae: 464.2292\n",
            "Epoch 156/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 550110.9375 - mae: 610.1938 - val_loss: 243192.5625 - val_mae: 453.8643\n",
            "Epoch 157/2000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 558546.0625 - mae: 611.7194 - val_loss: 249957.6250 - val_mae: 461.0000\n",
            "Epoch 158/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 560338.6875 - mae: 612.7241 - val_loss: 245811.7969 - val_mae: 456.1544\n",
            "Epoch 159/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 553085.3750 - mae: 611.1324 - val_loss: 244079.6875 - val_mae: 454.0777\n",
            "Epoch 160/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 557503.2500 - mae: 612.7009 - val_loss: 246902.7969 - val_mae: 456.6947\n",
            "Epoch 161/2000\n",
            "39/39 [==============================] - 9s 209ms/step - loss: 556517.3750 - mae: 612.9042 - val_loss: 242573.4531 - val_mae: 451.4394\n",
            "Epoch 162/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 549980.3125 - mae: 608.4631 - val_loss: 254123.4844 - val_mae: 464.3070\n",
            "Epoch 163/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 552524.3125 - mae: 610.6862 - val_loss: 247115.6719 - val_mae: 456.3791\n",
            "Epoch 164/2000\n",
            "39/39 [==============================] - 8s 203ms/step - loss: 553861.7500 - mae: 609.6976 - val_loss: 250353.7344 - val_mae: 459.3333\n",
            "Epoch 165/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 558410.2500 - mae: 612.6983 - val_loss: 252796.0781 - val_mae: 463.3958\n",
            "Epoch 166/2000\n",
            "39/39 [==============================] - 8s 203ms/step - loss: 551269.6250 - mae: 608.6740 - val_loss: 246900.6250 - val_mae: 454.5969\n",
            "Epoch 167/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 556964.1875 - mae: 613.0178 - val_loss: 251692.4219 - val_mae: 461.0833\n",
            "Epoch 168/2000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 550453.2500 - mae: 608.7448 - val_loss: 244932.5781 - val_mae: 453.3153\n",
            "Epoch 169/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 549494.4375 - mae: 607.2121 - val_loss: 247466.7031 - val_mae: 454.5641\n",
            "Epoch 170/2000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 549035.0625 - mae: 606.9935 - val_loss: 255413.8594 - val_mae: 464.1138\n",
            "Epoch 171/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 550004.2500 - mae: 608.1858 - val_loss: 249349.2344 - val_mae: 458.0413\n",
            "Epoch 172/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 558240.7500 - mae: 614.5820 - val_loss: 246004.7969 - val_mae: 453.5087\n",
            "Epoch 173/2000\n",
            "39/39 [==============================] - 4s 74ms/step - loss: 556841.6250 - mae: 613.8217 - val_loss: 248978.7344 - val_mae: 456.2696\n",
            "Epoch 174/2000\n",
            "39/39 [==============================] - 4s 79ms/step - loss: 553302.7500 - mae: 611.2986 - val_loss: 246729.3906 - val_mae: 453.7458\n",
            "Epoch 175/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 550129.4375 - mae: 611.4984 - val_loss: 257810.9375 - val_mae: 466.1177\n",
            "Epoch 176/2000\n",
            "39/39 [==============================] - 9s 204ms/step - loss: 555265.8750 - mae: 612.8877 - val_loss: 248824.1719 - val_mae: 454.4864\n",
            "Epoch 177/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 550414.9375 - mae: 610.0959 - val_loss: 254417.8750 - val_mae: 461.6458\n",
            "Epoch 178/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 542933.4375 - mae: 608.0519 - val_loss: 249210.8594 - val_mae: 454.4645\n",
            "Epoch 179/2000\n",
            "39/39 [==============================] - 4s 76ms/step - loss: 546807.8125 - mae: 608.0079 - val_loss: 258771.6406 - val_mae: 466.5252\n",
            "Epoch 180/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 557487.2500 - mae: 614.2483 - val_loss: 249589.4375 - val_mae: 454.4432\n",
            "Epoch 181/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 546192.2500 - mae: 611.2026 - val_loss: 255564.3906 - val_mae: 460.1721\n",
            "Epoch 182/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 548562.0000 - mae: 609.8539 - val_loss: 245969.4531 - val_mae: 450.6979\n",
            "Epoch 183/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 552469.7500 - mae: 613.3054 - val_loss: 251636.5625 - val_mae: 456.7226\n",
            "Epoch 184/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 551327.1875 - mae: 612.8276 - val_loss: 259465.0469 - val_mae: 466.2987\n",
            "Epoch 185/2000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 557123.5625 - mae: 615.3884 - val_loss: 254594.2344 - val_mae: 459.3333\n",
            "Epoch 186/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 554686.1250 - mae: 614.0739 - val_loss: 255864.7500 - val_mae: 461.3646\n",
            "Epoch 187/2000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 547790.9375 - mae: 612.3662 - val_loss: 256065.5000 - val_mae: 461.3646\n",
            "Epoch 188/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 550219.2500 - mae: 613.5098 - val_loss: 251488.5469 - val_mae: 455.8252\n",
            "Epoch 189/2000\n",
            "39/39 [==============================] - 9s 204ms/step - loss: 546832.9375 - mae: 611.9918 - val_loss: 257920.9531 - val_mae: 463.6771\n",
            "Epoch 190/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 548898.4375 - mae: 611.8112 - val_loss: 255239.0000 - val_mae: 459.0521\n",
            "Epoch 191/2000\n",
            "39/39 [==============================] - 9s 206ms/step - loss: 549089.5625 - mae: 612.7447 - val_loss: 256201.6875 - val_mae: 459.6146\n",
            "Epoch 192/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 551846.4375 - mae: 613.6302 - val_loss: 252287.3281 - val_mae: 455.7811\n",
            "Epoch 193/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 550145.1250 - mae: 611.1759 - val_loss: 250583.2344 - val_mae: 453.6132\n",
            "Epoch 194/2000\n",
            "39/39 [==============================] - 9s 209ms/step - loss: 546001.6875 - mae: 609.2745 - val_loss: 250040.1406 - val_mae: 453.0276\n",
            "Epoch 195/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 548341.8125 - mae: 613.1042 - val_loss: 253256.6719 - val_mae: 456.0297\n",
            "Epoch 196/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 546992.7500 - mae: 612.1569 - val_loss: 258296.4219 - val_mae: 461.6458\n",
            "Epoch 197/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 538794.3125 - mae: 609.7017 - val_loss: 246829.5625 - val_mae: 448.1736\n",
            "Epoch 198/2000\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 547618.1250 - mae: 611.0120 - val_loss: 257954.2969 - val_mae: 461.0833\n",
            "Epoch 199/2000\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 547243.1250 - mae: 610.6368 - val_loss: 257125.7500 - val_mae: 459.0521\n",
            "Epoch 200/2000\n",
            "39/39 [==============================] - 4s 80ms/step - loss: 548520.2500 - mae: 612.8204 - val_loss: 254971.8281 - val_mae: 456.5399\n",
            "Epoch 201/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 544857.6250 - mae: 609.2620 - val_loss: 267643.2188 - val_mae: 471.8813\n",
            "Epoch 202/2000\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 551041.1250 - mae: 615.0216 - val_loss: 261240.4844 - val_mae: 462.4301\n",
            "Epoch 203/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 549766.2500 - mae: 614.6115 - val_loss: 260400.3281 - val_mae: 463.3958\n",
            "Epoch 204/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 546702.1250 - mae: 611.6771 - val_loss: 247342.2969 - val_mae: 447.3865\n",
            "Epoch 205/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 542260.6250 - mae: 611.3801 - val_loss: 260436.3906 - val_mae: 463.1146\n",
            "Epoch 206/2000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 552675.0000 - mae: 617.8642 - val_loss: 254006.2344 - val_mae: 453.6013\n",
            "Epoch 207/2000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 554698.2500 - mae: 618.3480 - val_loss: 259132.6406 - val_mae: 459.3333\n",
            "Epoch 208/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 545450.8750 - mae: 612.7476 - val_loss: 259378.8125 - val_mae: 459.3333\n",
            "Epoch 209/2000\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 545171.9375 - mae: 611.8129 - val_loss: 252434.7969 - val_mae: 452.4331\n",
            "Epoch 210/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 538220.7500 - mae: 607.7907 - val_loss: 261179.8281 - val_mae: 461.6458\n",
            "Epoch 211/2000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 542216.8750 - mae: 612.6019 - val_loss: 253568.3594 - val_mae: 452.9535\n",
            "Epoch 212/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 553822.4375 - mae: 618.8469 - val_loss: 261600.6094 - val_mae: 461.6458\n",
            "Epoch 213/2000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 547770.6875 - mae: 614.8075 - val_loss: 264024.8125 - val_mae: 462.8258\n",
            "Epoch 214/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 540215.8125 - mae: 610.9455 - val_loss: 256617.6250 - val_mae: 455.5500\n",
            "Epoch 215/2000\n",
            "39/39 [==============================] - 9s 208ms/step - loss: 546748.7500 - mae: 613.7350 - val_loss: 262246.2500 - val_mae: 461.6458\n",
            "Epoch 216/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 552979.5000 - mae: 618.2115 - val_loss: 257803.1094 - val_mae: 456.0902\n",
            "Epoch 217/2000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 546535.8750 - mae: 613.4551 - val_loss: 258390.7969 - val_mae: 456.3607\n",
            "Epoch 218/2000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 543841.1250 - mae: 612.2239 - val_loss: 258856.8125 - val_mae: 457.8186\n",
            "Epoch 219/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 543332.6875 - mae: 612.1432 - val_loss: 265993.1562 - val_mae: 464.6382\n",
            "Epoch 220/2000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 547176.1875 - mae: 615.1454 - val_loss: 263945.4062 - val_mae: 463.3958\n",
            "Epoch 221/2000\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 541179.8750 - mae: 613.8773 - val_loss: 263522.4062 - val_mae: 461.6458\n",
            "Epoch 222/2000\n",
            "39/39 [==============================] - 5s 99ms/step - loss: 538321.1250 - mae: 608.7346 - val_loss: 255329.7500 - val_mae: 452.4400\n",
            "Epoch 223/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 538093.2500 - mae: 610.3055 - val_loss: 258240.5469 - val_mae: 453.9856\n",
            "Epoch 224/2000\n",
            "39/39 [==============================] - 4s 78ms/step - loss: 546976.8125 - mae: 615.4110 - val_loss: 254717.6875 - val_mae: 450.3675\n",
            "Epoch 225/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 545490.8125 - mae: 614.6346 - val_loss: 255304.0156 - val_mae: 450.6271\n",
            "Epoch 226/2000\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 546823.8125 - mae: 615.4759 - val_loss: 263240.7188 - val_mae: 459.3333\n",
            "Epoch 227/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 543074.0000 - mae: 613.5192 - val_loss: 264450.5938 - val_mae: 461.3646\n",
            "Epoch 228/2000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 539411.0625 - mae: 611.2889 - val_loss: 263668.5000 - val_mae: 459.3333\n",
            "Epoch 229/2000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 546580.9375 - mae: 614.8671 - val_loss: 261105.5781 - val_mae: 457.7037\n",
            "Epoch 230/2000\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 539596.8125 - mae: 613.2957 - val_loss: 259323.5625 - val_mae: 453.6316\n",
            "Epoch 231/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 543062.3125 - mae: 613.8364 - val_loss: 261873.9375 - val_mae: 457.9655\n",
            "Epoch 232/2000\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 542572.8125 - mae: 614.6533 - val_loss: 256696.5469 - val_mae: 450.4822\n",
            "Epoch 233/2000\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 528221.3125 - mae: 606.5601 - val_loss: 265970.9062 - val_mae: 461.2812\n",
            "Epoch 234/2000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 540364.7500 - mae: 612.6585 - val_loss: 260741.0000 - val_mae: 455.3412\n",
            "Epoch 235/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 541901.8750 - mae: 613.6832 - val_loss: 267127.2500 - val_mae: 463.3958\n",
            "Epoch 236/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 542247.0000 - mae: 615.0539 - val_loss: 264012.5938 - val_mae: 457.0208\n",
            "Epoch 237/2000\n",
            "39/39 [==============================] - 8s 213ms/step - loss: 547202.1250 - mae: 617.7751 - val_loss: 270067.5000 - val_mae: 464.8249\n",
            "Epoch 238/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 540957.9375 - mae: 613.4940 - val_loss: 258471.0000 - val_mae: 452.1104\n",
            "Epoch 239/2000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 547442.7500 - mae: 618.2739 - val_loss: 271898.8438 - val_mae: 467.1589\n",
            "Epoch 240/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 540122.3125 - mae: 613.4579 - val_loss: 261801.0156 - val_mae: 453.8108\n",
            "Epoch 241/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 543104.7500 - mae: 614.0465 - val_loss: 271377.9062 - val_mae: 465.1476\n",
            "Epoch 242/2000\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 540647.9375 - mae: 615.0489 - val_loss: 263765.0000 - val_mae: 457.5717\n",
            "Epoch 243/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 538242.0625 - mae: 613.0798 - val_loss: 263401.2812 - val_mae: 455.8113\n",
            "Epoch 244/2000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 540053.2500 - mae: 613.2552 - val_loss: 267168.8438 - val_mae: 459.3333\n",
            "Epoch 245/2000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 538809.1875 - mae: 613.9020 - val_loss: 263238.4688 - val_mae: 454.0417\n",
            "Epoch 246/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 539117.1875 - mae: 612.7527 - val_loss: 267592.0938 - val_mae: 459.3333\n",
            "Epoch 247/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 540755.6250 - mae: 614.7717 - val_loss: 268776.7188 - val_mae: 461.3646\n",
            "Epoch 248/2000\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 539571.4375 - mae: 614.1678 - val_loss: 272972.2812 - val_mae: 465.2180\n",
            "Epoch 249/2000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 543543.6875 - mae: 616.3686 - val_loss: 268240.0938 - val_mae: 459.3333\n",
            "Epoch 250/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 536049.5625 - mae: 611.6971 - val_loss: 272456.4062 - val_mae: 463.2057\n",
            "Epoch 251/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 542644.0625 - mae: 617.9286 - val_loss: 269517.8125 - val_mae: 461.0000\n",
            "Epoch 252/2000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 536657.1250 - mae: 611.5082 - val_loss: 260292.3750 - val_mae: 449.7995\n",
            "Epoch 253/2000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 539731.4375 - mae: 614.6292 - val_loss: 270041.2500 - val_mae: 461.3646\n",
            "Epoch 254/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 535822.7500 - mae: 612.2582 - val_loss: 265693.6562 - val_mae: 455.7020\n",
            "Epoch 255/2000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 539119.5000 - mae: 614.2605 - val_loss: 274145.3125 - val_mae: 465.0049\n",
            "Epoch 256/2000\n",
            "39/39 [==============================] - 4s 106ms/step - loss: 542948.6875 - mae: 618.0864 - val_loss: 271091.1562 - val_mae: 461.6458\n",
            "Epoch 257/2000\n",
            "39/39 [==============================] - 4s 78ms/step - loss: 539088.4375 - mae: 615.4191 - val_loss: 276851.1562 - val_mae: 469.3681\n",
            "Epoch 258/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 538198.4375 - mae: 613.6830 - val_loss: 266524.7500 - val_mae: 455.6630\n",
            "Epoch 259/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 537773.9375 - mae: 615.3887 - val_loss: 262632.2188 - val_mae: 451.6927\n",
            "Epoch 260/2000\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 538353.4375 - mae: 614.1172 - val_loss: 270275.2812 - val_mae: 459.0521\n",
            "Epoch 261/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 537887.9375 - mae: 614.0721 - val_loss: 265433.1250 - val_mae: 453.0406\n",
            "Epoch 262/2000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 532111.3125 - mae: 613.9012 - val_loss: 266812.5938 - val_mae: 453.8748\n",
            "Epoch 263/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 536509.1875 - mae: 612.8948 - val_loss: 272620.1875 - val_mae: 461.6458\n",
            "Epoch 264/2000\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 540404.1875 - mae: 617.1426 - val_loss: 272064.8750 - val_mae: 461.0833\n",
            "Epoch 265/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 531486.6875 - mae: 613.2378 - val_loss: 268919.4688 - val_mae: 457.6257\n",
            "Epoch 266/2000\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 538136.5000 - mae: 617.0793 - val_loss: 268310.9688 - val_mae: 457.0551\n",
            "Epoch 267/2000\n",
            "39/39 [==============================] - 5s 103ms/step - loss: 539631.1250 - mae: 615.7064 - val_loss: 267998.1562 - val_mae: 455.2953\n",
            "Epoch 268/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 536306.0625 - mae: 617.3013 - val_loss: 268754.5312 - val_mae: 457.0345\n",
            "Epoch 269/2000\n",
            "39/39 [==============================] - 4s 104ms/step - loss: 534985.1250 - mae: 612.9937 - val_loss: 258737.9219 - val_mae: 444.8482\n",
            "Epoch 270/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 519457.9375 - mae: 604.6080 - val_loss: 272819.2812 - val_mae: 459.3333\n",
            "Epoch 271/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 526853.0625 - mae: 610.7903 - val_loss: 272538.1562 - val_mae: 457.5833\n",
            "Epoch 272/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 537198.8125 - mae: 615.8557 - val_loss: 271989.1875 - val_mae: 457.0208\n",
            "Epoch 273/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 537593.1250 - mae: 616.6395 - val_loss: 268854.2188 - val_mae: 454.9570\n",
            "Epoch 274/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 535890.0000 - mae: 615.6459 - val_loss: 279734.3750 - val_mae: 467.5001\n",
            "Epoch 275/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 535042.3750 - mae: 614.2097 - val_loss: 272633.8750 - val_mae: 457.0208\n",
            "Epoch 276/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 532978.0625 - mae: 612.9008 - val_loss: 270276.9375 - val_mae: 455.4908\n",
            "Epoch 277/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 537636.1875 - mae: 617.1886 - val_loss: 280422.5312 - val_mae: 467.5290\n",
            "Epoch 278/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 531173.7500 - mae: 612.8249 - val_loss: 274967.0625 - val_mae: 459.6146\n",
            "Epoch 279/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 531710.4375 - mae: 612.5992 - val_loss: 261446.9531 - val_mae: 445.1254\n",
            "Epoch 280/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 540625.1250 - mae: 619.1473 - val_loss: 283223.8125 - val_mae: 467.3752\n",
            "Epoch 281/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 528261.9375 - mae: 610.5783 - val_loss: 275262.8750 - val_mae: 459.3333\n",
            "Epoch 282/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 540073.1250 - mae: 619.0731 - val_loss: 270684.0000 - val_mae: 453.4016\n",
            "Epoch 283/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 529637.3750 - mae: 611.8675 - val_loss: 266194.6250 - val_mae: 448.9176\n",
            "Epoch 284/2000\n",
            "39/39 [==============================] - 6s 128ms/step - loss: 532846.5625 - mae: 613.9384 - val_loss: 286880.2188 - val_mae: 473.5480\n",
            "Epoch 285/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 534275.0625 - mae: 614.0167 - val_loss: 272616.0312 - val_mae: 456.7889\n",
            "Epoch 286/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 524330.1250 - mae: 609.4319 - val_loss: 272427.0312 - val_mae: 455.3948\n",
            "Epoch 287/2000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 527843.4375 - mae: 611.3243 - val_loss: 276588.4062 - val_mae: 459.3333\n",
            "Epoch 288/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 534489.2500 - mae: 615.6779 - val_loss: 281575.3438 - val_mae: 464.9566\n",
            "Epoch 289/2000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 532839.3125 - mae: 613.1264 - val_loss: 277924.5312 - val_mae: 461.3646\n",
            "Epoch 290/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 528243.6250 - mae: 612.0708 - val_loss: 272853.3438 - val_mae: 455.0773\n",
            "Epoch 291/2000\n",
            "39/39 [==============================] - 9s 209ms/step - loss: 521948.4062 - mae: 609.4017 - val_loss: 272202.1250 - val_mae: 453.0364\n",
            "Epoch 292/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 523086.4688 - mae: 609.7474 - val_loss: 279034.3438 - val_mae: 463.1146\n",
            "Epoch 293/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 531596.3125 - mae: 614.0422 - val_loss: 279180.2812 - val_mae: 461.6458\n",
            "Epoch 294/2000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 535038.2500 - mae: 618.4140 - val_loss: 274976.2188 - val_mae: 457.3522\n",
            "Epoch 295/2000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 530610.1250 - mae: 614.2535 - val_loss: 280118.8438 - val_mae: 463.3958\n",
            "Epoch 296/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 527604.7500 - mae: 612.8670 - val_loss: 279008.5000 - val_mae: 459.6146\n",
            "Epoch 297/2000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 532198.8750 - mae: 616.2816 - val_loss: 275209.8125 - val_mae: 457.0432\n",
            "Epoch 298/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 522556.2500 - mae: 608.8687 - val_loss: 269983.2188 - val_mae: 450.3086\n",
            "Epoch 299/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 536270.2500 - mae: 620.6345 - val_loss: 274302.8438 - val_mae: 453.2443\n",
            "Epoch 300/2000\n",
            "39/39 [==============================] - 8s 203ms/step - loss: 535518.2500 - mae: 617.4392 - val_loss: 270047.7500 - val_mae: 448.8850\n",
            "Epoch 301/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 529002.8750 - mae: 616.2943 - val_loss: 279720.4062 - val_mae: 459.3333\n",
            "Epoch 302/2000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 527219.6250 - mae: 614.0839 - val_loss: 275422.4062 - val_mae: 454.9657\n",
            "Epoch 303/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 536339.8125 - mae: 620.0925 - val_loss: 275642.7188 - val_mae: 454.9563\n",
            "Epoch 304/2000\n",
            "39/39 [==============================] - 4s 76ms/step - loss: 538858.1875 - mae: 623.2624 - val_loss: 275868.2188 - val_mae: 454.9466\n",
            "Epoch 305/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 534351.6875 - mae: 618.9853 - val_loss: 272332.6250 - val_mae: 451.1052\n",
            "Epoch 306/2000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 532463.6875 - mae: 617.2639 - val_loss: 271712.8125 - val_mae: 449.0540\n",
            "Epoch 307/2000\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 526106.8750 - mae: 615.2120 - val_loss: 284770.2188 - val_mae: 461.7155\n",
            "Epoch 308/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 525907.3750 - mae: 614.6492 - val_loss: 281288.4375 - val_mae: 459.3333\n",
            "Epoch 309/2000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 529328.2500 - mae: 615.8188 - val_loss: 273137.2188 - val_mae: 451.0337\n",
            "Epoch 310/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 524659.0625 - mae: 612.7045 - val_loss: 287957.9688 - val_mae: 467.8355\n",
            "Epoch 311/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 534220.3125 - mae: 619.2715 - val_loss: 268527.5625 - val_mae: 444.7972\n",
            "Epoch 312/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 520551.1250 - mae: 613.4932 - val_loss: 291810.5938 - val_mae: 470.0008\n",
            "Epoch 313/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 522238.4375 - mae: 611.5048 - val_loss: 284047.4375 - val_mae: 463.3958\n",
            "Epoch 314/2000\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 526285.2500 - mae: 614.8835 - val_loss: 281771.5312 - val_mae: 457.3021\n",
            "Epoch 315/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 527407.8125 - mae: 616.4422 - val_loss: 287054.0938 - val_mae: 463.5372\n",
            "Epoch 316/2000\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 527742.1875 - mae: 616.4233 - val_loss: 274167.5625 - val_mae: 450.6263\n",
            "Epoch 317/2000\n",
            "39/39 [==============================] - 4s 104ms/step - loss: 518087.9375 - mae: 612.2478 - val_loss: 278229.0000 - val_mae: 454.5484\n",
            "Epoch 318/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 524411.1250 - mae: 615.2923 - val_loss: 283102.4375 - val_mae: 459.0521\n",
            "Epoch 319/2000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 523229.5938 - mae: 612.8788 - val_loss: 278242.2188 - val_mae: 452.7805\n",
            "Epoch 320/2000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 526142.6875 - mae: 617.1010 - val_loss: 283981.7812 - val_mae: 459.3333\n",
            "Epoch 321/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 521888.5625 - mae: 614.3203 - val_loss: 284172.9688 - val_mae: 459.3333\n",
            "Epoch 322/2000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 534645.6875 - mae: 622.2090 - val_loss: 278495.2188 - val_mae: 452.4721\n",
            "Epoch 323/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 521144.5625 - mae: 612.3453 - val_loss: 270506.6250 - val_mae: 444.1925\n",
            "Epoch 324/2000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 531075.6875 - mae: 619.0039 - val_loss: 275833.1250 - val_mae: 450.4817\n",
            "Epoch 325/2000\n",
            "39/39 [==============================] - 4s 80ms/step - loss: 529638.6875 - mae: 618.9574 - val_loss: 276047.7188 - val_mae: 450.4632\n",
            "Epoch 326/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 529570.0625 - mae: 617.2167 - val_loss: 285347.5312 - val_mae: 459.3333\n",
            "Epoch 327/2000\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 530141.3750 - mae: 617.8614 - val_loss: 287583.4688 - val_mae: 463.6771\n",
            "Epoch 328/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 525991.3750 - mae: 615.3361 - val_loss: 292541.2812 - val_mae: 469.7486\n",
            "Epoch 329/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 528930.1875 - mae: 618.5722 - val_loss: 286405.4062 - val_mae: 461.0833\n",
            "Epoch 330/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 531993.6875 - mae: 620.4590 - val_loss: 280679.5938 - val_mae: 452.6807\n",
            "Epoch 331/2000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 528068.2500 - mae: 619.2482 - val_loss: 276097.4062 - val_mae: 448.0431\n",
            "Epoch 332/2000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 518932.5938 - mae: 612.8130 - val_loss: 291876.1562 - val_mae: 465.7220\n",
            "Epoch 333/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 530331.9375 - mae: 621.4217 - val_loss: 281295.1562 - val_mae: 452.6558\n",
            "Epoch 334/2000\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 528044.2500 - mae: 619.2122 - val_loss: 282328.0000 - val_mae: 454.6774\n",
            "Epoch 335/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 523986.3125 - mae: 616.1617 - val_loss: 277737.8750 - val_mae: 450.0028\n",
            "Epoch 336/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 522590.8438 - mae: 615.1183 - val_loss: 289167.9688 - val_mae: 463.3958\n",
            "Epoch 337/2000\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 523489.3125 - mae: 615.3956 - val_loss: 272921.3750 - val_mae: 443.5369\n",
            "Epoch 338/2000\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 527361.5000 - mae: 618.7986 - val_loss: 297296.2812 - val_mae: 468.4323\n",
            "Epoch 339/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 525897.5625 - mae: 617.6974 - val_loss: 278922.6562 - val_mae: 450.2187\n",
            "Epoch 340/2000\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 525086.0000 - mae: 617.2325 - val_loss: 273895.9062 - val_mae: 443.7444\n",
            "Epoch 341/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 522529.6250 - mae: 614.5164 - val_loss: 283440.6875 - val_mae: 452.8674\n",
            "Epoch 342/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 521954.9688 - mae: 615.5518 - val_loss: 279509.2188 - val_mae: 450.1696\n",
            "Epoch 343/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 525229.8125 - mae: 616.7436 - val_loss: 279656.3438 - val_mae: 449.7859\n",
            "Epoch 344/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 525926.3750 - mae: 618.0582 - val_loss: 285233.7188 - val_mae: 456.6229\n",
            "Epoch 345/2000\n",
            "39/39 [==============================] - 8s 203ms/step - loss: 517362.1875 - mae: 614.3694 - val_loss: 289556.2500 - val_mae: 459.3333\n",
            "Epoch 346/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 525644.0000 - mae: 618.6034 - val_loss: 285272.9688 - val_mae: 454.8567\n",
            "Epoch 347/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 528419.4375 - mae: 620.3271 - val_loss: 291462.0312 - val_mae: 463.0312\n",
            "Epoch 348/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 530254.5000 - mae: 623.1995 - val_loss: 284492.3750 - val_mae: 452.5282\n",
            "Epoch 349/2000\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 525575.7500 - mae: 620.0551 - val_loss: 296902.1562 - val_mae: 468.1784\n",
            "Epoch 350/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 522184.2500 - mae: 619.5820 - val_loss: 290201.4688 - val_mae: 459.0521\n",
            "Epoch 351/2000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 523327.0000 - mae: 617.7789 - val_loss: 281338.0312 - val_mae: 450.0177\n",
            "Epoch 352/2000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 524892.3125 - mae: 618.4836 - val_loss: 296397.3438 - val_mae: 465.8909\n",
            "Epoch 353/2000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 529510.9375 - mae: 622.0752 - val_loss: 301575.1250 - val_mae: 470.7135\n",
            "Epoch 354/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 526399.0000 - mae: 620.4752 - val_loss: 281971.3438 - val_mae: 449.9656\n",
            "Epoch 355/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 525234.0000 - mae: 620.3864 - val_loss: 287157.4688 - val_mae: 454.7821\n",
            "Epoch 356/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 528770.4375 - mae: 622.6590 - val_loss: 286971.8438 - val_mae: 454.4919\n",
            "Epoch 357/2000\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 521853.6562 - mae: 617.6757 - val_loss: 297515.3438 - val_mae: 465.9319\n",
            "Epoch 358/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 522116.2500 - mae: 618.0283 - val_loss: 287768.5938 - val_mae: 454.7582\n",
            "Epoch 359/2000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 528151.1875 - mae: 623.7889 - val_loss: 292600.9688 - val_mae: 459.3333\n",
            "Epoch 360/2000\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 525492.5625 - mae: 620.9295 - val_loss: 298613.3438 - val_mae: 466.2381\n",
            "Epoch 361/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 522406.8125 - mae: 618.9208 - val_loss: 283404.0000 - val_mae: 449.8488\n",
            "Epoch 362/2000\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 527681.5000 - mae: 623.0555 - val_loss: 294467.5938 - val_mae: 461.6458\n",
            "Epoch 363/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 515050.9375 - mae: 616.1968 - val_loss: 283066.2812 - val_mae: 447.7844\n",
            "Epoch 364/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 524978.1250 - mae: 621.0312 - val_loss: 289121.5000 - val_mae: 454.7055\n",
            "Epoch 365/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 522099.5625 - mae: 619.7233 - val_loss: 284224.2812 - val_mae: 449.7824\n",
            "Epoch 366/2000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 519614.3125 - mae: 619.8939 - val_loss: 290256.7500 - val_mae: 456.7215\n",
            "Epoch 367/2000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 518410.2500 - mae: 617.1850 - val_loss: 301671.4688 - val_mae: 469.9958\n",
            "Epoch 368/2000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 524342.2500 - mae: 621.2217 - val_loss: 293913.4062 - val_mae: 457.3021\n",
            "Epoch 369/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 527071.9375 - mae: 623.1452 - val_loss: 290198.5000 - val_mae: 454.6639\n",
            "Epoch 370/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 523890.1562 - mae: 621.1097 - val_loss: 301951.1250 - val_mae: 469.7400\n",
            "Epoch 371/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 523572.0938 - mae: 621.5364 - val_loss: 289475.3750 - val_mae: 452.3350\n",
            "Epoch 372/2000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 521966.1250 - mae: 620.7489 - val_loss: 286064.0938 - val_mae: 449.9496\n",
            "Epoch 373/2000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 518589.7500 - mae: 620.8198 - val_loss: 296885.8438 - val_mae: 461.6458\n",
            "Epoch 374/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 523372.9062 - mae: 621.1388 - val_loss: 285658.9062 - val_mae: 449.3529\n",
            "Epoch 375/2000\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 518697.7188 - mae: 617.7184 - val_loss: 302061.9688 - val_mae: 466.3623\n",
            "Epoch 376/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 521482.1562 - mae: 620.3563 - val_loss: 286078.0938 - val_mae: 449.3195\n",
            "Epoch 377/2000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 515333.5938 - mae: 616.5101 - val_loss: 285546.4062 - val_mae: 447.2730\n",
            "Epoch 378/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 521768.4062 - mae: 619.6832 - val_loss: 290970.0938 - val_mae: 452.2783\n",
            "Epoch 379/2000\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 510594.7812 - mae: 615.5798 - val_loss: 297483.9688 - val_mae: 459.6146\n",
            "Epoch 380/2000\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 521571.9688 - mae: 620.8911 - val_loss: 292128.4062 - val_mae: 454.2931\n",
            "Epoch 381/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 524138.8750 - mae: 621.8301 - val_loss: 291614.5312 - val_mae: 452.2541\n",
            "Epoch 382/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 522406.3125 - mae: 622.2483 - val_loss: 298396.1250 - val_mae: 461.0000\n",
            "Epoch 383/2000\n",
            "39/39 [==============================] - 4s 78ms/step - loss: 520897.8750 - mae: 621.2862 - val_loss: 294273.5312 - val_mae: 456.4972\n",
            "Epoch 384/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 521394.2500 - mae: 620.3232 - val_loss: 287450.5000 - val_mae: 447.4381\n",
            "Epoch 385/2000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 521069.0312 - mae: 621.1784 - val_loss: 288758.1875 - val_mae: 449.7369\n",
            "Epoch 386/2000\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 517065.0000 - mae: 619.6835 - val_loss: 294082.1250 - val_mae: 456.2773\n",
            "Epoch 387/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 518708.8125 - mae: 620.3358 - val_loss: 298145.0938 - val_mae: 457.3021\n",
            "Epoch 388/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 525632.2500 - mae: 624.0116 - val_loss: 299130.1250 - val_mae: 459.3333\n",
            "Epoch 389/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 523478.1562 - mae: 622.3470 - val_loss: 300448.3125 - val_mae: 461.6458\n",
            "Epoch 390/2000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 516823.5938 - mae: 618.8389 - val_loss: 305501.0312 - val_mae: 466.1214\n",
            "Epoch 391/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 517470.5938 - mae: 619.1673 - val_loss: 299810.2500 - val_mae: 459.3333\n",
            "Epoch 392/2000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 527791.8125 - mae: 627.6788 - val_loss: 295874.4062 - val_mae: 456.5070\n",
            "Epoch 393/2000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 509489.4062 - mae: 617.2220 - val_loss: 289832.2500 - val_mae: 447.5680\n",
            "Epoch 394/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 522637.5000 - mae: 624.0632 - val_loss: 302350.6562 - val_mae: 463.6771\n",
            "Epoch 395/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 522339.9688 - mae: 622.7012 - val_loss: 295426.9688 - val_mae: 454.1693\n",
            "Epoch 396/2000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 513050.3125 - mae: 617.5505 - val_loss: 296296.2188 - val_mae: 456.1941\n",
            "Epoch 397/2000\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 519592.5625 - mae: 622.0582 - val_loss: 291301.5625 - val_mae: 449.5399\n",
            "Epoch 398/2000\n",
            "39/39 [==============================] - 9s 204ms/step - loss: 518813.6562 - mae: 621.0854 - val_loss: 301384.4688 - val_mae: 459.3333\n",
            "Epoch 399/2000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 522015.9062 - mae: 623.2836 - val_loss: 296215.6250 - val_mae: 454.1402\n",
            "Epoch 400/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 516650.0938 - mae: 622.0879 - val_loss: 309236.9688 - val_mae: 470.6281\n",
            "Epoch 401/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 512436.4375 - mae: 617.3824 - val_loss: 291659.4062 - val_mae: 449.1987\n",
            "Epoch 402/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 518966.9062 - mae: 621.5188 - val_loss: 303573.3438 - val_mae: 463.3958\n",
            "Epoch 403/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 519301.6562 - mae: 621.6792 - val_loss: 298119.3750 - val_mae: 456.4233\n",
            "Epoch 404/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 524182.9062 - mae: 625.2323 - val_loss: 291577.5000 - val_mae: 447.1217\n",
            "Epoch 405/2000\n",
            "39/39 [==============================] - 9s 209ms/step - loss: 517021.7500 - mae: 621.4778 - val_loss: 303529.2188 - val_mae: 461.3646\n",
            "Epoch 406/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 521379.0938 - mae: 623.7058 - val_loss: 303007.7812 - val_mae: 458.9688\n",
            "Epoch 407/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 518117.7500 - mae: 622.7575 - val_loss: 297475.2188 - val_mae: 453.7971\n",
            "Epoch 408/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 517612.2812 - mae: 620.5820 - val_loss: 292001.0312 - val_mae: 446.7765\n",
            "Epoch 409/2000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 507998.4375 - mae: 618.1489 - val_loss: 292629.0312 - val_mae: 447.0425\n",
            "Epoch 410/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 519884.4062 - mae: 624.8824 - val_loss: 297832.3438 - val_mae: 452.0250\n",
            "Epoch 411/2000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 523004.5000 - mae: 624.9592 - val_loss: 299383.2188 - val_mae: 456.0800\n",
            "Epoch 412/2000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 522464.3750 - mae: 625.2524 - val_loss: 293642.7188 - val_mae: 447.2797\n",
            "Epoch 413/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 522727.7812 - mae: 625.4348 - val_loss: 312097.5312 - val_mae: 470.7273\n",
            "Epoch 414/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 519202.8125 - mae: 623.5795 - val_loss: 299372.0938 - val_mae: 454.0248\n",
            "Epoch 415/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 517723.9062 - mae: 622.0864 - val_loss: 294264.6875 - val_mae: 447.2333\n",
            "Epoch 416/2000\n",
            "39/39 [==============================] - 9s 209ms/step - loss: 517488.7812 - mae: 623.0772 - val_loss: 311004.0938 - val_mae: 466.4062\n",
            "Epoch 417/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 518304.5312 - mae: 623.6619 - val_loss: 294246.9688 - val_mae: 446.9216\n",
            "Epoch 418/2000\n",
            "39/39 [==============================] - 8s 202ms/step - loss: 510788.1875 - mae: 620.6508 - val_loss: 300836.0625 - val_mae: 456.0270\n",
            "Epoch 419/2000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 519075.7188 - mae: 624.2981 - val_loss: 306974.4688 - val_mae: 461.6458\n",
            "Epoch 420/2000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 522870.4375 - mae: 627.0486 - val_loss: 301273.4688 - val_mae: 456.0112\n",
            "Epoch 421/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 521610.3125 - mae: 625.4256 - val_loss: 301268.8125 - val_mae: 454.2531\n",
            "Epoch 422/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 517164.9688 - mae: 621.3103 - val_loss: 307660.0625 - val_mae: 461.6458\n",
            "Epoch 423/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 517127.2188 - mae: 623.4142 - val_loss: 301016.4062 - val_mae: 452.2075\n",
            "Epoch 424/2000\n",
            "39/39 [==============================] - 5s 101ms/step - loss: 518503.3750 - mae: 622.7080 - val_loss: 301875.1562 - val_mae: 454.2314\n",
            "Epoch 425/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 520524.0312 - mae: 624.9518 - val_loss: 307004.4688 - val_mae: 457.5833\n",
            "Epoch 426/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 518514.7188 - mae: 624.2641 - val_loss: 307674.6250 - val_mae: 461.0833\n",
            "Epoch 427/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 513088.4688 - mae: 621.8458 - val_loss: 297350.1250 - val_mae: 449.0845\n",
            "Epoch 428/2000\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 521070.3750 - mae: 626.5211 - val_loss: 307848.5312 - val_mae: 459.3333\n",
            "Epoch 429/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 512655.4688 - mae: 621.8892 - val_loss: 318853.9688 - val_mae: 469.8926\n",
            "Epoch 430/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 511139.1875 - mae: 621.6089 - val_loss: 304148.1875 - val_mae: 456.5012\n",
            "Epoch 431/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 509812.4375 - mae: 620.1470 - val_loss: 303970.0000 - val_mae: 456.2110\n",
            "Epoch 432/2000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 519678.8125 - mae: 625.5461 - val_loss: 313948.3438 - val_mae: 464.4952\n",
            "Epoch 433/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 509465.7812 - mae: 620.3839 - val_loss: 303514.8750 - val_mae: 455.6340\n",
            "Epoch 434/2000\n",
            "39/39 [==============================] - 5s 100ms/step - loss: 518186.6250 - mae: 625.3127 - val_loss: 303515.7812 - val_mae: 453.8766\n",
            "Epoch 435/2000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 508892.1250 - mae: 620.7542 - val_loss: 309994.2500 - val_mae: 461.3646\n",
            "Epoch 436/2000\n",
            "39/39 [==============================] - 10s 233ms/step - loss: 520263.1562 - mae: 625.9554 - val_loss: 316071.6562 - val_mae: 468.5859\n",
            "Epoch 437/2000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 515556.4062 - mae: 623.6980 - val_loss: 310447.9688 - val_mae: 461.3646\n",
            "Epoch 438/2000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 519088.8750 - mae: 626.6792 - val_loss: 298887.3750 - val_mae: 446.8941\n",
            "Epoch 439/2000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 518690.0312 - mae: 625.1503 - val_loss: 317131.7188 - val_mae: 468.8880\n",
            "Epoch 440/2000\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 515843.5625 - mae: 624.4651 - val_loss: 305603.9375 - val_mae: 454.3960\n",
            "Epoch 441/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 518292.0938 - mae: 625.7827 - val_loss: 305549.0312 - val_mae: 455.8584\n",
            "Epoch 442/2000\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 503214.8125 - mae: 617.9044 - val_loss: 312043.5312 - val_mae: 463.3958\n",
            "Epoch 443/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 515276.9062 - mae: 624.3638 - val_loss: 316710.8125 - val_mae: 464.8530\n",
            "Epoch 444/2000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 521807.1562 - mae: 628.9556 - val_loss: 305295.2812 - val_mae: 452.0573\n",
            "Epoch 445/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 512057.9375 - mae: 621.8552 - val_loss: 310991.7188 - val_mae: 459.0521\n",
            "Epoch 446/2000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 515227.4062 - mae: 623.8283 - val_loss: 307448.7812 - val_mae: 456.3845\n",
            "Epoch 447/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 513799.9062 - mae: 622.5248 - val_loss: 312516.0000 - val_mae: 461.3646\n",
            "Epoch 448/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 518139.5938 - mae: 625.2065 - val_loss: 313117.0938 - val_mae: 461.6458\n",
            "Epoch 449/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 506736.6250 - mae: 619.6663 - val_loss: 323290.5312 - val_mae: 470.1740\n",
            "Epoch 450/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 515217.5625 - mae: 624.9201 - val_loss: 307116.0312 - val_mae: 454.0470\n",
            "Epoch 451/2000\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 519718.4688 - mae: 627.4916 - val_loss: 306870.7188 - val_mae: 453.7592\n",
            "Epoch 452/2000\n",
            "39/39 [==============================] - 5s 100ms/step - loss: 515845.9062 - mae: 625.4143 - val_loss: 307534.2188 - val_mae: 454.0325\n",
            "Epoch 453/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 513968.4688 - mae: 624.0894 - val_loss: 324241.6250 - val_mae: 470.2336\n",
            "Epoch 454/2000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 508299.1875 - mae: 620.3093 - val_loss: 314524.2812 - val_mae: 463.3958\n",
            "Epoch 455/2000\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 511465.8750 - mae: 625.6492 - val_loss: 324650.4062 - val_mae: 470.2591\n",
            "Epoch 456/2000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 517845.0312 - mae: 626.3421 - val_loss: 301530.3438 - val_mae: 446.0802\n",
            "Epoch 457/2000\n",
            "39/39 [==============================] - 5s 114ms/step - loss: 518867.7188 - mae: 627.8568 - val_loss: 308104.7812 - val_mae: 453.7166\n",
            "Epoch 458/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 520622.9062 - mae: 628.8999 - val_loss: 315149.2812 - val_mae: 461.6458\n",
            "Epoch 459/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 509817.9375 - mae: 622.3969 - val_loss: 315356.9062 - val_mae: 461.6458\n",
            "Epoch 460/2000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 514426.8125 - mae: 626.1316 - val_loss: 304165.5625 - val_mae: 448.9038\n",
            "Epoch 461/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 512633.0000 - mae: 623.8239 - val_loss: 313637.8438 - val_mae: 457.0208\n",
            "Epoch 462/2000\n",
            "39/39 [==============================] - 5s 103ms/step - loss: 515529.4062 - mae: 626.2229 - val_loss: 314408.0938 - val_mae: 459.0521\n",
            "Epoch 463/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 512539.0312 - mae: 624.7883 - val_loss: 315064.0625 - val_mae: 459.3333\n",
            "Epoch 464/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 514497.7188 - mae: 624.6802 - val_loss: 315402.4688 - val_mae: 461.0833\n",
            "Epoch 465/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 516518.7500 - mae: 626.1318 - val_loss: 304626.0938 - val_mae: 448.5591\n",
            "Epoch 466/2000\n",
            "39/39 [==============================] - 9s 232ms/step - loss: 513672.6875 - mae: 624.9052 - val_loss: 316875.0938 - val_mae: 463.3958\n",
            "Epoch 467/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 512752.5625 - mae: 624.9263 - val_loss: 316601.4062 - val_mae: 463.1146\n",
            "Epoch 468/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 515007.5938 - mae: 626.4566 - val_loss: 304312.8125 - val_mae: 447.9571\n",
            "Epoch 469/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 513995.1875 - mae: 626.2344 - val_loss: 304919.7812 - val_mae: 448.2263\n",
            "Epoch 470/2000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 514066.9375 - mae: 626.1360 - val_loss: 310999.6250 - val_mae: 453.9137\n",
            "Epoch 471/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 512482.1562 - mae: 625.5439 - val_loss: 316043.5938 - val_mae: 457.3021\n",
            "Epoch 472/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 503856.5312 - mae: 621.2369 - val_loss: 316799.5938 - val_mae: 459.3333\n",
            "Epoch 473/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 510426.9688 - mae: 623.3297 - val_loss: 328346.6250 - val_mae: 470.4878\n",
            "Epoch 474/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 513608.7812 - mae: 625.4542 - val_loss: 317923.1250 - val_mae: 463.1146\n",
            "Epoch 475/2000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 517489.8750 - mae: 629.3861 - val_loss: 305413.4062 - val_mae: 446.1194\n",
            "Epoch 476/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 516486.9062 - mae: 627.8004 - val_loss: 317597.9062 - val_mae: 459.3333\n",
            "Epoch 477/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 508584.1562 - mae: 621.9902 - val_loss: 311877.8438 - val_mae: 453.5879\n",
            "Epoch 478/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 519231.4688 - mae: 630.6669 - val_loss: 318178.6250 - val_mae: 461.0833\n",
            "Epoch 479/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 516003.5000 - mae: 627.1019 - val_loss: 318837.7812 - val_mae: 461.3646\n",
            "Epoch 480/2000\n",
            "39/39 [==============================] - 4s 80ms/step - loss: 513299.5938 - mae: 625.5913 - val_loss: 311441.6875 - val_mae: 451.2559\n",
            "Epoch 481/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 512667.3438 - mae: 626.0236 - val_loss: 299716.9688 - val_mae: 439.7060\n",
            "Epoch 482/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 513618.1562 - mae: 625.5605 - val_loss: 324320.3125 - val_mae: 464.8293\n",
            "Epoch 483/2000\n",
            "39/39 [==============================] - 5s 115ms/step - loss: 514551.6875 - mae: 627.0436 - val_loss: 313457.5312 - val_mae: 453.8308\n",
            "Epoch 484/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 503789.0625 - mae: 621.6548 - val_loss: 313610.5625 - val_mae: 453.8257\n",
            "Epoch 485/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 515082.8125 - mae: 628.6298 - val_loss: 319949.0312 - val_mae: 461.3646\n",
            "Epoch 486/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 507614.4375 - mae: 624.4783 - val_loss: 307465.0625 - val_mae: 445.9774\n",
            "Epoch 487/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 514248.1562 - mae: 627.5605 - val_loss: 307659.0625 - val_mae: 445.9641\n",
            "Epoch 488/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 503517.5000 - mae: 621.2522 - val_loss: 326570.0938 - val_mae: 467.1807\n",
            "Epoch 489/2000\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 508647.6875 - mae: 624.8355 - val_loss: 314460.2188 - val_mae: 452.0431\n",
            "Epoch 490/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 507797.6875 - mae: 625.2561 - val_loss: 302178.1562 - val_mae: 440.0990\n",
            "Epoch 491/2000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 509758.0000 - mae: 624.3438 - val_loss: 321519.3125 - val_mae: 461.6458\n",
            "Epoch 492/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 507616.2188 - mae: 624.0151 - val_loss: 315575.8125 - val_mae: 454.0561\n",
            "Epoch 493/2000\n",
            "39/39 [==============================] - 3s 83ms/step - loss: 513702.8125 - mae: 627.1781 - val_loss: 315854.7812 - val_mae: 455.8009\n",
            "Epoch 494/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 511141.4375 - mae: 625.7523 - val_loss: 321615.1250 - val_mae: 461.3646\n",
            "Epoch 495/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 517872.7188 - mae: 630.8920 - val_loss: 321848.6250 - val_mae: 461.3646\n",
            "Epoch 496/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 516092.9062 - mae: 631.1285 - val_loss: 309675.4688 - val_mae: 446.1377\n",
            "Epoch 497/2000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 516499.7188 - mae: 629.4124 - val_loss: 315625.1562 - val_mae: 453.4627\n",
            "Epoch 498/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 516919.6250 - mae: 629.6950 - val_loss: 334655.5312 - val_mae: 474.8658\n",
            "Epoch 499/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 515050.5000 - mae: 629.6945 - val_loss: 316455.1250 - val_mae: 453.7311\n",
            "Epoch 500/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 508750.5938 - mae: 625.6583 - val_loss: 317190.9062 - val_mae: 455.7563\n",
            "Epoch 501/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 508238.3125 - mae: 626.4631 - val_loss: 316354.1875 - val_mae: 453.4386\n",
            "Epoch 502/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 512320.2500 - mae: 627.1246 - val_loss: 316994.7500 - val_mae: 453.7134\n",
            "Epoch 503/2000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 506320.7812 - mae: 624.2032 - val_loss: 328457.7500 - val_mae: 464.9581\n",
            "Epoch 504/2000\n",
            "39/39 [==============================] - 10s 230ms/step - loss: 513851.1875 - mae: 628.1151 - val_loss: 329711.7500 - val_mae: 468.6621\n",
            "Epoch 505/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 513129.7188 - mae: 628.0887 - val_loss: 311400.9062 - val_mae: 447.7779\n",
            "Epoch 506/2000\n",
            "39/39 [==============================] - 6s 147ms/step - loss: 511439.6250 - mae: 626.8756 - val_loss: 323912.8750 - val_mae: 461.3646\n",
            "Epoch 507/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 511625.5625 - mae: 627.1052 - val_loss: 323979.7812 - val_mae: 459.6146\n",
            "Epoch 508/2000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 512249.0000 - mae: 627.4093 - val_loss: 330485.6562 - val_mae: 469.0495\n",
            "Epoch 509/2000\n",
            "39/39 [==============================] - 6s 133ms/step - loss: 513562.4688 - mae: 629.3508 - val_loss: 316793.3125 - val_mae: 451.0793\n",
            "Epoch 510/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 513526.8125 - mae: 628.5992 - val_loss: 317990.1562 - val_mae: 453.3849\n",
            "Epoch 511/2000\n",
            "39/39 [==============================] - 4s 80ms/step - loss: 512695.2812 - mae: 627.8147 - val_loss: 311994.3438 - val_mae: 447.4264\n",
            "Epoch 512/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 513610.6250 - mae: 628.4249 - val_loss: 330783.1875 - val_mae: 467.0443\n",
            "Epoch 513/2000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 507828.5938 - mae: 625.1036 - val_loss: 318506.2500 - val_mae: 453.3680\n",
            "Epoch 514/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 514287.6875 - mae: 630.2042 - val_loss: 318597.2812 - val_mae: 451.6120\n",
            "Epoch 515/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 508452.0312 - mae: 625.8561 - val_loss: 318752.5938 - val_mae: 451.6070\n",
            "Epoch 516/2000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 516101.9062 - mae: 630.1361 - val_loss: 318600.5312 - val_mae: 453.0692\n",
            "Epoch 517/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 513400.5312 - mae: 629.3908 - val_loss: 319184.5938 - val_mae: 452.9801\n",
            "Epoch 518/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 518482.6250 - mae: 632.9339 - val_loss: 332843.8750 - val_mae: 469.3900\n",
            "Epoch 519/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 512671.8438 - mae: 628.0862 - val_loss: 332046.4062 - val_mae: 467.0830\n",
            "Epoch 520/2000\n",
            "39/39 [==============================] - 10s 229ms/step - loss: 515901.5312 - mae: 630.6321 - val_loss: 314453.7812 - val_mae: 447.8831\n",
            "Epoch 521/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 510208.6875 - mae: 626.8083 - val_loss: 325616.7188 - val_mae: 457.3021\n",
            "Epoch 522/2000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 507120.2188 - mae: 627.0999 - val_loss: 325839.0938 - val_mae: 459.0521\n",
            "Epoch 523/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 513686.5312 - mae: 629.9084 - val_loss: 321139.9688 - val_mae: 453.8739\n",
            "Epoch 524/2000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 510155.5625 - mae: 628.3289 - val_loss: 321862.5000 - val_mae: 455.8988\n",
            "Epoch 525/2000\n",
            "39/39 [==============================] - 5s 100ms/step - loss: 513404.0312 - mae: 628.4131 - val_loss: 326365.4688 - val_mae: 459.0521\n",
            "Epoch 526/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 512053.8438 - mae: 628.9771 - val_loss: 333844.4062 - val_mae: 469.1532\n",
            "Epoch 527/2000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 509594.8125 - mae: 627.0923 - val_loss: 327734.4062 - val_mae: 461.3646\n",
            "Epoch 528/2000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 510817.0000 - mae: 628.0851 - val_loss: 321586.8438 - val_mae: 453.5639\n",
            "Epoch 529/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 506236.1250 - mae: 625.1024 - val_loss: 327609.4688 - val_mae: 461.0833\n",
            "Epoch 530/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 506016.3125 - mae: 624.9203 - val_loss: 328195.0625 - val_mae: 461.3646\n",
            "Epoch 531/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 510925.2812 - mae: 628.3912 - val_loss: 327453.5625 - val_mae: 459.0521\n",
            "Epoch 532/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 498213.5000 - mae: 624.9255 - val_loss: 321335.6875 - val_mae: 452.9807\n",
            "Epoch 533/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 514607.3750 - mae: 631.8365 - val_loss: 321937.7812 - val_mae: 453.2570\n",
            "Epoch 534/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 511042.0000 - mae: 628.2056 - val_loss: 335273.5000 - val_mae: 469.1969\n",
            "Epoch 535/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 510337.0938 - mae: 627.3024 - val_loss: 328677.7812 - val_mae: 461.0833\n",
            "Epoch 536/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 498792.0938 - mae: 623.3327 - val_loss: 323368.0000 - val_mae: 453.8023\n",
            "Epoch 537/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 512117.5000 - mae: 628.3875 - val_loss: 323101.1250 - val_mae: 453.5153\n",
            "Epoch 538/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 505093.2812 - mae: 626.4741 - val_loss: 310586.4062 - val_mae: 439.5513\n",
            "Epoch 539/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 512276.1250 - mae: 629.0869 - val_loss: 323328.6562 - val_mae: 451.7560\n",
            "Epoch 540/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 515874.5000 - mae: 632.3993 - val_loss: 316774.4688 - val_mae: 447.1069\n",
            "Epoch 541/2000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 508725.5312 - mae: 626.9885 - val_loss: 330547.0938 - val_mae: 461.6458\n",
            "Epoch 542/2000\n",
            "39/39 [==============================] - 5s 98ms/step - loss: 510644.5000 - mae: 629.3969 - val_loss: 316588.8750 - val_mae: 445.0544\n",
            "Epoch 543/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 508743.8438 - mae: 627.4417 - val_loss: 342641.2188 - val_mae: 473.3416\n",
            "Epoch 544/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 513715.7188 - mae: 631.0283 - val_loss: 330079.4688 - val_mae: 459.3333\n",
            "Epoch 545/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 510764.0312 - mae: 628.4896 - val_loss: 337110.6562 - val_mae: 467.5043\n",
            "Epoch 546/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 506948.8125 - mae: 627.6464 - val_loss: 317713.9688 - val_mae: 445.2914\n",
            "Epoch 547/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 509632.3125 - mae: 628.8064 - val_loss: 325149.7812 - val_mae: 453.7456\n",
            "Epoch 548/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 512835.8750 - mae: 632.3115 - val_loss: 337198.7500 - val_mae: 467.2391\n",
            "Epoch 549/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 505979.0312 - mae: 628.1736 - val_loss: 331437.3750 - val_mae: 461.3646\n",
            "Epoch 550/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 507566.2188 - mae: 626.9008 - val_loss: 324720.2500 - val_mae: 453.1683\n",
            "Epoch 551/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 509246.4688 - mae: 629.3488 - val_loss: 318487.0312 - val_mae: 445.2411\n",
            "Epoch 552/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 515268.2500 - mae: 632.9032 - val_loss: 337404.0312 - val_mae: 465.2290\n",
            "Epoch 553/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 511306.9375 - mae: 631.3289 - val_loss: 319310.8125 - val_mae: 447.2511\n",
            "Epoch 554/2000\n",
            "39/39 [==============================] - 5s 113ms/step - loss: 508259.8750 - mae: 628.2855 - val_loss: 337738.7188 - val_mae: 465.2389\n",
            "Epoch 555/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 509106.9375 - mae: 628.1779 - val_loss: 313132.9688 - val_mae: 439.2938\n",
            "Epoch 556/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 509736.8750 - mae: 629.2814 - val_loss: 339532.1562 - val_mae: 471.3418\n",
            "Epoch 557/2000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 504308.9062 - mae: 626.6483 - val_loss: 332255.4375 - val_mae: 459.3333\n",
            "Epoch 558/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 513005.9062 - mae: 631.7370 - val_loss: 332380.2812 - val_mae: 459.3333\n",
            "Epoch 559/2000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 507687.4688 - mae: 627.1821 - val_loss: 333044.9062 - val_mae: 461.3646\n",
            "Epoch 560/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 511627.2500 - mae: 630.4938 - val_loss: 333242.0938 - val_mae: 461.3646\n",
            "Epoch 561/2000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 514676.7188 - mae: 632.7634 - val_loss: 314951.7188 - val_mae: 439.7644\n",
            "Epoch 562/2000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 506916.4375 - mae: 628.2433 - val_loss: 327092.4688 - val_mae: 453.3889\n",
            "Epoch 563/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 508089.5312 - mae: 628.7092 - val_loss: 326752.1250 - val_mae: 451.3531\n",
            "Epoch 564/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 512238.8125 - mae: 632.4839 - val_loss: 340287.3750 - val_mae: 467.5990\n",
            "Epoch 565/2000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 513544.5312 - mae: 632.5782 - val_loss: 334988.8438 - val_mae: 463.6771\n",
            "Epoch 566/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 507024.7812 - mae: 628.9619 - val_loss: 328226.4062 - val_mae: 455.3998\n",
            "Epoch 567/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 513598.0000 - mae: 632.2624 - val_loss: 333895.5938 - val_mae: 457.5833\n",
            "Epoch 568/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 510727.4688 - mae: 630.0977 - val_loss: 341541.5312 - val_mae: 469.2893\n",
            "Epoch 569/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 509686.6562 - mae: 629.9897 - val_loss: 321381.7188 - val_mae: 446.8062\n",
            "Epoch 570/2000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 511375.7812 - mae: 631.9986 - val_loss: 321056.8750 - val_mae: 446.5167\n",
            "Epoch 571/2000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 510426.9375 - mae: 630.0299 - val_loss: 342075.7500 - val_mae: 469.6689\n",
            "Epoch 572/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 509226.7188 - mae: 631.0177 - val_loss: 316243.5312 - val_mae: 439.3098\n",
            "Epoch 573/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 505632.8750 - mae: 628.4598 - val_loss: 315937.5312 - val_mae: 439.0141\n",
            "Epoch 574/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 510256.8750 - mae: 630.2411 - val_loss: 335580.7188 - val_mae: 459.6146\n",
            "Epoch 575/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 511384.4688 - mae: 630.4807 - val_loss: 334860.7188 - val_mae: 459.0521\n",
            "Epoch 576/2000\n",
            "39/39 [==============================] - 5s 99ms/step - loss: 513436.6562 - mae: 633.4464 - val_loss: 342486.4688 - val_mae: 467.6638\n",
            "Epoch 577/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 508221.0312 - mae: 631.8211 - val_loss: 336124.5938 - val_mae: 461.3646\n",
            "Epoch 578/2000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 509730.5000 - mae: 630.3097 - val_loss: 335783.7812 - val_mae: 459.3334\n",
            "Epoch 579/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 508275.4375 - mae: 628.7661 - val_loss: 335982.9062 - val_mae: 457.5833\n",
            "Epoch 580/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 509896.2500 - mae: 630.5850 - val_loss: 336605.2500 - val_mae: 459.6146\n",
            "Epoch 581/2000\n",
            "39/39 [==============================] - 5s 97ms/step - loss: 514841.7188 - mae: 635.2084 - val_loss: 343330.3125 - val_mae: 467.6886\n",
            "Epoch 582/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 510335.9375 - mae: 631.6921 - val_loss: 329969.3438 - val_mae: 453.0039\n",
            "Epoch 583/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 506424.8438 - mae: 629.4304 - val_loss: 337061.9062 - val_mae: 461.3645\n",
            "Epoch 584/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 506170.2500 - mae: 628.3293 - val_loss: 337665.5000 - val_mae: 461.6458\n",
            "Epoch 585/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 506530.9688 - mae: 629.8124 - val_loss: 324683.1562 - val_mae: 447.2151\n",
            "Epoch 586/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 502624.1562 - mae: 627.8109 - val_loss: 331376.2500 - val_mae: 455.3014\n",
            "Epoch 587/2000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 508551.1562 - mae: 630.2620 - val_loss: 337119.9062 - val_mae: 461.0833\n",
            "Epoch 588/2000\n",
            "39/39 [==============================] - 9s 231ms/step - loss: 508060.0938 - mae: 629.5212 - val_loss: 331198.8438 - val_mae: 453.2613\n",
            "Epoch 589/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 507005.6562 - mae: 629.5168 - val_loss: 330906.2188 - val_mae: 451.2248\n",
            "Epoch 590/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 514500.7500 - mae: 635.1567 - val_loss: 330614.2188 - val_mae: 450.9386\n",
            "Epoch 591/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 508871.7500 - mae: 631.0310 - val_loss: 344871.0938 - val_mae: 467.7336\n",
            "Epoch 592/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 506572.3438 - mae: 630.6204 - val_loss: 324789.8438 - val_mae: 446.5880\n",
            "Epoch 593/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 506376.3750 - mae: 628.7729 - val_loss: 332008.8750 - val_mae: 451.4862\n",
            "Epoch 594/2000\n",
            "39/39 [==============================] - 9s 208ms/step - loss: 503289.5625 - mae: 628.6058 - val_loss: 351960.5312 - val_mae: 475.8812\n",
            "Epoch 595/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 509148.1250 - mae: 630.8198 - val_loss: 331888.3438 - val_mae: 452.9449\n",
            "Epoch 596/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 509668.6562 - mae: 631.2303 - val_loss: 332003.0938 - val_mae: 451.1913\n",
            "Epoch 597/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 512754.5000 - mae: 634.1523 - val_loss: 332136.9375 - val_mae: 452.9372\n",
            "Epoch 598/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 505784.8750 - mae: 628.8883 - val_loss: 338403.2500 - val_mae: 457.3021\n",
            "Epoch 599/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 502928.5625 - mae: 629.9537 - val_loss: 339487.8750 - val_mae: 459.6146\n",
            "Epoch 600/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 512376.6875 - mae: 633.5781 - val_loss: 319794.0312 - val_mae: 438.6359\n",
            "Epoch 601/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 507359.3750 - mae: 631.0572 - val_loss: 332748.9062 - val_mae: 452.9185\n",
            "Epoch 602/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 511929.7812 - mae: 632.8194 - val_loss: 346133.2500 - val_mae: 467.5021\n",
            "Epoch 603/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 511552.3750 - mae: 634.1753 - val_loss: 346768.7188 - val_mae: 467.7886\n",
            "Epoch 604/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 509487.4375 - mae: 631.6743 - val_loss: 347332.0938 - val_mae: 469.4591\n",
            "Epoch 605/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 512646.0625 - mae: 634.1580 - val_loss: 346191.7812 - val_mae: 465.4855\n",
            "Epoch 606/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 510758.8125 - mae: 632.2508 - val_loss: 333476.6562 - val_mae: 452.8963\n",
            "Epoch 607/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 511615.2188 - mae: 633.2408 - val_loss: 320778.7188 - val_mae: 438.5404\n",
            "Epoch 608/2000\n",
            "39/39 [==============================] - 5s 93ms/step - loss: 506240.6250 - mae: 629.2075 - val_loss: 347041.0938 - val_mae: 467.5284\n",
            "Epoch 609/2000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 509295.6875 - mae: 632.7359 - val_loss: 340030.4688 - val_mae: 459.0520\n",
            "Epoch 610/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 511109.4375 - mae: 633.8468 - val_loss: 346816.5312 - val_mae: 465.5034\n",
            "Epoch 611/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 506718.5312 - mae: 632.2146 - val_loss: 340342.9688 - val_mae: 457.3021\n",
            "Epoch 612/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 510244.5938 - mae: 632.3552 - val_loss: 333801.2812 - val_mae: 450.8417\n",
            "Epoch 613/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 498279.0625 - mae: 626.8991 - val_loss: 341912.6562 - val_mae: 463.3958\n",
            "Epoch 614/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 501870.5312 - mae: 630.0114 - val_loss: 341162.0625 - val_mae: 461.0833\n",
            "Epoch 615/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 506536.9375 - mae: 630.5917 - val_loss: 321304.2812 - val_mae: 438.1643\n",
            "Epoch 616/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 505492.2812 - mae: 629.1273 - val_loss: 334369.4688 - val_mae: 450.8246\n",
            "Epoch 617/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 511184.3750 - mae: 633.8056 - val_loss: 329172.2812 - val_mae: 446.9321\n",
            "Epoch 618/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 507103.2812 - mae: 631.2499 - val_loss: 334649.3750 - val_mae: 450.8161\n",
            "Epoch 619/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 510047.0000 - mae: 633.3271 - val_loss: 329895.0312 - val_mae: 447.1968\n",
            "Epoch 620/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 506245.4375 - mae: 630.1732 - val_loss: 336247.0312 - val_mae: 455.1518\n",
            "Epoch 621/2000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 510680.3750 - mae: 632.8112 - val_loss: 342276.4688 - val_mae: 459.3333\n",
            "Epoch 622/2000\n",
            "39/39 [==============================] - 5s 101ms/step - loss: 499121.3125 - mae: 626.0002 - val_loss: 355807.0000 - val_mae: 474.0908\n",
            "Epoch 623/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 506683.3438 - mae: 631.6572 - val_loss: 342489.7188 - val_mae: 461.0833\n",
            "Epoch 624/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 509056.4688 - mae: 632.2667 - val_loss: 336865.9688 - val_mae: 455.1331\n",
            "Epoch 625/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 501051.0938 - mae: 628.4517 - val_loss: 330338.8438 - val_mae: 445.1112\n",
            "Epoch 626/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 505820.9062 - mae: 630.0619 - val_loss: 351043.5000 - val_mae: 471.9490\n",
            "Epoch 627/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 501392.1562 - mae: 628.5385 - val_loss: 337705.9688 - val_mae: 455.4027\n",
            "Epoch 628/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 508085.0625 - mae: 632.7051 - val_loss: 329350.3750 - val_mae: 444.2435\n",
            "Epoch 629/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 507689.0312 - mae: 631.9239 - val_loss: 329463.7188 - val_mae: 444.2365\n",
            "Epoch 630/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 502857.3125 - mae: 628.9110 - val_loss: 336327.9375 - val_mae: 452.5149\n",
            "Epoch 631/2000\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 506511.1562 - mae: 631.2812 - val_loss: 343651.7188 - val_mae: 459.3333\n",
            "Epoch 632/2000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 511374.5938 - mae: 634.5190 - val_loss: 357296.0000 - val_mae: 474.1733\n",
            "Epoch 633/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 505022.4375 - mae: 630.5273 - val_loss: 344440.4062 - val_mae: 459.6146\n",
            "Epoch 634/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 503338.6562 - mae: 629.1317 - val_loss: 350841.2500 - val_mae: 467.6371\n",
            "Epoch 635/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 504903.8438 - mae: 632.5533 - val_loss: 337453.7812 - val_mae: 452.7761\n",
            "Epoch 636/2000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 510466.6562 - mae: 633.4496 - val_loss: 337975.3438 - val_mae: 454.8044\n",
            "Epoch 637/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 507367.6250 - mae: 632.4340 - val_loss: 330924.2812 - val_mae: 444.4562\n",
            "Epoch 638/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 511410.6250 - mae: 635.8887 - val_loss: 337846.3438 - val_mae: 452.7644\n",
            "Epoch 639/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 508857.1875 - mae: 634.8088 - val_loss: 345236.5625 - val_mae: 459.6146\n",
            "Epoch 640/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 509885.9062 - mae: 633.9364 - val_loss: 344938.5938 - val_mae: 458.9688\n",
            "Epoch 641/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 508749.9062 - mae: 634.7172 - val_loss: 345056.6562 - val_mae: 459.3333\n",
            "Epoch 642/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 507169.9375 - mae: 632.0970 - val_loss: 338401.2500 - val_mae: 452.7478\n",
            "Epoch 643/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 507080.8750 - mae: 633.1026 - val_loss: 338515.1562 - val_mae: 452.7444\n",
            "Epoch 644/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 507968.5625 - mae: 633.1708 - val_loss: 338739.1562 - val_mae: 450.9890\n",
            "Epoch 645/2000\n",
            "39/39 [==============================] - 5s 119ms/step - loss: 503993.8750 - mae: 630.9529 - val_loss: 345525.7500 - val_mae: 461.0833\n",
            "Epoch 646/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 507071.5938 - mae: 631.9545 - val_loss: 338919.4688 - val_mae: 452.7323\n",
            "Epoch 647/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 512653.2812 - mae: 636.7437 - val_loss: 338671.4062 - val_mae: 450.6962\n",
            "Epoch 648/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 499945.0000 - mae: 629.5213 - val_loss: 346432.5938 - val_mae: 459.6146\n",
            "Epoch 649/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 506063.8438 - mae: 632.1873 - val_loss: 331992.2188 - val_mae: 444.0814\n",
            "Epoch 650/2000\n",
            "39/39 [==============================] - 6s 130ms/step - loss: 509403.6562 - mae: 634.1808 - val_loss: 345774.7188 - val_mae: 459.0521\n",
            "Epoch 651/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 506906.2500 - mae: 633.9697 - val_loss: 339969.2812 - val_mae: 452.9961\n",
            "Epoch 652/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 506499.2188 - mae: 632.1346 - val_loss: 353306.6562 - val_mae: 467.7068\n",
            "Epoch 653/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 510974.3125 - mae: 634.9788 - val_loss: 339321.4062 - val_mae: 452.4254\n",
            "Epoch 654/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 501481.8438 - mae: 630.2706 - val_loss: 326760.0938 - val_mae: 437.9701\n",
            "Epoch 655/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 504461.5938 - mae: 630.9394 - val_loss: 340059.7188 - val_mae: 452.6985\n",
            "Epoch 656/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 509661.5312 - mae: 634.6731 - val_loss: 340694.4375 - val_mae: 451.2262\n",
            "Epoch 657/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 508243.8125 - mae: 634.5773 - val_loss: 333896.1562 - val_mae: 445.9654\n",
            "Epoch 658/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 501389.9062 - mae: 631.0873 - val_loss: 333150.9062 - val_mae: 444.0109\n",
            "Epoch 659/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 501718.0000 - mae: 629.1274 - val_loss: 354231.0312 - val_mae: 467.7328\n",
            "Epoch 660/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 509220.9688 - mae: 634.6695 - val_loss: 340269.8438 - val_mae: 450.6490\n",
            "Epoch 661/2000\n",
            "39/39 [==============================] - 5s 98ms/step - loss: 504993.0312 - mae: 631.2358 - val_loss: 333972.6875 - val_mae: 444.2703\n",
            "Epoch 662/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 510652.8125 - mae: 635.4237 - val_loss: 340451.0000 - val_mae: 452.3919\n",
            "Epoch 663/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 511027.9688 - mae: 635.4630 - val_loss: 347488.6562 - val_mae: 457.3021\n",
            "Epoch 664/2000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 504934.1250 - mae: 632.3252 - val_loss: 341147.2812 - val_mae: 452.6663\n",
            "Epoch 665/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 510862.3750 - mae: 636.2199 - val_loss: 341277.9688 - val_mae: 450.9142\n",
            "Epoch 666/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 510983.6250 - mae: 635.3063 - val_loss: 342258.7500 - val_mae: 454.9715\n",
            "Epoch 667/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 510982.8438 - mae: 635.4315 - val_loss: 355627.1250 - val_mae: 469.7919\n",
            "Epoch 668/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 507648.0938 - mae: 633.2747 - val_loss: 355430.1562 - val_mae: 466.0145\n",
            "Epoch 669/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 501603.4375 - mae: 631.9078 - val_loss: 342182.0625 - val_mae: 454.6787\n",
            "Epoch 670/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 493405.2812 - mae: 626.9611 - val_loss: 348302.3438 - val_mae: 459.0521\n",
            "Epoch 671/2000\n",
            "39/39 [==============================] - 5s 99ms/step - loss: 500889.7812 - mae: 630.8015 - val_loss: 356983.1250 - val_mae: 472.1183\n",
            "Epoch 672/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 507521.5625 - mae: 633.3281 - val_loss: 349805.7812 - val_mae: 463.3958\n",
            "Epoch 673/2000\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 508173.5312 - mae: 633.1152 - val_loss: 343178.5312 - val_mae: 453.2356\n",
            "Epoch 674/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 507170.6562 - mae: 633.1176 - val_loss: 342841.7812 - val_mae: 453.0401\n",
            "Epoch 675/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 505612.8125 - mae: 633.5073 - val_loss: 336022.1250 - val_mae: 446.4066\n",
            "Epoch 676/2000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 506725.8438 - mae: 634.0164 - val_loss: 341747.9688 - val_mae: 450.6123\n",
            "Epoch 677/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 509070.2812 - mae: 635.3374 - val_loss: 343606.4062 - val_mae: 455.3058\n",
            "Epoch 678/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 507667.5938 - mae: 633.5211 - val_loss: 349822.7188 - val_mae: 459.8177\n",
            "Epoch 679/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 504875.5625 - mae: 632.0396 - val_loss: 343387.9688 - val_mae: 455.1840\n",
            "Epoch 680/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 509643.0312 - mae: 635.2197 - val_loss: 343582.0312 - val_mae: 453.5390\n",
            "Epoch 681/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 506457.0938 - mae: 632.7302 - val_loss: 336819.4375 - val_mae: 445.1673\n",
            "Epoch 682/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 508552.7188 - mae: 635.1245 - val_loss: 343728.6250 - val_mae: 455.4046\n",
            "Epoch 683/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 506162.6250 - mae: 633.7551 - val_loss: 357254.8438 - val_mae: 468.6421\n",
            "Epoch 684/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 511342.0000 - mae: 637.3978 - val_loss: 350512.4688 - val_mae: 460.2881\n",
            "Epoch 685/2000\n",
            "39/39 [==============================] - 5s 103ms/step - loss: 505468.1875 - mae: 632.4617 - val_loss: 337277.1562 - val_mae: 445.4824\n",
            "Epoch 686/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 507951.2812 - mae: 634.1735 - val_loss: 350725.3750 - val_mae: 460.4331\n",
            "Epoch 687/2000\n",
            "39/39 [==============================] - 9s 232ms/step - loss: 506498.8750 - mae: 633.8156 - val_loss: 344726.7188 - val_mae: 456.0306\n",
            "Epoch 688/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 505880.7812 - mae: 632.7265 - val_loss: 350975.6250 - val_mae: 460.6034\n",
            "Epoch 689/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 506079.2812 - mae: 633.0925 - val_loss: 351839.7188 - val_mae: 464.6183\n",
            "Epoch 690/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 508568.5312 - mae: 635.1704 - val_loss: 343360.1875 - val_mae: 451.7386\n",
            "Epoch 691/2000\n",
            "39/39 [==============================] - 10s 233ms/step - loss: 505060.9062 - mae: 632.3832 - val_loss: 344379.9062 - val_mae: 452.3629\n",
            "Epoch 692/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 514141.8125 - mae: 639.6003 - val_loss: 337912.9688 - val_mae: 447.6600\n",
            "Epoch 693/2000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 503232.6250 - mae: 632.2977 - val_loss: 338065.5000 - val_mae: 446.0237\n",
            "Epoch 694/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 507078.1562 - mae: 634.0828 - val_loss: 352089.0000 - val_mae: 461.3244\n",
            "Epoch 695/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 504771.1875 - mae: 632.4095 - val_loss: 345128.0625 - val_mae: 456.3081\n",
            "Epoch 696/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 506259.8125 - mae: 633.4650 - val_loss: 365392.7188 - val_mae: 474.4739\n",
            "Epoch 697/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 506491.2500 - mae: 633.5186 - val_loss: 352378.8438 - val_mae: 463.2470\n",
            "Epoch 698/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 503304.4688 - mae: 633.1794 - val_loss: 345934.9688 - val_mae: 455.0855\n",
            "Epoch 699/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 509699.6562 - mae: 637.9600 - val_loss: 352554.3438 - val_mae: 463.3615\n",
            "Epoch 700/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 503104.4688 - mae: 632.0643 - val_loss: 352622.6250 - val_mae: 463.4060\n",
            "Epoch 701/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 503483.0938 - mae: 634.4285 - val_loss: 345852.9375 - val_mae: 453.3427\n",
            "Epoch 702/2000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 503753.6250 - mae: 633.4194 - val_loss: 352013.3438 - val_mae: 461.3418\n",
            "Epoch 703/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 509277.9062 - mae: 636.7424 - val_loss: 352606.6250 - val_mae: 461.7089\n",
            "Epoch 704/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 498908.1250 - mae: 629.2910 - val_loss: 345632.1250 - val_mae: 456.6505\n",
            "Epoch 705/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 503789.1875 - mae: 632.2683 - val_loss: 351947.8438 - val_mae: 459.6245\n",
            "Epoch 706/2000\n",
            "39/39 [==============================] - 9s 209ms/step - loss: 509907.5000 - mae: 636.8310 - val_loss: 352890.4062 - val_mae: 461.9005\n",
            "Epoch 707/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 508939.4062 - mae: 636.3116 - val_loss: 353391.8438 - val_mae: 463.9069\n",
            "Epoch 708/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 508959.5312 - mae: 636.0620 - val_loss: 346935.5312 - val_mae: 457.4502\n",
            "Epoch 709/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 507741.1875 - mae: 635.8253 - val_loss: 339261.1875 - val_mae: 446.8784\n",
            "Epoch 710/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 508286.6875 - mae: 636.2123 - val_loss: 354214.5000 - val_mae: 464.4193\n",
            "Epoch 711/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 508341.9062 - mae: 635.8199 - val_loss: 347355.3750 - val_mae: 456.0311\n",
            "Epoch 712/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 504600.3750 - mae: 632.9402 - val_loss: 360266.1562 - val_mae: 467.2907\n",
            "Epoch 713/2000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 504208.7188 - mae: 633.7112 - val_loss: 347125.1250 - val_mae: 455.9071\n",
            "Epoch 714/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 512028.2500 - mae: 638.9470 - val_loss: 339299.5312 - val_mae: 446.9414\n",
            "Epoch 715/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 504339.4375 - mae: 633.4828 - val_loss: 354301.1562 - val_mae: 464.4973\n",
            "Epoch 716/2000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 503750.9062 - mae: 632.3555 - val_loss: 340424.9062 - val_mae: 447.6335\n",
            "Epoch 717/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 497568.9375 - mae: 630.0081 - val_loss: 340482.2812 - val_mae: 447.6724\n",
            "Epoch 718/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 510031.4688 - mae: 637.4170 - val_loss: 362327.1562 - val_mae: 475.0426\n",
            "Epoch 719/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 508773.5000 - mae: 637.2139 - val_loss: 354629.6562 - val_mae: 464.7101\n",
            "Epoch 720/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 507591.3125 - mae: 635.3752 - val_loss: 354724.9062 - val_mae: 464.5603\n",
            "Epoch 721/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 509348.1250 - mae: 636.9182 - val_loss: 355725.4688 - val_mae: 467.0390\n",
            "Epoch 722/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 507628.2812 - mae: 635.3809 - val_loss: 347655.1562 - val_mae: 454.6252\n",
            "Epoch 723/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 504526.3125 - mae: 633.4592 - val_loss: 347275.1562 - val_mae: 454.4044\n",
            "Epoch 724/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 504898.1875 - mae: 634.2536 - val_loss: 348159.5938 - val_mae: 456.5924\n",
            "Epoch 725/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 508932.5000 - mae: 637.0804 - val_loss: 361584.7500 - val_mae: 469.8767\n",
            "Epoch 726/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 508318.8438 - mae: 636.1264 - val_loss: 333449.9688 - val_mae: 440.9192\n",
            "Epoch 727/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 504012.9688 - mae: 634.9621 - val_loss: 355474.4688 - val_mae: 466.9022\n",
            "Epoch 728/2000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 509391.0625 - mae: 637.3190 - val_loss: 349151.2188 - val_mae: 457.0340\n",
            "Epoch 729/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 506244.0938 - mae: 634.6643 - val_loss: 362062.0312 - val_mae: 470.0185\n",
            "Epoch 730/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 509263.7812 - mae: 637.0721 - val_loss: 349298.0938 - val_mae: 458.9551\n",
            "Epoch 731/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 504928.3125 - mae: 633.7395 - val_loss: 355679.2188 - val_mae: 463.7738\n",
            "Epoch 732/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 507343.2188 - mae: 636.1675 - val_loss: 349149.1562 - val_mae: 457.2455\n",
            "Epoch 733/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 506573.3750 - mae: 636.0616 - val_loss: 355385.7500 - val_mae: 463.4395\n",
            "Epoch 734/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 505692.9688 - mae: 634.7742 - val_loss: 355830.4688 - val_mae: 465.5063\n",
            "Epoch 735/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 509796.4375 - mae: 638.2289 - val_loss: 341928.9062 - val_mae: 448.6866\n",
            "Epoch 736/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 499844.7188 - mae: 632.9982 - val_loss: 370668.2500 - val_mae: 481.2815\n",
            "Epoch 737/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 505893.8438 - mae: 634.7388 - val_loss: 356461.2500 - val_mae: 467.5138\n",
            "Epoch 738/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 507034.9375 - mae: 635.5575 - val_loss: 363315.6250 - val_mae: 472.6365\n",
            "Epoch 739/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 505753.4062 - mae: 634.3318 - val_loss: 349740.5000 - val_mae: 457.6346\n",
            "Epoch 740/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 505154.9375 - mae: 634.2092 - val_loss: 356072.5938 - val_mae: 464.0685\n",
            "Epoch 741/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 509034.6562 - mae: 636.8861 - val_loss: 349492.5625 - val_mae: 457.4989\n",
            "Epoch 742/2000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 509390.3125 - mae: 637.4822 - val_loss: 342122.2500 - val_mae: 448.8518\n",
            "Epoch 743/2000\n",
            "39/39 [==============================] - 5s 102ms/step - loss: 508737.7812 - mae: 637.8482 - val_loss: 342179.8438 - val_mae: 448.8905\n",
            "Epoch 744/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 508251.5625 - mae: 636.8070 - val_loss: 357598.1562 - val_mae: 468.2073\n",
            "Epoch 745/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 506499.2500 - mae: 635.6174 - val_loss: 357343.7812 - val_mae: 466.4583\n",
            "Epoch 746/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 508247.6250 - mae: 636.9846 - val_loss: 364635.4688 - val_mae: 473.4713\n",
            "Epoch 747/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 508849.2500 - mae: 636.5962 - val_loss: 364257.9062 - val_mae: 473.2500\n",
            "Epoch 748/2000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 502589.1875 - mae: 632.3723 - val_loss: 364028.9062 - val_mae: 471.5292\n",
            "Epoch 749/2000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 501170.1562 - mae: 635.1553 - val_loss: 357427.6250 - val_mae: 464.9388\n",
            "Epoch 750/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 501416.4062 - mae: 632.0139 - val_loss: 350670.4688 - val_mae: 459.8381\n",
            "Epoch 751/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 506455.4688 - mae: 636.1147 - val_loss: 350880.5312 - val_mae: 458.3822\n",
            "Epoch 752/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 506405.0625 - mae: 635.7366 - val_loss: 364065.9062 - val_mae: 469.9993\n",
            "Epoch 753/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 511552.9375 - mae: 639.9417 - val_loss: 350797.2500 - val_mae: 456.7695\n",
            "Epoch 754/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 506658.5000 - mae: 635.7508 - val_loss: 358740.1562 - val_mae: 467.3321\n",
            "Epoch 755/2000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 507141.0312 - mae: 636.7590 - val_loss: 358358.3750 - val_mae: 467.1075\n",
            "Epoch 756/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 509431.9062 - mae: 637.7433 - val_loss: 350812.1562 - val_mae: 459.9423\n",
            "Epoch 757/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 503864.0000 - mae: 633.5311 - val_loss: 365624.6562 - val_mae: 475.6881\n",
            "Epoch 758/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 497369.3750 - mae: 632.6466 - val_loss: 358634.1562 - val_mae: 467.2835\n",
            "Epoch 759/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 506809.6875 - mae: 636.2450 - val_loss: 358425.3438 - val_mae: 465.6003\n",
            "Epoch 760/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 497654.8438 - mae: 633.2585 - val_loss: 365555.3750 - val_mae: 474.0916\n",
            "Epoch 761/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 505647.7500 - mae: 635.5389 - val_loss: 351883.4062 - val_mae: 459.0374\n",
            "Epoch 762/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 504621.4375 - mae: 635.2261 - val_loss: 366252.7812 - val_mae: 474.5194\n",
            "Epoch 763/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 505705.9375 - mae: 636.0413 - val_loss: 359192.0000 - val_mae: 467.5494\n",
            "Epoch 764/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 509081.7188 - mae: 637.9924 - val_loss: 351246.6562 - val_mae: 458.6740\n",
            "Epoch 765/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 507164.5625 - mae: 636.1511 - val_loss: 345073.2812 - val_mae: 452.3197\n",
            "Epoch 766/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 508830.6250 - mae: 636.9729 - val_loss: 351945.5312 - val_mae: 459.1036\n",
            "Epoch 767/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 509497.4688 - mae: 638.0131 - val_loss: 345362.9688 - val_mae: 452.5054\n",
            "Epoch 768/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 509716.1875 - mae: 638.1383 - val_loss: 352178.4688 - val_mae: 459.2552\n",
            "Epoch 769/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 506987.2500 - mae: 636.6364 - val_loss: 351809.6562 - val_mae: 459.0409\n",
            "Epoch 770/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 500078.9688 - mae: 634.6116 - val_loss: 359573.0000 - val_mae: 466.3585\n",
            "Epoch 771/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 507067.5938 - mae: 637.1282 - val_loss: 367220.8750 - val_mae: 475.1440\n",
            "Epoch 772/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 507368.9375 - mae: 636.7579 - val_loss: 359611.8750 - val_mae: 467.9248\n",
            "Epoch 773/2000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 508374.6875 - mae: 638.6552 - val_loss: 345500.5000 - val_mae: 451.0779\n",
            "Epoch 774/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 496648.1562 - mae: 632.8064 - val_loss: 352688.5312 - val_mae: 459.5868\n",
            "Epoch 775/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 507015.5312 - mae: 636.9836 - val_loss: 366815.1250 - val_mae: 473.3967\n",
            "Epoch 776/2000\n",
            "39/39 [==============================] - 9s 231ms/step - loss: 503501.2188 - mae: 634.9161 - val_loss: 375151.6562 - val_mae: 485.6327\n",
            "Epoch 777/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 502778.5625 - mae: 632.9691 - val_loss: 360235.4688 - val_mae: 466.7947\n",
            "Epoch 778/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 506161.3438 - mae: 636.1417 - val_loss: 338263.0000 - val_mae: 444.1024\n",
            "Epoch 779/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 502427.8125 - mae: 633.2653 - val_loss: 338870.1562 - val_mae: 444.4720\n",
            "Epoch 780/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 498530.3125 - mae: 633.0319 - val_loss: 361027.8438 - val_mae: 467.2863\n",
            "Epoch 781/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 510823.2812 - mae: 639.2357 - val_loss: 375702.2188 - val_mae: 485.9662\n",
            "Epoch 782/2000\n",
            "39/39 [==============================] - 5s 101ms/step - loss: 502318.4375 - mae: 632.7411 - val_loss: 346732.1250 - val_mae: 453.3804\n",
            "Epoch 783/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 509698.7188 - mae: 638.5847 - val_loss: 353711.7188 - val_mae: 458.7363\n",
            "Epoch 784/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 504574.5312 - mae: 635.2982 - val_loss: 354095.7500 - val_mae: 460.4739\n",
            "Epoch 785/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 502751.0000 - mae: 636.0443 - val_loss: 346528.1250 - val_mae: 451.7598\n",
            "Epoch 786/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 508186.9688 - mae: 638.4885 - val_loss: 360677.0000 - val_mae: 465.6031\n",
            "Epoch 787/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 493798.6250 - mae: 633.1545 - val_loss: 361050.0312 - val_mae: 467.3297\n",
            "Epoch 788/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 508670.4688 - mae: 638.5995 - val_loss: 353867.1562 - val_mae: 460.3506\n",
            "Epoch 789/2000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 494812.9062 - mae: 630.6788 - val_loss: 369139.5938 - val_mae: 477.8583\n",
            "Epoch 790/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 506223.5312 - mae: 636.4011 - val_loss: 355282.5000 - val_mae: 462.6951\n",
            "Epoch 791/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 498312.5625 - mae: 631.6921 - val_loss: 369297.2500 - val_mae: 477.9557\n",
            "Epoch 792/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 509881.3125 - mae: 639.0976 - val_loss: 368748.5000 - val_mae: 474.6499\n",
            "Epoch 793/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 508584.8750 - mae: 639.0354 - val_loss: 361491.1562 - val_mae: 467.6189\n",
            "Epoch 794/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 508022.0625 - mae: 637.4236 - val_loss: 354383.2188 - val_mae: 460.6839\n",
            "Epoch 795/2000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 502604.8125 - mae: 634.9047 - val_loss: 354087.8438 - val_mae: 459.0243\n",
            "Epoch 796/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 508592.1562 - mae: 639.1933 - val_loss: 340568.5312 - val_mae: 445.5524\n",
            "Epoch 797/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 507852.1875 - mae: 637.8821 - val_loss: 362685.2500 - val_mae: 469.8332\n",
            "Epoch 798/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 509162.0312 - mae: 638.9180 - val_loss: 362316.6250 - val_mae: 469.6180\n",
            "Epoch 799/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 509725.8125 - mae: 639.0468 - val_loss: 354760.7188 - val_mae: 460.9274\n",
            "Epoch 800/2000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 505286.7500 - mae: 635.7859 - val_loss: 362468.0000 - val_mae: 469.7118\n",
            "Epoch 801/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 504203.6562 - mae: 635.4755 - val_loss: 370198.6250 - val_mae: 478.5110\n",
            "Epoch 802/2000\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 500165.4375 - mae: 634.9050 - val_loss: 362268.2188 - val_mae: 468.1270\n",
            "Epoch 803/2000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 506011.9688 - mae: 636.0509 - val_loss: 355201.6250 - val_mae: 459.7338\n",
            "Epoch 804/2000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 505773.1250 - mae: 636.6658 - val_loss: 362462.6562 - val_mae: 468.2541\n",
            "Epoch 805/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 503901.3438 - mae: 636.1658 - val_loss: 355720.7500 - val_mae: 461.5217\n",
            "Epoch 806/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 504092.2500 - mae: 634.9893 - val_loss: 362502.4062 - val_mae: 469.7518\n",
            "Epoch 807/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 507811.5000 - mae: 639.7087 - val_loss: 361895.2188 - val_mae: 466.4688\n",
            "Epoch 808/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 510041.5312 - mae: 639.5392 - val_loss: 355807.9688 - val_mae: 463.0606\n",
            "Epoch 809/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 507661.6875 - mae: 638.1288 - val_loss: 348773.9375 - val_mae: 454.6766\n",
            "Epoch 810/2000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 503804.5938 - mae: 634.2690 - val_loss: 356105.4062 - val_mae: 461.7688\n",
            "Epoch 811/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 508102.6250 - mae: 639.5256 - val_loss: 362752.4688 - val_mae: 467.0089\n",
            "Epoch 812/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 501705.8750 - mae: 635.0947 - val_loss: 349448.0312 - val_mae: 455.0841\n",
            "Epoch 813/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 500990.0625 - mae: 633.9055 - val_loss: 363860.8438 - val_mae: 472.0538\n",
            "Epoch 814/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 504876.5000 - mae: 636.9449 - val_loss: 363282.4688 - val_mae: 468.7884\n",
            "Epoch 815/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 509578.9375 - mae: 638.7330 - val_loss: 356047.4688 - val_mae: 461.7549\n",
            "Epoch 816/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 507486.6875 - mae: 637.3787 - val_loss: 356121.0312 - val_mae: 461.8020\n",
            "Epoch 817/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 502680.7188 - mae: 635.1365 - val_loss: 363860.2500 - val_mae: 470.5878\n",
            "Epoch 818/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 502146.0938 - mae: 636.7797 - val_loss: 357017.3750 - val_mae: 463.7797\n",
            "Epoch 819/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 508239.9375 - mae: 638.2882 - val_loss: 356638.7188 - val_mae: 463.5576\n",
            "Epoch 820/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 502607.3125 - mae: 634.5680 - val_loss: 371065.3438 - val_mae: 476.1814\n",
            "Epoch 821/2000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 505987.5625 - mae: 637.8994 - val_loss: 357257.0312 - val_mae: 463.9274\n",
            "Epoch 822/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 504744.4688 - mae: 637.1832 - val_loss: 356524.6562 - val_mae: 462.0608\n",
            "Epoch 823/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 501091.9062 - mae: 633.9062 - val_loss: 348936.3750 - val_mae: 453.3776\n",
            "Epoch 824/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 499099.6562 - mae: 634.2270 - val_loss: 371197.1250 - val_mae: 477.7096\n",
            "Epoch 825/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 506559.9062 - mae: 637.3779 - val_loss: 363581.4062 - val_mae: 469.0102\n",
            "Epoch 826/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 509583.1562 - mae: 641.0875 - val_loss: 364159.3438 - val_mae: 469.3583\n",
            "Epoch 827/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 509000.2188 - mae: 639.4264 - val_loss: 357626.9688 - val_mae: 464.1549\n",
            "Epoch 828/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 510240.6250 - mae: 640.1529 - val_loss: 356607.1562 - val_mae: 460.7041\n",
            "Epoch 829/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 500769.7812 - mae: 635.1793 - val_loss: 357280.8438 - val_mae: 463.9530\n",
            "Epoch 830/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 506203.8125 - mae: 637.2407 - val_loss: 351054.6250 - val_mae: 456.0783\n",
            "Epoch 831/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 498214.8438 - mae: 635.1391 - val_loss: 365193.1250 - val_mae: 471.4056\n",
            "Epoch 832/2000\n",
            "39/39 [==============================] - 10s 237ms/step - loss: 502018.9688 - mae: 634.5831 - val_loss: 365105.8750 - val_mae: 472.7760\n",
            "Epoch 833/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 501601.6875 - mae: 636.9082 - val_loss: 356402.8438 - val_mae: 460.6027\n",
            "Epoch 834/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 503455.6250 - mae: 636.1111 - val_loss: 350054.8438 - val_mae: 454.0799\n",
            "Epoch 835/2000\n",
            "39/39 [==============================] - 6s 130ms/step - loss: 505853.4375 - mae: 636.9379 - val_loss: 357677.4062 - val_mae: 464.1967\n",
            "Epoch 836/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 500657.5625 - mae: 633.6818 - val_loss: 365331.8438 - val_mae: 470.0913\n",
            "Epoch 837/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 504933.0312 - mae: 636.8499 - val_loss: 349851.2188 - val_mae: 453.9763\n",
            "Epoch 838/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 504934.4688 - mae: 636.9784 - val_loss: 365441.0938 - val_mae: 470.1620\n",
            "Epoch 839/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 500255.6250 - mae: 633.3582 - val_loss: 357150.5938 - val_mae: 462.4836\n",
            "Epoch 840/2000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 504335.3125 - mae: 638.0909 - val_loss: 350340.9062 - val_mae: 455.6823\n",
            "Epoch 841/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 503284.9062 - mae: 634.8395 - val_loss: 358254.3438 - val_mae: 463.1433\n",
            "Epoch 842/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 505794.6250 - mae: 638.3467 - val_loss: 366036.6562 - val_mae: 471.9314\n",
            "Epoch 843/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 506794.6250 - mae: 637.7141 - val_loss: 358734.6562 - val_mae: 464.8346\n",
            "Epoch 844/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 505952.6875 - mae: 637.0251 - val_loss: 365269.8438 - val_mae: 471.4841\n",
            "Epoch 845/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 510107.6562 - mae: 640.4105 - val_loss: 358416.9062 - val_mae: 464.6502\n",
            "Epoch 846/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 502418.8125 - mae: 635.4359 - val_loss: 358138.3438 - val_mae: 463.0913\n",
            "Epoch 847/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 507647.7500 - mae: 638.6513 - val_loss: 373651.0938 - val_mae: 480.6231\n",
            "Epoch 848/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 503957.2188 - mae: 636.7325 - val_loss: 365517.1562 - val_mae: 471.7303\n",
            "Epoch 849/2000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 505145.5625 - mae: 636.4545 - val_loss: 358842.5000 - val_mae: 463.5177\n",
            "Epoch 850/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 499478.4375 - mae: 635.2842 - val_loss: 366092.2812 - val_mae: 471.9809\n",
            "Epoch 851/2000\n",
            "39/39 [==============================] - 5s 101ms/step - loss: 503858.0000 - mae: 636.9186 - val_loss: 366460.0312 - val_mae: 473.5875\n",
            "Epoch 852/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 504788.7188 - mae: 637.3752 - val_loss: 366187.0938 - val_mae: 472.0398\n",
            "Epoch 853/2000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 499406.8125 - mae: 636.7684 - val_loss: 358308.0938 - val_mae: 461.8297\n",
            "Epoch 854/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 506896.0625 - mae: 639.2277 - val_loss: 367117.1250 - val_mae: 473.9767\n",
            "Epoch 855/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 508756.2500 - mae: 639.7271 - val_loss: 358196.7812 - val_mae: 463.1504\n",
            "Epoch 856/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 504121.5312 - mae: 636.3602 - val_loss: 366476.2500 - val_mae: 472.2196\n",
            "Epoch 857/2000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 502678.0000 - mae: 635.6959 - val_loss: 373461.5312 - val_mae: 479.1431\n",
            "Epoch 858/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 506909.3438 - mae: 638.8875 - val_loss: 373968.0000 - val_mae: 479.4432\n",
            "Epoch 859/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 503446.3750 - mae: 636.0176 - val_loss: 366385.4688 - val_mae: 470.7977\n",
            "Epoch 860/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 501249.9375 - mae: 637.2998 - val_loss: 374129.6250 - val_mae: 479.5450\n",
            "Epoch 861/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 500036.2500 - mae: 634.6293 - val_loss: 373948.9688 - val_mae: 480.9236\n",
            "Epoch 862/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 500368.8438 - mae: 636.1992 - val_loss: 373736.0312 - val_mae: 479.3161\n",
            "Epoch 863/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 505441.1875 - mae: 637.3152 - val_loss: 366265.5000 - val_mae: 469.3662\n",
            "Epoch 864/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 504130.7188 - mae: 636.9328 - val_loss: 367091.2500 - val_mae: 471.2263\n",
            "Epoch 865/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 505232.3125 - mae: 637.5135 - val_loss: 366697.6562 - val_mae: 470.9987\n",
            "Epoch 866/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 507408.5312 - mae: 638.3885 - val_loss: 374309.2188 - val_mae: 481.0311\n",
            "Epoch 867/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 499405.5312 - mae: 635.2426 - val_loss: 367336.3438 - val_mae: 471.3839\n",
            "Epoch 868/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 502609.6250 - mae: 635.9994 - val_loss: 359194.5000 - val_mae: 462.4137\n",
            "Epoch 869/2000\n",
            "39/39 [==============================] - 10s 235ms/step - loss: 506202.7812 - mae: 637.2707 - val_loss: 359556.9062 - val_mae: 463.9923\n",
            "Epoch 870/2000\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 508761.8750 - mae: 639.2042 - val_loss: 367132.7500 - val_mae: 473.9923\n",
            "Epoch 871/2000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 504159.3750 - mae: 636.9443 - val_loss: 367555.0938 - val_mae: 471.5245\n",
            "Epoch 872/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 508330.0938 - mae: 639.4114 - val_loss: 360213.0000 - val_mae: 464.3869\n",
            "Epoch 873/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 509302.1562 - mae: 640.1097 - val_loss: 368018.5938 - val_mae: 473.1610\n",
            "Epoch 874/2000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 494844.7500 - mae: 632.6475 - val_loss: 367286.2500 - val_mae: 471.3770\n",
            "Epoch 875/2000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 505862.2500 - mae: 638.2642 - val_loss: 360228.0000 - val_mae: 465.7560\n",
            "Epoch 876/2000\n",
            "39/39 [==============================] - 5s 117ms/step - loss: 503386.7188 - mae: 636.7191 - val_loss: 367671.6562 - val_mae: 472.9604\n",
            "Epoch 877/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 504885.3750 - mae: 636.7713 - val_loss: 374145.7500 - val_mae: 476.8994\n",
            "Epoch 878/2000\n",
            "39/39 [==============================] - 10s 234ms/step - loss: 508777.6250 - mae: 639.7665 - val_loss: 367686.1250 - val_mae: 470.2756\n",
            "Epoch 879/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 506554.5000 - mae: 638.0992 - val_loss: 360282.0000 - val_mae: 463.0959\n",
            "Epoch 880/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 505343.7812 - mae: 637.9796 - val_loss: 360356.8438 - val_mae: 463.1449\n",
            "Epoch 881/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 508068.8125 - mae: 639.3055 - val_loss: 359976.3750 - val_mae: 462.9274\n",
            "Epoch 882/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 504494.3125 - mae: 637.4859 - val_loss: 375053.8438 - val_mae: 480.1449\n",
            "Epoch 883/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 505231.6875 - mae: 637.8536 - val_loss: 375371.2812 - val_mae: 481.8220\n",
            "Epoch 884/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 508023.1250 - mae: 639.4769 - val_loss: 367890.0000 - val_mae: 471.7644\n",
            "Epoch 885/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 505806.9062 - mae: 637.5630 - val_loss: 368243.0000 - val_mae: 473.3135\n",
            "Epoch 886/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 502991.5312 - mae: 636.6245 - val_loss: 375547.0000 - val_mae: 481.7804\n",
            "Epoch 887/2000\n",
            "39/39 [==============================] - 6s 144ms/step - loss: 506584.0625 - mae: 639.3779 - val_loss: 368057.7500 - val_mae: 471.8719\n",
            "Epoch 888/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 499213.7500 - mae: 634.7427 - val_loss: 353690.7500 - val_mae: 457.7574\n",
            "Epoch 889/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 508054.8438 - mae: 640.1547 - val_loss: 368955.1562 - val_mae: 473.7393\n",
            "Epoch 890/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 508203.6562 - mae: 639.5905 - val_loss: 353794.3750 - val_mae: 457.8217\n",
            "Epoch 891/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 507444.5000 - mae: 639.0312 - val_loss: 360899.7188 - val_mae: 464.8413\n",
            "Epoch 892/2000\n",
            "39/39 [==============================] - 10s 235ms/step - loss: 508319.6250 - mae: 639.8453 - val_loss: 368079.0938 - val_mae: 470.5725\n",
            "Epoch 893/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 504412.5000 - mae: 636.0411 - val_loss: 360198.4062 - val_mae: 463.1049\n",
            "Epoch 894/2000\n",
            "39/39 [==============================] - 5s 102ms/step - loss: 506654.5312 - mae: 639.0552 - val_loss: 354037.8750 - val_mae: 457.9728\n",
            "Epoch 895/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 504838.2188 - mae: 637.8639 - val_loss: 376356.8438 - val_mae: 480.9431\n",
            "Epoch 896/2000\n",
            "39/39 [==============================] - 9s 231ms/step - loss: 507360.3750 - mae: 638.4329 - val_loss: 360890.2188 - val_mae: 463.5259\n",
            "Epoch 897/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 507393.1562 - mae: 638.7874 - val_loss: 361704.6250 - val_mae: 465.3284\n",
            "Epoch 898/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 490003.6562 - mae: 631.5963 - val_loss: 354473.6562 - val_mae: 456.9177\n",
            "Epoch 899/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 505539.8750 - mae: 637.4616 - val_loss: 376326.8750 - val_mae: 479.6179\n",
            "Epoch 900/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 506655.6875 - mae: 638.7690 - val_loss: 361410.4688 - val_mae: 465.1631\n",
            "Epoch 901/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 508481.8438 - mae: 640.5697 - val_loss: 353218.8438 - val_mae: 456.1903\n",
            "Epoch 902/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 508641.1875 - mae: 640.5940 - val_loss: 369312.7188 - val_mae: 473.9727\n",
            "Epoch 903/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 506984.2500 - mae: 639.2338 - val_loss: 362340.9688 - val_mae: 467.0290\n",
            "Epoch 904/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 500562.1875 - mae: 634.3885 - val_loss: 361330.7812 - val_mae: 463.8138\n",
            "Epoch 905/2000\n",
            "39/39 [==============================] - 9s 235ms/step - loss: 507804.9688 - mae: 639.5760 - val_loss: 369409.6250 - val_mae: 474.0323\n",
            "Epoch 906/2000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 507885.1250 - mae: 638.9492 - val_loss: 361707.4062 - val_mae: 465.3500\n",
            "Epoch 907/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 505786.9375 - mae: 639.2384 - val_loss: 361492.9062 - val_mae: 463.9197\n",
            "Epoch 908/2000\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 509363.1875 - mae: 641.1345 - val_loss: 376662.1562 - val_mae: 481.1518\n",
            "Epoch 909/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 506487.1562 - mae: 638.9701 - val_loss: 369683.8438 - val_mae: 474.2009\n",
            "Epoch 910/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 504741.1250 - mae: 637.8997 - val_loss: 362119.5312 - val_mae: 464.2973\n",
            "Epoch 911/2000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 502319.7812 - mae: 635.2498 - val_loss: 369067.0938 - val_mae: 472.5418\n",
            "Epoch 912/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 503341.3438 - mae: 637.3624 - val_loss: 376760.0938 - val_mae: 478.6145\n",
            "Epoch 913/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 504333.3438 - mae: 637.3741 - val_loss: 369170.5938 - val_mae: 472.6078\n",
            "Epoch 914/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 506300.4375 - mae: 638.4677 - val_loss: 377717.6562 - val_mae: 483.0809\n",
            "Epoch 915/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 510023.3750 - mae: 641.5245 - val_loss: 369535.6562 - val_mae: 474.1228\n",
            "Epoch 916/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 509386.9688 - mae: 641.7349 - val_loss: 355002.3438 - val_mae: 457.2840\n",
            "Epoch 917/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 508087.5312 - mae: 640.1901 - val_loss: 377730.3750 - val_mae: 482.0035\n",
            "Epoch 918/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 508969.4062 - mae: 640.9778 - val_loss: 370082.3438 - val_mae: 475.7413\n",
            "Epoch 919/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 508487.6875 - mae: 641.2302 - val_loss: 377345.5938 - val_mae: 481.5781\n",
            "Epoch 920/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 511060.2500 - mae: 642.1168 - val_loss: 354587.4688 - val_mae: 458.3430\n",
            "Epoch 921/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 507438.9688 - mae: 639.7228 - val_loss: 377689.6562 - val_mae: 480.4989\n",
            "Epoch 922/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 507814.5312 - mae: 639.6055 - val_loss: 363518.6250 - val_mae: 467.7395\n",
            "Epoch 923/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 504029.8438 - mae: 637.7800 - val_loss: 370270.3750 - val_mae: 473.2843\n",
            "Epoch 924/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 507521.5625 - mae: 639.8813 - val_loss: 378176.7188 - val_mae: 482.0782\n",
            "Epoch 925/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 507612.9688 - mae: 639.3342 - val_loss: 362930.0312 - val_mae: 466.1173\n",
            "Epoch 926/2000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 505604.4062 - mae: 637.7665 - val_loss: 370608.1250 - val_mae: 476.0513\n",
            "Epoch 927/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 508093.5312 - mae: 640.2256 - val_loss: 378204.0000 - val_mae: 483.3789\n",
            "Epoch 928/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 504479.9375 - mae: 637.6536 - val_loss: 370706.3438 - val_mae: 473.5614\n",
            "Epoch 929/2000\n",
            "39/39 [==============================] - 5s 117ms/step - loss: 503519.9062 - mae: 636.6133 - val_loss: 370577.0938 - val_mae: 474.7615\n",
            "Epoch 930/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 503883.2500 - mae: 637.2305 - val_loss: 378392.3438 - val_mae: 483.4917\n",
            "Epoch 931/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 501690.3438 - mae: 637.3895 - val_loss: 364540.8750 - val_mae: 468.3471\n",
            "Epoch 932/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 504725.8438 - mae: 637.5541 - val_loss: 363443.3438 - val_mae: 466.4385\n",
            "Epoch 933/2000\n",
            "39/39 [==============================] - 5s 120ms/step - loss: 503887.0000 - mae: 636.8732 - val_loss: 378043.3438 - val_mae: 480.7548\n",
            "Epoch 934/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 505241.0938 - mae: 638.4940 - val_loss: 355694.9062 - val_mae: 457.7538\n",
            "Epoch 935/2000\n",
            "39/39 [==============================] - 5s 114ms/step - loss: 508850.2500 - mae: 641.1111 - val_loss: 370585.0000 - val_mae: 473.5078\n",
            "Epoch 936/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 506278.3125 - mae: 639.3003 - val_loss: 363609.7188 - val_mae: 466.5425\n",
            "Epoch 937/2000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 505090.5000 - mae: 637.7845 - val_loss: 356303.4062 - val_mae: 458.1171\n",
            "Epoch 938/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 509334.9062 - mae: 641.1714 - val_loss: 379378.1250 - val_mae: 484.0754\n",
            "Epoch 939/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 509167.2812 - mae: 641.0925 - val_loss: 349377.5938 - val_mae: 451.1819\n",
            "Epoch 940/2000\n",
            "39/39 [==============================] - 5s 113ms/step - loss: 506073.6875 - mae: 638.9905 - val_loss: 364299.5312 - val_mae: 466.9546\n",
            "Epoch 941/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 507941.5000 - mae: 640.4430 - val_loss: 364619.4062 - val_mae: 468.4012\n",
            "Epoch 942/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 506115.2500 - mae: 639.1307 - val_loss: 371545.1562 - val_mae: 476.6024\n",
            "Epoch 943/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 509526.2812 - mae: 641.5434 - val_loss: 356895.9062 - val_mae: 459.7359\n",
            "Epoch 944/2000\n",
            "39/39 [==============================] - 5s 102ms/step - loss: 507097.5625 - mae: 639.0731 - val_loss: 363999.0000 - val_mae: 466.7856\n",
            "Epoch 945/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 504526.5938 - mae: 638.7181 - val_loss: 356894.5938 - val_mae: 459.7351\n",
            "Epoch 946/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 508680.7812 - mae: 641.0676 - val_loss: 356702.0312 - val_mae: 458.3716\n",
            "Epoch 947/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 507030.3750 - mae: 639.6332 - val_loss: 379027.4688 - val_mae: 482.6233\n",
            "Epoch 948/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 506253.9688 - mae: 639.5443 - val_loss: 371757.1250 - val_mae: 474.2276\n",
            "Epoch 949/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 504608.6875 - mae: 639.0195 - val_loss: 364866.6562 - val_mae: 466.0503\n",
            "Epoch 950/2000\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 507255.3125 - mae: 639.3970 - val_loss: 372362.3438 - val_mae: 474.8411\n",
            "Epoch 951/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 496115.3438 - mae: 634.2481 - val_loss: 372327.2500 - val_mae: 474.5656\n",
            "Epoch 952/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 509110.6250 - mae: 641.4899 - val_loss: 372195.8438 - val_mae: 475.7380\n",
            "Epoch 953/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 502474.1875 - mae: 638.4362 - val_loss: 372976.0000 - val_mae: 477.4404\n",
            "Epoch 954/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 508238.4688 - mae: 640.9742 - val_loss: 357527.8750 - val_mae: 458.8729\n",
            "Epoch 955/2000\n",
            "39/39 [==============================] - 10s 231ms/step - loss: 505593.1875 - mae: 637.9574 - val_loss: 350024.7188 - val_mae: 451.5880\n",
            "Epoch 956/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 497560.0625 - mae: 634.3481 - val_loss: 373117.7812 - val_mae: 477.5234\n",
            "Epoch 957/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 504765.6875 - mae: 637.9971 - val_loss: 365213.7188 - val_mae: 466.2745\n",
            "Epoch 958/2000\n",
            "39/39 [==============================] - 9s 235ms/step - loss: 502294.9062 - mae: 637.4411 - val_loss: 380293.3438 - val_mae: 484.8827\n",
            "Epoch 959/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 507396.7500 - mae: 639.3467 - val_loss: 372488.8438 - val_mae: 475.9165\n",
            "Epoch 960/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 502101.3750 - mae: 636.9927 - val_loss: 365105.9688 - val_mae: 467.4571\n",
            "Epoch 961/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 503086.1250 - mae: 637.4209 - val_loss: 379597.5312 - val_mae: 482.9764\n",
            "Epoch 962/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 505770.2500 - mae: 639.2421 - val_loss: 365233.5938 - val_mae: 467.5364\n",
            "Epoch 963/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 503645.4375 - mae: 638.0190 - val_loss: 380486.7500 - val_mae: 484.7366\n",
            "Epoch 964/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 508570.8750 - mae: 640.6616 - val_loss: 372847.0938 - val_mae: 474.8940\n",
            "Epoch 965/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 501607.0000 - mae: 638.1559 - val_loss: 364829.9062 - val_mae: 467.3033\n",
            "Epoch 966/2000\n",
            "39/39 [==============================] - 9s 232ms/step - loss: 509453.9688 - mae: 642.1315 - val_loss: 358021.6250 - val_mae: 459.1870\n",
            "Epoch 967/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 506738.0938 - mae: 640.2300 - val_loss: 372802.6562 - val_mae: 476.1075\n",
            "Epoch 968/2000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 508852.1875 - mae: 641.3062 - val_loss: 365432.1562 - val_mae: 467.6599\n",
            "Epoch 969/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 508524.1875 - mae: 641.0886 - val_loss: 358080.0938 - val_mae: 459.2242\n",
            "Epoch 970/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 505757.9062 - mae: 639.5633 - val_loss: 372913.8438 - val_mae: 476.1751\n",
            "Epoch 971/2000\n",
            "39/39 [==============================] - 5s 103ms/step - loss: 503799.5312 - mae: 637.5500 - val_loss: 357956.4688 - val_mae: 460.3855\n",
            "Epoch 972/2000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 507509.0312 - mae: 640.0948 - val_loss: 372536.6562 - val_mae: 475.9571\n",
            "Epoch 973/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 505952.6250 - mae: 639.4809 - val_loss: 358327.0312 - val_mae: 459.3810\n",
            "Epoch 974/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 500955.8750 - mae: 637.2692 - val_loss: 366154.3438 - val_mae: 468.0909\n",
            "Epoch 975/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 500186.1562 - mae: 638.2736 - val_loss: 350296.5938 - val_mae: 451.7782\n",
            "Epoch 976/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 508732.4062 - mae: 641.6906 - val_loss: 358437.0938 - val_mae: 459.4508\n",
            "Epoch 977/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 501267.7188 - mae: 638.1653 - val_loss: 380837.7188 - val_mae: 484.0083\n",
            "Epoch 978/2000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 499235.6562 - mae: 636.4659 - val_loss: 388199.6250 - val_mae: 492.1632\n",
            "Epoch 979/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 507400.9375 - mae: 640.0431 - val_loss: 372529.2500 - val_mae: 474.7383\n",
            "Epoch 980/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 504189.7500 - mae: 638.1989 - val_loss: 374062.5938 - val_mae: 478.0754\n",
            "Epoch 981/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 503615.9375 - mae: 637.6016 - val_loss: 373324.6562 - val_mae: 476.4247\n",
            "Epoch 982/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 507419.9062 - mae: 640.7388 - val_loss: 365655.0938 - val_mae: 466.5881\n",
            "Epoch 983/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 506031.1562 - mae: 639.9927 - val_loss: 381022.2500 - val_mae: 483.8405\n",
            "Epoch 984/2000\n",
            "39/39 [==============================] - 9s 208ms/step - loss: 504986.4688 - mae: 638.4147 - val_loss: 381609.2500 - val_mae: 486.6174\n",
            "Epoch 985/2000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 502934.4688 - mae: 638.3528 - val_loss: 373515.2188 - val_mae: 476.5404\n",
            "Epoch 986/2000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 508607.3125 - mae: 640.7537 - val_loss: 365939.9688 - val_mae: 466.7715\n",
            "Epoch 987/2000\n",
            "39/39 [==============================] - 10s 234ms/step - loss: 500118.8438 - mae: 636.4756 - val_loss: 365730.0312 - val_mae: 467.8626\n",
            "Epoch 988/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 504803.5625 - mae: 638.5013 - val_loss: 373363.5000 - val_mae: 475.2419\n",
            "Epoch 989/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 507033.7812 - mae: 640.5086 - val_loss: 374177.7188 - val_mae: 476.9313\n",
            "Epoch 990/2000\n",
            "39/39 [==============================] - 9s 209ms/step - loss: 508022.0625 - mae: 640.3310 - val_loss: 373746.9062 - val_mae: 476.6809\n",
            "Epoch 991/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 507408.1562 - mae: 640.8413 - val_loss: 350875.8438 - val_mae: 452.1401\n",
            "Epoch 992/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 501261.9688 - mae: 636.6407 - val_loss: 365949.5938 - val_mae: 467.9987\n",
            "Epoch 993/2000\n",
            "39/39 [==============================] - 5s 100ms/step - loss: 509429.9062 - mae: 641.6479 - val_loss: 374048.1250 - val_mae: 475.6508\n",
            "Epoch 994/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 503112.5625 - mae: 637.0661 - val_loss: 373804.8438 - val_mae: 474.3024\n",
            "Epoch 995/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 498735.1250 - mae: 636.5595 - val_loss: 388621.3438 - val_mae: 491.2165\n",
            "Epoch 996/2000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 502552.2188 - mae: 636.7675 - val_loss: 366801.2188 - val_mae: 469.7052\n",
            "Epoch 997/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 505921.5312 - mae: 639.3320 - val_loss: 381567.8750 - val_mae: 486.8866\n",
            "Epoch 998/2000\n",
            "39/39 [==============================] - 6s 141ms/step - loss: 505567.9062 - mae: 640.5668 - val_loss: 358265.9688 - val_mae: 459.3908\n",
            "Epoch 999/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 506943.2188 - mae: 639.8048 - val_loss: 366592.7188 - val_mae: 468.3799\n",
            "Epoch 1000/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 504953.6250 - mae: 639.4213 - val_loss: 373997.5312 - val_mae: 476.8329\n",
            "Epoch 1001/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 499193.3125 - mae: 636.4504 - val_loss: 366897.2188 - val_mae: 469.7623\n",
            "Epoch 1002/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 505380.7188 - mae: 639.4042 - val_loss: 366445.0000 - val_mae: 467.0963\n",
            "Epoch 1003/2000\n",
            "39/39 [==============================] - 10s 235ms/step - loss: 505259.9688 - mae: 639.8525 - val_loss: 381749.2812 - val_mae: 484.2883\n",
            "Epoch 1004/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 499782.6250 - mae: 636.8542 - val_loss: 373932.4688 - val_mae: 478.3042\n",
            "Epoch 1005/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 510034.3125 - mae: 642.6088 - val_loss: 366617.8750 - val_mae: 469.6018\n",
            "Epoch 1006/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 501333.9688 - mae: 636.7463 - val_loss: 382086.0938 - val_mae: 485.6864\n",
            "Epoch 1007/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 507405.9062 - mae: 640.6707 - val_loss: 367134.0938 - val_mae: 469.9033\n",
            "Epoch 1008/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 505099.2812 - mae: 639.9321 - val_loss: 374507.7188 - val_mae: 475.9395\n",
            "Epoch 1009/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 510322.5000 - mae: 642.9299 - val_loss: 374070.3438 - val_mae: 475.6864\n",
            "Epoch 1010/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 502560.8750 - mae: 636.9642 - val_loss: 366929.5000 - val_mae: 468.5883\n",
            "Epoch 1011/2000\n",
            "39/39 [==============================] - 9s 236ms/step - loss: 508671.5312 - mae: 642.2845 - val_loss: 374321.6562 - val_mae: 474.6389\n",
            "Epoch 1012/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 504298.1875 - mae: 638.6826 - val_loss: 382330.8438 - val_mae: 485.8314\n",
            "Epoch 1013/2000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 499521.1875 - mae: 636.6902 - val_loss: 374684.4062 - val_mae: 478.4372\n",
            "Epoch 1014/2000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 508060.5000 - mae: 641.3828 - val_loss: 366356.1562 - val_mae: 467.0677\n",
            "Epoch 1015/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 505856.0938 - mae: 639.6678 - val_loss: 375053.5938 - val_mae: 477.4613\n",
            "Epoch 1016/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 505900.5938 - mae: 639.3135 - val_loss: 381760.4062 - val_mae: 484.6273\n",
            "Epoch 1017/2000\n",
            "39/39 [==============================] - 4s 104ms/step - loss: 507960.3125 - mae: 641.0468 - val_loss: 359159.9062 - val_mae: 461.1318\n",
            "Epoch 1018/2000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 504814.3125 - mae: 639.7025 - val_loss: 381879.0000 - val_mae: 484.3833\n",
            "Epoch 1019/2000\n",
            "39/39 [==============================] - 10s 235ms/step - loss: 507313.0000 - mae: 640.7198 - val_loss: 375242.5938 - val_mae: 477.5756\n",
            "Epoch 1020/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 508851.5000 - mae: 642.3178 - val_loss: 367376.0938 - val_mae: 468.8643\n",
            "Epoch 1021/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 507182.2188 - mae: 641.1620 - val_loss: 366894.7500 - val_mae: 468.5837\n",
            "Epoch 1022/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 506242.4688 - mae: 641.0520 - val_loss: 359025.7812 - val_mae: 459.8717\n",
            "Epoch 1023/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 497672.1562 - mae: 635.7247 - val_loss: 375315.0938 - val_mae: 477.6193\n",
            "Epoch 1024/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 506898.5625 - mae: 640.0069 - val_loss: 359518.5000 - val_mae: 460.1594\n",
            "Epoch 1025/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 502608.4688 - mae: 637.4821 - val_loss: 374659.2188 - val_mae: 476.3807\n",
            "Epoch 1026/2000\n",
            "39/39 [==============================] - 6s 133ms/step - loss: 502932.8125 - mae: 637.3168 - val_loss: 374958.3438 - val_mae: 477.4141\n",
            "Epoch 1027/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 507523.8750 - mae: 640.8237 - val_loss: 367060.6562 - val_mae: 468.6862\n",
            "Epoch 1028/2000\n",
            "39/39 [==============================] - 6s 126ms/step - loss: 503106.8125 - mae: 639.7682 - val_loss: 359916.4062 - val_mae: 461.5796\n",
            "Epoch 1029/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 505173.6875 - mae: 639.7557 - val_loss: 367116.9688 - val_mae: 468.7210\n",
            "Epoch 1030/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 508250.0312 - mae: 641.7307 - val_loss: 375021.9688 - val_mae: 477.4525\n",
            "Epoch 1031/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 505156.5938 - mae: 638.8909 - val_loss: 367631.6562 - val_mae: 469.0221\n",
            "Epoch 1032/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 504192.2188 - mae: 638.2120 - val_loss: 382287.3750 - val_mae: 484.6341\n",
            "Epoch 1033/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 508280.5312 - mae: 641.3179 - val_loss: 375414.8750 - val_mae: 478.8617\n",
            "Epoch 1034/2000\n",
            "39/39 [==============================] - 10s 237ms/step - loss: 505747.6562 - mae: 641.4748 - val_loss: 374178.3750 - val_mae: 474.6107\n",
            "Epoch 1035/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 503988.6562 - mae: 638.1329 - val_loss: 359693.6250 - val_mae: 461.4562\n",
            "Epoch 1036/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 502101.7500 - mae: 637.6106 - val_loss: 382199.2500 - val_mae: 483.4138\n",
            "Epoch 1037/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 503224.0938 - mae: 639.2752 - val_loss: 374832.2500 - val_mae: 477.3482\n",
            "Epoch 1038/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 505192.8438 - mae: 638.7322 - val_loss: 367926.7500 - val_mae: 469.5398\n",
            "Epoch 1039/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 509879.2812 - mae: 643.4003 - val_loss: 375395.6562 - val_mae: 477.6781\n",
            "Epoch 1040/2000\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 507610.9688 - mae: 641.9367 - val_loss: 367518.6250 - val_mae: 468.9688\n",
            "Epoch 1041/2000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 502118.6875 - mae: 637.4152 - val_loss: 383374.6562 - val_mae: 486.4483\n",
            "Epoch 1042/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 505946.4062 - mae: 640.4866 - val_loss: 375010.7500 - val_mae: 475.1190\n",
            "Epoch 1043/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 508331.3438 - mae: 641.7733 - val_loss: 367665.0312 - val_mae: 469.0592\n",
            "Epoch 1044/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 506480.2500 - mae: 639.8348 - val_loss: 383535.4688 - val_mae: 486.5432\n",
            "Epoch 1045/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 504054.5312 - mae: 638.8101 - val_loss: 375129.5312 - val_mae: 475.1960\n",
            "Epoch 1046/2000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 509474.9375 - mae: 642.2756 - val_loss: 360615.1250 - val_mae: 462.0033\n",
            "Epoch 1047/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 507746.0312 - mae: 641.4657 - val_loss: 368281.5312 - val_mae: 469.4226\n",
            "Epoch 1048/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 510193.0938 - mae: 643.1427 - val_loss: 383691.2188 - val_mae: 486.6350\n",
            "Epoch 1049/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 509862.8125 - mae: 643.0145 - val_loss: 390351.9062 - val_mae: 491.1427\n",
            "Epoch 1050/2000\n",
            "39/39 [==============================] - 5s 99ms/step - loss: 500178.4062 - mae: 638.0630 - val_loss: 375819.4688 - val_mae: 477.9336\n",
            "Epoch 1051/2000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 505894.6250 - mae: 639.6588 - val_loss: 368424.5312 - val_mae: 469.5106\n",
            "Epoch 1052/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 505637.0312 - mae: 639.7112 - val_loss: 382765.2500 - val_mae: 483.7734\n",
            "Epoch 1053/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 499984.9375 - mae: 636.3851 - val_loss: 367986.3750 - val_mae: 469.2571\n",
            "Epoch 1054/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 506261.5000 - mae: 640.1710 - val_loss: 368468.0938 - val_mae: 469.5374\n",
            "Epoch 1055/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 504720.4062 - mae: 638.6717 - val_loss: 375934.6250 - val_mae: 478.0029\n",
            "Epoch 1056/2000\n",
            "39/39 [==============================] - 5s 112ms/step - loss: 503814.4375 - mae: 638.3204 - val_loss: 375462.4062 - val_mae: 475.4117\n",
            "Epoch 1057/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 506017.5312 - mae: 640.5560 - val_loss: 390667.0000 - val_mae: 491.3454\n",
            "Epoch 1058/2000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 505471.1562 - mae: 639.5913 - val_loss: 384008.5312 - val_mae: 486.8220\n",
            "Epoch 1059/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 504178.1875 - mae: 638.6136 - val_loss: 367924.8750 - val_mae: 468.0723\n",
            "Epoch 1060/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 503103.7500 - mae: 637.9805 - val_loss: 375911.5000 - val_mae: 476.8402\n",
            "Epoch 1061/2000\n",
            "39/39 [==============================] - 9s 234ms/step - loss: 499957.5938 - mae: 636.2809 - val_loss: 367732.0938 - val_mae: 469.1169\n",
            "Epoch 1062/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 507047.5938 - mae: 639.9355 - val_loss: 376911.5938 - val_mae: 479.7306\n",
            "Epoch 1063/2000\n",
            "39/39 [==============================] - 10s 232ms/step - loss: 503759.6250 - mae: 638.6069 - val_loss: 368236.5312 - val_mae: 469.4113\n",
            "Epoch 1064/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 506306.7188 - mae: 640.2983 - val_loss: 361080.0000 - val_mae: 462.2857\n",
            "Epoch 1065/2000\n",
            "39/39 [==============================] - 10s 235ms/step - loss: 498833.0312 - mae: 637.0703 - val_loss: 376401.2500 - val_mae: 477.1256\n",
            "Epoch 1066/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 507503.8438 - mae: 641.6085 - val_loss: 383452.0312 - val_mae: 485.3504\n",
            "Epoch 1067/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 503801.8438 - mae: 638.7560 - val_loss: 376515.4062 - val_mae: 477.1998\n",
            "Epoch 1068/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 504638.4375 - mae: 638.6382 - val_loss: 368314.3438 - val_mae: 469.4612\n",
            "Epoch 1069/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 501425.3750 - mae: 636.6260 - val_loss: 375560.0000 - val_mae: 476.6449\n",
            "Epoch 1070/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 498931.5625 - mae: 637.8051 - val_loss: 368619.3750 - val_mae: 470.7929\n",
            "Epoch 1071/2000\n",
            "39/39 [==============================] - 5s 99ms/step - loss: 507254.0000 - mae: 642.1614 - val_loss: 361251.7188 - val_mae: 462.3943\n",
            "Epoch 1072/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 506688.6250 - mae: 640.4263 - val_loss: 368454.2812 - val_mae: 469.5511\n",
            "Epoch 1073/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 504889.7812 - mae: 639.1284 - val_loss: 384051.3438 - val_mae: 485.7053\n",
            "Epoch 1074/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 505396.4375 - mae: 638.9927 - val_loss: 376370.6250 - val_mae: 478.2709\n",
            "Epoch 1075/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 503179.5938 - mae: 638.7827 - val_loss: 368948.0938 - val_mae: 469.8389\n",
            "Epoch 1076/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 506626.5625 - mae: 640.1674 - val_loss: 368485.7500 - val_mae: 469.5712\n",
            "Epoch 1077/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 506203.4062 - mae: 640.5761 - val_loss: 376019.8438 - val_mae: 478.4294\n",
            "Epoch 1078/2000\n",
            "39/39 [==============================] - 9s 232ms/step - loss: 505880.8438 - mae: 641.3356 - val_loss: 368308.0000 - val_mae: 468.3257\n",
            "Epoch 1079/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 504684.8125 - mae: 638.6880 - val_loss: 368354.6562 - val_mae: 470.6470\n",
            "Epoch 1080/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 502200.6250 - mae: 639.5098 - val_loss: 391343.8438 - val_mae: 492.9202\n",
            "Epoch 1081/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 511477.3438 - mae: 645.3454 - val_loss: 376786.8750 - val_mae: 477.3762\n",
            "Epoch 1082/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 503147.0312 - mae: 638.5184 - val_loss: 369075.8750 - val_mae: 469.9207\n",
            "Epoch 1083/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 506519.9375 - mae: 641.7016 - val_loss: 369386.8438 - val_mae: 471.2495\n",
            "Epoch 1084/2000\n",
            "39/39 [==============================] - 5s 114ms/step - loss: 506913.0312 - mae: 640.5348 - val_loss: 353954.5000 - val_mae: 454.0433\n",
            "Epoch 1085/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 499771.3438 - mae: 637.5475 - val_loss: 377107.2500 - val_mae: 478.7107\n",
            "Epoch 1086/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 507963.2812 - mae: 641.7662 - val_loss: 384286.6250 - val_mae: 485.8551\n",
            "Epoch 1087/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 503058.4062 - mae: 638.8608 - val_loss: 369499.0938 - val_mae: 469.0366\n",
            "Epoch 1088/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 504768.6875 - mae: 639.5119 - val_loss: 361351.2188 - val_mae: 461.3289\n",
            "Epoch 1089/2000\n",
            "39/39 [==============================] - 5s 90ms/step - loss: 501304.3750 - mae: 636.4855 - val_loss: 376265.5000 - val_mae: 475.9474\n",
            "Epoch 1090/2000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 506389.0312 - mae: 639.7395 - val_loss: 369585.7812 - val_mae: 471.3722\n",
            "Epoch 1091/2000\n",
            "39/39 [==============================] - 5s 114ms/step - loss: 504468.9688 - mae: 639.7088 - val_loss: 368141.4062 - val_mae: 468.2553\n",
            "Epoch 1092/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 506637.6562 - mae: 641.0572 - val_loss: 369396.0938 - val_mae: 470.1258\n",
            "Epoch 1093/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 505902.2188 - mae: 640.4631 - val_loss: 384111.8750 - val_mae: 485.7705\n",
            "Epoch 1094/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 506028.0312 - mae: 640.0876 - val_loss: 355291.0938 - val_mae: 454.8437\n",
            "Epoch 1095/2000\n",
            "39/39 [==============================] - 5s 114ms/step - loss: 494829.8438 - mae: 635.7880 - val_loss: 361848.4062 - val_mae: 462.7709\n",
            "Epoch 1096/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 505527.2812 - mae: 639.9448 - val_loss: 377502.8750 - val_mae: 478.9585\n",
            "Epoch 1097/2000\n",
            "39/39 [==============================] - 10s 234ms/step - loss: 508177.9375 - mae: 642.6814 - val_loss: 377072.4688 - val_mae: 478.7108\n",
            "Epoch 1098/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 503758.6250 - mae: 638.7758 - val_loss: 361687.4688 - val_mae: 461.5490\n",
            "Epoch 1099/2000\n",
            "39/39 [==============================] - 10s 233ms/step - loss: 507392.5312 - mae: 642.3383 - val_loss: 353066.6562 - val_mae: 453.5639\n",
            "Epoch 1100/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 507750.0625 - mae: 641.2372 - val_loss: 376446.7812 - val_mae: 477.2214\n",
            "Epoch 1101/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 496621.6562 - mae: 639.3962 - val_loss: 362290.5938 - val_mae: 461.9080\n",
            "Epoch 1102/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 501281.7812 - mae: 636.5214 - val_loss: 377454.1562 - val_mae: 477.8092\n",
            "Epoch 1103/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 504351.2188 - mae: 639.2589 - val_loss: 384780.5938 - val_mae: 487.6657\n",
            "Epoch 1104/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 505214.4375 - mae: 639.3030 - val_loss: 377042.8438 - val_mae: 477.5752\n",
            "Epoch 1105/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 501748.1250 - mae: 637.6653 - val_loss: 384782.2812 - val_mae: 485.0560\n",
            "Epoch 1106/2000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 505922.4062 - mae: 640.8196 - val_loss: 377602.9062 - val_mae: 477.9055\n",
            "Epoch 1107/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 503653.5938 - mae: 638.6494 - val_loss: 369152.2812 - val_mae: 471.1395\n",
            "Epoch 1108/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 502896.4688 - mae: 637.5795 - val_loss: 385333.5938 - val_mae: 487.6329\n",
            "Epoch 1109/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 507331.2812 - mae: 641.9394 - val_loss: 376398.5000 - val_mae: 476.0807\n",
            "Epoch 1110/2000\n",
            "39/39 [==============================] - 5s 122ms/step - loss: 505060.7500 - mae: 639.4333 - val_loss: 385131.8438 - val_mae: 486.3919\n",
            "Epoch 1111/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 500184.2188 - mae: 635.8787 - val_loss: 377216.3750 - val_mae: 477.6877\n",
            "Epoch 1112/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 501400.2500 - mae: 636.9363 - val_loss: 362775.3438 - val_mae: 463.3309\n",
            "Epoch 1113/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 502949.2188 - mae: 638.2578 - val_loss: 377271.7812 - val_mae: 477.7236\n",
            "Epoch 1114/2000\n",
            "39/39 [==============================] - 5s 115ms/step - loss: 506158.8125 - mae: 641.2098 - val_loss: 378311.5312 - val_mae: 480.9309\n",
            "Epoch 1115/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 503516.0312 - mae: 638.4766 - val_loss: 377837.6562 - val_mae: 478.0576\n",
            "Epoch 1116/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 503150.9688 - mae: 638.3174 - val_loss: 378169.4062 - val_mae: 479.3752\n",
            "Epoch 1117/2000\n",
            "39/39 [==============================] - 9s 207ms/step - loss: 503945.8438 - mae: 638.9614 - val_loss: 370171.3438 - val_mae: 470.6214\n",
            "Epoch 1118/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 509129.7188 - mae: 642.4384 - val_loss: 377733.6562 - val_mae: 479.1244\n",
            "Epoch 1119/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 501716.0938 - mae: 637.1800 - val_loss: 370048.5312 - val_mae: 471.6743\n",
            "Epoch 1120/2000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 505636.6562 - mae: 640.2623 - val_loss: 370348.9688 - val_mae: 470.7347\n",
            "Epoch 1121/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 504836.1250 - mae: 639.1373 - val_loss: 377626.4688 - val_mae: 477.9533\n",
            "Epoch 1122/2000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 502633.0000 - mae: 638.3627 - val_loss: 378363.8438 - val_mae: 479.4966\n",
            "Epoch 1123/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 498372.5625 - mae: 637.7327 - val_loss: 378131.8438 - val_mae: 480.4769\n",
            "Epoch 1124/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 506495.2188 - mae: 640.1470 - val_loss: 369709.3750 - val_mae: 469.2549\n",
            "Epoch 1125/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 509837.0312 - mae: 643.1583 - val_loss: 385681.3438 - val_mae: 489.3223\n",
            "Epoch 1126/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 501380.0938 - mae: 638.9009 - val_loss: 384973.5000 - val_mae: 485.2183\n",
            "Epoch 1127/2000\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 508024.5625 - mae: 641.3092 - val_loss: 370261.2812 - val_mae: 471.8052\n",
            "Epoch 1128/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 503565.4375 - mae: 638.7252 - val_loss: 362566.5000 - val_mae: 462.1232\n",
            "Epoch 1129/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 505770.7188 - mae: 640.1708 - val_loss: 378548.2188 - val_mae: 479.6116\n",
            "Epoch 1130/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 509354.4688 - mae: 643.9439 - val_loss: 385261.7188 - val_mae: 486.5003\n",
            "Epoch 1131/2000\n",
            "39/39 [==============================] - 5s 115ms/step - loss: 508667.5938 - mae: 642.0574 - val_loss: 362583.3438 - val_mae: 462.1342\n",
            "Epoch 1132/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 503711.7812 - mae: 638.4302 - val_loss: 370111.0938 - val_mae: 470.6111\n",
            "Epoch 1133/2000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 499333.6562 - mae: 636.0208 - val_loss: 377619.3438 - val_mae: 476.8554\n",
            "Epoch 1134/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 504748.3438 - mae: 639.7117 - val_loss: 363604.4688 - val_mae: 462.7302\n",
            "Epoch 1135/2000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 505915.4375 - mae: 640.3989 - val_loss: 370393.3438 - val_mae: 469.6678\n",
            "Epoch 1136/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 509660.7500 - mae: 642.9904 - val_loss: 355417.8438 - val_mae: 454.9859\n",
            "Epoch 1137/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 510949.8438 - mae: 645.1191 - val_loss: 370465.3438 - val_mae: 469.7154\n",
            "Epoch 1138/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 504444.8750 - mae: 639.9000 - val_loss: 370720.7500 - val_mae: 470.9719\n",
            "Epoch 1139/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 507224.1562 - mae: 641.3845 - val_loss: 378265.3750 - val_mae: 479.4564\n",
            "Epoch 1140/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 505020.2812 - mae: 639.3633 - val_loss: 362831.6562 - val_mae: 462.2961\n",
            "Epoch 1141/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 506482.9375 - mae: 640.3416 - val_loss: 386263.7188 - val_mae: 488.2015\n",
            "Epoch 1142/2000\n",
            "39/39 [==============================] - 10s 237ms/step - loss: 500304.3125 - mae: 638.0320 - val_loss: 363812.1562 - val_mae: 462.8654\n",
            "Epoch 1143/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 503404.0312 - mae: 638.9368 - val_loss: 370802.9688 - val_mae: 471.0243\n",
            "Epoch 1144/2000\n",
            "39/39 [==============================] - 6s 142ms/step - loss: 504997.3438 - mae: 639.4998 - val_loss: 393809.7812 - val_mae: 496.6843\n",
            "Epoch 1145/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 504960.2188 - mae: 639.8066 - val_loss: 371395.8438 - val_mae: 471.3742\n",
            "Epoch 1146/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 507797.3750 - mae: 641.6023 - val_loss: 378167.6562 - val_mae: 478.3033\n",
            "Epoch 1147/2000\n",
            "39/39 [==============================] - 9s 235ms/step - loss: 499285.1250 - mae: 636.8484 - val_loss: 393196.1562 - val_mae: 493.0255\n",
            "Epoch 1148/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 508252.1250 - mae: 642.1985 - val_loss: 370755.0000 - val_mae: 469.9066\n",
            "Epoch 1149/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 509520.1562 - mae: 643.4815 - val_loss: 378578.7188 - val_mae: 479.6517\n",
            "Epoch 1150/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 509555.4375 - mae: 643.0412 - val_loss: 363830.6562 - val_mae: 463.9936\n",
            "Epoch 1151/2000\n",
            "39/39 [==============================] - 5s 100ms/step - loss: 507206.3750 - mae: 641.7861 - val_loss: 378593.4062 - val_mae: 479.6609\n",
            "Epoch 1152/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 502425.0312 - mae: 638.4241 - val_loss: 378155.4062 - val_mae: 479.4091\n",
            "Epoch 1153/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 506963.3438 - mae: 641.3459 - val_loss: 378637.4688 - val_mae: 479.6884\n",
            "Epoch 1154/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 503254.4688 - mae: 639.0209 - val_loss: 378420.7812 - val_mae: 478.4668\n",
            "Epoch 1155/2000\n",
            "39/39 [==============================] - 5s 100ms/step - loss: 508059.1250 - mae: 641.5589 - val_loss: 370707.9062 - val_mae: 470.9915\n",
            "Epoch 1156/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 501960.7812 - mae: 638.4282 - val_loss: 378221.0938 - val_mae: 479.4500\n",
            "Epoch 1157/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 506317.6875 - mae: 640.7893 - val_loss: 371937.5000 - val_mae: 473.1564\n",
            "Epoch 1158/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 505677.1250 - mae: 639.8181 - val_loss: 386653.2812 - val_mae: 488.4391\n",
            "Epoch 1159/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 504739.7188 - mae: 639.9266 - val_loss: 378496.5312 - val_mae: 478.5157\n",
            "Epoch 1160/2000\n",
            "39/39 [==============================] - 9s 238ms/step - loss: 503050.6250 - mae: 639.4196 - val_loss: 370684.2812 - val_mae: 470.9765\n",
            "Epoch 1161/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 506473.0312 - mae: 640.8415 - val_loss: 370747.9062 - val_mae: 471.0169\n",
            "Epoch 1162/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 506687.9375 - mae: 642.0292 - val_loss: 386491.7812 - val_mae: 487.2530\n",
            "Epoch 1163/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 510466.5000 - mae: 644.3388 - val_loss: 370267.7500 - val_mae: 470.7390\n",
            "Epoch 1164/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 503743.0625 - mae: 639.1450 - val_loss: 371268.1250 - val_mae: 471.6754\n",
            "Epoch 1165/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 499529.7188 - mae: 636.4351 - val_loss: 378786.7188 - val_mae: 479.7813\n",
            "Epoch 1166/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 504902.4375 - mae: 640.5267 - val_loss: 378777.1250 - val_mae: 479.7754\n",
            "Epoch 1167/2000\n",
            "39/39 [==============================] - 10s 237ms/step - loss: 502225.9375 - mae: 638.3734 - val_loss: 371313.5000 - val_mae: 471.3493\n",
            "Epoch 1168/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 507080.3125 - mae: 641.6428 - val_loss: 363108.5312 - val_mae: 463.5868\n",
            "Epoch 1169/2000\n",
            "39/39 [==============================] - 10s 235ms/step - loss: 505864.0000 - mae: 639.9374 - val_loss: 371146.2188 - val_mae: 472.3485\n",
            "Epoch 1170/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 501952.3125 - mae: 640.2860 - val_loss: 378429.9062 - val_mae: 479.5801\n",
            "Epoch 1171/2000\n",
            "39/39 [==============================] - 6s 121ms/step - loss: 502608.2500 - mae: 637.9385 - val_loss: 362725.2188 - val_mae: 463.3696\n",
            "Epoch 1172/2000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 504254.2188 - mae: 640.3848 - val_loss: 370969.2500 - val_mae: 471.1578\n",
            "Epoch 1173/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 500609.4688 - mae: 639.5480 - val_loss: 378442.1562 - val_mae: 479.5878\n",
            "Epoch 1174/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 507290.7188 - mae: 642.1204 - val_loss: 378499.8750 - val_mae: 477.4440\n",
            "Epoch 1175/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 506952.9375 - mae: 641.1817 - val_loss: 371982.5312 - val_mae: 471.7473\n",
            "Epoch 1176/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 502762.0312 - mae: 639.3565 - val_loss: 379205.6250 - val_mae: 478.9413\n",
            "Epoch 1177/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 504793.5625 - mae: 639.6147 - val_loss: 378708.1562 - val_mae: 480.8333\n",
            "Epoch 1178/2000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 502205.6875 - mae: 639.0971 - val_loss: 379693.3438 - val_mae: 481.7598\n",
            "Epoch 1179/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 505016.7188 - mae: 640.2562 - val_loss: 355687.7500 - val_mae: 455.1892\n",
            "Epoch 1180/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 503080.5625 - mae: 638.9774 - val_loss: 378743.2500 - val_mae: 481.2097\n",
            "Epoch 1181/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 507860.2812 - mae: 642.3858 - val_loss: 378999.3750 - val_mae: 479.9137\n",
            "Epoch 1182/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 508235.9688 - mae: 642.5118 - val_loss: 378554.3438 - val_mae: 477.4804\n",
            "Epoch 1183/2000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 497239.7500 - mae: 637.8889 - val_loss: 379266.0312 - val_mae: 481.1580\n",
            "Epoch 1184/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 509907.2500 - mae: 643.2692 - val_loss: 386573.9062 - val_mae: 488.4054\n",
            "Epoch 1185/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 505520.1562 - mae: 639.8404 - val_loss: 371352.6250 - val_mae: 472.4750\n",
            "Epoch 1186/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 506781.5000 - mae: 640.8488 - val_loss: 378584.8750 - val_mae: 479.6766\n",
            "Epoch 1187/2000\n",
            "39/39 [==============================] - 9s 231ms/step - loss: 505499.3438 - mae: 640.2239 - val_loss: 355418.7812 - val_mae: 455.0468\n",
            "Epoch 1188/2000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 505985.2812 - mae: 641.0411 - val_loss: 378907.1562 - val_mae: 479.1353\n",
            "Epoch 1189/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 508401.1562 - mae: 642.7013 - val_loss: 371126.1250 - val_mae: 471.2576\n",
            "Epoch 1190/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 502415.0625 - mae: 637.9969 - val_loss: 371638.5938 - val_mae: 471.5560\n",
            "Epoch 1191/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 501893.0625 - mae: 637.5195 - val_loss: 371455.1250 - val_mae: 470.3681\n",
            "Epoch 1192/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 506748.2500 - mae: 641.0580 - val_loss: 378974.3750 - val_mae: 478.8240\n",
            "Epoch 1193/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 506247.7812 - mae: 640.4268 - val_loss: 379488.5000 - val_mae: 481.2913\n",
            "Epoch 1194/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 505469.2188 - mae: 640.3086 - val_loss: 378631.6562 - val_mae: 478.6349\n",
            "Epoch 1195/2000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 502533.5938 - mae: 640.6866 - val_loss: 379176.6562 - val_mae: 478.9544\n",
            "Epoch 1196/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 504641.0312 - mae: 640.6721 - val_loss: 386914.1562 - val_mae: 488.6126\n",
            "Epoch 1197/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 507564.2500 - mae: 641.7034 - val_loss: 379204.7500 - val_mae: 478.9724\n",
            "Epoch 1198/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 501735.2812 - mae: 637.9598 - val_loss: 378972.3438 - val_mae: 477.7591\n",
            "Epoch 1199/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 503938.6250 - mae: 639.7450 - val_loss: 378757.9062 - val_mae: 478.7163\n",
            "Epoch 1200/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 508586.7812 - mae: 643.4555 - val_loss: 371952.9688 - val_mae: 471.7556\n",
            "Epoch 1201/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 505737.0312 - mae: 640.1255 - val_loss: 379273.7812 - val_mae: 479.0169\n",
            "Epoch 1202/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 505671.3125 - mae: 640.7827 - val_loss: 371064.4062 - val_mae: 471.2459\n",
            "Epoch 1203/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 507306.8125 - mae: 641.8814 - val_loss: 387285.1562 - val_mae: 487.7537\n",
            "Epoch 1204/2000\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 506769.8750 - mae: 641.6180 - val_loss: 371825.8750 - val_mae: 470.6122\n",
            "Epoch 1205/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 505118.3125 - mae: 640.9256 - val_loss: 380146.5938 - val_mae: 480.9608\n",
            "Epoch 1206/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 501451.7500 - mae: 637.4484 - val_loss: 386941.6562 - val_mae: 487.5622\n",
            "Epoch 1207/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 508708.5938 - mae: 642.5396 - val_loss: 372194.5000 - val_mae: 471.9089\n",
            "Epoch 1208/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 504915.8125 - mae: 639.4948 - val_loss: 371227.5938 - val_mae: 471.3496\n",
            "Epoch 1209/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 507236.9688 - mae: 641.7045 - val_loss: 387529.9062 - val_mae: 487.9079\n",
            "Epoch 1210/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 504985.8750 - mae: 640.4860 - val_loss: 378876.1562 - val_mae: 477.7376\n",
            "Epoch 1211/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 504101.0625 - mae: 640.7294 - val_loss: 371849.1250 - val_mae: 472.0713\n",
            "Epoch 1212/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 502202.5000 - mae: 639.7382 - val_loss: 364552.2812 - val_mae: 464.4677\n",
            "Epoch 1213/2000\n",
            "39/39 [==============================] - 5s 120ms/step - loss: 504670.6562 - mae: 640.1583 - val_loss: 387667.7500 - val_mae: 490.1326\n",
            "Epoch 1214/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 509228.7500 - mae: 643.3804 - val_loss: 372662.0312 - val_mae: 473.2600\n",
            "Epoch 1215/2000\n",
            "39/39 [==============================] - 4s 105ms/step - loss: 502706.0000 - mae: 639.2020 - val_loss: 387450.2188 - val_mae: 488.9387\n",
            "Epoch 1216/2000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 505737.6875 - mae: 640.3149 - val_loss: 380448.2812 - val_mae: 480.7932\n",
            "Epoch 1217/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 499588.9062 - mae: 635.7540 - val_loss: 379553.9062 - val_mae: 480.6336\n",
            "Epoch 1218/2000\n",
            "39/39 [==============================] - 5s 112ms/step - loss: 504486.0000 - mae: 640.0126 - val_loss: 372262.5938 - val_mae: 473.0316\n",
            "Epoch 1219/2000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 505081.3750 - mae: 640.7829 - val_loss: 379358.7500 - val_mae: 479.1032\n",
            "Epoch 1220/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 503607.6875 - mae: 639.7214 - val_loss: 357314.5938 - val_mae: 456.2003\n",
            "Epoch 1221/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 502563.0938 - mae: 639.2281 - val_loss: 380396.5938 - val_mae: 479.7077\n",
            "Epoch 1222/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 505109.9688 - mae: 640.3896 - val_loss: 373326.7500 - val_mae: 473.6501\n",
            "Epoch 1223/2000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 496161.2500 - mae: 636.0995 - val_loss: 372117.9062 - val_mae: 471.8873\n",
            "Epoch 1224/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 502524.0312 - mae: 638.3958 - val_loss: 371644.4688 - val_mae: 471.6143\n",
            "Epoch 1225/2000\n",
            "39/39 [==============================] - 6s 130ms/step - loss: 504906.8750 - mae: 640.9223 - val_loss: 380627.9688 - val_mae: 480.9047\n",
            "Epoch 1226/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 499213.5938 - mae: 636.4479 - val_loss: 372118.0312 - val_mae: 471.8875\n",
            "Epoch 1227/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 506529.8438 - mae: 641.4429 - val_loss: 380133.7188 - val_mae: 480.6184\n",
            "Epoch 1228/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 507299.7500 - mae: 642.0455 - val_loss: 364407.2500 - val_mae: 464.3995\n",
            "Epoch 1229/2000\n",
            "39/39 [==============================] - 9s 235ms/step - loss: 497119.1250 - mae: 636.7514 - val_loss: 387425.3438 - val_mae: 487.8670\n",
            "Epoch 1230/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 508168.4688 - mae: 642.8635 - val_loss: 364166.6250 - val_mae: 463.1980\n",
            "Epoch 1231/2000\n",
            "39/39 [==============================] - 10s 235ms/step - loss: 501504.4688 - mae: 637.9592 - val_loss: 373169.0312 - val_mae: 472.4996\n",
            "Epoch 1232/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 502971.4062 - mae: 638.6331 - val_loss: 379932.7500 - val_mae: 479.4408\n",
            "Epoch 1233/2000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 496926.4688 - mae: 637.7091 - val_loss: 379701.9062 - val_mae: 478.2449\n",
            "Epoch 1234/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 504746.8750 - mae: 639.8945 - val_loss: 364828.4688 - val_mae: 464.6401\n",
            "Epoch 1235/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 505243.5000 - mae: 640.1135 - val_loss: 387935.6250 - val_mae: 490.2893\n",
            "Epoch 1236/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 507274.4062 - mae: 641.3959 - val_loss: 371965.7812 - val_mae: 470.7423\n",
            "Epoch 1237/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 505654.7500 - mae: 640.2230 - val_loss: 372475.2500 - val_mae: 471.0387\n",
            "Epoch 1238/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 503441.9375 - mae: 639.4521 - val_loss: 364722.7812 - val_mae: 463.5245\n",
            "Epoch 1239/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 506903.9375 - mae: 641.3364 - val_loss: 387908.4688 - val_mae: 487.0997\n",
            "Epoch 1240/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 510813.3438 - mae: 645.0892 - val_loss: 380113.2812 - val_mae: 479.5569\n",
            "Epoch 1241/2000\n",
            "39/39 [==============================] - 10s 235ms/step - loss: 503258.5625 - mae: 638.8115 - val_loss: 373066.1250 - val_mae: 473.5066\n",
            "Epoch 1242/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 508328.0625 - mae: 642.4686 - val_loss: 365094.0000 - val_mae: 464.8058\n",
            "Epoch 1243/2000\n",
            "39/39 [==============================] - 5s 119ms/step - loss: 501832.0938 - mae: 638.9576 - val_loss: 379724.8438 - val_mae: 479.3385\n",
            "Epoch 1244/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 507240.4688 - mae: 641.7593 - val_loss: 387721.0000 - val_mae: 488.0531\n",
            "Epoch 1245/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 508001.6250 - mae: 642.7538 - val_loss: 357616.2812 - val_mae: 456.3927\n",
            "Epoch 1246/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 506076.5625 - mae: 640.8008 - val_loss: 373486.9062 - val_mae: 472.7007\n",
            "Epoch 1247/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 507194.3438 - mae: 641.5871 - val_loss: 380588.0938 - val_mae: 481.2542\n",
            "Epoch 1248/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 502211.5625 - mae: 638.8762 - val_loss: 372520.0938 - val_mae: 472.1422\n",
            "Epoch 1249/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 501431.4688 - mae: 640.6312 - val_loss: 380514.0312 - val_mae: 478.7426\n",
            "Epoch 1250/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 509049.0938 - mae: 643.3298 - val_loss: 395577.5938 - val_mae: 495.6356\n",
            "Epoch 1251/2000\n",
            "39/39 [==============================] - 9s 232ms/step - loss: 503978.8750 - mae: 639.5261 - val_loss: 379816.8750 - val_mae: 479.3978\n",
            "Epoch 1252/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 499512.8438 - mae: 639.4702 - val_loss: 380239.6562 - val_mae: 479.6380\n",
            "Epoch 1253/2000\n",
            "39/39 [==============================] - 5s 112ms/step - loss: 505938.6562 - mae: 640.7406 - val_loss: 380268.7500 - val_mae: 479.6567\n",
            "Epoch 1254/2000\n",
            "39/39 [==============================] - 9s 209ms/step - loss: 504413.2812 - mae: 640.2233 - val_loss: 373242.3438 - val_mae: 473.6139\n",
            "Epoch 1255/2000\n",
            "39/39 [==============================] - 9s 231ms/step - loss: 502254.3125 - mae: 638.3134 - val_loss: 381030.0000 - val_mae: 481.1537\n",
            "Epoch 1256/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 499859.0938 - mae: 638.1873 - val_loss: 381000.8750 - val_mae: 481.1356\n",
            "Epoch 1257/2000\n",
            "39/39 [==============================] - 10s 234ms/step - loss: 502202.0938 - mae: 639.9732 - val_loss: 380350.5312 - val_mae: 479.7092\n",
            "Epoch 1258/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 507588.8750 - mae: 641.9124 - val_loss: 388179.0938 - val_mae: 489.3813\n",
            "Epoch 1259/2000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 500357.9688 - mae: 638.4907 - val_loss: 388437.6562 - val_mae: 488.4790\n",
            "Epoch 1260/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 502114.3438 - mae: 639.0305 - val_loss: 372661.2812 - val_mae: 472.2315\n",
            "Epoch 1261/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 508315.8750 - mae: 642.5371 - val_loss: 373151.4688 - val_mae: 472.8689\n",
            "Epoch 1262/2000\n",
            "39/39 [==============================] - 5s 114ms/step - loss: 507040.1562 - mae: 642.0377 - val_loss: 380477.0000 - val_mae: 479.7904\n",
            "Epoch 1263/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 507923.7188 - mae: 642.3903 - val_loss: 381042.5938 - val_mae: 480.1222\n",
            "Epoch 1264/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 505340.5625 - mae: 640.1243 - val_loss: 396185.2812 - val_mae: 497.0564\n",
            "Epoch 1265/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 506954.3438 - mae: 641.9984 - val_loss: 381351.2500 - val_mae: 481.7065\n",
            "Epoch 1266/2000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 503498.5000 - mae: 638.8966 - val_loss: 372618.9062 - val_mae: 471.1708\n",
            "Epoch 1267/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 506369.5625 - mae: 641.2206 - val_loss: 388708.8750 - val_mae: 488.6493\n",
            "Epoch 1268/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 504389.2188 - mae: 640.8696 - val_loss: 364823.4688 - val_mae: 463.6233\n",
            "Epoch 1269/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 508252.3438 - mae: 642.5024 - val_loss: 365555.2500 - val_mae: 465.0932\n",
            "Epoch 1270/2000\n",
            "39/39 [==============================] - 10s 242ms/step - loss: 505336.5625 - mae: 641.4405 - val_loss: 373374.7500 - val_mae: 472.6562\n",
            "Epoch 1271/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 506308.5938 - mae: 641.5220 - val_loss: 364397.3750 - val_mae: 463.3813\n",
            "Epoch 1272/2000\n",
            "39/39 [==============================] - 5s 112ms/step - loss: 503463.1250 - mae: 639.9941 - val_loss: 388501.7812 - val_mae: 487.4855\n",
            "Epoch 1273/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 509086.8438 - mae: 643.3367 - val_loss: 388321.3438 - val_mae: 488.4304\n",
            "Epoch 1274/2000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 504466.8125 - mae: 639.3778 - val_loss: 373220.3438 - val_mae: 473.6158\n",
            "Epoch 1275/2000\n",
            "39/39 [==============================] - 10s 245ms/step - loss: 506932.0312 - mae: 642.0225 - val_loss: 365666.6250 - val_mae: 465.1626\n",
            "Epoch 1276/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 506791.4375 - mae: 642.1535 - val_loss: 373059.6562 - val_mae: 472.4834\n",
            "Epoch 1277/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 507606.5312 - mae: 642.2137 - val_loss: 358179.1250 - val_mae: 456.7511\n",
            "Epoch 1278/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 508523.9062 - mae: 643.6639 - val_loss: 372562.0000 - val_mae: 472.1954\n",
            "Epoch 1279/2000\n",
            "39/39 [==============================] - 9s 231ms/step - loss: 502734.8438 - mae: 639.1215 - val_loss: 373824.7188 - val_mae: 473.9685\n",
            "Epoch 1280/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 505218.6250 - mae: 640.4857 - val_loss: 381163.5938 - val_mae: 479.1735\n",
            "Epoch 1281/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 507693.9062 - mae: 643.0726 - val_loss: 373403.8750 - val_mae: 471.6472\n",
            "Epoch 1282/2000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 508565.5000 - mae: 643.1639 - val_loss: 396741.4062 - val_mae: 498.4301\n",
            "Epoch 1283/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 509711.7812 - mae: 644.4365 - val_loss: 389252.1250 - val_mae: 490.0177\n",
            "Epoch 1284/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 505503.1250 - mae: 641.2080 - val_loss: 365911.7812 - val_mae: 465.3150\n",
            "Epoch 1285/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 501277.3438 - mae: 637.9604 - val_loss: 373213.9688 - val_mae: 472.5809\n",
            "Epoch 1286/2000\n",
            "39/39 [==============================] - 10s 230ms/step - loss: 509664.8438 - mae: 643.6852 - val_loss: 381261.3438 - val_mae: 481.3166\n",
            "Epoch 1287/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 504898.0000 - mae: 640.1984 - val_loss: 388622.7188 - val_mae: 488.6196\n",
            "Epoch 1288/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 504059.1875 - mae: 640.4633 - val_loss: 381788.6562 - val_mae: 481.6227\n",
            "Epoch 1289/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 503009.5625 - mae: 639.0498 - val_loss: 381347.0312 - val_mae: 481.3695\n",
            "Epoch 1290/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 505170.0938 - mae: 639.7753 - val_loss: 382076.8438 - val_mae: 482.8271\n",
            "Epoch 1291/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 505538.5000 - mae: 640.6015 - val_loss: 381875.3750 - val_mae: 481.6762\n",
            "Epoch 1292/2000\n",
            "39/39 [==============================] - 10s 235ms/step - loss: 509362.3438 - mae: 644.0206 - val_loss: 366017.0938 - val_mae: 465.3805\n",
            "Epoch 1293/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 505840.4062 - mae: 641.2758 - val_loss: 373851.9688 - val_mae: 472.9574\n",
            "Epoch 1294/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 507910.2812 - mae: 642.4476 - val_loss: 388689.9688 - val_mae: 488.6618\n",
            "Epoch 1295/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 508710.4375 - mae: 643.0294 - val_loss: 373827.5312 - val_mae: 472.9420\n",
            "Epoch 1296/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 508096.0938 - mae: 643.2233 - val_loss: 373303.5000 - val_mae: 472.6375\n",
            "Epoch 1297/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 499629.1250 - mae: 638.3047 - val_loss: 396733.9062 - val_mae: 497.3938\n",
            "Epoch 1298/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 506761.7812 - mae: 641.8371 - val_loss: 380921.8438 - val_mae: 479.0548\n",
            "Epoch 1299/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 510521.6875 - mae: 644.5859 - val_loss: 388910.0000 - val_mae: 489.8241\n",
            "Epoch 1300/2000\n",
            "39/39 [==============================] - 10s 238ms/step - loss: 502932.7188 - mae: 640.7351 - val_loss: 373869.7188 - val_mae: 472.9687\n",
            "Epoch 1301/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 506369.0938 - mae: 641.2982 - val_loss: 365525.2500 - val_mae: 465.0963\n",
            "Epoch 1302/2000\n",
            "39/39 [==============================] - 5s 112ms/step - loss: 506808.8438 - mae: 642.2477 - val_loss: 388537.0000 - val_mae: 487.5434\n",
            "Epoch 1303/2000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 503778.3125 - mae: 640.8790 - val_loss: 365883.7500 - val_mae: 464.2747\n",
            "Epoch 1304/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 500768.3125 - mae: 639.1431 - val_loss: 382197.1250 - val_mae: 482.8986\n",
            "Epoch 1305/2000\n",
            "39/39 [==============================] - 5s 113ms/step - loss: 504715.4375 - mae: 641.3563 - val_loss: 381579.4062 - val_mae: 481.5131\n",
            "Epoch 1306/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 500733.9062 - mae: 639.1748 - val_loss: 381073.5000 - val_mae: 481.2203\n",
            "Epoch 1307/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 503190.7500 - mae: 640.1902 - val_loss: 374454.0938 - val_mae: 473.3112\n",
            "Epoch 1308/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 504259.5000 - mae: 639.9343 - val_loss: 373569.9062 - val_mae: 472.8057\n",
            "Epoch 1309/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 509502.9062 - mae: 644.1241 - val_loss: 365729.0938 - val_mae: 465.2231\n",
            "Epoch 1310/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 499867.0938 - mae: 638.2811 - val_loss: 366058.8438 - val_mae: 464.3877\n",
            "Epoch 1311/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 503263.7812 - mae: 640.9285 - val_loss: 366523.0000 - val_mae: 464.6540\n",
            "Epoch 1312/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 506563.9688 - mae: 641.5859 - val_loss: 381662.6250 - val_mae: 481.9181\n",
            "Epoch 1313/2000\n",
            "39/39 [==============================] - 5s 112ms/step - loss: 507772.8750 - mae: 643.2746 - val_loss: 381852.2500 - val_mae: 482.7020\n",
            "Epoch 1314/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 504689.5312 - mae: 640.1143 - val_loss: 381928.2812 - val_mae: 480.6893\n",
            "Epoch 1315/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 507432.4062 - mae: 642.4716 - val_loss: 381180.2812 - val_mae: 479.2260\n",
            "Epoch 1316/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 504969.0312 - mae: 640.5204 - val_loss: 366518.3750 - val_mae: 464.6510\n",
            "Epoch 1317/2000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 506301.0312 - mae: 641.8227 - val_loss: 389457.3750 - val_mae: 489.1187\n",
            "Epoch 1318/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 506726.8438 - mae: 642.4515 - val_loss: 365808.2500 - val_mae: 465.2723\n",
            "Epoch 1319/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 504462.5938 - mae: 639.9151 - val_loss: 381248.5938 - val_mae: 481.3285\n",
            "Epoch 1320/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 504937.5625 - mae: 641.0496 - val_loss: 381779.1562 - val_mae: 481.6364\n",
            "Epoch 1321/2000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 495419.8750 - mae: 636.3341 - val_loss: 381279.5000 - val_mae: 479.2917\n",
            "Epoch 1322/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 497874.1875 - mae: 637.7840 - val_loss: 373666.6562 - val_mae: 472.8667\n",
            "Epoch 1323/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 506607.9375 - mae: 642.6334 - val_loss: 396422.5000 - val_mae: 494.1452\n",
            "Epoch 1324/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 503841.0938 - mae: 640.9760 - val_loss: 366596.5000 - val_mae: 464.7014\n",
            "Epoch 1325/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 504690.3438 - mae: 640.2261 - val_loss: 373894.2188 - val_mae: 474.0257\n",
            "Epoch 1326/2000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 505066.9375 - mae: 640.5503 - val_loss: 382216.0000 - val_mae: 481.8864\n",
            "Epoch 1327/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 501507.8750 - mae: 639.0294 - val_loss: 381482.2500 - val_mae: 482.4906\n",
            "Epoch 1328/2000\n",
            "39/39 [==============================] - 9s 232ms/step - loss: 500571.8125 - mae: 637.6608 - val_loss: 381931.0938 - val_mae: 482.7489\n",
            "Epoch 1329/2000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 507811.2812 - mae: 642.4073 - val_loss: 382224.3750 - val_mae: 482.2451\n",
            "Epoch 1330/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 507930.9375 - mae: 643.1213 - val_loss: 382021.0000 - val_mae: 482.8023\n",
            "Epoch 1331/2000\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 496197.9062 - mae: 637.0279 - val_loss: 365680.3438 - val_mae: 464.1766\n",
            "Epoch 1332/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 504884.3438 - mae: 641.3428 - val_loss: 382300.2188 - val_mae: 481.9384\n",
            "Epoch 1333/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 508676.4375 - mae: 643.0103 - val_loss: 366419.2188 - val_mae: 465.6302\n",
            "Epoch 1334/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 502357.9688 - mae: 640.1354 - val_loss: 374253.2812 - val_mae: 473.2105\n",
            "Epoch 1335/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 499461.1875 - mae: 638.9583 - val_loss: 390087.4688 - val_mae: 491.5418\n",
            "Epoch 1336/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 509753.1875 - mae: 644.0351 - val_loss: 380901.1562 - val_mae: 479.0827\n",
            "Epoch 1337/2000\n",
            "39/39 [==============================] - 6s 129ms/step - loss: 502476.4375 - mae: 638.9115 - val_loss: 366014.1250 - val_mae: 465.4001\n",
            "Epoch 1338/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 497444.1250 - mae: 638.1315 - val_loss: 382401.5938 - val_mae: 482.0008\n",
            "Epoch 1339/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 505492.3438 - mae: 641.9344 - val_loss: 373607.6562 - val_mae: 473.8665\n",
            "Epoch 1340/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 504935.4375 - mae: 640.3016 - val_loss: 374589.8750 - val_mae: 474.4334\n",
            "Epoch 1341/2000\n",
            "39/39 [==============================] - 5s 112ms/step - loss: 504925.6562 - mae: 640.7929 - val_loss: 365374.7812 - val_mae: 464.0127\n",
            "Epoch 1342/2000\n",
            "39/39 [==============================] - 5s 100ms/step - loss: 503732.9062 - mae: 639.5522 - val_loss: 374891.7500 - val_mae: 473.5869\n",
            "Epoch 1343/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 507234.2500 - mae: 642.4429 - val_loss: 389749.9062 - val_mae: 489.3019\n",
            "Epoch 1344/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 503988.5000 - mae: 639.9896 - val_loss: 381952.8750 - val_mae: 481.7435\n",
            "Epoch 1345/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 506141.2188 - mae: 642.1400 - val_loss: 374141.2188 - val_mae: 472.1292\n",
            "Epoch 1346/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 506969.3750 - mae: 642.6451 - val_loss: 375088.1250 - val_mae: 474.7211\n",
            "Epoch 1347/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 504101.4375 - mae: 639.6933 - val_loss: 365456.6562 - val_mae: 464.0655\n",
            "Epoch 1348/2000\n",
            "39/39 [==============================] - 6s 148ms/step - loss: 508850.0312 - mae: 643.8427 - val_loss: 389347.0000 - val_mae: 489.0736\n",
            "Epoch 1349/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 506224.1562 - mae: 641.2738 - val_loss: 373946.7812 - val_mae: 473.0433\n",
            "Epoch 1350/2000\n",
            "39/39 [==============================] - 5s 118ms/step - loss: 501668.6562 - mae: 637.8389 - val_loss: 390019.2500 - val_mae: 490.4814\n",
            "Epoch 1351/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 506493.1250 - mae: 642.0393 - val_loss: 381766.1250 - val_mae: 480.6160\n",
            "Epoch 1352/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 508499.5000 - mae: 642.9221 - val_loss: 374477.4688 - val_mae: 473.3518\n",
            "Epoch 1353/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 498395.7188 - mae: 637.8472 - val_loss: 389855.1562 - val_mae: 489.3678\n",
            "Epoch 1354/2000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 500177.9375 - mae: 639.1411 - val_loss: 381739.9062 - val_mae: 480.5992\n",
            "Epoch 1355/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 502824.3125 - mae: 640.0024 - val_loss: 397171.9062 - val_mae: 496.6499\n",
            "Epoch 1356/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 502828.1875 - mae: 639.8705 - val_loss: 382056.5938 - val_mae: 481.8075\n",
            "Epoch 1357/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 507491.5000 - mae: 642.7653 - val_loss: 389661.4688 - val_mae: 488.2376\n",
            "Epoch 1358/2000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 507668.0938 - mae: 642.5156 - val_loss: 366428.4062 - val_mae: 464.6257\n",
            "Epoch 1359/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 508506.6562 - mae: 643.3920 - val_loss: 373559.2812 - val_mae: 472.8252\n",
            "Epoch 1360/2000\n",
            "39/39 [==============================] - 4s 104ms/step - loss: 507100.5938 - mae: 641.5610 - val_loss: 374073.3438 - val_mae: 473.1230\n",
            "Epoch 1361/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 503453.2188 - mae: 639.0924 - val_loss: 374359.7500 - val_mae: 474.3083\n",
            "Epoch 1362/2000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 507884.5938 - mae: 642.4638 - val_loss: 367048.8438 - val_mae: 464.9924\n",
            "Epoch 1363/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 501661.1875 - mae: 640.1519 - val_loss: 373875.5312 - val_mae: 471.9928\n",
            "Epoch 1364/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 504138.8750 - mae: 640.2216 - val_loss: 374601.5312 - val_mae: 473.4298\n",
            "Epoch 1365/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 507557.0625 - mae: 642.3806 - val_loss: 374628.5000 - val_mae: 473.4469\n",
            "Epoch 1366/2000\n",
            "39/39 [==============================] - 10s 237ms/step - loss: 508836.9688 - mae: 643.9258 - val_loss: 374481.8438 - val_mae: 472.3514\n",
            "Epoch 1367/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 497633.4688 - mae: 637.4448 - val_loss: 390331.1250 - val_mae: 490.6696\n",
            "Epoch 1368/2000\n",
            "39/39 [==============================] - 9s 232ms/step - loss: 500109.8125 - mae: 639.5657 - val_loss: 382021.0000 - val_mae: 480.7788\n",
            "Epoch 1369/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 505795.2812 - mae: 640.8780 - val_loss: 374506.0000 - val_mae: 472.3672\n",
            "Epoch 1370/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 501016.9375 - mae: 640.3250 - val_loss: 389814.1562 - val_mae: 490.3706\n",
            "Epoch 1371/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 503285.8438 - mae: 639.1974 - val_loss: 382761.0000 - val_mae: 482.2223\n",
            "Epoch 1372/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 506826.5625 - mae: 642.5452 - val_loss: 367345.7188 - val_mae: 466.1837\n",
            "Epoch 1373/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 507758.2188 - mae: 642.5995 - val_loss: 366915.6562 - val_mae: 465.9382\n",
            "Epoch 1374/2000\n",
            "39/39 [==============================] - 10s 238ms/step - loss: 507502.5938 - mae: 642.2116 - val_loss: 366905.3438 - val_mae: 465.9318\n",
            "Epoch 1375/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 504243.2500 - mae: 640.2751 - val_loss: 389705.3438 - val_mae: 489.2979\n",
            "Epoch 1376/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 500110.2188 - mae: 639.6158 - val_loss: 374303.6562 - val_mae: 473.2682\n",
            "Epoch 1377/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 502197.2812 - mae: 639.7419 - val_loss: 390671.0312 - val_mae: 491.8810\n",
            "Epoch 1378/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 502702.8438 - mae: 640.3524 - val_loss: 382634.6562 - val_mae: 481.1404\n",
            "Epoch 1379/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 502853.5938 - mae: 640.2489 - val_loss: 389985.0000 - val_mae: 488.4471\n",
            "Epoch 1380/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 492174.5938 - mae: 635.7349 - val_loss: 366699.2188 - val_mae: 464.8000\n",
            "Epoch 1381/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 497582.6250 - mae: 638.6955 - val_loss: 374266.6250 - val_mae: 473.2448\n",
            "Epoch 1382/2000\n",
            "39/39 [==============================] - 4s 104ms/step - loss: 506129.4688 - mae: 643.8056 - val_loss: 382295.5938 - val_mae: 481.9547\n",
            "Epoch 1383/2000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 504072.9375 - mae: 640.1005 - val_loss: 381628.2812 - val_mae: 480.5583\n",
            "Epoch 1384/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 503194.9688 - mae: 639.1259 - val_loss: 389952.1562 - val_mae: 488.4258\n",
            "Epoch 1385/2000\n",
            "39/39 [==============================] - 4s 104ms/step - loss: 506156.8750 - mae: 642.5214 - val_loss: 374032.9688 - val_mae: 474.1247\n",
            "Epoch 1386/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 504202.8125 - mae: 639.9673 - val_loss: 367215.7500 - val_mae: 465.0997\n",
            "Epoch 1387/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 503772.2812 - mae: 640.4603 - val_loss: 382169.3438 - val_mae: 480.8735\n",
            "Epoch 1388/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 508005.6562 - mae: 643.3660 - val_loss: 390045.2188 - val_mae: 488.4860\n",
            "Epoch 1389/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 507630.5312 - mae: 642.6485 - val_loss: 375112.9688 - val_mae: 475.1039\n",
            "Epoch 1390/2000\n",
            "39/39 [==============================] - 9s 233ms/step - loss: 505829.9062 - mae: 640.9423 - val_loss: 358974.3438 - val_mae: 457.2843\n",
            "Epoch 1391/2000\n",
            "39/39 [==============================] - 6s 137ms/step - loss: 504189.2188 - mae: 641.5245 - val_loss: 374426.0938 - val_mae: 473.3452\n",
            "Epoch 1392/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 503623.5312 - mae: 640.0947 - val_loss: 382004.9688 - val_mae: 481.7950\n",
            "Epoch 1393/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 505492.9062 - mae: 641.4131 - val_loss: 382476.3438 - val_mae: 482.0661\n",
            "Epoch 1394/2000\n",
            "39/39 [==============================] - 5s 112ms/step - loss: 502736.3125 - mae: 638.5402 - val_loss: 366433.7188 - val_mae: 464.6618\n",
            "Epoch 1395/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 508167.1250 - mae: 643.8682 - val_loss: 374671.7188 - val_mae: 474.4975\n",
            "Epoch 1396/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 492685.9062 - mae: 635.3577 - val_loss: 383272.0312 - val_mae: 483.5365\n",
            "Epoch 1397/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 502474.2500 - mae: 639.9348 - val_loss: 366380.4688 - val_mae: 464.6276\n",
            "Epoch 1398/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 504940.5000 - mae: 641.1266 - val_loss: 382557.0938 - val_mae: 482.1158\n",
            "Epoch 1399/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 506237.5312 - mae: 642.3226 - val_loss: 374305.0312 - val_mae: 472.2730\n",
            "Epoch 1400/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 505853.0625 - mae: 641.1428 - val_loss: 359077.1562 - val_mae: 457.3495\n",
            "Epoch 1401/2000\n",
            "39/39 [==============================] - 10s 236ms/step - loss: 505760.0000 - mae: 641.8412 - val_loss: 382362.5938 - val_mae: 480.9969\n",
            "Epoch 1402/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 503898.0312 - mae: 640.2908 - val_loss: 366486.0938 - val_mae: 464.6955\n",
            "Epoch 1403/2000\n",
            "39/39 [==============================] - 5s 122ms/step - loss: 505190.5938 - mae: 640.2890 - val_loss: 390171.3438 - val_mae: 490.5862\n",
            "Epoch 1404/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 499948.5625 - mae: 639.3780 - val_loss: 366702.9062 - val_mae: 465.8275\n",
            "Epoch 1405/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 503987.3438 - mae: 640.2521 - val_loss: 374833.9062 - val_mae: 472.5808\n",
            "Epoch 1406/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 509692.7188 - mae: 644.4628 - val_loss: 382897.7500 - val_mae: 481.3082\n",
            "Epoch 1407/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 504794.1875 - mae: 641.1917 - val_loss: 368280.0938 - val_mae: 466.7412\n",
            "Epoch 1408/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 503277.4375 - mae: 639.2227 - val_loss: 382935.6250 - val_mae: 483.3451\n",
            "Epoch 1409/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 500710.4688 - mae: 638.0977 - val_loss: 390107.3750 - val_mae: 487.5365\n",
            "Epoch 1410/2000\n",
            "39/39 [==============================] - 10s 236ms/step - loss: 495746.1562 - mae: 635.6013 - val_loss: 390557.7500 - val_mae: 489.8069\n",
            "Epoch 1411/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 505116.7188 - mae: 641.5031 - val_loss: 358753.3750 - val_mae: 457.1722\n",
            "Epoch 1412/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 502004.8125 - mae: 639.3097 - val_loss: 382512.5312 - val_mae: 481.0926\n",
            "Epoch 1413/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 502326.0000 - mae: 640.5703 - val_loss: 382798.8750 - val_mae: 480.2545\n",
            "Epoch 1414/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 500488.3125 - mae: 638.1161 - val_loss: 367816.4062 - val_mae: 466.4750\n",
            "Epoch 1415/2000\n",
            "39/39 [==============================] - 9s 231ms/step - loss: 503932.4375 - mae: 639.9517 - val_loss: 397483.8750 - val_mae: 494.8634\n",
            "Epoch 1416/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 507737.0938 - mae: 643.8367 - val_loss: 382528.3438 - val_mae: 481.1026\n",
            "Epoch 1417/2000\n",
            "39/39 [==============================] - 10s 238ms/step - loss: 508085.1875 - mae: 642.5486 - val_loss: 382629.8438 - val_mae: 481.1674\n",
            "Epoch 1418/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 504780.2812 - mae: 640.4835 - val_loss: 390481.9688 - val_mae: 490.7733\n",
            "Epoch 1419/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 505268.8750 - mae: 641.3978 - val_loss: 382978.0312 - val_mae: 480.3727\n",
            "Epoch 1420/2000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 501793.9375 - mae: 638.4547 - val_loss: 383645.2812 - val_mae: 483.7576\n",
            "Epoch 1421/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 504715.3438 - mae: 640.7027 - val_loss: 375058.1562 - val_mae: 474.7317\n",
            "Epoch 1422/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 504640.2500 - mae: 640.6030 - val_loss: 375398.2500 - val_mae: 473.9307\n",
            "Epoch 1423/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 508869.1250 - mae: 643.3597 - val_loss: 390098.9688 - val_mae: 488.5550\n",
            "Epoch 1424/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 507839.5312 - mae: 643.3118 - val_loss: 367079.8750 - val_mae: 466.0609\n",
            "Epoch 1425/2000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 504261.6562 - mae: 640.7389 - val_loss: 367319.5000 - val_mae: 465.1986\n",
            "Epoch 1426/2000\n",
            "39/39 [==============================] - 5s 100ms/step - loss: 496149.2188 - mae: 635.9273 - val_loss: 375148.5938 - val_mae: 474.7863\n",
            "Epoch 1427/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 502016.3750 - mae: 638.9164 - val_loss: 382769.2812 - val_mae: 481.2562\n",
            "Epoch 1428/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 496938.7188 - mae: 638.7190 - val_loss: 382249.1250 - val_mae: 481.3071\n",
            "Epoch 1429/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 503452.3438 - mae: 639.2974 - val_loss: 382962.1562 - val_mae: 482.3651\n",
            "Epoch 1430/2000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 502958.8438 - mae: 640.4873 - val_loss: 375118.0000 - val_mae: 475.1209\n",
            "Epoch 1431/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 507840.0625 - mae: 642.7003 - val_loss: 374923.8750 - val_mae: 473.6582\n",
            "Epoch 1432/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 501207.2812 - mae: 638.4678 - val_loss: 383005.2500 - val_mae: 482.3915\n",
            "Epoch 1433/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 503672.0938 - mae: 640.3948 - val_loss: 374933.7500 - val_mae: 473.6644\n",
            "Epoch 1434/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 505095.2188 - mae: 641.9964 - val_loss: 375662.3438 - val_mae: 475.0830\n",
            "Epoch 1435/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 507649.7188 - mae: 642.8102 - val_loss: 382597.7812 - val_mae: 482.1600\n",
            "Epoch 1436/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 507816.1562 - mae: 642.9260 - val_loss: 390650.7500 - val_mae: 488.8773\n",
            "Epoch 1437/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 507399.3750 - mae: 642.9137 - val_loss: 398560.3750 - val_mae: 498.8661\n",
            "Epoch 1438/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 497015.1562 - mae: 638.0757 - val_loss: 375988.8438 - val_mae: 474.2762\n",
            "Epoch 1439/2000\n",
            "39/39 [==============================] - 5s 117ms/step - loss: 501150.5312 - mae: 638.3967 - val_loss: 366940.5000 - val_mae: 464.9875\n",
            "Epoch 1440/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 498119.5312 - mae: 637.7595 - val_loss: 375040.2812 - val_mae: 473.7313\n",
            "Epoch 1441/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 504148.0938 - mae: 640.5573 - val_loss: 383572.9688 - val_mae: 482.7216\n",
            "Epoch 1442/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 505430.0625 - mae: 642.1676 - val_loss: 383101.6562 - val_mae: 482.8037\n",
            "Epoch 1443/2000\n",
            "39/39 [==============================] - 5s 98ms/step - loss: 504278.4688 - mae: 640.5316 - val_loss: 367616.5312 - val_mae: 466.3721\n",
            "Epoch 1444/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 506662.2812 - mae: 642.0363 - val_loss: 383328.5000 - val_mae: 481.5826\n",
            "Epoch 1445/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 509067.1250 - mae: 643.7051 - val_loss: 390681.0000 - val_mae: 490.8932\n",
            "Epoch 1446/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 507416.0000 - mae: 642.8140 - val_loss: 390500.1250 - val_mae: 489.7944\n",
            "Epoch 1447/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 508541.9062 - mae: 643.0335 - val_loss: 359118.1562 - val_mae: 457.4033\n",
            "Epoch 1448/2000\n",
            "39/39 [==============================] - 10s 237ms/step - loss: 507961.5625 - mae: 643.0779 - val_loss: 375077.7500 - val_mae: 473.7549\n",
            "Epoch 1449/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 504643.5625 - mae: 642.8670 - val_loss: 391207.2500 - val_mae: 491.1974\n",
            "Epoch 1450/2000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 503886.0625 - mae: 640.5896 - val_loss: 383342.3438 - val_mae: 483.5860\n",
            "Epoch 1451/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 505594.1562 - mae: 641.3024 - val_loss: 367752.4688 - val_mae: 466.4561\n",
            "Epoch 1452/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 504660.6562 - mae: 640.9158 - val_loss: 383181.5000 - val_mae: 482.8527\n",
            "Epoch 1453/2000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 507856.0938 - mae: 642.5579 - val_loss: 375866.1562 - val_mae: 473.2161\n",
            "Epoch 1454/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 506239.6250 - mae: 641.9410 - val_loss: 376117.9062 - val_mae: 474.3571\n",
            "Epoch 1455/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 506812.3438 - mae: 642.3201 - val_loss: 367764.9062 - val_mae: 466.4637\n",
            "Epoch 1456/2000\n",
            "39/39 [==============================] - 10s 239ms/step - loss: 510419.1875 - mae: 645.1992 - val_loss: 375673.2188 - val_mae: 474.1033\n",
            "Epoch 1457/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 501342.3750 - mae: 638.2012 - val_loss: 383229.7188 - val_mae: 482.5294\n",
            "Epoch 1458/2000\n",
            "39/39 [==============================] - 10s 243ms/step - loss: 502712.5312 - mae: 640.1814 - val_loss: 375370.6250 - val_mae: 474.9207\n",
            "Epoch 1459/2000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 506232.7812 - mae: 642.1342 - val_loss: 368540.6562 - val_mae: 465.9180\n",
            "Epoch 1460/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 505832.5312 - mae: 641.1312 - val_loss: 383492.8750 - val_mae: 481.6873\n",
            "Epoch 1461/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 505879.4375 - mae: 641.3714 - val_loss: 375218.8438 - val_mae: 473.8434\n",
            "Epoch 1462/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 502319.5312 - mae: 639.8228 - val_loss: 376217.6562 - val_mae: 474.4197\n",
            "Epoch 1463/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 506909.5000 - mae: 643.1017 - val_loss: 382663.8750 - val_mae: 481.2189\n",
            "Epoch 1464/2000\n",
            "39/39 [==============================] - 5s 102ms/step - loss: 501055.5312 - mae: 637.9778 - val_loss: 399054.5938 - val_mae: 499.7975\n",
            "Epoch 1465/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 501640.8750 - mae: 639.6664 - val_loss: 391213.5312 - val_mae: 490.2160\n",
            "Epoch 1466/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 506773.6875 - mae: 642.9714 - val_loss: 383362.0000 - val_mae: 482.6108\n",
            "Epoch 1467/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 506191.4688 - mae: 641.9984 - val_loss: 390948.6250 - val_mae: 491.0543\n",
            "Epoch 1468/2000\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 508878.0000 - mae: 643.6900 - val_loss: 382402.0938 - val_mae: 480.0743\n",
            "Epoch 1469/2000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 501826.8750 - mae: 639.4228 - val_loss: 367427.3750 - val_mae: 466.6284\n",
            "Epoch 1470/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 497846.0000 - mae: 638.1824 - val_loss: 383600.2188 - val_mae: 481.7556\n",
            "Epoch 1471/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 507086.0625 - mae: 642.2461 - val_loss: 390489.9062 - val_mae: 488.8076\n",
            "Epoch 1472/2000\n",
            "39/39 [==============================] - 10s 233ms/step - loss: 500130.8125 - mae: 638.1074 - val_loss: 383463.1562 - val_mae: 483.6575\n",
            "Epoch 1473/2000\n",
            "39/39 [==============================] - 9s 231ms/step - loss: 509266.6250 - mae: 644.1004 - val_loss: 398930.7812 - val_mae: 499.7245\n",
            "Epoch 1474/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 502647.2812 - mae: 638.9250 - val_loss: 375465.3438 - val_mae: 472.9918\n",
            "Epoch 1475/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 507358.9062 - mae: 642.9185 - val_loss: 383042.9688 - val_mae: 481.4305\n",
            "Epoch 1476/2000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 507282.8125 - mae: 642.5698 - val_loss: 398764.3750 - val_mae: 498.6378\n",
            "Epoch 1477/2000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 501414.3125 - mae: 639.4100 - val_loss: 383248.0312 - val_mae: 482.5407\n",
            "Epoch 1478/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 501784.4688 - mae: 638.7326 - val_loss: 391112.3438 - val_mae: 490.1530\n",
            "Epoch 1479/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 508305.6875 - mae: 643.3993 - val_loss: 383065.8750 - val_mae: 481.4451\n",
            "Epoch 1480/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 502948.9062 - mae: 640.0641 - val_loss: 367853.8750 - val_mae: 466.5187\n",
            "Epoch 1481/2000\n",
            "39/39 [==============================] - 9s 234ms/step - loss: 506520.6875 - mae: 641.8138 - val_loss: 383546.0312 - val_mae: 483.7065\n",
            "Epoch 1482/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 506089.5312 - mae: 641.4553 - val_loss: 383763.8750 - val_mae: 482.8388\n",
            "Epoch 1483/2000\n",
            "39/39 [==============================] - 10s 239ms/step - loss: 503230.2812 - mae: 639.7492 - val_loss: 360208.2812 - val_mae: 458.0374\n",
            "Epoch 1484/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 506163.8125 - mae: 641.1795 - val_loss: 383243.6562 - val_mae: 482.5381\n",
            "Epoch 1485/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 506775.1562 - mae: 642.1892 - val_loss: 375486.5938 - val_mae: 473.0056\n",
            "Epoch 1486/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 500541.9688 - mae: 639.0477 - val_loss: 382616.5000 - val_mae: 481.1887\n",
            "Epoch 1487/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 505170.5000 - mae: 641.3528 - val_loss: 382562.2500 - val_mae: 481.1541\n",
            "Epoch 1488/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 506643.5938 - mae: 642.0929 - val_loss: 391210.8438 - val_mae: 490.2144\n",
            "Epoch 1489/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 505916.0938 - mae: 641.2585 - val_loss: 383142.9688 - val_mae: 481.4942\n",
            "Epoch 1490/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 508104.0000 - mae: 643.4911 - val_loss: 375292.2812 - val_mae: 473.8895\n",
            "Epoch 1491/2000\n",
            "39/39 [==============================] - 10s 226ms/step - loss: 505860.8125 - mae: 641.5915 - val_loss: 360376.5312 - val_mae: 458.1437\n",
            "Epoch 1492/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 506303.8438 - mae: 641.7214 - val_loss: 374666.4688 - val_mae: 472.5452\n",
            "Epoch 1493/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 506520.6875 - mae: 642.5909 - val_loss: 391497.9062 - val_mae: 491.3721\n",
            "Epoch 1494/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 505469.3750 - mae: 641.1849 - val_loss: 382964.4062 - val_mae: 482.3853\n",
            "Epoch 1495/2000\n",
            "39/39 [==============================] - 10s 240ms/step - loss: 506252.2812 - mae: 641.7358 - val_loss: 391121.8438 - val_mae: 489.1813\n",
            "Epoch 1496/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 503207.2812 - mae: 639.8783 - val_loss: 398965.9688 - val_mae: 498.7610\n",
            "Epoch 1497/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 505887.9375 - mae: 641.9664 - val_loss: 376090.6562 - val_mae: 475.3419\n",
            "Epoch 1498/2000\n",
            "39/39 [==============================] - 5s 112ms/step - loss: 508187.0938 - mae: 643.3798 - val_loss: 383432.2500 - val_mae: 482.6539\n",
            "Epoch 1499/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 503218.8750 - mae: 640.1420 - val_loss: 383219.3438 - val_mae: 481.5428\n",
            "Epoch 1500/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 508393.0312 - mae: 643.3059 - val_loss: 375837.0000 - val_mae: 474.2060\n",
            "Epoch 1501/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 499985.0312 - mae: 638.0967 - val_loss: 375335.9688 - val_mae: 474.2694\n",
            "Epoch 1502/2000\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 510191.5938 - mae: 644.6393 - val_loss: 391232.5312 - val_mae: 490.2279\n",
            "Epoch 1503/2000\n",
            "39/39 [==============================] - 5s 112ms/step - loss: 504159.9375 - mae: 640.3411 - val_loss: 391003.5938 - val_mae: 491.0874\n",
            "Epoch 1504/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 498531.4062 - mae: 639.1799 - val_loss: 374557.6250 - val_mae: 472.4743\n",
            "Epoch 1505/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 503659.8750 - mae: 640.3344 - val_loss: 391023.8438 - val_mae: 489.1181\n",
            "Epoch 1506/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 506163.8125 - mae: 642.3236 - val_loss: 359886.4062 - val_mae: 457.8614\n",
            "Epoch 1507/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 504417.6250 - mae: 640.3723 - val_loss: 384116.8438 - val_mae: 484.0365\n",
            "Epoch 1508/2000\n",
            "39/39 [==============================] - 5s 100ms/step - loss: 502474.4688 - mae: 639.3418 - val_loss: 383198.5938 - val_mae: 481.5296\n",
            "Epoch 1509/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 505056.6250 - mae: 641.0931 - val_loss: 383595.9062 - val_mae: 483.7360\n",
            "Epoch 1510/2000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 504408.7812 - mae: 640.0827 - val_loss: 398640.5312 - val_mae: 497.5803\n",
            "Epoch 1511/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 503109.6875 - mae: 640.1833 - val_loss: 376008.3750 - val_mae: 475.2921\n",
            "Epoch 1512/2000\n",
            "39/39 [==============================] - 10s 239ms/step - loss: 504444.3125 - mae: 640.7580 - val_loss: 375758.7500 - val_mae: 474.1569\n",
            "Epoch 1513/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 506933.3438 - mae: 642.7390 - val_loss: 367755.6562 - val_mae: 465.4785\n",
            "Epoch 1514/2000\n",
            "39/39 [==============================] - 10s 233ms/step - loss: 498236.1875 - mae: 637.9294 - val_loss: 391726.5312 - val_mae: 492.8463\n",
            "Epoch 1515/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 505788.5625 - mae: 641.2880 - val_loss: 398663.7812 - val_mae: 497.5950\n",
            "Epoch 1516/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 504778.5625 - mae: 640.6907 - val_loss: 367685.4688 - val_mae: 465.4334\n",
            "Epoch 1517/2000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 503163.4062 - mae: 639.5248 - val_loss: 375547.1562 - val_mae: 473.0449\n",
            "Epoch 1518/2000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 499764.8750 - mae: 640.0169 - val_loss: 367216.3438 - val_mae: 465.1646\n",
            "Epoch 1519/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 501228.7500 - mae: 638.8715 - val_loss: 382870.0000 - val_mae: 482.3273\n",
            "Epoch 1520/2000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 490069.5000 - mae: 634.1545 - val_loss: 383616.5312 - val_mae: 481.7660\n",
            "Epoch 1521/2000\n",
            "39/39 [==============================] - 9s 233ms/step - loss: 507149.2812 - mae: 642.4986 - val_loss: 375254.9688 - val_mae: 473.8661\n",
            "Epoch 1522/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 498761.5312 - mae: 637.2648 - val_loss: 376469.4688 - val_mae: 475.5569\n",
            "Epoch 1523/2000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 505824.0000 - mae: 641.6142 - val_loss: 383357.4062 - val_mae: 482.9607\n",
            "Epoch 1524/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 508916.1875 - mae: 643.2153 - val_loss: 375257.8438 - val_mae: 473.8679\n",
            "Epoch 1525/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 506441.4688 - mae: 642.1867 - val_loss: 375742.2500 - val_mae: 474.1466\n",
            "Epoch 1526/2000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 504194.5000 - mae: 640.1531 - val_loss: 367900.1250 - val_mae: 466.5473\n",
            "Epoch 1527/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 501001.0000 - mae: 639.0695 - val_loss: 375557.0938 - val_mae: 473.0514\n",
            "Epoch 1528/2000\n",
            "39/39 [==============================] - 10s 237ms/step - loss: 506486.1562 - mae: 642.4320 - val_loss: 367889.5000 - val_mae: 466.5407\n",
            "Epoch 1529/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 508150.1562 - mae: 643.0978 - val_loss: 375276.8750 - val_mae: 473.8798\n",
            "Epoch 1530/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 501172.4375 - mae: 638.7946 - val_loss: 391437.8438 - val_mae: 491.6890\n",
            "Epoch 1531/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 501127.2812 - mae: 638.9519 - val_loss: 390177.5000 - val_mae: 487.6279\n",
            "Epoch 1532/2000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 504197.5312 - mae: 640.5770 - val_loss: 367829.2500 - val_mae: 466.5034\n",
            "Epoch 1533/2000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 502151.9375 - mae: 639.1417 - val_loss: 383585.0938 - val_mae: 481.7459\n",
            "Epoch 1534/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 504480.5625 - mae: 640.4020 - val_loss: 375004.1250 - val_mae: 472.7282\n",
            "Epoch 1535/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 508512.2500 - mae: 643.3705 - val_loss: 375972.3750 - val_mae: 473.2851\n",
            "Epoch 1536/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 501069.6562 - mae: 640.5522 - val_loss: 359279.6250 - val_mae: 457.5054\n",
            "Epoch 1537/2000\n",
            "39/39 [==============================] - 6s 131ms/step - loss: 499036.5000 - mae: 639.0746 - val_loss: 383130.0312 - val_mae: 481.4860\n",
            "Epoch 1538/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 507314.2500 - mae: 643.0955 - val_loss: 382821.8750 - val_mae: 482.2978\n",
            "Epoch 1539/2000\n",
            "39/39 [==============================] - 10s 243ms/step - loss: 501975.5312 - mae: 639.2202 - val_loss: 383466.3750 - val_mae: 483.6594\n",
            "Epoch 1540/2000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 509009.8438 - mae: 643.7418 - val_loss: 383514.8750 - val_mae: 481.7013\n",
            "Epoch 1541/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 506345.5625 - mae: 641.9800 - val_loss: 375646.5000 - val_mae: 474.0865\n",
            "Epoch 1542/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 505215.5312 - mae: 640.8867 - val_loss: 383980.4062 - val_mae: 483.9558\n",
            "Epoch 1543/2000\n",
            "39/39 [==============================] - 5s 115ms/step - loss: 502417.0312 - mae: 639.5009 - val_loss: 375244.5938 - val_mae: 473.8595\n",
            "Epoch 1544/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 498985.3750 - mae: 639.6674 - val_loss: 375045.7500 - val_mae: 472.7553\n",
            "Epoch 1545/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 505833.3750 - mae: 641.2277 - val_loss: 376424.5000 - val_mae: 475.5297\n",
            "Epoch 1546/2000\n",
            "39/39 [==============================] - 10s 240ms/step - loss: 505438.7500 - mae: 641.0696 - val_loss: 375496.0000 - val_mae: 473.0117\n",
            "Epoch 1547/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 506009.8438 - mae: 641.5173 - val_loss: 383645.7500 - val_mae: 481.7845\n",
            "Epoch 1548/2000\n",
            "39/39 [==============================] - 9s 232ms/step - loss: 495618.9688 - mae: 638.1992 - val_loss: 383398.5312 - val_mae: 482.6332\n",
            "Epoch 1549/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 503843.2812 - mae: 640.1152 - val_loss: 383198.4688 - val_mae: 481.5295\n",
            "Epoch 1550/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 501541.5312 - mae: 638.8256 - val_loss: 376540.6562 - val_mae: 475.5998\n",
            "Epoch 1551/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 506787.9688 - mae: 642.4215 - val_loss: 383032.6250 - val_mae: 480.4491\n",
            "Epoch 1552/2000\n",
            "39/39 [==============================] - 5s 96ms/step - loss: 501387.7500 - mae: 637.9727 - val_loss: 376392.9688 - val_mae: 474.5294\n",
            "Epoch 1553/2000\n",
            "39/39 [==============================] - 5s 98ms/step - loss: 504586.6562 - mae: 640.7359 - val_loss: 399167.8750 - val_mae: 500.2174\n",
            "Epoch 1554/2000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 503807.1250 - mae: 641.7564 - val_loss: 383932.9688 - val_mae: 482.9426\n",
            "Epoch 1555/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 500280.3750 - mae: 637.2429 - val_loss: 383199.7500 - val_mae: 481.5303\n",
            "Epoch 1556/2000\n",
            "39/39 [==============================] - 10s 240ms/step - loss: 502290.4062 - mae: 639.0380 - val_loss: 383385.7812 - val_mae: 482.6253\n",
            "Epoch 1557/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 500852.4375 - mae: 637.7136 - val_loss: 376296.3750 - val_mae: 474.4690\n",
            "Epoch 1558/2000\n",
            "39/39 [==============================] - 10s 235ms/step - loss: 496594.8750 - mae: 637.0771 - val_loss: 376028.6562 - val_mae: 473.3217\n",
            "Epoch 1559/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 505690.1875 - mae: 641.8698 - val_loss: 383825.0938 - val_mae: 482.8764\n",
            "Epoch 1560/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 501775.0000 - mae: 639.0761 - val_loss: 374804.7500 - val_mae: 473.6089\n",
            "Epoch 1561/2000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 501184.0625 - mae: 639.6313 - val_loss: 375452.3438 - val_mae: 474.9701\n",
            "Epoch 1562/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 504347.3438 - mae: 641.1487 - val_loss: 367886.6562 - val_mae: 466.5390\n",
            "Epoch 1563/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 507192.0625 - mae: 642.9797 - val_loss: 391212.2812 - val_mae: 490.2152\n",
            "Epoch 1564/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 504130.0312 - mae: 640.4067 - val_loss: 383808.3438 - val_mae: 482.8661\n",
            "Epoch 1565/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 508210.1562 - mae: 643.0960 - val_loss: 382820.7812 - val_mae: 482.2971\n",
            "Epoch 1566/2000\n",
            "39/39 [==============================] - 6s 127ms/step - loss: 502464.0625 - mae: 639.9373 - val_loss: 374510.3750 - val_mae: 472.4436\n",
            "Epoch 1567/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 506288.6875 - mae: 641.7222 - val_loss: 374520.1562 - val_mae: 472.4499\n",
            "Epoch 1568/2000\n",
            "39/39 [==============================] - 10s 237ms/step - loss: 505370.8125 - mae: 640.8345 - val_loss: 375033.2500 - val_mae: 472.7472\n",
            "Epoch 1569/2000\n",
            "39/39 [==============================] - 5s 115ms/step - loss: 504409.0000 - mae: 639.8698 - val_loss: 383538.9062 - val_mae: 483.7024\n",
            "Epoch 1570/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 501016.0938 - mae: 640.1404 - val_loss: 383241.0000 - val_mae: 482.5364\n",
            "Epoch 1571/2000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 496911.3750 - mae: 635.4433 - val_loss: 391565.9062 - val_mae: 492.3999\n",
            "Epoch 1572/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 507911.0000 - mae: 643.1877 - val_loss: 383509.5938 - val_mae: 481.6979\n",
            "Epoch 1573/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 503013.6562 - mae: 641.9731 - val_loss: 375137.5000 - val_mae: 473.7923\n",
            "Epoch 1574/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 507750.2188 - mae: 642.9308 - val_loss: 390865.7812 - val_mae: 489.0161\n",
            "Epoch 1575/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 504634.2500 - mae: 641.2289 - val_loss: 367290.7500 - val_mae: 466.1913\n",
            "Epoch 1576/2000\n",
            "39/39 [==============================] - 10s 240ms/step - loss: 505396.7188 - mae: 641.2277 - val_loss: 375456.8438 - val_mae: 472.9863\n",
            "Epoch 1577/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 506130.2500 - mae: 641.7393 - val_loss: 360670.6562 - val_mae: 458.3022\n",
            "Epoch 1578/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 500685.0625 - mae: 638.0153 - val_loss: 367532.6562 - val_mae: 465.3354\n",
            "Epoch 1579/2000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 500557.3750 - mae: 638.2591 - val_loss: 382760.7500 - val_mae: 480.2701\n",
            "Epoch 1580/2000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 502728.4688 - mae: 639.2599 - val_loss: 375344.5938 - val_mae: 474.9049\n",
            "Epoch 1581/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 503438.7500 - mae: 640.6005 - val_loss: 367522.5938 - val_mae: 465.3289\n",
            "Epoch 1582/2000\n",
            "39/39 [==============================] - 9s 237ms/step - loss: 501242.3438 - mae: 638.9920 - val_loss: 375442.8750 - val_mae: 472.9771\n",
            "Epoch 1583/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 503398.6250 - mae: 640.2034 - val_loss: 374971.4062 - val_mae: 472.7069\n",
            "Epoch 1584/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 506023.2188 - mae: 641.3066 - val_loss: 367859.0000 - val_mae: 466.5219\n",
            "Epoch 1585/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 502239.1250 - mae: 639.2670 - val_loss: 383069.3438 - val_mae: 481.4473\n",
            "Epoch 1586/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 508085.6562 - mae: 643.1163 - val_loss: 383323.5312 - val_mae: 482.5871\n",
            "Epoch 1587/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 502647.7812 - mae: 639.7177 - val_loss: 375951.8438 - val_mae: 475.2580\n",
            "Epoch 1588/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 506593.1562 - mae: 642.5428 - val_loss: 375720.8750 - val_mae: 474.1332\n",
            "Epoch 1589/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 505450.6250 - mae: 641.0258 - val_loss: 376220.2812 - val_mae: 474.4213\n",
            "Epoch 1590/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 506750.4375 - mae: 642.5292 - val_loss: 390249.0000 - val_mae: 487.6757\n",
            "Epoch 1591/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 501445.3750 - mae: 638.1155 - val_loss: 367137.6562 - val_mae: 465.1141\n",
            "Epoch 1592/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 503919.6250 - mae: 640.5169 - val_loss: 382914.1250 - val_mae: 480.3711\n",
            "Epoch 1593/2000\n",
            "39/39 [==============================] - 10s 240ms/step - loss: 509136.2188 - mae: 643.9300 - val_loss: 383794.9062 - val_mae: 482.8578\n",
            "Epoch 1594/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 504713.6250 - mae: 640.5822 - val_loss: 375746.9688 - val_mae: 474.1495\n",
            "Epoch 1595/2000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 504665.4688 - mae: 641.2451 - val_loss: 375255.2500 - val_mae: 473.8662\n",
            "Epoch 1596/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 503985.0000 - mae: 640.6218 - val_loss: 375752.7500 - val_mae: 474.1532\n",
            "Epoch 1597/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 500157.5938 - mae: 640.0212 - val_loss: 375944.9688 - val_mae: 475.2539\n",
            "Epoch 1598/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 505178.9375 - mae: 642.1357 - val_loss: 375229.2500 - val_mae: 473.8500\n",
            "Epoch 1599/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 502411.1875 - mae: 639.2670 - val_loss: 384020.9062 - val_mae: 483.9798\n",
            "Epoch 1600/2000\n",
            "39/39 [==============================] - 5s 130ms/step - loss: 499224.2188 - mae: 637.8997 - val_loss: 398344.5000 - val_mae: 496.4142\n",
            "Epoch 1601/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 503480.7812 - mae: 639.4581 - val_loss: 367721.5000 - val_mae: 465.4565\n",
            "Epoch 1602/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 498667.7500 - mae: 637.1713 - val_loss: 383411.1562 - val_mae: 482.6410\n",
            "Epoch 1603/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 506529.3125 - mae: 641.7926 - val_loss: 391430.0938 - val_mae: 491.3314\n",
            "Epoch 1604/2000\n",
            "39/39 [==============================] - 5s 113ms/step - loss: 501798.6250 - mae: 639.5745 - val_loss: 375080.9688 - val_mae: 472.7782\n",
            "Epoch 1605/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 504402.2500 - mae: 640.2938 - val_loss: 383881.8750 - val_mae: 482.9113\n",
            "Epoch 1606/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 499319.3125 - mae: 637.6561 - val_loss: 367221.0938 - val_mae: 465.1676\n",
            "Epoch 1607/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 502064.8438 - mae: 640.0136 - val_loss: 374773.4062 - val_mae: 473.5892\n",
            "Epoch 1608/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 504516.3438 - mae: 640.3315 - val_loss: 382716.3438 - val_mae: 481.2523\n",
            "Epoch 1609/2000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 505700.9062 - mae: 641.8679 - val_loss: 383398.1250 - val_mae: 482.6329\n",
            "Epoch 1610/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 501309.6875 - mae: 638.2570 - val_loss: 375813.3750 - val_mae: 474.1912\n",
            "Epoch 1611/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 508616.5625 - mae: 643.3652 - val_loss: 375274.2500 - val_mae: 473.8782\n",
            "Epoch 1612/2000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 500655.3125 - mae: 639.5712 - val_loss: 375590.1562 - val_mae: 473.0729\n",
            "Epoch 1613/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 503228.1875 - mae: 639.3226 - val_loss: 391495.5312 - val_mae: 491.3707\n",
            "Epoch 1614/2000\n",
            "39/39 [==============================] - 6s 138ms/step - loss: 505473.5312 - mae: 641.6734 - val_loss: 368738.9688 - val_mae: 466.0449\n",
            "Epoch 1615/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 506270.0000 - mae: 641.6294 - val_loss: 367510.7188 - val_mae: 466.3272\n",
            "Epoch 1616/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 510304.5312 - mae: 644.8679 - val_loss: 375620.1562 - val_mae: 475.0714\n",
            "Epoch 1617/2000\n",
            "39/39 [==============================] - 10s 236ms/step - loss: 508346.0000 - mae: 644.0121 - val_loss: 382998.8438 - val_mae: 482.4065\n",
            "Epoch 1618/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 505853.5312 - mae: 641.5801 - val_loss: 375365.3438 - val_mae: 473.9354\n",
            "Epoch 1619/2000\n",
            "39/39 [==============================] - 5s 112ms/step - loss: 507592.6250 - mae: 642.9134 - val_loss: 375828.0938 - val_mae: 474.2003\n",
            "Epoch 1620/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 501983.1562 - mae: 640.4659 - val_loss: 391026.6250 - val_mae: 491.1012\n",
            "Epoch 1621/2000\n",
            "39/39 [==============================] - 5s 112ms/step - loss: 502130.9375 - mae: 639.0813 - val_loss: 390559.1250 - val_mae: 488.8523\n",
            "Epoch 1622/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 509169.4062 - mae: 644.4317 - val_loss: 383420.0938 - val_mae: 482.6464\n",
            "Epoch 1623/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 505597.6562 - mae: 641.5141 - val_loss: 376037.7500 - val_mae: 475.3098\n",
            "Epoch 1624/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 508588.8125 - mae: 644.0736 - val_loss: 390824.0312 - val_mae: 489.9965\n",
            "Epoch 1625/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 502046.3750 - mae: 639.6133 - val_loss: 367511.4688 - val_mae: 466.3277\n",
            "Epoch 1626/2000\n",
            "39/39 [==============================] - 9s 231ms/step - loss: 498332.2500 - mae: 639.6451 - val_loss: 391512.5938 - val_mae: 491.3810\n",
            "Epoch 1627/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 503260.2500 - mae: 640.0453 - val_loss: 383844.0938 - val_mae: 482.8881\n",
            "Epoch 1628/2000\n",
            "39/39 [==============================] - 5s 113ms/step - loss: 503550.8125 - mae: 640.4402 - val_loss: 382877.3438 - val_mae: 482.3319\n",
            "Epoch 1629/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 507865.3750 - mae: 643.7338 - val_loss: 368438.7500 - val_mae: 466.8595\n",
            "Epoch 1630/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 500936.5312 - mae: 638.0422 - val_loss: 375558.3750 - val_mae: 473.0522\n",
            "Epoch 1631/2000\n",
            "39/39 [==============================] - 5s 114ms/step - loss: 504139.0312 - mae: 640.5848 - val_loss: 382930.0000 - val_mae: 482.7169\n",
            "Epoch 1632/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 505171.8750 - mae: 641.2997 - val_loss: 375201.1250 - val_mae: 472.8564\n",
            "Epoch 1633/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 507530.5625 - mae: 643.6559 - val_loss: 376047.5000 - val_mae: 475.3158\n",
            "Epoch 1634/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 505940.3438 - mae: 642.8462 - val_loss: 367257.4062 - val_mae: 465.1909\n",
            "Epoch 1635/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 502223.3125 - mae: 638.8664 - val_loss: 368015.5938 - val_mae: 466.6186\n",
            "Epoch 1636/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 507261.1875 - mae: 643.4041 - val_loss: 360395.0312 - val_mae: 458.1554\n",
            "Epoch 1637/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 510780.9062 - mae: 645.3749 - val_loss: 383450.3438 - val_mae: 482.6650\n",
            "Epoch 1638/2000\n",
            "39/39 [==============================] - 5s 101ms/step - loss: 502412.4375 - mae: 640.0736 - val_loss: 367979.0312 - val_mae: 466.5960\n",
            "Epoch 1639/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 505948.2500 - mae: 642.4407 - val_loss: 383709.9062 - val_mae: 481.8253\n",
            "Epoch 1640/2000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 501525.5938 - mae: 638.9382 - val_loss: 368454.0000 - val_mae: 466.8689\n",
            "Epoch 1641/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 504532.9688 - mae: 641.7503 - val_loss: 382939.1562 - val_mae: 482.3698\n",
            "Epoch 1642/2000\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 505071.6250 - mae: 640.8339 - val_loss: 384147.3750 - val_mae: 484.0544\n",
            "Epoch 1643/2000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 510543.1562 - mae: 646.1864 - val_loss: 382810.2188 - val_mae: 481.3121\n",
            "Epoch 1644/2000\n",
            "39/39 [==============================] - 6s 131ms/step - loss: 511053.5312 - mae: 646.2134 - val_loss: 368044.2500 - val_mae: 466.6363\n",
            "Epoch 1645/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 502868.5000 - mae: 639.4941 - val_loss: 398834.9062 - val_mae: 497.7031\n",
            "Epoch 1646/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 495851.7500 - mae: 636.3678 - val_loss: 391166.5938 - val_mae: 491.5383\n",
            "Epoch 1647/2000\n",
            "39/39 [==============================] - 10s 237ms/step - loss: 505466.8750 - mae: 641.2026 - val_loss: 391356.5938 - val_mae: 492.2804\n",
            "Epoch 1648/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 507492.3438 - mae: 643.1473 - val_loss: 383291.7188 - val_mae: 481.5889\n",
            "Epoch 1649/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 499566.0625 - mae: 639.6677 - val_loss: 383529.8750 - val_mae: 482.7138\n",
            "Epoch 1650/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 502022.8125 - mae: 639.0045 - val_loss: 383520.8750 - val_mae: 482.7083\n",
            "Epoch 1651/2000\n",
            "39/39 [==============================] - 9s 232ms/step - loss: 503100.5625 - mae: 639.2634 - val_loss: 383469.3750 - val_mae: 482.6767\n",
            "Epoch 1652/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 509250.8125 - mae: 644.3825 - val_loss: 367296.9688 - val_mae: 465.2163\n",
            "Epoch 1653/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 501348.4062 - mae: 640.1275 - val_loss: 382991.1562 - val_mae: 482.4018\n",
            "Epoch 1654/2000\n",
            "39/39 [==============================] - 10s 235ms/step - loss: 504721.1562 - mae: 640.8569 - val_loss: 383236.2500 - val_mae: 481.5536\n",
            "Epoch 1655/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 507676.5000 - mae: 643.4103 - val_loss: 376143.4062 - val_mae: 475.3737\n",
            "Epoch 1656/2000\n",
            "39/39 [==============================] - 10s 234ms/step - loss: 505632.2188 - mae: 641.3482 - val_loss: 390679.0312 - val_mae: 488.9296\n",
            "Epoch 1657/2000\n",
            "39/39 [==============================] - 10s 234ms/step - loss: 506412.4062 - mae: 641.6498 - val_loss: 383756.0312 - val_mae: 481.8547\n",
            "Epoch 1658/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 500657.5312 - mae: 639.9263 - val_loss: 375633.6250 - val_mae: 475.0796\n",
            "Epoch 1659/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 505676.2812 - mae: 641.3876 - val_loss: 383079.8438 - val_mae: 480.4802\n",
            "Epoch 1660/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 506154.0000 - mae: 641.8380 - val_loss: 376598.5000 - val_mae: 475.6347\n",
            "Epoch 1661/2000\n",
            "39/39 [==============================] - 5s 113ms/step - loss: 505437.7500 - mae: 640.7956 - val_loss: 360384.3750 - val_mae: 458.1486\n",
            "Epoch 1662/2000\n",
            "39/39 [==============================] - 5s 113ms/step - loss: 508529.8750 - mae: 643.8284 - val_loss: 375339.2188 - val_mae: 473.9189\n",
            "Epoch 1663/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 509021.8125 - mae: 644.7139 - val_loss: 368346.6562 - val_mae: 465.8253\n",
            "Epoch 1664/2000\n",
            "39/39 [==============================] - 9s 233ms/step - loss: 507246.3750 - mae: 642.3046 - val_loss: 390949.6250 - val_mae: 488.0983\n",
            "Epoch 1665/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 505427.4062 - mae: 642.8736 - val_loss: 383227.2188 - val_mae: 483.5256\n",
            "Epoch 1666/2000\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 506022.6250 - mae: 641.3076 - val_loss: 383764.0312 - val_mae: 483.8354\n",
            "Epoch 1667/2000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 501404.4375 - mae: 638.7196 - val_loss: 375504.3438 - val_mae: 474.0226\n",
            "Epoch 1668/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 505892.6562 - mae: 642.0768 - val_loss: 383862.7812 - val_mae: 481.9225\n",
            "Epoch 1669/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 500543.4375 - mae: 639.5086 - val_loss: 383801.1250 - val_mae: 483.8574\n",
            "Epoch 1670/2000\n",
            "39/39 [==============================] - 10s 228ms/step - loss: 501485.4375 - mae: 638.6776 - val_loss: 384105.5000 - val_mae: 483.0485\n",
            "Epoch 1671/2000\n",
            "39/39 [==============================] - 9s 232ms/step - loss: 498151.8438 - mae: 638.3230 - val_loss: 391250.0000 - val_mae: 489.2639\n",
            "Epoch 1672/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 507149.2812 - mae: 643.8793 - val_loss: 369139.0312 - val_mae: 467.2713\n",
            "Epoch 1673/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 504424.5625 - mae: 639.7068 - val_loss: 375824.1562 - val_mae: 473.2249\n",
            "Epoch 1674/2000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 509303.5938 - mae: 644.0842 - val_loss: 391758.3438 - val_mae: 491.8815\n",
            "Epoch 1675/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 505973.9062 - mae: 642.1351 - val_loss: 375089.6562 - val_mae: 473.7877\n",
            "Epoch 1676/2000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 505929.3750 - mae: 641.6334 - val_loss: 383678.0000 - val_mae: 482.8047\n",
            "Epoch 1677/2000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 503528.3125 - mae: 640.8114 - val_loss: 383616.2812 - val_mae: 482.7668\n",
            "Epoch 1678/2000\n",
            "39/39 [==============================] - 5s 99ms/step - loss: 509575.0000 - mae: 644.2549 - val_loss: 376276.6562 - val_mae: 473.4827\n",
            "Epoch 1679/2000\n",
            "39/39 [==============================] - 10s 239ms/step - loss: 502394.9375 - mae: 638.6595 - val_loss: 391904.0000 - val_mae: 492.5957\n",
            "Epoch 1680/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 508832.3125 - mae: 643.6508 - val_loss: 391262.9688 - val_mae: 491.2434\n",
            "Epoch 1681/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 507736.3750 - mae: 643.2460 - val_loss: 376490.1562 - val_mae: 474.5903\n",
            "Epoch 1682/2000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 509181.1875 - mae: 644.7571 - val_loss: 367927.1562 - val_mae: 465.5883\n",
            "Epoch 1683/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 505685.3750 - mae: 641.2758 - val_loss: 375796.3438 - val_mae: 473.2068\n",
            "Epoch 1684/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 508750.9062 - mae: 643.7343 - val_loss: 375335.7188 - val_mae: 472.9438\n",
            "Epoch 1685/2000\n",
            "39/39 [==============================] - 10s 238ms/step - loss: 502035.5938 - mae: 639.0884 - val_loss: 368396.8750 - val_mae: 465.8575\n",
            "Epoch 1686/2000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 502627.5625 - mae: 638.3810 - val_loss: 375538.7500 - val_mae: 474.3965\n",
            "Epoch 1687/2000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 501811.9375 - mae: 639.5169 - val_loss: 367449.6250 - val_mae: 465.3142\n",
            "Epoch 1688/2000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 505293.6562 - mae: 641.2249 - val_loss: 383630.4688 - val_mae: 482.7755\n",
            "Epoch 1689/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 506002.0000 - mae: 641.9196 - val_loss: 375772.9062 - val_mae: 475.1637\n",
            "Epoch 1690/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 495695.9062 - mae: 636.9168 - val_loss: 375720.3750 - val_mae: 475.1320\n",
            "Epoch 1691/2000\n",
            "39/39 [==============================] - 10s 237ms/step - loss: 506964.1875 - mae: 642.5450 - val_loss: 368113.2188 - val_mae: 466.6788\n",
            "Epoch 1692/2000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 504231.1562 - mae: 640.2188 - val_loss: 367695.9062 - val_mae: 466.4417\n",
            "Epoch 1693/2000\n",
            "39/39 [==============================] - 10s 242ms/step - loss: 499416.2188 - mae: 639.3549 - val_loss: 383702.0000 - val_mae: 480.8494\n",
            "Epoch 1694/2000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 507301.7500 - mae: 642.6687 - val_loss: 383408.2500 - val_mae: 481.6630\n",
            "Epoch 1695/2000\n",
            "39/39 [==============================] - 10s 237ms/step - loss: 503840.8750 - mae: 640.2534 - val_loss: 368646.4062 - val_mae: 466.9876\n",
            "Epoch 1696/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 504316.7188 - mae: 640.3260 - val_loss: 391548.0938 - val_mae: 490.4244\n",
            "Epoch 1697/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 506603.2812 - mae: 642.1657 - val_loss: 375575.4688 - val_mae: 474.0671\n",
            "Epoch 1698/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 509511.7812 - mae: 644.4161 - val_loss: 383160.4688 - val_mae: 482.5058\n",
            "Epoch 1699/2000\n",
            "39/39 [==============================] - 10s 241ms/step - loss: 498609.2500 - mae: 638.8458 - val_loss: 383652.9062 - val_mae: 482.7893\n",
            "Epoch 1700/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 508791.9375 - mae: 643.9686 - val_loss: 383674.8750 - val_mae: 482.8028\n",
            "Epoch 1701/2000\n",
            "39/39 [==============================] - 10s 243ms/step - loss: 502279.5938 - mae: 640.9592 - val_loss: 376052.1250 - val_mae: 474.3408\n",
            "Epoch 1702/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 505029.5000 - mae: 641.9771 - val_loss: 390847.0312 - val_mae: 489.0380\n",
            "Epoch 1703/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 506644.4062 - mae: 642.6914 - val_loss: 375606.7812 - val_mae: 474.0868\n",
            "Epoch 1704/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 501011.8750 - mae: 639.1966 - val_loss: 384179.8438 - val_mae: 483.0940\n",
            "Epoch 1705/2000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 499986.0312 - mae: 638.3604 - val_loss: 375749.6562 - val_mae: 475.1497\n",
            "Epoch 1706/2000\n",
            "39/39 [==============================] - 6s 137ms/step - loss: 504851.2812 - mae: 640.7759 - val_loss: 383472.2500 - val_mae: 481.7037\n",
            "Epoch 1707/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 506966.2812 - mae: 642.7015 - val_loss: 376076.7500 - val_mae: 474.3563\n",
            "Epoch 1708/2000\n",
            "39/39 [==============================] - 5s 100ms/step - loss: 504460.1875 - mae: 640.3002 - val_loss: 368423.6250 - val_mae: 465.8745\n",
            "Epoch 1709/2000\n",
            "39/39 [==============================] - 10s 243ms/step - loss: 508235.5938 - mae: 642.9918 - val_loss: 390811.9062 - val_mae: 489.0153\n",
            "Epoch 1710/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 505514.3125 - mae: 640.9486 - val_loss: 368693.5938 - val_mae: 467.0166\n",
            "Epoch 1711/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 504377.0312 - mae: 640.5131 - val_loss: 376112.0938 - val_mae: 474.3784\n",
            "Epoch 1712/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 498923.1250 - mae: 639.5349 - val_loss: 391131.2812 - val_mae: 490.1880\n",
            "Epoch 1713/2000\n",
            "39/39 [==============================] - 5s 119ms/step - loss: 505372.4062 - mae: 641.1608 - val_loss: 375436.1562 - val_mae: 473.0091\n",
            "Epoch 1714/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 503657.3125 - mae: 641.3015 - val_loss: 399213.1562 - val_mae: 498.9119\n",
            "Epoch 1715/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 504365.1875 - mae: 640.4229 - val_loss: 391620.6562 - val_mae: 490.4696\n",
            "Epoch 1716/2000\n",
            "39/39 [==============================] - 6s 128ms/step - loss: 505697.1562 - mae: 641.4496 - val_loss: 398761.6562 - val_mae: 496.6866\n",
            "Epoch 1717/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 505436.8125 - mae: 641.4276 - val_loss: 391119.8750 - val_mae: 490.1809\n",
            "Epoch 1718/2000\n",
            "39/39 [==============================] - 5s 115ms/step - loss: 507368.0625 - mae: 642.4349 - val_loss: 368019.0000 - val_mae: 465.6472\n",
            "Epoch 1719/2000\n",
            "39/39 [==============================] - 10s 232ms/step - loss: 505688.7188 - mae: 641.9692 - val_loss: 376336.2188 - val_mae: 475.4901\n",
            "Epoch 1720/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 506509.2188 - mae: 642.0541 - val_loss: 374995.8750 - val_mae: 472.7594\n",
            "Epoch 1721/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 502394.6250 - mae: 638.8461 - val_loss: 391613.3438 - val_mae: 490.4650\n",
            "Epoch 1722/2000\n",
            "39/39 [==============================] - 5s 121ms/step - loss: 509781.9688 - mae: 644.5236 - val_loss: 384263.0938 - val_mae: 483.1451\n",
            "Epoch 1723/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 508476.7500 - mae: 643.9674 - val_loss: 376473.0000 - val_mae: 475.5725\n",
            "Epoch 1724/2000\n",
            "39/39 [==============================] - 10s 240ms/step - loss: 496532.9062 - mae: 637.9017 - val_loss: 399366.1250 - val_mae: 499.0052\n",
            "Epoch 1725/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 506319.5312 - mae: 641.6606 - val_loss: 376533.4062 - val_mae: 473.6493\n",
            "Epoch 1726/2000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 502878.3750 - mae: 641.4125 - val_loss: 376479.4062 - val_mae: 475.5764\n",
            "Epoch 1727/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 499050.4688 - mae: 638.3225 - val_loss: 391479.0938 - val_mae: 491.3732\n",
            "Epoch 1728/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 503109.5938 - mae: 640.2493 - val_loss: 376707.0938 - val_mae: 474.7262\n",
            "Epoch 1729/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 502464.2500 - mae: 639.7585 - val_loss: 383659.4062 - val_mae: 481.8227\n",
            "Epoch 1730/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 506444.7500 - mae: 641.7975 - val_loss: 376087.0938 - val_mae: 473.3956\n",
            "Epoch 1731/2000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 490270.0625 - mae: 635.3154 - val_loss: 368183.9688 - val_mae: 465.7528\n",
            "Epoch 1732/2000\n",
            "39/39 [==============================] - 5s 121ms/step - loss: 502598.2188 - mae: 639.1730 - val_loss: 384316.9062 - val_mae: 483.1781\n",
            "Epoch 1733/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 508447.7812 - mae: 643.5067 - val_loss: 376522.0312 - val_mae: 473.6419\n",
            "Epoch 1734/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 504527.3750 - mae: 640.4391 - val_loss: 384045.4688 - val_mae: 484.0017\n",
            "Epoch 1735/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 508880.4688 - mae: 643.9683 - val_loss: 368801.9062 - val_mae: 467.0835\n",
            "Epoch 1736/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 504697.0938 - mae: 641.1317 - val_loss: 375993.9062 - val_mae: 473.3351\n",
            "Epoch 1737/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 505312.4062 - mae: 641.3890 - val_loss: 383661.5312 - val_mae: 481.8240\n",
            "Epoch 1738/2000\n",
            "39/39 [==============================] - 10s 234ms/step - loss: 500166.2188 - mae: 639.4818 - val_loss: 376205.6562 - val_mae: 474.4370\n",
            "Epoch 1739/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 506692.0312 - mae: 642.1149 - val_loss: 392120.3750 - val_mae: 492.7208\n",
            "Epoch 1740/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 506195.8125 - mae: 642.3714 - val_loss: 368340.2500 - val_mae: 466.8190\n",
            "Epoch 1741/2000\n",
            "39/39 [==============================] - 5s 114ms/step - loss: 508715.6562 - mae: 643.8001 - val_loss: 391696.9062 - val_mae: 490.5171\n",
            "Epoch 1742/2000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 503348.4062 - mae: 639.9455 - val_loss: 399715.6250 - val_mae: 501.1642\n",
            "Epoch 1743/2000\n",
            "39/39 [==============================] - 9s 231ms/step - loss: 506190.9688 - mae: 642.0167 - val_loss: 383361.5000 - val_mae: 482.6292\n",
            "Epoch 1744/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 498528.6250 - mae: 638.3159 - val_loss: 383308.5312 - val_mae: 482.5967\n",
            "Epoch 1745/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 504487.3750 - mae: 641.2252 - val_loss: 368776.7188 - val_mae: 467.0679\n",
            "Epoch 1746/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 504386.9375 - mae: 640.3118 - val_loss: 383322.2188 - val_mae: 482.6051\n",
            "Epoch 1747/2000\n",
            "39/39 [==============================] - 10s 239ms/step - loss: 503662.1250 - mae: 641.1005 - val_loss: 375659.4688 - val_mae: 474.4721\n",
            "Epoch 1748/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 510806.3125 - mae: 645.8645 - val_loss: 384277.0000 - val_mae: 483.5061\n",
            "Epoch 1749/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 499599.1562 - mae: 638.8755 - val_loss: 375812.8438 - val_mae: 475.1879\n",
            "Epoch 1750/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 506568.8750 - mae: 641.8599 - val_loss: 367520.4688 - val_mae: 465.3596\n",
            "Epoch 1751/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 506021.5938 - mae: 641.3249 - val_loss: 383968.5938 - val_mae: 481.9897\n",
            "Epoch 1752/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 498229.9062 - mae: 638.3857 - val_loss: 368030.5938 - val_mae: 465.6546\n",
            "Epoch 1753/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 500100.2812 - mae: 637.5126 - val_loss: 382788.5000 - val_mae: 480.3289\n",
            "Epoch 1754/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 504858.8125 - mae: 641.1612 - val_loss: 383286.5938 - val_mae: 480.6163\n",
            "Epoch 1755/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 496311.3750 - mae: 636.5739 - val_loss: 384209.8438 - val_mae: 483.1124\n",
            "Epoch 1756/2000\n",
            "39/39 [==============================] - 6s 133ms/step - loss: 497605.3438 - mae: 637.3890 - val_loss: 383928.5000 - val_mae: 483.9326\n",
            "Epoch 1757/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 506145.8438 - mae: 642.6967 - val_loss: 375886.8438 - val_mae: 473.2656\n",
            "Epoch 1758/2000\n",
            "39/39 [==============================] - 7s 157ms/step - loss: 499426.7812 - mae: 639.9407 - val_loss: 383314.9062 - val_mae: 482.6006\n",
            "Epoch 1759/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 508357.1875 - mae: 643.2470 - val_loss: 384107.8438 - val_mae: 482.0782\n",
            "Epoch 1760/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 503826.8750 - mae: 640.4663 - val_loss: 383611.5938 - val_mae: 481.7923\n",
            "Epoch 1761/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 506670.5938 - mae: 642.2824 - val_loss: 375747.7500 - val_mae: 474.1751\n",
            "Epoch 1762/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 504175.6875 - mae: 639.7198 - val_loss: 383656.8438 - val_mae: 481.8210\n",
            "Epoch 1763/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 506668.1875 - mae: 641.8861 - val_loss: 391446.9062 - val_mae: 491.7066\n",
            "Epoch 1764/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 503755.5625 - mae: 639.9768 - val_loss: 383420.4062 - val_mae: 480.7043\n",
            "Epoch 1765/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 503263.4688 - mae: 640.3506 - val_loss: 367875.9062 - val_mae: 466.5528\n",
            "Epoch 1766/2000\n",
            "39/39 [==============================] - 9s 234ms/step - loss: 509438.0000 - mae: 644.8931 - val_loss: 376210.0000 - val_mae: 474.4397\n",
            "Epoch 1767/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 505568.1562 - mae: 641.4677 - val_loss: 368646.8750 - val_mae: 466.0174\n",
            "Epoch 1768/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 506072.3750 - mae: 641.7798 - val_loss: 375780.0000 - val_mae: 474.5476\n",
            "Epoch 1769/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 502631.6875 - mae: 639.8784 - val_loss: 376907.8750 - val_mae: 475.8213\n",
            "Epoch 1770/2000\n",
            "39/39 [==============================] - 10s 237ms/step - loss: 506878.2812 - mae: 642.2764 - val_loss: 375941.2500 - val_mae: 473.3009\n",
            "Epoch 1771/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 505729.6875 - mae: 641.4713 - val_loss: 383311.9062 - val_mae: 482.9513\n",
            "Epoch 1772/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 500808.0625 - mae: 638.7467 - val_loss: 376163.8438 - val_mae: 474.4108\n",
            "Epoch 1773/2000\n",
            "39/39 [==============================] - 9s 233ms/step - loss: 503710.7500 - mae: 640.4881 - val_loss: 375183.5000 - val_mae: 473.8466\n",
            "Epoch 1774/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 499334.3125 - mae: 639.2609 - val_loss: 390956.5938 - val_mae: 489.1086\n",
            "Epoch 1775/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 501995.1250 - mae: 640.8713 - val_loss: 375681.6562 - val_mae: 474.1337\n",
            "Epoch 1776/2000\n",
            "39/39 [==============================] - 5s 121ms/step - loss: 506522.1562 - mae: 642.1128 - val_loss: 390967.8438 - val_mae: 489.1158\n",
            "Epoch 1777/2000\n",
            "39/39 [==============================] - 5s 119ms/step - loss: 508078.9688 - mae: 643.6150 - val_loss: 384476.7500 - val_mae: 484.2490\n",
            "Epoch 1778/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 508223.9062 - mae: 643.1364 - val_loss: 391375.0000 - val_mae: 491.3107\n",
            "Epoch 1779/2000\n",
            "39/39 [==============================] - 9s 232ms/step - loss: 502442.1875 - mae: 641.4542 - val_loss: 375964.1562 - val_mae: 475.2793\n",
            "Epoch 1780/2000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 506747.7500 - mae: 641.6492 - val_loss: 392149.5938 - val_mae: 492.7377\n",
            "Epoch 1781/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 507729.7188 - mae: 643.0634 - val_loss: 383159.1250 - val_mae: 481.5342\n",
            "Epoch 1782/2000\n",
            "39/39 [==============================] - 5s 117ms/step - loss: 506402.1562 - mae: 642.8235 - val_loss: 399823.3750 - val_mae: 501.2253\n",
            "Epoch 1783/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 506771.2812 - mae: 641.9883 - val_loss: 375376.5000 - val_mae: 473.9676\n",
            "Epoch 1784/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 506138.0938 - mae: 641.4961 - val_loss: 392067.9688 - val_mae: 492.0672\n",
            "Epoch 1785/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 498139.8750 - mae: 639.9724 - val_loss: 376594.1562 - val_mae: 473.6886\n",
            "Epoch 1786/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 498547.4375 - mae: 637.0316 - val_loss: 376311.2188 - val_mae: 474.5031\n",
            "Epoch 1787/2000\n",
            "39/39 [==============================] - 5s 114ms/step - loss: 506721.3125 - mae: 641.8977 - val_loss: 368734.5938 - val_mae: 466.0736\n",
            "Epoch 1788/2000\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 509102.3750 - mae: 644.2327 - val_loss: 391328.6562 - val_mae: 488.3507\n",
            "Epoch 1789/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 504021.5312 - mae: 640.7609 - val_loss: 383385.1562 - val_mae: 482.6437\n",
            "Epoch 1790/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 504153.9375 - mae: 640.6431 - val_loss: 391751.9062 - val_mae: 490.5514\n",
            "Epoch 1791/2000\n",
            "39/39 [==============================] - 5s 103ms/step - loss: 502140.4375 - mae: 638.7001 - val_loss: 368679.0938 - val_mae: 466.0381\n",
            "Epoch 1792/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 505664.0000 - mae: 641.7403 - val_loss: 391756.7812 - val_mae: 492.5121\n",
            "Epoch 1793/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 507510.7500 - mae: 642.8486 - val_loss: 368921.2500 - val_mae: 467.1570\n",
            "Epoch 1794/2000\n",
            "39/39 [==============================] - 10s 237ms/step - loss: 499283.6562 - mae: 639.1848 - val_loss: 368010.9062 - val_mae: 466.9884\n",
            "Epoch 1795/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 498193.4688 - mae: 638.7642 - val_loss: 391505.2812 - val_mae: 491.3890\n",
            "Epoch 1796/2000\n",
            "39/39 [==============================] - 10s 241ms/step - loss: 497650.3438 - mae: 637.5975 - val_loss: 376832.8438 - val_mae: 474.8048\n",
            "Epoch 1797/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 507057.4688 - mae: 643.1964 - val_loss: 368473.3438 - val_mae: 466.9010\n",
            "Epoch 1798/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 505900.9688 - mae: 641.9719 - val_loss: 383753.0000 - val_mae: 481.8822\n",
            "Epoch 1799/2000\n",
            "39/39 [==============================] - 6s 138ms/step - loss: 505332.7188 - mae: 640.9396 - val_loss: 376821.2188 - val_mae: 474.7976\n",
            "Epoch 1800/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 496797.0625 - mae: 637.6346 - val_loss: 383654.5000 - val_mae: 484.1312\n",
            "Epoch 1801/2000\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 504354.8750 - mae: 640.2369 - val_loss: 368209.7812 - val_mae: 465.7693\n",
            "Epoch 1802/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 506848.5312 - mae: 643.1923 - val_loss: 375759.7812 - val_mae: 474.1826\n",
            "Epoch 1803/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 498479.1250 - mae: 639.2736 - val_loss: 376048.3438 - val_mae: 473.3705\n",
            "Epoch 1804/2000\n",
            "39/39 [==============================] - 5s 115ms/step - loss: 509496.6250 - mae: 644.3864 - val_loss: 383864.9688 - val_mae: 482.9194\n",
            "Epoch 1805/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 498291.5938 - mae: 638.1428 - val_loss: 399356.2188 - val_mae: 498.9991\n",
            "Epoch 1806/2000\n",
            "39/39 [==============================] - 6s 133ms/step - loss: 499794.8750 - mae: 637.9996 - val_loss: 368182.2188 - val_mae: 465.7517\n",
            "Epoch 1807/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 507441.0312 - mae: 642.7703 - val_loss: 376024.8438 - val_mae: 475.3159\n",
            "Epoch 1808/2000\n",
            "39/39 [==============================] - 9s 234ms/step - loss: 502646.8438 - mae: 639.4233 - val_loss: 375829.6250 - val_mae: 474.2264\n",
            "Epoch 1809/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 507790.4688 - mae: 643.4739 - val_loss: 359344.7188 - val_mae: 457.5742\n",
            "Epoch 1810/2000\n",
            "39/39 [==============================] - 5s 112ms/step - loss: 510725.4375 - mae: 645.8099 - val_loss: 375370.8438 - val_mae: 473.9641\n",
            "Epoch 1811/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 503700.5938 - mae: 640.7661 - val_loss: 368933.5000 - val_mae: 467.1646\n",
            "Epoch 1812/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 504947.7188 - mae: 641.0410 - val_loss: 391528.7500 - val_mae: 491.4031\n",
            "Epoch 1813/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 501931.4375 - mae: 638.5621 - val_loss: 375627.1250 - val_mae: 473.1331\n",
            "Epoch 1814/2000\n",
            "39/39 [==============================] - 5s 114ms/step - loss: 506465.0000 - mae: 643.0026 - val_loss: 376098.0000 - val_mae: 475.3600\n",
            "Epoch 1815/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 503781.1250 - mae: 640.2292 - val_loss: 376131.0938 - val_mae: 473.4242\n",
            "Epoch 1816/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 504807.3750 - mae: 641.1907 - val_loss: 391330.0000 - val_mae: 490.3117\n",
            "Epoch 1817/2000\n",
            "39/39 [==============================] - 10s 241ms/step - loss: 501288.4688 - mae: 638.8848 - val_loss: 375797.6250 - val_mae: 474.2064\n",
            "Epoch 1818/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 507018.8125 - mae: 642.6727 - val_loss: 383925.7500 - val_mae: 482.9566\n",
            "Epoch 1819/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 507640.7188 - mae: 643.0862 - val_loss: 368897.3438 - val_mae: 467.1423\n",
            "Epoch 1820/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 505741.0625 - mae: 642.5934 - val_loss: 383236.9688 - val_mae: 481.5836\n",
            "Epoch 1821/2000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 508774.2812 - mae: 644.4471 - val_loss: 376309.1250 - val_mae: 474.5018\n",
            "Epoch 1822/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 496854.8438 - mae: 636.7614 - val_loss: 376582.0312 - val_mae: 473.6808\n",
            "Epoch 1823/2000\n",
            "39/39 [==============================] - 10s 242ms/step - loss: 510349.5312 - mae: 645.2224 - val_loss: 383787.8438 - val_mae: 481.9043\n",
            "Epoch 1824/2000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 502559.3750 - mae: 639.7940 - val_loss: 384725.5000 - val_mae: 484.3958\n",
            "Epoch 1825/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 504336.6875 - mae: 640.7685 - val_loss: 375359.3438 - val_mae: 473.9569\n",
            "Epoch 1826/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 508320.1562 - mae: 643.2571 - val_loss: 376565.6562 - val_mae: 475.6284\n",
            "Epoch 1827/2000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 507413.7500 - mae: 642.7867 - val_loss: 376203.0938 - val_mae: 473.4709\n",
            "Epoch 1828/2000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 501720.5625 - mae: 639.2762 - val_loss: 383782.3438 - val_mae: 481.9008\n",
            "Epoch 1829/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 507069.9062 - mae: 642.2073 - val_loss: 383757.6250 - val_mae: 481.8850\n",
            "Epoch 1830/2000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 505377.8750 - mae: 640.6816 - val_loss: 384200.7188 - val_mae: 484.4463\n",
            "Epoch 1831/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 509369.2500 - mae: 643.9753 - val_loss: 368279.9688 - val_mae: 465.8142\n",
            "Epoch 1832/2000\n",
            "39/39 [==============================] - 5s 112ms/step - loss: 504950.3750 - mae: 641.5735 - val_loss: 383737.0000 - val_mae: 481.8719\n",
            "Epoch 1833/2000\n",
            "39/39 [==============================] - 10s 237ms/step - loss: 504815.1562 - mae: 641.0485 - val_loss: 399685.0312 - val_mae: 500.5216\n",
            "Epoch 1834/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 507864.6250 - mae: 642.8611 - val_loss: 376635.3438 - val_mae: 473.7154\n",
            "Epoch 1835/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 505654.7500 - mae: 641.6893 - val_loss: 383553.9688 - val_mae: 480.7922\n",
            "Epoch 1836/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 508237.5938 - mae: 643.7408 - val_loss: 376398.0938 - val_mae: 474.5575\n",
            "Epoch 1837/2000\n",
            "39/39 [==============================] - 5s 121ms/step - loss: 505367.3750 - mae: 641.1207 - val_loss: 375683.8438 - val_mae: 475.1239\n",
            "Epoch 1838/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 506302.0000 - mae: 642.2115 - val_loss: 369109.0938 - val_mae: 467.6250\n",
            "Epoch 1839/2000\n",
            "39/39 [==============================] - 10s 238ms/step - loss: 500395.4375 - mae: 639.0760 - val_loss: 376413.3438 - val_mae: 474.5670\n",
            "Epoch 1840/2000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 505499.8125 - mae: 640.7963 - val_loss: 391887.9062 - val_mae: 490.6359\n",
            "Epoch 1841/2000\n",
            "39/39 [==============================] - 5s 118ms/step - loss: 497952.4062 - mae: 638.5836 - val_loss: 375884.3438 - val_mae: 474.2607\n",
            "Epoch 1842/2000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 504935.7812 - mae: 641.3359 - val_loss: 376355.3438 - val_mae: 474.5308\n",
            "Epoch 1843/2000\n",
            "39/39 [==============================] - 10s 237ms/step - loss: 503295.9062 - mae: 639.7814 - val_loss: 367854.0000 - val_mae: 465.5733\n",
            "Epoch 1844/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 508391.4375 - mae: 643.1512 - val_loss: 375467.4062 - val_mae: 474.0246\n",
            "Epoch 1845/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 504631.5312 - mae: 641.5267 - val_loss: 376978.5938 - val_mae: 474.8960\n",
            "Epoch 1846/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 505460.0938 - mae: 640.5156 - val_loss: 391480.0938 - val_mae: 490.7574\n",
            "Epoch 1847/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 501307.9688 - mae: 639.3192 - val_loss: 376170.3438 - val_mae: 475.4037\n",
            "Epoch 1848/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 505653.0312 - mae: 643.0432 - val_loss: 376665.8750 - val_mae: 475.6888\n",
            "Epoch 1849/2000\n",
            "39/39 [==============================] - 10s 238ms/step - loss: 503863.4375 - mae: 639.3486 - val_loss: 384063.4062 - val_mae: 483.0411\n",
            "Epoch 1850/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 507869.6875 - mae: 643.5484 - val_loss: 361988.3438 - val_mae: 459.1058\n",
            "Epoch 1851/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 498554.3125 - mae: 639.4495 - val_loss: 383463.0000 - val_mae: 481.7273\n",
            "Epoch 1852/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 507136.0000 - mae: 643.4018 - val_loss: 383920.4062 - val_mae: 481.9885\n",
            "Epoch 1853/2000\n",
            "39/39 [==============================] - 9s 232ms/step - loss: 507437.8438 - mae: 642.5746 - val_loss: 383665.2812 - val_mae: 482.8155\n",
            "Epoch 1854/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 503647.4688 - mae: 641.6592 - val_loss: 360016.0312 - val_mae: 457.9706\n",
            "Epoch 1855/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 508249.0000 - mae: 644.2764 - val_loss: 361997.4062 - val_mae: 459.1115\n",
            "Epoch 1856/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 506899.4375 - mae: 642.2661 - val_loss: 383824.1562 - val_mae: 483.8786\n",
            "Epoch 1857/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 502985.6250 - mae: 639.7674 - val_loss: 376481.5312 - val_mae: 474.6097\n",
            "Epoch 1858/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 504021.0312 - mae: 640.1558 - val_loss: 376990.5312 - val_mae: 474.9035\n",
            "Epoch 1859/2000\n",
            "39/39 [==============================] - 5s 112ms/step - loss: 502997.6875 - mae: 639.7017 - val_loss: 384326.9062 - val_mae: 484.5208\n",
            "Epoch 1860/2000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 511357.7500 - mae: 646.4732 - val_loss: 392218.2500 - val_mae: 492.1573\n",
            "Epoch 1861/2000\n",
            "39/39 [==============================] - 10s 243ms/step - loss: 506752.5000 - mae: 643.0621 - val_loss: 383896.0312 - val_mae: 481.9730\n",
            "Epoch 1862/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 507972.5938 - mae: 643.2734 - val_loss: 368629.0312 - val_mae: 466.9969\n",
            "Epoch 1863/2000\n",
            "39/39 [==============================] - 10s 232ms/step - loss: 506426.0000 - mae: 641.9738 - val_loss: 376547.1562 - val_mae: 474.6508\n",
            "Epoch 1864/2000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 504357.1875 - mae: 640.5102 - val_loss: 367963.0938 - val_mae: 465.6432\n",
            "Epoch 1865/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 502192.0938 - mae: 638.9472 - val_loss: 376790.0938 - val_mae: 475.7638\n",
            "Epoch 1866/2000\n",
            "39/39 [==============================] - 10s 237ms/step - loss: 508434.7188 - mae: 643.5520 - val_loss: 375846.1250 - val_mae: 473.2753\n",
            "Epoch 1867/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 492905.4062 - mae: 635.9448 - val_loss: 391250.4062 - val_mae: 489.2979\n",
            "Epoch 1868/2000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 502318.4375 - mae: 638.8336 - val_loss: 376268.7500 - val_mae: 473.5134\n",
            "Epoch 1869/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 497480.6875 - mae: 637.1092 - val_loss: 376255.1562 - val_mae: 473.5046\n",
            "Epoch 1870/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 505381.7500 - mae: 641.9207 - val_loss: 383600.8750 - val_mae: 482.7760\n",
            "Epoch 1871/2000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 504841.3750 - mae: 640.9649 - val_loss: 376255.3750 - val_mae: 473.5048\n",
            "Epoch 1872/2000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 508380.4062 - mae: 644.3162 - val_loss: 376665.2500 - val_mae: 475.6885\n",
            "Epoch 1873/2000\n",
            "39/39 [==============================] - 5s 112ms/step - loss: 508589.9688 - mae: 644.5336 - val_loss: 375797.9062 - val_mae: 473.2440\n",
            "Epoch 1874/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 505477.1875 - mae: 642.0068 - val_loss: 391770.8750 - val_mae: 489.5995\n",
            "Epoch 1875/2000\n",
            "39/39 [==============================] - 10s 240ms/step - loss: 506014.1250 - mae: 641.9668 - val_loss: 392201.5312 - val_mae: 491.7947\n",
            "Epoch 1876/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 505700.6562 - mae: 641.1783 - val_loss: 375496.8750 - val_mae: 474.0431\n",
            "Epoch 1877/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 501606.6250 - mae: 638.5276 - val_loss: 368833.2812 - val_mae: 466.1367\n",
            "Epoch 1878/2000\n",
            "39/39 [==============================] - 9s 233ms/step - loss: 505653.4375 - mae: 642.0573 - val_loss: 375924.5938 - val_mae: 474.6381\n",
            "Epoch 1879/2000\n",
            "39/39 [==============================] - 5s 114ms/step - loss: 498241.3125 - mae: 637.9546 - val_loss: 376928.9688 - val_mae: 474.8650\n",
            "Epoch 1880/2000\n",
            "39/39 [==============================] - 10s 244ms/step - loss: 498696.2188 - mae: 639.1476 - val_loss: 384268.8750 - val_mae: 484.1337\n",
            "Epoch 1881/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 506668.8125 - mae: 642.2333 - val_loss: 391771.5938 - val_mae: 491.9015\n",
            "Epoch 1882/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 495829.9688 - mae: 636.3536 - val_loss: 384343.8750 - val_mae: 484.1779\n",
            "Epoch 1883/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 506632.6250 - mae: 642.2578 - val_loss: 399717.1250 - val_mae: 499.2192\n",
            "Epoch 1884/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 503371.4375 - mae: 642.0351 - val_loss: 383988.6562 - val_mae: 482.0318\n",
            "Epoch 1885/2000\n",
            "39/39 [==============================] - 10s 236ms/step - loss: 501981.9688 - mae: 639.1823 - val_loss: 384045.9062 - val_mae: 482.0681\n",
            "Epoch 1886/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 501064.3750 - mae: 639.6172 - val_loss: 377138.7500 - val_mae: 474.9961\n",
            "Epoch 1887/2000\n",
            "39/39 [==============================] - 10s 243ms/step - loss: 506749.5312 - mae: 642.1021 - val_loss: 368720.4062 - val_mae: 467.0533\n",
            "Epoch 1888/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 506322.0000 - mae: 641.9797 - val_loss: 375658.3750 - val_mae: 474.4962\n",
            "Epoch 1889/2000\n",
            "39/39 [==============================] - 10s 241ms/step - loss: 503019.7188 - mae: 640.8406 - val_loss: 392114.7188 - val_mae: 490.7769\n",
            "Epoch 1890/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 510470.9688 - mae: 646.2242 - val_loss: 384931.7500 - val_mae: 484.5174\n",
            "Epoch 1891/2000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 506257.3750 - mae: 641.9672 - val_loss: 376778.1562 - val_mae: 475.7566\n",
            "Epoch 1892/2000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 507739.9062 - mae: 642.9236 - val_loss: 391664.3750 - val_mae: 488.5741\n",
            "Epoch 1893/2000\n",
            "39/39 [==============================] - 10s 224ms/step - loss: 499107.9062 - mae: 638.9959 - val_loss: 392029.3438 - val_mae: 490.7239\n",
            "Epoch 1894/2000\n",
            "39/39 [==============================] - 6s 146ms/step - loss: 502268.7500 - mae: 640.7026 - val_loss: 376527.5000 - val_mae: 474.6384\n",
            "Epoch 1895/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 504236.4375 - mae: 640.8768 - val_loss: 391980.8438 - val_mae: 492.6415\n",
            "Epoch 1896/2000\n",
            "39/39 [==============================] - 6s 147ms/step - loss: 508763.8750 - mae: 644.7137 - val_loss: 376774.9062 - val_mae: 475.7545\n",
            "Epoch 1897/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 505985.4062 - mae: 641.6998 - val_loss: 376318.5938 - val_mae: 475.4931\n",
            "Epoch 1898/2000\n",
            "39/39 [==============================] - 5s 112ms/step - loss: 504175.5312 - mae: 641.2682 - val_loss: 367971.8750 - val_mae: 465.6488\n",
            "Epoch 1899/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 505993.3750 - mae: 642.3301 - val_loss: 375855.7812 - val_mae: 473.2816\n",
            "Epoch 1900/2000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 504983.6250 - mae: 641.6201 - val_loss: 375849.6562 - val_mae: 473.2776\n",
            "Epoch 1901/2000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 508281.3750 - mae: 643.8696 - val_loss: 384198.4688 - val_mae: 481.1757\n",
            "Epoch 1902/2000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 504400.3125 - mae: 640.3063 - val_loss: 376209.5000 - val_mae: 475.4273\n",
            "Epoch 1903/2000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 506112.7188 - mae: 641.9716 - val_loss: 384139.5312 - val_mae: 483.0876\n",
            "Epoch 1904/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 503043.0312 - mae: 639.9985 - val_loss: 399186.7812 - val_mae: 496.9640\n",
            "Epoch 1905/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 502951.2188 - mae: 639.9147 - val_loss: 391294.0938 - val_mae: 489.3260\n",
            "Epoch 1906/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 508827.1875 - mae: 644.3212 - val_loss: 383873.9688 - val_mae: 483.9080\n",
            "Epoch 1907/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 504877.0312 - mae: 640.6011 - val_loss: 376366.6250 - val_mae: 473.5769\n",
            "Epoch 1908/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 505612.0312 - mae: 640.8347 - val_loss: 369183.0000 - val_mae: 467.3182\n",
            "Epoch 1909/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 505478.2188 - mae: 640.8348 - val_loss: 384421.6562 - val_mae: 484.2238\n",
            "Epoch 1910/2000\n",
            "39/39 [==============================] - 5s 100ms/step - loss: 503847.7812 - mae: 640.7935 - val_loss: 391943.1562 - val_mae: 489.7103\n",
            "Epoch 1911/2000\n",
            "39/39 [==============================] - 10s 240ms/step - loss: 503832.6875 - mae: 640.4052 - val_loss: 384222.0000 - val_mae: 483.1382\n",
            "Epoch 1912/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 504356.3438 - mae: 640.2758 - val_loss: 369203.8750 - val_mae: 467.3310\n",
            "Epoch 1913/2000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 509931.4375 - mae: 644.2493 - val_loss: 376125.3750 - val_mae: 474.4116\n",
            "Epoch 1914/2000\n",
            "39/39 [==============================] - 5s 102ms/step - loss: 504129.6875 - mae: 640.6390 - val_loss: 376094.2500 - val_mae: 474.3921\n",
            "Epoch 1915/2000\n",
            "39/39 [==============================] - 10s 232ms/step - loss: 499854.3750 - mae: 639.0497 - val_loss: 392066.9062 - val_mae: 490.7473\n",
            "Epoch 1916/2000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 507606.1562 - mae: 642.3922 - val_loss: 376328.7500 - val_mae: 473.5523\n",
            "Epoch 1917/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 510579.9688 - mae: 644.9589 - val_loss: 399250.9062 - val_mae: 497.0059\n",
            "Epoch 1918/2000\n",
            "39/39 [==============================] - 10s 236ms/step - loss: 504963.6562 - mae: 641.4055 - val_loss: 391536.4688 - val_mae: 490.4403\n",
            "Epoch 1919/2000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 504780.7812 - mae: 641.7706 - val_loss: 369469.0938 - val_mae: 466.5117\n",
            "Epoch 1920/2000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 499843.8125 - mae: 639.7757 - val_loss: 384164.4062 - val_mae: 483.1029\n",
            "Epoch 1921/2000\n",
            "39/39 [==============================] - 5s 130ms/step - loss: 506596.9688 - mae: 642.0397 - val_loss: 361082.5938 - val_mae: 458.5889\n",
            "Epoch 1922/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 507587.3438 - mae: 644.3278 - val_loss: 384132.4688 - val_mae: 483.0833\n",
            "Epoch 1923/2000\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 496096.9375 - mae: 637.1967 - val_loss: 384425.6562 - val_mae: 482.2801\n",
            "Epoch 1924/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 500958.5938 - mae: 637.9138 - val_loss: 376316.7500 - val_mae: 473.5446\n",
            "Epoch 1925/2000\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 490538.7812 - mae: 635.8035 - val_loss: 391538.1250 - val_mae: 490.4413\n",
            "Epoch 1926/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 508378.8125 - mae: 642.8276 - val_loss: 383895.5000 - val_mae: 482.3246\n",
            "Epoch 1927/2000\n",
            "39/39 [==============================] - 5s 103ms/step - loss: 504475.8125 - mae: 641.7853 - val_loss: 383902.1250 - val_mae: 481.9768\n",
            "Epoch 1928/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 505544.7188 - mae: 641.4179 - val_loss: 384160.5938 - val_mae: 483.1006\n",
            "Epoch 1929/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 507466.6562 - mae: 642.6851 - val_loss: 376758.2500 - val_mae: 475.7446\n",
            "Epoch 1930/2000\n",
            "39/39 [==============================] - 10s 238ms/step - loss: 506918.2812 - mae: 642.3154 - val_loss: 383927.2812 - val_mae: 481.9928\n",
            "Epoch 1931/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 505217.1562 - mae: 641.7082 - val_loss: 392505.0312 - val_mae: 492.9431\n",
            "Epoch 1932/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 494974.4688 - mae: 636.8307 - val_loss: 376288.0000 - val_mae: 473.5260\n",
            "Epoch 1933/2000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 503578.6250 - mae: 639.8784 - val_loss: 391529.5938 - val_mae: 490.7881\n",
            "Epoch 1934/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 500233.6875 - mae: 639.0975 - val_loss: 376236.1562 - val_mae: 475.4434\n",
            "Epoch 1935/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 509335.2188 - mae: 645.1211 - val_loss: 368364.6562 - val_mae: 465.8685\n",
            "Epoch 1936/2000\n",
            "39/39 [==============================] - 5s 103ms/step - loss: 505200.9375 - mae: 641.1916 - val_loss: 368123.2188 - val_mae: 466.7054\n",
            "Epoch 1937/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 501811.8750 - mae: 639.5753 - val_loss: 384115.6250 - val_mae: 483.0730\n",
            "Epoch 1938/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 503612.0312 - mae: 640.8517 - val_loss: 383824.1562 - val_mae: 483.8786\n",
            "Epoch 1939/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 503834.6562 - mae: 640.6863 - val_loss: 384070.9062 - val_mae: 483.0457\n",
            "Epoch 1940/2000\n",
            "39/39 [==============================] - 10s 238ms/step - loss: 505559.4375 - mae: 641.3913 - val_loss: 399105.9062 - val_mae: 496.9113\n",
            "Epoch 1941/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 506670.4688 - mae: 642.0151 - val_loss: 376145.9062 - val_mae: 475.3889\n",
            "Epoch 1942/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 499470.2188 - mae: 638.9276 - val_loss: 384478.7188 - val_mae: 483.2771\n",
            "Epoch 1943/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 509004.7500 - mae: 643.7820 - val_loss: 369526.2188 - val_mae: 467.5097\n",
            "Epoch 1944/2000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 503323.8125 - mae: 641.2935 - val_loss: 384034.3438 - val_mae: 483.0233\n",
            "Epoch 1945/2000\n",
            "39/39 [==============================] - 10s 238ms/step - loss: 505657.6250 - mae: 641.4664 - val_loss: 384060.2500 - val_mae: 483.0391\n",
            "Epoch 1946/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 504331.7188 - mae: 641.2207 - val_loss: 367839.6250 - val_mae: 465.5641\n",
            "Epoch 1947/2000\n",
            "39/39 [==============================] - 10s 243ms/step - loss: 499397.8438 - mae: 637.8192 - val_loss: 384483.2812 - val_mae: 483.2799\n",
            "Epoch 1948/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 502401.7812 - mae: 640.7565 - val_loss: 369006.8750 - val_mae: 467.2097\n",
            "Epoch 1949/2000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 508073.7188 - mae: 642.9304 - val_loss: 376656.9062 - val_mae: 475.6835\n",
            "Epoch 1950/2000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 506793.6250 - mae: 642.0244 - val_loss: 368333.7500 - val_mae: 465.8487\n",
            "Epoch 1951/2000\n",
            "39/39 [==============================] - 10s 230ms/step - loss: 506092.7500 - mae: 641.1181 - val_loss: 391454.7812 - val_mae: 490.3894\n",
            "Epoch 1952/2000\n",
            "39/39 [==============================] - 10s 236ms/step - loss: 505883.0312 - mae: 642.1832 - val_loss: 398939.8438 - val_mae: 495.8455\n",
            "Epoch 1953/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 504978.8125 - mae: 640.8237 - val_loss: 375709.2812 - val_mae: 475.1393\n",
            "Epoch 1954/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 506182.7500 - mae: 642.9708 - val_loss: 383606.1562 - val_mae: 482.7792\n",
            "Epoch 1955/2000\n",
            "39/39 [==============================] - 5s 118ms/step - loss: 507503.0000 - mae: 642.7549 - val_loss: 376685.7188 - val_mae: 475.7008\n",
            "Epoch 1956/2000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 507871.4375 - mae: 643.3982 - val_loss: 384330.4062 - val_mae: 484.1700\n",
            "Epoch 1957/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 498131.7188 - mae: 638.1370 - val_loss: 360979.5938 - val_mae: 458.5240\n",
            "Epoch 1958/2000\n",
            "39/39 [==============================] - 6s 131ms/step - loss: 506821.8438 - mae: 642.5162 - val_loss: 391658.1562 - val_mae: 491.4808\n",
            "Epoch 1959/2000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 507613.8125 - mae: 643.4172 - val_loss: 383613.3438 - val_mae: 483.1360\n",
            "Epoch 1960/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 507496.0000 - mae: 642.7892 - val_loss: 376138.8438 - val_mae: 475.3847\n",
            "Epoch 1961/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 507939.2812 - mae: 643.1749 - val_loss: 375459.8750 - val_mae: 474.0199\n",
            "Epoch 1962/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 507529.1875 - mae: 642.5956 - val_loss: 376420.4062 - val_mae: 474.5714\n",
            "Epoch 1963/2000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 506250.9375 - mae: 642.4658 - val_loss: 392360.5938 - val_mae: 492.8596\n",
            "Epoch 1964/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 506278.7500 - mae: 641.9059 - val_loss: 383603.0312 - val_mae: 480.8245\n",
            "Epoch 1965/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 505051.3750 - mae: 641.3657 - val_loss: 383330.6250 - val_mae: 481.6432\n",
            "Epoch 1966/2000\n",
            "39/39 [==============================] - 10s 234ms/step - loss: 505791.6562 - mae: 642.0234 - val_loss: 383865.3438 - val_mae: 481.9536\n",
            "Epoch 1967/2000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 507214.4688 - mae: 643.7191 - val_loss: 368588.2500 - val_mae: 466.9718\n",
            "Epoch 1968/2000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 506722.6250 - mae: 642.3632 - val_loss: 391498.1562 - val_mae: 490.4164\n",
            "Epoch 1969/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 502639.2812 - mae: 640.8844 - val_loss: 392173.7500 - val_mae: 491.7780\n",
            "Epoch 1970/2000\n",
            "39/39 [==============================] - 10s 239ms/step - loss: 504207.6875 - mae: 640.9299 - val_loss: 383872.6562 - val_mae: 481.9582\n",
            "Epoch 1971/2000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 499498.5625 - mae: 637.5671 - val_loss: 384490.2812 - val_mae: 483.2842\n",
            "Epoch 1972/2000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 506569.4062 - mae: 642.1845 - val_loss: 376391.5938 - val_mae: 474.5534\n",
            "Epoch 1973/2000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 508874.4062 - mae: 644.5626 - val_loss: 384286.9062 - val_mae: 484.1444\n",
            "Epoch 1974/2000\n",
            "39/39 [==============================] - 9s 231ms/step - loss: 506706.8125 - mae: 643.9424 - val_loss: 392146.5000 - val_mae: 491.7616\n",
            "Epoch 1975/2000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 505211.4375 - mae: 641.3671 - val_loss: 383612.6562 - val_mae: 483.1356\n",
            "Epoch 1976/2000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 504559.0000 - mae: 640.9951 - val_loss: 391894.5938 - val_mae: 490.6401\n",
            "Epoch 1977/2000\n",
            "39/39 [==============================] - 6s 134ms/step - loss: 501682.1562 - mae: 638.7126 - val_loss: 375423.8750 - val_mae: 473.9973\n",
            "Epoch 1978/2000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 508358.3750 - mae: 643.0692 - val_loss: 368367.4062 - val_mae: 465.8702\n",
            "Epoch 1979/2000\n",
            "39/39 [==============================] - 6s 139ms/step - loss: 498898.5625 - mae: 637.9282 - val_loss: 368057.1250 - val_mae: 466.6646\n",
            "Epoch 1980/2000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 508359.4688 - mae: 643.8018 - val_loss: 383566.1562 - val_mae: 483.1071\n",
            "Epoch 1981/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 507010.5625 - mae: 643.4314 - val_loss: 376109.7500 - val_mae: 475.3671\n",
            "Epoch 1982/2000\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 503886.9062 - mae: 639.6690 - val_loss: 384336.4062 - val_mae: 482.2234\n",
            "Epoch 1983/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 506983.4688 - mae: 643.9167 - val_loss: 399320.0312 - val_mae: 498.0095\n",
            "Epoch 1984/2000\n",
            "39/39 [==============================] - 10s 237ms/step - loss: 508779.8125 - mae: 644.1701 - val_loss: 383544.6562 - val_mae: 480.7860\n",
            "Epoch 1985/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 505373.9062 - mae: 641.3134 - val_loss: 376418.3750 - val_mae: 474.5702\n",
            "Epoch 1986/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 507358.0000 - mae: 642.4979 - val_loss: 360815.7500 - val_mae: 458.4207\n",
            "Epoch 1987/2000\n",
            "39/39 [==============================] - 6s 130ms/step - loss: 503889.6875 - mae: 639.4020 - val_loss: 383679.3750 - val_mae: 483.7931\n",
            "Epoch 1988/2000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 505220.9688 - mae: 641.6965 - val_loss: 368427.9688 - val_mae: 466.8730\n",
            "Epoch 1989/2000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 505633.7812 - mae: 642.2087 - val_loss: 384641.5000 - val_mae: 484.3462\n",
            "Epoch 1990/2000\n",
            "39/39 [==============================] - 10s 236ms/step - loss: 508871.2812 - mae: 644.6091 - val_loss: 384277.2188 - val_mae: 484.4914\n",
            "Epoch 1991/2000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 501723.5000 - mae: 640.0695 - val_loss: 383755.4062 - val_mae: 481.8837\n",
            "Epoch 1992/2000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 494438.1250 - mae: 636.6750 - val_loss: 376143.2812 - val_mae: 475.3874\n",
            "Epoch 1993/2000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 502485.8125 - mae: 639.4949 - val_loss: 376362.2500 - val_mae: 474.5351\n",
            "Epoch 1994/2000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 503071.6250 - mae: 641.5039 - val_loss: 367348.6562 - val_mae: 465.2816\n",
            "Epoch 1995/2000\n",
            "39/39 [==============================] - 10s 235ms/step - loss: 509218.6250 - mae: 644.1649 - val_loss: 383300.4062 - val_mae: 481.6240\n",
            "Epoch 1996/2000\n",
            "39/39 [==============================] - 9s 234ms/step - loss: 506866.3125 - mae: 643.1808 - val_loss: 368533.2812 - val_mae: 466.9380\n",
            "Epoch 1997/2000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 507719.8438 - mae: 644.0650 - val_loss: 391653.3438 - val_mae: 491.4779\n",
            "Epoch 1998/2000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 503151.9062 - mae: 640.0406 - val_loss: 384734.7500 - val_mae: 484.4013\n",
            "Epoch 1999/2000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 510021.6562 - mae: 645.3273 - val_loss: 375696.9062 - val_mae: 473.1784\n",
            "Epoch 2000/2000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 503201.8438 - mae: 641.1470 - val_loss: 375963.9688 - val_mae: 474.3105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "mae = history.history['mae']\n",
        "val_mae = history.history['val_mae']\n",
        "\n",
        "epochs_x = range(len(loss))\n",
        "\n",
        "plt.plot(epochs_x, mae, 'co', label='Training MAE')\n",
        "plt.plot(epochs_x, val_mae, 'k', label='Validation MAE')\n",
        "plt.title('Training and Mean squared error')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'co', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "     "
      ],
      "metadata": {
        "id": "Y3K89-CM-dfg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "e1fde937-dd2d-447f-9b78-0c67b2ca1e15"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_x"
      ],
      "metadata": {
        "id": "N_sP_ZmSY-Jv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27867753-33a5-429b-98e5-235d5e87f047"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "range(0, 2000)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download the model\n"
      ],
      "metadata": {
        "id": "R19IJQSYoW7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('./content/drive/My Drive/new', exist_ok=True)\n",
        "model.save('./content/drive/My Drive/new/regression_unfreeze.h5')"
      ],
      "metadata": {
        "id": "Zed4TdFcG2iJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n"
      ],
      "metadata": {
        "id": "P5eMxm1NV-oY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('./content/drive/My Drive/new/regression_unfreeze.h5')"
      ],
      "metadata": {
        "id": "wY_pDlxkRwxS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e80bc2c2-49f0-4145-fdfe-9ae1084885e2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5c836267-6cc5-44f5-9354-78ebbbf0e9e6\", \"regression_unfreeze.h5\", 16620968)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}