{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kittikhun62/efficientnet_keras_transfer_learning/blob/master/regression_2Class_Unfreeze.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#เรียกใช้ CSV"
      ],
      "metadata": {
        "id": "ow7eWoNw6U-c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "z8o_VVNXzcL8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_2Fe8u81d5r",
        "outputId": "da6971a9-d3e4-4d71-8aa2-4bc1e371a16c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "5qxePnnn7TGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "D-hCRloc3t39"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "YZWXwjXeGxZP"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#กำหนดค่าพารามิเตอร์\n"
      ],
      "metadata": {
        "id": "RooqSdBc7QHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "width = 150\n",
        "height = 150\n",
        "\n",
        "epochs = 1000 #จำนวนรอบในการ Train\n",
        "\n",
        "NUM_TRAIN = 598  # จำนวนภาพ Train\n",
        "NUM_TEST = 101 #จำนวนภาพ Test\n",
        "\n",
        "dropout_rate = 0.3\n",
        "input_shape = (height, width, 3) #ขนาด image enter"
      ],
      "metadata": {
        "id": "thDb7U9B3xOo"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clone efficientnet repo\n"
      ],
      "metadata": {
        "id": "pumGmy6f3eSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7iy2f8n16p0",
        "outputId": "b4fb66fb-f593-4508-da55-276950f4ac5f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "tjZBRnfo3bN0"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "r8BN74_JJdfj"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#load model\n"
      ],
      "metadata": {
        "id": "PdNWyD-QYkzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/new/regression_2e-2.h5')\n",
        "\n",
        "from efficientnet.layers import Swish, DropConnect\n",
        "from efficientnet.model import ConvKernalInitializer\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "\n",
        "get_custom_objects().update({\n",
        "    'ConvKernalInitializer': ConvKernalInitializer,\n",
        "    'Swish': Swish,\n",
        "    'DropConnect':DropConnect\n",
        "})"
      ],
      "metadata": {
        "id": "_gPnx2UvYf5A"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load model \n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/drive/My Drive/new/regression_2e-2.h5')\n",
        "height = width = model.input_shape[1]"
      ],
      "metadata": {
        "id": "Nu93WzFUYm9e"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "gp5EbyyXYvc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a09c8aed-7ae6-43db-a19c-63cb54f44e62"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 2)                 2562      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,052,129\n",
            "Trainable params: 2,565\n",
            "Non-trainable params: 4,049,564\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (f'/content/drive/My Drive/data - 2 class Regress.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "q1Dc131_Y3uA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "06719881-ee78-4041-bdcb-a7058587513a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      No                      Name_file  \\\n",
              "0      1                        pore-sb   \n",
              "1      2                        pore-sb   \n",
              "2      3                        pore-sb   \n",
              "3      4                        pore-sb   \n",
              "4      5                        pore-sb   \n",
              "..   ...                            ...   \n",
              "795  796  1-s2.0-S2095268622000210-main   \n",
              "796  797  1-s2.0-S2095268622000210-main   \n",
              "797  798  1-s2.0-S2095268622000210-main   \n",
              "798  799  1-s2.0-S2095268622000210-main   \n",
              "799  800  1-s2.0-S2095268622000210-main   \n",
              "\n",
              "                                            Name_Paper  \\\n",
              "0    Preparation and electrochemical behaviour of b...   \n",
              "1    Preparation and electrochemical behaviour of b...   \n",
              "2    Preparation and electrochemical behaviour of b...   \n",
              "3    Preparation and electrochemical behaviour of b...   \n",
              "4    Preparation and electrochemical behaviour of b...   \n",
              "..                                                 ...   \n",
              "795  Integration of preparation of K, Na-embedded a...   \n",
              "796  Integration of preparation of K, Na-embedded a...   \n",
              "797  Integration of preparation of K, Na-embedded a...   \n",
              "798  Integration of preparation of K, Na-embedded a...   \n",
              "799  Integration of preparation of K, Na-embedded a...   \n",
              "\n",
              "                                               journal  \\\n",
              "0                                  Korean J. Chem. Eng   \n",
              "1                                  Korean J. Chem. Eng   \n",
              "2                                  Korean J. Chem. Eng   \n",
              "3                                  Korean J. Chem. Eng   \n",
              "4                                  Korean J. Chem. Eng   \n",
              "..                                                 ...   \n",
              "795  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "796  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "797  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "798  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "799  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "\n",
              "                                          path_Picture  detail  Class     BET  \\\n",
              "0    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom1  0-800  135.06   \n",
              "1    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom2  0-800  135.06   \n",
              "2    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom3  0-800  135.06   \n",
              "3    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom4  0-800  135.06   \n",
              "4    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom5  0-800  135.06   \n",
              "..                                                 ...     ...    ...     ...   \n",
              "795  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom21  0-800  301.70   \n",
              "796  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom22  0-800  301.70   \n",
              "797  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom23  0-800  301.70   \n",
              "798  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom24  0-800  301.70   \n",
              "799  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom25  0-800  301.70   \n",
              "\n",
              "     Size(mico)  Class_01  \n",
              "0            10         0  \n",
              "1            10         0  \n",
              "2            10         0  \n",
              "3            10         0  \n",
              "4            10         0  \n",
              "..          ...       ...  \n",
              "795          10         0  \n",
              "796          10         0  \n",
              "797          10         0  \n",
              "798          10         0  \n",
              "799          10         0  \n",
              "\n",
              "[800 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-64e19641-d99e-4faa-b703-216aa81418ce\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>No</th>\n",
              "      <th>Name_file</th>\n",
              "      <th>Name_Paper</th>\n",
              "      <th>journal</th>\n",
              "      <th>path_Picture</th>\n",
              "      <th>detail</th>\n",
              "      <th>Class</th>\n",
              "      <th>BET</th>\n",
              "      <th>Size(mico)</th>\n",
              "      <th>Class_01</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom1</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom2</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom3</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom4</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom5</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>795</th>\n",
              "      <td>796</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom21</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>796</th>\n",
              "      <td>797</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom22</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>797</th>\n",
              "      <td>798</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom23</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>798</th>\n",
              "      <td>799</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom24</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799</th>\n",
              "      <td>800</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom25</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>800 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-64e19641-d99e-4faa-b703-216aa81418ce')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-64e19641-d99e-4faa-b703-216aa81418ce button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-64e19641-d99e-4faa-b703-216aa81418ce');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "FdYoTgJ19LRv"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val = df[df['No'].between(599,699)]\n",
        "train = df[df['No'].between(1,598)]"
      ],
      "metadata": {
        "id": "Z1zBw01Gl8Ac"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = '/content/drive/My Drive/new Regress'\n",
        "os.chdir(DATA_PATH)\n",
        "train_dir = os.path.join(DATA_PATH, 'train')\n",
        "print(train_dir)\n",
        "validation_dir = os.path.join(DATA_PATH, 'validation')\n",
        "print(validation_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QL0g-8iOnMC4",
        "outputId": "5392db28-7d22-4bfa-e327-ab6a2aecf922"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/new Regress/train\n",
            "/content/drive/My Drive/new Regress/validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Train"
      ],
      "metadata": {
        "id": "bWEnlTSwazL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "xGPrsn9no_pa"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe = train,\n",
        "        directory = train_dir,\n",
        "        x_col = 'path_Picture',\n",
        "        y_col = 'BET',\n",
        "        class_mode = 'other',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)\n",
        "\n",
        "validation_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe = val,\n",
        "        directory = validation_dir,\n",
        "        x_col = 'path_Picture',\n",
        "        y_col = 'BET',\n",
        "        class_mode = 'other',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nVlmAszntK_",
        "outputId": "aa65ec9e-ee90-4c15-db34-28a86585314c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 598 validated image filenames.\n",
            "Found 101 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multiply_16\n",
        "# set 'multiply_16' and following layers trainable\n",
        "model.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'multiply_16':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False  "
      ],
      "metadata": {
        "id": "RY14olxmJj92"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzCdn3X4Jm_E",
        "outputId": "4a183f50-5cc9-48b2-b9e2-899302b4a3b3"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 2)                 2562      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,052,129\n",
            "Trainable params: 4,010,113\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mse',\n",
        "          optimizer=Adam(learning_rate=2e-2),\n",
        "          metrics=['mae'])\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "N6qUmmF856ZE",
        "outputId": "f6bf89a2-a661-4e76-9d70-1a75686c5923",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-1fcca56a0755>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "37/37 [==============================] - 99s 1s/step - loss: 499820.6875 - mae: 638.9727 - val_loss: 397204.2188 - val_mae: 487.6948\n",
            "Epoch 2/1000\n",
            "37/37 [==============================] - 5s 116ms/step - loss: 499893.3750 - mae: 638.9380 - val_loss: 397328.8438 - val_mae: 486.7777\n",
            "Epoch 3/1000\n",
            "37/37 [==============================] - 10s 255ms/step - loss: 498463.5625 - mae: 640.2794 - val_loss: 397987.2188 - val_mae: 487.6414\n",
            "Epoch 4/1000\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 498374.2812 - mae: 637.2863 - val_loss: 414041.3750 - val_mae: 504.0205\n",
            "Epoch 5/1000\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 500645.1562 - mae: 640.1530 - val_loss: 398789.9062 - val_mae: 488.5846\n",
            "Epoch 6/1000\n",
            "37/37 [==============================] - 5s 113ms/step - loss: 504663.1875 - mae: 642.4958 - val_loss: 405674.0312 - val_mae: 495.4030\n",
            "Epoch 7/1000\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 502608.3750 - mae: 641.3205 - val_loss: 398323.8750 - val_mae: 487.8391\n",
            "Epoch 8/1000\n",
            "37/37 [==============================] - 5s 112ms/step - loss: 499265.0312 - mae: 639.3193 - val_loss: 397763.3750 - val_mae: 487.0424\n",
            "Epoch 9/1000\n",
            "37/37 [==============================] - 10s 249ms/step - loss: 497003.8125 - mae: 637.6185 - val_loss: 423016.6562 - val_mae: 512.9915\n",
            "Epoch 10/1000\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 499011.0938 - mae: 639.3950 - val_loss: 398428.7812 - val_mae: 487.4219\n",
            "Epoch 11/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 502865.4375 - mae: 640.7355 - val_loss: 407211.6562 - val_mae: 496.2813\n",
            "Epoch 12/1000\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 500055.6562 - mae: 639.3362 - val_loss: 406918.0000 - val_mae: 496.5965\n",
            "Epoch 13/1000\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 504807.9062 - mae: 643.1568 - val_loss: 399393.5938 - val_mae: 488.4519\n",
            "Epoch 14/1000\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 498547.7500 - mae: 638.2610 - val_loss: 399124.5938 - val_mae: 488.7769\n",
            "Epoch 15/1000\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 499006.0625 - mae: 639.3770 - val_loss: 398498.1250 - val_mae: 488.4266\n",
            "Epoch 16/1000\n",
            "37/37 [==============================] - 10s 250ms/step - loss: 498896.2812 - mae: 638.6938 - val_loss: 415638.2812 - val_mae: 504.9409\n",
            "Epoch 17/1000\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 503482.3438 - mae: 641.9741 - val_loss: 390215.2812 - val_mae: 479.8639\n",
            "Epoch 18/1000\n",
            "37/37 [==============================] - 10s 254ms/step - loss: 498623.5625 - mae: 638.3395 - val_loss: 407506.7500 - val_mae: 497.7399\n",
            "Epoch 19/1000\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 504603.8125 - mae: 643.1771 - val_loss: 407355.5000 - val_mae: 496.8478\n",
            "Epoch 20/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 502436.0625 - mae: 641.1663 - val_loss: 390765.5000 - val_mae: 479.7091\n",
            "Epoch 21/1000\n",
            "37/37 [==============================] - 10s 250ms/step - loss: 501334.8125 - mae: 640.3267 - val_loss: 390786.8438 - val_mae: 479.7219\n",
            "Epoch 22/1000\n",
            "37/37 [==============================] - 5s 116ms/step - loss: 500636.8750 - mae: 639.8455 - val_loss: 399515.7188 - val_mae: 488.0818\n",
            "Epoch 23/1000\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 502580.9062 - mae: 640.6218 - val_loss: 399199.9062 - val_mae: 488.8225\n",
            "Epoch 24/1000\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 499875.7812 - mae: 639.8036 - val_loss: 415973.5312 - val_mae: 506.0571\n",
            "Epoch 25/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 502561.8125 - mae: 640.9952 - val_loss: 407101.7812 - val_mae: 495.8018\n",
            "Epoch 26/1000\n",
            "37/37 [==============================] - 10s 251ms/step - loss: 499299.2500 - mae: 640.2291 - val_loss: 407747.1562 - val_mae: 496.6188\n",
            "Epoch 27/1000\n",
            "37/37 [==============================] - 5s 115ms/step - loss: 503451.4375 - mae: 641.6944 - val_loss: 391320.2500 - val_mae: 480.0403\n",
            "Epoch 28/1000\n",
            "37/37 [==============================] - 10s 251ms/step - loss: 496884.7188 - mae: 637.9272 - val_loss: 416075.9688 - val_mae: 505.6588\n",
            "Epoch 29/1000\n",
            "37/37 [==============================] - 5s 118ms/step - loss: 504042.8750 - mae: 642.2742 - val_loss: 399530.9062 - val_mae: 488.5602\n",
            "Epoch 30/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 496806.0938 - mae: 638.1705 - val_loss: 399462.0000 - val_mae: 488.0741\n",
            "Epoch 31/1000\n",
            "37/37 [==============================] - 10s 250ms/step - loss: 503970.6875 - mae: 642.9068 - val_loss: 399693.7500 - val_mae: 488.6554\n",
            "Epoch 32/1000\n",
            "37/37 [==============================] - 10s 246ms/step - loss: 502007.0312 - mae: 640.8981 - val_loss: 416639.4062 - val_mae: 504.6396\n",
            "Epoch 33/1000\n",
            "37/37 [==============================] - 10s 249ms/step - loss: 492120.3125 - mae: 636.3164 - val_loss: 416991.1250 - val_mae: 505.7292\n",
            "Epoch 34/1000\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 505680.3438 - mae: 644.1208 - val_loss: 391891.2812 - val_mae: 480.3806\n",
            "Epoch 35/1000\n",
            "37/37 [==============================] - 5s 114ms/step - loss: 501435.8750 - mae: 640.6346 - val_loss: 400492.1562 - val_mae: 488.6730\n",
            "Epoch 36/1000\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 502993.0000 - mae: 641.9603 - val_loss: 400281.7188 - val_mae: 489.4312\n",
            "Epoch 37/1000\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 502611.0938 - mae: 641.7517 - val_loss: 417468.8750 - val_mae: 506.0070\n",
            "Epoch 38/1000\n",
            "37/37 [==============================] - 5s 115ms/step - loss: 502303.7812 - mae: 641.5352 - val_loss: 409356.9062 - val_mae: 497.5555\n",
            "Epoch 39/1000\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 498412.8750 - mae: 638.7431 - val_loss: 408915.5312 - val_mae: 497.3122\n",
            "Epoch 40/1000\n",
            "37/37 [==============================] - 5s 118ms/step - loss: 502819.9688 - mae: 642.6503 - val_loss: 408868.3438 - val_mae: 497.2842\n",
            "Epoch 41/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 502361.0625 - mae: 641.5514 - val_loss: 409095.7500 - val_mae: 497.8443\n",
            "Epoch 42/1000\n",
            "37/37 [==============================] - 10s 255ms/step - loss: 491318.3750 - mae: 635.8798 - val_loss: 417285.0938 - val_mae: 506.3374\n",
            "Epoch 43/1000\n",
            "37/37 [==============================] - 9s 248ms/step - loss: 502166.1562 - mae: 640.9160 - val_loss: 401581.5312 - val_mae: 489.3069\n",
            "Epoch 44/1000\n",
            "37/37 [==============================] - 5s 114ms/step - loss: 505012.2188 - mae: 644.3306 - val_loss: 408772.2812 - val_mae: 497.6672\n",
            "Epoch 45/1000\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 496729.6875 - mae: 640.2788 - val_loss: 401154.2188 - val_mae: 489.4937\n",
            "Epoch 46/1000\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 494885.3438 - mae: 638.8529 - val_loss: 401316.0312 - val_mae: 489.5880\n",
            "Epoch 47/1000\n",
            "37/37 [==============================] - 10s 250ms/step - loss: 502632.9062 - mae: 642.1028 - val_loss: 400606.1562 - val_mae: 489.1878\n",
            "Epoch 48/1000\n",
            "37/37 [==============================] - 10s 250ms/step - loss: 500584.0938 - mae: 641.3091 - val_loss: 409394.8438 - val_mae: 498.4381\n",
            "Epoch 49/1000\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 499493.7812 - mae: 639.7288 - val_loss: 401245.1250 - val_mae: 489.1279\n",
            "Epoch 50/1000\n",
            "37/37 [==============================] - 10s 250ms/step - loss: 501850.8750 - mae: 640.7233 - val_loss: 402009.2500 - val_mae: 490.3954\n",
            "Epoch 51/1000\n",
            "37/37 [==============================] - 10s 252ms/step - loss: 494334.1562 - mae: 638.3913 - val_loss: 401042.2188 - val_mae: 489.8579\n",
            "Epoch 52/1000\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 494719.8750 - mae: 638.7001 - val_loss: 418299.1562 - val_mae: 506.9033\n",
            "Epoch 53/1000\n",
            "37/37 [==============================] - 5s 114ms/step - loss: 489799.1875 - mae: 635.3542 - val_loss: 401426.7188 - val_mae: 489.6523\n",
            "Epoch 54/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 497294.0625 - mae: 637.9898 - val_loss: 409440.6562 - val_mae: 497.2089\n",
            "Epoch 55/1000\n",
            "37/37 [==============================] - 5s 117ms/step - loss: 495057.9688 - mae: 637.4247 - val_loss: 401403.4062 - val_mae: 489.9790\n",
            "Epoch 56/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 502449.6562 - mae: 641.7869 - val_loss: 409281.9688 - val_mae: 498.3729\n",
            "Epoch 57/1000\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 487396.9062 - mae: 635.8107 - val_loss: 401115.3438 - val_mae: 489.4844\n",
            "Epoch 58/1000\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 499378.3125 - mae: 639.8364 - val_loss: 410342.0000 - val_mae: 499.3033\n",
            "Epoch 59/1000\n",
            "37/37 [==============================] - 5s 116ms/step - loss: 502906.8438 - mae: 642.3961 - val_loss: 417813.7812 - val_mae: 506.2197\n",
            "Epoch 60/1000\n",
            "37/37 [==============================] - 6s 138ms/step - loss: 498492.8750 - mae: 638.9723 - val_loss: 393689.7500 - val_mae: 481.8395\n",
            "Epoch 61/1000\n",
            "37/37 [==============================] - 10s 248ms/step - loss: 506392.8125 - mae: 644.2583 - val_loss: 400717.2812 - val_mae: 488.8576\n",
            "Epoch 62/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 499925.2188 - mae: 639.4536 - val_loss: 393222.0000 - val_mae: 481.1716\n",
            "Epoch 63/1000\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 502540.4375 - mae: 641.3287 - val_loss: 418610.2188 - val_mae: 506.6693\n",
            "Epoch 64/1000\n",
            "37/37 [==============================] - 10s 252ms/step - loss: 496323.8438 - mae: 639.0140 - val_loss: 410157.1562 - val_mae: 498.7904\n",
            "Epoch 65/1000\n",
            "37/37 [==============================] - 5s 137ms/step - loss: 502496.9375 - mae: 641.9427 - val_loss: 385349.0938 - val_mae: 473.2786\n",
            "Epoch 66/1000\n",
            "37/37 [==============================] - 10s 251ms/step - loss: 503944.6875 - mae: 643.5696 - val_loss: 409691.5938 - val_mae: 497.7896\n",
            "Epoch 67/1000\n",
            "37/37 [==============================] - 5s 117ms/step - loss: 500676.0000 - mae: 640.5261 - val_loss: 401718.4688 - val_mae: 490.2368\n",
            "Epoch 68/1000\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 497128.6875 - mae: 638.6412 - val_loss: 401890.0312 - val_mae: 490.3327\n",
            "Epoch 69/1000\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 500305.3750 - mae: 640.8207 - val_loss: 393779.3438 - val_mae: 481.8985\n",
            "Epoch 70/1000\n",
            "37/37 [==============================] - 5s 116ms/step - loss: 501380.5000 - mae: 641.9097 - val_loss: 402392.0000 - val_mae: 490.2133\n",
            "Epoch 71/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 493539.0938 - mae: 637.6162 - val_loss: 393804.0312 - val_mae: 481.9126\n",
            "Epoch 72/1000\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 494030.2812 - mae: 636.9741 - val_loss: 394178.4688 - val_mae: 481.7196\n",
            "Epoch 73/1000\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 496623.5000 - mae: 639.6658 - val_loss: 402381.1250 - val_mae: 490.2070\n",
            "Epoch 74/1000\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 504773.9375 - mae: 643.5043 - val_loss: 410851.5000 - val_mae: 498.4390\n",
            "Epoch 75/1000\n",
            "37/37 [==============================] - 10s 255ms/step - loss: 494823.2500 - mae: 638.0269 - val_loss: 393872.7188 - val_mae: 481.9518\n",
            "Epoch 76/1000\n",
            "37/37 [==============================] - 5s 115ms/step - loss: 498492.3125 - mae: 639.0209 - val_loss: 393748.3750 - val_mae: 481.4837\n",
            "Epoch 77/1000\n",
            "37/37 [==============================] - 6s 138ms/step - loss: 502859.3750 - mae: 641.6887 - val_loss: 418845.6562 - val_mae: 507.2104\n",
            "Epoch 78/1000\n",
            "37/37 [==============================] - 10s 250ms/step - loss: 501481.7812 - mae: 641.4099 - val_loss: 402511.8750 - val_mae: 489.8910\n",
            "Epoch 79/1000\n",
            "37/37 [==============================] - 6s 146ms/step - loss: 492499.0312 - mae: 635.1154 - val_loss: 402018.6250 - val_mae: 490.0094\n",
            "Epoch 80/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 500277.0000 - mae: 639.8899 - val_loss: 410642.5938 - val_mae: 499.0666\n",
            "Epoch 81/1000\n",
            "37/37 [==============================] - 10s 250ms/step - loss: 500010.5000 - mae: 640.5153 - val_loss: 402956.2812 - val_mae: 490.1349\n",
            "Epoch 82/1000\n",
            "37/37 [==============================] - 10s 252ms/step - loss: 505761.9688 - mae: 644.5417 - val_loss: 427566.7188 - val_mae: 515.5883\n",
            "Epoch 83/1000\n",
            "37/37 [==============================] - 10s 252ms/step - loss: 497428.5000 - mae: 639.4293 - val_loss: 411405.2500 - val_mae: 499.4933\n",
            "Epoch 84/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 504087.0938 - mae: 642.4766 - val_loss: 418954.8750 - val_mae: 507.2713\n",
            "Epoch 85/1000\n",
            "37/37 [==============================] - 10s 251ms/step - loss: 500681.6875 - mae: 640.7640 - val_loss: 427643.5000 - val_mae: 515.6320\n",
            "Epoch 86/1000\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 499045.1562 - mae: 638.8922 - val_loss: 410865.7500 - val_mae: 498.8533\n",
            "Epoch 87/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 503224.9062 - mae: 643.2239 - val_loss: 401774.2812 - val_mae: 489.8805\n",
            "Epoch 88/1000\n",
            "37/37 [==============================] - 10s 252ms/step - loss: 501797.8750 - mae: 641.7336 - val_loss: 411047.9062 - val_mae: 498.9569\n",
            "Epoch 89/1000\n",
            "37/37 [==============================] - 5s 137ms/step - loss: 496148.2188 - mae: 637.1745 - val_loss: 411049.9688 - val_mae: 498.5735\n",
            "Epoch 90/1000\n",
            "37/37 [==============================] - 5s 137ms/step - loss: 499144.9062 - mae: 640.7100 - val_loss: 402442.3750 - val_mae: 490.2553\n",
            "Epoch 91/1000\n",
            "37/37 [==============================] - 5s 116ms/step - loss: 504084.4688 - mae: 642.8395 - val_loss: 427914.3750 - val_mae: 515.7856\n",
            "Epoch 92/1000\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 503621.8438 - mae: 642.2815 - val_loss: 394456.4062 - val_mae: 481.9027\n",
            "Epoch 93/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 501770.8438 - mae: 642.1154 - val_loss: 403063.0938 - val_mae: 490.2223\n",
            "Epoch 94/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 499804.8125 - mae: 640.1453 - val_loss: 419352.2188 - val_mae: 506.7318\n",
            "Epoch 95/1000\n",
            "37/37 [==============================] - 10s 251ms/step - loss: 502006.5312 - mae: 642.4806 - val_loss: 402589.2812 - val_mae: 489.9611\n",
            "Epoch 96/1000\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 503149.9688 - mae: 642.0693 - val_loss: 420040.3750 - val_mae: 507.1213\n",
            "Epoch 97/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 502714.7188 - mae: 642.1011 - val_loss: 402607.2500 - val_mae: 490.7353\n",
            "Epoch 98/1000\n",
            "37/37 [==============================] - 10s 253ms/step - loss: 503547.1562 - mae: 642.9210 - val_loss: 419818.8438 - val_mae: 507.7530\n",
            "Epoch 99/1000\n",
            "37/37 [==============================] - 10s 251ms/step - loss: 502376.3125 - mae: 642.0161 - val_loss: 411137.4688 - val_mae: 499.0146\n",
            "Epoch 100/1000\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 490591.4062 - mae: 636.4064 - val_loss: 403564.8438 - val_mae: 491.2660\n",
            "Epoch 101/1000\n",
            "37/37 [==============================] - 5s 118ms/step - loss: 495499.7812 - mae: 638.4722 - val_loss: 411457.7500 - val_mae: 498.4410\n",
            "Epoch 102/1000\n",
            "37/37 [==============================] - 6s 142ms/step - loss: 504298.5625 - mae: 642.7134 - val_loss: 411644.8438 - val_mae: 499.2960\n",
            "Epoch 103/1000\n",
            "37/37 [==============================] - 5s 118ms/step - loss: 498690.9062 - mae: 639.1047 - val_loss: 403662.6562 - val_mae: 491.2888\n",
            "Epoch 104/1000\n",
            "37/37 [==============================] - 6s 138ms/step - loss: 499842.6875 - mae: 640.2125 - val_loss: 412179.6562 - val_mae: 499.2212\n",
            "Epoch 105/1000\n",
            "37/37 [==============================] - 5s 118ms/step - loss: 495185.0312 - mae: 636.7800 - val_loss: 420266.0000 - val_mae: 508.0008\n",
            "Epoch 106/1000\n",
            "37/37 [==============================] - 10s 251ms/step - loss: 503333.1562 - mae: 642.0422 - val_loss: 403013.9062 - val_mae: 490.9258\n",
            "Epoch 107/1000\n",
            "37/37 [==============================] - 10s 250ms/step - loss: 497603.1250 - mae: 639.6583 - val_loss: 420268.3438 - val_mae: 507.6281\n",
            "Epoch 108/1000\n",
            "37/37 [==============================] - 5s 116ms/step - loss: 503082.2812 - mae: 641.9485 - val_loss: 420177.0000 - val_mae: 507.5754\n",
            "Epoch 109/1000\n",
            "37/37 [==============================] - 10s 252ms/step - loss: 503014.7500 - mae: 642.3777 - val_loss: 419764.6562 - val_mae: 506.9784\n",
            "Epoch 110/1000\n",
            "37/37 [==============================] - 5s 116ms/step - loss: 502141.4688 - mae: 641.2151 - val_loss: 403352.0312 - val_mae: 491.1489\n",
            "Epoch 111/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 499048.4688 - mae: 641.1603 - val_loss: 420640.2188 - val_mae: 507.8426\n",
            "Epoch 112/1000\n",
            "37/37 [==============================] - 10s 249ms/step - loss: 494871.4688 - mae: 638.9908 - val_loss: 420643.8438 - val_mae: 507.8447\n",
            "Epoch 113/1000\n",
            "37/37 [==============================] - 10s 251ms/step - loss: 497910.0000 - mae: 639.5807 - val_loss: 395357.3438 - val_mae: 482.4347\n",
            "Epoch 114/1000\n",
            "37/37 [==============================] - 5s 117ms/step - loss: 496188.5938 - mae: 637.8423 - val_loss: 412662.0312 - val_mae: 499.8662\n",
            "Epoch 115/1000\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 503512.5625 - mae: 642.6524 - val_loss: 394745.6562 - val_mae: 482.0919\n",
            "Epoch 116/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 502374.5000 - mae: 641.4093 - val_loss: 386157.2500 - val_mae: 473.7758\n",
            "Epoch 117/1000\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 504916.7188 - mae: 644.8471 - val_loss: 411568.8750 - val_mae: 498.8963\n",
            "Epoch 118/1000\n",
            "37/37 [==============================] - 10s 251ms/step - loss: 490570.3438 - mae: 637.2123 - val_loss: 394805.4688 - val_mae: 482.4904\n",
            "Epoch 119/1000\n",
            "37/37 [==============================] - 9s 246ms/step - loss: 504269.5938 - mae: 643.8594 - val_loss: 412186.2188 - val_mae: 499.6029\n",
            "Epoch 120/1000\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 501237.5625 - mae: 640.5609 - val_loss: 395411.9688 - val_mae: 482.8279\n",
            "Epoch 121/1000\n",
            "37/37 [==============================] - 10s 250ms/step - loss: 498330.3438 - mae: 639.0816 - val_loss: 404336.8438 - val_mae: 490.9632\n",
            "Epoch 122/1000\n",
            "37/37 [==============================] - 5s 115ms/step - loss: 499205.6562 - mae: 639.6483 - val_loss: 403593.5000 - val_mae: 491.2834\n",
            "Epoch 123/1000\n",
            "37/37 [==============================] - 10s 249ms/step - loss: 501673.4062 - mae: 641.7427 - val_loss: 412711.0000 - val_mae: 500.2578\n",
            "Epoch 124/1000\n",
            "37/37 [==============================] - 10s 253ms/step - loss: 501451.7188 - mae: 641.6641 - val_loss: 404283.8750 - val_mae: 492.0063\n",
            "Epoch 125/1000\n",
            "37/37 [==============================] - 10s 250ms/step - loss: 501975.8125 - mae: 643.0690 - val_loss: 412962.0000 - val_mae: 500.3948\n",
            "Epoch 126/1000\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 495414.0938 - mae: 636.8416 - val_loss: 395585.1562 - val_mae: 482.9262\n",
            "Epoch 127/1000\n",
            "37/37 [==============================] - 5s 118ms/step - loss: 498309.5000 - mae: 639.2084 - val_loss: 420483.7812 - val_mae: 508.4630\n",
            "Epoch 128/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 501056.1562 - mae: 640.3240 - val_loss: 403133.0000 - val_mae: 490.6679\n",
            "Epoch 129/1000\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 498404.1875 - mae: 638.8769 - val_loss: 404312.2812 - val_mae: 491.6820\n",
            "Epoch 130/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 504774.4375 - mae: 644.1052 - val_loss: 412549.1562 - val_mae: 499.4553\n",
            "Epoch 131/1000\n",
            "37/37 [==============================] - 7s 167ms/step - loss: 502225.6562 - mae: 642.4741 - val_loss: 404025.0000 - val_mae: 491.5234\n",
            "Epoch 132/1000\n",
            "37/37 [==============================] - 5s 120ms/step - loss: 500452.4062 - mae: 640.5903 - val_loss: 403916.7188 - val_mae: 491.1086\n",
            "Epoch 133/1000\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 505282.0312 - mae: 643.8207 - val_loss: 412203.3750 - val_mae: 499.2692\n",
            "Epoch 134/1000\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 502775.1875 - mae: 642.9987 - val_loss: 404077.1562 - val_mae: 491.2012\n",
            "Epoch 135/1000\n",
            "37/37 [==============================] - 11s 276ms/step - loss: 501806.2500 - mae: 641.4416 - val_loss: 395080.3750 - val_mae: 482.3076\n",
            "Epoch 136/1000\n",
            "37/37 [==============================] - 10s 251ms/step - loss: 501680.2188 - mae: 641.4135 - val_loss: 396207.8750 - val_mae: 482.9357\n",
            "Epoch 137/1000\n",
            "37/37 [==============================] - 10s 250ms/step - loss: 500815.4375 - mae: 641.2449 - val_loss: 413241.0938 - val_mae: 500.2002\n",
            "Epoch 138/1000\n",
            "37/37 [==============================] - 5s 116ms/step - loss: 505764.5625 - mae: 644.9917 - val_loss: 404930.5938 - val_mae: 491.6817\n",
            "Epoch 139/1000\n",
            "37/37 [==============================] - 5s 116ms/step - loss: 500237.4688 - mae: 640.9809 - val_loss: 413628.8438 - val_mae: 500.0718\n",
            "Epoch 140/1000\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 500851.2500 - mae: 641.3428 - val_loss: 413118.1250 - val_mae: 499.7891\n",
            "Epoch 141/1000\n",
            "37/37 [==============================] - 10s 255ms/step - loss: 501038.2812 - mae: 641.1112 - val_loss: 395865.7500 - val_mae: 483.0922\n",
            "Epoch 142/1000\n",
            "37/37 [==============================] - 10s 250ms/step - loss: 504590.5000 - mae: 643.7480 - val_loss: 421514.7500 - val_mae: 508.6954\n",
            "Epoch 143/1000\n",
            "37/37 [==============================] - 5s 118ms/step - loss: 501251.6250 - mae: 641.0510 - val_loss: 395925.9688 - val_mae: 482.7876\n",
            "Epoch 144/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 503657.7188 - mae: 642.8967 - val_loss: 396550.1250 - val_mae: 483.4732\n",
            "Epoch 145/1000\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 499135.5625 - mae: 639.4819 - val_loss: 387876.8438 - val_mae: 474.7589\n",
            "Epoch 146/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 499770.2188 - mae: 640.2448 - val_loss: 404710.8750 - val_mae: 491.9045\n",
            "Epoch 147/1000\n",
            "37/37 [==============================] - 10s 253ms/step - loss: 503941.5000 - mae: 644.1640 - val_loss: 413516.5312 - val_mae: 500.6921\n",
            "Epoch 148/1000\n",
            "37/37 [==============================] - 5s 117ms/step - loss: 504749.4688 - mae: 643.6710 - val_loss: 396988.7812 - val_mae: 483.7150\n",
            "Epoch 149/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 502194.1875 - mae: 642.3171 - val_loss: 422078.7812 - val_mae: 509.0076\n",
            "Epoch 150/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 505308.5938 - mae: 644.5732 - val_loss: 413441.6562 - val_mae: 500.3134\n",
            "Epoch 151/1000\n",
            "37/37 [==============================] - 10s 252ms/step - loss: 501000.1875 - mae: 641.5689 - val_loss: 413397.2500 - val_mae: 499.9526\n",
            "Epoch 152/1000\n",
            "37/37 [==============================] - 5s 117ms/step - loss: 498661.5625 - mae: 639.0533 - val_loss: 404748.8750 - val_mae: 491.5887\n",
            "Epoch 153/1000\n",
            "37/37 [==============================] - 10s 251ms/step - loss: 501076.9375 - mae: 640.8081 - val_loss: 414089.5312 - val_mae: 501.0125\n",
            "Epoch 154/1000\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 499952.8125 - mae: 640.1404 - val_loss: 405318.4688 - val_mae: 491.5727\n",
            "Epoch 155/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 501080.7500 - mae: 640.7344 - val_loss: 413744.6250 - val_mae: 500.8161\n",
            "Epoch 156/1000\n",
            "37/37 [==============================] - 10s 249ms/step - loss: 503488.3438 - mae: 642.3212 - val_loss: 405030.2500 - val_mae: 492.0893\n",
            "Epoch 157/1000\n",
            "37/37 [==============================] - 10s 250ms/step - loss: 499235.5625 - mae: 639.8926 - val_loss: 413589.8438 - val_mae: 500.0654\n",
            "Epoch 158/1000\n",
            "37/37 [==============================] - 10s 255ms/step - loss: 497091.5312 - mae: 639.3378 - val_loss: 405038.3438 - val_mae: 492.0863\n",
            "Epoch 159/1000\n",
            "37/37 [==============================] - 6s 138ms/step - loss: 496939.0625 - mae: 637.8143 - val_loss: 421826.7812 - val_mae: 508.5367\n",
            "Epoch 160/1000\n",
            "37/37 [==============================] - 10s 252ms/step - loss: 502443.8125 - mae: 642.0487 - val_loss: 389258.2188 - val_mae: 475.5317\n",
            "Epoch 161/1000\n",
            "37/37 [==============================] - 10s 250ms/step - loss: 500981.0000 - mae: 641.4073 - val_loss: 406073.7812 - val_mae: 492.0011\n",
            "Epoch 162/1000\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 493118.6250 - mae: 637.2985 - val_loss: 405691.7500 - val_mae: 492.1201\n",
            "Epoch 163/1000\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 501034.2812 - mae: 640.7654 - val_loss: 413777.5312 - val_mae: 500.1753\n",
            "Epoch 164/1000\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 503766.3125 - mae: 643.0148 - val_loss: 413378.0938 - val_mae: 500.6121\n",
            "Epoch 165/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 499725.0312 - mae: 640.6314 - val_loss: 405368.2500 - val_mae: 492.6085\n",
            "Epoch 166/1000\n",
            "37/37 [==============================] - 5s 120ms/step - loss: 505171.0312 - mae: 644.3016 - val_loss: 405846.6250 - val_mae: 492.5335\n",
            "Epoch 167/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 501245.6875 - mae: 642.3532 - val_loss: 406022.4062 - val_mae: 492.9702\n",
            "Epoch 168/1000\n",
            "37/37 [==============================] - 7s 169ms/step - loss: 497914.3438 - mae: 639.6481 - val_loss: 414588.5938 - val_mae: 500.9550\n",
            "Epoch 169/1000\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 493266.8438 - mae: 636.7675 - val_loss: 414143.9688 - val_mae: 501.0331\n",
            "Epoch 170/1000\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 504166.7188 - mae: 643.5873 - val_loss: 422163.3750 - val_mae: 508.7300\n",
            "Epoch 171/1000\n",
            "37/37 [==============================] - 10s 255ms/step - loss: 499851.1562 - mae: 640.5481 - val_loss: 405839.9688 - val_mae: 492.2053\n",
            "Epoch 172/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 501050.7188 - mae: 641.0997 - val_loss: 396742.9688 - val_mae: 483.5888\n",
            "Epoch 173/1000\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 502272.1562 - mae: 641.7449 - val_loss: 422889.5000 - val_mae: 509.4563\n",
            "Epoch 174/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 503128.5312 - mae: 642.3151 - val_loss: 414203.5938 - val_mae: 500.7435\n",
            "Epoch 175/1000\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 500260.0625 - mae: 640.3964 - val_loss: 414225.4688 - val_mae: 500.7558\n",
            "Epoch 176/1000\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 501853.9688 - mae: 641.7319 - val_loss: 414068.5000 - val_mae: 500.6673\n",
            "Epoch 177/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 497576.3438 - mae: 638.2935 - val_loss: 397361.7812 - val_mae: 483.6135\n",
            "Epoch 178/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 503309.0312 - mae: 643.6406 - val_loss: 406682.2188 - val_mae: 492.9956\n",
            "Epoch 179/1000\n",
            "37/37 [==============================] - 6s 135ms/step - loss: 500044.4688 - mae: 640.6084 - val_loss: 405484.9062 - val_mae: 491.6942\n",
            "Epoch 180/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 500229.3750 - mae: 641.0947 - val_loss: 422457.5000 - val_mae: 508.8988\n",
            "Epoch 181/1000\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 492688.8750 - mae: 637.4972 - val_loss: 413862.5938 - val_mae: 500.2415\n",
            "Epoch 182/1000\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 491501.3750 - mae: 637.4084 - val_loss: 423210.0938 - val_mae: 509.6336\n",
            "Epoch 183/1000\n",
            "37/37 [==============================] - 10s 254ms/step - loss: 505274.5000 - mae: 644.6327 - val_loss: 406320.8750 - val_mae: 492.4817\n",
            "Epoch 184/1000\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 503694.8438 - mae: 642.9272 - val_loss: 406531.6562 - val_mae: 492.9126\n",
            "Epoch 185/1000\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 500584.2500 - mae: 641.7061 - val_loss: 407012.1562 - val_mae: 492.8675\n",
            "Epoch 186/1000\n",
            "37/37 [==============================] - 6s 136ms/step - loss: 501476.0000 - mae: 641.7081 - val_loss: 405483.6562 - val_mae: 491.7157\n",
            "Epoch 187/1000\n",
            "37/37 [==============================] - 10s 251ms/step - loss: 499417.3438 - mae: 640.9531 - val_loss: 397966.2188 - val_mae: 484.2733\n",
            "Epoch 188/1000\n",
            "37/37 [==============================] - 5s 117ms/step - loss: 501840.9375 - mae: 642.4237 - val_loss: 406220.0312 - val_mae: 492.7406\n",
            "Epoch 189/1000\n",
            "37/37 [==============================] - 6s 136ms/step - loss: 504301.6875 - mae: 643.3698 - val_loss: 414915.0000 - val_mae: 501.4514\n",
            "Epoch 190/1000\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 503692.5312 - mae: 643.8075 - val_loss: 398598.4688 - val_mae: 484.6239\n",
            "Epoch 191/1000\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 506466.1562 - mae: 645.5153 - val_loss: 398636.5000 - val_mae: 484.3431\n",
            "Epoch 192/1000\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 505800.0938 - mae: 644.9846 - val_loss: 398708.5000 - val_mae: 484.6858\n",
            "Epoch 193/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 496381.5312 - mae: 638.8929 - val_loss: 405869.1250 - val_mae: 492.5470\n",
            "Epoch 194/1000\n",
            "37/37 [==============================] - 10s 253ms/step - loss: 500084.0000 - mae: 641.5126 - val_loss: 399208.5000 - val_mae: 484.6609\n",
            "Epoch 195/1000\n",
            "37/37 [==============================] - 10s 249ms/step - loss: 499322.8438 - mae: 640.8638 - val_loss: 415465.9688 - val_mae: 501.4490\n",
            "Epoch 196/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 492304.8750 - mae: 636.6343 - val_loss: 415045.7188 - val_mae: 501.2179\n",
            "Epoch 197/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 502413.1562 - mae: 642.4778 - val_loss: 406748.3438 - val_mae: 493.0651\n",
            "Epoch 198/1000\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 504212.0625 - mae: 644.9406 - val_loss: 397174.3438 - val_mae: 483.8388\n",
            "Epoch 199/1000\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 501013.3438 - mae: 641.9538 - val_loss: 414957.6562 - val_mae: 500.8649\n",
            "Epoch 200/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 496326.6562 - mae: 638.3062 - val_loss: 415079.3438 - val_mae: 501.2368\n",
            "Epoch 201/1000\n",
            "37/37 [==============================] - 10s 252ms/step - loss: 502786.5312 - mae: 642.2225 - val_loss: 423258.7188 - val_mae: 509.3580\n",
            "Epoch 202/1000\n",
            "37/37 [==============================] - 10s 251ms/step - loss: 497643.3750 - mae: 638.9841 - val_loss: 414579.5000 - val_mae: 500.6603\n",
            "Epoch 203/1000\n",
            "37/37 [==============================] - 10s 251ms/step - loss: 489947.9375 - mae: 636.7982 - val_loss: 423322.3438 - val_mae: 509.3944\n",
            "Epoch 204/1000\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 504360.2500 - mae: 643.8045 - val_loss: 406954.4062 - val_mae: 492.8453\n",
            "Epoch 205/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 503140.5625 - mae: 643.6632 - val_loss: 406340.2500 - val_mae: 492.5039\n",
            "Epoch 206/1000\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 502302.1250 - mae: 641.9609 - val_loss: 398342.8438 - val_mae: 484.4856\n",
            "Epoch 207/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 494291.8438 - mae: 638.7413 - val_loss: 423391.9062 - val_mae: 509.7340\n",
            "Epoch 208/1000\n",
            "37/37 [==============================] - 6s 137ms/step - loss: 498651.4375 - mae: 639.7457 - val_loss: 397814.0938 - val_mae: 484.1935\n",
            "Epoch 209/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 497830.5312 - mae: 640.1012 - val_loss: 398882.9062 - val_mae: 484.7840\n",
            "Epoch 210/1000\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 503115.0938 - mae: 642.6477 - val_loss: 407107.4062 - val_mae: 492.9330\n",
            "Epoch 211/1000\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 502251.7812 - mae: 643.4589 - val_loss: 415223.6250 - val_mae: 501.0200\n",
            "Epoch 212/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 501621.9375 - mae: 642.0394 - val_loss: 407102.6562 - val_mae: 492.9303\n",
            "Epoch 213/1000\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 498075.7812 - mae: 640.2459 - val_loss: 415193.9688 - val_mae: 501.0028\n",
            "Epoch 214/1000\n",
            "37/37 [==============================] - 5s 118ms/step - loss: 496824.4062 - mae: 641.2451 - val_loss: 423843.3438 - val_mae: 509.6822\n",
            "Epoch 215/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 499708.6875 - mae: 639.8499 - val_loss: 432017.4062 - val_mae: 517.5040\n",
            "Epoch 216/1000\n",
            "37/37 [==============================] - 5s 120ms/step - loss: 500131.8438 - mae: 640.4786 - val_loss: 415676.5938 - val_mae: 501.2683\n",
            "Epoch 217/1000\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 503973.6562 - mae: 643.8385 - val_loss: 405988.7500 - val_mae: 492.6131\n",
            "Epoch 218/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 502693.4375 - mae: 643.6752 - val_loss: 406544.6562 - val_mae: 492.9200\n",
            "Epoch 219/1000\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 494783.8438 - mae: 640.1041 - val_loss: 414595.2500 - val_mae: 500.6695\n",
            "Epoch 220/1000\n",
            "37/37 [==============================] - 6s 133ms/step - loss: 493556.4688 - mae: 639.0314 - val_loss: 397266.9062 - val_mae: 483.8910\n",
            "Epoch 221/1000\n",
            "37/37 [==============================] - 10s 252ms/step - loss: 500312.5625 - mae: 641.3484 - val_loss: 406379.1562 - val_mae: 492.2268\n",
            "Epoch 222/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 497262.5000 - mae: 639.0157 - val_loss: 415223.2812 - val_mae: 501.0198\n",
            "Epoch 223/1000\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 499356.0312 - mae: 640.3258 - val_loss: 399379.7188 - val_mae: 485.0581\n",
            "Epoch 224/1000\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 502743.0312 - mae: 642.0991 - val_loss: 415419.8438 - val_mae: 501.4283\n",
            "Epoch 225/1000\n",
            "37/37 [==============================] - 10s 253ms/step - loss: 501988.1250 - mae: 641.9009 - val_loss: 423627.7188 - val_mae: 509.8641\n",
            "Epoch 226/1000\n",
            "37/37 [==============================] - 10s 249ms/step - loss: 502149.6562 - mae: 641.8819 - val_loss: 406741.5000 - val_mae: 492.7341\n",
            "Epoch 227/1000\n",
            "37/37 [==============================] - 10s 251ms/step - loss: 501744.6562 - mae: 642.2275 - val_loss: 415711.5000 - val_mae: 501.2887\n",
            "Epoch 228/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 503700.8438 - mae: 644.2994 - val_loss: 406047.0000 - val_mae: 492.0511\n",
            "Epoch 229/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 495511.1875 - mae: 639.3480 - val_loss: 406677.9062 - val_mae: 492.9936\n",
            "Epoch 230/1000\n",
            "37/37 [==============================] - 10s 253ms/step - loss: 501810.9062 - mae: 641.7076 - val_loss: 398541.9062 - val_mae: 484.5977\n",
            "Epoch 231/1000\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 500327.8750 - mae: 641.6829 - val_loss: 407276.3438 - val_mae: 493.0298\n",
            "Epoch 232/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 493665.2188 - mae: 638.2226 - val_loss: 416000.2812 - val_mae: 501.4569\n",
            "Epoch 233/1000\n",
            "37/37 [==============================] - 10s 254ms/step - loss: 503064.5312 - mae: 643.2590 - val_loss: 399266.4688 - val_mae: 484.9998\n",
            "Epoch 234/1000\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 499380.2812 - mae: 640.6092 - val_loss: 415690.4688 - val_mae: 501.5803\n",
            "Epoch 235/1000\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 495200.5000 - mae: 638.0148 - val_loss: 424031.3438 - val_mae: 510.7158\n",
            "Epoch 236/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 503600.5938 - mae: 642.9965 - val_loss: 407880.3750 - val_mae: 493.0757\n",
            "Epoch 237/1000\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 505109.1562 - mae: 644.9714 - val_loss: 408015.7188 - val_mae: 493.4425\n",
            "Epoch 238/1000\n",
            "37/37 [==============================] - 6s 139ms/step - loss: 502376.1875 - mae: 642.0685 - val_loss: 407547.1562 - val_mae: 493.1848\n",
            "Epoch 239/1000\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 499344.1562 - mae: 640.1828 - val_loss: 415696.2188 - val_mae: 501.5836\n",
            "Epoch 240/1000\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 500614.4375 - mae: 640.9620 - val_loss: 423882.3750 - val_mae: 509.1428\n",
            "Epoch 241/1000\n",
            "37/37 [==============================] - 6s 142ms/step - loss: 500477.6875 - mae: 641.1172 - val_loss: 399460.4062 - val_mae: 484.8244\n",
            "Epoch 242/1000\n",
            "37/37 [==============================] - 10s 254ms/step - loss: 502228.5625 - mae: 642.8093 - val_loss: 407020.6562 - val_mae: 492.6082\n",
            "Epoch 243/1000\n",
            "37/37 [==============================] - 10s 253ms/step - loss: 495453.4062 - mae: 637.4600 - val_loss: 415983.9688 - val_mae: 501.7451\n",
            "Epoch 244/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 498106.1250 - mae: 639.4244 - val_loss: 407669.1250 - val_mae: 493.2547\n",
            "Epoch 245/1000\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 504274.0938 - mae: 643.9487 - val_loss: 415324.1562 - val_mae: 501.0945\n",
            "Epoch 246/1000\n",
            "37/37 [==============================] - 5s 120ms/step - loss: 500212.1875 - mae: 640.4441 - val_loss: 416444.5312 - val_mae: 501.9987\n",
            "Epoch 247/1000\n",
            "37/37 [==============================] - 10s 253ms/step - loss: 499154.4688 - mae: 640.4310 - val_loss: 424113.7500 - val_mae: 510.4198\n",
            "Epoch 248/1000\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 502326.8125 - mae: 642.9609 - val_loss: 415467.9062 - val_mae: 501.4605\n",
            "Epoch 249/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 494767.3438 - mae: 638.7298 - val_loss: 400003.2812 - val_mae: 485.4086\n",
            "Epoch 250/1000\n",
            "37/37 [==============================] - 10s 254ms/step - loss: 500122.8125 - mae: 641.3392 - val_loss: 389244.0000 - val_mae: 475.5714\n",
            "Epoch 251/1000\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 501229.3750 - mae: 641.0292 - val_loss: 407266.9062 - val_mae: 493.0352\n",
            "Epoch 252/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 501068.9062 - mae: 641.6690 - val_loss: 416066.3438 - val_mae: 502.0746\n",
            "Epoch 253/1000\n",
            "37/37 [==============================] - 10s 252ms/step - loss: 489964.6562 - mae: 637.6528 - val_loss: 406795.6562 - val_mae: 492.7761\n",
            "Epoch 254/1000\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 499781.9375 - mae: 640.5343 - val_loss: 416191.4688 - val_mae: 502.1421\n",
            "Epoch 255/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 499144.4062 - mae: 639.3397 - val_loss: 415521.4062 - val_mae: 501.2094\n",
            "Epoch 256/1000\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 501840.0625 - mae: 643.4846 - val_loss: 399105.2500 - val_mae: 484.9146\n",
            "Epoch 257/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 503203.8438 - mae: 643.1041 - val_loss: 407946.2812 - val_mae: 493.4132\n",
            "Epoch 258/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 500741.6562 - mae: 641.3297 - val_loss: 407402.9062 - val_mae: 493.1129\n",
            "Epoch 259/1000\n",
            "37/37 [==============================] - 10s 254ms/step - loss: 497866.0625 - mae: 640.2104 - val_loss: 407820.7500 - val_mae: 493.0615\n",
            "Epoch 260/1000\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 494759.1875 - mae: 638.4507 - val_loss: 415955.7812 - val_mae: 501.4466\n",
            "Epoch 261/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 502107.3750 - mae: 642.2437 - val_loss: 432966.1562 - val_mae: 518.3526\n",
            "Epoch 262/1000\n",
            "37/37 [==============================] - 10s 255ms/step - loss: 500191.5000 - mae: 641.2698 - val_loss: 398504.0000 - val_mae: 484.5821\n",
            "Epoch 263/1000\n",
            "37/37 [==============================] - 5s 120ms/step - loss: 499792.0625 - mae: 640.8494 - val_loss: 424831.0312 - val_mae: 510.5276\n",
            "Epoch 264/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 504490.4062 - mae: 644.3439 - val_loss: 407817.9688 - val_mae: 493.0599\n",
            "Epoch 265/1000\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 501498.6250 - mae: 641.8668 - val_loss: 407831.9062 - val_mae: 493.3479\n",
            "Epoch 266/1000\n",
            "37/37 [==============================] - 6s 146ms/step - loss: 497589.9375 - mae: 639.9796 - val_loss: 416105.2500 - val_mae: 501.5335\n",
            "Epoch 267/1000\n",
            "37/37 [==============================] - 10s 253ms/step - loss: 497789.7500 - mae: 639.9802 - val_loss: 407770.1562 - val_mae: 493.0315\n",
            "Epoch 268/1000\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 499480.0938 - mae: 640.6832 - val_loss: 424724.3750 - val_mae: 510.5233\n",
            "Epoch 269/1000\n",
            "37/37 [==============================] - 6s 137ms/step - loss: 503241.9375 - mae: 642.6507 - val_loss: 408186.1562 - val_mae: 493.5400\n",
            "Epoch 270/1000\n",
            "37/37 [==============================] - 6s 136ms/step - loss: 503326.4688 - mae: 642.9568 - val_loss: 399504.5000 - val_mae: 484.8502\n",
            "Epoch 271/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 502338.2500 - mae: 641.8863 - val_loss: 407866.5000 - val_mae: 493.3676\n",
            "Epoch 272/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 497643.0000 - mae: 640.4409 - val_loss: 406664.8438 - val_mae: 492.7012\n",
            "Epoch 273/1000\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 500463.0000 - mae: 641.7849 - val_loss: 415942.9062 - val_mae: 501.7221\n",
            "Epoch 274/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 495717.3438 - mae: 640.5129 - val_loss: 416482.4062 - val_mae: 502.0199\n",
            "Epoch 275/1000\n",
            "37/37 [==============================] - 10s 252ms/step - loss: 499158.5000 - mae: 641.8310 - val_loss: 415920.7500 - val_mae: 502.0479\n",
            "Epoch 276/1000\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 501777.8750 - mae: 641.9088 - val_loss: 424553.4062 - val_mae: 509.5226\n",
            "Epoch 277/1000\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 498633.2812 - mae: 639.3859 - val_loss: 407235.5938 - val_mae: 493.0172\n",
            "Epoch 278/1000\n",
            "37/37 [==============================] - 6s 134ms/step - loss: 501590.7188 - mae: 642.1433 - val_loss: 415998.8438 - val_mae: 501.7535\n",
            "Epoch 279/1000\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 498581.0625 - mae: 640.8690 - val_loss: 415974.3750 - val_mae: 501.7398\n",
            "Epoch 280/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 499384.1250 - mae: 641.3922 - val_loss: 432990.4062 - val_mae: 518.6475\n",
            "Epoch 281/1000\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 502883.9688 - mae: 642.8992 - val_loss: 407685.3750 - val_mae: 492.9812\n",
            "Epoch 282/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 500327.5312 - mae: 641.2212 - val_loss: 406778.6562 - val_mae: 492.4861\n",
            "Epoch 283/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 495385.7188 - mae: 640.7792 - val_loss: 433120.0938 - val_mae: 519.3398\n",
            "Epoch 284/1000\n",
            "37/37 [==============================] - 10s 255ms/step - loss: 501484.7500 - mae: 641.7644 - val_loss: 407325.0938 - val_mae: 492.7889\n",
            "Epoch 285/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 501714.9688 - mae: 641.8078 - val_loss: 407437.8750 - val_mae: 493.4127\n",
            "Epoch 286/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 503529.3438 - mae: 643.5009 - val_loss: 407397.8438 - val_mae: 493.3907\n",
            "Epoch 287/1000\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 496877.2500 - mae: 638.3417 - val_loss: 424450.1562 - val_mae: 510.3767\n",
            "Epoch 288/1000\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 498836.2812 - mae: 639.9993 - val_loss: 416521.5938 - val_mae: 501.4811\n",
            "Epoch 289/1000\n",
            "37/37 [==============================] - 10s 254ms/step - loss: 502164.8438 - mae: 642.2441 - val_loss: 416115.7188 - val_mae: 501.8192\n",
            "Epoch 290/1000\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 501042.7500 - mae: 640.9482 - val_loss: 398473.5938 - val_mae: 484.2813\n",
            "Epoch 291/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 501152.5000 - mae: 641.1389 - val_loss: 415983.9062 - val_mae: 501.7451\n",
            "Epoch 292/1000\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 496311.6875 - mae: 638.2612 - val_loss: 407806.3438 - val_mae: 493.3332\n",
            "Epoch 293/1000\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 499222.3750 - mae: 640.6276 - val_loss: 424757.0312 - val_mae: 510.2043\n",
            "Epoch 294/1000\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 501670.9688 - mae: 641.5144 - val_loss: 416618.0312 - val_mae: 501.8163\n",
            "Epoch 295/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 500592.1562 - mae: 640.9745 - val_loss: 416277.2500 - val_mae: 502.1885\n",
            "Epoch 296/1000\n",
            "37/37 [==============================] - 6s 138ms/step - loss: 498864.2812 - mae: 639.9976 - val_loss: 424780.4062 - val_mae: 510.2177\n",
            "Epoch 297/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 501492.6875 - mae: 643.1631 - val_loss: 407583.7188 - val_mae: 493.4932\n",
            "Epoch 298/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 496921.9375 - mae: 640.2648 - val_loss: 424901.1562 - val_mae: 509.7350\n",
            "Epoch 299/1000\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 501498.4062 - mae: 641.7587 - val_loss: 408709.1562 - val_mae: 494.1134\n",
            "Epoch 300/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 501485.1875 - mae: 641.8386 - val_loss: 416404.5000 - val_mae: 501.9811\n",
            "Epoch 301/1000\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 499674.7812 - mae: 641.8213 - val_loss: 391185.6562 - val_mae: 476.6512\n",
            "Epoch 302/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 506106.9375 - mae: 645.7036 - val_loss: 415806.2188 - val_mae: 501.6505\n",
            "Epoch 303/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 495114.6562 - mae: 640.1359 - val_loss: 424912.3750 - val_mae: 510.0161\n",
            "Epoch 304/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 496797.5938 - mae: 638.1292 - val_loss: 416814.7812 - val_mae: 502.2063\n",
            "Epoch 305/1000\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 500001.0312 - mae: 643.7069 - val_loss: 407436.5000 - val_mae: 493.1322\n",
            "Epoch 306/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 505287.1562 - mae: 644.6556 - val_loss: 407543.5938 - val_mae: 493.1935\n",
            "Epoch 307/1000\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 504604.0312 - mae: 643.9422 - val_loss: 425082.9062 - val_mae: 510.6661\n",
            "Epoch 308/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 503422.6875 - mae: 642.9552 - val_loss: 416700.1250 - val_mae: 501.8641\n",
            "Epoch 309/1000\n",
            "37/37 [==============================] - 10s 253ms/step - loss: 497414.5000 - mae: 639.2354 - val_loss: 408102.7500 - val_mae: 493.7793\n",
            "Epoch 310/1000\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 499119.5625 - mae: 640.1261 - val_loss: 416208.3438 - val_mae: 501.5935\n",
            "Epoch 311/1000\n",
            "37/37 [==============================] - 10s 255ms/step - loss: 502371.0938 - mae: 642.5707 - val_loss: 425054.6250 - val_mae: 510.7117\n",
            "Epoch 312/1000\n",
            "37/37 [==============================] - 10s 253ms/step - loss: 502940.1562 - mae: 643.2955 - val_loss: 408002.5000 - val_mae: 493.1693\n",
            "Epoch 313/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 495944.5312 - mae: 638.2968 - val_loss: 407638.9062 - val_mae: 493.5236\n",
            "Epoch 314/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 500583.9062 - mae: 641.0093 - val_loss: 416421.3750 - val_mae: 501.9906\n",
            "Epoch 315/1000\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 497406.6875 - mae: 639.0867 - val_loss: 416720.5000 - val_mae: 501.6008\n",
            "Epoch 316/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 501657.6250 - mae: 641.5302 - val_loss: 415921.9062 - val_mae: 501.9908\n",
            "Epoch 317/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 502517.0000 - mae: 642.0020 - val_loss: 416817.2188 - val_mae: 501.9321\n",
            "Epoch 318/1000\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 499461.5000 - mae: 640.4260 - val_loss: 399896.1562 - val_mae: 485.0785\n",
            "Epoch 319/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 500142.7812 - mae: 640.8954 - val_loss: 398589.5000 - val_mae: 484.6358\n",
            "Epoch 320/1000\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 501880.0312 - mae: 642.2377 - val_loss: 425035.6562 - val_mae: 510.0890\n",
            "Epoch 321/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 500846.6875 - mae: 641.6656 - val_loss: 399414.4062 - val_mae: 485.0883\n",
            "Epoch 322/1000\n",
            "37/37 [==============================] - 10s 254ms/step - loss: 502052.6875 - mae: 642.5735 - val_loss: 399557.8438 - val_mae: 485.1689\n",
            "Epoch 323/1000\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 497910.4375 - mae: 639.7264 - val_loss: 416311.4688 - val_mae: 501.6535\n",
            "Epoch 324/1000\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 499564.8125 - mae: 640.4418 - val_loss: 416003.0000 - val_mae: 502.0347\n",
            "Epoch 325/1000\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 503037.6875 - mae: 643.3920 - val_loss: 416039.3438 - val_mae: 501.7813\n",
            "Epoch 326/1000\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 501182.3438 - mae: 641.7833 - val_loss: 407824.7500 - val_mae: 493.6916\n",
            "Epoch 327/1000\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 500543.0000 - mae: 641.2003 - val_loss: 416479.9062 - val_mae: 501.7515\n",
            "Epoch 328/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 502979.0938 - mae: 643.4018 - val_loss: 416404.9062 - val_mae: 501.7079\n",
            "Epoch 329/1000\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 502247.0312 - mae: 642.7138 - val_loss: 399494.4062 - val_mae: 484.8606\n",
            "Epoch 330/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 502338.6250 - mae: 642.6708 - val_loss: 416071.9688 - val_mae: 501.7996\n",
            "Epoch 331/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 504534.5938 - mae: 644.5034 - val_loss: 416420.9062 - val_mae: 501.9904\n",
            "Epoch 332/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 499362.6250 - mae: 640.3726 - val_loss: 416382.5938 - val_mae: 501.4233\n",
            "Epoch 333/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 497113.0625 - mae: 639.5532 - val_loss: 407304.8438 - val_mae: 493.0676\n",
            "Epoch 334/1000\n",
            "37/37 [==============================] - 10s 254ms/step - loss: 501049.6875 - mae: 642.3479 - val_loss: 408829.7188 - val_mae: 493.9077\n",
            "Epoch 335/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 500879.1250 - mae: 641.5275 - val_loss: 399425.9688 - val_mae: 484.8207\n",
            "Epoch 336/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 498152.8438 - mae: 639.8973 - val_loss: 408192.5938 - val_mae: 493.5541\n",
            "Epoch 337/1000\n",
            "37/37 [==============================] - 6s 137ms/step - loss: 498830.3438 - mae: 640.1734 - val_loss: 408232.1562 - val_mae: 493.8506\n",
            "Epoch 338/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 499713.7500 - mae: 640.3087 - val_loss: 408195.5000 - val_mae: 493.2837\n",
            "Epoch 339/1000\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 499064.0938 - mae: 640.4698 - val_loss: 400036.1250 - val_mae: 485.4321\n",
            "Epoch 340/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 501534.3438 - mae: 641.4187 - val_loss: 424774.0000 - val_mae: 510.4957\n",
            "Epoch 341/1000\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 502510.7812 - mae: 642.7297 - val_loss: 416492.4688 - val_mae: 502.0304\n",
            "Epoch 342/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 499949.2500 - mae: 640.6528 - val_loss: 416389.0312 - val_mae: 501.6986\n",
            "Epoch 343/1000\n",
            "37/37 [==============================] - 10s 255ms/step - loss: 502097.8125 - mae: 642.6118 - val_loss: 400091.1562 - val_mae: 485.1922\n",
            "Epoch 344/1000\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 506485.5938 - mae: 646.0297 - val_loss: 416452.5000 - val_mae: 501.7355\n",
            "Epoch 345/1000\n",
            "37/37 [==============================] - 6s 140ms/step - loss: 497248.2188 - mae: 639.3799 - val_loss: 416687.8750 - val_mae: 502.4102\n",
            "Epoch 346/1000\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 500918.2812 - mae: 641.2968 - val_loss: 416775.1562 - val_mae: 502.4572\n",
            "Epoch 347/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 501353.9062 - mae: 641.5323 - val_loss: 399210.7188 - val_mae: 484.7116\n",
            "Epoch 348/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 503512.4688 - mae: 643.8926 - val_loss: 399868.5312 - val_mae: 485.3433\n",
            "Epoch 349/1000\n",
            "37/37 [==============================] - 10s 255ms/step - loss: 500576.5000 - mae: 641.7896 - val_loss: 416328.1250 - val_mae: 501.9432\n",
            "Epoch 350/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 503681.2500 - mae: 643.4322 - val_loss: 425035.3438 - val_mae: 510.6394\n",
            "Epoch 351/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 497193.7188 - mae: 638.6212 - val_loss: 407967.4688 - val_mae: 493.4358\n",
            "Epoch 352/1000\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 493046.2812 - mae: 639.5364 - val_loss: 408526.5000 - val_mae: 493.7448\n",
            "Epoch 353/1000\n",
            "37/37 [==============================] - 11s 268ms/step - loss: 502993.5312 - mae: 643.1039 - val_loss: 399664.4688 - val_mae: 485.2287\n",
            "Epoch 354/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 501515.6562 - mae: 641.2319 - val_loss: 407939.4062 - val_mae: 493.4198\n",
            "Epoch 355/1000\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 502055.3750 - mae: 642.8890 - val_loss: 407942.7812 - val_mae: 493.1551\n",
            "Epoch 356/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 501215.7188 - mae: 641.6116 - val_loss: 409086.5312 - val_mae: 494.0543\n",
            "Epoch 357/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 492557.2500 - mae: 637.6900 - val_loss: 416726.9062 - val_mae: 502.1618\n",
            "Epoch 358/1000\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 501620.5000 - mae: 642.3583 - val_loss: 417101.2500 - val_mae: 502.0972\n",
            "Epoch 359/1000\n",
            "37/37 [==============================] - 11s 268ms/step - loss: 494093.6875 - mae: 637.6270 - val_loss: 407968.8438 - val_mae: 493.7052\n",
            "Epoch 360/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 501363.3125 - mae: 641.2879 - val_loss: 425151.2188 - val_mae: 510.7031\n",
            "Epoch 361/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 501657.5625 - mae: 642.6800 - val_loss: 400904.5312 - val_mae: 485.6497\n",
            "Epoch 362/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 503273.9375 - mae: 643.6671 - val_loss: 416336.0000 - val_mae: 501.6832\n",
            "Epoch 363/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 497778.8125 - mae: 639.4219 - val_loss: 416852.0938 - val_mae: 501.9677\n",
            "Epoch 364/1000\n",
            "37/37 [==============================] - 6s 145ms/step - loss: 498972.9688 - mae: 641.1342 - val_loss: 407347.1562 - val_mae: 492.8234\n",
            "Epoch 365/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 496293.6562 - mae: 638.3658 - val_loss: 409036.1562 - val_mae: 494.0255\n",
            "Epoch 366/1000\n",
            "37/37 [==============================] - 10s 254ms/step - loss: 501313.8125 - mae: 641.7107 - val_loss: 407997.3438 - val_mae: 493.1875\n",
            "Epoch 367/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 500629.2812 - mae: 641.2590 - val_loss: 433848.0000 - val_mae: 519.4654\n",
            "Epoch 368/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 496710.4375 - mae: 639.5916 - val_loss: 424878.4688 - val_mae: 510.0164\n",
            "Epoch 369/1000\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 502492.2188 - mae: 642.2094 - val_loss: 391494.7188 - val_mae: 476.8282\n",
            "Epoch 370/1000\n",
            "37/37 [==============================] - 6s 134ms/step - loss: 491834.0625 - mae: 637.1498 - val_loss: 416842.5938 - val_mae: 502.2267\n",
            "Epoch 371/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 491695.4375 - mae: 637.9097 - val_loss: 416762.1562 - val_mae: 502.4502\n",
            "Epoch 372/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 503089.0938 - mae: 642.5069 - val_loss: 400393.2188 - val_mae: 485.6324\n",
            "Epoch 373/1000\n",
            "37/37 [==============================] - 6s 146ms/step - loss: 502107.9375 - mae: 642.3920 - val_loss: 399402.4062 - val_mae: 485.0869\n",
            "Epoch 374/1000\n",
            "37/37 [==============================] - 10s 252ms/step - loss: 503255.1562 - mae: 643.1580 - val_loss: 408070.7500 - val_mae: 494.0995\n",
            "Epoch 375/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 499644.0938 - mae: 641.4404 - val_loss: 424975.2188 - val_mae: 510.3387\n",
            "Epoch 376/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 505525.1250 - mae: 644.6882 - val_loss: 416707.5938 - val_mae: 501.8838\n",
            "Epoch 377/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 503809.0000 - mae: 643.3494 - val_loss: 416637.6562 - val_mae: 501.8431\n",
            "Epoch 378/1000\n",
            "37/37 [==============================] - 10s 254ms/step - loss: 505592.2500 - mae: 645.0409 - val_loss: 425469.8750 - val_mae: 510.6817\n",
            "Epoch 379/1000\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 504787.3438 - mae: 644.5588 - val_loss: 408432.6250 - val_mae: 493.4242\n",
            "Epoch 380/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 498584.5312 - mae: 640.7838 - val_loss: 408428.9688 - val_mae: 493.4220\n",
            "Epoch 381/1000\n",
            "37/37 [==============================] - 10s 255ms/step - loss: 503325.2500 - mae: 643.4441 - val_loss: 416181.2500 - val_mae: 501.8609\n",
            "Epoch 382/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 503756.5938 - mae: 643.4278 - val_loss: 399672.1562 - val_mae: 484.9642\n",
            "Epoch 383/1000\n",
            "37/37 [==============================] - 10s 254ms/step - loss: 502906.4062 - mae: 643.9827 - val_loss: 398763.2500 - val_mae: 484.4671\n",
            "Epoch 384/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 493099.1562 - mae: 638.3840 - val_loss: 425422.0312 - val_mae: 510.5836\n",
            "Epoch 385/1000\n",
            "37/37 [==============================] - 7s 172ms/step - loss: 499569.3125 - mae: 640.8743 - val_loss: 417226.1562 - val_mae: 502.4368\n",
            "Epoch 386/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 502778.2188 - mae: 642.4012 - val_loss: 408375.6250 - val_mae: 493.3904\n",
            "Epoch 387/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 502409.0312 - mae: 643.0413 - val_loss: 407522.5938 - val_mae: 493.1921\n",
            "Epoch 388/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 501413.7812 - mae: 642.8474 - val_loss: 399832.0938 - val_mae: 485.3228\n",
            "Epoch 389/1000\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 502796.8750 - mae: 643.0843 - val_loss: 425568.0312 - val_mae: 510.6668\n",
            "Epoch 390/1000\n",
            "37/37 [==============================] - 10s 273ms/step - loss: 496908.9688 - mae: 638.9440 - val_loss: 416230.7500 - val_mae: 501.6221\n",
            "Epoch 391/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 505629.8125 - mae: 645.8301 - val_loss: 416770.1562 - val_mae: 502.1860\n",
            "Epoch 392/1000\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 497467.3750 - mae: 639.6503 - val_loss: 424801.2188 - val_mae: 509.9707\n",
            "Epoch 393/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 498861.0938 - mae: 642.3638 - val_loss: 408463.0000 - val_mae: 493.7086\n",
            "Epoch 394/1000\n",
            "37/37 [==============================] - 6s 145ms/step - loss: 502653.2500 - mae: 644.0110 - val_loss: 425446.1562 - val_mae: 510.8659\n",
            "Epoch 395/1000\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 501606.0625 - mae: 642.1873 - val_loss: 424971.0000 - val_mae: 511.2135\n",
            "Epoch 396/1000\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 503307.4375 - mae: 643.3427 - val_loss: 408512.1562 - val_mae: 493.7367\n",
            "Epoch 397/1000\n",
            "37/37 [==============================] - 11s 266ms/step - loss: 503442.0312 - mae: 643.2133 - val_loss: 416244.2500 - val_mae: 501.8961\n",
            "Epoch 398/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 500869.2188 - mae: 642.4158 - val_loss: 416225.5312 - val_mae: 501.8857\n",
            "Epoch 399/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 499189.2812 - mae: 640.5812 - val_loss: 433700.0938 - val_mae: 518.5137\n",
            "Epoch 400/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 503573.0000 - mae: 643.3161 - val_loss: 416351.8438 - val_mae: 502.2230\n",
            "Epoch 401/1000\n",
            "37/37 [==============================] - 6s 136ms/step - loss: 503019.0000 - mae: 642.9551 - val_loss: 399939.9688 - val_mae: 485.1202\n",
            "Epoch 402/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 503864.6875 - mae: 644.1382 - val_loss: 399781.0000 - val_mae: 485.2941\n",
            "Epoch 403/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 496895.5625 - mae: 639.5098 - val_loss: 416744.1250 - val_mae: 502.1715\n",
            "Epoch 404/1000\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 503268.2812 - mae: 643.7864 - val_loss: 391549.1562 - val_mae: 476.8593\n",
            "Epoch 405/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 498923.7188 - mae: 640.5054 - val_loss: 424972.9062 - val_mae: 510.3374\n",
            "Epoch 406/1000\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 500055.3125 - mae: 641.9833 - val_loss: 408959.3750 - val_mae: 493.9818\n",
            "Epoch 407/1000\n",
            "37/37 [==============================] - 6s 145ms/step - loss: 500680.0938 - mae: 641.2383 - val_loss: 424983.0938 - val_mae: 510.6107\n",
            "Epoch 408/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 492750.5625 - mae: 637.6644 - val_loss: 399115.5938 - val_mae: 484.9259\n",
            "Epoch 409/1000\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 491720.4688 - mae: 637.0780 - val_loss: 416029.6562 - val_mae: 501.5052\n",
            "Epoch 410/1000\n",
            "37/37 [==============================] - 10s 254ms/step - loss: 499406.2812 - mae: 640.3851 - val_loss: 400114.2812 - val_mae: 485.4760\n",
            "Epoch 411/1000\n",
            "37/37 [==============================] - 6s 138ms/step - loss: 501258.2188 - mae: 641.6277 - val_loss: 407767.5938 - val_mae: 493.3216\n",
            "Epoch 412/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 492719.8438 - mae: 638.4037 - val_loss: 416307.1250 - val_mae: 501.6510\n",
            "Epoch 413/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 497527.0938 - mae: 639.6523 - val_loss: 408122.4688 - val_mae: 493.5140\n",
            "Epoch 414/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 505220.7188 - mae: 644.7057 - val_loss: 416294.2500 - val_mae: 501.3701\n",
            "Epoch 415/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 501913.9062 - mae: 642.7400 - val_loss: 424920.0938 - val_mae: 510.0207\n",
            "Epoch 416/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 495921.9688 - mae: 638.3400 - val_loss: 417102.4062 - val_mae: 502.9786\n",
            "Epoch 417/1000\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 489166.1250 - mae: 636.5350 - val_loss: 399293.0000 - val_mae: 484.7431\n",
            "Epoch 418/1000\n",
            "37/37 [==============================] - 10s 273ms/step - loss: 500642.5312 - mae: 641.7777 - val_loss: 424972.2500 - val_mae: 510.3272\n",
            "Epoch 419/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 501292.2188 - mae: 642.1972 - val_loss: 424868.0938 - val_mae: 510.2677\n",
            "Epoch 420/1000\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 493682.1562 - mae: 638.0278 - val_loss: 416867.2188 - val_mae: 502.5128\n",
            "Epoch 421/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 501789.4062 - mae: 642.8140 - val_loss: 407536.3438 - val_mae: 492.9142\n",
            "Epoch 422/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 499212.4375 - mae: 641.7943 - val_loss: 416769.1562 - val_mae: 501.6301\n",
            "Epoch 423/1000\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 495475.9688 - mae: 639.2471 - val_loss: 407051.5312 - val_mae: 492.9227\n",
            "Epoch 424/1000\n",
            "37/37 [==============================] - 7s 175ms/step - loss: 494352.9375 - mae: 637.0607 - val_loss: 415707.2188 - val_mae: 501.5950\n",
            "Epoch 425/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 501833.2812 - mae: 641.7421 - val_loss: 407343.7812 - val_mae: 492.8000\n",
            "Epoch 426/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 501456.2812 - mae: 641.8508 - val_loss: 424878.3438 - val_mae: 509.9960\n",
            "Epoch 427/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 501006.0312 - mae: 641.7708 - val_loss: 416181.6562 - val_mae: 501.8561\n",
            "Epoch 428/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 500008.3125 - mae: 640.2653 - val_loss: 416229.7188 - val_mae: 502.1628\n",
            "Epoch 429/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 504972.5938 - mae: 644.4523 - val_loss: 407325.7500 - val_mae: 492.7892\n",
            "Epoch 430/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 499024.8125 - mae: 640.5410 - val_loss: 415935.3438 - val_mae: 501.1540\n",
            "Epoch 431/1000\n",
            "37/37 [==============================] - 11s 277ms/step - loss: 502282.9375 - mae: 642.6724 - val_loss: 416172.9062 - val_mae: 501.8512\n",
            "Epoch 432/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 500172.6875 - mae: 641.1393 - val_loss: 424306.4688 - val_mae: 510.2947\n",
            "Epoch 433/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 495773.4062 - mae: 639.8524 - val_loss: 407331.1250 - val_mae: 493.0719\n",
            "Epoch 434/1000\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 503013.2188 - mae: 643.3555 - val_loss: 416587.4688 - val_mae: 501.5208\n",
            "Epoch 435/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 499556.4062 - mae: 641.5273 - val_loss: 399144.5312 - val_mae: 484.6565\n",
            "Epoch 436/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 503632.3750 - mae: 643.9785 - val_loss: 415653.1250 - val_mae: 501.2860\n",
            "Epoch 437/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 501166.4688 - mae: 642.5178 - val_loss: 400162.4062 - val_mae: 485.2176\n",
            "Epoch 438/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 495561.5625 - mae: 637.4047 - val_loss: 424096.8438 - val_mae: 509.2739\n",
            "Epoch 439/1000\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 501685.2188 - mae: 642.4338 - val_loss: 416583.8438 - val_mae: 502.0768\n",
            "Epoch 440/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 500223.6250 - mae: 640.9196 - val_loss: 407353.5938 - val_mae: 492.8058\n",
            "Epoch 441/1000\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 498739.8438 - mae: 640.1357 - val_loss: 416552.3438 - val_mae: 501.7782\n",
            "Epoch 442/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 503490.9688 - mae: 643.0072 - val_loss: 407768.8750 - val_mae: 493.3118\n",
            "Epoch 443/1000\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 498712.5312 - mae: 640.4706 - val_loss: 424671.5000 - val_mae: 510.1555\n",
            "Epoch 444/1000\n",
            "37/37 [==============================] - 11s 270ms/step - loss: 498813.3125 - mae: 642.9550 - val_loss: 416051.2500 - val_mae: 501.7830\n",
            "Epoch 445/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 501863.7188 - mae: 642.5569 - val_loss: 406716.3750 - val_mae: 492.7307\n",
            "Epoch 446/1000\n",
            "37/37 [==============================] - 6s 137ms/step - loss: 493334.8125 - mae: 638.7017 - val_loss: 407577.0312 - val_mae: 493.2019\n",
            "Epoch 447/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 501008.8750 - mae: 642.1620 - val_loss: 397871.8438 - val_mae: 483.9464\n",
            "Epoch 448/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 501037.1875 - mae: 641.5573 - val_loss: 416176.9062 - val_mae: 501.2736\n",
            "Epoch 449/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 497410.3125 - mae: 638.7589 - val_loss: 415776.0938 - val_mae: 501.6284\n",
            "Epoch 450/1000\n",
            "37/37 [==============================] - 6s 136ms/step - loss: 501115.0000 - mae: 641.3949 - val_loss: 398483.4062 - val_mae: 484.5705\n",
            "Epoch 451/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 501738.6562 - mae: 642.0228 - val_loss: 415235.2812 - val_mae: 501.0428\n",
            "Epoch 452/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 499934.7812 - mae: 640.6230 - val_loss: 415966.9688 - val_mae: 501.7357\n",
            "Epoch 453/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 493042.8438 - mae: 637.1517 - val_loss: 415917.4688 - val_mae: 501.7079\n",
            "Epoch 454/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 493389.7500 - mae: 638.1837 - val_loss: 398408.9688 - val_mae: 484.2435\n",
            "Epoch 455/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 503432.4062 - mae: 642.5465 - val_loss: 415348.5938 - val_mae: 501.3935\n",
            "Epoch 456/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 498959.5625 - mae: 639.9460 - val_loss: 423919.7188 - val_mae: 509.4496\n",
            "Epoch 457/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 505598.1250 - mae: 645.3228 - val_loss: 415850.8438 - val_mae: 501.6705\n",
            "Epoch 458/1000\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 493859.9688 - mae: 637.9222 - val_loss: 415796.9062 - val_mae: 501.3541\n",
            "Epoch 459/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 500867.1875 - mae: 641.1468 - val_loss: 415859.7812 - val_mae: 501.3907\n",
            "Epoch 460/1000\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 496009.8438 - mae: 639.9480 - val_loss: 399943.9062 - val_mae: 485.0902\n",
            "Epoch 461/1000\n",
            "37/37 [==============================] - 11s 273ms/step - loss: 498247.9062 - mae: 638.6833 - val_loss: 407569.9062 - val_mae: 492.9127\n",
            "Epoch 462/1000\n",
            "37/37 [==============================] - 6s 147ms/step - loss: 496882.2500 - mae: 638.4846 - val_loss: 399043.2812 - val_mae: 484.8798\n",
            "Epoch 463/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 500400.5938 - mae: 640.6809 - val_loss: 424613.1562 - val_mae: 511.0352\n",
            "Epoch 464/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 498846.4062 - mae: 639.8184 - val_loss: 407575.9688 - val_mae: 493.2014\n",
            "Epoch 465/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 499370.8438 - mae: 640.0516 - val_loss: 407156.1562 - val_mae: 493.2574\n",
            "Epoch 466/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 502278.9688 - mae: 643.3059 - val_loss: 398888.5312 - val_mae: 484.5071\n",
            "Epoch 467/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 502763.8125 - mae: 642.3384 - val_loss: 398863.9688 - val_mae: 484.4927\n",
            "Epoch 468/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 496012.0000 - mae: 637.7889 - val_loss: 415690.4688 - val_mae: 501.2921\n",
            "Epoch 469/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 505959.1562 - mae: 645.1158 - val_loss: 406987.5312 - val_mae: 492.5885\n",
            "Epoch 470/1000\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 503011.9688 - mae: 643.3350 - val_loss: 398917.5938 - val_mae: 484.8091\n",
            "Epoch 471/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 498487.7812 - mae: 640.0023 - val_loss: 416213.1250 - val_mae: 501.5807\n",
            "Epoch 472/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 502713.2500 - mae: 642.4711 - val_loss: 398926.8438 - val_mae: 484.5294\n",
            "Epoch 473/1000\n",
            "37/37 [==============================] - 6s 139ms/step - loss: 500517.7188 - mae: 640.5692 - val_loss: 407703.3438 - val_mae: 493.5592\n",
            "Epoch 474/1000\n",
            "37/37 [==============================] - 10s 255ms/step - loss: 497897.9375 - mae: 640.6462 - val_loss: 407563.3438 - val_mae: 492.9088\n",
            "Epoch 475/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 498239.5625 - mae: 640.1775 - val_loss: 407123.8438 - val_mae: 492.9532\n",
            "Epoch 476/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 501912.9688 - mae: 641.6235 - val_loss: 407622.2500 - val_mae: 493.2278\n",
            "Epoch 477/1000\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 500390.5312 - mae: 640.7615 - val_loss: 415708.0312 - val_mae: 501.3023\n",
            "Epoch 478/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 499513.3438 - mae: 641.0348 - val_loss: 408255.2500 - val_mae: 493.8636\n",
            "Epoch 479/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 498286.2500 - mae: 639.6647 - val_loss: 415996.2500 - val_mae: 501.4701\n",
            "Epoch 480/1000\n",
            "37/37 [==============================] - 6s 147ms/step - loss: 504871.4375 - mae: 644.3292 - val_loss: 407829.5938 - val_mae: 493.3465\n",
            "Epoch 481/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 500725.7188 - mae: 641.5859 - val_loss: 416026.6250 - val_mae: 501.4878\n",
            "Epoch 482/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 498451.5625 - mae: 640.1775 - val_loss: 407619.5938 - val_mae: 492.9422\n",
            "Epoch 483/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 489475.8438 - mae: 635.7804 - val_loss: 407625.8438 - val_mae: 492.9460\n",
            "Epoch 484/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 497178.7812 - mae: 640.2716 - val_loss: 391293.2812 - val_mae: 476.7018\n",
            "Epoch 485/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 502182.6562 - mae: 642.0745 - val_loss: 407690.0312 - val_mae: 493.2666\n",
            "Epoch 486/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 501365.2188 - mae: 641.9433 - val_loss: 424685.2500 - val_mae: 510.4473\n",
            "Epoch 487/1000\n",
            "37/37 [==============================] - 11s 272ms/step - loss: 505863.4375 - mae: 645.7195 - val_loss: 399309.7188 - val_mae: 484.7365\n",
            "Epoch 488/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 503042.0312 - mae: 643.2526 - val_loss: 399515.2812 - val_mae: 484.8565\n",
            "Epoch 489/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 501327.7812 - mae: 641.5145 - val_loss: 415891.8438 - val_mae: 501.4093\n",
            "Epoch 490/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 501958.7188 - mae: 641.5229 - val_loss: 416340.2500 - val_mae: 501.3720\n",
            "Epoch 491/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 501407.9375 - mae: 642.2460 - val_loss: 407826.9688 - val_mae: 493.0653\n",
            "Epoch 492/1000\n",
            "37/37 [==============================] - 6s 145ms/step - loss: 501598.2812 - mae: 642.8408 - val_loss: 415499.7500 - val_mae: 501.4784\n",
            "Epoch 493/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 499144.5625 - mae: 640.3967 - val_loss: 407316.2188 - val_mae: 493.3457\n",
            "Epoch 494/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 502121.2500 - mae: 642.5842 - val_loss: 415595.7188 - val_mae: 501.5323\n",
            "Epoch 495/1000\n",
            "37/37 [==============================] - 6s 137ms/step - loss: 501401.5625 - mae: 641.7971 - val_loss: 415876.7188 - val_mae: 501.4005\n",
            "Epoch 496/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 496951.4375 - mae: 640.2104 - val_loss: 415953.9688 - val_mae: 501.4455\n",
            "Epoch 497/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 500750.1875 - mae: 640.6044 - val_loss: 416120.1250 - val_mae: 502.1036\n",
            "Epoch 498/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 498133.8438 - mae: 639.5973 - val_loss: 408260.5000 - val_mae: 493.8665\n",
            "Epoch 499/1000\n",
            "37/37 [==============================] - 11s 272ms/step - loss: 500271.4062 - mae: 641.1207 - val_loss: 415966.6250 - val_mae: 501.7355\n",
            "Epoch 500/1000\n",
            "37/37 [==============================] - 10s 273ms/step - loss: 500445.8125 - mae: 642.0351 - val_loss: 424140.2188 - val_mae: 509.5800\n",
            "Epoch 501/1000\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 504147.6250 - mae: 643.4828 - val_loss: 415538.9688 - val_mae: 501.2196\n",
            "Epoch 502/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 500149.1562 - mae: 640.4103 - val_loss: 407808.5312 - val_mae: 493.0543\n",
            "Epoch 503/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 493939.1875 - mae: 639.7979 - val_loss: 424211.5312 - val_mae: 509.6222\n",
            "Epoch 504/1000\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 504966.6562 - mae: 644.5916 - val_loss: 416164.4688 - val_mae: 501.8464\n",
            "Epoch 505/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 499672.6875 - mae: 639.8996 - val_loss: 398773.0938 - val_mae: 484.4563\n",
            "Epoch 506/1000\n",
            "37/37 [==============================] - 10s 273ms/step - loss: 505501.7500 - mae: 645.0365 - val_loss: 424384.0000 - val_mae: 509.7242\n",
            "Epoch 507/1000\n",
            "37/37 [==============================] - 6s 144ms/step - loss: 504194.5938 - mae: 644.0511 - val_loss: 416815.1562 - val_mae: 502.2065\n",
            "Epoch 508/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 502101.1250 - mae: 642.5988 - val_loss: 406903.2812 - val_mae: 492.8378\n",
            "Epoch 509/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 502186.0000 - mae: 642.7658 - val_loss: 416253.3750 - val_mae: 501.6197\n",
            "Epoch 510/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 499104.0625 - mae: 639.8860 - val_loss: 399310.6250 - val_mae: 484.7534\n",
            "Epoch 511/1000\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 497276.6562 - mae: 639.1776 - val_loss: 416635.7500 - val_mae: 501.8266\n",
            "Epoch 512/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 504371.1875 - mae: 643.9394 - val_loss: 416081.3438 - val_mae: 501.5197\n",
            "Epoch 513/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 495562.1562 - mae: 639.8896 - val_loss: 415653.4062 - val_mae: 501.5647\n",
            "Epoch 514/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 500432.5938 - mae: 641.1182 - val_loss: 406946.8750 - val_mae: 493.4806\n",
            "Epoch 515/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 495763.6250 - mae: 639.1917 - val_loss: 416048.5312 - val_mae: 501.5005\n",
            "Epoch 516/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 502268.2500 - mae: 642.1657 - val_loss: 390899.8438 - val_mae: 476.4874\n",
            "Epoch 517/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 496944.2812 - mae: 639.2737 - val_loss: 399656.4062 - val_mae: 484.9388\n",
            "Epoch 518/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 501299.2500 - mae: 642.0654 - val_loss: 433009.3750 - val_mae: 518.3776\n",
            "Epoch 519/1000\n",
            "37/37 [==============================] - 6s 139ms/step - loss: 495138.8438 - mae: 639.9238 - val_loss: 390934.0000 - val_mae: 476.5069\n",
            "Epoch 520/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 497540.6250 - mae: 638.5872 - val_loss: 407469.8750 - val_mae: 493.4304\n",
            "Epoch 521/1000\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 500727.7500 - mae: 641.7578 - val_loss: 433142.2188 - val_mae: 518.7325\n",
            "Epoch 522/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 498296.9062 - mae: 639.6971 - val_loss: 407920.1562 - val_mae: 493.3983\n",
            "Epoch 523/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 496554.5000 - mae: 637.9689 - val_loss: 390976.2500 - val_mae: 476.5312\n",
            "Epoch 524/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 498608.5000 - mae: 639.8598 - val_loss: 424398.2500 - val_mae: 510.0095\n",
            "Epoch 525/1000\n",
            "37/37 [==============================] - 11s 274ms/step - loss: 501905.7500 - mae: 642.5549 - val_loss: 416235.6250 - val_mae: 502.1660\n",
            "Epoch 526/1000\n",
            "37/37 [==============================] - 11s 274ms/step - loss: 494992.9375 - mae: 637.7073 - val_loss: 389962.5000 - val_mae: 475.9724\n",
            "Epoch 527/1000\n",
            "37/37 [==============================] - 11s 284ms/step - loss: 495837.3750 - mae: 638.1499 - val_loss: 416073.5000 - val_mae: 501.7955\n",
            "Epoch 528/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 506448.6562 - mae: 646.3215 - val_loss: 398705.6250 - val_mae: 484.6955\n",
            "Epoch 529/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 500504.8125 - mae: 640.9078 - val_loss: 407374.7812 - val_mae: 493.0969\n",
            "Epoch 530/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 501651.1250 - mae: 641.8395 - val_loss: 416084.0938 - val_mae: 501.8014\n",
            "Epoch 531/1000\n",
            "37/37 [==============================] - 10s 272ms/step - loss: 500658.5312 - mae: 641.4185 - val_loss: 415643.6562 - val_mae: 501.5592\n",
            "Epoch 532/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 501449.9062 - mae: 641.9854 - val_loss: 416223.8438 - val_mae: 501.6025\n",
            "Epoch 533/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 501765.5625 - mae: 641.4844 - val_loss: 407446.8438 - val_mae: 492.8611\n",
            "Epoch 534/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 498724.6875 - mae: 640.4508 - val_loss: 407396.3750 - val_mae: 493.1093\n",
            "Epoch 535/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 494898.8438 - mae: 639.6702 - val_loss: 399311.0312 - val_mae: 485.0303\n",
            "Epoch 536/1000\n",
            "37/37 [==============================] - 11s 272ms/step - loss: 505317.1250 - mae: 645.1086 - val_loss: 407306.7188 - val_mae: 493.0579\n",
            "Epoch 537/1000\n",
            "37/37 [==============================] - 6s 142ms/step - loss: 500476.5938 - mae: 640.5867 - val_loss: 416198.5312 - val_mae: 502.1459\n",
            "Epoch 538/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 498660.1250 - mae: 638.9780 - val_loss: 416936.8750 - val_mae: 502.8893\n",
            "Epoch 539/1000\n",
            "37/37 [==============================] - 11s 273ms/step - loss: 495573.5625 - mae: 639.0516 - val_loss: 407485.3438 - val_mae: 492.8839\n",
            "Epoch 540/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 499237.9375 - mae: 641.8605 - val_loss: 399929.1562 - val_mae: 485.3721\n",
            "Epoch 541/1000\n",
            "37/37 [==============================] - 6s 135ms/step - loss: 499038.1250 - mae: 640.0682 - val_loss: 391136.8750 - val_mae: 476.6232\n",
            "Epoch 542/1000\n",
            "37/37 [==============================] - 11s 274ms/step - loss: 501075.4688 - mae: 641.2916 - val_loss: 416922.7812 - val_mae: 502.5428\n",
            "Epoch 543/1000\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 500939.9375 - mae: 641.6743 - val_loss: 425106.5312 - val_mae: 511.0176\n",
            "Epoch 544/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 501989.5000 - mae: 643.0531 - val_loss: 416312.2812 - val_mae: 501.6540\n",
            "Epoch 545/1000\n",
            "37/37 [==============================] - 11s 273ms/step - loss: 501489.4688 - mae: 642.5869 - val_loss: 416289.5312 - val_mae: 501.6408\n",
            "Epoch 546/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 506233.8438 - mae: 646.0145 - val_loss: 424909.3750 - val_mae: 510.0144\n",
            "Epoch 547/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 501641.7188 - mae: 642.4434 - val_loss: 407265.6562 - val_mae: 493.3178\n",
            "Epoch 548/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 498934.2188 - mae: 639.9386 - val_loss: 416889.1562 - val_mae: 502.2480\n",
            "Epoch 549/1000\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 505094.5938 - mae: 644.9332 - val_loss: 399376.0000 - val_mae: 485.0667\n",
            "Epoch 550/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 502119.0312 - mae: 642.9828 - val_loss: 408259.2812 - val_mae: 493.8654\n",
            "Epoch 551/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 498462.5000 - mae: 640.0923 - val_loss: 425040.3750 - val_mae: 510.3661\n",
            "Epoch 552/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 494488.6875 - mae: 637.5873 - val_loss: 400540.0000 - val_mae: 485.7097\n",
            "Epoch 553/1000\n",
            "37/37 [==============================] - 6s 142ms/step - loss: 498458.4375 - mae: 639.8802 - val_loss: 400026.0000 - val_mae: 485.4264\n",
            "Epoch 554/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 492985.5625 - mae: 638.4866 - val_loss: 391365.0000 - val_mae: 476.7539\n",
            "Epoch 555/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 501441.2500 - mae: 641.7046 - val_loss: 391782.7812 - val_mae: 476.9821\n",
            "Epoch 556/1000\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 499321.7812 - mae: 640.9362 - val_loss: 399025.3750 - val_mae: 484.6035\n",
            "Epoch 557/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 491714.6250 - mae: 637.7476 - val_loss: 407865.6562 - val_mae: 493.3777\n",
            "Epoch 558/1000\n",
            "37/37 [==============================] - 11s 272ms/step - loss: 498831.8750 - mae: 640.1291 - val_loss: 424652.5312 - val_mae: 509.6135\n",
            "Epoch 559/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 502152.7500 - mae: 642.3644 - val_loss: 425301.4688 - val_mae: 510.5150\n",
            "Epoch 560/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 503143.2500 - mae: 643.6003 - val_loss: 399519.0000 - val_mae: 484.8750\n",
            "Epoch 561/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 504476.4375 - mae: 644.4119 - val_loss: 416622.2500 - val_mae: 501.8341\n",
            "Epoch 562/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 500361.8438 - mae: 640.8687 - val_loss: 417096.6250 - val_mae: 502.0944\n",
            "Epoch 563/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 501041.9375 - mae: 640.7569 - val_loss: 407645.2500 - val_mae: 492.9788\n",
            "Epoch 564/1000\n",
            "37/37 [==============================] - 10s 274ms/step - loss: 502400.7812 - mae: 642.6267 - val_loss: 407927.6562 - val_mae: 494.0208\n",
            "Epoch 565/1000\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 499327.6250 - mae: 640.8525 - val_loss: 416572.2500 - val_mae: 501.8051\n",
            "Epoch 566/1000\n",
            "37/37 [==============================] - 11s 282ms/step - loss: 502969.9062 - mae: 642.5272 - val_loss: 416607.2500 - val_mae: 501.8254\n",
            "Epoch 567/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 496361.1250 - mae: 640.5943 - val_loss: 399017.8438 - val_mae: 484.5991\n",
            "Epoch 568/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 496198.8125 - mae: 638.5858 - val_loss: 399542.5938 - val_mae: 484.8887\n",
            "Epoch 569/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 503166.4688 - mae: 643.4119 - val_loss: 425317.9688 - val_mae: 510.7954\n",
            "Epoch 570/1000\n",
            "37/37 [==============================] - 6s 140ms/step - loss: 502259.0312 - mae: 642.0849 - val_loss: 407826.7188 - val_mae: 493.3554\n",
            "Epoch 571/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 500964.9062 - mae: 641.1620 - val_loss: 416478.7188 - val_mae: 502.0227\n",
            "Epoch 572/1000\n",
            "37/37 [==============================] - 10s 272ms/step - loss: 499435.2812 - mae: 640.1843 - val_loss: 424611.8750 - val_mae: 510.1315\n",
            "Epoch 573/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 498820.6250 - mae: 640.5595 - val_loss: 425120.2500 - val_mae: 510.1389\n",
            "Epoch 574/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 502698.0000 - mae: 642.5547 - val_loss: 415752.6250 - val_mae: 501.3440\n",
            "Epoch 575/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 501493.3750 - mae: 642.2336 - val_loss: 406994.2188 - val_mae: 492.8899\n",
            "Epoch 576/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 501056.2188 - mae: 641.2439 - val_loss: 406974.0938 - val_mae: 492.8783\n",
            "Epoch 577/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 502010.5625 - mae: 641.9320 - val_loss: 407502.8438 - val_mae: 493.4486\n",
            "Epoch 578/1000\n",
            "37/37 [==============================] - 10s 274ms/step - loss: 503794.2500 - mae: 643.2654 - val_loss: 424460.4688 - val_mae: 510.3232\n",
            "Epoch 579/1000\n",
            "37/37 [==============================] - 6s 142ms/step - loss: 497155.4062 - mae: 638.9200 - val_loss: 407992.0938 - val_mae: 493.1632\n",
            "Epoch 580/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 498604.6875 - mae: 640.3913 - val_loss: 416028.7812 - val_mae: 501.4890\n",
            "Epoch 581/1000\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 502971.5938 - mae: 642.5945 - val_loss: 389957.0938 - val_mae: 475.9693\n",
            "Epoch 582/1000\n",
            "37/37 [==============================] - 11s 274ms/step - loss: 496410.7812 - mae: 640.5341 - val_loss: 399125.7188 - val_mae: 484.6455\n",
            "Epoch 583/1000\n",
            "37/37 [==============================] - 11s 273ms/step - loss: 492093.3125 - mae: 637.8433 - val_loss: 416129.0000 - val_mae: 501.8266\n",
            "Epoch 584/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 501841.2188 - mae: 642.7388 - val_loss: 416845.5938 - val_mae: 502.5011\n",
            "Epoch 585/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 501085.4688 - mae: 641.3499 - val_loss: 390438.5938 - val_mae: 476.2341\n",
            "Epoch 586/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 487738.2188 - mae: 634.2883 - val_loss: 407952.8750 - val_mae: 493.4170\n",
            "Epoch 587/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 501235.6250 - mae: 641.4981 - val_loss: 407733.4062 - val_mae: 493.0097\n",
            "Epoch 588/1000\n",
            "37/37 [==============================] - 11s 282ms/step - loss: 502131.4062 - mae: 642.1851 - val_loss: 407856.7500 - val_mae: 493.6438\n",
            "Epoch 589/1000\n",
            "37/37 [==============================] - 6s 140ms/step - loss: 489158.9688 - mae: 636.2545 - val_loss: 416708.7500 - val_mae: 502.4272\n",
            "Epoch 590/1000\n",
            "37/37 [==============================] - 6s 142ms/step - loss: 498853.6562 - mae: 640.7825 - val_loss: 416188.9062 - val_mae: 501.9192\n",
            "Epoch 591/1000\n",
            "37/37 [==============================] - 6s 143ms/step - loss: 499686.0000 - mae: 640.8671 - val_loss: 416098.1250 - val_mae: 501.8092\n",
            "Epoch 592/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 501683.3438 - mae: 641.9286 - val_loss: 416030.7500 - val_mae: 501.7715\n",
            "Epoch 593/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 503399.5312 - mae: 643.7701 - val_loss: 416030.4062 - val_mae: 501.7713\n",
            "Epoch 594/1000\n",
            "37/37 [==============================] - 11s 272ms/step - loss: 499721.5625 - mae: 642.9138 - val_loss: 407265.2188 - val_mae: 493.0342\n",
            "Epoch 595/1000\n",
            "37/37 [==============================] - 10s 273ms/step - loss: 504235.0625 - mae: 644.4256 - val_loss: 407789.0000 - val_mae: 493.6064\n",
            "Epoch 596/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 505050.3438 - mae: 644.5911 - val_loss: 398585.1250 - val_mae: 484.6277\n",
            "Epoch 597/1000\n",
            "37/37 [==============================] - 6s 139ms/step - loss: 498589.9688 - mae: 640.3438 - val_loss: 416545.8438 - val_mae: 502.0555\n",
            "Epoch 598/1000\n",
            "37/37 [==============================] - 10s 272ms/step - loss: 498759.9688 - mae: 639.4208 - val_loss: 415539.9062 - val_mae: 501.2201\n",
            "Epoch 599/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 495365.8438 - mae: 638.2253 - val_loss: 406828.5938 - val_mae: 492.7950\n",
            "Epoch 600/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 492312.0938 - mae: 636.9999 - val_loss: 416187.5000 - val_mae: 502.1400\n",
            "Epoch 601/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 501330.0938 - mae: 642.7002 - val_loss: 398609.5312 - val_mae: 484.6414\n",
            "Epoch 602/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 500580.9062 - mae: 641.3776 - val_loss: 416141.3750 - val_mae: 501.8336\n",
            "Epoch 603/1000\n",
            "37/37 [==============================] - 11s 274ms/step - loss: 502697.5625 - mae: 642.9803 - val_loss: 406895.1562 - val_mae: 492.5553\n",
            "Epoch 604/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 502860.0938 - mae: 642.5422 - val_loss: 415513.8750 - val_mae: 501.2050\n",
            "Epoch 605/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 495570.6250 - mae: 639.9704 - val_loss: 415527.5000 - val_mae: 501.2130\n",
            "Epoch 606/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 505716.9375 - mae: 645.6436 - val_loss: 399049.5938 - val_mae: 484.6011\n",
            "Epoch 607/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 500668.2188 - mae: 640.8957 - val_loss: 415579.2812 - val_mae: 501.5231\n",
            "Epoch 608/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 502113.8125 - mae: 643.0098 - val_loss: 424781.9062 - val_mae: 510.7849\n",
            "Epoch 609/1000\n",
            "37/37 [==============================] - 11s 276ms/step - loss: 497101.6250 - mae: 638.1558 - val_loss: 424147.2500 - val_mae: 509.5842\n",
            "Epoch 610/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 500486.8125 - mae: 641.1588 - val_loss: 424810.2500 - val_mae: 510.2347\n",
            "Epoch 611/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 502272.1562 - mae: 642.3351 - val_loss: 416091.8438 - val_mae: 501.5257\n",
            "Epoch 612/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 499791.5625 - mae: 640.5692 - val_loss: 407339.7500 - val_mae: 492.7976\n",
            "Epoch 613/1000\n",
            "37/37 [==============================] - 6s 132ms/step - loss: 501918.5625 - mae: 642.6900 - val_loss: 399333.1562 - val_mae: 484.7665\n",
            "Epoch 614/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 500398.2500 - mae: 640.7256 - val_loss: 416241.9688 - val_mae: 502.1693\n",
            "Epoch 615/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 497546.2188 - mae: 642.2444 - val_loss: 407972.1562 - val_mae: 493.7074\n",
            "Epoch 616/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 497999.1250 - mae: 639.0847 - val_loss: 407814.1562 - val_mae: 493.0576\n",
            "Epoch 617/1000\n",
            "37/37 [==============================] - 11s 271ms/step - loss: 498801.0000 - mae: 640.6729 - val_loss: 407395.1562 - val_mae: 492.8305\n",
            "Epoch 618/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 500525.5312 - mae: 641.2921 - val_loss: 407713.5000 - val_mae: 493.5646\n",
            "Epoch 619/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 499847.0938 - mae: 641.4393 - val_loss: 399186.7812 - val_mae: 484.6812\n",
            "Epoch 620/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 500710.2188 - mae: 641.3127 - val_loss: 416179.5938 - val_mae: 501.5768\n",
            "Epoch 621/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 495815.3125 - mae: 638.8585 - val_loss: 399280.7188 - val_mae: 484.7360\n",
            "Epoch 622/1000\n",
            "37/37 [==============================] - 11s 277ms/step - loss: 492852.8438 - mae: 639.7056 - val_loss: 399370.3750 - val_mae: 485.0636\n",
            "Epoch 623/1000\n",
            "37/37 [==============================] - 10s 275ms/step - loss: 497532.4688 - mae: 639.5473 - val_loss: 407450.1562 - val_mae: 493.1400\n",
            "Epoch 624/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 500287.1875 - mae: 641.0094 - val_loss: 408451.4688 - val_mae: 493.4143\n",
            "Epoch 625/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 500288.0000 - mae: 640.2954 - val_loss: 416191.8750 - val_mae: 501.8619\n",
            "Epoch 626/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 504814.2500 - mae: 644.1605 - val_loss: 424377.7500 - val_mae: 509.9978\n",
            "Epoch 627/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 499462.7500 - mae: 640.4848 - val_loss: 416299.9062 - val_mae: 501.9225\n",
            "Epoch 628/1000\n",
            "37/37 [==============================] - 10s 273ms/step - loss: 504872.9062 - mae: 644.2038 - val_loss: 416078.0938 - val_mae: 501.5177\n",
            "Epoch 629/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 496653.2500 - mae: 638.6014 - val_loss: 399646.6562 - val_mae: 485.2135\n",
            "Epoch 630/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 497919.2812 - mae: 639.1938 - val_loss: 415467.7812 - val_mae: 501.1782\n",
            "Epoch 631/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 500504.9062 - mae: 640.9154 - val_loss: 406678.2188 - val_mae: 492.4264\n",
            "Epoch 632/1000\n",
            "37/37 [==============================] - 6s 140ms/step - loss: 503787.0938 - mae: 643.2775 - val_loss: 399268.7500 - val_mae: 485.0065\n",
            "Epoch 633/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 501297.3750 - mae: 642.4810 - val_loss: 416621.4062 - val_mae: 502.3800\n",
            "Epoch 634/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 502280.4375 - mae: 642.8803 - val_loss: 408299.2812 - val_mae: 493.6047\n",
            "Epoch 635/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 503431.6562 - mae: 643.0597 - val_loss: 433123.4062 - val_mae: 519.0025\n",
            "Epoch 636/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 502919.3750 - mae: 643.8181 - val_loss: 390945.4062 - val_mae: 476.5135\n",
            "Epoch 637/1000\n",
            "37/37 [==============================] - 6s 141ms/step - loss: 501768.0938 - mae: 642.9476 - val_loss: 399697.7812 - val_mae: 484.9629\n",
            "Epoch 638/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 502393.6250 - mae: 643.3842 - val_loss: 407313.2812 - val_mae: 492.7819\n",
            "Epoch 639/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 501975.3750 - mae: 642.5399 - val_loss: 398712.5000 - val_mae: 484.6993\n",
            "Epoch 640/1000\n",
            "37/37 [==============================] - 6s 139ms/step - loss: 500975.3125 - mae: 642.4812 - val_loss: 406962.5938 - val_mae: 492.8717\n",
            "Epoch 641/1000\n",
            "37/37 [==============================] - 11s 279ms/step - loss: 500514.9062 - mae: 641.9194 - val_loss: 424798.0938 - val_mae: 509.9486\n",
            "Epoch 642/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 501711.6562 - mae: 641.9828 - val_loss: 389948.9062 - val_mae: 475.9646\n",
            "Epoch 643/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 497381.0625 - mae: 638.7304 - val_loss: 407931.1562 - val_mae: 493.4045\n",
            "Epoch 644/1000\n",
            "37/37 [==============================] - 10s 272ms/step - loss: 503425.2500 - mae: 643.5393 - val_loss: 416628.0938 - val_mae: 501.8222\n",
            "Epoch 645/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 495348.3438 - mae: 639.5347 - val_loss: 398736.7500 - val_mae: 484.7130\n",
            "Epoch 646/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 500738.6250 - mae: 641.2236 - val_loss: 406959.5000 - val_mae: 492.5935\n",
            "Epoch 647/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 504080.7812 - mae: 643.2293 - val_loss: 408681.0938 - val_mae: 494.1603\n",
            "Epoch 648/1000\n",
            "37/37 [==============================] - 11s 274ms/step - loss: 501496.4688 - mae: 641.7385 - val_loss: 415908.0000 - val_mae: 501.7076\n",
            "Epoch 649/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 501312.8125 - mae: 641.9023 - val_loss: 416360.3750 - val_mae: 501.6820\n",
            "Epoch 650/1000\n",
            "37/37 [==============================] - 10s 273ms/step - loss: 498710.7188 - mae: 640.9612 - val_loss: 407610.9062 - val_mae: 493.2320\n",
            "Epoch 651/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 502637.1562 - mae: 642.9736 - val_loss: 399414.0000 - val_mae: 485.0880\n",
            "Epoch 652/1000\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 492167.8750 - mae: 637.0714 - val_loss: 424757.2500 - val_mae: 510.5518\n",
            "Epoch 653/1000\n",
            "37/37 [==============================] - 11s 271ms/step - loss: 500577.2500 - mae: 640.7440 - val_loss: 424468.5938 - val_mae: 509.7742\n",
            "Epoch 654/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 502334.8438 - mae: 642.7047 - val_loss: 408683.2500 - val_mae: 494.0992\n",
            "Epoch 655/1000\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 498669.2500 - mae: 639.8117 - val_loss: 424617.7812 - val_mae: 510.4097\n",
            "Epoch 656/1000\n",
            "37/37 [==============================] - 11s 272ms/step - loss: 507442.6250 - mae: 646.8521 - val_loss: 407592.7500 - val_mae: 493.2216\n",
            "Epoch 657/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 494053.5000 - mae: 637.8047 - val_loss: 407709.8750 - val_mae: 493.5626\n",
            "Epoch 658/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 499619.4062 - mae: 641.1909 - val_loss: 416745.8750 - val_mae: 501.6161\n",
            "Epoch 659/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 504575.0000 - mae: 644.2042 - val_loss: 407258.2500 - val_mae: 493.0409\n",
            "Epoch 660/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 502531.0938 - mae: 642.3882 - val_loss: 416903.0000 - val_mae: 502.2558\n",
            "Epoch 661/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 502051.9062 - mae: 642.2057 - val_loss: 408745.6562 - val_mae: 493.5885\n",
            "Epoch 662/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 502585.7188 - mae: 642.5615 - val_loss: 399506.2812 - val_mae: 485.1399\n",
            "Epoch 663/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 500176.2812 - mae: 640.3447 - val_loss: 415913.2500 - val_mae: 501.7106\n",
            "Epoch 664/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 498700.9688 - mae: 639.5020 - val_loss: 424579.0938 - val_mae: 509.8395\n",
            "Epoch 665/1000\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 500497.7188 - mae: 640.7296 - val_loss: 408299.0312 - val_mae: 493.8873\n",
            "Epoch 666/1000\n",
            "37/37 [==============================] - 11s 271ms/step - loss: 498559.8438 - mae: 642.1971 - val_loss: 390324.2188 - val_mae: 476.1799\n",
            "Epoch 667/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 502640.2188 - mae: 643.0220 - val_loss: 398950.3438 - val_mae: 484.5597\n",
            "Epoch 668/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 497398.3750 - mae: 638.8115 - val_loss: 399065.0000 - val_mae: 484.8975\n",
            "Epoch 669/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 500864.5000 - mae: 641.5980 - val_loss: 425216.9062 - val_mae: 510.7398\n",
            "Epoch 670/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 505372.0000 - mae: 645.4423 - val_loss: 416833.2500 - val_mae: 501.9414\n",
            "Epoch 671/1000\n",
            "37/37 [==============================] - 11s 277ms/step - loss: 500442.6562 - mae: 641.0917 - val_loss: 391231.8438 - val_mae: 476.6776\n",
            "Epoch 672/1000\n",
            "37/37 [==============================] - 10s 273ms/step - loss: 502929.8125 - mae: 643.2655 - val_loss: 416469.5000 - val_mae: 502.0175\n",
            "Epoch 673/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 501682.0625 - mae: 642.2125 - val_loss: 416366.3750 - val_mae: 501.6855\n",
            "Epoch 674/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 497729.9688 - mae: 639.5134 - val_loss: 408385.9062 - val_mae: 493.9351\n",
            "Epoch 675/1000\n",
            "37/37 [==============================] - 6s 140ms/step - loss: 499761.0312 - mae: 639.9290 - val_loss: 416993.7500 - val_mae: 501.7652\n",
            "Epoch 676/1000\n",
            "37/37 [==============================] - 10s 272ms/step - loss: 500803.8438 - mae: 641.4216 - val_loss: 425291.1250 - val_mae: 510.5090\n",
            "Epoch 677/1000\n",
            "37/37 [==============================] - 10s 273ms/step - loss: 503799.7500 - mae: 643.5266 - val_loss: 416673.6250 - val_mae: 502.1320\n",
            "Epoch 678/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 495073.6562 - mae: 639.6351 - val_loss: 424789.1250 - val_mae: 510.2326\n",
            "Epoch 679/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 502677.5625 - mae: 642.4136 - val_loss: 424915.9062 - val_mae: 510.3049\n",
            "Epoch 680/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 500751.7812 - mae: 641.6439 - val_loss: 399248.6250 - val_mae: 484.7336\n",
            "Epoch 681/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 502332.0312 - mae: 642.5162 - val_loss: 417317.7500 - val_mae: 502.4881\n",
            "Epoch 682/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 500032.6562 - mae: 641.0342 - val_loss: 416731.6250 - val_mae: 502.1645\n",
            "Epoch 683/1000\n",
            "37/37 [==============================] - 10s 272ms/step - loss: 501014.1562 - mae: 641.3736 - val_loss: 408686.0938 - val_mae: 493.8359\n",
            "Epoch 684/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 503107.3438 - mae: 643.8138 - val_loss: 425080.1562 - val_mae: 510.3986\n",
            "Epoch 685/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 494808.8125 - mae: 638.8427 - val_loss: 425107.1562 - val_mae: 510.6790\n",
            "Epoch 686/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 499047.3750 - mae: 639.9406 - val_loss: 408647.7188 - val_mae: 493.5515\n",
            "Epoch 687/1000\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 502359.9062 - mae: 641.7075 - val_loss: 407940.7500 - val_mae: 493.1539\n",
            "Epoch 688/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 498297.9375 - mae: 641.8517 - val_loss: 408609.8438 - val_mae: 493.7924\n",
            "Epoch 689/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 502735.6562 - mae: 642.7460 - val_loss: 425571.2500 - val_mae: 510.4051\n",
            "Epoch 690/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 499016.5312 - mae: 641.5339 - val_loss: 409234.0938 - val_mae: 494.1385\n",
            "Epoch 691/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 493160.0312 - mae: 637.0701 - val_loss: 407741.5312 - val_mae: 493.5798\n",
            "Epoch 692/1000\n",
            "37/37 [==============================] - 6s 148ms/step - loss: 503128.9062 - mae: 643.7441 - val_loss: 416824.5000 - val_mae: 501.6892\n",
            "Epoch 693/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 500165.3438 - mae: 641.0357 - val_loss: 425523.1250 - val_mae: 510.9081\n",
            "Epoch 694/1000\n",
            "37/37 [==============================] - 11s 276ms/step - loss: 502132.5000 - mae: 642.8658 - val_loss: 416901.4688 - val_mae: 502.2596\n",
            "Epoch 695/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 501936.8125 - mae: 642.9153 - val_loss: 425533.9062 - val_mae: 510.1211\n",
            "Epoch 696/1000\n",
            "37/37 [==============================] - 11s 272ms/step - loss: 502207.8438 - mae: 642.8283 - val_loss: 425139.1562 - val_mae: 510.6965\n",
            "Epoch 697/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 503213.5312 - mae: 643.0294 - val_loss: 399290.5938 - val_mae: 484.7581\n",
            "Epoch 698/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 504148.5000 - mae: 643.7029 - val_loss: 408052.7188 - val_mae: 493.4845\n",
            "Epoch 699/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 497969.9375 - mae: 639.2027 - val_loss: 425522.7188 - val_mae: 510.6410\n",
            "Epoch 700/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 500864.2812 - mae: 641.2087 - val_loss: 416998.0938 - val_mae: 502.5774\n",
            "Epoch 701/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 503121.6562 - mae: 642.7706 - val_loss: 416968.0312 - val_mae: 502.5612\n",
            "Epoch 702/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 503410.4062 - mae: 643.8112 - val_loss: 408204.5312 - val_mae: 493.5713\n",
            "Epoch 703/1000\n",
            "37/37 [==============================] - 11s 277ms/step - loss: 500844.6562 - mae: 641.1912 - val_loss: 417506.5000 - val_mae: 502.5937\n",
            "Epoch 704/1000\n",
            "37/37 [==============================] - 10s 273ms/step - loss: 492409.4062 - mae: 636.3837 - val_loss: 425665.1562 - val_mae: 510.9862\n",
            "Epoch 705/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 500780.2500 - mae: 642.3615 - val_loss: 407698.0312 - val_mae: 493.2924\n",
            "Epoch 706/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 501930.7812 - mae: 642.2939 - val_loss: 408025.0938 - val_mae: 493.2039\n",
            "Epoch 707/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 502726.5312 - mae: 642.7419 - val_loss: 417263.1250 - val_mae: 502.1912\n",
            "Epoch 708/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 502768.8750 - mae: 642.6238 - val_loss: 416908.5312 - val_mae: 502.2636\n",
            "Epoch 709/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 500124.1562 - mae: 641.0759 - val_loss: 433715.4062 - val_mae: 518.7870\n",
            "Epoch 710/1000\n",
            "37/37 [==============================] - 11s 274ms/step - loss: 498811.3125 - mae: 640.4086 - val_loss: 400371.2812 - val_mae: 485.6201\n",
            "Epoch 711/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 505369.7188 - mae: 644.8704 - val_loss: 409265.2812 - val_mae: 494.4191\n",
            "Epoch 712/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 499288.9688 - mae: 640.8472 - val_loss: 416369.9062 - val_mae: 501.9667\n",
            "Epoch 713/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 500267.0625 - mae: 641.2757 - val_loss: 416343.7812 - val_mae: 501.9520\n",
            "Epoch 714/1000\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 501106.9688 - mae: 640.9098 - val_loss: 416632.8750 - val_mae: 502.1092\n",
            "Epoch 715/1000\n",
            "37/37 [==============================] - 10s 273ms/step - loss: 501197.5312 - mae: 642.0992 - val_loss: 416156.5000 - val_mae: 501.5789\n",
            "Epoch 716/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 500383.4062 - mae: 641.4981 - val_loss: 416250.9062 - val_mae: 501.6338\n",
            "Epoch 717/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 498287.4062 - mae: 639.9650 - val_loss: 433788.1562 - val_mae: 519.4319\n",
            "Epoch 718/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 504629.7188 - mae: 644.1596 - val_loss: 417240.6562 - val_mae: 502.1781\n",
            "Epoch 719/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 499836.3125 - mae: 640.0770 - val_loss: 408520.7500 - val_mae: 493.7415\n",
            "Epoch 720/1000\n",
            "37/37 [==============================] - 11s 273ms/step - loss: 503528.0312 - mae: 642.8972 - val_loss: 408345.8438 - val_mae: 493.3728\n",
            "Epoch 721/1000\n",
            "37/37 [==============================] - 10s 272ms/step - loss: 503056.7812 - mae: 643.7147 - val_loss: 400263.1562 - val_mae: 485.2924\n",
            "Epoch 722/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 503878.7500 - mae: 643.6652 - val_loss: 425602.7812 - val_mae: 511.2196\n",
            "Epoch 723/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 499640.2500 - mae: 640.9590 - val_loss: 417176.4062 - val_mae: 502.6796\n",
            "Epoch 724/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 504450.3125 - mae: 644.7228 - val_loss: 416154.7188 - val_mae: 501.3122\n",
            "Epoch 725/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 501900.6875 - mae: 641.6472 - val_loss: 416669.1562 - val_mae: 501.8614\n",
            "Epoch 726/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 498903.1875 - mae: 640.5677 - val_loss: 433765.2500 - val_mae: 519.6191\n",
            "Epoch 727/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 500330.6875 - mae: 641.2802 - val_loss: 407996.5312 - val_mae: 493.7205\n",
            "Epoch 728/1000\n",
            "37/37 [==============================] - 10s 274ms/step - loss: 493993.7812 - mae: 636.6191 - val_loss: 408520.8438 - val_mae: 493.7416\n",
            "Epoch 729/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 500602.6562 - mae: 641.2242 - val_loss: 425530.5000 - val_mae: 511.2506\n",
            "Epoch 730/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 497363.6250 - mae: 638.9333 - val_loss: 417155.8750 - val_mae: 502.3975\n",
            "Epoch 731/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 500055.5938 - mae: 640.4246 - val_loss: 408337.8750 - val_mae: 493.6371\n",
            "Epoch 732/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 500627.5625 - mae: 643.2001 - val_loss: 399051.5312 - val_mae: 484.6187\n",
            "Epoch 733/1000\n",
            "37/37 [==============================] - 11s 276ms/step - loss: 495498.8438 - mae: 638.6620 - val_loss: 415955.9062 - val_mae: 501.1925\n",
            "Epoch 734/1000\n",
            "37/37 [==============================] - 11s 274ms/step - loss: 499645.4062 - mae: 641.8197 - val_loss: 399997.6562 - val_mae: 485.1377\n",
            "Epoch 735/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 503068.8125 - mae: 642.8322 - val_loss: 407614.9062 - val_mae: 493.2343\n",
            "Epoch 736/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 501579.1562 - mae: 642.1155 - val_loss: 416919.5312 - val_mae: 502.5410\n",
            "Epoch 737/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 502421.4375 - mae: 643.0980 - val_loss: 416324.5000 - val_mae: 501.3884\n",
            "Epoch 738/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 501521.5938 - mae: 642.2034 - val_loss: 399435.5938 - val_mae: 484.8263\n",
            "Epoch 739/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 501507.4062 - mae: 641.4212 - val_loss: 417037.9062 - val_mae: 502.0603\n",
            "Epoch 740/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 492201.7188 - mae: 638.1243 - val_loss: 416604.2500 - val_mae: 502.0931\n",
            "Epoch 741/1000\n",
            "37/37 [==============================] - 10s 275ms/step - loss: 498760.6875 - mae: 640.6857 - val_loss: 424631.2812 - val_mae: 509.8703\n",
            "Epoch 742/1000\n",
            "37/37 [==============================] - 12s 321ms/step - loss: 493645.0312 - mae: 638.7256 - val_loss: 407785.5000 - val_mae: 493.3319\n",
            "Epoch 743/1000\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 502227.7500 - mae: 642.5581 - val_loss: 424773.7188 - val_mae: 510.2238\n",
            "Epoch 744/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 499802.0000 - mae: 642.5609 - val_loss: 416370.7188 - val_mae: 501.4162\n",
            "Epoch 745/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 500704.7812 - mae: 641.9225 - val_loss: 424846.8438 - val_mae: 510.2655\n",
            "Epoch 746/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 503215.6250 - mae: 642.9480 - val_loss: 425397.7500 - val_mae: 510.5698\n",
            "Epoch 747/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 501988.7812 - mae: 642.5944 - val_loss: 408438.2188 - val_mae: 493.6944\n",
            "Epoch 748/1000\n",
            "37/37 [==============================] - 11s 274ms/step - loss: 498891.8750 - mae: 640.3678 - val_loss: 408964.6250 - val_mae: 493.9848\n",
            "Epoch 749/1000\n",
            "37/37 [==============================] - 10s 272ms/step - loss: 498470.7500 - mae: 641.6440 - val_loss: 408591.4688 - val_mae: 494.3864\n",
            "Epoch 750/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 505191.5312 - mae: 645.3400 - val_loss: 408530.5000 - val_mae: 493.4821\n",
            "Epoch 751/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 501153.5000 - mae: 641.6984 - val_loss: 399797.5000 - val_mae: 485.0373\n",
            "Epoch 752/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 499298.9062 - mae: 640.0120 - val_loss: 408622.4688 - val_mae: 493.7997\n",
            "Epoch 753/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 490540.6562 - mae: 637.5961 - val_loss: 408669.4062 - val_mae: 494.0909\n",
            "Epoch 754/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 503313.9688 - mae: 643.5408 - val_loss: 399902.3750 - val_mae: 485.3622\n",
            "Epoch 755/1000\n",
            "37/37 [==============================] - 10s 274ms/step - loss: 502201.6875 - mae: 642.8998 - val_loss: 417121.5000 - val_mae: 502.6440\n",
            "Epoch 756/1000\n",
            "37/37 [==============================] - 11s 272ms/step - loss: 496732.3125 - mae: 638.8521 - val_loss: 416917.5312 - val_mae: 501.7450\n",
            "Epoch 757/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 504337.4375 - mae: 644.5396 - val_loss: 425713.2812 - val_mae: 510.4889\n",
            "Epoch 758/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 493858.4688 - mae: 637.5910 - val_loss: 408664.0938 - val_mae: 493.8233\n",
            "Epoch 759/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 499466.0000 - mae: 641.5717 - val_loss: 417351.7500 - val_mae: 502.2426\n",
            "Epoch 760/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 502259.5312 - mae: 642.6344 - val_loss: 399852.7188 - val_mae: 485.0694\n",
            "Epoch 761/1000\n",
            "37/37 [==============================] - 11s 277ms/step - loss: 502066.4688 - mae: 642.0505 - val_loss: 416456.2188 - val_mae: 502.0150\n",
            "Epoch 762/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 495836.1562 - mae: 640.0188 - val_loss: 416809.0938 - val_mae: 501.9427\n",
            "Epoch 763/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 499022.0625 - mae: 639.8460 - val_loss: 425104.1250 - val_mae: 510.7494\n",
            "Epoch 764/1000\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 497328.3750 - mae: 640.8516 - val_loss: 416308.3438 - val_mae: 501.6671\n",
            "Epoch 765/1000\n",
            "37/37 [==============================] - 11s 278ms/step - loss: 499964.0938 - mae: 641.8238 - val_loss: 408079.9688 - val_mae: 493.5002\n",
            "Epoch 766/1000\n",
            "37/37 [==============================] - 11s 276ms/step - loss: 500528.9375 - mae: 641.4344 - val_loss: 417396.2500 - val_mae: 502.5321\n",
            "Epoch 767/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 496109.8438 - mae: 640.9797 - val_loss: 416341.3750 - val_mae: 501.9507\n",
            "Epoch 768/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 500228.0625 - mae: 641.1841 - val_loss: 425101.2812 - val_mae: 510.9431\n",
            "Epoch 769/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 501399.8125 - mae: 641.7115 - val_loss: 408519.6562 - val_mae: 493.4757\n",
            "Epoch 770/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 494379.8750 - mae: 637.9957 - val_loss: 416926.6250 - val_mae: 502.5388\n",
            "Epoch 771/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 495926.1562 - mae: 639.7969 - val_loss: 408640.2188 - val_mae: 493.8098\n",
            "Epoch 772/1000\n",
            "37/37 [==============================] - 10s 273ms/step - loss: 500769.2500 - mae: 641.6603 - val_loss: 400303.7188 - val_mae: 485.5822\n",
            "Epoch 773/1000\n",
            "37/37 [==============================] - 10s 273ms/step - loss: 498762.6562 - mae: 640.1375 - val_loss: 407942.9062 - val_mae: 493.1552\n",
            "Epoch 774/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 497849.0625 - mae: 640.7926 - val_loss: 400800.5312 - val_mae: 485.8557\n",
            "Epoch 775/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 501836.0312 - mae: 641.6243 - val_loss: 416156.2812 - val_mae: 501.5788\n",
            "Epoch 776/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 499371.5625 - mae: 641.1264 - val_loss: 407985.4062 - val_mae: 493.7143\n",
            "Epoch 777/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 498390.1562 - mae: 640.2257 - val_loss: 416611.2500 - val_mae: 502.0970\n",
            "Epoch 778/1000\n",
            "37/37 [==============================] - 11s 278ms/step - loss: 500575.3438 - mae: 641.3956 - val_loss: 399181.5000 - val_mae: 484.6945\n",
            "Epoch 779/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 497878.8125 - mae: 639.7239 - val_loss: 407806.4062 - val_mae: 493.0743\n",
            "Epoch 780/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 502380.8750 - mae: 642.3408 - val_loss: 399733.8750 - val_mae: 485.2677\n",
            "Epoch 781/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 497934.1250 - mae: 639.4945 - val_loss: 408503.8438 - val_mae: 494.0692\n",
            "Epoch 782/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 503458.6875 - mae: 642.9287 - val_loss: 408923.5312 - val_mae: 493.9613\n",
            "Epoch 783/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 502521.4062 - mae: 643.2741 - val_loss: 424848.0312 - val_mae: 509.9983\n",
            "Epoch 784/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 497940.0000 - mae: 639.3593 - val_loss: 399852.7188 - val_mae: 485.3344\n",
            "Epoch 785/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 500590.2812 - mae: 640.9817 - val_loss: 407585.6562 - val_mae: 493.4940\n",
            "Epoch 786/1000\n",
            "37/37 [==============================] - 11s 277ms/step - loss: 498162.1875 - mae: 639.7498 - val_loss: 416160.2188 - val_mae: 501.3155\n",
            "Epoch 787/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 498490.1250 - mae: 639.6686 - val_loss: 416794.6562 - val_mae: 502.1998\n",
            "Epoch 788/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 504752.3438 - mae: 643.6453 - val_loss: 408528.9062 - val_mae: 493.7462\n",
            "Epoch 789/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 505208.7500 - mae: 645.1252 - val_loss: 416685.0000 - val_mae: 502.1383\n",
            "Epoch 790/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 504766.1875 - mae: 644.3940 - val_loss: 408602.7188 - val_mae: 494.0543\n",
            "Epoch 791/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 496516.0625 - mae: 639.0901 - val_loss: 408461.7188 - val_mae: 493.4414\n",
            "Epoch 792/1000\n",
            "37/37 [==============================] - 11s 277ms/step - loss: 505891.0312 - mae: 645.9046 - val_loss: 417345.5000 - val_mae: 502.2389\n",
            "Epoch 793/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 496157.6875 - mae: 639.0125 - val_loss: 399784.9688 - val_mae: 485.0300\n",
            "Epoch 794/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 503802.2188 - mae: 644.3214 - val_loss: 407885.6250 - val_mae: 493.1212\n",
            "Epoch 795/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 502953.5625 - mae: 642.9794 - val_loss: 416767.7500 - val_mae: 502.1847\n",
            "Epoch 796/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 497851.6562 - mae: 639.2949 - val_loss: 417269.4688 - val_mae: 502.4610\n",
            "Epoch 797/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 503476.9062 - mae: 643.9490 - val_loss: 416869.6250 - val_mae: 501.9778\n",
            "Epoch 798/1000\n",
            "37/37 [==============================] - 11s 277ms/step - loss: 501504.5625 - mae: 642.4017 - val_loss: 416350.0938 - val_mae: 501.4297\n",
            "Epoch 799/1000\n",
            "37/37 [==============================] - 10s 272ms/step - loss: 502251.2812 - mae: 642.6226 - val_loss: 417411.0938 - val_mae: 502.5404\n",
            "Epoch 800/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 503306.5000 - mae: 642.6937 - val_loss: 399869.2500 - val_mae: 485.0791\n",
            "Epoch 801/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 504779.5312 - mae: 644.7858 - val_loss: 416389.7500 - val_mae: 501.9778\n",
            "Epoch 802/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 504294.8750 - mae: 644.1520 - val_loss: 408125.6562 - val_mae: 493.5262\n",
            "Epoch 803/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 499955.6250 - mae: 641.4449 - val_loss: 416770.2188 - val_mae: 501.9201\n",
            "Epoch 804/1000\n",
            "37/37 [==============================] - 11s 273ms/step - loss: 498263.8750 - mae: 639.5298 - val_loss: 425062.2188 - val_mae: 510.7256\n",
            "Epoch 805/1000\n",
            "37/37 [==============================] - 11s 276ms/step - loss: 499360.5938 - mae: 640.6267 - val_loss: 399798.3750 - val_mae: 485.3039\n",
            "Epoch 806/1000\n",
            "37/37 [==============================] - 11s 278ms/step - loss: 502587.5312 - mae: 644.2388 - val_loss: 392223.2500 - val_mae: 477.2341\n",
            "Epoch 807/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 501980.6562 - mae: 642.6743 - val_loss: 417307.0312 - val_mae: 502.2166\n",
            "Epoch 808/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 501831.0312 - mae: 642.5078 - val_loss: 425116.7500 - val_mae: 510.4194\n",
            "Epoch 809/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 498112.0000 - mae: 639.4070 - val_loss: 416271.9688 - val_mae: 501.9117\n",
            "Epoch 810/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 500704.2812 - mae: 641.4634 - val_loss: 399328.6562 - val_mae: 484.7804\n",
            "Epoch 811/1000\n",
            "37/37 [==============================] - 11s 276ms/step - loss: 491485.7500 - mae: 637.3704 - val_loss: 400522.5000 - val_mae: 485.4433\n",
            "Epoch 812/1000\n",
            "37/37 [==============================] - 11s 273ms/step - loss: 500495.1875 - mae: 640.2352 - val_loss: 417192.7500 - val_mae: 502.6823\n",
            "Epoch 813/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 501604.6250 - mae: 641.6059 - val_loss: 417500.3438 - val_mae: 502.5902\n",
            "Epoch 814/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 500032.0000 - mae: 640.9529 - val_loss: 417043.9062 - val_mae: 502.0791\n",
            "Epoch 815/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 498875.0625 - mae: 640.5687 - val_loss: 417463.9688 - val_mae: 502.3077\n",
            "Epoch 816/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 500487.0938 - mae: 641.5640 - val_loss: 425236.1562 - val_mae: 510.4874\n",
            "Epoch 817/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 499477.1562 - mae: 640.3745 - val_loss: 425678.3438 - val_mae: 510.4683\n",
            "Epoch 818/1000\n",
            "37/37 [==============================] - 11s 280ms/step - loss: 503763.6875 - mae: 644.4326 - val_loss: 408697.0000 - val_mae: 493.8422\n",
            "Epoch 819/1000\n",
            "37/37 [==============================] - 11s 280ms/step - loss: 491947.6562 - mae: 637.9128 - val_loss: 416907.5312 - val_mae: 501.9999\n",
            "Epoch 820/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 501755.5938 - mae: 642.1270 - val_loss: 407731.5312 - val_mae: 493.5743\n",
            "Epoch 821/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 502696.5312 - mae: 642.7520 - val_loss: 409237.3750 - val_mae: 494.1404\n",
            "Epoch 822/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 502310.8125 - mae: 642.9063 - val_loss: 425750.1250 - val_mae: 510.7706\n",
            "Epoch 823/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 502920.8438 - mae: 642.7817 - val_loss: 425264.1250 - val_mae: 510.7651\n",
            "Epoch 824/1000\n",
            "37/37 [==============================] - 6s 141ms/step - loss: 499526.5938 - mae: 643.3777 - val_loss: 407752.1562 - val_mae: 493.3234\n",
            "Epoch 825/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 493531.0938 - mae: 639.2403 - val_loss: 417044.0312 - val_mae: 502.3395\n",
            "Epoch 826/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 497247.7188 - mae: 639.6439 - val_loss: 408893.0938 - val_mae: 493.9541\n",
            "Epoch 827/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 503288.7500 - mae: 642.5325 - val_loss: 409338.6250 - val_mae: 494.1982\n",
            "Epoch 828/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 503112.1875 - mae: 643.4099 - val_loss: 400099.1562 - val_mae: 485.4726\n",
            "Epoch 829/1000\n",
            "37/37 [==============================] - 11s 274ms/step - loss: 501155.8438 - mae: 641.3453 - val_loss: 417095.0312 - val_mae: 502.3680\n",
            "Epoch 830/1000\n",
            "37/37 [==============================] - 11s 279ms/step - loss: 502934.7188 - mae: 642.6549 - val_loss: 417159.1562 - val_mae: 502.4039\n",
            "Epoch 831/1000\n",
            "37/37 [==============================] - 11s 276ms/step - loss: 502804.3438 - mae: 643.1747 - val_loss: 408444.9688 - val_mae: 493.7085\n",
            "Epoch 832/1000\n",
            "37/37 [==============================] - 6s 148ms/step - loss: 489765.0625 - mae: 636.5435 - val_loss: 409448.2188 - val_mae: 494.5195\n",
            "Epoch 833/1000\n",
            "37/37 [==============================] - 11s 281ms/step - loss: 498224.1562 - mae: 639.7111 - val_loss: 417150.3438 - val_mae: 502.3989\n",
            "Epoch 834/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 499679.4062 - mae: 641.1366 - val_loss: 408440.1250 - val_mae: 493.7058\n",
            "Epoch 835/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 495989.2812 - mae: 637.8845 - val_loss: 400598.7500 - val_mae: 485.4877\n",
            "Epoch 836/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 501995.4375 - mae: 642.0267 - val_loss: 425266.1562 - val_mae: 510.2451\n",
            "Epoch 837/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 497443.7500 - mae: 640.4839 - val_loss: 425923.0312 - val_mae: 511.4660\n",
            "Epoch 838/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 500879.8438 - mae: 641.0639 - val_loss: 408230.9062 - val_mae: 493.5863\n",
            "Epoch 839/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 502129.8750 - mae: 642.6433 - val_loss: 416815.4062 - val_mae: 501.9464\n",
            "Epoch 840/1000\n",
            "37/37 [==============================] - 11s 268ms/step - loss: 494237.7500 - mae: 638.7596 - val_loss: 416868.4062 - val_mae: 501.9771\n",
            "Epoch 841/1000\n",
            "37/37 [==============================] - 11s 279ms/step - loss: 502616.8125 - mae: 643.9373 - val_loss: 408465.1250 - val_mae: 493.7098\n",
            "Epoch 842/1000\n",
            "37/37 [==============================] - 11s 279ms/step - loss: 497824.5938 - mae: 639.3097 - val_loss: 417257.6250 - val_mae: 501.9238\n",
            "Epoch 843/1000\n",
            "37/37 [==============================] - 10s 272ms/step - loss: 490759.5312 - mae: 636.0861 - val_loss: 425512.0000 - val_mae: 510.6349\n",
            "Epoch 844/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 502298.7188 - mae: 642.1616 - val_loss: 433552.1250 - val_mae: 518.6924\n",
            "Epoch 845/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 502408.1250 - mae: 642.5264 - val_loss: 408042.1562 - val_mae: 493.7456\n",
            "Epoch 846/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 493996.8750 - mae: 638.3802 - val_loss: 408443.9062 - val_mae: 493.4308\n",
            "Epoch 847/1000\n",
            "37/37 [==============================] - 11s 271ms/step - loss: 499243.9375 - mae: 641.2189 - val_loss: 399768.0312 - val_mae: 485.0201\n",
            "Epoch 848/1000\n",
            "37/37 [==============================] - 11s 279ms/step - loss: 500850.4688 - mae: 641.4291 - val_loss: 399745.0938 - val_mae: 485.0067\n",
            "Epoch 849/1000\n",
            "37/37 [==============================] - 6s 146ms/step - loss: 500103.0312 - mae: 641.2089 - val_loss: 407950.5000 - val_mae: 493.4262\n",
            "Epoch 850/1000\n",
            "37/37 [==============================] - 11s 273ms/step - loss: 500427.4375 - mae: 641.3076 - val_loss: 399093.3750 - val_mae: 484.6432\n",
            "Epoch 851/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 502579.5625 - mae: 642.7328 - val_loss: 425352.7188 - val_mae: 510.5441\n",
            "Epoch 852/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 497662.9688 - mae: 640.2133 - val_loss: 407885.2500 - val_mae: 493.3888\n",
            "Epoch 853/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 499881.0625 - mae: 641.1805 - val_loss: 399089.3750 - val_mae: 484.9111\n",
            "Epoch 854/1000\n",
            "37/37 [==============================] - 11s 282ms/step - loss: 500332.9062 - mae: 641.5914 - val_loss: 407885.6250 - val_mae: 493.1213\n",
            "Epoch 855/1000\n",
            "37/37 [==============================] - 11s 280ms/step - loss: 496953.7812 - mae: 639.8252 - val_loss: 425375.0000 - val_mae: 510.8268\n",
            "Epoch 856/1000\n",
            "37/37 [==============================] - 11s 274ms/step - loss: 494766.9062 - mae: 638.9768 - val_loss: 416524.3438 - val_mae: 501.7773\n",
            "Epoch 857/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 495382.6562 - mae: 640.8663 - val_loss: 408232.3438 - val_mae: 493.5768\n",
            "Epoch 858/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 502111.2188 - mae: 642.6279 - val_loss: 425436.1562 - val_mae: 511.1314\n",
            "Epoch 859/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 495569.8750 - mae: 639.3578 - val_loss: 407790.5312 - val_mae: 493.3347\n",
            "Epoch 860/1000\n",
            "37/37 [==============================] - 6s 147ms/step - loss: 502822.2812 - mae: 642.8083 - val_loss: 407747.0938 - val_mae: 493.3098\n",
            "Epoch 861/1000\n",
            "37/37 [==============================] - 11s 279ms/step - loss: 502276.6875 - mae: 642.4517 - val_loss: 400200.7812 - val_mae: 485.2561\n",
            "Epoch 862/1000\n",
            "37/37 [==============================] - 11s 277ms/step - loss: 501373.7500 - mae: 642.3520 - val_loss: 407827.8750 - val_mae: 493.3561\n",
            "Epoch 863/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 501796.6875 - mae: 642.2655 - val_loss: 416976.5938 - val_mae: 502.2970\n",
            "Epoch 864/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 500447.0625 - mae: 641.0873 - val_loss: 425286.7500 - val_mae: 510.5066\n",
            "Epoch 865/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 503368.3125 - mae: 642.9934 - val_loss: 425371.6250 - val_mae: 510.8249\n",
            "Epoch 866/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 492706.4062 - mae: 636.1192 - val_loss: 399739.9062 - val_mae: 485.2711\n",
            "Epoch 867/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 498148.3438 - mae: 639.8275 - val_loss: 417163.9688 - val_mae: 502.4019\n",
            "Epoch 868/1000\n",
            "37/37 [==============================] - 11s 295ms/step - loss: 498547.3125 - mae: 640.4269 - val_loss: 408066.4688 - val_mae: 493.4924\n",
            "Epoch 869/1000\n",
            "37/37 [==============================] - 11s 281ms/step - loss: 502401.5000 - mae: 641.9283 - val_loss: 407899.3438 - val_mae: 493.1294\n",
            "Epoch 870/1000\n",
            "37/37 [==============================] - 11s 277ms/step - loss: 503249.0000 - mae: 644.0788 - val_loss: 417079.8438 - val_mae: 502.0847\n",
            "Epoch 871/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 487110.3750 - mae: 635.4686 - val_loss: 407416.5000 - val_mae: 493.4009\n",
            "Epoch 872/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 496786.8438 - mae: 638.5611 - val_loss: 407844.4688 - val_mae: 493.3656\n",
            "Epoch 873/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 503230.5625 - mae: 643.6123 - val_loss: 424899.9062 - val_mae: 510.5649\n",
            "Epoch 874/1000\n",
            "37/37 [==============================] - 11s 273ms/step - loss: 501209.3438 - mae: 641.7626 - val_loss: 417088.4062 - val_mae: 502.3596\n",
            "Epoch 875/1000\n",
            "37/37 [==============================] - 11s 281ms/step - loss: 499356.0000 - mae: 639.9764 - val_loss: 416250.5938 - val_mae: 501.8998\n",
            "Epoch 876/1000\n",
            "37/37 [==============================] - 11s 278ms/step - loss: 504176.0000 - mae: 644.0945 - val_loss: 399784.1250 - val_mae: 485.2959\n",
            "Epoch 877/1000\n",
            "37/37 [==============================] - 10s 273ms/step - loss: 503681.1562 - mae: 643.9337 - val_loss: 416606.2812 - val_mae: 501.8249\n",
            "Epoch 878/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 499957.6562 - mae: 641.3343 - val_loss: 407539.8438 - val_mae: 493.4688\n",
            "Epoch 879/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 499698.0312 - mae: 641.4462 - val_loss: 399328.0938 - val_mae: 485.3830\n",
            "Epoch 880/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 503098.8438 - mae: 642.8224 - val_loss: 408911.4688 - val_mae: 493.6866\n",
            "Epoch 881/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 501486.5000 - mae: 642.3739 - val_loss: 416197.6562 - val_mae: 501.8701\n",
            "Epoch 882/1000\n",
            "37/37 [==============================] - 11s 281ms/step - loss: 496808.0312 - mae: 638.7440 - val_loss: 424940.7812 - val_mae: 510.5874\n",
            "Epoch 883/1000\n",
            "37/37 [==============================] - 11s 277ms/step - loss: 503227.9375 - mae: 643.1104 - val_loss: 408847.6562 - val_mae: 493.9180\n",
            "Epoch 884/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 497354.0625 - mae: 639.6530 - val_loss: 416530.5000 - val_mae: 501.7808\n",
            "Epoch 885/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 492161.7500 - mae: 637.9274 - val_loss: 398444.4062 - val_mae: 484.2810\n",
            "Epoch 886/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 487822.7500 - mae: 636.4194 - val_loss: 399072.0000 - val_mae: 484.9014\n",
            "Epoch 887/1000\n",
            "37/37 [==============================] - 10s 273ms/step - loss: 491949.7500 - mae: 637.0579 - val_loss: 425294.2500 - val_mae: 510.7823\n",
            "Epoch 888/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 501744.5938 - mae: 642.3441 - val_loss: 400642.8438 - val_mae: 485.7674\n",
            "Epoch 889/1000\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 494116.2812 - mae: 638.4324 - val_loss: 424966.1562 - val_mae: 510.0480\n",
            "Epoch 890/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 503250.9062 - mae: 643.6199 - val_loss: 407806.0312 - val_mae: 493.6809\n",
            "Epoch 891/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 499435.5938 - mae: 640.7009 - val_loss: 398976.4688 - val_mae: 484.8477\n",
            "Epoch 892/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 502385.5000 - mae: 643.0099 - val_loss: 408084.2500 - val_mae: 493.4922\n",
            "Epoch 893/1000\n",
            "37/37 [==============================] - 11s 279ms/step - loss: 502134.8750 - mae: 642.0002 - val_loss: 416383.6562 - val_mae: 501.9695\n",
            "Epoch 894/1000\n",
            "37/37 [==============================] - 11s 279ms/step - loss: 500557.3125 - mae: 642.9335 - val_loss: 408575.7500 - val_mae: 494.0400\n",
            "Epoch 895/1000\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 497470.5625 - mae: 640.3958 - val_loss: 416210.0938 - val_mae: 501.5946\n",
            "Epoch 896/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 498942.0625 - mae: 639.6168 - val_loss: 425108.8438 - val_mae: 510.1322\n",
            "Epoch 897/1000\n",
            "37/37 [==============================] - 11s 269ms/step - loss: 502443.9375 - mae: 642.6993 - val_loss: 408650.2500 - val_mae: 493.8053\n",
            "Epoch 898/1000\n",
            "37/37 [==============================] - 11s 285ms/step - loss: 491367.8750 - mae: 637.2574 - val_loss: 398765.8438 - val_mae: 484.7293\n",
            "Epoch 899/1000\n",
            "37/37 [==============================] - 11s 281ms/step - loss: 494045.3750 - mae: 638.3593 - val_loss: 416716.8750 - val_mae: 501.5986\n",
            "Epoch 900/1000\n",
            "37/37 [==============================] - 6s 139ms/step - loss: 501919.0000 - mae: 642.9679 - val_loss: 408014.5312 - val_mae: 493.4523\n",
            "Epoch 901/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 501238.2188 - mae: 642.1134 - val_loss: 408132.3438 - val_mae: 494.1340\n",
            "Epoch 902/1000\n",
            "37/37 [==============================] - 11s 280ms/step - loss: 492984.2500 - mae: 638.3166 - val_loss: 416207.3438 - val_mae: 501.8705\n",
            "Epoch 903/1000\n",
            "37/37 [==============================] - 11s 279ms/step - loss: 500862.7500 - mae: 641.6985 - val_loss: 407904.3438 - val_mae: 493.6700\n",
            "Epoch 904/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 500175.2812 - mae: 640.6157 - val_loss: 406940.9062 - val_mae: 492.8593\n",
            "Epoch 905/1000\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 500499.1875 - mae: 640.6093 - val_loss: 407955.5000 - val_mae: 493.6982\n",
            "Epoch 906/1000\n",
            "37/37 [==============================] - 11s 285ms/step - loss: 501559.5938 - mae: 641.6906 - val_loss: 407879.9062 - val_mae: 493.6565\n",
            "Epoch 907/1000\n",
            "37/37 [==============================] - 11s 281ms/step - loss: 499474.1562 - mae: 640.5653 - val_loss: 416124.0000 - val_mae: 501.8238\n",
            "Epoch 908/1000\n",
            "37/37 [==============================] - 10s 272ms/step - loss: 494523.3125 - mae: 637.8937 - val_loss: 415538.5312 - val_mae: 501.2194\n",
            "Epoch 909/1000\n",
            "37/37 [==============================] - 11s 278ms/step - loss: 498283.5000 - mae: 640.0520 - val_loss: 424707.2812 - val_mae: 509.8950\n",
            "Epoch 910/1000\n",
            "37/37 [==============================] - 10s 274ms/step - loss: 501069.5312 - mae: 642.3944 - val_loss: 416033.0312 - val_mae: 501.7727\n",
            "Epoch 911/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 499462.0000 - mae: 640.4926 - val_loss: 424762.2500 - val_mae: 509.9275\n",
            "Epoch 912/1000\n",
            "37/37 [==============================] - 11s 273ms/step - loss: 500764.6562 - mae: 640.8627 - val_loss: 416081.8438 - val_mae: 502.0829\n",
            "Epoch 913/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 487262.4688 - mae: 635.2751 - val_loss: 415954.4062 - val_mae: 501.4458\n",
            "Epoch 914/1000\n",
            "37/37 [==============================] - 11s 282ms/step - loss: 498017.4375 - mae: 639.7261 - val_loss: 399506.9062 - val_mae: 484.8516\n",
            "Epoch 915/1000\n",
            "37/37 [==============================] - 11s 282ms/step - loss: 492137.2812 - mae: 638.8472 - val_loss: 416559.5938 - val_mae: 502.0632\n",
            "Epoch 916/1000\n",
            "37/37 [==============================] - 11s 277ms/step - loss: 501715.1875 - mae: 641.8771 - val_loss: 399179.4688 - val_mae: 484.9563\n",
            "Epoch 917/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 496565.7812 - mae: 639.4887 - val_loss: 415640.8750 - val_mae: 501.8390\n",
            "Epoch 918/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 491297.9375 - mae: 637.6295 - val_loss: 390388.0000 - val_mae: 476.2051\n",
            "Epoch 919/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 500094.3438 - mae: 641.7742 - val_loss: 406723.2500 - val_mae: 492.4531\n",
            "Epoch 920/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 499546.1250 - mae: 640.5206 - val_loss: 407237.5938 - val_mae: 492.7369\n",
            "Epoch 921/1000\n",
            "37/37 [==============================] - 11s 277ms/step - loss: 500671.0625 - mae: 641.2610 - val_loss: 407321.5000 - val_mae: 493.0664\n",
            "Epoch 922/1000\n",
            "37/37 [==============================] - 6s 141ms/step - loss: 497326.9062 - mae: 639.3629 - val_loss: 407271.4688 - val_mae: 493.0377\n",
            "Epoch 923/1000\n",
            "37/37 [==============================] - 11s 267ms/step - loss: 504701.3750 - mae: 644.6925 - val_loss: 407296.9062 - val_mae: 492.7721\n",
            "Epoch 924/1000\n",
            "37/37 [==============================] - 11s 285ms/step - loss: 499359.5000 - mae: 640.0910 - val_loss: 416475.0000 - val_mae: 501.4530\n",
            "Epoch 925/1000\n",
            "37/37 [==============================] - 11s 278ms/step - loss: 502668.7500 - mae: 642.5347 - val_loss: 424316.0938 - val_mae: 509.6841\n",
            "Epoch 926/1000\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 495015.0938 - mae: 637.8713 - val_loss: 398600.2812 - val_mae: 484.6362\n",
            "Epoch 927/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 503359.1875 - mae: 643.6564 - val_loss: 407941.9062 - val_mae: 493.6907\n",
            "Epoch 928/1000\n",
            "37/37 [==============================] - 11s 274ms/step - loss: 499396.5000 - mae: 640.1783 - val_loss: 398034.7812 - val_mae: 484.0417\n",
            "Epoch 929/1000\n",
            "37/37 [==============================] - 11s 283ms/step - loss: 501987.9688 - mae: 642.6484 - val_loss: 399123.2188 - val_mae: 484.6440\n",
            "Epoch 930/1000\n",
            "37/37 [==============================] - 11s 277ms/step - loss: 495898.9375 - mae: 639.6404 - val_loss: 407893.1562 - val_mae: 493.6638\n",
            "Epoch 931/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 495140.4688 - mae: 638.9654 - val_loss: 408289.2812 - val_mae: 493.5989\n",
            "Epoch 932/1000\n",
            "37/37 [==============================] - 10s 273ms/step - loss: 499804.4688 - mae: 640.8101 - val_loss: 424676.7500 - val_mae: 510.1585\n",
            "Epoch 933/1000\n",
            "37/37 [==============================] - 10s 276ms/step - loss: 503558.0000 - mae: 644.0905 - val_loss: 399584.5312 - val_mae: 484.8969\n",
            "Epoch 934/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 493808.7188 - mae: 637.3364 - val_loss: 406674.0000 - val_mae: 492.7064\n",
            "Epoch 935/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 500069.7812 - mae: 640.5894 - val_loss: 407820.8438 - val_mae: 493.6240\n",
            "Epoch 936/1000\n",
            "37/37 [==============================] - 11s 282ms/step - loss: 499492.2812 - mae: 640.4791 - val_loss: 408175.8438 - val_mae: 493.5340\n",
            "Epoch 937/1000\n",
            "37/37 [==============================] - 11s 281ms/step - loss: 499002.8750 - mae: 639.9771 - val_loss: 408124.4688 - val_mae: 493.2204\n",
            "Epoch 938/1000\n",
            "37/37 [==============================] - 11s 280ms/step - loss: 502287.5625 - mae: 642.4974 - val_loss: 408161.2812 - val_mae: 493.2423\n",
            "Epoch 939/1000\n",
            "37/37 [==============================] - 10s 272ms/step - loss: 494971.7812 - mae: 637.1093 - val_loss: 432920.4062 - val_mae: 518.6082\n",
            "Epoch 940/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 503466.1562 - mae: 643.5047 - val_loss: 399546.0938 - val_mae: 485.1570\n",
            "Epoch 941/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 499302.7188 - mae: 640.1898 - val_loss: 399022.7500 - val_mae: 484.5854\n",
            "Epoch 942/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 501882.2812 - mae: 642.2130 - val_loss: 407347.6250 - val_mae: 493.0813\n",
            "Epoch 943/1000\n",
            "37/37 [==============================] - 11s 268ms/step - loss: 500140.8125 - mae: 641.1077 - val_loss: 416025.3438 - val_mae: 501.7684\n",
            "Epoch 944/1000\n",
            "37/37 [==============================] - 11s 281ms/step - loss: 497680.3750 - mae: 639.8755 - val_loss: 399184.5000 - val_mae: 484.6798\n",
            "Epoch 945/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 498938.7812 - mae: 640.5451 - val_loss: 416666.7812 - val_mae: 501.5685\n",
            "Epoch 946/1000\n",
            "37/37 [==============================] - 11s 273ms/step - loss: 504632.0938 - mae: 645.0942 - val_loss: 416191.2500 - val_mae: 501.8615\n",
            "Epoch 947/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 498712.8125 - mae: 640.2280 - val_loss: 416082.6562 - val_mae: 501.5204\n",
            "Epoch 948/1000\n",
            "37/37 [==============================] - 6s 137ms/step - loss: 501887.9375 - mae: 642.2394 - val_loss: 415527.7500 - val_mae: 500.9345\n",
            "Epoch 949/1000\n",
            "37/37 [==============================] - 11s 277ms/step - loss: 487970.3125 - mae: 636.9598 - val_loss: 406989.2500 - val_mae: 493.1654\n",
            "Epoch 950/1000\n",
            "37/37 [==============================] - 11s 280ms/step - loss: 505021.9688 - mae: 646.5752 - val_loss: 424521.5000 - val_mae: 510.6360\n",
            "Epoch 951/1000\n",
            "37/37 [==============================] - 10s 273ms/step - loss: 505178.0625 - mae: 644.3720 - val_loss: 415659.7500 - val_mae: 501.8492\n",
            "Epoch 952/1000\n",
            "37/37 [==============================] - 11s 273ms/step - loss: 498837.7812 - mae: 639.8185 - val_loss: 407967.3438 - val_mae: 493.4253\n",
            "Epoch 953/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 500938.2188 - mae: 641.2468 - val_loss: 399243.5938 - val_mae: 484.7143\n",
            "Epoch 954/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 503173.7188 - mae: 643.7913 - val_loss: 416252.0312 - val_mae: 501.6189\n",
            "Epoch 955/1000\n",
            "37/37 [==============================] - 6s 146ms/step - loss: 500881.9375 - mae: 641.2197 - val_loss: 407002.1562 - val_mae: 492.6188\n",
            "Epoch 956/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 502782.8438 - mae: 642.8232 - val_loss: 416408.9688 - val_mae: 502.2596\n",
            "Epoch 957/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 500104.3438 - mae: 640.2823 - val_loss: 416697.3438 - val_mae: 501.5869\n",
            "Epoch 958/1000\n",
            "37/37 [==============================] - 11s 271ms/step - loss: 501090.4062 - mae: 641.9205 - val_loss: 407538.3438 - val_mae: 493.1905\n",
            "Epoch 959/1000\n",
            "37/37 [==============================] - 11s 278ms/step - loss: 501100.8750 - mae: 641.5195 - val_loss: 433176.9062 - val_mae: 518.2001\n",
            "Epoch 960/1000\n",
            "37/37 [==============================] - 11s 278ms/step - loss: 496978.0312 - mae: 639.4916 - val_loss: 408680.5938 - val_mae: 493.8225\n",
            "Epoch 961/1000\n",
            "37/37 [==============================] - 11s 276ms/step - loss: 503760.5000 - mae: 643.7306 - val_loss: 407060.4062 - val_mae: 492.9277\n",
            "Epoch 962/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 501976.3438 - mae: 641.5525 - val_loss: 408157.9062 - val_mae: 493.5342\n",
            "Epoch 963/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 501932.1562 - mae: 642.0483 - val_loss: 425097.9688 - val_mae: 510.1258\n",
            "Epoch 964/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 502214.9688 - mae: 642.6154 - val_loss: 407171.8438 - val_mae: 492.7195\n",
            "Epoch 965/1000\n",
            "37/37 [==============================] - 11s 282ms/step - loss: 500506.1250 - mae: 641.4743 - val_loss: 399202.0312 - val_mae: 484.9744\n",
            "Epoch 966/1000\n",
            "37/37 [==============================] - 11s 276ms/step - loss: 503073.7188 - mae: 643.1904 - val_loss: 400098.5312 - val_mae: 485.1965\n",
            "Epoch 967/1000\n",
            "37/37 [==============================] - 6s 136ms/step - loss: 503987.2500 - mae: 644.3904 - val_loss: 417056.6250 - val_mae: 502.3418\n",
            "Epoch 968/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 500573.1875 - mae: 641.4941 - val_loss: 424853.0938 - val_mae: 510.5392\n",
            "Epoch 969/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 503089.5000 - mae: 642.5377 - val_loss: 416990.0312 - val_mae: 502.3045\n",
            "Epoch 970/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 501338.8125 - mae: 642.3197 - val_loss: 416609.2500 - val_mae: 502.3677\n",
            "Epoch 971/1000\n",
            "37/37 [==============================] - 11s 278ms/step - loss: 503846.5000 - mae: 644.3276 - val_loss: 416501.3750 - val_mae: 501.7639\n",
            "Epoch 972/1000\n",
            "37/37 [==============================] - 11s 284ms/step - loss: 500784.9375 - mae: 641.7659 - val_loss: 424655.3438 - val_mae: 510.1562\n",
            "Epoch 973/1000\n",
            "37/37 [==============================] - 11s 282ms/step - loss: 500051.6875 - mae: 641.5131 - val_loss: 416593.7500 - val_mae: 502.0872\n",
            "Epoch 974/1000\n",
            "37/37 [==============================] - 11s 278ms/step - loss: 507186.2500 - mae: 646.6589 - val_loss: 424742.5938 - val_mae: 510.2061\n",
            "Epoch 975/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 497117.5938 - mae: 639.5007 - val_loss: 425216.1562 - val_mae: 510.4663\n",
            "Epoch 976/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 504376.3125 - mae: 644.3225 - val_loss: 399064.5938 - val_mae: 484.8972\n",
            "Epoch 977/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 499612.9062 - mae: 641.1794 - val_loss: 424673.1250 - val_mae: 509.8951\n",
            "Epoch 978/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 498969.9375 - mae: 640.6098 - val_loss: 416473.4688 - val_mae: 501.7477\n",
            "Epoch 979/1000\n",
            "37/37 [==============================] - 11s 279ms/step - loss: 503796.9062 - mae: 643.8359 - val_loss: 425231.3438 - val_mae: 510.4749\n",
            "Epoch 980/1000\n",
            "37/37 [==============================] - 11s 281ms/step - loss: 495741.5312 - mae: 640.3087 - val_loss: 407258.7500 - val_mae: 492.7710\n",
            "Epoch 981/1000\n",
            "37/37 [==============================] - 11s 280ms/step - loss: 494115.7812 - mae: 639.7653 - val_loss: 407392.4062 - val_mae: 493.3876\n",
            "Epoch 982/1000\n",
            "37/37 [==============================] - 11s 273ms/step - loss: 500827.5000 - mae: 641.1263 - val_loss: 425091.4688 - val_mae: 510.1220\n",
            "Epoch 983/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 491713.2188 - mae: 637.6006 - val_loss: 424777.2188 - val_mae: 510.7715\n",
            "Epoch 984/1000\n",
            "37/37 [==============================] - 10s 272ms/step - loss: 493398.1562 - mae: 638.8896 - val_loss: 407791.1250 - val_mae: 493.3351\n",
            "Epoch 985/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 501096.0938 - mae: 641.7483 - val_loss: 425488.4062 - val_mae: 511.4984\n",
            "Epoch 986/1000\n",
            "37/37 [==============================] - 11s 269ms/step - loss: 504738.4062 - mae: 645.7183 - val_loss: 407408.5312 - val_mae: 493.7348\n",
            "Epoch 987/1000\n",
            "37/37 [==============================] - 11s 285ms/step - loss: 502385.5312 - mae: 642.4869 - val_loss: 408898.5000 - val_mae: 493.9470\n",
            "Epoch 988/1000\n",
            "37/37 [==============================] - 11s 281ms/step - loss: 499435.0000 - mae: 640.0970 - val_loss: 416648.9062 - val_mae: 502.3891\n",
            "Epoch 989/1000\n",
            "37/37 [==============================] - 6s 146ms/step - loss: 502983.2500 - mae: 643.9796 - val_loss: 415966.3750 - val_mae: 501.4684\n",
            "Epoch 990/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 496438.8125 - mae: 640.5186 - val_loss: 433416.2500 - val_mae: 518.8860\n",
            "Epoch 991/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 498575.0625 - mae: 639.2690 - val_loss: 417041.4062 - val_mae: 502.0624\n",
            "Epoch 992/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 502247.9062 - mae: 643.1082 - val_loss: 416017.5000 - val_mae: 501.2296\n",
            "Epoch 993/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 500190.0312 - mae: 641.6160 - val_loss: 408536.4062 - val_mae: 494.0179\n",
            "Epoch 994/1000\n",
            "37/37 [==============================] - 11s 282ms/step - loss: 498266.4375 - mae: 639.9337 - val_loss: 424808.5938 - val_mae: 510.2437\n",
            "Epoch 995/1000\n",
            "37/37 [==============================] - 11s 277ms/step - loss: 505591.3750 - mae: 645.9344 - val_loss: 416609.2812 - val_mae: 502.3678\n",
            "Epoch 996/1000\n",
            "37/37 [==============================] - 11s 278ms/step - loss: 495285.7188 - mae: 638.8193 - val_loss: 424731.4688 - val_mae: 509.9295\n",
            "Epoch 997/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 496954.2188 - mae: 640.0835 - val_loss: 407778.7500 - val_mae: 493.0580\n",
            "Epoch 998/1000\n",
            "37/37 [==============================] - 10s 272ms/step - loss: 499541.3750 - mae: 641.8466 - val_loss: 417008.6250 - val_mae: 502.0433\n",
            "Epoch 999/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 502050.6875 - mae: 641.8328 - val_loss: 399554.2812 - val_mae: 484.8955\n",
            "Epoch 1000/1000\n",
            "37/37 [==============================] - 10s 272ms/step - loss: 492215.2500 - mae: 637.0911 - val_loss: 399028.0312 - val_mae: 484.8767\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "mae = history.history['mae']\n",
        "val_mae = history.history['val_mae']\n",
        "\n",
        "epochs_x = range(len(loss))\n",
        "\n",
        "plt.plot(epochs_x, mae, 'co', label='Training MAE')\n",
        "plt.plot(epochs_x, val_mae, 'k', label='Validation MAE')\n",
        "plt.title('Training and Mean squared error')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'co', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "     "
      ],
      "metadata": {
        "id": "Y3K89-CM-dfg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "644eb38e-331f-4dca-f53a-c4687546d206"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_x"
      ],
      "metadata": {
        "id": "N_sP_ZmSY-Jv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a422f2b6-46c3-4078-8ac8-a5aba0926f44"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "range(0, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download the model\n"
      ],
      "metadata": {
        "id": "R19IJQSYoW7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('./content/drive/My Drive/new', exist_ok=True)\n",
        "model.save('./content/drive/My Drive/new/regression_unfreeze_2e-2.h5')"
      ],
      "metadata": {
        "id": "Zed4TdFcG2iJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n"
      ],
      "metadata": {
        "id": "P5eMxm1NV-oY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('./content/drive/My Drive/new/regression_unfreeze_2e-2.h5')"
      ],
      "metadata": {
        "id": "wY_pDlxkRwxS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "69b2a2b0-8fc6-4848-e44d-38d55c3ac45c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_312830fb-476b-4bff-89cb-4b4854405f0f\", \"regression_unfreeze_2e-2.h5\", 49138080)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}