{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kittikhun62/efficientnet_keras_transfer_learning/blob/master/regression_2Class_Unfreeze.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#เรียกใช้ CSV"
      ],
      "metadata": {
        "id": "ow7eWoNw6U-c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z8o_VVNXzcL8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_2Fe8u81d5r",
        "outputId": "1230046d-df64-4b29-b1d9-8b6cd99a39ee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "5qxePnnn7TGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "D-hCRloc3t39"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "YZWXwjXeGxZP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#กำหนดค่าพารามิเตอร์\n"
      ],
      "metadata": {
        "id": "RooqSdBc7QHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "width = 150\n",
        "height = 150\n",
        "\n",
        "epochs = 1000 #จำนวนรอบในการ Train\n",
        "\n",
        "NUM_TRAIN = 628  # จำนวนภาพ Train\n",
        "NUM_TEST = 101 #จำนวนภาพ Test\n",
        "\n",
        "dropout_rate = 0.3\n",
        "input_shape = (height, width, 3) #ขนาด image enter"
      ],
      "metadata": {
        "id": "thDb7U9B3xOo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clone efficientnet repo\n"
      ],
      "metadata": {
        "id": "pumGmy6f3eSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7iy2f8n16p0",
        "outputId": "55401eed-7b39-4fc1-c242-6f55db6e7bdb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 1079, done.\u001b[K\n",
            "remote: Counting objects: 100% (242/242), done.\u001b[K\n",
            "remote: Compressing objects: 100% (121/121), done.\u001b[K\n",
            "remote: Total 1079 (delta 121), reused 241 (delta 121), pack-reused 837\u001b[K\n",
            "Receiving objects: 100% (1079/1079), 13.94 MiB | 18.62 MiB/s, done.\n",
            "Resolving deltas: 100% (618/618), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "tjZBRnfo3bN0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "r8BN74_JJdfj",
        "outputId": "27697863-91ff-4411-cf4d-1b7f8080e2ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#load model\n"
      ],
      "metadata": {
        "id": "PdNWyD-QYkzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/new/regression.h5')\n",
        "\n",
        "from efficientnet.layers import Swish, DropConnect\n",
        "from efficientnet.model import ConvKernalInitializer\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "\n",
        "get_custom_objects().update({\n",
        "    'ConvKernalInitializer': ConvKernalInitializer,\n",
        "    'Swish': Swish,\n",
        "    'DropConnect':DropConnect\n",
        "})"
      ],
      "metadata": {
        "id": "_gPnx2UvYf5A"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load model \n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/drive/My Drive/new/regression.h5')\n",
        "height = width = model.input_shape[1]"
      ],
      "metadata": {
        "id": "Nu93WzFUYm9e"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "gp5EbyyXYvc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7e31653-5714-428e-fe16-0216c430953c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 2)                 2562      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,052,129\n",
            "Trainable params: 2,565\n",
            "Non-trainable params: 4,049,564\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (f'/content/drive/My Drive/data - 2 class เพิ่ม 4 paper.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "q1Dc131_Y3uA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "43267b0f-2a60-477c-86bc-22873a575b1c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      No                      Name_file  \\\n",
              "0      1                        pore-sb   \n",
              "1      2                        pore-sb   \n",
              "2      3                        pore-sb   \n",
              "3      4                        pore-sb   \n",
              "4      5                        pore-sb   \n",
              "..   ...                            ...   \n",
              "825  826  1-s2.0-S2095268622000210-main   \n",
              "826  827  1-s2.0-S2095268622000210-main   \n",
              "827  828  1-s2.0-S2095268622000210-main   \n",
              "828  829  1-s2.0-S2095268622000210-main   \n",
              "829  830  1-s2.0-S2095268622000210-main   \n",
              "\n",
              "                                            Name_Paper  \\\n",
              "0    Preparation and electrochemical behaviour of b...   \n",
              "1    Preparation and electrochemical behaviour of b...   \n",
              "2    Preparation and electrochemical behaviour of b...   \n",
              "3    Preparation and electrochemical behaviour of b...   \n",
              "4    Preparation and electrochemical behaviour of b...   \n",
              "..                                                 ...   \n",
              "825  Integration of preparation of K, Na-embedded a...   \n",
              "826  Integration of preparation of K, Na-embedded a...   \n",
              "827  Integration of preparation of K, Na-embedded a...   \n",
              "828  Integration of preparation of K, Na-embedded a...   \n",
              "829  Integration of preparation of K, Na-embedded a...   \n",
              "\n",
              "                                               journal  \\\n",
              "0                                  Korean J. Chem. Eng   \n",
              "1                                  Korean J. Chem. Eng   \n",
              "2                                  Korean J. Chem. Eng   \n",
              "3                                  Korean J. Chem. Eng   \n",
              "4                                  Korean J. Chem. Eng   \n",
              "..                                                 ...   \n",
              "825  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "826  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "827  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "828  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "829  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "\n",
              "                                          path_Picture  detail  Class     BET  \\\n",
              "0    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom1  0-800  135.06   \n",
              "1    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom2  0-800  135.06   \n",
              "2    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom3  0-800  135.06   \n",
              "3    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom4  0-800  135.06   \n",
              "4    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom5  0-800  135.06   \n",
              "..                                                 ...     ...    ...     ...   \n",
              "825  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom21  0-800  301.70   \n",
              "826  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom22  0-800  301.70   \n",
              "827  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom23  0-800  301.70   \n",
              "828  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom24  0-800  301.70   \n",
              "829  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom25  0-800  301.70   \n",
              "\n",
              "     Size(mico)  Class_01  \n",
              "0            10         0  \n",
              "1            10         0  \n",
              "2            10         0  \n",
              "3            10         0  \n",
              "4            10         0  \n",
              "..          ...       ...  \n",
              "825          10         0  \n",
              "826          10         0  \n",
              "827          10         0  \n",
              "828          10         0  \n",
              "829          10         0  \n",
              "\n",
              "[830 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-beca6dcc-8402-4f33-9fbf-c51d54fb5c62\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>No</th>\n",
              "      <th>Name_file</th>\n",
              "      <th>Name_Paper</th>\n",
              "      <th>journal</th>\n",
              "      <th>path_Picture</th>\n",
              "      <th>detail</th>\n",
              "      <th>Class</th>\n",
              "      <th>BET</th>\n",
              "      <th>Size(mico)</th>\n",
              "      <th>Class_01</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom1</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom2</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom3</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom4</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom5</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>825</th>\n",
              "      <td>826</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom21</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>826</th>\n",
              "      <td>827</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom22</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>827</th>\n",
              "      <td>828</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom23</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>828</th>\n",
              "      <td>829</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom24</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>829</th>\n",
              "      <td>830</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom25</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>830 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-beca6dcc-8402-4f33-9fbf-c51d54fb5c62')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-beca6dcc-8402-4f33-9fbf-c51d54fb5c62 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-beca6dcc-8402-4f33-9fbf-c51d54fb5c62');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "FdYoTgJ19LRv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val = df[df['No'].between(629,729)]\n",
        "train = df[df['No'].between(1,628)]"
      ],
      "metadata": {
        "id": "Z1zBw01Gl8Ac"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = '/content/drive/My Drive/new project'\n",
        "os.chdir(DATA_PATH)\n",
        "train_dir = os.path.join(DATA_PATH, 'train')\n",
        "print(train_dir)\n",
        "validation_dir = os.path.join(DATA_PATH, 'validation')\n",
        "print(validation_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QL0g-8iOnMC4",
        "outputId": "31c3a0f7-6a78-4119-b1ca-ef825d659dcc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/new project/train\n",
            "/content/drive/My Drive/new project/validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Train"
      ],
      "metadata": {
        "id": "bWEnlTSwazL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "xGPrsn9no_pa"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe = train,\n",
        "        directory = train_dir,\n",
        "        x_col = 'path_Picture',\n",
        "        y_col = 'BET',\n",
        "        class_mode = 'other',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)\n",
        "\n",
        "validation_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe = val,\n",
        "        directory = validation_dir,\n",
        "        x_col = 'path_Picture',\n",
        "        y_col = 'BET',\n",
        "        class_mode = 'other',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nVlmAszntK_",
        "outputId": "81c9b960-f68f-48b6-b3ff-0cfd2a6f7a3c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 628 validated image filenames.\n",
            "Found 101 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multiply_16\n",
        "# set 'multiply_16' and following layers trainable\n",
        "model.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'multiply_16':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False  "
      ],
      "metadata": {
        "id": "RY14olxmJj92"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzCdn3X4Jm_E",
        "outputId": "e89c3eab-2a21-4e18-9583-11e9b70be02b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 2)                 2562      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,052,129\n",
            "Trainable params: 4,010,113\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "N6qUmmF856ZE",
        "outputId": "bc456a06-8d12-483d-b702-51a54941503e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-caa7b37242a8>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "39/39 [==============================] - 150s 3s/step - loss: 605954.6875 - mae: 615.4678 - val_loss: 222434.9531 - val_mae: 456.5224\n",
            "Epoch 2/1000\n",
            "39/39 [==============================] - 3s 83ms/step - loss: 603689.2500 - mae: 613.4155 - val_loss: 222292.4844 - val_mae: 456.9071\n",
            "Epoch 3/1000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 604680.7500 - mae: 615.4921 - val_loss: 223010.5000 - val_mae: 457.4432\n",
            "Epoch 4/1000\n",
            "39/39 [==============================] - 3s 69ms/step - loss: 604250.3750 - mae: 616.1613 - val_loss: 222473.7031 - val_mae: 456.8561\n",
            "Epoch 5/1000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 600478.8125 - mae: 613.8466 - val_loss: 223189.7656 - val_mae: 457.3935\n",
            "Epoch 6/1000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 605261.7500 - mae: 615.7400 - val_loss: 222950.4375 - val_mae: 456.4612\n",
            "Epoch 7/1000\n",
            "39/39 [==============================] - 3s 72ms/step - loss: 598659.6875 - mae: 611.9658 - val_loss: 224847.8750 - val_mae: 458.7617\n",
            "Epoch 8/1000\n",
            "39/39 [==============================] - 3s 73ms/step - loss: 606602.6250 - mae: 617.2896 - val_loss: 225285.6094 - val_mae: 459.5718\n",
            "Epoch 9/1000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 599279.6875 - mae: 612.3695 - val_loss: 222072.1250 - val_mae: 455.2651\n",
            "Epoch 10/1000\n",
            "39/39 [==============================] - 3s 70ms/step - loss: 602293.2500 - mae: 613.4879 - val_loss: 223638.2500 - val_mae: 457.2725\n",
            "Epoch 11/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 598976.1875 - mae: 613.1815 - val_loss: 224636.2500 - val_mae: 458.1503\n",
            "Epoch 12/1000\n",
            "39/39 [==============================] - 9s 207ms/step - loss: 588382.3750 - mae: 610.8994 - val_loss: 226200.5781 - val_mae: 460.1705\n",
            "Epoch 13/1000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 602883.6875 - mae: 614.4655 - val_loss: 224841.8906 - val_mae: 458.1266\n",
            "Epoch 14/1000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 603883.6250 - mae: 616.6460 - val_loss: 226523.7656 - val_mae: 459.6146\n",
            "Epoch 15/1000\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 602115.5000 - mae: 614.8959 - val_loss: 228934.2969 - val_mae: 463.1146\n",
            "Epoch 16/1000\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 598008.3125 - mae: 613.0052 - val_loss: 226124.5469 - val_mae: 459.0521\n",
            "Epoch 17/1000\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 601572.0625 - mae: 615.0674 - val_loss: 228016.1250 - val_mae: 461.3646\n",
            "Epoch 18/1000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 601340.5625 - mae: 615.9105 - val_loss: 229584.9375 - val_mae: 463.3958\n",
            "Epoch 19/1000\n",
            "39/39 [==============================] - 4s 76ms/step - loss: 588995.1250 - mae: 609.8255 - val_loss: 226940.1406 - val_mae: 460.0851\n",
            "Epoch 20/1000\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 595200.6875 - mae: 612.2590 - val_loss: 229394.9219 - val_mae: 462.3745\n",
            "Epoch 21/1000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 603713.3750 - mae: 616.1469 - val_loss: 232328.1719 - val_mae: 465.7223\n",
            "Epoch 22/1000\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 594214.1875 - mae: 610.8726 - val_loss: 226858.5000 - val_mae: 459.0521\n",
            "Epoch 23/1000\n",
            "39/39 [==============================] - 4s 79ms/step - loss: 595442.5625 - mae: 613.6301 - val_loss: 225612.2969 - val_mae: 457.7242\n",
            "Epoch 24/1000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 588394.0625 - mae: 609.0060 - val_loss: 231486.2500 - val_mae: 464.3705\n",
            "Epoch 25/1000\n",
            "39/39 [==============================] - 9s 207ms/step - loss: 599499.0000 - mae: 615.8217 - val_loss: 228993.7344 - val_mae: 461.3646\n",
            "Epoch 26/1000\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 584351.0625 - mae: 608.3824 - val_loss: 226263.8281 - val_mae: 457.9700\n",
            "Epoch 27/1000\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 593487.2500 - mae: 612.4609 - val_loss: 227800.4219 - val_mae: 459.3333\n",
            "Epoch 28/1000\n",
            "39/39 [==============================] - 8s 201ms/step - loss: 600591.3125 - mae: 618.2136 - val_loss: 229365.3594 - val_mae: 461.3646\n",
            "Epoch 29/1000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 600575.6250 - mae: 616.1580 - val_loss: 232373.4844 - val_mae: 464.7967\n",
            "Epoch 30/1000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 590535.5000 - mae: 613.1889 - val_loss: 225275.3594 - val_mae: 456.5081\n",
            "Epoch 31/1000\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 591923.5625 - mae: 610.8923 - val_loss: 233794.7656 - val_mae: 465.9641\n",
            "Epoch 32/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 599533.9375 - mae: 615.6526 - val_loss: 232471.3906 - val_mae: 464.5524\n",
            "Epoch 33/1000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 592186.5000 - mae: 612.6046 - val_loss: 223000.1250 - val_mae: 453.2355\n",
            "Epoch 34/1000\n",
            "39/39 [==============================] - 8s 212ms/step - loss: 599073.1250 - mae: 615.6170 - val_loss: 227215.8750 - val_mae: 457.8715\n",
            "Epoch 35/1000\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 593918.4375 - mae: 614.1523 - val_loss: 229197.3281 - val_mae: 460.0889\n",
            "Epoch 36/1000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 589682.5000 - mae: 613.3117 - val_loss: 224824.5781 - val_mae: 454.6129\n",
            "Epoch 37/1000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 594470.2500 - mae: 614.3854 - val_loss: 229123.4219 - val_mae: 459.3333\n",
            "Epoch 38/1000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 591885.3750 - mae: 613.1384 - val_loss: 227690.8906 - val_mae: 457.8240\n",
            "Epoch 39/1000\n",
            "39/39 [==============================] - 3s 72ms/step - loss: 589065.8750 - mae: 611.1105 - val_loss: 232517.0156 - val_mae: 463.6771\n",
            "Epoch 40/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 589930.7500 - mae: 611.4280 - val_loss: 225275.1094 - val_mae: 454.5160\n",
            "Epoch 41/1000\n",
            "39/39 [==============================] - 8s 203ms/step - loss: 593692.1875 - mae: 614.6640 - val_loss: 232648.0469 - val_mae: 462.9096\n",
            "Epoch 42/1000\n",
            "39/39 [==============================] - 3s 73ms/step - loss: 591969.0000 - mae: 613.7126 - val_loss: 232914.7031 - val_mae: 463.6771\n",
            "Epoch 43/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 590516.3125 - mae: 611.6818 - val_loss: 226357.2656 - val_mae: 455.9139\n",
            "Epoch 44/1000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 593446.1875 - mae: 613.9398 - val_loss: 225728.8594 - val_mae: 454.4208\n",
            "Epoch 45/1000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 591778.7500 - mae: 612.3511 - val_loss: 223872.6250 - val_mae: 452.5223\n",
            "Epoch 46/1000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 592590.0000 - mae: 614.0775 - val_loss: 227035.8750 - val_mae: 456.1204\n",
            "Epoch 47/1000\n",
            "39/39 [==============================] - 4s 79ms/step - loss: 595683.4375 - mae: 616.0009 - val_loss: 230821.7656 - val_mae: 459.6146\n",
            "Epoch 48/1000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 596984.1250 - mae: 618.4036 - val_loss: 235074.3906 - val_mae: 464.3464\n",
            "Epoch 49/1000\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 591839.2500 - mae: 615.3762 - val_loss: 229087.5469 - val_mae: 457.6900\n",
            "Epoch 50/1000\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 583575.5000 - mae: 611.4956 - val_loss: 233350.1250 - val_mae: 463.1146\n",
            "Epoch 51/1000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 578129.0000 - mae: 607.8421 - val_loss: 233834.6250 - val_mae: 462.7502\n",
            "Epoch 52/1000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 588144.6875 - mae: 613.2986 - val_loss: 235349.9531 - val_mae: 464.7925\n",
            "Epoch 53/1000\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 587982.8750 - mae: 612.1956 - val_loss: 234413.3281 - val_mae: 463.6771\n",
            "Epoch 54/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 587494.1875 - mae: 613.2530 - val_loss: 228294.7969 - val_mae: 456.2108\n",
            "Epoch 55/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 589576.8125 - mae: 614.2148 - val_loss: 234770.9375 - val_mae: 463.0789\n",
            "Epoch 56/1000\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 587761.6875 - mae: 613.2430 - val_loss: 231488.4375 - val_mae: 459.5562\n",
            "Epoch 57/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 584032.5000 - mae: 610.9141 - val_loss: 227799.5469 - val_mae: 455.2141\n",
            "Epoch 58/1000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 589421.0000 - mae: 615.3559 - val_loss: 233741.1875 - val_mae: 461.6458\n",
            "Epoch 59/1000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 589356.0000 - mae: 613.1515 - val_loss: 236736.8594 - val_mae: 465.1567\n",
            "Epoch 60/1000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 577455.5000 - mae: 609.0906 - val_loss: 234737.1719 - val_mae: 463.1146\n",
            "Epoch 61/1000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 585610.6875 - mae: 612.1563 - val_loss: 233844.5000 - val_mae: 461.3646\n",
            "Epoch 62/1000\n",
            "39/39 [==============================] - 8s 202ms/step - loss: 587206.6875 - mae: 614.7003 - val_loss: 233991.0000 - val_mae: 461.3646\n",
            "Epoch 63/1000\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 588358.3125 - mae: 614.3964 - val_loss: 229060.2969 - val_mae: 455.7153\n",
            "Epoch 64/1000\n",
            "39/39 [==============================] - 4s 76ms/step - loss: 589735.1250 - mae: 615.5331 - val_loss: 237723.6875 - val_mae: 464.7251\n",
            "Epoch 65/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 579272.0625 - mae: 610.4352 - val_loss: 239245.0000 - val_mae: 466.7808\n",
            "Epoch 66/1000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 590978.9375 - mae: 617.3086 - val_loss: 235595.8750 - val_mae: 463.1146\n",
            "Epoch 67/1000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 584922.3750 - mae: 612.9448 - val_loss: 238228.5000 - val_mae: 464.7947\n",
            "Epoch 68/1000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 584297.3125 - mae: 612.6017 - val_loss: 235466.5469 - val_mae: 461.2008\n",
            "Epoch 69/1000\n",
            "39/39 [==============================] - 8s 201ms/step - loss: 587522.6250 - mae: 615.2638 - val_loss: 230474.7500 - val_mae: 456.1371\n",
            "Epoch 70/1000\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 580385.4375 - mae: 612.8497 - val_loss: 230889.7969 - val_mae: 455.6921\n",
            "Epoch 71/1000\n",
            "39/39 [==============================] - 9s 209ms/step - loss: 576149.2500 - mae: 610.4492 - val_loss: 235653.1719 - val_mae: 461.6458\n",
            "Epoch 72/1000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 584115.0000 - mae: 613.9810 - val_loss: 232156.0156 - val_mae: 457.4198\n",
            "Epoch 73/1000\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 580924.9375 - mae: 611.4752 - val_loss: 233961.3750 - val_mae: 459.0521\n",
            "Epoch 74/1000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 581773.9375 - mae: 611.2588 - val_loss: 231455.4219 - val_mae: 455.6458\n",
            "Epoch 75/1000\n",
            "39/39 [==============================] - 4s 79ms/step - loss: 570204.8750 - mae: 608.7875 - val_loss: 229254.5781 - val_mae: 453.4029\n",
            "Epoch 76/1000\n",
            "39/39 [==============================] - 4s 78ms/step - loss: 582193.0000 - mae: 613.1846 - val_loss: 241117.4531 - val_mae: 467.0376\n",
            "Epoch 77/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 578891.6875 - mae: 611.2233 - val_loss: 231896.1250 - val_mae: 455.6102\n",
            "Epoch 78/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 570279.8125 - mae: 605.4498 - val_loss: 234094.3281 - val_mae: 457.5833\n",
            "Epoch 79/1000\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 577053.1250 - mae: 610.5532 - val_loss: 231441.7344 - val_mae: 455.6212\n",
            "Epoch 80/1000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 582942.5625 - mae: 614.2780 - val_loss: 236370.3125 - val_mae: 461.0833\n",
            "Epoch 81/1000\n",
            "39/39 [==============================] - 8s 199ms/step - loss: 583430.2500 - mae: 614.3604 - val_loss: 237839.1719 - val_mae: 463.1146\n",
            "Epoch 82/1000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 571809.1875 - mae: 609.9340 - val_loss: 231520.1250 - val_mae: 455.2672\n",
            "Epoch 83/1000\n",
            "39/39 [==============================] - 4s 77ms/step - loss: 564301.0000 - mae: 602.9446 - val_loss: 238955.9219 - val_mae: 463.1281\n",
            "Epoch 84/1000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 582717.1875 - mae: 615.3622 - val_loss: 232127.2031 - val_mae: 455.5019\n",
            "Epoch 85/1000\n",
            "39/39 [==============================] - 5s 100ms/step - loss: 574257.0000 - mae: 609.9587 - val_loss: 235357.0156 - val_mae: 459.2968\n",
            "Epoch 86/1000\n",
            "39/39 [==============================] - 4s 76ms/step - loss: 575830.0625 - mae: 610.4024 - val_loss: 236360.0469 - val_mae: 459.3333\n",
            "Epoch 87/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 577963.5000 - mae: 612.2863 - val_loss: 234700.5469 - val_mae: 457.5230\n",
            "Epoch 88/1000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 574548.6875 - mae: 609.5470 - val_loss: 237573.5625 - val_mae: 459.4060\n",
            "Epoch 89/1000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 581948.6875 - mae: 615.5703 - val_loss: 235001.5000 - val_mae: 457.4996\n",
            "Epoch 90/1000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 573538.4375 - mae: 609.3317 - val_loss: 237002.1875 - val_mae: 459.3333\n",
            "Epoch 91/1000\n",
            "39/39 [==============================] - 8s 203ms/step - loss: 576775.3750 - mae: 611.5063 - val_loss: 243811.0156 - val_mae: 467.3900\n",
            "Epoch 92/1000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 568536.8750 - mae: 607.6323 - val_loss: 233225.8594 - val_mae: 455.3163\n",
            "Epoch 93/1000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 560802.3125 - mae: 604.1117 - val_loss: 237494.3750 - val_mae: 459.3333\n",
            "Epoch 94/1000\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 572235.3125 - mae: 610.1753 - val_loss: 243072.9219 - val_mae: 465.4273\n",
            "Epoch 95/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 573259.9375 - mae: 611.6984 - val_loss: 235905.7656 - val_mae: 457.4305\n",
            "Epoch 96/1000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 571592.8125 - mae: 610.0202 - val_loss: 242459.2969 - val_mae: 465.3102\n",
            "Epoch 97/1000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 573698.3750 - mae: 612.0969 - val_loss: 236795.9219 - val_mae: 458.8765\n",
            "Epoch 98/1000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 579838.3750 - mae: 614.3775 - val_loss: 237291.7344 - val_mae: 459.1461\n",
            "Epoch 99/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 574094.2500 - mae: 612.6032 - val_loss: 239417.1875 - val_mae: 461.0833\n",
            "Epoch 100/1000\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 572229.9375 - mae: 610.0104 - val_loss: 235421.6250 - val_mae: 455.3409\n",
            "Epoch 101/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 566676.6875 - mae: 606.4200 - val_loss: 238469.0625 - val_mae: 459.0521\n",
            "Epoch 102/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 570654.0625 - mae: 610.1678 - val_loss: 239889.3125 - val_mae: 461.0833\n",
            "Epoch 103/1000\n",
            "39/39 [==============================] - 4s 78ms/step - loss: 570128.4375 - mae: 610.7117 - val_loss: 238063.0781 - val_mae: 459.0882\n",
            "Epoch 104/1000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 562554.1875 - mae: 609.2046 - val_loss: 236040.1719 - val_mae: 455.2962\n",
            "Epoch 105/1000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 577763.0625 - mae: 616.0691 - val_loss: 244365.2031 - val_mae: 465.6944\n",
            "Epoch 106/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 566048.0625 - mae: 607.7054 - val_loss: 237613.1719 - val_mae: 457.3044\n",
            "Epoch 107/1000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 573405.6250 - mae: 612.9272 - val_loss: 239820.4531 - val_mae: 459.3333\n",
            "Epoch 108/1000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 558520.5625 - mae: 606.7997 - val_loss: 232544.1719 - val_mae: 451.1496\n",
            "Epoch 109/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 571981.2500 - mae: 612.1307 - val_loss: 245964.1875 - val_mae: 467.4895\n",
            "Epoch 110/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 565250.1875 - mae: 609.7781 - val_loss: 238243.7031 - val_mae: 457.2592\n",
            "Epoch 111/1000\n",
            "39/39 [==============================] - 8s 201ms/step - loss: 567056.6250 - mae: 609.1736 - val_loss: 238947.1094 - val_mae: 458.7168\n",
            "Epoch 112/1000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 574758.8750 - mae: 614.0068 - val_loss: 240662.0156 - val_mae: 459.3333\n",
            "Epoch 113/1000\n",
            "39/39 [==============================] - 8s 201ms/step - loss: 573728.4375 - mae: 613.4761 - val_loss: 240847.6250 - val_mae: 459.3333\n",
            "Epoch 114/1000\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 559460.6250 - mae: 607.7376 - val_loss: 238895.1719 - val_mae: 457.2131\n",
            "Epoch 115/1000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 569470.4375 - mae: 612.3787 - val_loss: 239596.6719 - val_mae: 458.6703\n",
            "Epoch 116/1000\n",
            "39/39 [==============================] - 8s 199ms/step - loss: 569766.5625 - mae: 613.0067 - val_loss: 239749.9375 - val_mae: 458.6594\n",
            "Epoch 117/1000\n",
            "39/39 [==============================] - 8s 203ms/step - loss: 569721.2500 - mae: 612.1764 - val_loss: 240327.5469 - val_mae: 457.3021\n",
            "Epoch 118/1000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 545821.5625 - mae: 601.8723 - val_loss: 241562.8125 - val_mae: 458.9688\n",
            "Epoch 119/1000\n",
            "39/39 [==============================] - 4s 79ms/step - loss: 564933.8750 - mae: 609.6530 - val_loss: 245329.0156 - val_mae: 463.5424\n",
            "Epoch 120/1000\n",
            "39/39 [==============================] - 9s 208ms/step - loss: 569093.9375 - mae: 611.9370 - val_loss: 242073.8281 - val_mae: 459.3333\n",
            "Epoch 121/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 561153.8750 - mae: 609.4274 - val_loss: 240040.6719 - val_mae: 457.1338\n",
            "Epoch 122/1000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 570466.3125 - mae: 612.8704 - val_loss: 244699.5469 - val_mae: 463.0313\n",
            "Epoch 123/1000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 569537.1875 - mae: 613.5245 - val_loss: 248486.5469 - val_mae: 467.6493\n",
            "Epoch 124/1000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 568452.3125 - mae: 611.5530 - val_loss: 241409.4531 - val_mae: 458.8492\n",
            "Epoch 125/1000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 566368.4375 - mae: 612.7841 - val_loss: 244534.1250 - val_mae: 461.6458\n",
            "Epoch 126/1000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 560939.7500 - mae: 609.9714 - val_loss: 242300.1250 - val_mae: 457.5833\n",
            "Epoch 127/1000\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 565030.3125 - mae: 611.6337 - val_loss: 243321.0469 - val_mae: 459.3333\n",
            "Epoch 128/1000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 565855.3750 - mae: 611.2690 - val_loss: 242416.9375 - val_mae: 459.0858\n",
            "Epoch 129/1000\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 566002.3750 - mae: 613.0796 - val_loss: 244894.5625 - val_mae: 461.3646\n",
            "Epoch 130/1000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 563117.9375 - mae: 610.1284 - val_loss: 238177.2656 - val_mae: 453.8872\n",
            "Epoch 131/1000\n",
            "39/39 [==============================] - 4s 76ms/step - loss: 561868.1250 - mae: 610.5120 - val_loss: 245592.3594 - val_mae: 461.6458\n",
            "Epoch 132/1000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 564050.8750 - mae: 610.1602 - val_loss: 245048.4531 - val_mae: 461.0833\n",
            "Epoch 133/1000\n",
            "39/39 [==============================] - 5s 128ms/step - loss: 569456.9375 - mae: 615.6592 - val_loss: 239351.7969 - val_mae: 454.3833\n",
            "Epoch 134/1000\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 566131.4375 - mae: 612.5914 - val_loss: 246124.6719 - val_mae: 461.6458\n",
            "Epoch 135/1000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 563820.3750 - mae: 611.4554 - val_loss: 237756.6094 - val_mae: 451.7473\n",
            "Epoch 136/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 563629.3750 - mae: 612.3444 - val_loss: 245304.4844 - val_mae: 459.6146\n",
            "Epoch 137/1000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 561976.8750 - mae: 612.8098 - val_loss: 247493.8281 - val_mae: 463.3958\n",
            "Epoch 138/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 553783.5000 - mae: 607.6362 - val_loss: 240508.0156 - val_mae: 454.5527\n",
            "Epoch 139/1000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 566460.6250 - mae: 615.0539 - val_loss: 246176.6406 - val_mae: 460.7188\n",
            "Epoch 140/1000\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 564059.0625 - mae: 613.4323 - val_loss: 247690.8906 - val_mae: 463.1146\n",
            "Epoch 141/1000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 553563.5625 - mae: 607.5317 - val_loss: 249483.3906 - val_mae: 463.7882\n",
            "Epoch 142/1000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 562062.1250 - mae: 611.3246 - val_loss: 243251.3125 - val_mae: 456.6173\n",
            "Epoch 143/1000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 555799.8125 - mae: 607.9613 - val_loss: 249048.6250 - val_mae: 462.0599\n",
            "Epoch 144/1000\n",
            "39/39 [==============================] - 4s 104ms/step - loss: 567850.6250 - mae: 615.9465 - val_loss: 246420.9375 - val_mae: 459.3333\n",
            "Epoch 145/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 563160.5000 - mae: 613.1749 - val_loss: 249086.3750 - val_mae: 461.8008\n",
            "Epoch 146/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 552542.1875 - mae: 608.9521 - val_loss: 247963.2031 - val_mae: 461.3646\n",
            "Epoch 147/1000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 563888.9375 - mae: 613.0755 - val_loss: 244497.5781 - val_mae: 456.8423\n",
            "Epoch 148/1000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 562915.6250 - mae: 613.4330 - val_loss: 244676.2031 - val_mae: 456.8311\n",
            "Epoch 149/1000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 558000.7500 - mae: 610.1492 - val_loss: 245985.4531 - val_mae: 458.8529\n",
            "Epoch 150/1000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 556900.7500 - mae: 612.5517 - val_loss: 243501.7500 - val_mae: 454.4975\n",
            "Epoch 151/1000\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 560973.5625 - mae: 612.7882 - val_loss: 248119.0156 - val_mae: 459.6146\n",
            "Epoch 152/1000\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 565536.5000 - mae: 616.4795 - val_loss: 246185.5000 - val_mae: 458.5366\n",
            "Epoch 153/1000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 554185.6875 - mae: 608.4401 - val_loss: 250064.9844 - val_mae: 463.1146\n",
            "Epoch 154/1000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 548477.4375 - mae: 606.6776 - val_loss: 244590.2969 - val_mae: 454.7343\n",
            "Epoch 155/1000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 559409.6250 - mae: 612.4630 - val_loss: 251149.0156 - val_mae: 463.6771\n",
            "Epoch 156/1000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 557460.5000 - mae: 611.2130 - val_loss: 249048.0625 - val_mae: 459.6146\n",
            "Epoch 157/1000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 554073.4375 - mae: 607.5505 - val_loss: 245914.1719 - val_mae: 456.4514\n",
            "Epoch 158/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 558598.1250 - mae: 610.8314 - val_loss: 245320.9219 - val_mae: 454.6903\n",
            "Epoch 159/1000\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 551293.3750 - mae: 608.7390 - val_loss: 242507.6094 - val_mae: 451.7749\n",
            "Epoch 160/1000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 555057.0625 - mae: 610.5746 - val_loss: 249478.7344 - val_mae: 459.3333\n",
            "Epoch 161/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 561742.2500 - mae: 614.6289 - val_loss: 247371.9531 - val_mae: 456.9695\n",
            "Epoch 162/1000\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 555849.4375 - mae: 611.3094 - val_loss: 245697.5156 - val_mae: 454.3650\n",
            "Epoch 163/1000\n",
            "39/39 [==============================] - 5s 117ms/step - loss: 554014.9375 - mae: 614.0143 - val_loss: 243929.4531 - val_mae: 452.2493\n",
            "Epoch 164/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 559400.8125 - mae: 614.2551 - val_loss: 248678.4531 - val_mae: 458.6871\n",
            "Epoch 165/1000\n",
            "39/39 [==============================] - 8s 203ms/step - loss: 556289.4375 - mae: 612.3111 - val_loss: 254636.3750 - val_mae: 464.3344\n",
            "Epoch 166/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 559260.0625 - mae: 613.5191 - val_loss: 252142.7656 - val_mae: 461.6458\n",
            "Epoch 167/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 556685.9375 - mae: 611.9470 - val_loss: 245397.2500 - val_mae: 453.9107\n",
            "Epoch 168/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 549168.5000 - mae: 610.6270 - val_loss: 244454.2031 - val_mae: 451.8578\n",
            "Epoch 169/1000\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 554210.6250 - mae: 611.7357 - val_loss: 248849.7500 - val_mae: 456.8821\n",
            "Epoch 170/1000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 547919.8125 - mae: 606.7665 - val_loss: 245530.3125 - val_mae: 453.5674\n",
            "Epoch 171/1000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 555191.1875 - mae: 611.3002 - val_loss: 248485.1250 - val_mae: 456.2983\n",
            "Epoch 172/1000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 549074.5000 - mae: 607.9927 - val_loss: 249033.8125 - val_mae: 456.5688\n",
            "Epoch 173/1000\n",
            "39/39 [==============================] - 9s 208ms/step - loss: 550588.4375 - mae: 610.1981 - val_loss: 253678.1406 - val_mae: 460.0763\n",
            "Epoch 174/1000\n",
            "39/39 [==============================] - 8s 201ms/step - loss: 550589.8125 - mae: 608.9687 - val_loss: 252564.1719 - val_mae: 459.6146\n",
            "Epoch 175/1000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 549394.0625 - mae: 609.6930 - val_loss: 248123.0469 - val_mae: 454.2241\n",
            "Epoch 176/1000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 557735.5000 - mae: 615.1955 - val_loss: 253703.6406 - val_mae: 461.3646\n",
            "Epoch 177/1000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 555212.3125 - mae: 611.5059 - val_loss: 252804.2969 - val_mae: 459.3333\n",
            "Epoch 178/1000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 553821.2500 - mae: 611.5692 - val_loss: 257320.1250 - val_mae: 464.4754\n",
            "Epoch 179/1000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 551311.8125 - mae: 611.1359 - val_loss: 245662.1094 - val_mae: 451.0597\n",
            "Epoch 180/1000\n",
            "39/39 [==============================] - 4s 77ms/step - loss: 552466.5000 - mae: 611.9846 - val_loss: 256278.0469 - val_mae: 462.1844\n",
            "Epoch 181/1000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 556740.4375 - mae: 613.8657 - val_loss: 253987.7344 - val_mae: 459.6146\n",
            "Epoch 182/1000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 542224.6875 - mae: 606.4556 - val_loss: 254538.5000 - val_mae: 461.0833\n",
            "Epoch 183/1000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 550395.8125 - mae: 611.7100 - val_loss: 246755.7656 - val_mae: 451.2545\n",
            "Epoch 184/1000\n",
            "39/39 [==============================] - 8s 202ms/step - loss: 551484.5000 - mae: 610.6266 - val_loss: 252400.3750 - val_mae: 458.4698\n",
            "Epoch 185/1000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 549760.1875 - mae: 611.5820 - val_loss: 248219.5469 - val_mae: 453.2407\n",
            "Epoch 186/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 552068.8750 - mae: 612.0247 - val_loss: 251345.0156 - val_mae: 456.1350\n",
            "Epoch 187/1000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 547769.3750 - mae: 609.4213 - val_loss: 255928.5469 - val_mae: 461.3646\n",
            "Epoch 188/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 539976.5625 - mae: 608.1166 - val_loss: 259452.7031 - val_mae: 464.5841\n",
            "Epoch 189/1000\n",
            "39/39 [==============================] - 4s 80ms/step - loss: 544432.6875 - mae: 608.2482 - val_loss: 260736.2344 - val_mae: 466.6260\n",
            "Epoch 190/1000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 552425.4375 - mae: 612.5454 - val_loss: 253541.6719 - val_mae: 458.4055\n",
            "Epoch 191/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 549515.3750 - mae: 612.1600 - val_loss: 256348.7656 - val_mae: 461.0833\n",
            "Epoch 192/1000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 549991.5625 - mae: 611.7241 - val_loss: 254818.1250 - val_mae: 457.3021\n",
            "Epoch 193/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 547125.6250 - mae: 613.2130 - val_loss: 260533.9531 - val_mae: 464.6382\n",
            "Epoch 194/1000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 548421.8125 - mae: 611.1302 - val_loss: 257382.0781 - val_mae: 461.3646\n",
            "Epoch 195/1000\n",
            "39/39 [==============================] - 4s 77ms/step - loss: 552656.8750 - mae: 614.6683 - val_loss: 252415.2500 - val_mae: 454.2881\n",
            "Epoch 196/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 549871.8750 - mae: 612.6445 - val_loss: 256723.8281 - val_mae: 459.3333\n",
            "Epoch 197/1000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 547532.3125 - mae: 610.8669 - val_loss: 252422.5000 - val_mae: 453.9864\n",
            "Epoch 198/1000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 550001.6250 - mae: 612.7017 - val_loss: 255110.7656 - val_mae: 458.3190\n",
            "Epoch 199/1000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 544886.7500 - mae: 610.8261 - val_loss: 257330.2031 - val_mae: 459.3333\n",
            "Epoch 200/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 545072.3125 - mae: 610.0299 - val_loss: 246112.9219 - val_mae: 447.2576\n",
            "Epoch 201/1000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 554132.9375 - mae: 617.5293 - val_loss: 258114.7656 - val_mae: 459.6146\n",
            "Epoch 202/1000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 549615.0625 - mae: 612.7169 - val_loss: 257599.3750 - val_mae: 459.0521\n",
            "Epoch 203/1000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 553938.5625 - mae: 616.2775 - val_loss: 255438.5000 - val_mae: 456.5150\n",
            "Epoch 204/1000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 546782.6250 - mae: 610.6971 - val_loss: 263991.2812 - val_mae: 466.7880\n",
            "Epoch 205/1000\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 552886.3750 - mae: 618.1378 - val_loss: 265134.4688 - val_mae: 465.4922\n",
            "Epoch 206/1000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 547190.8125 - mae: 612.9945 - val_loss: 266527.0000 - val_mae: 467.9088\n",
            "Epoch 207/1000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 539618.3750 - mae: 610.0643 - val_loss: 266764.5312 - val_mae: 467.9306\n",
            "Epoch 208/1000\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 545587.1875 - mae: 613.9385 - val_loss: 257461.5625 - val_mae: 458.4938\n",
            "Epoch 209/1000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 547783.3750 - mae: 613.0894 - val_loss: 259815.8750 - val_mae: 459.6146\n",
            "Epoch 210/1000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 540695.8125 - mae: 610.0942 - val_loss: 264898.7500 - val_mae: 466.5690\n",
            "Epoch 211/1000\n",
            "39/39 [==============================] - 4s 79ms/step - loss: 546686.5625 - mae: 613.0500 - val_loss: 260220.5469 - val_mae: 459.6146\n",
            "Epoch 212/1000\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 544332.8125 - mae: 611.7740 - val_loss: 263276.0000 - val_mae: 462.5271\n",
            "Epoch 213/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 540188.0000 - mae: 609.0480 - val_loss: 257681.2656 - val_mae: 457.8800\n",
            "Epoch 214/1000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 539265.8750 - mae: 610.7826 - val_loss: 261490.8125 - val_mae: 461.3646\n",
            "Epoch 215/1000\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 552636.4375 - mae: 618.4544 - val_loss: 256681.6406 - val_mae: 455.5467\n",
            "Epoch 216/1000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 544669.3750 - mae: 614.3015 - val_loss: 260911.0625 - val_mae: 459.3334\n",
            "Epoch 217/1000\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 550200.1875 - mae: 616.4822 - val_loss: 260753.1875 - val_mae: 459.0521\n",
            "Epoch 218/1000\n",
            "39/39 [==============================] - 9s 209ms/step - loss: 550335.6875 - mae: 616.6309 - val_loss: 261332.9531 - val_mae: 459.3333\n",
            "Epoch 219/1000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 542590.4375 - mae: 612.2758 - val_loss: 269512.3125 - val_mae: 468.1793\n",
            "Epoch 220/1000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 550682.0000 - mae: 617.8776 - val_loss: 265067.9062 - val_mae: 462.6107\n",
            "Epoch 221/1000\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 540143.6250 - mae: 610.9200 - val_loss: 263614.7500 - val_mae: 463.1145\n",
            "Epoch 222/1000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 539860.6250 - mae: 614.4566 - val_loss: 263077.3438 - val_mae: 461.0000\n",
            "Epoch 223/1000\n",
            "39/39 [==============================] - 4s 79ms/step - loss: 540566.0000 - mae: 613.7219 - val_loss: 266092.3438 - val_mae: 462.9218\n",
            "Epoch 224/1000\n",
            "39/39 [==============================] - 9s 207ms/step - loss: 535151.5625 - mae: 608.4177 - val_loss: 264591.9062 - val_mae: 463.3958\n",
            "Epoch 225/1000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 535747.0000 - mae: 609.5728 - val_loss: 266518.6875 - val_mae: 462.9413\n",
            "Epoch 226/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 547255.6875 - mae: 615.6511 - val_loss: 259277.3594 - val_mae: 455.7146\n",
            "Epoch 227/1000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 546474.3750 - mae: 615.9184 - val_loss: 255739.2031 - val_mae: 452.0746\n",
            "Epoch 228/1000\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 544624.3125 - mae: 614.9354 - val_loss: 267212.3438 - val_mae: 462.9730\n",
            "Epoch 229/1000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 539129.4375 - mae: 612.0939 - val_loss: 255142.3906 - val_mae: 450.0017\n",
            "Epoch 230/1000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 528790.0625 - mae: 605.9754 - val_loss: 259737.7031 - val_mae: 455.3911\n",
            "Epoch 231/1000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 549494.2500 - mae: 619.1526 - val_loss: 264731.9688 - val_mae: 461.0833\n",
            "Epoch 232/1000\n",
            "39/39 [==============================] - 10s 239ms/step - loss: 532656.6250 - mae: 610.1614 - val_loss: 263839.4688 - val_mae: 458.6875\n",
            "Epoch 233/1000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 542743.8750 - mae: 613.0220 - val_loss: 261729.0781 - val_mae: 457.6724\n",
            "Epoch 234/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 538957.5625 - mae: 611.5192 - val_loss: 268212.4375 - val_mae: 462.7542\n",
            "Epoch 235/1000\n",
            "39/39 [==============================] - 8s 211ms/step - loss: 545596.3750 - mae: 615.3271 - val_loss: 262915.1562 - val_mae: 458.2139\n",
            "Epoch 236/1000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 542592.7500 - mae: 614.0039 - val_loss: 266582.4062 - val_mae: 461.6458\n",
            "Epoch 237/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 536293.3750 - mae: 610.0435 - val_loss: 257710.5000 - val_mae: 451.8680\n",
            "Epoch 238/1000\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 544502.0625 - mae: 615.3655 - val_loss: 257688.8281 - val_mae: 450.3804\n",
            "Epoch 239/1000\n",
            "39/39 [==============================] - 4s 80ms/step - loss: 540587.6250 - mae: 613.0857 - val_loss: 262356.1875 - val_mae: 455.8621\n",
            "Epoch 240/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 541620.1250 - mae: 613.5106 - val_loss: 267441.4688 - val_mae: 461.6458\n",
            "Epoch 241/1000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 537492.3125 - mae: 611.4196 - val_loss: 275627.3125 - val_mae: 470.6602\n",
            "Epoch 242/1000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 540068.3125 - mae: 613.4846 - val_loss: 266486.1250 - val_mae: 459.3333\n",
            "Epoch 243/1000\n",
            "39/39 [==============================] - 5s 131ms/step - loss: 541736.1875 - mae: 613.7855 - val_loss: 275123.4062 - val_mae: 468.6683\n",
            "Epoch 244/1000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 538666.6875 - mae: 613.4053 - val_loss: 258886.1250 - val_mae: 450.2592\n",
            "Epoch 245/1000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 528422.8750 - mae: 608.0054 - val_loss: 271066.8750 - val_mae: 463.1451\n",
            "Epoch 246/1000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 543498.5000 - mae: 616.5656 - val_loss: 267346.5312 - val_mae: 459.3333\n",
            "Epoch 247/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 536252.9375 - mae: 611.5887 - val_loss: 274373.1562 - val_mae: 469.2581\n",
            "Epoch 248/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 538180.7500 - mae: 612.8077 - val_loss: 263251.2812 - val_mae: 453.7415\n",
            "Epoch 249/1000\n",
            "39/39 [==============================] - 9s 209ms/step - loss: 541499.3750 - mae: 614.9240 - val_loss: 259477.5469 - val_mae: 449.8802\n",
            "Epoch 250/1000\n",
            "39/39 [==============================] - 4s 79ms/step - loss: 536845.6250 - mae: 612.6418 - val_loss: 260630.1719 - val_mae: 451.8912\n",
            "Epoch 251/1000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 543025.4375 - mae: 616.2198 - val_loss: 268828.4688 - val_mae: 459.6146\n",
            "Epoch 252/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 541789.9375 - mae: 615.7905 - val_loss: 274546.3750 - val_mae: 467.2769\n",
            "Epoch 253/1000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 531014.5000 - mae: 609.5041 - val_loss: 261232.7031 - val_mae: 451.8310\n",
            "Epoch 254/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 540165.5625 - mae: 613.9227 - val_loss: 266403.5000 - val_mae: 457.7441\n",
            "Epoch 255/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 528311.0625 - mae: 609.1494 - val_loss: 266126.0312 - val_mae: 457.0878\n",
            "Epoch 256/1000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 541623.5625 - mae: 615.2947 - val_loss: 274151.7500 - val_mae: 465.0052\n",
            "Epoch 257/1000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 530040.1250 - mae: 608.0881 - val_loss: 267042.4688 - val_mae: 457.7138\n",
            "Epoch 258/1000\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 540052.5625 - mae: 616.9192 - val_loss: 269992.1250 - val_mae: 459.3333\n",
            "Epoch 259/1000\n",
            "39/39 [==============================] - 9s 235ms/step - loss: 532041.8125 - mae: 610.7529 - val_loss: 269840.2812 - val_mae: 459.0521\n",
            "Epoch 260/1000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 537192.3750 - mae: 613.8735 - val_loss: 275059.3438 - val_mae: 465.0443\n",
            "Epoch 261/1000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 539562.5625 - mae: 616.1796 - val_loss: 266541.4688 - val_mae: 455.3627\n",
            "Epoch 262/1000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 538169.7500 - mae: 615.0894 - val_loss: 271789.4062 - val_mae: 461.3646\n",
            "Epoch 263/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 530183.1250 - mae: 608.8629 - val_loss: 267353.8438 - val_mae: 455.6244\n",
            "Epoch 264/1000\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 536277.8750 - mae: 613.3074 - val_loss: 263827.7188 - val_mae: 451.8955\n",
            "Epoch 265/1000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 534798.1875 - mae: 612.7778 - val_loss: 270205.2812 - val_mae: 457.0208\n",
            "Epoch 266/1000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 531907.8125 - mae: 613.4467 - val_loss: 271347.6562 - val_mae: 459.0521\n",
            "Epoch 267/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 527410.2500 - mae: 611.7054 - val_loss: 267666.0312 - val_mae: 453.8357\n",
            "Epoch 268/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 530924.1875 - mae: 613.8907 - val_loss: 268378.4062 - val_mae: 455.5771\n",
            "Epoch 269/1000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 534471.1875 - mae: 613.2090 - val_loss: 272401.0625 - val_mae: 459.3333\n",
            "Epoch 270/1000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 531020.6250 - mae: 611.4311 - val_loss: 273506.5938 - val_mae: 461.3646\n",
            "Epoch 271/1000\n",
            "39/39 [==============================] - 8s 203ms/step - loss: 534317.6875 - mae: 613.5370 - val_loss: 268621.0938 - val_mae: 455.2668\n",
            "Epoch 272/1000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 537771.5000 - mae: 616.8763 - val_loss: 269240.7500 - val_mae: 455.5377\n",
            "Epoch 273/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 533503.0625 - mae: 613.0681 - val_loss: 273286.7188 - val_mae: 459.3333\n",
            "Epoch 274/1000\n",
            "39/39 [==============================] - 9s 205ms/step - loss: 536749.2500 - mae: 614.7120 - val_loss: 282483.5312 - val_mae: 469.2763\n",
            "Epoch 275/1000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 539609.8750 - mae: 617.7639 - val_loss: 269874.0938 - val_mae: 455.5090\n",
            "Epoch 276/1000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 538540.1875 - mae: 616.1407 - val_loss: 275759.3750 - val_mae: 463.3958\n",
            "Epoch 277/1000\n",
            "39/39 [==============================] - 5s 101ms/step - loss: 536775.1875 - mae: 616.1777 - val_loss: 274674.1562 - val_mae: 461.0833\n",
            "Epoch 278/1000\n",
            "39/39 [==============================] - 9s 207ms/step - loss: 527343.5625 - mae: 612.0645 - val_loss: 266646.5625 - val_mae: 451.6260\n",
            "Epoch 279/1000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 536292.6250 - mae: 614.9540 - val_loss: 275487.0000 - val_mae: 461.3646\n",
            "Epoch 280/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 537831.0000 - mae: 616.6117 - val_loss: 276020.1562 - val_mae: 461.2812\n",
            "Epoch 281/1000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 535734.1875 - mae: 615.1958 - val_loss: 275966.0000 - val_mae: 461.3646\n",
            "Epoch 282/1000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 534591.8125 - mae: 613.9026 - val_loss: 267059.9375 - val_mae: 451.2689\n",
            "Epoch 283/1000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 527836.3750 - mae: 612.7072 - val_loss: 279467.1562 - val_mae: 463.2358\n",
            "Epoch 284/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 527832.5000 - mae: 610.6627 - val_loss: 280087.0000 - val_mae: 463.5262\n",
            "Epoch 285/1000\n",
            "39/39 [==============================] - 6s 123ms/step - loss: 536510.2500 - mae: 616.1522 - val_loss: 276856.5938 - val_mae: 461.3646\n",
            "Epoch 286/1000\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 525651.5625 - mae: 612.4929 - val_loss: 267495.9062 - val_mae: 450.9101\n",
            "Epoch 287/1000\n",
            "39/39 [==============================] - 5s 100ms/step - loss: 531730.1875 - mae: 613.3262 - val_loss: 277710.9688 - val_mae: 461.6459\n",
            "Epoch 288/1000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 529481.5625 - mae: 614.3733 - val_loss: 282769.6562 - val_mae: 467.6264\n",
            "Epoch 289/1000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 532111.3125 - mae: 614.5349 - val_loss: 277730.0938 - val_mae: 461.3646\n",
            "Epoch 290/1000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 530906.5000 - mae: 613.3728 - val_loss: 277542.3438 - val_mae: 461.0833\n",
            "Epoch 291/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 529943.1250 - mae: 614.1580 - val_loss: 276900.5312 - val_mae: 459.0521\n",
            "Epoch 292/1000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 533946.0000 - mae: 616.8164 - val_loss: 282385.5938 - val_mae: 465.3501\n",
            "Epoch 293/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 535904.8750 - mae: 618.1221 - val_loss: 276891.2812 - val_mae: 457.3021\n",
            "Epoch 294/1000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 534774.1875 - mae: 616.9111 - val_loss: 273850.2812 - val_mae: 454.9635\n",
            "Epoch 295/1000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 532304.9375 - mae: 615.2927 - val_loss: 283091.4688 - val_mae: 465.3787\n",
            "Epoch 296/1000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 532596.5625 - mae: 616.0623 - val_loss: 279288.3750 - val_mae: 461.3646\n",
            "Epoch 297/1000\n",
            "39/39 [==============================] - 9s 208ms/step - loss: 528978.4375 - mae: 615.6487 - val_loss: 279914.2188 - val_mae: 461.6459\n",
            "Epoch 298/1000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 534244.3125 - mae: 617.4688 - val_loss: 273953.4688 - val_mae: 453.2593\n",
            "Epoch 299/1000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 537442.3750 - mae: 618.9806 - val_loss: 268905.1562 - val_mae: 448.3531\n",
            "Epoch 300/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 528327.0625 - mae: 613.4944 - val_loss: 275626.3438 - val_mae: 455.5539\n",
            "Epoch 301/1000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 524662.3750 - mae: 612.4174 - val_loss: 273782.4688 - val_mae: 452.6698\n",
            "Epoch 302/1000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 532362.5000 - mae: 616.7729 - val_loss: 284245.6250 - val_mae: 463.6930\n",
            "Epoch 303/1000\n",
            "39/39 [==============================] - 4s 79ms/step - loss: 529478.3125 - mae: 615.8233 - val_loss: 265993.6562 - val_mae: 444.4743\n",
            "Epoch 304/1000\n",
            "39/39 [==============================] - 5s 131ms/step - loss: 521951.8438 - mae: 612.3863 - val_loss: 281058.6875 - val_mae: 461.3646\n",
            "Epoch 305/1000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 528901.6250 - mae: 615.4492 - val_loss: 281257.7812 - val_mae: 461.3646\n",
            "Epoch 306/1000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 529279.2500 - mae: 614.9627 - val_loss: 284780.2812 - val_mae: 463.4486\n",
            "Epoch 307/1000\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 528745.7500 - mae: 615.9271 - val_loss: 281703.6250 - val_mae: 461.3646\n",
            "Epoch 308/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 533986.5625 - mae: 617.5363 - val_loss: 281511.6250 - val_mae: 461.0833\n",
            "Epoch 309/1000\n",
            "39/39 [==============================] - 4s 79ms/step - loss: 527176.3750 - mae: 614.1461 - val_loss: 281307.2812 - val_mae: 459.3333\n",
            "Epoch 310/1000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 528919.0000 - mae: 615.3666 - val_loss: 281942.2812 - val_mae: 461.0833\n",
            "Epoch 311/1000\n",
            "39/39 [==============================] - 9s 231ms/step - loss: 526600.8125 - mae: 617.2059 - val_loss: 281745.0000 - val_mae: 459.3333\n",
            "Epoch 312/1000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 527931.3125 - mae: 615.0065 - val_loss: 281550.1875 - val_mae: 459.0521\n",
            "Epoch 313/1000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 525118.8750 - mae: 612.2186 - val_loss: 277984.5938 - val_mae: 455.1551\n",
            "Epoch 314/1000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 531591.8125 - mae: 616.7054 - val_loss: 278614.6875 - val_mae: 456.8966\n",
            "Epoch 315/1000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 524550.4375 - mae: 614.1257 - val_loss: 278397.1250 - val_mae: 455.1378\n",
            "Epoch 316/1000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 532381.0625 - mae: 618.3292 - val_loss: 282069.1875 - val_mae: 457.3021\n",
            "Epoch 317/1000\n",
            "39/39 [==============================] - 5s 117ms/step - loss: 522424.7188 - mae: 613.1113 - val_loss: 284731.8125 - val_mae: 463.3958\n",
            "Epoch 318/1000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 525461.3125 - mae: 617.6267 - val_loss: 279853.7188 - val_mae: 457.1425\n",
            "Epoch 319/1000\n",
            "39/39 [==============================] - 5s 102ms/step - loss: 528501.6875 - mae: 618.5197 - val_loss: 283932.9688 - val_mae: 459.6146\n",
            "Epoch 320/1000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 522989.9375 - mae: 613.5050 - val_loss: 278243.4062 - val_mae: 452.7804\n",
            "Epoch 321/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 530775.5000 - mae: 618.6795 - val_loss: 275425.9688 - val_mae: 450.8332\n",
            "Epoch 322/1000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 518824.8750 - mae: 612.0372 - val_loss: 273995.7188 - val_mae: 448.2223\n",
            "Epoch 323/1000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 528112.1875 - mae: 617.0388 - val_loss: 290758.5312 - val_mae: 467.9452\n",
            "Epoch 324/1000\n",
            "39/39 [==============================] - 6s 143ms/step - loss: 531373.1875 - mae: 620.4038 - val_loss: 285791.2188 - val_mae: 462.7500\n",
            "Epoch 325/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 523094.6875 - mae: 615.5278 - val_loss: 280126.2500 - val_mae: 454.7676\n",
            "Epoch 326/1000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 528102.5000 - mae: 617.9573 - val_loss: 280734.5000 - val_mae: 455.0405\n",
            "Epoch 327/1000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 526448.3125 - mae: 616.8737 - val_loss: 276220.5938 - val_mae: 450.4483\n",
            "Epoch 328/1000\n",
            "39/39 [==============================] - 4s 80ms/step - loss: 524417.1250 - mae: 614.7773 - val_loss: 280772.4062 - val_mae: 454.7410\n",
            "Epoch 329/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 528770.2500 - mae: 618.6678 - val_loss: 286537.6562 - val_mae: 461.3646\n",
            "Epoch 330/1000\n",
            "39/39 [==============================] - 6s 135ms/step - loss: 529689.5625 - mae: 619.1370 - val_loss: 287210.9062 - val_mae: 461.6459\n",
            "Epoch 331/1000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 523126.3750 - mae: 615.1486 - val_loss: 286598.0312 - val_mae: 461.0833\n",
            "Epoch 332/1000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 526653.3125 - mae: 618.0298 - val_loss: 281667.9062 - val_mae: 454.7043\n",
            "Epoch 333/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 531603.4375 - mae: 621.0887 - val_loss: 271513.8125 - val_mae: 443.3872\n",
            "Epoch 334/1000\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 533425.0625 - mae: 623.0786 - val_loss: 290488.7500 - val_mae: 461.6672\n",
            "Epoch 335/1000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 525124.8750 - mae: 616.5126 - val_loss: 278716.3438 - val_mae: 450.8676\n",
            "Epoch 336/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 530137.4375 - mae: 619.6848 - val_loss: 283299.0000 - val_mae: 456.7014\n",
            "Epoch 337/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 523263.7812 - mae: 616.3801 - val_loss: 287174.2500 - val_mae: 457.5833\n",
            "Epoch 338/1000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 528817.1250 - mae: 619.9166 - val_loss: 273295.9375 - val_mae: 443.8227\n",
            "Epoch 339/1000\n",
            "39/39 [==============================] - 4s 104ms/step - loss: 521867.7500 - mae: 618.1524 - val_loss: 283963.5938 - val_mae: 455.2068\n",
            "Epoch 340/1000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 531808.1250 - mae: 623.1158 - val_loss: 284152.5312 - val_mae: 456.6666\n",
            "Epoch 341/1000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 524178.7188 - mae: 616.9849 - val_loss: 284012.5938 - val_mae: 454.9071\n",
            "Epoch 342/1000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 521471.5312 - mae: 618.1628 - val_loss: 293160.3438 - val_mae: 463.7686\n",
            "Epoch 343/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 527908.0625 - mae: 619.5111 - val_loss: 294176.7188 - val_mae: 465.8085\n",
            "Epoch 344/1000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 518354.3438 - mae: 615.0726 - val_loss: 274109.3750 - val_mae: 443.3820\n",
            "Epoch 345/1000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 518670.3750 - mae: 614.7589 - val_loss: 275125.6562 - val_mae: 443.9193\n",
            "Epoch 346/1000\n",
            "39/39 [==============================] - 5s 100ms/step - loss: 525001.0000 - mae: 618.3576 - val_loss: 295614.1875 - val_mae: 467.8645\n",
            "Epoch 347/1000\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 522670.8438 - mae: 616.5811 - val_loss: 285292.0938 - val_mae: 454.8559\n",
            "Epoch 348/1000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 519758.8125 - mae: 616.8017 - val_loss: 291586.2188 - val_mae: 463.3959\n",
            "Epoch 349/1000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 528262.3750 - mae: 621.1595 - val_loss: 296655.9688 - val_mae: 467.8076\n",
            "Epoch 350/1000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 522935.8438 - mae: 618.3145 - val_loss: 296225.6562 - val_mae: 466.1506\n",
            "Epoch 351/1000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 526657.0625 - mae: 619.4108 - val_loss: 295686.9688 - val_mae: 464.1278\n",
            "Epoch 352/1000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 529706.5000 - mae: 623.5688 - val_loss: 285978.9375 - val_mae: 454.5311\n",
            "Epoch 353/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 525621.2500 - mae: 619.9370 - val_loss: 285016.3125 - val_mae: 452.2101\n",
            "Epoch 354/1000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 527716.7500 - mae: 621.4630 - val_loss: 281443.0938 - val_mae: 449.6938\n",
            "Epoch 355/1000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 528111.1875 - mae: 622.7376 - val_loss: 281277.5938 - val_mae: 447.9289\n",
            "Epoch 356/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 518940.7188 - mae: 617.5473 - val_loss: 291487.2812 - val_mae: 457.5833\n",
            "Epoch 357/1000\n",
            "39/39 [==============================] - 5s 93ms/step - loss: 521141.6875 - mae: 617.6597 - val_loss: 292464.9688 - val_mae: 459.6146\n",
            "Epoch 358/1000\n",
            "39/39 [==============================] - 6s 127ms/step - loss: 524643.7500 - mae: 620.4989 - val_loss: 286129.0312 - val_mae: 452.1666\n",
            "Epoch 359/1000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 521344.3125 - mae: 618.3267 - val_loss: 296824.4375 - val_mae: 462.1654\n",
            "Epoch 360/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 526498.5000 - mae: 621.6221 - val_loss: 294285.1250 - val_mae: 463.3958\n",
            "Epoch 361/1000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 517283.0312 - mae: 616.8670 - val_loss: 288389.4375 - val_mae: 454.7340\n",
            "Epoch 362/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 522618.3125 - mae: 619.0480 - val_loss: 289002.3438 - val_mae: 455.0075\n",
            "Epoch 363/1000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 522239.1250 - mae: 618.8134 - val_loss: 299248.2812 - val_mae: 466.2611\n",
            "Epoch 364/1000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 515854.2812 - mae: 616.8190 - val_loss: 293325.5312 - val_mae: 457.5833\n",
            "Epoch 365/1000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 518528.9375 - mae: 616.5076 - val_loss: 299274.9062 - val_mae: 465.9959\n",
            "Epoch 366/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 526413.0000 - mae: 622.5029 - val_loss: 283923.4375 - val_mae: 449.4919\n",
            "Epoch 367/1000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 524043.8125 - mae: 621.3908 - val_loss: 284548.1562 - val_mae: 449.7563\n",
            "Epoch 368/1000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 515357.0312 - mae: 617.8257 - val_loss: 279303.4062 - val_mae: 443.0558\n",
            "Epoch 369/1000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 517797.4375 - mae: 620.5895 - val_loss: 284223.6562 - val_mae: 447.6919\n",
            "Epoch 370/1000\n",
            "39/39 [==============================] - 5s 113ms/step - loss: 520088.4688 - mae: 617.1553 - val_loss: 285242.4688 - val_mae: 448.2397\n",
            "Epoch 371/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 519715.6875 - mae: 618.4805 - val_loss: 290154.0938 - val_mae: 452.9034\n",
            "Epoch 372/1000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 524012.5000 - mae: 622.3674 - val_loss: 296118.9375 - val_mae: 461.3646\n",
            "Epoch 373/1000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 525213.3125 - mae: 621.5195 - val_loss: 301083.8125 - val_mae: 466.0610\n",
            "Epoch 374/1000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 517781.7500 - mae: 617.1211 - val_loss: 295417.7500 - val_mae: 459.0521\n",
            "Epoch 375/1000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 523802.0938 - mae: 621.1501 - val_loss: 291684.4062 - val_mae: 454.5369\n",
            "Epoch 376/1000\n",
            "39/39 [==============================] - 9s 209ms/step - loss: 520718.3125 - mae: 619.7390 - val_loss: 291560.3438 - val_mae: 454.6118\n",
            "Epoch 377/1000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 521201.7812 - mae: 619.7275 - val_loss: 297989.2812 - val_mae: 463.3958\n",
            "Epoch 378/1000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 520826.8125 - mae: 621.4135 - val_loss: 286069.0312 - val_mae: 447.5461\n",
            "Epoch 379/1000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 519905.1562 - mae: 620.1537 - val_loss: 297675.3438 - val_mae: 461.3646\n",
            "Epoch 380/1000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 522773.4375 - mae: 621.8782 - val_loss: 301940.4688 - val_mae: 464.0859\n",
            "Epoch 381/1000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 524224.7812 - mae: 623.1289 - val_loss: 292179.2188 - val_mae: 454.2911\n",
            "Epoch 382/1000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 518794.0312 - mae: 620.7592 - val_loss: 292405.2812 - val_mae: 454.2826\n",
            "Epoch 383/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 517833.1875 - mae: 619.0930 - val_loss: 299280.2812 - val_mae: 463.3958\n",
            "Epoch 384/1000\n",
            "39/39 [==============================] - 9s 232ms/step - loss: 520328.0625 - mae: 619.1124 - val_loss: 304662.9062 - val_mae: 468.4604\n",
            "Epoch 385/1000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 525660.1875 - mae: 624.3767 - val_loss: 293429.3750 - val_mae: 454.5410\n",
            "Epoch 386/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 521596.7188 - mae: 620.9521 - val_loss: 298484.7500 - val_mae: 459.3333\n",
            "Epoch 387/1000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 518433.6250 - mae: 619.7989 - val_loss: 304249.4688 - val_mae: 466.1733\n",
            "Epoch 388/1000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 522687.9375 - mae: 621.3030 - val_loss: 304895.0312 - val_mae: 466.4624\n",
            "Epoch 389/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 519644.1875 - mae: 620.4568 - val_loss: 294987.3438 - val_mae: 456.5403\n",
            "Epoch 390/1000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 515122.6562 - mae: 618.7775 - val_loss: 300388.0938 - val_mae: 461.2812\n",
            "Epoch 391/1000\n",
            "39/39 [==============================] - 5s 100ms/step - loss: 516468.5625 - mae: 619.2711 - val_loss: 299159.1562 - val_mae: 459.0521\n",
            "Epoch 392/1000\n",
            "39/39 [==============================] - 5s 131ms/step - loss: 521600.4062 - mae: 622.7458 - val_loss: 293351.7188 - val_mae: 451.8922\n",
            "Epoch 393/1000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 524963.3125 - mae: 625.2100 - val_loss: 289821.4062 - val_mae: 449.3402\n",
            "Epoch 394/1000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 514151.2812 - mae: 617.3916 - val_loss: 295320.7188 - val_mae: 454.4702\n",
            "Epoch 395/1000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 517045.5000 - mae: 620.3766 - val_loss: 300036.6562 - val_mae: 459.0521\n",
            "Epoch 396/1000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 522294.6250 - mae: 622.2233 - val_loss: 312348.8125 - val_mae: 473.4392\n",
            "Epoch 397/1000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 517740.9688 - mae: 620.5159 - val_loss: 295138.9062 - val_mae: 453.8831\n",
            "Epoch 398/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 521284.9062 - mae: 623.2090 - val_loss: 310724.3438 - val_mae: 467.3760\n",
            "Epoch 399/1000\n",
            "39/39 [==============================] - 6s 131ms/step - loss: 517321.5312 - mae: 619.3236 - val_loss: 308768.8750 - val_mae: 470.6117\n",
            "Epoch 400/1000\n",
            "39/39 [==============================] - 5s 113ms/step - loss: 520331.7188 - mae: 622.4629 - val_loss: 307647.9688 - val_mae: 466.5582\n",
            "Epoch 401/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 522829.4375 - mae: 625.0580 - val_loss: 300725.2812 - val_mae: 457.0208\n",
            "Epoch 402/1000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 512319.2812 - mae: 619.2504 - val_loss: 292124.3125 - val_mae: 449.4769\n",
            "Epoch 403/1000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 524812.2500 - mae: 626.3916 - val_loss: 302702.0938 - val_mae: 459.6146\n",
            "Epoch 404/1000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 518477.2188 - mae: 622.4614 - val_loss: 297777.8438 - val_mae: 456.1391\n",
            "Epoch 405/1000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 517636.9688 - mae: 620.6523 - val_loss: 297281.6250 - val_mae: 454.1010\n",
            "Epoch 406/1000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 520482.8125 - mae: 623.6605 - val_loss: 299024.5938 - val_mae: 456.6869\n",
            "Epoch 407/1000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 512652.0312 - mae: 617.9696 - val_loss: 298108.7188 - val_mae: 454.3675\n",
            "Epoch 408/1000\n",
            "39/39 [==============================] - 5s 100ms/step - loss: 517370.2500 - mae: 620.9050 - val_loss: 297642.2812 - val_mae: 452.3285\n",
            "Epoch 409/1000\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 510416.7812 - mae: 619.5086 - val_loss: 304627.0938 - val_mae: 461.6458\n",
            "Epoch 410/1000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 520053.9688 - mae: 623.6698 - val_loss: 316188.3438 - val_mae: 475.6823\n",
            "Epoch 411/1000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 517787.7500 - mae: 620.7903 - val_loss: 303954.5312 - val_mae: 459.3333\n",
            "Epoch 412/1000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 514281.0938 - mae: 620.4810 - val_loss: 315354.2188 - val_mae: 471.6538\n",
            "Epoch 413/1000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 516504.9375 - mae: 621.7336 - val_loss: 303939.2812 - val_mae: 459.0521\n",
            "Epoch 414/1000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 516827.0312 - mae: 621.4977 - val_loss: 299102.9062 - val_mae: 454.0345\n",
            "Epoch 415/1000\n",
            "39/39 [==============================] - 5s 99ms/step - loss: 512485.0312 - mae: 620.8384 - val_loss: 306568.3750 - val_mae: 463.6771\n",
            "Epoch 416/1000\n",
            "39/39 [==============================] - 6s 141ms/step - loss: 518030.5938 - mae: 623.1299 - val_loss: 310032.5312 - val_mae: 464.3646\n",
            "Epoch 417/1000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 519355.4062 - mae: 623.0984 - val_loss: 300096.9062 - val_mae: 454.2953\n",
            "Epoch 418/1000\n",
            "39/39 [==============================] - 4s 104ms/step - loss: 519449.6250 - mae: 623.6708 - val_loss: 300353.8438 - val_mae: 454.2860\n",
            "Epoch 419/1000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 516301.9062 - mae: 621.3403 - val_loss: 306699.6562 - val_mae: 461.6458\n",
            "Epoch 420/1000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 524029.9688 - mae: 628.0026 - val_loss: 295161.8438 - val_mae: 448.5649\n",
            "Epoch 421/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 519912.6875 - mae: 624.4060 - val_loss: 311590.7812 - val_mae: 464.6839\n",
            "Epoch 422/1000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 518988.5625 - mae: 623.8545 - val_loss: 305837.5312 - val_mae: 459.0521\n",
            "Epoch 423/1000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 522011.8750 - mae: 626.6046 - val_loss: 307110.0938 - val_mae: 461.3646\n",
            "Epoch 424/1000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 514532.7500 - mae: 620.2784 - val_loss: 311558.0625 - val_mae: 462.6734\n",
            "Epoch 425/1000\n",
            "39/39 [==============================] - 4s 77ms/step - loss: 512483.1250 - mae: 619.8400 - val_loss: 305795.6250 - val_mae: 457.0208\n",
            "Epoch 426/1000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 523022.0625 - mae: 626.9458 - val_loss: 300884.2188 - val_mae: 451.9157\n",
            "Epoch 427/1000\n",
            "39/39 [==============================] - 9s 234ms/step - loss: 517614.2500 - mae: 623.9374 - val_loss: 301303.3750 - val_mae: 453.6587\n",
            "Epoch 428/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 516268.8125 - mae: 623.4272 - val_loss: 303031.9375 - val_mae: 456.2445\n",
            "Epoch 429/1000\n",
            "39/39 [==============================] - 5s 102ms/step - loss: 513534.6250 - mae: 620.7733 - val_loss: 308396.2188 - val_mae: 461.3646\n",
            "Epoch 430/1000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 515883.5625 - mae: 623.0626 - val_loss: 308834.3125 - val_mae: 463.1146\n",
            "Epoch 431/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 519422.1250 - mae: 625.0845 - val_loss: 320257.9688 - val_mae: 473.9624\n",
            "Epoch 432/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 510541.5312 - mae: 619.6056 - val_loss: 307967.6250 - val_mae: 459.0521\n",
            "Epoch 433/1000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 516499.9688 - mae: 624.8851 - val_loss: 320075.3438 - val_mae: 471.9610\n",
            "Epoch 434/1000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 514747.0312 - mae: 622.5130 - val_loss: 308808.5938 - val_mae: 459.3333\n",
            "Epoch 435/1000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 516950.8125 - mae: 624.1961 - val_loss: 309677.1562 - val_mae: 461.3646\n",
            "Epoch 436/1000\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 514017.1875 - mae: 621.5135 - val_loss: 314912.5000 - val_mae: 464.7941\n",
            "Epoch 437/1000\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 519903.7812 - mae: 627.0325 - val_loss: 303811.9688 - val_mae: 453.8661\n",
            "Epoch 438/1000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 519835.2812 - mae: 626.0403 - val_loss: 310120.3750 - val_mae: 459.6146\n",
            "Epoch 439/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 518246.0625 - mae: 627.0283 - val_loss: 304007.9062 - val_mae: 452.1021\n",
            "Epoch 440/1000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 513244.7500 - mae: 621.2018 - val_loss: 309439.4688 - val_mae: 457.3021\n",
            "Epoch 441/1000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 519460.8750 - mae: 626.1931 - val_loss: 305058.4688 - val_mae: 454.1187\n",
            "Epoch 442/1000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 517622.1250 - mae: 623.8629 - val_loss: 304393.2812 - val_mae: 453.5493\n",
            "Epoch 443/1000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 505699.7500 - mae: 618.7789 - val_loss: 317011.5938 - val_mae: 466.8736\n",
            "Epoch 444/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 517532.5938 - mae: 625.6290 - val_loss: 317428.3438 - val_mae: 468.6309\n",
            "Epoch 445/1000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 519779.1250 - mae: 626.4240 - val_loss: 299075.8438 - val_mae: 446.2558\n",
            "Epoch 446/1000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 519844.3438 - mae: 626.3958 - val_loss: 305387.4688 - val_mae: 452.0541\n",
            "Epoch 447/1000\n",
            "39/39 [==============================] - 9s 207ms/step - loss: 512955.9688 - mae: 621.9691 - val_loss: 306208.9688 - val_mae: 454.0785\n",
            "Epoch 448/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 516117.5938 - mae: 625.8420 - val_loss: 316992.9062 - val_mae: 464.5951\n",
            "Epoch 449/1000\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 520459.7500 - mae: 627.9905 - val_loss: 312107.0000 - val_mae: 461.0833\n",
            "Epoch 450/1000\n",
            "39/39 [==============================] - 5s 118ms/step - loss: 513703.1562 - mae: 623.6061 - val_loss: 301519.1875 - val_mae: 448.7806\n",
            "Epoch 451/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 515909.3438 - mae: 624.9865 - val_loss: 312972.5312 - val_mae: 461.3646\n",
            "Epoch 452/1000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 513327.9062 - mae: 623.8834 - val_loss: 318427.9062 - val_mae: 466.2900\n",
            "Epoch 453/1000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 515787.4375 - mae: 625.9377 - val_loss: 307618.6562 - val_mae: 455.7858\n",
            "Epoch 454/1000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 511280.3750 - mae: 623.7101 - val_loss: 312964.4688 - val_mae: 459.3333\n",
            "Epoch 455/1000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 519894.1250 - mae: 628.8135 - val_loss: 306315.4062 - val_mae: 451.4297\n",
            "Epoch 456/1000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 509771.5625 - mae: 622.5145 - val_loss: 319758.0312 - val_mae: 466.9633\n",
            "Epoch 457/1000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 515996.6562 - mae: 625.4306 - val_loss: 307998.3438 - val_mae: 452.2604\n",
            "Epoch 458/1000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 515390.5312 - mae: 625.2309 - val_loss: 314727.3438 - val_mae: 461.2812\n",
            "Epoch 459/1000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 502546.5000 - mae: 620.2006 - val_loss: 302168.2500 - val_mae: 446.3471\n",
            "Epoch 460/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 510799.2188 - mae: 622.5275 - val_loss: 314759.3750 - val_mae: 461.3646\n",
            "Epoch 461/1000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 517879.6250 - mae: 627.7091 - val_loss: 314768.5938 - val_mae: 459.6146\n",
            "Epoch 462/1000\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 514210.0312 - mae: 625.9534 - val_loss: 326966.4375 - val_mae: 474.3907\n",
            "Epoch 463/1000\n",
            "39/39 [==============================] - 4s 80ms/step - loss: 510128.6875 - mae: 622.2717 - val_loss: 309786.5312 - val_mae: 454.2512\n",
            "Epoch 464/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 519114.7812 - mae: 629.3063 - val_loss: 314502.9688 - val_mae: 459.0521\n",
            "Epoch 465/1000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 516683.8750 - mae: 626.6958 - val_loss: 309154.2188 - val_mae: 451.9249\n",
            "Epoch 466/1000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 504201.2500 - mae: 620.4199 - val_loss: 322383.9062 - val_mae: 469.0600\n",
            "Epoch 467/1000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 511716.9688 - mae: 623.5698 - val_loss: 321366.9375 - val_mae: 465.0032\n",
            "Epoch 468/1000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 515012.8750 - mae: 625.4975 - val_loss: 297994.8438 - val_mae: 440.5501\n",
            "Epoch 469/1000\n",
            "39/39 [==============================] - 5s 113ms/step - loss: 509394.2500 - mae: 623.8620 - val_loss: 322991.3438 - val_mae: 469.0796\n",
            "Epoch 470/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 505557.3750 - mae: 622.6446 - val_loss: 328624.7500 - val_mae: 474.1329\n",
            "Epoch 471/1000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 493341.7500 - mae: 616.5859 - val_loss: 317908.1562 - val_mae: 463.3125\n",
            "Epoch 472/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 514306.4062 - mae: 626.3270 - val_loss: 315510.4062 - val_mae: 457.0208\n",
            "Epoch 473/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 514765.2812 - mae: 625.4582 - val_loss: 330451.5312 - val_mae: 478.5975\n",
            "Epoch 474/1000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 515827.9688 - mae: 627.7354 - val_loss: 323006.0312 - val_mae: 466.8005\n",
            "Epoch 475/1000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 511500.7500 - mae: 623.8321 - val_loss: 311675.7812 - val_mae: 453.8908\n",
            "Epoch 476/1000\n",
            "39/39 [==============================] - 5s 100ms/step - loss: 512061.8125 - mae: 624.5064 - val_loss: 316922.2188 - val_mae: 459.0521\n",
            "Epoch 477/1000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 516349.2188 - mae: 628.2155 - val_loss: 319154.3125 - val_mae: 463.6771\n",
            "Epoch 478/1000\n",
            "39/39 [==============================] - 9s 207ms/step - loss: 513659.1250 - mae: 625.4854 - val_loss: 306359.1250 - val_mae: 448.1253\n",
            "Epoch 479/1000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 510226.6250 - mae: 624.0228 - val_loss: 300397.4688 - val_mae: 440.6182\n",
            "Epoch 480/1000\n",
            "39/39 [==============================] - 5s 99ms/step - loss: 516964.1875 - mae: 628.8182 - val_loss: 306583.9062 - val_mae: 446.3498\n",
            "Epoch 481/1000\n",
            "39/39 [==============================] - 4s 79ms/step - loss: 516534.8125 - mae: 629.3798 - val_loss: 311995.1875 - val_mae: 453.2880\n",
            "Epoch 482/1000\n",
            "39/39 [==============================] - 5s 99ms/step - loss: 510109.8438 - mae: 623.9260 - val_loss: 314074.0938 - val_mae: 456.1567\n",
            "Epoch 483/1000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 511223.5938 - mae: 626.3327 - val_loss: 318763.9062 - val_mae: 459.3333\n",
            "Epoch 484/1000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 512202.6562 - mae: 625.1033 - val_loss: 319557.2812 - val_mae: 461.3645\n",
            "Epoch 485/1000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 511299.2500 - mae: 624.6608 - val_loss: 307655.2188 - val_mae: 448.0351\n",
            "Epoch 486/1000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 515190.8438 - mae: 628.6022 - val_loss: 313980.9062 - val_mae: 455.5677\n",
            "Epoch 487/1000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 514980.3438 - mae: 627.6808 - val_loss: 308034.6875 - val_mae: 448.0088\n",
            "Epoch 488/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 512578.3438 - mae: 626.1309 - val_loss: 327042.8438 - val_mae: 470.9548\n",
            "Epoch 489/1000\n",
            "39/39 [==============================] - 4s 79ms/step - loss: 514305.3125 - mae: 627.7265 - val_loss: 320439.5938 - val_mae: 459.6146\n",
            "Epoch 490/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 510787.9062 - mae: 624.7674 - val_loss: 320257.5938 - val_mae: 461.0833\n",
            "Epoch 491/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 512513.3750 - mae: 626.0980 - val_loss: 320310.5000 - val_mae: 459.3333\n",
            "Epoch 492/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 515569.5625 - mae: 628.5541 - val_loss: 321691.4062 - val_mae: 463.3958\n",
            "Epoch 493/1000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 515289.7188 - mae: 628.0692 - val_loss: 320941.4062 - val_mae: 461.0833\n",
            "Epoch 494/1000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 515011.5625 - mae: 628.9573 - val_loss: 307929.1250 - val_mae: 445.3228\n",
            "Epoch 495/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 516297.7812 - mae: 629.5683 - val_loss: 316135.5938 - val_mae: 455.7915\n",
            "Epoch 496/1000\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 514346.3438 - mae: 628.3086 - val_loss: 316313.6562 - val_mae: 455.7856\n",
            "Epoch 497/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 516418.6562 - mae: 629.6320 - val_loss: 320552.6250 - val_mae: 457.0208\n",
            "Epoch 498/1000\n",
            "39/39 [==============================] - 6s 127ms/step - loss: 511495.5312 - mae: 625.8519 - val_loss: 315254.5938 - val_mae: 453.1791\n",
            "Epoch 499/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 515530.8125 - mae: 628.9940 - val_loss: 329141.3438 - val_mae: 469.2750\n",
            "Epoch 500/1000\n",
            "39/39 [==============================] - 5s 95ms/step - loss: 513446.9688 - mae: 627.9880 - val_loss: 322713.7188 - val_mae: 461.3646\n",
            "Epoch 501/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 510706.3125 - mae: 626.7339 - val_loss: 316715.0938 - val_mae: 453.7225\n",
            "Epoch 502/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 513912.6875 - mae: 627.8871 - val_loss: 328761.7812 - val_mae: 466.9817\n",
            "Epoch 503/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 516281.0938 - mae: 630.9362 - val_loss: 317118.2188 - val_mae: 453.7093\n",
            "Epoch 504/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 508937.3125 - mae: 624.3723 - val_loss: 322954.4688 - val_mae: 459.3333\n",
            "Epoch 505/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 512423.4688 - mae: 627.9684 - val_loss: 329249.1562 - val_mae: 465.2502\n",
            "Epoch 506/1000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 515669.9062 - mae: 628.8499 - val_loss: 322798.5312 - val_mae: 457.3021\n",
            "Epoch 507/1000\n",
            "39/39 [==============================] - 5s 99ms/step - loss: 513931.6562 - mae: 627.5637 - val_loss: 317904.9688 - val_mae: 453.6834\n",
            "Epoch 508/1000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 515543.5938 - mae: 630.8868 - val_loss: 304409.9688 - val_mae: 439.2074\n",
            "Epoch 509/1000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 511406.0000 - mae: 627.4396 - val_loss: 330717.6562 - val_mae: 469.0567\n",
            "Epoch 510/1000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 511663.7812 - mae: 627.1669 - val_loss: 331384.1875 - val_mae: 469.3449\n",
            "Epoch 511/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 515966.2812 - mae: 629.6985 - val_loss: 330570.8125 - val_mae: 467.0377\n",
            "Epoch 512/1000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 514369.7188 - mae: 630.1355 - val_loss: 318269.5312 - val_mae: 451.6227\n",
            "Epoch 513/1000\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 516514.9375 - mae: 631.1019 - val_loss: 319021.4375 - val_mae: 453.6470\n",
            "Epoch 514/1000\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 514522.5000 - mae: 629.2616 - val_loss: 324960.4062 - val_mae: 459.3333\n",
            "Epoch 515/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 509651.6562 - mae: 626.3333 - val_loss: 318942.7500 - val_mae: 453.3538\n",
            "Epoch 516/1000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 509159.8438 - mae: 625.8898 - val_loss: 326355.6562 - val_mae: 463.3958\n",
            "Epoch 517/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 514864.0625 - mae: 629.5911 - val_loss: 325453.2188 - val_mae: 459.3333\n",
            "Epoch 518/1000\n",
            "39/39 [==============================] - 5s 101ms/step - loss: 514768.0938 - mae: 630.0455 - val_loss: 318919.7188 - val_mae: 451.3060\n",
            "Epoch 519/1000\n",
            "39/39 [==============================] - 9s 209ms/step - loss: 507765.2812 - mae: 625.8999 - val_loss: 325872.9062 - val_mae: 459.3333\n",
            "Epoch 520/1000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 507134.4375 - mae: 627.0522 - val_loss: 319814.9688 - val_mae: 453.3254\n",
            "Epoch 521/1000\n",
            "39/39 [==============================] - 9s 209ms/step - loss: 512898.3438 - mae: 630.0049 - val_loss: 332340.2500 - val_mae: 464.9812\n",
            "Epoch 522/1000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 515724.5938 - mae: 631.9277 - val_loss: 314330.9062 - val_mae: 445.8247\n",
            "Epoch 523/1000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 509284.6562 - mae: 630.0046 - val_loss: 326610.8438 - val_mae: 459.3333\n",
            "Epoch 524/1000\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 508900.0312 - mae: 626.5278 - val_loss: 327302.7500 - val_mae: 461.0000\n",
            "Epoch 525/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 512479.5312 - mae: 629.2537 - val_loss: 326956.3125 - val_mae: 459.3333\n",
            "Epoch 526/1000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 516015.0000 - mae: 631.8655 - val_loss: 321891.4062 - val_mae: 455.6022\n",
            "Epoch 527/1000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 513156.1875 - mae: 629.4987 - val_loss: 315275.0000 - val_mae: 447.5172\n",
            "Epoch 528/1000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 512661.5938 - mae: 630.1285 - val_loss: 327488.2812 - val_mae: 459.3333\n",
            "Epoch 529/1000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 514593.1875 - mae: 631.7387 - val_loss: 328110.0000 - val_mae: 459.6146\n",
            "Epoch 530/1000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 509585.8438 - mae: 626.1346 - val_loss: 321086.2188 - val_mae: 452.9888\n",
            "Epoch 531/1000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 514196.8125 - mae: 630.8683 - val_loss: 322226.0312 - val_mae: 455.2957\n",
            "Epoch 532/1000\n",
            "39/39 [==============================] - 5s 101ms/step - loss: 507651.4062 - mae: 627.6009 - val_loss: 321940.5938 - val_mae: 455.0092\n",
            "Epoch 533/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 508092.5625 - mae: 628.0585 - val_loss: 340442.9688 - val_mae: 471.2119\n",
            "Epoch 534/1000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 511144.4062 - mae: 628.4570 - val_loss: 315863.2188 - val_mae: 447.1672\n",
            "Epoch 535/1000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 513516.2500 - mae: 631.8315 - val_loss: 329113.7812 - val_mae: 461.3646\n",
            "Epoch 536/1000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 512928.2188 - mae: 629.7377 - val_loss: 336629.7188 - val_mae: 471.5214\n",
            "Epoch 537/1000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 511491.8750 - mae: 628.4860 - val_loss: 342704.1562 - val_mae: 477.3479\n",
            "Epoch 538/1000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 515276.4062 - mae: 631.6202 - val_loss: 316994.7188 - val_mae: 447.4032\n",
            "Epoch 539/1000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 507011.5625 - mae: 626.7823 - val_loss: 329365.8438 - val_mae: 459.3333\n",
            "Epoch 540/1000\n",
            "39/39 [==============================] - 4s 78ms/step - loss: 512970.6250 - mae: 630.4252 - val_loss: 329590.8438 - val_mae: 461.0833\n",
            "Epoch 541/1000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 507566.7500 - mae: 626.6923 - val_loss: 335076.4688 - val_mae: 463.1434\n",
            "Epoch 542/1000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 514457.9375 - mae: 632.3426 - val_loss: 324949.3125 - val_mae: 455.7993\n",
            "Epoch 543/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 513528.0625 - mae: 631.4785 - val_loss: 343324.4688 - val_mae: 475.3832\n",
            "Epoch 544/1000\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 512921.8750 - mae: 631.1705 - val_loss: 323936.2812 - val_mae: 454.9449\n",
            "Epoch 545/1000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 501121.0000 - mae: 625.1973 - val_loss: 330393.3125 - val_mae: 459.3333\n",
            "Epoch 546/1000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 512086.2188 - mae: 629.8857 - val_loss: 324627.1562 - val_mae: 453.4667\n",
            "Epoch 547/1000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 511586.9375 - mae: 629.4616 - val_loss: 337542.7188 - val_mae: 467.5172\n",
            "Epoch 548/1000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 509134.6250 - mae: 628.4536 - val_loss: 330897.0000 - val_mae: 461.0833\n",
            "Epoch 549/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 513359.5938 - mae: 632.0563 - val_loss: 331552.9375 - val_mae: 461.3646\n",
            "Epoch 550/1000\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 513061.8438 - mae: 631.4363 - val_loss: 338063.0938 - val_mae: 467.5328\n",
            "Epoch 551/1000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 512991.0625 - mae: 632.8446 - val_loss: 319456.7500 - val_mae: 447.5522\n",
            "Epoch 552/1000\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 514105.7188 - mae: 631.8378 - val_loss: 325631.5312 - val_mae: 455.1864\n",
            "Epoch 553/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 512069.5312 - mae: 630.5708 - val_loss: 325728.0938 - val_mae: 453.4319\n",
            "Epoch 554/1000\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 496266.9688 - mae: 624.8828 - val_loss: 339222.0938 - val_mae: 469.5839\n",
            "Epoch 555/1000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 508144.7812 - mae: 628.4924 - val_loss: 331904.1562 - val_mae: 457.5833\n",
            "Epoch 556/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 511723.4062 - mae: 630.5569 - val_loss: 332192.2812 - val_mae: 461.0833\n",
            "Epoch 557/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 510015.2812 - mae: 630.0106 - val_loss: 319469.2812 - val_mae: 445.1775\n",
            "Epoch 558/1000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 511504.4062 - mae: 630.1680 - val_loss: 326520.2188 - val_mae: 451.6556\n",
            "Epoch 559/1000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 503117.8438 - mae: 626.8826 - val_loss: 319368.8438 - val_mae: 446.6261\n",
            "Epoch 560/1000\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 509807.7812 - mae: 629.5998 - val_loss: 320863.3438 - val_mae: 447.4607\n",
            "Epoch 561/1000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 508049.4062 - mae: 627.8771 - val_loss: 333907.9688 - val_mae: 461.2812\n",
            "Epoch 562/1000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 509905.2500 - mae: 629.7580 - val_loss: 327156.5938 - val_mae: 451.6357\n",
            "Epoch 563/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 513939.0938 - mae: 633.3981 - val_loss: 340239.0312 - val_mae: 467.5976\n",
            "Epoch 564/1000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 513968.3750 - mae: 632.9399 - val_loss: 327009.0312 - val_mae: 451.3451\n",
            "Epoch 565/1000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 503397.1250 - mae: 626.7160 - val_loss: 326725.5938 - val_mae: 452.8096\n",
            "Epoch 566/1000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 512621.8438 - mae: 630.8051 - val_loss: 334328.2188 - val_mae: 463.1146\n",
            "Epoch 567/1000\n",
            "39/39 [==============================] - 6s 135ms/step - loss: 509475.8750 - mae: 630.8502 - val_loss: 327979.5312 - val_mae: 453.3612\n",
            "Epoch 568/1000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 510130.8750 - mae: 630.4523 - val_loss: 334654.8750 - val_mae: 461.3646\n",
            "Epoch 569/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 512029.5312 - mae: 632.0331 - val_loss: 334831.8438 - val_mae: 461.3646\n",
            "Epoch 570/1000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 508587.5000 - mae: 628.7927 - val_loss: 328510.5312 - val_mae: 455.0955\n",
            "Epoch 571/1000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 513303.1562 - mae: 633.0867 - val_loss: 322161.0938 - val_mae: 447.0663\n",
            "Epoch 572/1000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 513951.0625 - mae: 633.1730 - val_loss: 328376.5312 - val_mae: 453.0534\n",
            "Epoch 573/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 505857.6875 - mae: 628.1240 - val_loss: 329048.5938 - val_mae: 455.0785\n",
            "Epoch 574/1000\n",
            "39/39 [==============================] - 5s 131ms/step - loss: 510898.7188 - mae: 631.1489 - val_loss: 341763.6250 - val_mae: 467.3747\n",
            "Epoch 575/1000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 502876.8750 - mae: 628.6651 - val_loss: 322410.2812 - val_mae: 446.7400\n",
            "Epoch 576/1000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 508493.1250 - mae: 629.5785 - val_loss: 336458.8750 - val_mae: 461.6458\n",
            "Epoch 577/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 504947.8750 - mae: 630.2092 - val_loss: 328690.4062 - val_mae: 452.3829\n",
            "Epoch 578/1000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 511008.7812 - mae: 631.3335 - val_loss: 315810.4062 - val_mae: 438.3746\n",
            "Epoch 579/1000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 499605.8438 - mae: 626.8281 - val_loss: 343043.8750 - val_mae: 467.6802\n",
            "Epoch 580/1000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 511997.9062 - mae: 632.3397 - val_loss: 337131.5938 - val_mae: 463.3958\n",
            "Epoch 581/1000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 508580.5000 - mae: 630.0080 - val_loss: 335945.0000 - val_mae: 459.0521\n",
            "Epoch 582/1000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 508712.4688 - mae: 629.6408 - val_loss: 329019.5938 - val_mae: 450.6923\n",
            "Epoch 583/1000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 510027.9062 - mae: 631.2746 - val_loss: 330118.7812 - val_mae: 452.9994\n",
            "Epoch 584/1000\n",
            "39/39 [==============================] - 5s 98ms/step - loss: 507317.4375 - mae: 629.3106 - val_loss: 330711.0000 - val_mae: 453.2763\n",
            "Epoch 585/1000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 512506.4688 - mae: 633.2027 - val_loss: 330433.8438 - val_mae: 452.9896\n",
            "Epoch 586/1000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 512230.3750 - mae: 632.5356 - val_loss: 345105.3125 - val_mae: 471.7758\n",
            "Epoch 587/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 507922.6250 - mae: 630.6448 - val_loss: 324213.3438 - val_mae: 444.8741\n",
            "Epoch 588/1000\n",
            "39/39 [==============================] - 4s 80ms/step - loss: 512364.0938 - mae: 633.5742 - val_loss: 331895.7500 - val_mae: 453.5351\n",
            "Epoch 589/1000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 509756.8125 - mae: 632.3954 - val_loss: 344239.1562 - val_mae: 465.6973\n",
            "Epoch 590/1000\n",
            "39/39 [==============================] - 4s 79ms/step - loss: 511308.7188 - mae: 632.9860 - val_loss: 351520.9688 - val_mae: 475.8562\n",
            "Epoch 591/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 510589.8125 - mae: 631.7096 - val_loss: 332332.1875 - val_mae: 454.9065\n",
            "Epoch 592/1000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 509239.6250 - mae: 630.6392 - val_loss: 331538.8125 - val_mae: 451.2055\n",
            "Epoch 593/1000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 511881.1875 - mae: 633.8034 - val_loss: 331748.4688 - val_mae: 451.1991\n",
            "Epoch 594/1000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 507597.2812 - mae: 630.1777 - val_loss: 345542.2812 - val_mae: 469.5030\n",
            "Epoch 595/1000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 513189.4375 - mae: 633.7695 - val_loss: 339097.6562 - val_mae: 461.3646\n",
            "Epoch 596/1000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 510888.8438 - mae: 632.6666 - val_loss: 332224.3438 - val_mae: 451.1846\n",
            "Epoch 597/1000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 507328.8750 - mae: 630.2943 - val_loss: 345596.6250 - val_mae: 467.4866\n",
            "Epoch 598/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 512038.4375 - mae: 633.4202 - val_loss: 332946.9688 - val_mae: 453.2076\n",
            "Epoch 599/1000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 507416.9375 - mae: 631.2004 - val_loss: 326515.0000 - val_mae: 445.0392\n",
            "Epoch 600/1000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 502446.0000 - mae: 628.7508 - val_loss: 333707.7812 - val_mae: 455.2294\n",
            "Epoch 601/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 511028.0312 - mae: 632.8155 - val_loss: 339617.9688 - val_mae: 459.3333\n",
            "Epoch 602/1000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 506274.0000 - mae: 629.9172 - val_loss: 326492.6875 - val_mae: 444.7307\n",
            "Epoch 603/1000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 509728.5625 - mae: 632.7886 - val_loss: 339913.4688 - val_mae: 459.3333\n",
            "Epoch 604/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 505034.0938 - mae: 629.2769 - val_loss: 340558.5000 - val_mae: 461.3646\n",
            "Epoch 605/1000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 506610.9688 - mae: 631.8889 - val_loss: 347330.7812 - val_mae: 467.4408\n",
            "Epoch 606/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 507802.7188 - mae: 631.5104 - val_loss: 340777.0938 - val_mae: 463.1146\n",
            "Epoch 607/1000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 508783.3750 - mae: 631.7892 - val_loss: 333862.5625 - val_mae: 452.8845\n",
            "Epoch 608/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 505237.3750 - mae: 632.5571 - val_loss: 340670.6250 - val_mae: 457.5834\n",
            "Epoch 609/1000\n",
            "39/39 [==============================] - 5s 98ms/step - loss: 511030.4688 - mae: 632.7323 - val_loss: 353675.9688 - val_mae: 471.9656\n",
            "Epoch 610/1000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 506070.7500 - mae: 629.3783 - val_loss: 327579.1250 - val_mae: 446.4120\n",
            "Epoch 611/1000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 507729.1875 - mae: 631.1735 - val_loss: 347748.7500 - val_mae: 467.5487\n",
            "Epoch 612/1000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 508716.8750 - mae: 632.0263 - val_loss: 340836.7812 - val_mae: 459.0521\n",
            "Epoch 613/1000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 504880.1562 - mae: 628.5197 - val_loss: 334747.3438 - val_mae: 452.8577\n",
            "Epoch 614/1000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 504490.7188 - mae: 630.8301 - val_loss: 334906.2188 - val_mae: 451.1034\n",
            "Epoch 615/1000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 510625.9375 - mae: 633.4787 - val_loss: 328785.0625 - val_mae: 444.8977\n",
            "Epoch 616/1000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 510976.4688 - mae: 632.7865 - val_loss: 341853.1562 - val_mae: 459.3333\n",
            "Epoch 617/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 503117.3750 - mae: 629.5549 - val_loss: 334814.1562 - val_mae: 450.8112\n",
            "Epoch 618/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 504772.5938 - mae: 629.6667 - val_loss: 329596.2812 - val_mae: 446.9057\n",
            "Epoch 619/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 504571.2500 - mae: 630.5974 - val_loss: 341833.8438 - val_mae: 459.0521\n",
            "Epoch 620/1000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 503031.2812 - mae: 629.6360 - val_loss: 336565.8750 - val_mae: 455.1421\n",
            "Epoch 621/1000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 509883.1875 - mae: 632.8428 - val_loss: 322871.4062 - val_mae: 438.3391\n",
            "Epoch 622/1000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 511531.9688 - mae: 635.3826 - val_loss: 336026.9062 - val_mae: 451.0698\n",
            "Epoch 623/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 506688.0000 - mae: 631.4165 - val_loss: 350841.4688 - val_mae: 471.9431\n",
            "Epoch 624/1000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 506646.0625 - mae: 630.8066 - val_loss: 342484.1562 - val_mae: 459.0521\n",
            "Epoch 625/1000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 510677.9688 - mae: 635.2336 - val_loss: 343598.7188 - val_mae: 459.6146\n",
            "Epoch 626/1000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 511682.7188 - mae: 634.7061 - val_loss: 344161.1562 - val_mae: 461.6458\n",
            "Epoch 627/1000\n",
            "39/39 [==============================] - 5s 100ms/step - loss: 508942.8125 - mae: 632.8246 - val_loss: 343844.2188 - val_mae: 461.3646\n",
            "Epoch 628/1000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 504538.8750 - mae: 629.4017 - val_loss: 343532.4688 - val_mae: 459.3333\n",
            "Epoch 629/1000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 510783.6875 - mae: 633.9472 - val_loss: 336010.3438 - val_mae: 450.4803\n",
            "Epoch 630/1000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 513473.3125 - mae: 637.1648 - val_loss: 344285.9688 - val_mae: 459.6146\n",
            "Epoch 631/1000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 504950.0000 - mae: 630.5627 - val_loss: 344454.3125 - val_mae: 461.3646\n",
            "Epoch 632/1000\n",
            "39/39 [==============================] - 4s 79ms/step - loss: 503253.8125 - mae: 631.9167 - val_loss: 350829.5000 - val_mae: 467.6367\n",
            "Epoch 633/1000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 508438.8438 - mae: 631.8571 - val_loss: 344718.2188 - val_mae: 461.3646\n",
            "Epoch 634/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 508543.7500 - mae: 632.9200 - val_loss: 344856.1250 - val_mae: 461.3646\n",
            "Epoch 635/1000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 505076.6562 - mae: 630.3618 - val_loss: 338635.7500 - val_mae: 455.0796\n",
            "Epoch 636/1000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 503047.3125 - mae: 630.4160 - val_loss: 331145.7812 - val_mae: 444.4425\n",
            "Epoch 637/1000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 507127.7500 - mae: 632.4500 - val_loss: 331261.4062 - val_mae: 444.4355\n",
            "Epoch 638/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 508775.6250 - mae: 632.7793 - val_loss: 339006.9688 - val_mae: 455.0685\n",
            "Epoch 639/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 509471.8438 - mae: 634.2499 - val_loss: 338712.8438 - val_mae: 453.0335\n",
            "Epoch 640/1000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 507786.8750 - mae: 633.5240 - val_loss: 351960.6250 - val_mae: 465.9176\n",
            "Epoch 641/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 509929.6250 - mae: 634.5433 - val_loss: 345298.5938 - val_mae: 459.3333\n",
            "Epoch 642/1000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 513120.4062 - mae: 636.8577 - val_loss: 331825.1562 - val_mae: 444.4010\n",
            "Epoch 643/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 516377.0938 - mae: 640.2710 - val_loss: 338756.5312 - val_mae: 450.9885\n",
            "Epoch 644/1000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 507341.0625 - mae: 632.1510 - val_loss: 332963.1875 - val_mae: 446.6975\n",
            "Epoch 645/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 502848.7188 - mae: 631.3476 - val_loss: 352569.0938 - val_mae: 467.6859\n",
            "Epoch 646/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 512132.4062 - mae: 635.8323 - val_loss: 352749.1562 - val_mae: 467.6910\n",
            "Epoch 647/1000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 503712.0000 - mae: 629.5139 - val_loss: 346526.6562 - val_mae: 459.6146\n",
            "Epoch 648/1000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 512897.4688 - mae: 636.8163 - val_loss: 339803.1875 - val_mae: 453.0010\n",
            "Epoch 649/1000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 509465.8438 - mae: 633.3599 - val_loss: 345896.2812 - val_mae: 457.3021\n",
            "Epoch 650/1000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 509870.1250 - mae: 633.9758 - val_loss: 332382.7188 - val_mae: 444.0576\n",
            "Epoch 651/1000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 511908.7188 - mae: 636.1949 - val_loss: 333446.9688 - val_mae: 444.6115\n",
            "Epoch 652/1000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 511050.1875 - mae: 635.2635 - val_loss: 341245.7812 - val_mae: 455.2965\n",
            "Epoch 653/1000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 508698.5625 - mae: 632.9965 - val_loss: 347737.2188 - val_mae: 461.6458\n",
            "Epoch 654/1000\n",
            "39/39 [==============================] - 5s 101ms/step - loss: 508689.7812 - mae: 633.9518 - val_loss: 346977.7500 - val_mae: 461.0833\n",
            "Epoch 655/1000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 508768.8750 - mae: 633.5594 - val_loss: 340775.3438 - val_mae: 452.9722\n",
            "Epoch 656/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 507946.0000 - mae: 634.6686 - val_loss: 340864.0312 - val_mae: 452.9696\n",
            "Epoch 657/1000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 503815.1562 - mae: 631.1142 - val_loss: 346938.5625 - val_mae: 459.0521\n",
            "Epoch 658/1000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 504336.4688 - mae: 632.9573 - val_loss: 348378.3750 - val_mae: 463.3958\n",
            "Epoch 659/1000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 507188.9062 - mae: 633.2710 - val_loss: 334852.2812 - val_mae: 446.5820\n",
            "Epoch 660/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 507942.5312 - mae: 632.8431 - val_loss: 347470.7188 - val_mae: 457.3020\n",
            "Epoch 661/1000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 507313.6875 - mae: 632.5616 - val_loss: 355182.7812 - val_mae: 469.7794\n",
            "Epoch 662/1000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 506834.5625 - mae: 632.1605 - val_loss: 340771.2812 - val_mae: 450.6343\n",
            "Epoch 663/1000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 506694.1562 - mae: 632.5688 - val_loss: 349024.3125 - val_mae: 463.3958\n",
            "Epoch 664/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 507504.6250 - mae: 633.5812 - val_loss: 342297.9688 - val_mae: 454.9703\n",
            "Epoch 665/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 510109.6875 - mae: 635.0888 - val_loss: 356141.6250 - val_mae: 470.0746\n",
            "Epoch 666/1000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 509526.5312 - mae: 634.7513 - val_loss: 348153.2188 - val_mae: 459.0521\n",
            "Epoch 667/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 508517.1875 - mae: 634.4461 - val_loss: 349192.1875 - val_mae: 461.3646\n",
            "Epoch 668/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 509110.4375 - mae: 635.0383 - val_loss: 341993.4375 - val_mae: 452.6414\n",
            "Epoch 669/1000\n",
            "39/39 [==============================] - 6s 129ms/step - loss: 502373.6875 - mae: 631.1618 - val_loss: 341756.1250 - val_mae: 450.6054\n",
            "Epoch 670/1000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 508447.6250 - mae: 634.2090 - val_loss: 349190.1250 - val_mae: 459.3853\n",
            "Epoch 671/1000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 509445.5000 - mae: 635.3802 - val_loss: 349337.0938 - val_mae: 457.6934\n",
            "Epoch 672/1000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 507344.7812 - mae: 633.6239 - val_loss: 342515.2188 - val_mae: 451.0622\n",
            "Epoch 673/1000\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 499721.1562 - mae: 631.0385 - val_loss: 336119.7188 - val_mae: 446.4715\n",
            "Epoch 674/1000\n",
            "39/39 [==============================] - 4s 80ms/step - loss: 511614.8125 - mae: 636.5189 - val_loss: 349270.9688 - val_mae: 457.6938\n",
            "Epoch 675/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 510142.5938 - mae: 635.4822 - val_loss: 342806.8438 - val_mae: 454.8269\n",
            "Epoch 676/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 507198.0000 - mae: 633.9416 - val_loss: 342105.5312 - val_mae: 450.8628\n",
            "Epoch 677/1000\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 505075.7188 - mae: 634.2155 - val_loss: 350874.9688 - val_mae: 462.2388\n",
            "Epoch 678/1000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 500487.0000 - mae: 631.4821 - val_loss: 350145.6562 - val_mae: 460.0382\n",
            "Epoch 679/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 509108.4062 - mae: 635.0504 - val_loss: 336430.1562 - val_mae: 444.9380\n",
            "Epoch 680/1000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 509192.3125 - mae: 634.6166 - val_loss: 350365.2188 - val_mae: 460.1878\n",
            "Epoch 681/1000\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 508794.5625 - mae: 635.3689 - val_loss: 344021.4688 - val_mae: 453.8346\n",
            "Epoch 682/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 504140.1875 - mae: 631.7312 - val_loss: 337623.9062 - val_mae: 447.4426\n",
            "Epoch 683/1000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 512808.0000 - mae: 638.1638 - val_loss: 358873.0000 - val_mae: 473.1454\n",
            "Epoch 684/1000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 506598.8438 - mae: 633.4108 - val_loss: 344441.5000 - val_mae: 452.3635\n",
            "Epoch 685/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 503911.3750 - mae: 632.2430 - val_loss: 357940.3438 - val_mae: 467.3480\n",
            "Epoch 686/1000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 508169.5625 - mae: 634.9692 - val_loss: 351921.0312 - val_mae: 462.9247\n",
            "Epoch 687/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 504713.8438 - mae: 632.6533 - val_loss: 350749.8438 - val_mae: 458.7376\n",
            "Epoch 688/1000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 508156.8750 - mae: 634.0695 - val_loss: 344721.9062 - val_mae: 454.3044\n",
            "Epoch 689/1000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 509249.4688 - mae: 635.1915 - val_loss: 350963.5000 - val_mae: 460.6301\n",
            "Epoch 690/1000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 506060.0312 - mae: 633.7452 - val_loss: 344663.3438 - val_mae: 452.5598\n",
            "Epoch 691/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 506311.9062 - mae: 633.7002 - val_loss: 344246.0625 - val_mae: 454.0470\n",
            "Epoch 692/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 501027.5938 - mae: 631.1309 - val_loss: 351411.4062 - val_mae: 459.2028\n",
            "Epoch 693/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 509032.2188 - mae: 635.1254 - val_loss: 338015.6562 - val_mae: 446.0275\n",
            "Epoch 694/1000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 506168.2188 - mae: 633.6099 - val_loss: 338990.2188 - val_mae: 448.3444\n",
            "Epoch 695/1000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 500722.4688 - mae: 630.4739 - val_loss: 352547.0000 - val_mae: 463.3567\n",
            "Epoch 696/1000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 508299.9375 - mae: 635.6748 - val_loss: 345687.6875 - val_mae: 454.9503\n",
            "Epoch 697/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 507363.4062 - mae: 634.1193 - val_loss: 338399.0938 - val_mae: 446.2899\n",
            "Epoch 698/1000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 510968.8438 - mae: 637.5897 - val_loss: 339361.9062 - val_mae: 448.5887\n",
            "Epoch 699/1000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 510717.5312 - mae: 637.3572 - val_loss: 345996.0000 - val_mae: 455.1560\n",
            "Epoch 700/1000\n",
            "39/39 [==============================] - 6s 129ms/step - loss: 501946.8750 - mae: 632.7363 - val_loss: 345712.5000 - val_mae: 453.2868\n",
            "Epoch 701/1000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 509486.2812 - mae: 636.9388 - val_loss: 346283.2500 - val_mae: 453.6401\n",
            "Epoch 702/1000\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 502997.3438 - mae: 632.9721 - val_loss: 331393.7500 - val_mae: 439.5393\n",
            "Epoch 703/1000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 503429.5000 - mae: 634.2097 - val_loss: 353333.4062 - val_mae: 463.8689\n",
            "Epoch 704/1000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 507057.0000 - mae: 635.4643 - val_loss: 346037.6562 - val_mae: 455.2134\n",
            "Epoch 705/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 508437.1875 - mae: 635.7671 - val_loss: 346162.2500 - val_mae: 455.2964\n",
            "Epoch 706/1000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 505922.2500 - mae: 635.2546 - val_loss: 353791.6250 - val_mae: 462.4747\n",
            "Epoch 707/1000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 506892.9062 - mae: 635.0854 - val_loss: 340311.8438 - val_mae: 449.2118\n",
            "Epoch 708/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 505639.9062 - mae: 633.6083 - val_loss: 353924.2500 - val_mae: 464.2528\n",
            "Epoch 709/1000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 500089.6875 - mae: 632.2756 - val_loss: 346965.4688 - val_mae: 457.4867\n",
            "Epoch 710/1000\n",
            "39/39 [==============================] - 5s 98ms/step - loss: 501927.6875 - mae: 631.9529 - val_loss: 346838.2500 - val_mae: 454.0636\n",
            "Epoch 711/1000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 510100.2812 - mae: 637.4528 - val_loss: 354172.7500 - val_mae: 464.4140\n",
            "Epoch 712/1000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 506621.6562 - mae: 634.3962 - val_loss: 333768.1562 - val_mae: 441.0370\n",
            "Epoch 713/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 496281.2500 - mae: 630.2293 - val_loss: 354770.5000 - val_mae: 466.4545\n",
            "Epoch 714/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 506336.6250 - mae: 633.3619 - val_loss: 340898.5938 - val_mae: 449.5953\n",
            "Epoch 715/1000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 509021.0625 - mae: 635.5464 - val_loss: 332621.4688 - val_mae: 440.3646\n",
            "Epoch 716/1000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 506259.1875 - mae: 634.6982 - val_loss: 354633.3438 - val_mae: 464.7124\n",
            "Epoch 717/1000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 499312.0625 - mae: 631.6545 - val_loss: 347899.0938 - val_mae: 454.7528\n",
            "Epoch 718/1000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 506659.0938 - mae: 635.3466 - val_loss: 340461.7500 - val_mae: 447.6946\n",
            "Epoch 719/1000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 505243.8125 - mae: 634.3262 - val_loss: 354702.7188 - val_mae: 461.4565\n",
            "Epoch 720/1000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 508482.0938 - mae: 634.9872 - val_loss: 348100.0312 - val_mae: 456.5531\n",
            "Epoch 721/1000\n",
            "39/39 [==============================] - 9s 233ms/step - loss: 506172.1250 - mae: 634.5022 - val_loss: 354430.4688 - val_mae: 461.3113\n",
            "Epoch 722/1000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 505155.3438 - mae: 633.9905 - val_loss: 355369.7812 - val_mae: 463.5347\n",
            "Epoch 723/1000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 501275.4062 - mae: 631.4072 - val_loss: 348025.6875 - val_mae: 454.8794\n",
            "Epoch 724/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 507150.0000 - mae: 634.5659 - val_loss: 355501.5312 - val_mae: 465.2735\n",
            "Epoch 725/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 506431.3125 - mae: 635.8319 - val_loss: 362260.0938 - val_mae: 471.9468\n",
            "Epoch 726/1000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 507502.0000 - mae: 635.9486 - val_loss: 348307.8750 - val_mae: 456.7186\n",
            "Epoch 727/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 505957.8438 - mae: 634.1404 - val_loss: 341271.6562 - val_mae: 449.8861\n",
            "Epoch 728/1000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 509157.5938 - mae: 636.6779 - val_loss: 342310.5000 - val_mae: 450.5146\n",
            "Epoch 729/1000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 508621.5000 - mae: 636.1255 - val_loss: 355701.7188 - val_mae: 463.7889\n",
            "Epoch 730/1000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 511871.1250 - mae: 639.7014 - val_loss: 362839.2188 - val_mae: 472.3255\n",
            "Epoch 731/1000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 501361.7812 - mae: 631.5798 - val_loss: 370756.8438 - val_mae: 482.7796\n",
            "Epoch 732/1000\n",
            "39/39 [==============================] - 5s 106ms/step - loss: 501354.6562 - mae: 632.8665 - val_loss: 349385.9062 - val_mae: 457.4014\n",
            "Epoch 733/1000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 504875.2812 - mae: 634.0509 - val_loss: 349001.9688 - val_mae: 457.1761\n",
            "Epoch 734/1000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 511878.9688 - mae: 638.7117 - val_loss: 363751.0938 - val_mae: 472.8957\n",
            "Epoch 735/1000\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 499306.7188 - mae: 632.9464 - val_loss: 348855.1562 - val_mae: 455.4863\n",
            "Epoch 736/1000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 497753.4062 - mae: 631.3489 - val_loss: 364302.7500 - val_mae: 474.6936\n",
            "Epoch 737/1000\n",
            "39/39 [==============================] - 9s 234ms/step - loss: 501110.6875 - mae: 632.8267 - val_loss: 349406.7500 - val_mae: 457.4425\n",
            "Epoch 738/1000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 513356.2500 - mae: 640.7915 - val_loss: 350011.7500 - val_mae: 457.8127\n",
            "Epoch 739/1000\n",
            "39/39 [==============================] - 9s 233ms/step - loss: 509272.5312 - mae: 638.2304 - val_loss: 356739.1562 - val_mae: 466.0905\n",
            "Epoch 740/1000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 504043.9062 - mae: 633.5648 - val_loss: 350217.9688 - val_mae: 457.9481\n",
            "Epoch 741/1000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 507329.4062 - mae: 635.4444 - val_loss: 356897.5938 - val_mae: 466.1921\n",
            "Epoch 742/1000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 513591.0625 - mae: 641.5259 - val_loss: 357106.8750 - val_mae: 464.7257\n",
            "Epoch 743/1000\n",
            "39/39 [==============================] - 5s 113ms/step - loss: 502117.7500 - mae: 635.0804 - val_loss: 342934.2812 - val_mae: 450.9641\n",
            "Epoch 744/1000\n",
            "39/39 [==============================] - 4s 81ms/step - loss: 508336.8438 - mae: 636.8924 - val_loss: 349760.3438 - val_mae: 457.7018\n",
            "Epoch 745/1000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 509201.0312 - mae: 637.9077 - val_loss: 350294.5000 - val_mae: 458.0251\n",
            "Epoch 746/1000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 505150.2188 - mae: 634.4809 - val_loss: 351344.4062 - val_mae: 458.6594\n",
            "Epoch 747/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 505365.3438 - mae: 634.5151 - val_loss: 357528.9688 - val_mae: 466.5967\n",
            "Epoch 748/1000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 507870.6875 - mae: 635.6469 - val_loss: 357754.1562 - val_mae: 465.1556\n",
            "Epoch 749/1000\n",
            "39/39 [==============================] - 5s 114ms/step - loss: 505759.8438 - mae: 635.7379 - val_loss: 351119.6562 - val_mae: 458.5387\n",
            "Epoch 750/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 508137.3125 - mae: 636.7230 - val_loss: 358385.0938 - val_mae: 465.5433\n",
            "Epoch 751/1000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 504081.2500 - mae: 633.2728 - val_loss: 358758.0312 - val_mae: 468.9211\n",
            "Epoch 752/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 506671.7812 - mae: 635.9522 - val_loss: 343834.6250 - val_mae: 451.4378\n",
            "Epoch 753/1000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 506106.8750 - mae: 635.9987 - val_loss: 358604.3438 - val_mae: 467.2645\n",
            "Epoch 754/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 501817.8750 - mae: 633.9767 - val_loss: 351168.9062 - val_mae: 458.5971\n",
            "Epoch 755/1000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 507310.0000 - mae: 636.8745 - val_loss: 359257.2500 - val_mae: 467.6620\n",
            "Epoch 756/1000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 506945.0000 - mae: 635.5209 - val_loss: 359359.6562 - val_mae: 467.7271\n",
            "Epoch 757/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 509139.2500 - mae: 638.1690 - val_loss: 351340.2812 - val_mae: 460.2743\n",
            "Epoch 758/1000\n",
            "39/39 [==============================] - 5s 100ms/step - loss: 506819.4375 - mae: 636.3442 - val_loss: 352056.3438 - val_mae: 459.1501\n",
            "Epoch 759/1000\n",
            "39/39 [==============================] - 9s 207ms/step - loss: 505270.6875 - mae: 636.4701 - val_loss: 344521.4375 - val_mae: 451.9867\n",
            "Epoch 760/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 506336.5625 - mae: 636.0891 - val_loss: 358818.4062 - val_mae: 467.4200\n",
            "Epoch 761/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 510533.8125 - mae: 639.2577 - val_loss: 351749.0938 - val_mae: 460.5308\n",
            "Epoch 762/1000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 498653.4375 - mae: 634.6384 - val_loss: 366532.1250 - val_mae: 476.2537\n",
            "Epoch 763/1000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 500956.2500 - mae: 633.3513 - val_loss: 358880.2812 - val_mae: 464.3782\n",
            "Epoch 764/1000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 507624.0625 - mae: 636.9808 - val_loss: 359773.5938 - val_mae: 466.4611\n",
            "Epoch 765/1000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 511233.7188 - mae: 639.7263 - val_loss: 352020.6562 - val_mae: 460.7010\n",
            "Epoch 766/1000\n",
            "39/39 [==============================] - 10s 230ms/step - loss: 505915.0312 - mae: 636.4348 - val_loss: 374118.5312 - val_mae: 483.3975\n",
            "Epoch 767/1000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 505412.4375 - mae: 636.3414 - val_loss: 366249.5938 - val_mae: 473.0190\n",
            "Epoch 768/1000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 508330.3125 - mae: 637.8991 - val_loss: 352872.3438 - val_mae: 459.6809\n",
            "Epoch 769/1000\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 497106.9375 - mae: 631.6281 - val_loss: 352466.7812 - val_mae: 459.4427\n",
            "Epoch 770/1000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 510083.0312 - mae: 639.0345 - val_loss: 352607.8750 - val_mae: 459.5344\n",
            "Epoch 771/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 504308.0938 - mae: 635.4920 - val_loss: 353095.4062 - val_mae: 459.8258\n",
            "Epoch 772/1000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 509417.6875 - mae: 638.2194 - val_loss: 360487.4062 - val_mae: 466.9312\n",
            "Epoch 773/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 501422.1562 - mae: 633.4867 - val_loss: 352890.5000 - val_mae: 459.7179\n",
            "Epoch 774/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 512191.3125 - mae: 640.2708 - val_loss: 353028.9688 - val_mae: 458.2774\n",
            "Epoch 775/1000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 506963.1250 - mae: 635.8431 - val_loss: 361029.0000 - val_mae: 468.7874\n",
            "Epoch 776/1000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 511386.6562 - mae: 640.3585 - val_loss: 353900.8438 - val_mae: 461.8485\n",
            "Epoch 777/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 506549.5000 - mae: 636.6929 - val_loss: 354091.4062 - val_mae: 460.4467\n",
            "Epoch 778/1000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 507252.7500 - mae: 637.9323 - val_loss: 360154.2188 - val_mae: 465.2475\n",
            "Epoch 779/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 504762.0000 - mae: 635.1386 - val_loss: 346225.1562 - val_mae: 451.5591\n",
            "Epoch 780/1000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 499305.7812 - mae: 633.2098 - val_loss: 368581.3438 - val_mae: 477.5134\n",
            "Epoch 781/1000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 501945.6250 - mae: 633.2305 - val_loss: 346663.0938 - val_mae: 453.3363\n",
            "Epoch 782/1000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 508246.0000 - mae: 636.9888 - val_loss: 361592.7188 - val_mae: 469.1440\n",
            "Epoch 783/1000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 508290.5000 - mae: 637.1824 - val_loss: 361562.6250 - val_mae: 470.6349\n",
            "Epoch 784/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 504786.6250 - mae: 635.9986 - val_loss: 353991.0312 - val_mae: 461.9177\n",
            "Epoch 785/1000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 504165.1875 - mae: 635.4995 - val_loss: 354276.5000 - val_mae: 460.5908\n",
            "Epoch 786/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 506486.8438 - mae: 637.3776 - val_loss: 368361.4688 - val_mae: 474.3929\n",
            "Epoch 787/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 509577.4688 - mae: 638.6425 - val_loss: 368828.5000 - val_mae: 476.1770\n",
            "Epoch 788/1000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 504869.1875 - mae: 635.1224 - val_loss: 353500.9688 - val_mae: 460.1383\n",
            "Epoch 789/1000\n",
            "39/39 [==============================] - 4s 80ms/step - loss: 507399.5938 - mae: 637.5020 - val_loss: 354046.1250 - val_mae: 460.4662\n",
            "Epoch 790/1000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 504647.2188 - mae: 636.0919 - val_loss: 346912.2188 - val_mae: 453.5149\n",
            "Epoch 791/1000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 504453.5312 - mae: 636.1733 - val_loss: 368286.3438 - val_mae: 474.3759\n",
            "Epoch 792/1000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 504400.2188 - mae: 635.6074 - val_loss: 361908.4062 - val_mae: 469.3607\n",
            "Epoch 793/1000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 502778.3438 - mae: 636.8975 - val_loss: 348098.8438 - val_mae: 454.2301\n",
            "Epoch 794/1000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 503694.2812 - mae: 634.9058 - val_loss: 376228.3750 - val_mae: 483.3244\n",
            "Epoch 795/1000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 506800.0625 - mae: 636.9225 - val_loss: 354087.8750 - val_mae: 460.5176\n",
            "Epoch 796/1000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 505875.8750 - mae: 636.5031 - val_loss: 362780.6562 - val_mae: 469.8933\n",
            "Epoch 797/1000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 508570.8750 - mae: 637.9698 - val_loss: 362400.0000 - val_mae: 469.6705\n",
            "Epoch 798/1000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 511448.3125 - mae: 640.4219 - val_loss: 347612.3438 - val_mae: 453.9598\n",
            "Epoch 799/1000\n",
            "39/39 [==============================] - 5s 101ms/step - loss: 503541.4375 - mae: 635.3134 - val_loss: 355441.4062 - val_mae: 461.3420\n",
            "Epoch 800/1000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 505853.2188 - mae: 636.5551 - val_loss: 369497.0938 - val_mae: 476.6264\n",
            "Epoch 801/1000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 503871.9375 - mae: 635.0718 - val_loss: 363269.2500 - val_mae: 470.2006\n",
            "Epoch 802/1000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 506679.4375 - mae: 637.5851 - val_loss: 347582.9375 - val_mae: 452.4880\n",
            "Epoch 803/1000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 508791.6250 - mae: 637.6720 - val_loss: 362768.7812 - val_mae: 471.3722\n",
            "Epoch 804/1000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 508979.1875 - mae: 638.0910 - val_loss: 361826.5938 - val_mae: 466.4225\n",
            "Epoch 805/1000\n",
            "39/39 [==============================] - 10s 231ms/step - loss: 503824.5312 - mae: 635.1523 - val_loss: 363041.8750 - val_mae: 470.0742\n",
            "Epoch 806/1000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 509068.4062 - mae: 639.2876 - val_loss: 348775.8750 - val_mae: 453.2118\n",
            "Epoch 807/1000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 501824.2188 - mae: 636.3748 - val_loss: 370446.4062 - val_mae: 477.2110\n",
            "Epoch 808/1000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 497060.7188 - mae: 634.1606 - val_loss: 363503.9688 - val_mae: 471.8113\n",
            "Epoch 809/1000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 508454.2188 - mae: 638.6657 - val_loss: 355687.1562 - val_mae: 461.5236\n",
            "Epoch 810/1000\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 498864.0000 - mae: 632.4778 - val_loss: 362582.3438 - val_mae: 468.3601\n",
            "Epoch 811/1000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 500493.6875 - mae: 634.3375 - val_loss: 370418.0312 - val_mae: 475.7547\n",
            "Epoch 812/1000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 500459.4375 - mae: 635.6797 - val_loss: 348547.8438 - val_mae: 454.5522\n",
            "Epoch 813/1000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 508769.7812 - mae: 638.6630 - val_loss: 356110.0000 - val_mae: 460.3394\n",
            "Epoch 814/1000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 505220.7500 - mae: 636.1743 - val_loss: 355990.4062 - val_mae: 461.7183\n",
            "Epoch 815/1000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 503473.2500 - mae: 634.8672 - val_loss: 370592.9062 - val_mae: 477.3253\n",
            "Epoch 816/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 503846.9062 - mae: 634.6842 - val_loss: 357139.9688 - val_mae: 462.4093\n",
            "Epoch 817/1000\n",
            "39/39 [==============================] - 5s 112ms/step - loss: 500980.4062 - mae: 635.0782 - val_loss: 349355.8750 - val_mae: 455.0443\n",
            "Epoch 818/1000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 509003.5625 - mae: 638.8565 - val_loss: 363795.9062 - val_mae: 467.6737\n",
            "Epoch 819/1000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 505414.2188 - mae: 637.3489 - val_loss: 356516.7188 - val_mae: 460.6099\n",
            "Epoch 820/1000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 492749.9062 - mae: 631.5055 - val_loss: 356485.0312 - val_mae: 462.0354\n",
            "Epoch 821/1000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 507320.5625 - mae: 637.4558 - val_loss: 364686.7188 - val_mae: 471.0891\n",
            "Epoch 822/1000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 512972.2812 - mae: 643.0971 - val_loss: 378828.0000 - val_mae: 486.4196\n",
            "Epoch 823/1000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 499469.6875 - mae: 633.5914 - val_loss: 371247.3750 - val_mae: 477.7415\n",
            "Epoch 824/1000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 505245.4375 - mae: 636.0254 - val_loss: 371981.5000 - val_mae: 481.0351\n",
            "Epoch 825/1000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 512108.8750 - mae: 642.7693 - val_loss: 357350.5938 - val_mae: 462.5666\n",
            "Epoch 826/1000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 504376.9375 - mae: 635.7711 - val_loss: 357000.5312 - val_mae: 462.3653\n",
            "Epoch 827/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 506123.9688 - mae: 636.9550 - val_loss: 356989.1250 - val_mae: 462.3579\n",
            "Epoch 828/1000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 509982.6875 - mae: 639.6328 - val_loss: 364315.5000 - val_mae: 470.8886\n",
            "Epoch 829/1000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 507154.1875 - mae: 637.9670 - val_loss: 350486.7500 - val_mae: 454.3328\n",
            "Epoch 830/1000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 508490.9688 - mae: 639.6071 - val_loss: 358254.0000 - val_mae: 463.1211\n",
            "Epoch 831/1000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 508560.8750 - mae: 639.7183 - val_loss: 379581.5938 - val_mae: 486.8875\n",
            "Epoch 832/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 506695.6875 - mae: 638.6912 - val_loss: 357892.9062 - val_mae: 462.9128\n",
            "Epoch 833/1000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 513148.5000 - mae: 643.1925 - val_loss: 350750.6250 - val_mae: 454.5050\n",
            "Epoch 834/1000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 507337.7812 - mae: 637.9401 - val_loss: 380122.6562 - val_mae: 488.6232\n",
            "Epoch 835/1000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 501333.8438 - mae: 634.1161 - val_loss: 349943.3750 - val_mae: 454.0365\n",
            "Epoch 836/1000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 503716.1875 - mae: 636.0907 - val_loss: 357375.7500 - val_mae: 461.2136\n",
            "Epoch 837/1000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 498949.6562 - mae: 634.5010 - val_loss: 357234.6562 - val_mae: 462.5374\n",
            "Epoch 838/1000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 508725.1250 - mae: 639.5758 - val_loss: 379777.2500 - val_mae: 485.6145\n",
            "Epoch 839/1000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 507120.5312 - mae: 638.6183 - val_loss: 364439.3438 - val_mae: 468.1821\n",
            "Epoch 840/1000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 503578.0312 - mae: 636.8796 - val_loss: 365344.4688 - val_mae: 470.2090\n",
            "Epoch 841/1000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 497452.6562 - mae: 632.7025 - val_loss: 358798.4062 - val_mae: 464.8736\n",
            "Epoch 842/1000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 507901.7500 - mae: 638.4696 - val_loss: 351128.3438 - val_mae: 456.1588\n",
            "Epoch 843/1000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 504771.4375 - mae: 636.8153 - val_loss: 365513.6250 - val_mae: 470.2352\n",
            "Epoch 844/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 506953.7812 - mae: 637.6339 - val_loss: 358516.2812 - val_mae: 464.8010\n",
            "Epoch 845/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 507607.6250 - mae: 638.2495 - val_loss: 358772.3438 - val_mae: 463.4731\n",
            "Epoch 846/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 506253.5312 - mae: 638.6031 - val_loss: 365852.8750 - val_mae: 473.2279\n",
            "Epoch 847/1000\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 505922.9375 - mae: 637.2816 - val_loss: 358894.4062 - val_mae: 463.5507\n",
            "Epoch 848/1000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 503319.6875 - mae: 636.4436 - val_loss: 352032.0000 - val_mae: 456.7078\n",
            "Epoch 849/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 509062.3750 - mae: 640.9360 - val_loss: 373400.6562 - val_mae: 480.4792\n",
            "Epoch 850/1000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 503944.7812 - mae: 636.8677 - val_loss: 366217.2500 - val_mae: 472.0586\n",
            "Epoch 851/1000\n",
            "39/39 [==============================] - 5s 104ms/step - loss: 502689.6250 - mae: 635.5179 - val_loss: 365959.8750 - val_mae: 470.5233\n",
            "Epoch 852/1000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 505793.1875 - mae: 637.8418 - val_loss: 344497.2812 - val_mae: 448.0869\n",
            "Epoch 853/1000\n",
            "39/39 [==============================] - 5s 99ms/step - loss: 504766.6250 - mae: 637.0154 - val_loss: 373103.8438 - val_mae: 477.5499\n",
            "Epoch 854/1000\n",
            "39/39 [==============================] - 5s 89ms/step - loss: 506190.6875 - mae: 637.4790 - val_loss: 359657.2500 - val_mae: 465.5066\n",
            "Epoch 855/1000\n",
            "39/39 [==============================] - 5s 103ms/step - loss: 504336.9375 - mae: 636.4352 - val_loss: 359211.7188 - val_mae: 465.1364\n",
            "Epoch 856/1000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 508274.9375 - mae: 639.0017 - val_loss: 367197.0000 - val_mae: 472.6523\n",
            "Epoch 857/1000\n",
            "39/39 [==============================] - 9s 209ms/step - loss: 509237.3750 - mae: 639.3685 - val_loss: 359836.9062 - val_mae: 465.5083\n",
            "Epoch 858/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 506065.9375 - mae: 637.0873 - val_loss: 352247.7812 - val_mae: 456.8591\n",
            "Epoch 859/1000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 511201.5625 - mae: 641.2394 - val_loss: 352778.5000 - val_mae: 457.1740\n",
            "Epoch 860/1000\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 506189.3438 - mae: 639.7845 - val_loss: 366782.7500 - val_mae: 471.0534\n",
            "Epoch 861/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 505226.9688 - mae: 636.3973 - val_loss: 360403.5938 - val_mae: 464.4868\n",
            "Epoch 862/1000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 509238.8125 - mae: 640.2172 - val_loss: 367247.9688 - val_mae: 472.6982\n",
            "Epoch 863/1000\n",
            "39/39 [==============================] - 9s 234ms/step - loss: 502683.3438 - mae: 635.9720 - val_loss: 344867.2188 - val_mae: 448.3470\n",
            "Epoch 864/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 504816.2500 - mae: 637.2988 - val_loss: 381764.4688 - val_mae: 486.8861\n",
            "Epoch 865/1000\n",
            "39/39 [==============================] - 5s 109ms/step - loss: 507619.5938 - mae: 640.5980 - val_loss: 375439.5312 - val_mae: 483.1908\n",
            "Epoch 866/1000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 507058.4688 - mae: 638.7436 - val_loss: 345474.9688 - val_mae: 448.7116\n",
            "Epoch 867/1000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 505977.6250 - mae: 636.9299 - val_loss: 360255.0938 - val_mae: 464.4136\n",
            "Epoch 868/1000\n",
            "39/39 [==============================] - 10s 235ms/step - loss: 503567.7500 - mae: 638.4869 - val_loss: 367845.9062 - val_mae: 474.4140\n",
            "Epoch 869/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 504142.3125 - mae: 637.4666 - val_loss: 367899.1250 - val_mae: 474.4457\n",
            "Epoch 870/1000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 509333.8125 - mae: 641.2017 - val_loss: 360193.2812 - val_mae: 465.7348\n",
            "Epoch 871/1000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 506531.0312 - mae: 638.4946 - val_loss: 367690.7812 - val_mae: 473.1092\n",
            "Epoch 872/1000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 504131.5625 - mae: 636.4557 - val_loss: 375488.3438 - val_mae: 481.7375\n",
            "Epoch 873/1000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 507018.5625 - mae: 637.8023 - val_loss: 360131.8438 - val_mae: 464.3564\n",
            "Epoch 874/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 504081.5625 - mae: 636.4191 - val_loss: 360606.9062 - val_mae: 464.6360\n",
            "Epoch 875/1000\n",
            "39/39 [==============================] - 6s 156ms/step - loss: 501882.7188 - mae: 636.0334 - val_loss: 367908.3438 - val_mae: 473.1067\n",
            "Epoch 876/1000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 505648.4688 - mae: 638.1745 - val_loss: 375432.5312 - val_mae: 480.3641\n",
            "Epoch 877/1000\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 507469.6875 - mae: 639.6052 - val_loss: 346110.8438 - val_mae: 449.1167\n",
            "Epoch 878/1000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 510473.3125 - mae: 642.2532 - val_loss: 360192.4688 - val_mae: 465.7436\n",
            "Epoch 879/1000\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 505405.1875 - mae: 637.1833 - val_loss: 368115.0000 - val_mae: 473.2345\n",
            "Epoch 880/1000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 505271.8438 - mae: 637.5049 - val_loss: 368222.5938 - val_mae: 473.3009\n",
            "Epoch 881/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 508452.3438 - mae: 639.8307 - val_loss: 352800.0000 - val_mae: 455.8925\n",
            "Epoch 882/1000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 502691.5938 - mae: 635.6800 - val_loss: 361383.9062 - val_mae: 466.4493\n",
            "Epoch 883/1000\n",
            "39/39 [==============================] - 9s 207ms/step - loss: 506966.0625 - mae: 638.3118 - val_loss: 360861.9688 - val_mae: 463.4759\n",
            "Epoch 884/1000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 504940.0312 - mae: 637.1600 - val_loss: 368399.3438 - val_mae: 470.7491\n",
            "Epoch 885/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 505092.0312 - mae: 637.2520 - val_loss: 360775.7188 - val_mae: 464.7630\n",
            "Epoch 886/1000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 501948.7500 - mae: 635.3301 - val_loss: 360834.5938 - val_mae: 464.8002\n",
            "Epoch 887/1000\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 502340.9688 - mae: 636.5132 - val_loss: 347600.7812 - val_mae: 450.0183\n",
            "Epoch 888/1000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 505721.0000 - mae: 637.9171 - val_loss: 354202.9062 - val_mae: 456.7434\n",
            "Epoch 889/1000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 505098.0000 - mae: 637.2716 - val_loss: 361985.7812 - val_mae: 465.4855\n",
            "Epoch 890/1000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 508102.8125 - mae: 639.4985 - val_loss: 361416.1562 - val_mae: 466.4775\n",
            "Epoch 891/1000\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 500722.6562 - mae: 635.4189 - val_loss: 368463.6562 - val_mae: 473.4633\n",
            "Epoch 892/1000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 502270.0625 - mae: 636.2792 - val_loss: 353755.0000 - val_mae: 457.8127\n",
            "Epoch 893/1000\n",
            "39/39 [==============================] - 6s 132ms/step - loss: 505985.3750 - mae: 639.0042 - val_loss: 383468.2500 - val_mae: 487.9703\n",
            "Epoch 894/1000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 498242.0000 - mae: 635.3334 - val_loss: 376826.5938 - val_mae: 482.7179\n",
            "Epoch 895/1000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 505204.1875 - mae: 637.2775 - val_loss: 354328.2500 - val_mae: 458.1527\n",
            "Epoch 896/1000\n",
            "39/39 [==============================] - 4s 95ms/step - loss: 501719.3125 - mae: 635.9447 - val_loss: 353853.6562 - val_mae: 457.8739\n",
            "Epoch 897/1000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 508184.0000 - mae: 640.1655 - val_loss: 369937.7188 - val_mae: 475.6526\n",
            "Epoch 898/1000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 507974.5938 - mae: 639.0488 - val_loss: 362202.3438 - val_mae: 467.1219\n",
            "Epoch 899/1000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 503461.1875 - mae: 636.8819 - val_loss: 377032.6250 - val_mae: 482.8473\n",
            "Epoch 900/1000\n",
            "39/39 [==============================] - 5s 110ms/step - loss: 506274.9688 - mae: 638.9453 - val_loss: 361354.0938 - val_mae: 466.4485\n",
            "Epoch 901/1000\n",
            "39/39 [==============================] - 4s 98ms/step - loss: 508800.0938 - mae: 640.0542 - val_loss: 354320.9062 - val_mae: 456.8461\n",
            "Epoch 902/1000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 505588.9688 - mae: 638.4648 - val_loss: 354363.3438 - val_mae: 456.8734\n",
            "Epoch 903/1000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 507337.7812 - mae: 639.2031 - val_loss: 362045.4062 - val_mae: 466.8584\n",
            "Epoch 904/1000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 504613.5000 - mae: 637.5338 - val_loss: 362041.7812 - val_mae: 467.0415\n",
            "Epoch 905/1000\n",
            "39/39 [==============================] - 10s 232ms/step - loss: 508501.6875 - mae: 639.6242 - val_loss: 369357.4062 - val_mae: 472.7028\n",
            "Epoch 906/1000\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 493699.0938 - mae: 632.5265 - val_loss: 354374.4688 - val_mae: 458.1964\n",
            "Epoch 907/1000\n",
            "39/39 [==============================] - 5s 116ms/step - loss: 505695.8438 - mae: 638.9225 - val_loss: 376960.6562 - val_mae: 480.0282\n",
            "Epoch 908/1000\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 503175.1250 - mae: 638.1893 - val_loss: 361581.4062 - val_mae: 465.2905\n",
            "Epoch 909/1000\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 507457.7812 - mae: 639.4445 - val_loss: 356077.5938 - val_mae: 459.2047\n",
            "Epoch 910/1000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 507113.1875 - mae: 639.4058 - val_loss: 361441.0938 - val_mae: 463.9170\n",
            "Epoch 911/1000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 506238.9062 - mae: 638.6905 - val_loss: 369597.3750 - val_mae: 474.1607\n",
            "Epoch 912/1000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 499680.0625 - mae: 634.3569 - val_loss: 377062.8438 - val_mae: 478.8169\n",
            "Epoch 913/1000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 506222.6250 - mae: 638.6140 - val_loss: 385333.5938 - val_mae: 491.7091\n",
            "Epoch 914/1000\n",
            "39/39 [==============================] - 6s 133ms/step - loss: 509813.5938 - mae: 641.2683 - val_loss: 377316.9688 - val_mae: 481.7650\n",
            "Epoch 915/1000\n",
            "39/39 [==============================] - 4s 100ms/step - loss: 504024.5312 - mae: 640.0816 - val_loss: 363535.1562 - val_mae: 466.4583\n",
            "Epoch 916/1000\n",
            "39/39 [==============================] - 4s 87ms/step - loss: 505726.0625 - mae: 638.8241 - val_loss: 369834.1562 - val_mae: 471.7331\n",
            "Epoch 917/1000\n",
            "39/39 [==============================] - 6s 137ms/step - loss: 501703.7500 - mae: 637.3995 - val_loss: 355772.6250 - val_mae: 457.7519\n",
            "Epoch 918/1000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 510713.6250 - mae: 642.0999 - val_loss: 377525.0938 - val_mae: 481.6898\n",
            "Epoch 919/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 504863.1562 - mae: 638.1863 - val_loss: 370546.0000 - val_mae: 474.7299\n",
            "Epoch 920/1000\n",
            "39/39 [==============================] - 5s 114ms/step - loss: 500983.5312 - mae: 635.6608 - val_loss: 355700.1562 - val_mae: 459.0005\n",
            "Epoch 921/1000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 504920.6250 - mae: 640.3986 - val_loss: 371041.0312 - val_mae: 475.0207\n",
            "Epoch 922/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 497064.7188 - mae: 633.9189 - val_loss: 370843.8438 - val_mae: 473.6253\n",
            "Epoch 923/1000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 503598.9688 - mae: 636.9684 - val_loss: 378486.0312 - val_mae: 483.5417\n",
            "Epoch 924/1000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 506176.3125 - mae: 638.8192 - val_loss: 363927.2188 - val_mae: 466.7035\n",
            "Epoch 925/1000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 505372.0625 - mae: 638.4103 - val_loss: 363710.1250 - val_mae: 465.3014\n",
            "Epoch 926/1000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 501514.9688 - mae: 637.7693 - val_loss: 356295.7188 - val_mae: 458.0868\n",
            "Epoch 927/1000\n",
            "39/39 [==============================] - 4s 83ms/step - loss: 502028.4062 - mae: 635.2498 - val_loss: 369992.3750 - val_mae: 471.8722\n",
            "Epoch 928/1000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 511014.2812 - mae: 642.1649 - val_loss: 356184.8750 - val_mae: 459.2989\n",
            "Epoch 929/1000\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 504400.4062 - mae: 637.0714 - val_loss: 370318.0938 - val_mae: 473.3383\n",
            "Epoch 930/1000\n",
            "39/39 [==============================] - 5s 103ms/step - loss: 507500.9062 - mae: 640.0720 - val_loss: 362932.2500 - val_mae: 466.1378\n",
            "Epoch 931/1000\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 509215.3125 - mae: 641.7729 - val_loss: 363679.2812 - val_mae: 465.3113\n",
            "Epoch 932/1000\n",
            "39/39 [==============================] - 10s 238ms/step - loss: 507824.6875 - mae: 640.2519 - val_loss: 378460.9062 - val_mae: 482.2719\n",
            "Epoch 933/1000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 506761.6875 - mae: 639.9329 - val_loss: 378731.0312 - val_mae: 481.1696\n",
            "Epoch 934/1000\n",
            "39/39 [==============================] - 5s 114ms/step - loss: 501882.0938 - mae: 638.0795 - val_loss: 356312.2500 - val_mae: 458.1228\n",
            "Epoch 935/1000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 509591.3750 - mae: 641.1538 - val_loss: 357147.7188 - val_mae: 459.8769\n",
            "Epoch 936/1000\n",
            "39/39 [==============================] - 5s 108ms/step - loss: 502692.5625 - mae: 637.3608 - val_loss: 371163.5000 - val_mae: 475.1200\n",
            "Epoch 937/1000\n",
            "39/39 [==============================] - 9s 210ms/step - loss: 506398.4688 - mae: 639.0711 - val_loss: 379234.0000 - val_mae: 482.7348\n",
            "Epoch 938/1000\n",
            "39/39 [==============================] - 9s 231ms/step - loss: 503046.5312 - mae: 636.8019 - val_loss: 371431.0000 - val_mae: 474.0211\n",
            "Epoch 939/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 508152.0000 - mae: 641.7179 - val_loss: 371453.4062 - val_mae: 474.0353\n",
            "Epoch 940/1000\n",
            "39/39 [==============================] - 10s 237ms/step - loss: 502887.5312 - mae: 637.0150 - val_loss: 363895.7500 - val_mae: 466.7211\n",
            "Epoch 941/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 506672.5312 - mae: 640.1497 - val_loss: 364483.0938 - val_mae: 467.0691\n",
            "Epoch 942/1000\n",
            "39/39 [==============================] - 5s 105ms/step - loss: 507125.4375 - mae: 640.0352 - val_loss: 371579.9688 - val_mae: 474.1155\n",
            "Epoch 943/1000\n",
            "39/39 [==============================] - 4s 88ms/step - loss: 500174.2188 - mae: 636.5669 - val_loss: 372110.3750 - val_mae: 476.9334\n",
            "Epoch 944/1000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 504305.5625 - mae: 638.0845 - val_loss: 364329.9062 - val_mae: 468.2344\n",
            "Epoch 945/1000\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 502414.1562 - mae: 637.4336 - val_loss: 357245.7812 - val_mae: 458.6932\n",
            "Epoch 946/1000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 502697.8750 - mae: 636.4440 - val_loss: 372266.1250 - val_mae: 477.0248\n",
            "Epoch 947/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 506720.5625 - mae: 639.4074 - val_loss: 364184.6250 - val_mae: 467.1512\n",
            "Epoch 948/1000\n",
            "39/39 [==============================] - 4s 105ms/step - loss: 511150.4688 - mae: 643.6450 - val_loss: 378927.4688 - val_mae: 481.3232\n",
            "Epoch 949/1000\n",
            "39/39 [==============================] - 5s 111ms/step - loss: 504216.3750 - mae: 638.3713 - val_loss: 364033.5938 - val_mae: 465.5707\n",
            "Epoch 950/1000\n",
            "39/39 [==============================] - 5s 103ms/step - loss: 504109.0312 - mae: 637.3707 - val_loss: 364294.2812 - val_mae: 466.9697\n",
            "Epoch 951/1000\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 499801.7812 - mae: 636.1848 - val_loss: 364335.1250 - val_mae: 466.9951\n",
            "Epoch 952/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 502697.4062 - mae: 637.1204 - val_loss: 380023.2500 - val_mae: 484.4604\n",
            "Epoch 953/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 508867.7500 - mae: 641.3342 - val_loss: 371937.1562 - val_mae: 474.3416\n",
            "Epoch 954/1000\n",
            "39/39 [==============================] - 5s 121ms/step - loss: 499422.2188 - mae: 635.0834 - val_loss: 372270.8438 - val_mae: 476.0403\n",
            "Epoch 955/1000\n",
            "39/39 [==============================] - 4s 82ms/step - loss: 503475.7500 - mae: 638.4930 - val_loss: 349996.1562 - val_mae: 451.5702\n",
            "Epoch 956/1000\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 510252.4375 - mae: 642.6725 - val_loss: 350049.2188 - val_mae: 451.6034\n",
            "Epoch 957/1000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 507933.5312 - mae: 640.8228 - val_loss: 379459.9062 - val_mae: 483.1503\n",
            "Epoch 958/1000\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 506722.1875 - mae: 639.8152 - val_loss: 364844.8750 - val_mae: 468.5431\n",
            "Epoch 959/1000\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 506364.9062 - mae: 640.0128 - val_loss: 364345.7812 - val_mae: 465.7726\n",
            "Epoch 960/1000\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 502709.7500 - mae: 639.6326 - val_loss: 365150.5000 - val_mae: 467.4849\n",
            "Epoch 961/1000\n",
            "39/39 [==============================] - 5s 102ms/step - loss: 509190.8438 - mae: 640.9546 - val_loss: 379570.3750 - val_mae: 480.4861\n",
            "Epoch 962/1000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 508879.0625 - mae: 641.5574 - val_loss: 350322.0000 - val_mae: 451.7743\n",
            "Epoch 963/1000\n",
            "39/39 [==============================] - 9s 235ms/step - loss: 503263.2812 - mae: 637.7313 - val_loss: 365590.2188 - val_mae: 468.9826\n",
            "Epoch 964/1000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 504525.9688 - mae: 638.6944 - val_loss: 357507.9688 - val_mae: 458.8850\n",
            "Epoch 965/1000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 508202.6250 - mae: 641.7839 - val_loss: 372549.7500 - val_mae: 474.7288\n",
            "Epoch 966/1000\n",
            "39/39 [==============================] - 5s 107ms/step - loss: 507246.0000 - mae: 640.6629 - val_loss: 372859.1562 - val_mae: 476.1418\n",
            "Epoch 967/1000\n",
            "39/39 [==============================] - 9s 217ms/step - loss: 504551.3750 - mae: 638.5602 - val_loss: 379969.6250 - val_mae: 483.2065\n",
            "Epoch 968/1000\n",
            "39/39 [==============================] - 9s 232ms/step - loss: 500786.3438 - mae: 635.8262 - val_loss: 357973.9062 - val_mae: 460.3961\n",
            "Epoch 969/1000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 502066.5000 - mae: 636.3849 - val_loss: 387686.2500 - val_mae: 490.6310\n",
            "Epoch 970/1000\n",
            "39/39 [==============================] - 9s 213ms/step - loss: 499657.8750 - mae: 636.0383 - val_loss: 365941.3750 - val_mae: 469.1925\n",
            "Epoch 971/1000\n",
            "39/39 [==============================] - 5s 122ms/step - loss: 505615.5938 - mae: 638.4501 - val_loss: 358102.3438 - val_mae: 460.4746\n",
            "Epoch 972/1000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 506462.9062 - mae: 639.5851 - val_loss: 388070.9062 - val_mae: 492.0855\n",
            "Epoch 973/1000\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 509564.7500 - mae: 642.3270 - val_loss: 372625.7500 - val_mae: 473.5659\n",
            "Epoch 974/1000\n",
            "39/39 [==============================] - 5s 119ms/step - loss: 503675.7500 - mae: 638.0236 - val_loss: 365299.3750 - val_mae: 467.5952\n",
            "Epoch 975/1000\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 504852.5625 - mae: 639.2299 - val_loss: 372206.9688 - val_mae: 473.3256\n",
            "Epoch 976/1000\n",
            "39/39 [==============================] - 9s 212ms/step - loss: 510471.5312 - mae: 642.3432 - val_loss: 380413.1562 - val_mae: 483.4805\n",
            "Epoch 977/1000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 507773.5312 - mae: 640.2382 - val_loss: 365703.7812 - val_mae: 466.6195\n",
            "Epoch 978/1000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 501833.0938 - mae: 637.9917 - val_loss: 365963.2500 - val_mae: 467.9897\n",
            "Epoch 979/1000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 500811.5625 - mae: 636.7423 - val_loss: 373407.5000 - val_mae: 476.4750\n",
            "Epoch 980/1000\n",
            "39/39 [==============================] - 4s 99ms/step - loss: 504984.2188 - mae: 640.2466 - val_loss: 373220.6562 - val_mae: 477.5836\n",
            "Epoch 981/1000\n",
            "39/39 [==============================] - 4s 97ms/step - loss: 505826.5625 - mae: 639.9756 - val_loss: 365851.7188 - val_mae: 469.1451\n",
            "Epoch 982/1000\n",
            "39/39 [==============================] - 9s 216ms/step - loss: 504804.5625 - mae: 639.2886 - val_loss: 373740.0000 - val_mae: 477.8870\n",
            "Epoch 983/1000\n",
            "39/39 [==============================] - 9s 215ms/step - loss: 505312.2188 - mae: 638.8304 - val_loss: 365642.0000 - val_mae: 467.8080\n",
            "Epoch 984/1000\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 504037.9688 - mae: 637.5898 - val_loss: 358236.1562 - val_mae: 459.3476\n",
            "Epoch 985/1000\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 509466.0000 - mae: 641.9078 - val_loss: 380366.0938 - val_mae: 482.2450\n",
            "Epoch 986/1000\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 508100.9688 - mae: 641.1586 - val_loss: 374389.7188 - val_mae: 478.2662\n",
            "Epoch 987/1000\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 504977.3125 - mae: 639.3433 - val_loss: 365788.2500 - val_mae: 467.8987\n",
            "Epoch 988/1000\n",
            "39/39 [==============================] - 9s 211ms/step - loss: 505300.3438 - mae: 639.0164 - val_loss: 381312.1562 - val_mae: 484.0192\n",
            "Epoch 989/1000\n",
            "39/39 [==============================] - 4s 94ms/step - loss: 505628.5000 - mae: 638.8712 - val_loss: 358260.4062 - val_mae: 460.5839\n",
            "Epoch 990/1000\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 500925.5312 - mae: 638.1559 - val_loss: 380653.6562 - val_mae: 482.4288\n",
            "Epoch 991/1000\n",
            "39/39 [==============================] - 5s 101ms/step - loss: 495526.4375 - mae: 633.0314 - val_loss: 366179.7812 - val_mae: 469.3408\n",
            "Epoch 992/1000\n",
            "39/39 [==============================] - 5s 102ms/step - loss: 506705.1875 - mae: 640.2775 - val_loss: 358309.0000 - val_mae: 460.6136\n",
            "Epoch 993/1000\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 507862.2188 - mae: 641.3115 - val_loss: 358598.9062 - val_mae: 459.5776\n",
            "Epoch 994/1000\n",
            "39/39 [==============================] - 5s 102ms/step - loss: 505048.0000 - mae: 638.6361 - val_loss: 373904.0312 - val_mae: 476.7762\n",
            "Epoch 995/1000\n",
            "39/39 [==============================] - 9s 226ms/step - loss: 506672.8750 - mae: 640.0314 - val_loss: 381596.5938 - val_mae: 484.4950\n",
            "Epoch 996/1000\n",
            "39/39 [==============================] - 4s 96ms/step - loss: 499278.0000 - mae: 636.2014 - val_loss: 388742.4688 - val_mae: 491.2922\n",
            "Epoch 997/1000\n",
            "39/39 [==============================] - 5s 98ms/step - loss: 507223.2188 - mae: 639.8411 - val_loss: 366659.0938 - val_mae: 468.4210\n",
            "Epoch 998/1000\n",
            "39/39 [==============================] - 9s 214ms/step - loss: 505191.1250 - mae: 640.0156 - val_loss: 381702.6562 - val_mae: 484.2596\n",
            "Epoch 999/1000\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 504712.8750 - mae: 641.9720 - val_loss: 366236.5000 - val_mae: 468.1765\n",
            "Epoch 1000/1000\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 508911.5312 - mae: 641.6445 - val_loss: 373869.0312 - val_mae: 475.5599\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "mae = history.history['mae']\n",
        "val_mae = history.history['val_mae']\n",
        "\n",
        "epochs_x = range(len(loss))\n",
        "\n",
        "plt.plot(epochs_x, mae, 'co', label='Training MAE')\n",
        "plt.plot(epochs_x, val_mae, 'k', label='Validation MAE')\n",
        "plt.title('Training and Mean squared error')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'co', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "     "
      ],
      "metadata": {
        "id": "Y3K89-CM-dfg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "23b633aa-6189-469c-af67-954f0d6f1409"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_x"
      ],
      "metadata": {
        "id": "N_sP_ZmSY-Jv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "079e7087-fc06-4f74-8301-fbfd1357c1f5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "range(0, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download the model\n"
      ],
      "metadata": {
        "id": "R19IJQSYoW7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('./content/drive/My Drive/new', exist_ok=True)\n",
        "model.save('./content/drive/My Drive/new/regression_unfreeze.h5')"
      ],
      "metadata": {
        "id": "Zed4TdFcG2iJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n"
      ],
      "metadata": {
        "id": "P5eMxm1NV-oY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('./content/drive/My Drive/new/regression_unfreeze.h5')"
      ],
      "metadata": {
        "id": "wY_pDlxkRwxS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "913cc561-cd28-4ff3-ba3f-1b1015144e22"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_de9a76ce-ca12-4080-a634-17de22d2188d\", \"regression_unfreeze.h5\", 16621184)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}