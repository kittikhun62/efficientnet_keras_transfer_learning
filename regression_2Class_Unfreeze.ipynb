{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kittikhun62/efficientnet_keras_transfer_learning/blob/master/regression_2Class_Unfreeze.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#เรียกใช้ CSV"
      ],
      "metadata": {
        "id": "ow7eWoNw6U-c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z8o_VVNXzcL8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_2Fe8u81d5r",
        "outputId": "e73cc50d-565e-4894-ed0d-f39bf311cdec"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "5qxePnnn7TGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "D-hCRloc3t39"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "YZWXwjXeGxZP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#กำหนดค่าพารามิเตอร์\n"
      ],
      "metadata": {
        "id": "RooqSdBc7QHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "width = 150\n",
        "height = 150\n",
        "\n",
        "epochs = 1000 #จำนวนรอบในการ Train\n",
        "\n",
        "NUM_TRAIN = 598  # จำนวนภาพ Train\n",
        "NUM_TEST = 101 #จำนวนภาพ Test\n",
        "\n",
        "dropout_rate = 0.3\n",
        "input_shape = (height, width, 3) #ขนาด image enter"
      ],
      "metadata": {
        "id": "thDb7U9B3xOo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clone efficientnet repo\n"
      ],
      "metadata": {
        "id": "pumGmy6f3eSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7iy2f8n16p0",
        "outputId": "4e12b440-92ac-412b-8451-a510df98a28a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 837, done.\u001b[K\n",
            "remote: Total 837 (delta 0), reused 0 (delta 0), pack-reused 837\u001b[K\n",
            "Receiving objects: 100% (837/837), 13.85 MiB | 35.56 MiB/s, done.\n",
            "Resolving deltas: 100% (497/497), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "tjZBRnfo3bN0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8BN74_JJdfj",
        "outputId": "51efc5f8-13f0-427d-d0df-67abb6c0bf02"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#load model\n"
      ],
      "metadata": {
        "id": "PdNWyD-QYkzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/new/regression.h5')\n",
        "\n",
        "from efficientnet.layers import Swish, DropConnect\n",
        "from efficientnet.model import ConvKernalInitializer\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "\n",
        "get_custom_objects().update({\n",
        "    'ConvKernalInitializer': ConvKernalInitializer,\n",
        "    'Swish': Swish,\n",
        "    'DropConnect':DropConnect\n",
        "})"
      ],
      "metadata": {
        "id": "_gPnx2UvYf5A"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load model \n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/drive/My Drive/new/regression.h5')\n",
        "height = width = model.input_shape[1]"
      ],
      "metadata": {
        "id": "Nu93WzFUYm9e"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "gp5EbyyXYvc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f98b650-208f-4d22-848d-08c8dc0b769b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 2)                 2562      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,052,129\n",
            "Trainable params: 2,565\n",
            "Non-trainable params: 4,049,564\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (f'/content/drive/My Drive/data - 2 class Regress.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "q1Dc131_Y3uA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "b1c53f31-5369-451f-c198-5dc8b79533cf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      No                      Name_file  \\\n",
              "0      1                        pore-sb   \n",
              "1      2                        pore-sb   \n",
              "2      3                        pore-sb   \n",
              "3      4                        pore-sb   \n",
              "4      5                        pore-sb   \n",
              "..   ...                            ...   \n",
              "795  796  1-s2.0-S2095268622000210-main   \n",
              "796  797  1-s2.0-S2095268622000210-main   \n",
              "797  798  1-s2.0-S2095268622000210-main   \n",
              "798  799  1-s2.0-S2095268622000210-main   \n",
              "799  800  1-s2.0-S2095268622000210-main   \n",
              "\n",
              "                                            Name_Paper  \\\n",
              "0    Preparation and electrochemical behaviour of b...   \n",
              "1    Preparation and electrochemical behaviour of b...   \n",
              "2    Preparation and electrochemical behaviour of b...   \n",
              "3    Preparation and electrochemical behaviour of b...   \n",
              "4    Preparation and electrochemical behaviour of b...   \n",
              "..                                                 ...   \n",
              "795  Integration of preparation of K, Na-embedded a...   \n",
              "796  Integration of preparation of K, Na-embedded a...   \n",
              "797  Integration of preparation of K, Na-embedded a...   \n",
              "798  Integration of preparation of K, Na-embedded a...   \n",
              "799  Integration of preparation of K, Na-embedded a...   \n",
              "\n",
              "                                               journal  \\\n",
              "0                                  Korean J. Chem. Eng   \n",
              "1                                  Korean J. Chem. Eng   \n",
              "2                                  Korean J. Chem. Eng   \n",
              "3                                  Korean J. Chem. Eng   \n",
              "4                                  Korean J. Chem. Eng   \n",
              "..                                                 ...   \n",
              "795  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "796  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "797  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "798  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "799  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "\n",
              "                                          path_Picture  detail  Class     BET  \\\n",
              "0    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom1  0-800  135.06   \n",
              "1    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom2  0-800  135.06   \n",
              "2    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom3  0-800  135.06   \n",
              "3    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom4  0-800  135.06   \n",
              "4    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom5  0-800  135.06   \n",
              "..                                                 ...     ...    ...     ...   \n",
              "795  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom21  0-800  301.70   \n",
              "796  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom22  0-800  301.70   \n",
              "797  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom23  0-800  301.70   \n",
              "798  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom24  0-800  301.70   \n",
              "799  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom25  0-800  301.70   \n",
              "\n",
              "     Size(mico)  Class_01  \n",
              "0            10         0  \n",
              "1            10         0  \n",
              "2            10         0  \n",
              "3            10         0  \n",
              "4            10         0  \n",
              "..          ...       ...  \n",
              "795          10         0  \n",
              "796          10         0  \n",
              "797          10         0  \n",
              "798          10         0  \n",
              "799          10         0  \n",
              "\n",
              "[800 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a48ae49-ea2e-4ba2-9e7f-7ab0edf5946e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>No</th>\n",
              "      <th>Name_file</th>\n",
              "      <th>Name_Paper</th>\n",
              "      <th>journal</th>\n",
              "      <th>path_Picture</th>\n",
              "      <th>detail</th>\n",
              "      <th>Class</th>\n",
              "      <th>BET</th>\n",
              "      <th>Size(mico)</th>\n",
              "      <th>Class_01</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom1</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom2</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom3</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom4</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom5</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>795</th>\n",
              "      <td>796</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom21</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>796</th>\n",
              "      <td>797</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom22</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>797</th>\n",
              "      <td>798</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom23</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>798</th>\n",
              "      <td>799</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom24</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799</th>\n",
              "      <td>800</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom25</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>800 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a48ae49-ea2e-4ba2-9e7f-7ab0edf5946e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7a48ae49-ea2e-4ba2-9e7f-7ab0edf5946e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7a48ae49-ea2e-4ba2-9e7f-7ab0edf5946e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "FdYoTgJ19LRv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val = df[df['No'].between(599,699)]\n",
        "train = df[df['No'].between(1,598)]"
      ],
      "metadata": {
        "id": "Z1zBw01Gl8Ac"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = '/content/drive/My Drive/new Regress'\n",
        "os.chdir(DATA_PATH)\n",
        "train_dir = os.path.join(DATA_PATH, 'train')\n",
        "print(train_dir)\n",
        "validation_dir = os.path.join(DATA_PATH, 'validation')\n",
        "print(validation_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QL0g-8iOnMC4",
        "outputId": "a56ae98e-4db7-40d6-ee71-63bed264cb3c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/new Regress/train\n",
            "/content/drive/My Drive/new Regress/validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Train"
      ],
      "metadata": {
        "id": "bWEnlTSwazL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "xGPrsn9no_pa"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe = train,\n",
        "        directory = train_dir,\n",
        "        x_col = 'path_Picture',\n",
        "        y_col = 'BET',\n",
        "        class_mode = 'other',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)\n",
        "\n",
        "validation_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe = val,\n",
        "        directory = validation_dir,\n",
        "        x_col = 'path_Picture',\n",
        "        y_col = 'BET',\n",
        "        class_mode = 'other',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nVlmAszntK_",
        "outputId": "bbf9a5c4-084c-4590-b427-2f4e26a73f24"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 598 validated image filenames.\n",
            "Found 101 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multiply_16\n",
        "# set 'multiply_16' and following layers trainable\n",
        "model.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'multiply_16':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False  "
      ],
      "metadata": {
        "id": "RY14olxmJj92"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzCdn3X4Jm_E",
        "outputId": "fa1dc10f-0981-493f-e963-f8947bfa4041"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 2)                 2562      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,052,129\n",
            "Trainable params: 4,010,113\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mse',\n",
        "          optimizer=Adam(learning_rate=2e-1),\n",
        "          metrics=['mae'])\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "N6qUmmF856ZE",
        "outputId": "ff2c9b28-98af-4138-9088-3db0da995468",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-5e84c54916dc>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "37/37 [==============================] - 95s 1s/step - loss: 501924.5000 - mae: 642.0807 - val_loss: 416104.8750 - val_mae: 501.2562\n",
            "Epoch 2/1000\n",
            "37/37 [==============================] - 9s 245ms/step - loss: 503199.4062 - mae: 643.4534 - val_loss: 392844.5312 - val_mae: 477.5890\n",
            "Epoch 3/1000\n",
            "37/37 [==============================] - 9s 242ms/step - loss: 501156.6250 - mae: 641.0100 - val_loss: 416645.5000 - val_mae: 501.8477\n",
            "Epoch 4/1000\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 502068.6875 - mae: 642.8370 - val_loss: 416150.8438 - val_mae: 501.5601\n",
            "Epoch 5/1000\n",
            "37/37 [==============================] - 5s 114ms/step - loss: 496954.2812 - mae: 640.2721 - val_loss: 398956.4688 - val_mae: 484.5301\n",
            "Epoch 6/1000\n",
            "37/37 [==============================] - 6s 135ms/step - loss: 502944.5625 - mae: 643.4256 - val_loss: 425331.0938 - val_mae: 511.4152\n",
            "Epoch 7/1000\n",
            "37/37 [==============================] - 10s 247ms/step - loss: 503055.7812 - mae: 643.0999 - val_loss: 392889.1250 - val_mae: 477.6145\n",
            "Epoch 8/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 499813.2188 - mae: 640.0552 - val_loss: 425214.3750 - val_mae: 510.4653\n",
            "Epoch 9/1000\n",
            "37/37 [==============================] - 10s 255ms/step - loss: 499888.2188 - mae: 641.2134 - val_loss: 399538.9062 - val_mae: 484.9192\n",
            "Epoch 10/1000\n",
            "37/37 [==============================] - 5s 114ms/step - loss: 503277.0312 - mae: 643.7063 - val_loss: 409720.8438 - val_mae: 494.1857\n",
            "Epoch 11/1000\n",
            "37/37 [==============================] - 6s 138ms/step - loss: 503496.3438 - mae: 643.5220 - val_loss: 425448.8750 - val_mae: 510.6086\n",
            "Epoch 12/1000\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 497365.5000 - mae: 641.6965 - val_loss: 434208.6250 - val_mae: 519.0726\n",
            "Epoch 13/1000\n",
            "37/37 [==============================] - 10s 253ms/step - loss: 499882.8750 - mae: 641.0386 - val_loss: 406851.1562 - val_mae: 492.8080\n",
            "Epoch 14/1000\n",
            "37/37 [==============================] - 9s 249ms/step - loss: 500243.3125 - mae: 640.6755 - val_loss: 399442.9062 - val_mae: 484.8143\n",
            "Epoch 15/1000\n",
            "37/37 [==============================] - 5s 115ms/step - loss: 501676.3125 - mae: 642.9283 - val_loss: 416539.7500 - val_mae: 502.0570\n",
            "Epoch 16/1000\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 502679.6562 - mae: 643.3635 - val_loss: 416771.6562 - val_mae: 501.9057\n",
            "Epoch 17/1000\n",
            "37/37 [==============================] - 10s 255ms/step - loss: 501215.7188 - mae: 641.2901 - val_loss: 415649.6562 - val_mae: 501.2526\n",
            "Epoch 18/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 500547.2500 - mae: 641.3373 - val_loss: 405695.0000 - val_mae: 491.8195\n",
            "Epoch 19/1000\n",
            "37/37 [==============================] - 5s 116ms/step - loss: 503483.4375 - mae: 643.7944 - val_loss: 407539.8438 - val_mae: 493.1914\n",
            "Epoch 20/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 501956.9062 - mae: 643.0967 - val_loss: 407051.0000 - val_mae: 493.1995\n",
            "Epoch 21/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 501812.0000 - mae: 642.1152 - val_loss: 417930.6250 - val_mae: 503.0796\n",
            "Epoch 22/1000\n",
            "37/37 [==============================] - 5s 117ms/step - loss: 504344.8125 - mae: 643.8956 - val_loss: 406687.0000 - val_mae: 492.3882\n",
            "Epoch 23/1000\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 489131.4375 - mae: 635.7042 - val_loss: 417734.2812 - val_mae: 502.4645\n",
            "Epoch 24/1000\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 501123.4688 - mae: 644.2885 - val_loss: 426734.4062 - val_mae: 511.5728\n",
            "Epoch 25/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 504060.9062 - mae: 643.7808 - val_loss: 409297.9062 - val_mae: 493.9359\n",
            "Epoch 26/1000\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 501090.9062 - mae: 641.0436 - val_loss: 416507.0312 - val_mae: 501.7672\n",
            "Epoch 27/1000\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 498423.3750 - mae: 639.7580 - val_loss: 409511.9688 - val_mae: 494.0624\n",
            "Epoch 28/1000\n",
            "37/37 [==============================] - 10s 251ms/step - loss: 501176.8125 - mae: 642.6168 - val_loss: 417985.2812 - val_mae: 502.8658\n",
            "Epoch 29/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 494147.1875 - mae: 638.9283 - val_loss: 408082.1250 - val_mae: 493.5014\n",
            "Epoch 30/1000\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 500678.9375 - mae: 641.1026 - val_loss: 399455.0938 - val_mae: 484.8540\n",
            "Epoch 31/1000\n",
            "37/37 [==============================] - 10s 251ms/step - loss: 502140.9062 - mae: 642.2509 - val_loss: 418470.3438 - val_mae: 503.3761\n",
            "Epoch 32/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 501346.5312 - mae: 641.8680 - val_loss: 400289.7188 - val_mae: 485.3238\n",
            "Epoch 33/1000\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 501678.1875 - mae: 642.4569 - val_loss: 409615.8438 - val_mae: 494.6096\n",
            "Epoch 34/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 504136.4062 - mae: 645.3613 - val_loss: 418015.9688 - val_mae: 503.1255\n",
            "Epoch 35/1000\n",
            "37/37 [==============================] - 6s 139ms/step - loss: 498403.0938 - mae: 640.7148 - val_loss: 424811.8438 - val_mae: 509.9568\n",
            "Epoch 36/1000\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 501386.0625 - mae: 641.2055 - val_loss: 398320.3438 - val_mae: 484.4845\n",
            "Epoch 37/1000\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 499279.5000 - mae: 639.5756 - val_loss: 415887.0000 - val_mae: 501.4066\n",
            "Epoch 38/1000\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 500639.4062 - mae: 641.6397 - val_loss: 408141.8438 - val_mae: 493.2519\n",
            "Epoch 39/1000\n",
            "37/37 [==============================] - 5s 118ms/step - loss: 500224.0625 - mae: 640.3444 - val_loss: 409406.4688 - val_mae: 494.4957\n",
            "Epoch 40/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 500161.0000 - mae: 640.7939 - val_loss: 400117.7812 - val_mae: 485.2077\n",
            "Epoch 41/1000\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 496297.5625 - mae: 640.3791 - val_loss: 400159.8750 - val_mae: 485.5066\n",
            "Epoch 42/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 498402.3125 - mae: 639.6936 - val_loss: 416290.5938 - val_mae: 501.3939\n",
            "Epoch 43/1000\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 501065.5625 - mae: 641.5856 - val_loss: 425726.3750 - val_mae: 510.7666\n",
            "Epoch 44/1000\n",
            "37/37 [==============================] - 10s 252ms/step - loss: 504297.3438 - mae: 643.6743 - val_loss: 397042.8750 - val_mae: 483.4612\n",
            "Epoch 45/1000\n",
            "37/37 [==============================] - 5s 118ms/step - loss: 498547.6250 - mae: 640.0629 - val_loss: 416010.0000 - val_mae: 501.7648\n",
            "Epoch 46/1000\n",
            "37/37 [==============================] - 6s 134ms/step - loss: 499889.1562 - mae: 641.7305 - val_loss: 409089.6562 - val_mae: 494.0662\n",
            "Epoch 47/1000\n",
            "37/37 [==============================] - 10s 251ms/step - loss: 500872.3125 - mae: 641.7803 - val_loss: 389984.0312 - val_mae: 475.9615\n",
            "Epoch 48/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 501699.5625 - mae: 641.5062 - val_loss: 422688.1250 - val_mae: 508.4111\n",
            "Epoch 49/1000\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 503338.0625 - mae: 643.1198 - val_loss: 405303.4688 - val_mae: 491.9081\n",
            "Epoch 50/1000\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 502414.2500 - mae: 642.6033 - val_loss: 412970.3438 - val_mae: 499.7024\n",
            "Epoch 51/1000\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 501643.8750 - mae: 642.8845 - val_loss: 421811.8750 - val_mae: 508.8601\n",
            "Epoch 52/1000\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 502328.1875 - mae: 642.6379 - val_loss: 406398.7500 - val_mae: 492.2166\n",
            "Epoch 53/1000\n",
            "37/37 [==============================] - 10s 250ms/step - loss: 504392.4688 - mae: 643.4766 - val_loss: 414303.3750 - val_mae: 501.1147\n",
            "Epoch 54/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 498628.4062 - mae: 639.7878 - val_loss: 416462.2500 - val_mae: 501.7257\n",
            "Epoch 55/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 500122.0000 - mae: 641.2260 - val_loss: 415619.8438 - val_mae: 501.2510\n",
            "Epoch 56/1000\n",
            "37/37 [==============================] - 5s 117ms/step - loss: 501276.5938 - mae: 642.1837 - val_loss: 397794.2500 - val_mae: 484.5265\n",
            "Epoch 57/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 504889.5625 - mae: 643.8098 - val_loss: 415253.9062 - val_mae: 501.3350\n",
            "Epoch 58/1000\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 499894.0000 - mae: 640.8795 - val_loss: 389241.9688 - val_mae: 475.5464\n",
            "Epoch 59/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 500070.5312 - mae: 641.4626 - val_loss: 415391.9688 - val_mae: 501.1023\n",
            "Epoch 60/1000\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 502523.6562 - mae: 641.9866 - val_loss: 423666.0312 - val_mae: 509.8854\n",
            "Epoch 61/1000\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 499889.8750 - mae: 641.0219 - val_loss: 398464.0000 - val_mae: 484.2757\n",
            "Epoch 62/1000\n",
            "37/37 [==============================] - 5s 117ms/step - loss: 505313.8125 - mae: 645.1521 - val_loss: 406697.9062 - val_mae: 493.0045\n",
            "Epoch 63/1000\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 490998.8125 - mae: 636.0475 - val_loss: 414860.4062 - val_mae: 501.1190\n",
            "Epoch 64/1000\n",
            "37/37 [==============================] - 10s 252ms/step - loss: 503845.0625 - mae: 643.5788 - val_loss: 398898.7500 - val_mae: 484.7985\n",
            "Epoch 65/1000\n",
            "37/37 [==============================] - 10s 255ms/step - loss: 502414.2812 - mae: 642.8582 - val_loss: 424513.6562 - val_mae: 510.3528\n",
            "Epoch 66/1000\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 501847.8125 - mae: 642.8818 - val_loss: 415696.0312 - val_mae: 501.8743\n",
            "Epoch 67/1000\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 500000.7812 - mae: 640.1393 - val_loss: 424133.9062 - val_mae: 509.8484\n",
            "Epoch 68/1000\n",
            "37/37 [==============================] - 6s 137ms/step - loss: 502612.4688 - mae: 642.2906 - val_loss: 414648.4688 - val_mae: 500.9942\n",
            "Epoch 69/1000\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 500815.0000 - mae: 641.0793 - val_loss: 398703.1562 - val_mae: 484.6772\n",
            "Epoch 70/1000\n",
            "37/37 [==============================] - 10s 249ms/step - loss: 500244.9375 - mae: 640.8257 - val_loss: 424249.8438 - val_mae: 509.6245\n",
            "Epoch 71/1000\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 501147.1562 - mae: 642.0971 - val_loss: 416023.0000 - val_mae: 501.4857\n",
            "Epoch 72/1000\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 501802.6250 - mae: 642.8739 - val_loss: 416344.0938 - val_mae: 501.6725\n",
            "Epoch 73/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 502929.5938 - mae: 643.9016 - val_loss: 402153.7500 - val_mae: 486.6127\n",
            "Epoch 74/1000\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 497764.7188 - mae: 639.3209 - val_loss: 416776.2188 - val_mae: 502.7904\n",
            "Epoch 75/1000\n",
            "37/37 [==============================] - 10s 251ms/step - loss: 504745.5000 - mae: 644.8199 - val_loss: 417663.5000 - val_mae: 503.0193\n",
            "Epoch 76/1000\n",
            "37/37 [==============================] - 5s 117ms/step - loss: 501144.9062 - mae: 641.3588 - val_loss: 399382.0000 - val_mae: 485.0702\n",
            "Epoch 77/1000\n",
            "37/37 [==============================] - 10s 250ms/step - loss: 505186.9062 - mae: 644.6610 - val_loss: 417316.4688 - val_mae: 502.4919\n",
            "Epoch 78/1000\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 501412.2188 - mae: 642.2004 - val_loss: 409326.2188 - val_mae: 493.9320\n",
            "Epoch 79/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 501343.0000 - mae: 641.6451 - val_loss: 408337.3438 - val_mae: 493.9083\n",
            "Epoch 80/1000\n",
            "37/37 [==============================] - 10s 252ms/step - loss: 504296.8438 - mae: 644.1131 - val_loss: 409270.6562 - val_mae: 493.9198\n",
            "Epoch 81/1000\n",
            "37/37 [==============================] - 10s 250ms/step - loss: 493104.9375 - mae: 638.3926 - val_loss: 426618.4062 - val_mae: 511.7446\n",
            "Epoch 82/1000\n",
            "37/37 [==============================] - 10s 253ms/step - loss: 498547.1250 - mae: 640.3651 - val_loss: 407770.4062 - val_mae: 493.5959\n",
            "Epoch 83/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 495420.2188 - mae: 639.0295 - val_loss: 416841.2812 - val_mae: 502.2212\n",
            "Epoch 84/1000\n",
            "37/37 [==============================] - 7s 168ms/step - loss: 503292.0000 - mae: 643.2931 - val_loss: 415529.9062 - val_mae: 501.1986\n",
            "Epoch 85/1000\n",
            "37/37 [==============================] - 5s 117ms/step - loss: 502091.5312 - mae: 641.9916 - val_loss: 408144.3438 - val_mae: 493.5369\n",
            "Epoch 86/1000\n",
            "37/37 [==============================] - 5s 117ms/step - loss: 501312.1250 - mae: 641.9115 - val_loss: 423441.8750 - val_mae: 509.8008\n",
            "Epoch 87/1000\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 500986.8438 - mae: 641.7316 - val_loss: 425052.3750 - val_mae: 510.3729\n",
            "Epoch 88/1000\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 498789.6562 - mae: 639.8685 - val_loss: 416845.7500 - val_mae: 502.8341\n",
            "Epoch 89/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 498166.8125 - mae: 639.7177 - val_loss: 400558.4062 - val_mae: 485.7250\n",
            "Epoch 90/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 500758.5312 - mae: 641.7433 - val_loss: 417170.2188 - val_mae: 502.4101\n",
            "Epoch 91/1000\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 502461.0938 - mae: 642.3774 - val_loss: 434243.5000 - val_mae: 519.3487\n",
            "Epoch 92/1000\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 504592.5938 - mae: 644.4490 - val_loss: 416838.6562 - val_mae: 501.6977\n",
            "Epoch 93/1000\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 495246.0312 - mae: 639.3719 - val_loss: 408636.6562 - val_mae: 493.8077\n",
            "Epoch 94/1000\n",
            "37/37 [==============================] - 6s 130ms/step - loss: 499757.8438 - mae: 639.9127 - val_loss: 407975.4688 - val_mae: 493.1533\n",
            "Epoch 95/1000\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 502503.3750 - mae: 642.1207 - val_loss: 418299.0938 - val_mae: 503.0410\n",
            "Epoch 96/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 498213.5625 - mae: 639.7993 - val_loss: 409444.8438 - val_mae: 494.2785\n",
            "Epoch 97/1000\n",
            "37/37 [==============================] - 10s 250ms/step - loss: 501307.2188 - mae: 642.1146 - val_loss: 417419.7500 - val_mae: 502.5497\n",
            "Epoch 98/1000\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 497770.0625 - mae: 641.8745 - val_loss: 408224.7500 - val_mae: 493.8464\n",
            "Epoch 99/1000\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 501427.1875 - mae: 641.6241 - val_loss: 407793.1250 - val_mae: 493.6087\n",
            "Epoch 100/1000\n",
            "37/37 [==============================] - 10s 254ms/step - loss: 506230.0625 - mae: 645.2755 - val_loss: 407434.2500 - val_mae: 492.8322\n",
            "Epoch 101/1000\n",
            "37/37 [==============================] - 6s 141ms/step - loss: 496191.0000 - mae: 638.4510 - val_loss: 416433.3438 - val_mae: 501.7244\n",
            "Epoch 102/1000\n",
            "37/37 [==============================] - 10s 252ms/step - loss: 498601.1250 - mae: 639.8869 - val_loss: 415900.8438 - val_mae: 501.6986\n",
            "Epoch 103/1000\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 501808.8750 - mae: 642.3303 - val_loss: 424833.8750 - val_mae: 510.2581\n",
            "Epoch 104/1000\n",
            "37/37 [==============================] - 10s 251ms/step - loss: 492912.7812 - mae: 638.2059 - val_loss: 416637.5312 - val_mae: 501.8276\n",
            "Epoch 105/1000\n",
            "37/37 [==============================] - 10s 252ms/step - loss: 501670.5312 - mae: 642.0792 - val_loss: 415829.6562 - val_mae: 501.6534\n",
            "Epoch 106/1000\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 501560.5312 - mae: 642.1547 - val_loss: 417114.1250 - val_mae: 502.3740\n",
            "Epoch 107/1000\n",
            "37/37 [==============================] - 5s 120ms/step - loss: 500369.3750 - mae: 641.8956 - val_loss: 415888.0000 - val_mae: 501.4071\n",
            "Epoch 108/1000\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 501136.5938 - mae: 641.3005 - val_loss: 407537.0938 - val_mae: 493.4673\n",
            "Epoch 109/1000\n",
            "37/37 [==============================] - 5s 118ms/step - loss: 501497.9062 - mae: 642.3983 - val_loss: 400856.2188 - val_mae: 485.6374\n",
            "Epoch 110/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 502151.2500 - mae: 642.3859 - val_loss: 409115.8438 - val_mae: 493.8491\n",
            "Epoch 111/1000\n",
            "37/37 [==============================] - 5s 118ms/step - loss: 500502.9688 - mae: 641.1899 - val_loss: 418644.2812 - val_mae: 503.2377\n",
            "Epoch 112/1000\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 502781.8125 - mae: 644.2355 - val_loss: 419153.3438 - val_mae: 503.3003\n",
            "Epoch 113/1000\n",
            "37/37 [==============================] - 10s 251ms/step - loss: 493216.0000 - mae: 636.7679 - val_loss: 410669.3750 - val_mae: 494.9557\n",
            "Epoch 114/1000\n",
            "37/37 [==============================] - 6s 139ms/step - loss: 498754.1875 - mae: 640.5356 - val_loss: 419282.7188 - val_mae: 503.3750\n",
            "Epoch 115/1000\n",
            "37/37 [==============================] - 10s 255ms/step - loss: 499100.6562 - mae: 640.1152 - val_loss: 418856.2188 - val_mae: 503.3517\n",
            "Epoch 116/1000\n",
            "37/37 [==============================] - 10s 252ms/step - loss: 502255.2188 - mae: 643.3782 - val_loss: 427770.2812 - val_mae: 512.1382\n",
            "Epoch 117/1000\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 499509.1250 - mae: 641.9858 - val_loss: 419696.4062 - val_mae: 503.8195\n",
            "Epoch 118/1000\n",
            "37/37 [==============================] - 6s 133ms/step - loss: 502865.9688 - mae: 643.7990 - val_loss: 428533.5000 - val_mae: 512.1461\n",
            "Epoch 119/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 502049.3750 - mae: 642.9184 - val_loss: 412525.9062 - val_mae: 495.8158\n",
            "Epoch 120/1000\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 491614.1875 - mae: 638.0683 - val_loss: 411051.7188 - val_mae: 495.7337\n",
            "Epoch 121/1000\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 500118.9375 - mae: 641.4136 - val_loss: 418990.5000 - val_mae: 503.4226\n",
            "Epoch 122/1000\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 488339.2500 - mae: 635.6404 - val_loss: 427872.5312 - val_mae: 512.4050\n",
            "Epoch 123/1000\n",
            "37/37 [==============================] - 10s 253ms/step - loss: 490532.7812 - mae: 637.3973 - val_loss: 419669.0938 - val_mae: 503.8043\n",
            "Epoch 124/1000\n",
            "37/37 [==============================] - 5s 120ms/step - loss: 492508.5312 - mae: 637.4025 - val_loss: 411158.2188 - val_mae: 495.0324\n",
            "Epoch 125/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 501610.5000 - mae: 642.6522 - val_loss: 435935.5000 - val_mae: 519.8492\n",
            "Epoch 126/1000\n",
            "37/37 [==============================] - 10s 252ms/step - loss: 497037.4688 - mae: 641.2482 - val_loss: 418116.6562 - val_mae: 502.9392\n",
            "Epoch 127/1000\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 500462.5312 - mae: 642.1927 - val_loss: 418916.5312 - val_mae: 503.6159\n",
            "Epoch 128/1000\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 502932.5625 - mae: 642.7327 - val_loss: 409738.3438 - val_mae: 494.1960\n",
            "Epoch 129/1000\n",
            "37/37 [==============================] - 5s 117ms/step - loss: 504745.4062 - mae: 644.9973 - val_loss: 426616.9062 - val_mae: 511.5073\n",
            "Epoch 130/1000\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 504901.7812 - mae: 645.8910 - val_loss: 411197.2500 - val_mae: 495.2646\n",
            "Epoch 131/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 497786.7188 - mae: 640.0428 - val_loss: 419485.2500 - val_mae: 503.4776\n",
            "Epoch 132/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 502728.1875 - mae: 643.3541 - val_loss: 428319.2812 - val_mae: 512.4395\n",
            "Epoch 133/1000\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 504373.2188 - mae: 644.7728 - val_loss: 409884.6250 - val_mae: 494.2823\n",
            "Epoch 134/1000\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 502691.5312 - mae: 643.0432 - val_loss: 417512.0312 - val_mae: 502.3656\n",
            "Epoch 135/1000\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 492876.7500 - mae: 639.0488 - val_loss: 419601.1250 - val_mae: 504.3210\n",
            "Epoch 136/1000\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 498064.1250 - mae: 639.7509 - val_loss: 401407.9062 - val_mae: 486.2050\n",
            "Epoch 137/1000\n",
            "37/37 [==============================] - 10s 254ms/step - loss: 502479.6562 - mae: 643.3298 - val_loss: 418301.5938 - val_mae: 503.0466\n",
            "Epoch 138/1000\n",
            "37/37 [==============================] - 5s 120ms/step - loss: 500361.2812 - mae: 642.0698 - val_loss: 403074.0938 - val_mae: 486.9229\n",
            "Epoch 139/1000\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 501383.5938 - mae: 642.2855 - val_loss: 409588.9688 - val_mae: 494.3605\n",
            "Epoch 140/1000\n",
            "37/37 [==============================] - 10s 250ms/step - loss: 501748.1875 - mae: 642.3251 - val_loss: 427119.9062 - val_mae: 511.5493\n",
            "Epoch 141/1000\n",
            "37/37 [==============================] - 10s 251ms/step - loss: 500870.5938 - mae: 641.6921 - val_loss: 418228.5000 - val_mae: 502.7657\n",
            "Epoch 142/1000\n",
            "37/37 [==============================] - 10s 254ms/step - loss: 505242.8750 - mae: 645.0319 - val_loss: 426021.9688 - val_mae: 510.6906\n",
            "Epoch 143/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 498660.7188 - mae: 640.2163 - val_loss: 401335.9062 - val_mae: 486.1602\n",
            "Epoch 144/1000\n",
            "37/37 [==============================] - 10s 255ms/step - loss: 499347.2500 - mae: 641.5217 - val_loss: 417133.0938 - val_mae: 501.8746\n",
            "Epoch 145/1000\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 494058.0625 - mae: 636.9422 - val_loss: 408379.9062 - val_mae: 493.6715\n",
            "Epoch 146/1000\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 491437.3125 - mae: 638.1246 - val_loss: 407954.5312 - val_mae: 493.1409\n",
            "Epoch 147/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 497003.5000 - mae: 640.6498 - val_loss: 416278.6562 - val_mae: 502.2485\n",
            "Epoch 148/1000\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 500956.0312 - mae: 641.6493 - val_loss: 425161.7500 - val_mae: 510.4353\n",
            "Epoch 149/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 500916.7188 - mae: 641.5676 - val_loss: 408018.3750 - val_mae: 493.4650\n",
            "Epoch 150/1000\n",
            "37/37 [==============================] - 5s 118ms/step - loss: 500410.4375 - mae: 641.2757 - val_loss: 426052.9688 - val_mae: 511.2801\n",
            "Epoch 151/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 502718.4688 - mae: 642.4971 - val_loss: 407876.7812 - val_mae: 493.3840\n",
            "Epoch 152/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 500174.6250 - mae: 640.3100 - val_loss: 407792.5312 - val_mae: 493.0448\n",
            "Epoch 153/1000\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 499667.7812 - mae: 640.8874 - val_loss: 416686.7500 - val_mae: 502.1393\n",
            "Epoch 154/1000\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 500670.6250 - mae: 642.0771 - val_loss: 415666.5938 - val_mae: 501.5721\n",
            "Epoch 155/1000\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 502640.1250 - mae: 643.4868 - val_loss: 424514.9688 - val_mae: 510.3531\n",
            "Epoch 156/1000\n",
            "37/37 [==============================] - 6s 136ms/step - loss: 492564.5625 - mae: 637.4331 - val_loss: 424436.4062 - val_mae: 510.0313\n",
            "Epoch 157/1000\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 500339.4688 - mae: 641.1564 - val_loss: 424472.5938 - val_mae: 510.0420\n",
            "Epoch 158/1000\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 496085.3438 - mae: 639.6531 - val_loss: 425244.9688 - val_mae: 510.7552\n",
            "Epoch 159/1000\n",
            "37/37 [==============================] - 6s 130ms/step - loss: 500612.2188 - mae: 640.9788 - val_loss: 408426.6250 - val_mae: 493.6982\n",
            "Epoch 160/1000\n",
            "37/37 [==============================] - 10s 253ms/step - loss: 497849.9062 - mae: 639.0779 - val_loss: 398749.0312 - val_mae: 484.7143\n",
            "Epoch 161/1000\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 501064.0312 - mae: 642.7861 - val_loss: 417147.0938 - val_mae: 502.6577\n",
            "Epoch 162/1000\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 501702.5938 - mae: 642.7362 - val_loss: 416615.3750 - val_mae: 501.8302\n",
            "Epoch 163/1000\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 503446.5938 - mae: 643.2324 - val_loss: 425128.2812 - val_mae: 509.9039\n",
            "Epoch 164/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 499881.9062 - mae: 640.5244 - val_loss: 398437.4688 - val_mae: 484.5388\n",
            "Epoch 165/1000\n",
            "37/37 [==============================] - 5s 118ms/step - loss: 500702.2812 - mae: 641.8276 - val_loss: 424387.8438 - val_mae: 510.0035\n",
            "Epoch 166/1000\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 503166.6875 - mae: 643.1232 - val_loss: 423906.6250 - val_mae: 510.0182\n",
            "Epoch 167/1000\n",
            "37/37 [==============================] - 10s 252ms/step - loss: 502061.0938 - mae: 642.8716 - val_loss: 406984.7188 - val_mae: 492.8735\n",
            "Epoch 168/1000\n",
            "37/37 [==============================] - 10s 251ms/step - loss: 497265.7188 - mae: 638.5052 - val_loss: 414018.4062 - val_mae: 500.3163\n",
            "Epoch 169/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 502474.4062 - mae: 641.9150 - val_loss: 407027.4062 - val_mae: 492.5905\n",
            "Epoch 170/1000\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 499088.1250 - mae: 639.6434 - val_loss: 415505.0312 - val_mae: 501.4762\n",
            "Epoch 171/1000\n",
            "37/37 [==============================] - 5s 120ms/step - loss: 501760.7188 - mae: 642.0474 - val_loss: 415462.4688 - val_mae: 501.1593\n",
            "Epoch 172/1000\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 496371.7812 - mae: 638.3580 - val_loss: 407039.0000 - val_mae: 492.8828\n",
            "Epoch 173/1000\n",
            "37/37 [==============================] - 6s 132ms/step - loss: 499151.6250 - mae: 640.0528 - val_loss: 406994.9062 - val_mae: 492.5929\n",
            "Epoch 174/1000\n",
            "37/37 [==============================] - 10s 255ms/step - loss: 501781.3438 - mae: 641.9229 - val_loss: 407166.3750 - val_mae: 492.9560\n",
            "Epoch 175/1000\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 502063.4375 - mae: 641.6653 - val_loss: 432115.6250 - val_mae: 518.4573\n",
            "Epoch 176/1000\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 499339.2188 - mae: 640.3931 - val_loss: 404972.8438 - val_mae: 492.0499\n",
            "Epoch 177/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 492267.0000 - mae: 637.2438 - val_loss: 421923.1250 - val_mae: 508.9218\n",
            "Epoch 178/1000\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 501016.4062 - mae: 641.0756 - val_loss: 406517.2500 - val_mae: 492.9046\n",
            "Epoch 179/1000\n",
            "37/37 [==============================] - 11s 286ms/step - loss: 502693.6562 - mae: 642.5005 - val_loss: 423979.8438 - val_mae: 509.4648\n",
            "Epoch 180/1000\n",
            "37/37 [==============================] - 6s 142ms/step - loss: 499377.8125 - mae: 640.5267 - val_loss: 414900.0312 - val_mae: 500.8313\n",
            "Epoch 181/1000\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 502299.0000 - mae: 643.2363 - val_loss: 406035.0000 - val_mae: 492.0220\n",
            "Epoch 182/1000\n",
            "37/37 [==============================] - 5s 120ms/step - loss: 494883.1250 - mae: 638.4385 - val_loss: 413709.8750 - val_mae: 500.4649\n",
            "Epoch 183/1000\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 503075.8438 - mae: 643.3058 - val_loss: 414193.3438 - val_mae: 500.7377\n",
            "Epoch 184/1000\n",
            "37/37 [==============================] - 10s 252ms/step - loss: 498705.2188 - mae: 640.0380 - val_loss: 414350.2500 - val_mae: 500.8262\n",
            "Epoch 185/1000\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 495483.1562 - mae: 638.9346 - val_loss: 422119.5000 - val_mae: 509.0305\n",
            "Epoch 186/1000\n",
            "37/37 [==============================] - 5s 120ms/step - loss: 501747.0312 - mae: 641.9797 - val_loss: 405748.5312 - val_mae: 491.8735\n",
            "Epoch 187/1000\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 498891.0625 - mae: 640.8017 - val_loss: 423014.3438 - val_mae: 508.5802\n",
            "Epoch 188/1000\n",
            "37/37 [==============================] - 5s 120ms/step - loss: 502282.3438 - mae: 642.4642 - val_loss: 406633.5938 - val_mae: 492.6722\n",
            "Epoch 189/1000\n",
            "37/37 [==============================] - 6s 137ms/step - loss: 500482.1875 - mae: 640.4337 - val_loss: 415464.9062 - val_mae: 501.1449\n",
            "Epoch 190/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 503163.3125 - mae: 642.3142 - val_loss: 415009.4062 - val_mae: 500.9111\n",
            "Epoch 191/1000\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 501339.2812 - mae: 641.2210 - val_loss: 423522.8750 - val_mae: 509.4989\n",
            "Epoch 192/1000\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 500566.8125 - mae: 640.9786 - val_loss: 397602.2500 - val_mae: 483.7716\n",
            "Epoch 193/1000\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 500743.3125 - mae: 640.8379 - val_loss: 423623.1562 - val_mae: 510.2005\n",
            "Epoch 194/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 500977.6562 - mae: 641.1973 - val_loss: 407194.8750 - val_mae: 492.9831\n",
            "Epoch 195/1000\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 500849.0000 - mae: 640.9863 - val_loss: 399577.0000 - val_mae: 485.1743\n",
            "Epoch 196/1000\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 498737.8750 - mae: 640.1774 - val_loss: 405887.2188 - val_mae: 491.9340\n",
            "Epoch 197/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 505537.0938 - mae: 644.1472 - val_loss: 406591.9062 - val_mae: 492.3316\n",
            "Epoch 198/1000\n",
            "37/37 [==============================] - 10s 252ms/step - loss: 500587.8125 - mae: 640.8952 - val_loss: 406645.1562 - val_mae: 493.0060\n",
            "Epoch 199/1000\n",
            "37/37 [==============================] - 5s 120ms/step - loss: 497404.5312 - mae: 638.7665 - val_loss: 396469.8438 - val_mae: 483.1074\n",
            "Epoch 200/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 498276.6250 - mae: 639.7844 - val_loss: 422860.4062 - val_mae: 508.8220\n",
            "Epoch 201/1000\n",
            "37/37 [==============================] - 10s 253ms/step - loss: 499940.0000 - mae: 640.6113 - val_loss: 415951.1562 - val_mae: 501.7268\n",
            "Epoch 202/1000\n",
            "37/37 [==============================] - 5s 120ms/step - loss: 501032.4688 - mae: 641.7341 - val_loss: 416141.9062 - val_mae: 501.8338\n",
            "Epoch 203/1000\n",
            "37/37 [==============================] - 6s 139ms/step - loss: 503136.7812 - mae: 642.5703 - val_loss: 398707.8438 - val_mae: 484.6967\n",
            "Epoch 204/1000\n",
            "37/37 [==============================] - 10s 252ms/step - loss: 501803.5312 - mae: 642.3770 - val_loss: 408436.8438 - val_mae: 493.7039\n",
            "Epoch 205/1000\n",
            "37/37 [==============================] - 10s 251ms/step - loss: 502307.0938 - mae: 642.3790 - val_loss: 417161.7500 - val_mae: 502.1626\n",
            "Epoch 206/1000\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 501925.2188 - mae: 642.7103 - val_loss: 418034.1562 - val_mae: 503.1416\n",
            "Epoch 207/1000\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 496845.4688 - mae: 638.5700 - val_loss: 408992.7500 - val_mae: 493.7348\n",
            "Epoch 208/1000\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 506275.3125 - mae: 645.3589 - val_loss: 408565.5938 - val_mae: 494.0339\n",
            "Epoch 209/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 502472.1250 - mae: 642.3441 - val_loss: 408727.8438 - val_mae: 493.8597\n",
            "Epoch 210/1000\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 495930.6250 - mae: 638.2683 - val_loss: 408648.3438 - val_mae: 493.8144\n",
            "Epoch 211/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 499212.4375 - mae: 639.9427 - val_loss: 408790.2500 - val_mae: 493.8954\n",
            "Epoch 212/1000\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 503507.3438 - mae: 644.5704 - val_loss: 409786.6562 - val_mae: 494.7052\n",
            "Epoch 213/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 500647.8125 - mae: 641.8794 - val_loss: 425462.7188 - val_mae: 510.3411\n",
            "Epoch 214/1000\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 493795.0938 - mae: 638.3367 - val_loss: 425852.1562 - val_mae: 510.5707\n",
            "Epoch 215/1000\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 502455.5312 - mae: 642.6368 - val_loss: 408624.3750 - val_mae: 494.0656\n",
            "Epoch 216/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 504500.2188 - mae: 643.8356 - val_loss: 416037.0000 - val_mae: 501.4938\n",
            "Epoch 217/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 500617.6875 - mae: 640.7101 - val_loss: 424732.1250 - val_mae: 510.2001\n",
            "Epoch 218/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 502006.9375 - mae: 641.4822 - val_loss: 415232.2188 - val_mae: 501.3228\n",
            "Epoch 219/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 495050.4375 - mae: 639.5413 - val_loss: 407333.9062 - val_mae: 493.0627\n",
            "Epoch 220/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 497638.9688 - mae: 640.3677 - val_loss: 415919.2500 - val_mae: 501.4097\n",
            "Epoch 221/1000\n",
            "37/37 [==============================] - 10s 255ms/step - loss: 488373.5625 - mae: 636.7540 - val_loss: 423481.0312 - val_mae: 509.4748\n",
            "Epoch 222/1000\n",
            "37/37 [==============================] - 10s 253ms/step - loss: 500844.3125 - mae: 641.6318 - val_loss: 405757.3750 - val_mae: 492.4841\n",
            "Epoch 223/1000\n",
            "37/37 [==============================] - 10s 254ms/step - loss: 492003.5625 - mae: 638.2991 - val_loss: 405248.8438 - val_mae: 491.8651\n",
            "Epoch 224/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 499979.0000 - mae: 641.7070 - val_loss: 405345.1562 - val_mae: 492.2556\n",
            "Epoch 225/1000\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 498008.5312 - mae: 638.3788 - val_loss: 387348.0000 - val_mae: 474.4401\n",
            "Epoch 226/1000\n",
            "37/37 [==============================] - 10s 254ms/step - loss: 501755.3125 - mae: 641.4166 - val_loss: 403552.2812 - val_mae: 490.5388\n",
            "Epoch 227/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 503286.9375 - mae: 642.3221 - val_loss: 413839.3438 - val_mae: 500.5380\n",
            "Epoch 228/1000\n",
            "37/37 [==============================] - 6s 142ms/step - loss: 497243.7812 - mae: 640.7431 - val_loss: 396511.0000 - val_mae: 483.1315\n",
            "Epoch 229/1000\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 496535.4375 - mae: 639.4282 - val_loss: 406200.7500 - val_mae: 492.7300\n",
            "Epoch 230/1000\n",
            "37/37 [==============================] - 10s 255ms/step - loss: 501242.7812 - mae: 640.8853 - val_loss: 414623.8750 - val_mae: 501.2884\n",
            "Epoch 231/1000\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 503397.8438 - mae: 643.7173 - val_loss: 397775.7812 - val_mae: 484.1719\n",
            "Epoch 232/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 489661.2500 - mae: 635.7387 - val_loss: 408632.3438 - val_mae: 494.0706\n",
            "Epoch 233/1000\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 502602.8750 - mae: 641.8786 - val_loss: 408045.2812 - val_mae: 493.7476\n",
            "Epoch 234/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 491103.9375 - mae: 636.6783 - val_loss: 398819.8750 - val_mae: 484.7597\n",
            "Epoch 235/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 505712.9375 - mae: 645.2571 - val_loss: 416844.2188 - val_mae: 502.2276\n",
            "Epoch 236/1000\n",
            "37/37 [==============================] - 5s 120ms/step - loss: 494373.0000 - mae: 639.7419 - val_loss: 399582.0312 - val_mae: 484.9280\n",
            "Epoch 237/1000\n",
            "37/37 [==============================] - 6s 131ms/step - loss: 500493.8438 - mae: 642.1202 - val_loss: 425428.6250 - val_mae: 510.5971\n",
            "Epoch 238/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 502028.8125 - mae: 643.0955 - val_loss: 407939.3750 - val_mae: 493.1531\n",
            "Epoch 239/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 502376.4688 - mae: 643.7476 - val_loss: 417004.9062 - val_mae: 502.3223\n",
            "Epoch 240/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 501543.4688 - mae: 642.3506 - val_loss: 418259.6250 - val_mae: 503.0147\n",
            "Epoch 241/1000\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 494620.5938 - mae: 639.3206 - val_loss: 416224.1250 - val_mae: 501.9550\n",
            "Epoch 242/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 500268.9062 - mae: 640.8959 - val_loss: 416813.6562 - val_mae: 502.2152\n",
            "Epoch 243/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 487208.8438 - mae: 635.3975 - val_loss: 409855.7500 - val_mae: 494.5026\n",
            "Epoch 244/1000\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 501156.2812 - mae: 641.5159 - val_loss: 409057.0938 - val_mae: 494.0476\n",
            "Epoch 245/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 500207.0625 - mae: 641.4009 - val_loss: 407462.7188 - val_mae: 493.1366\n",
            "Epoch 246/1000\n",
            "37/37 [==============================] - 6s 138ms/step - loss: 498214.0625 - mae: 640.3397 - val_loss: 398797.7188 - val_mae: 484.7417\n",
            "Epoch 247/1000\n",
            "37/37 [==============================] - 10s 253ms/step - loss: 489715.7812 - mae: 636.4926 - val_loss: 414541.5312 - val_mae: 500.2861\n",
            "Epoch 248/1000\n",
            "37/37 [==============================] - 6s 149ms/step - loss: 503617.6562 - mae: 643.2510 - val_loss: 424335.8438 - val_mae: 510.8882\n",
            "Epoch 249/1000\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 500376.1875 - mae: 641.7164 - val_loss: 405832.4062 - val_mae: 492.8654\n",
            "Epoch 250/1000\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 500643.1250 - mae: 640.9463 - val_loss: 405683.9062 - val_mae: 492.7828\n",
            "Epoch 251/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 494142.6250 - mae: 639.5215 - val_loss: 413836.8750 - val_mae: 500.5308\n",
            "Epoch 252/1000\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 502295.8125 - mae: 643.0743 - val_loss: 404274.8750 - val_mae: 490.9943\n",
            "Epoch 253/1000\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 493680.8125 - mae: 638.5045 - val_loss: 414290.1250 - val_mae: 500.4588\n",
            "Epoch 254/1000\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 501391.1250 - mae: 640.6615 - val_loss: 404702.0312 - val_mae: 491.8996\n",
            "Epoch 255/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 501506.6250 - mae: 641.8560 - val_loss: 396811.9062 - val_mae: 483.6213\n",
            "Epoch 256/1000\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 502429.2500 - mae: 642.8428 - val_loss: 398332.3438 - val_mae: 484.4680\n",
            "Epoch 257/1000\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 500801.3750 - mae: 642.7496 - val_loss: 404928.1250 - val_mae: 491.3620\n",
            "Epoch 258/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 498488.4688 - mae: 640.3078 - val_loss: 404958.6562 - val_mae: 491.7096\n",
            "Epoch 259/1000\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 502055.9062 - mae: 641.7967 - val_loss: 414495.6250 - val_mae: 500.2584\n",
            "Epoch 260/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 505452.2500 - mae: 645.0181 - val_loss: 406474.8750 - val_mae: 492.8814\n",
            "Epoch 261/1000\n",
            "37/37 [==============================] - 10s 255ms/step - loss: 504231.5938 - mae: 644.1685 - val_loss: 414578.8438 - val_mae: 500.9550\n",
            "Epoch 262/1000\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 498766.7500 - mae: 639.3911 - val_loss: 422457.2500 - val_mae: 509.5568\n",
            "Epoch 263/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 499813.8750 - mae: 641.9213 - val_loss: 398100.8438 - val_mae: 484.3492\n",
            "Epoch 264/1000\n",
            "37/37 [==============================] - 10s 255ms/step - loss: 502638.1250 - mae: 641.9839 - val_loss: 414556.2500 - val_mae: 500.9478\n",
            "Epoch 265/1000\n",
            "37/37 [==============================] - 10s 254ms/step - loss: 503249.7500 - mae: 642.9842 - val_loss: 415992.2812 - val_mae: 501.4522\n",
            "Epoch 266/1000\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 505246.6250 - mae: 644.9388 - val_loss: 407287.0312 - val_mae: 492.7448\n",
            "Epoch 267/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 501485.3125 - mae: 641.8561 - val_loss: 415099.2188 - val_mae: 501.2533\n",
            "Epoch 268/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 496183.5312 - mae: 638.0426 - val_loss: 408251.1250 - val_mae: 493.5875\n",
            "Epoch 269/1000\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 503537.3125 - mae: 642.7366 - val_loss: 416495.2812 - val_mae: 502.0321\n",
            "Epoch 270/1000\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 505257.6875 - mae: 645.3809 - val_loss: 391613.2188 - val_mae: 476.8850\n",
            "Epoch 271/1000\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 498583.0312 - mae: 640.1418 - val_loss: 407986.6562 - val_mae: 493.4364\n",
            "Epoch 272/1000\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 492104.5312 - mae: 637.8323 - val_loss: 408923.0938 - val_mae: 493.7144\n",
            "Epoch 273/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 500416.3750 - mae: 640.9716 - val_loss: 407400.6250 - val_mae: 492.8123\n",
            "Epoch 274/1000\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 504154.7812 - mae: 643.5806 - val_loss: 406922.2812 - val_mae: 492.8269\n",
            "Epoch 275/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 502343.4375 - mae: 642.2238 - val_loss: 414313.8438 - val_mae: 500.8113\n",
            "Epoch 276/1000\n",
            "37/37 [==============================] - 10s 253ms/step - loss: 502630.5312 - mae: 642.0529 - val_loss: 406868.2500 - val_mae: 492.7959\n",
            "Epoch 277/1000\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 496385.0938 - mae: 638.4533 - val_loss: 405457.9062 - val_mae: 491.7004\n",
            "Epoch 278/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 503762.7500 - mae: 642.8442 - val_loss: 415148.0312 - val_mae: 501.5776\n",
            "Epoch 279/1000\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 498056.7500 - mae: 639.2217 - val_loss: 399266.9688 - val_mae: 484.7115\n",
            "Epoch 280/1000\n",
            "37/37 [==============================] - 11s 264ms/step - loss: 502500.2812 - mae: 642.6545 - val_loss: 424270.5938 - val_mae: 509.9366\n",
            "Epoch 281/1000\n",
            "37/37 [==============================] - 6s 145ms/step - loss: 500889.4062 - mae: 642.0605 - val_loss: 406570.5000 - val_mae: 492.6471\n",
            "Epoch 282/1000\n",
            "37/37 [==============================] - 10s 255ms/step - loss: 494253.6875 - mae: 637.6375 - val_loss: 406517.7500 - val_mae: 492.3093\n",
            "Epoch 283/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 499341.0312 - mae: 639.9463 - val_loss: 389477.6250 - val_mae: 475.7057\n",
            "Epoch 284/1000\n",
            "37/37 [==============================] - 6s 136ms/step - loss: 504181.5000 - mae: 643.6630 - val_loss: 415101.6562 - val_mae: 501.2494\n",
            "Epoch 285/1000\n",
            "37/37 [==============================] - 10s 254ms/step - loss: 501698.4688 - mae: 641.7642 - val_loss: 406939.6562 - val_mae: 492.5384\n",
            "Epoch 286/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 499282.5312 - mae: 640.1148 - val_loss: 415645.9688 - val_mae: 501.8472\n",
            "Epoch 287/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 504003.5625 - mae: 644.2244 - val_loss: 406559.9062 - val_mae: 492.6410\n",
            "Epoch 288/1000\n",
            "37/37 [==============================] - 6s 135ms/step - loss: 501255.3750 - mae: 641.5964 - val_loss: 423299.0000 - val_mae: 509.3810\n",
            "Epoch 289/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 501738.8438 - mae: 641.8877 - val_loss: 406627.1562 - val_mae: 492.6686\n",
            "Epoch 290/1000\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 500564.6250 - mae: 640.9197 - val_loss: 415691.5000 - val_mae: 501.5861\n",
            "Epoch 291/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 497804.8125 - mae: 639.1576 - val_loss: 423698.8438 - val_mae: 509.3189\n",
            "Epoch 292/1000\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 501241.0625 - mae: 642.6473 - val_loss: 408187.4688 - val_mae: 493.2578\n",
            "Epoch 293/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 502430.6250 - mae: 642.7194 - val_loss: 405258.0938 - val_mae: 491.8936\n",
            "Epoch 294/1000\n",
            "37/37 [==============================] - 6s 135ms/step - loss: 503792.9375 - mae: 643.4358 - val_loss: 407325.5938 - val_mae: 493.3510\n",
            "Epoch 295/1000\n",
            "37/37 [==============================] - 6s 135ms/step - loss: 499816.9062 - mae: 640.8672 - val_loss: 407923.5000 - val_mae: 493.3897\n",
            "Epoch 296/1000\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 504758.0625 - mae: 644.3261 - val_loss: 424049.7500 - val_mae: 510.0969\n",
            "Epoch 297/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 500988.7500 - mae: 641.3497 - val_loss: 415791.3438 - val_mae: 501.3665\n",
            "Epoch 298/1000\n",
            "37/37 [==============================] - 10s 255ms/step - loss: 501437.5938 - mae: 642.2035 - val_loss: 400165.3438 - val_mae: 485.4995\n",
            "Epoch 299/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 503673.5000 - mae: 643.7814 - val_loss: 415072.5000 - val_mae: 500.9478\n",
            "Epoch 300/1000\n",
            "37/37 [==============================] - 10s 254ms/step - loss: 498222.5000 - mae: 641.4880 - val_loss: 424258.0938 - val_mae: 509.9295\n",
            "Epoch 301/1000\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 504804.5000 - mae: 644.6043 - val_loss: 407625.0312 - val_mae: 493.5157\n",
            "Epoch 302/1000\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 498218.7812 - mae: 640.1522 - val_loss: 401116.4062 - val_mae: 485.7730\n",
            "Epoch 303/1000\n",
            "37/37 [==============================] - 6s 135ms/step - loss: 501357.6875 - mae: 641.6270 - val_loss: 399478.0312 - val_mae: 484.8347\n",
            "Epoch 304/1000\n",
            "37/37 [==============================] - 10s 253ms/step - loss: 491421.6875 - mae: 637.0787 - val_loss: 415883.1250 - val_mae: 501.6886\n",
            "Epoch 305/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 501452.8125 - mae: 641.2101 - val_loss: 432885.4062 - val_mae: 518.5886\n",
            "Epoch 306/1000\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 501509.7188 - mae: 642.2856 - val_loss: 415735.2500 - val_mae: 501.0334\n",
            "Epoch 307/1000\n",
            "37/37 [==============================] - 10s 254ms/step - loss: 499883.4375 - mae: 640.5237 - val_loss: 414339.0312 - val_mae: 500.5037\n",
            "Epoch 308/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 495699.0312 - mae: 639.4742 - val_loss: 416277.2500 - val_mae: 501.6181\n",
            "Epoch 309/1000\n",
            "37/37 [==============================] - 10s 254ms/step - loss: 496649.6875 - mae: 638.1325 - val_loss: 415551.4688 - val_mae: 501.4970\n",
            "Epoch 310/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 500153.2500 - mae: 640.8109 - val_loss: 407896.6562 - val_mae: 493.3744\n",
            "Epoch 311/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 502595.6250 - mae: 642.8096 - val_loss: 391220.9688 - val_mae: 476.6491\n",
            "Epoch 312/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 502637.3750 - mae: 642.5401 - val_loss: 433466.5312 - val_mae: 518.9141\n",
            "Epoch 313/1000\n",
            "37/37 [==============================] - 10s 254ms/step - loss: 497031.8750 - mae: 640.4584 - val_loss: 415625.8750 - val_mae: 501.8823\n",
            "Epoch 314/1000\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 505778.4062 - mae: 645.2703 - val_loss: 414535.5938 - val_mae: 500.9307\n",
            "Epoch 315/1000\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 494780.3125 - mae: 638.8441 - val_loss: 415357.5312 - val_mae: 501.3985\n",
            "Epoch 316/1000\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 494902.2188 - mae: 638.8110 - val_loss: 400052.8438 - val_mae: 485.7794\n",
            "Epoch 317/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 491035.0000 - mae: 636.9180 - val_loss: 415832.3750 - val_mae: 501.3748\n",
            "Epoch 318/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 501411.2500 - mae: 641.5793 - val_loss: 399270.4062 - val_mae: 484.7135\n",
            "Epoch 319/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 502167.1562 - mae: 641.9377 - val_loss: 424350.0938 - val_mae: 510.2623\n",
            "Epoch 320/1000\n",
            "37/37 [==============================] - 6s 136ms/step - loss: 501384.1250 - mae: 641.9798 - val_loss: 415709.5938 - val_mae: 501.8761\n",
            "Epoch 321/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 501873.8750 - mae: 641.5018 - val_loss: 424778.7188 - val_mae: 509.6602\n",
            "Epoch 322/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 502330.3438 - mae: 642.7177 - val_loss: 432069.9062 - val_mae: 518.4326\n",
            "Epoch 323/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 493115.7812 - mae: 638.4474 - val_loss: 424148.5312 - val_mae: 510.1516\n",
            "Epoch 324/1000\n",
            "37/37 [==============================] - 10s 254ms/step - loss: 504033.5312 - mae: 643.0193 - val_loss: 423344.5312 - val_mae: 509.4071\n",
            "Epoch 325/1000\n",
            "37/37 [==============================] - 10s 272ms/step - loss: 492703.0625 - mae: 638.7919 - val_loss: 404481.0312 - val_mae: 491.1175\n",
            "Epoch 326/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 499601.7500 - mae: 639.6215 - val_loss: 407160.1250 - val_mae: 493.5985\n",
            "Epoch 327/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 500413.4688 - mae: 641.0295 - val_loss: 408913.0312 - val_mae: 494.2255\n",
            "Epoch 328/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 501975.3750 - mae: 642.6819 - val_loss: 416359.6562 - val_mae: 501.9560\n",
            "Epoch 329/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 501123.3125 - mae: 642.0724 - val_loss: 416130.5312 - val_mae: 501.5482\n",
            "Epoch 330/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 501419.5000 - mae: 641.9368 - val_loss: 417131.7188 - val_mae: 502.3932\n",
            "Epoch 331/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 501241.6875 - mae: 641.6654 - val_loss: 434845.8438 - val_mae: 519.4410\n",
            "Epoch 332/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 500043.5312 - mae: 640.9055 - val_loss: 416972.8750 - val_mae: 502.0378\n",
            "Epoch 333/1000\n",
            "37/37 [==============================] - 10s 255ms/step - loss: 498619.3125 - mae: 640.6565 - val_loss: 400258.0000 - val_mae: 485.3373\n",
            "Epoch 334/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 494402.2500 - mae: 639.5567 - val_loss: 410355.8750 - val_mae: 494.7870\n",
            "Epoch 335/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 499972.9062 - mae: 640.5218 - val_loss: 419417.5312 - val_mae: 503.2431\n",
            "Epoch 336/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 496267.0000 - mae: 638.3792 - val_loss: 419880.7188 - val_mae: 503.9256\n",
            "Epoch 337/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 502502.6562 - mae: 643.1216 - val_loss: 418039.2812 - val_mae: 502.8960\n",
            "Epoch 338/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 500162.2500 - mae: 641.5233 - val_loss: 418728.2188 - val_mae: 502.8310\n",
            "Epoch 339/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 498119.2500 - mae: 640.2073 - val_loss: 409643.7188 - val_mae: 494.1402\n",
            "Epoch 340/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 505388.5312 - mae: 645.8035 - val_loss: 400836.1250 - val_mae: 485.6100\n",
            "Epoch 341/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 496884.4062 - mae: 639.3172 - val_loss: 409107.7812 - val_mae: 494.0865\n",
            "Epoch 342/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 502805.6562 - mae: 643.1124 - val_loss: 416735.4688 - val_mae: 502.4299\n",
            "Epoch 343/1000\n",
            "37/37 [==============================] - 10s 255ms/step - loss: 503200.4375 - mae: 643.6845 - val_loss: 408909.9688 - val_mae: 493.7066\n",
            "Epoch 344/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 502886.4375 - mae: 643.3731 - val_loss: 417533.2500 - val_mae: 502.8719\n",
            "Epoch 345/1000\n",
            "37/37 [==============================] - 6s 144ms/step - loss: 493065.5000 - mae: 638.5797 - val_loss: 425118.8438 - val_mae: 511.2917\n",
            "Epoch 346/1000\n",
            "37/37 [==============================] - 6s 139ms/step - loss: 500411.6562 - mae: 640.9731 - val_loss: 408607.3750 - val_mae: 493.5695\n",
            "Epoch 347/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 503564.9062 - mae: 643.6032 - val_loss: 419091.2500 - val_mae: 503.2500\n",
            "Epoch 348/1000\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 499219.9062 - mae: 641.0212 - val_loss: 407864.7500 - val_mae: 493.6479\n",
            "Epoch 349/1000\n",
            "37/37 [==============================] - 7s 154ms/step - loss: 493508.5000 - mae: 638.5674 - val_loss: 416892.8438 - val_mae: 501.9913\n",
            "Epoch 350/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 501480.8438 - mae: 642.0313 - val_loss: 400609.0312 - val_mae: 485.5095\n",
            "Epoch 351/1000\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 497252.2812 - mae: 639.2031 - val_loss: 433596.3438 - val_mae: 518.9868\n",
            "Epoch 352/1000\n",
            "37/37 [==============================] - 6s 142ms/step - loss: 505151.7812 - mae: 644.4988 - val_loss: 416892.4688 - val_mae: 502.2499\n",
            "Epoch 353/1000\n",
            "37/37 [==============================] - 11s 267ms/step - loss: 501828.2812 - mae: 642.5830 - val_loss: 426704.8438 - val_mae: 511.3136\n",
            "Epoch 354/1000\n",
            "37/37 [==============================] - 11s 274ms/step - loss: 495988.5625 - mae: 640.2929 - val_loss: 408450.1562 - val_mae: 493.6909\n",
            "Epoch 355/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 502692.5625 - mae: 643.0026 - val_loss: 408725.1250 - val_mae: 493.8684\n",
            "Epoch 356/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 499607.2500 - mae: 640.8854 - val_loss: 399930.4062 - val_mae: 485.0985\n",
            "Epoch 357/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 488621.4688 - mae: 636.7230 - val_loss: 398984.8750 - val_mae: 484.8524\n",
            "Epoch 358/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 495424.8750 - mae: 639.9886 - val_loss: 400200.5000 - val_mae: 485.5294\n",
            "Epoch 359/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 499617.3125 - mae: 641.6730 - val_loss: 407765.2812 - val_mae: 493.3203\n",
            "Epoch 360/1000\n",
            "37/37 [==============================] - 11s 273ms/step - loss: 501068.3125 - mae: 641.7280 - val_loss: 416265.5000 - val_mae: 501.9032\n",
            "Epoch 361/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 502929.4375 - mae: 643.0834 - val_loss: 416092.8750 - val_mae: 501.8113\n",
            "Epoch 362/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 503777.6562 - mae: 643.6964 - val_loss: 415606.8438 - val_mae: 500.9560\n",
            "Epoch 363/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 500129.5938 - mae: 641.1329 - val_loss: 415206.7812 - val_mae: 501.3138\n",
            "Epoch 364/1000\n",
            "37/37 [==============================] - 6s 144ms/step - loss: 500488.4062 - mae: 640.6807 - val_loss: 415079.2188 - val_mae: 500.9518\n",
            "Epoch 365/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 495949.1875 - mae: 639.6511 - val_loss: 407063.5000 - val_mae: 492.6120\n",
            "Epoch 366/1000\n",
            "37/37 [==============================] - 6s 141ms/step - loss: 506024.3125 - mae: 646.0679 - val_loss: 406199.5938 - val_mae: 492.4344\n",
            "Epoch 367/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 500411.8750 - mae: 640.9198 - val_loss: 399226.6250 - val_mae: 484.9774\n",
            "Epoch 368/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 504710.3125 - mae: 644.1210 - val_loss: 407003.2500 - val_mae: 492.5762\n",
            "Epoch 369/1000\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 493387.0000 - mae: 638.7696 - val_loss: 416421.4688 - val_mae: 501.9906\n",
            "Epoch 370/1000\n",
            "37/37 [==============================] - 6s 139ms/step - loss: 502164.5625 - mae: 642.2277 - val_loss: 407519.5938 - val_mae: 493.1690\n",
            "Epoch 371/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 504276.9375 - mae: 643.7526 - val_loss: 424509.9688 - val_mae: 510.0733\n",
            "Epoch 372/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 503507.4062 - mae: 644.2194 - val_loss: 418213.0938 - val_mae: 502.9887\n",
            "Epoch 373/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 500952.9688 - mae: 641.5294 - val_loss: 416044.5312 - val_mae: 501.7842\n",
            "Epoch 374/1000\n",
            "37/37 [==============================] - 6s 138ms/step - loss: 498581.7812 - mae: 640.0069 - val_loss: 408787.5938 - val_mae: 493.9041\n",
            "Epoch 375/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 498803.1875 - mae: 640.1135 - val_loss: 432474.0312 - val_mae: 518.6514\n",
            "Epoch 376/1000\n",
            "37/37 [==============================] - 6s 141ms/step - loss: 489083.2188 - mae: 636.9944 - val_loss: 399586.2188 - val_mae: 484.9142\n",
            "Epoch 377/1000\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 503018.9375 - mae: 643.5396 - val_loss: 408036.5938 - val_mae: 493.4544\n",
            "Epoch 378/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 497106.3750 - mae: 639.2767 - val_loss: 423978.3438 - val_mae: 509.7594\n",
            "Epoch 379/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 501542.7500 - mae: 642.4333 - val_loss: 415281.6250 - val_mae: 501.0697\n",
            "Epoch 380/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 500848.5625 - mae: 640.8449 - val_loss: 398686.4688 - val_mae: 484.3890\n",
            "Epoch 381/1000\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 504107.5312 - mae: 644.0134 - val_loss: 408794.4062 - val_mae: 493.8876\n",
            "Epoch 382/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 500878.2812 - mae: 641.8830 - val_loss: 408370.7500 - val_mae: 493.6559\n",
            "Epoch 383/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 499612.4688 - mae: 640.9236 - val_loss: 408549.0000 - val_mae: 493.7679\n",
            "Epoch 384/1000\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 500552.4062 - mae: 642.3506 - val_loss: 416375.1250 - val_mae: 501.9646\n",
            "Epoch 385/1000\n",
            "37/37 [==============================] - 10s 254ms/step - loss: 502822.2188 - mae: 642.8846 - val_loss: 408773.6562 - val_mae: 493.6260\n",
            "Epoch 386/1000\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 497816.0312 - mae: 641.6840 - val_loss: 425634.8750 - val_mae: 510.4626\n",
            "Epoch 387/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 501181.3125 - mae: 642.7462 - val_loss: 425894.5000 - val_mae: 510.8623\n",
            "Epoch 388/1000\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 498990.9062 - mae: 640.4509 - val_loss: 417953.7500 - val_mae: 502.8438\n",
            "Epoch 389/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 496416.5000 - mae: 638.9047 - val_loss: 416319.5312 - val_mae: 501.3854\n",
            "Epoch 390/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 502556.6562 - mae: 642.6739 - val_loss: 425304.0000 - val_mae: 510.2674\n",
            "Epoch 391/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 497931.7188 - mae: 639.4877 - val_loss: 409651.8438 - val_mae: 494.1449\n",
            "Epoch 392/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 499483.3750 - mae: 640.9720 - val_loss: 434901.0938 - val_mae: 519.2320\n",
            "Epoch 393/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 498536.0312 - mae: 640.1057 - val_loss: 402546.6562 - val_mae: 486.8319\n",
            "Epoch 394/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 498030.2500 - mae: 639.3584 - val_loss: 399799.3750 - val_mae: 485.0545\n",
            "Epoch 395/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 501958.9688 - mae: 641.4841 - val_loss: 416520.1562 - val_mae: 502.0508\n",
            "Epoch 396/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 502979.6875 - mae: 643.2585 - val_loss: 434418.5938 - val_mae: 519.4466\n",
            "Epoch 397/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 495188.7812 - mae: 640.2028 - val_loss: 409644.7812 - val_mae: 494.1408\n",
            "Epoch 398/1000\n",
            "37/37 [==============================] - 10s 255ms/step - loss: 500485.0625 - mae: 641.7148 - val_loss: 400483.4688 - val_mae: 485.6927\n",
            "Epoch 399/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 499424.0625 - mae: 640.7320 - val_loss: 425078.2812 - val_mae: 510.6630\n",
            "Epoch 400/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 501705.7812 - mae: 642.1340 - val_loss: 419751.2188 - val_mae: 503.6311\n",
            "Epoch 401/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 502817.5938 - mae: 642.6239 - val_loss: 409639.6250 - val_mae: 494.1789\n",
            "Epoch 402/1000\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 505015.0938 - mae: 644.6055 - val_loss: 428222.7812 - val_mae: 512.3869\n",
            "Epoch 403/1000\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 500867.3125 - mae: 641.8569 - val_loss: 409750.9062 - val_mae: 494.4527\n",
            "Epoch 404/1000\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 499085.2500 - mae: 640.5011 - val_loss: 418810.8438 - val_mae: 503.1024\n",
            "Epoch 405/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 491280.6562 - mae: 636.5117 - val_loss: 401501.5938 - val_mae: 486.0278\n",
            "Epoch 406/1000\n",
            "37/37 [==============================] - 10s 255ms/step - loss: 495694.9688 - mae: 639.5849 - val_loss: 416932.4062 - val_mae: 502.0295\n",
            "Epoch 407/1000\n",
            "37/37 [==============================] - 6s 141ms/step - loss: 503333.3438 - mae: 642.9454 - val_loss: 415683.1562 - val_mae: 501.9145\n",
            "Epoch 408/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 498196.6875 - mae: 641.1845 - val_loss: 399752.9062 - val_mae: 485.0113\n",
            "Epoch 409/1000\n",
            "37/37 [==============================] - 10s 255ms/step - loss: 495827.7500 - mae: 638.9066 - val_loss: 415783.4688 - val_mae: 501.6326\n",
            "Epoch 410/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 496017.7500 - mae: 642.0949 - val_loss: 407819.0938 - val_mae: 493.6230\n",
            "Epoch 411/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 496690.0938 - mae: 638.4966 - val_loss: 408800.7500 - val_mae: 494.1631\n",
            "Epoch 412/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 499612.8125 - mae: 641.7543 - val_loss: 398240.7188 - val_mae: 484.1453\n",
            "Epoch 413/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 498554.8438 - mae: 640.0370 - val_loss: 399628.9062 - val_mae: 485.2088\n",
            "Epoch 414/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 501019.9375 - mae: 641.7963 - val_loss: 425204.2500 - val_mae: 510.1885\n",
            "Epoch 415/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 500237.1875 - mae: 641.6167 - val_loss: 406810.8438 - val_mae: 492.7739\n",
            "Epoch 416/1000\n",
            "37/37 [==============================] - 10s 272ms/step - loss: 494248.3125 - mae: 639.3895 - val_loss: 399196.2812 - val_mae: 484.6703\n",
            "Epoch 417/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 502664.0938 - mae: 642.7718 - val_loss: 407007.1562 - val_mae: 492.8755\n",
            "Epoch 418/1000\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 494703.1250 - mae: 639.6655 - val_loss: 433255.8438 - val_mae: 518.5206\n",
            "Epoch 419/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 501575.0312 - mae: 641.5523 - val_loss: 416486.8438 - val_mae: 502.3016\n",
            "Epoch 420/1000\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 500319.0000 - mae: 641.8781 - val_loss: 423517.8438 - val_mae: 509.5063\n",
            "Epoch 421/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 496357.3750 - mae: 637.9619 - val_loss: 424094.3438 - val_mae: 509.8257\n",
            "Epoch 422/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 502527.6250 - mae: 641.9767 - val_loss: 413076.7500 - val_mae: 500.1133\n",
            "Epoch 423/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 499633.5312 - mae: 640.3442 - val_loss: 414418.9688 - val_mae: 500.5666\n",
            "Epoch 424/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 498205.5312 - mae: 639.1866 - val_loss: 422790.1250 - val_mae: 509.0789\n",
            "Epoch 425/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 502883.9062 - mae: 643.7058 - val_loss: 406351.0000 - val_mae: 492.5102\n",
            "Epoch 426/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 497210.0625 - mae: 640.9179 - val_loss: 407460.7188 - val_mae: 493.1354\n",
            "Epoch 427/1000\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 498142.1250 - mae: 639.8865 - val_loss: 406667.5000 - val_mae: 492.6807\n",
            "Epoch 428/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 496728.0312 - mae: 638.9574 - val_loss: 423628.2188 - val_mae: 509.2564\n",
            "Epoch 429/1000\n",
            "37/37 [==============================] - 6s 137ms/step - loss: 503413.3750 - mae: 642.7979 - val_loss: 388975.5938 - val_mae: 475.3929\n",
            "Epoch 430/1000\n",
            "37/37 [==============================] - 11s 270ms/step - loss: 501331.0938 - mae: 642.0103 - val_loss: 407210.9688 - val_mae: 492.9815\n",
            "Epoch 431/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 503457.5938 - mae: 643.2556 - val_loss: 424217.5312 - val_mae: 510.1896\n",
            "Epoch 432/1000\n",
            "37/37 [==============================] - 11s 288ms/step - loss: 500124.5312 - mae: 640.1053 - val_loss: 406714.5312 - val_mae: 492.4480\n",
            "Epoch 433/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 500427.6562 - mae: 640.6245 - val_loss: 408461.8750 - val_mae: 493.4625\n",
            "Epoch 434/1000\n",
            "37/37 [==============================] - 6s 136ms/step - loss: 504507.8125 - mae: 644.9883 - val_loss: 408347.6562 - val_mae: 493.6427\n",
            "Epoch 435/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 499912.9062 - mae: 640.3239 - val_loss: 416313.0938 - val_mae: 501.9298\n",
            "Epoch 436/1000\n",
            "37/37 [==============================] - 6s 137ms/step - loss: 500084.9062 - mae: 640.3589 - val_loss: 423216.1562 - val_mae: 509.6370\n",
            "Epoch 437/1000\n",
            "37/37 [==============================] - 11s 272ms/step - loss: 498176.2812 - mae: 638.5082 - val_loss: 423594.6562 - val_mae: 510.1443\n",
            "Epoch 438/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 500245.2188 - mae: 640.0995 - val_loss: 415585.7188 - val_mae: 501.5267\n",
            "Epoch 439/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 498138.8750 - mae: 639.6245 - val_loss: 390264.2500 - val_mae: 476.1455\n",
            "Epoch 440/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 504365.1875 - mae: 643.7230 - val_loss: 400026.2500 - val_mae: 485.4317\n",
            "Epoch 441/1000\n",
            "37/37 [==============================] - 10s 255ms/step - loss: 502734.4688 - mae: 642.7408 - val_loss: 400734.6250 - val_mae: 485.5825\n",
            "Epoch 442/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 499653.1562 - mae: 640.8667 - val_loss: 408321.9688 - val_mae: 493.6383\n",
            "Epoch 443/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 501582.3438 - mae: 642.8134 - val_loss: 407300.2812 - val_mae: 493.0542\n",
            "Epoch 444/1000\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 502049.0938 - mae: 642.4597 - val_loss: 398868.6562 - val_mae: 484.4955\n",
            "Epoch 445/1000\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 502092.2188 - mae: 643.0876 - val_loss: 390609.0938 - val_mae: 476.3319\n",
            "Epoch 446/1000\n",
            "37/37 [==============================] - 11s 277ms/step - loss: 499566.0312 - mae: 641.9960 - val_loss: 397741.8438 - val_mae: 483.8534\n",
            "Epoch 447/1000\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 502623.1250 - mae: 642.9126 - val_loss: 415357.2500 - val_mae: 501.3878\n",
            "Epoch 448/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 501743.2188 - mae: 641.4993 - val_loss: 397049.9062 - val_mae: 483.7559\n",
            "Epoch 449/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 499907.0938 - mae: 640.9474 - val_loss: 414464.6250 - val_mae: 500.5609\n",
            "Epoch 450/1000\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 495643.5312 - mae: 637.4995 - val_loss: 397152.6250 - val_mae: 483.4908\n",
            "Epoch 451/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 500781.7500 - mae: 641.3348 - val_loss: 413705.1562 - val_mae: 500.1329\n",
            "Epoch 452/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 496650.0625 - mae: 638.5795 - val_loss: 405605.3438 - val_mae: 492.4004\n",
            "Epoch 453/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 495041.0312 - mae: 638.3350 - val_loss: 430122.5000 - val_mae: 517.0347\n",
            "Epoch 454/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 495347.7812 - mae: 637.1721 - val_loss: 431573.3750 - val_mae: 518.1906\n",
            "Epoch 455/1000\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 498509.9062 - mae: 640.6584 - val_loss: 397380.0312 - val_mae: 483.9363\n",
            "Epoch 456/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 497776.9375 - mae: 639.0292 - val_loss: 398014.6250 - val_mae: 484.2947\n",
            "Epoch 457/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 499820.1562 - mae: 639.7952 - val_loss: 404914.9062 - val_mae: 491.6844\n",
            "Epoch 458/1000\n",
            "37/37 [==============================] - 6s 144ms/step - loss: 503951.4375 - mae: 643.5724 - val_loss: 406155.3438 - val_mae: 492.0717\n",
            "Epoch 459/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 500079.2188 - mae: 640.3366 - val_loss: 424051.2500 - val_mae: 509.8011\n",
            "Epoch 460/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 499992.8438 - mae: 641.4747 - val_loss: 406473.3438 - val_mae: 492.2610\n",
            "Epoch 461/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 483923.6875 - mae: 633.7001 - val_loss: 405109.6562 - val_mae: 491.7965\n",
            "Epoch 462/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 504355.4688 - mae: 643.9585 - val_loss: 407012.7812 - val_mae: 493.1783\n",
            "Epoch 463/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 500959.3438 - mae: 640.6668 - val_loss: 414245.2500 - val_mae: 500.4489\n",
            "Epoch 464/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 496040.1875 - mae: 640.0579 - val_loss: 415298.8750 - val_mae: 501.3550\n",
            "Epoch 465/1000\n",
            "37/37 [==============================] - 6s 138ms/step - loss: 500300.6875 - mae: 641.2186 - val_loss: 405468.0312 - val_mae: 491.9913\n",
            "Epoch 466/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 494873.2500 - mae: 639.6710 - val_loss: 407077.0000 - val_mae: 492.5984\n",
            "Epoch 467/1000\n",
            "37/37 [==============================] - 6s 142ms/step - loss: 499056.8125 - mae: 639.8892 - val_loss: 406205.1250 - val_mae: 492.4264\n",
            "Epoch 468/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 496070.4375 - mae: 640.4753 - val_loss: 390575.5938 - val_mae: 476.2899\n",
            "Epoch 469/1000\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 502535.9062 - mae: 642.8224 - val_loss: 415571.7188 - val_mae: 501.5136\n",
            "Epoch 470/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 499444.2812 - mae: 640.6623 - val_loss: 406040.0938 - val_mae: 492.0030\n",
            "Epoch 471/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 504625.3750 - mae: 644.9685 - val_loss: 423450.1250 - val_mae: 510.0675\n",
            "Epoch 472/1000\n",
            "37/37 [==============================] - 6s 139ms/step - loss: 500674.9688 - mae: 641.2324 - val_loss: 414475.2500 - val_mae: 500.8966\n",
            "Epoch 473/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 501231.4375 - mae: 641.3503 - val_loss: 405516.0938 - val_mae: 492.3510\n",
            "Epoch 474/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 500732.5312 - mae: 641.9424 - val_loss: 415070.8438 - val_mae: 500.9469\n",
            "Epoch 475/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 501552.1250 - mae: 641.3051 - val_loss: 423529.3438 - val_mae: 508.9267\n",
            "Epoch 476/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 504411.0938 - mae: 643.6727 - val_loss: 415447.2812 - val_mae: 500.8598\n",
            "Epoch 477/1000\n",
            "37/37 [==============================] - 6s 138ms/step - loss: 502860.8750 - mae: 643.6369 - val_loss: 415227.5000 - val_mae: 501.3255\n",
            "Epoch 478/1000\n",
            "37/37 [==============================] - 10s 272ms/step - loss: 499995.8125 - mae: 641.6644 - val_loss: 423764.1562 - val_mae: 509.6472\n",
            "Epoch 479/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 497623.8125 - mae: 639.9464 - val_loss: 407043.8750 - val_mae: 493.2451\n",
            "Epoch 480/1000\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 507259.5000 - mae: 646.8221 - val_loss: 415123.1250 - val_mae: 501.3146\n",
            "Epoch 481/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 502905.4062 - mae: 642.8074 - val_loss: 415584.0000 - val_mae: 501.8136\n",
            "Epoch 482/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 500875.6562 - mae: 641.4455 - val_loss: 423885.7812 - val_mae: 509.7168\n",
            "Epoch 483/1000\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 503267.1250 - mae: 642.5023 - val_loss: 407700.0938 - val_mae: 493.5573\n",
            "Epoch 484/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 489870.4062 - mae: 636.2788 - val_loss: 424150.0938 - val_mae: 509.3065\n",
            "Epoch 485/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 500313.5000 - mae: 640.8020 - val_loss: 416256.7500 - val_mae: 501.6217\n",
            "Epoch 486/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 500233.5000 - mae: 641.8069 - val_loss: 407334.3438 - val_mae: 493.0737\n",
            "Epoch 487/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 502264.8125 - mae: 643.1858 - val_loss: 425784.5938 - val_mae: 511.6549\n",
            "Epoch 488/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 502096.8750 - mae: 641.8866 - val_loss: 416077.6250 - val_mae: 502.0806\n",
            "Epoch 489/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 496686.7812 - mae: 640.6370 - val_loss: 406292.5938 - val_mae: 492.7804\n",
            "Epoch 490/1000\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 500984.1250 - mae: 641.1441 - val_loss: 415033.5000 - val_mae: 501.2164\n",
            "Epoch 491/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 500814.3438 - mae: 641.1809 - val_loss: 416830.8438 - val_mae: 502.2153\n",
            "Epoch 492/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 502814.9688 - mae: 643.3558 - val_loss: 415488.0938 - val_mae: 501.4667\n",
            "Epoch 493/1000\n",
            "37/37 [==============================] - 6s 137ms/step - loss: 503430.5938 - mae: 642.7482 - val_loss: 431940.4688 - val_mae: 517.4577\n",
            "Epoch 494/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 492395.5312 - mae: 637.3891 - val_loss: 406583.7812 - val_mae: 492.9418\n",
            "Epoch 495/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 499039.0625 - mae: 639.2395 - val_loss: 407233.0000 - val_mae: 493.0265\n",
            "Epoch 496/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 504656.0625 - mae: 644.3785 - val_loss: 408780.7500 - val_mae: 493.8798\n",
            "Epoch 497/1000\n",
            "37/37 [==============================] - 10s 272ms/step - loss: 500829.9062 - mae: 641.5223 - val_loss: 415495.9688 - val_mae: 501.1946\n",
            "Epoch 498/1000\n",
            "37/37 [==============================] - 6s 139ms/step - loss: 494283.3125 - mae: 638.9366 - val_loss: 408953.7500 - val_mae: 493.9886\n",
            "Epoch 499/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 492868.6250 - mae: 638.2537 - val_loss: 415716.5938 - val_mae: 501.3230\n",
            "Epoch 500/1000\n",
            "37/37 [==============================] - 11s 273ms/step - loss: 495982.3438 - mae: 639.5298 - val_loss: 408082.6562 - val_mae: 493.7682\n",
            "Epoch 501/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 501372.1562 - mae: 642.6912 - val_loss: 417187.1250 - val_mae: 502.4242\n",
            "Epoch 502/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 501866.3438 - mae: 643.0251 - val_loss: 416521.5000 - val_mae: 501.7910\n",
            "Epoch 503/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 496285.1562 - mae: 638.6329 - val_loss: 400009.8750 - val_mae: 485.4225\n",
            "Epoch 504/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 502920.2500 - mae: 642.6958 - val_loss: 415855.0000 - val_mae: 501.6779\n",
            "Epoch 505/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 490678.5000 - mae: 636.9274 - val_loss: 416624.6562 - val_mae: 502.3818\n",
            "Epoch 506/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 501984.0000 - mae: 643.0995 - val_loss: 408751.2500 - val_mae: 493.6336\n",
            "Epoch 507/1000\n",
            "37/37 [==============================] - 6s 142ms/step - loss: 501254.0938 - mae: 642.5371 - val_loss: 424687.7500 - val_mae: 510.1748\n",
            "Epoch 508/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 499053.1875 - mae: 640.3252 - val_loss: 407953.4688 - val_mae: 493.1190\n",
            "Epoch 509/1000\n",
            "37/37 [==============================] - 6s 138ms/step - loss: 503409.4375 - mae: 643.1157 - val_loss: 416781.6250 - val_mae: 502.5258\n",
            "Epoch 510/1000\n",
            "37/37 [==============================] - 6s 146ms/step - loss: 500566.2812 - mae: 640.9610 - val_loss: 406688.6250 - val_mae: 492.9993\n",
            "Epoch 511/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 496230.4375 - mae: 639.2581 - val_loss: 425532.1562 - val_mae: 511.1823\n",
            "Epoch 512/1000\n",
            "37/37 [==============================] - 6s 137ms/step - loss: 497652.4688 - mae: 642.1364 - val_loss: 406853.0000 - val_mae: 492.8090\n",
            "Epoch 513/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 500219.2812 - mae: 640.2001 - val_loss: 407336.0938 - val_mae: 493.3567\n",
            "Epoch 514/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 503218.7500 - mae: 643.7105 - val_loss: 426935.6562 - val_mae: 511.2085\n",
            "Epoch 515/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 505042.4062 - mae: 644.7900 - val_loss: 400082.4688 - val_mae: 485.2032\n",
            "Epoch 516/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 503155.2500 - mae: 644.0359 - val_loss: 410163.5938 - val_mae: 494.6776\n",
            "Epoch 517/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 503590.4375 - mae: 644.2393 - val_loss: 417496.9062 - val_mae: 502.5883\n",
            "Epoch 518/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 502644.7812 - mae: 644.0557 - val_loss: 409305.2500 - val_mae: 494.1791\n",
            "Epoch 519/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 491702.2188 - mae: 636.9811 - val_loss: 408276.8750 - val_mae: 493.6023\n",
            "Epoch 520/1000\n",
            "37/37 [==============================] - 11s 274ms/step - loss: 500769.5312 - mae: 641.1148 - val_loss: 400007.5000 - val_mae: 485.1435\n",
            "Epoch 521/1000\n",
            "37/37 [==============================] - 10s 272ms/step - loss: 502173.4688 - mae: 642.7823 - val_loss: 417054.0938 - val_mae: 502.6076\n",
            "Epoch 522/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 501456.4375 - mae: 641.9596 - val_loss: 416940.4688 - val_mae: 502.0190\n",
            "Epoch 523/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 493815.5938 - mae: 638.2431 - val_loss: 415549.7812 - val_mae: 501.7898\n",
            "Epoch 524/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 503012.2188 - mae: 643.0330 - val_loss: 405894.2500 - val_mae: 492.2592\n",
            "Epoch 525/1000\n",
            "37/37 [==============================] - 6s 149ms/step - loss: 503602.4688 - mae: 643.0674 - val_loss: 416343.3438 - val_mae: 501.6875\n",
            "Epoch 526/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 495023.9375 - mae: 640.9284 - val_loss: 416816.2500 - val_mae: 502.2166\n",
            "Epoch 527/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 504909.9062 - mae: 644.5988 - val_loss: 408990.9688 - val_mae: 494.0099\n",
            "Epoch 528/1000\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 503777.0000 - mae: 643.7734 - val_loss: 399983.5000 - val_mae: 485.1456\n",
            "Epoch 529/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 505582.9062 - mae: 645.3469 - val_loss: 426381.5312 - val_mae: 511.1393\n",
            "Epoch 530/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 502734.0312 - mae: 642.9565 - val_loss: 408375.5938 - val_mae: 493.6689\n",
            "Epoch 531/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 504994.9688 - mae: 645.0164 - val_loss: 410231.5312 - val_mae: 494.7163\n",
            "Epoch 532/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 493965.3125 - mae: 637.5830 - val_loss: 400144.1562 - val_mae: 485.4978\n",
            "Epoch 533/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 501325.1562 - mae: 642.3221 - val_loss: 415694.7188 - val_mae: 501.3103\n",
            "Epoch 534/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 498339.1875 - mae: 639.8195 - val_loss: 414553.7812 - val_mae: 500.6453\n",
            "Epoch 535/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 498973.2500 - mae: 639.9906 - val_loss: 416756.2500 - val_mae: 501.8967\n",
            "Epoch 536/1000\n",
            "37/37 [==============================] - 6s 139ms/step - loss: 500307.4062 - mae: 640.8631 - val_loss: 415510.7500 - val_mae: 501.4794\n",
            "Epoch 537/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 502942.2812 - mae: 643.1972 - val_loss: 406292.9688 - val_mae: 492.4879\n",
            "Epoch 538/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 500967.5938 - mae: 641.3352 - val_loss: 415190.8438 - val_mae: 501.0168\n",
            "Epoch 539/1000\n",
            "37/37 [==============================] - 6s 141ms/step - loss: 499832.3438 - mae: 640.9249 - val_loss: 399011.1250 - val_mae: 484.5786\n",
            "Epoch 540/1000\n",
            "37/37 [==============================] - 10s 273ms/step - loss: 500982.5000 - mae: 641.2061 - val_loss: 407006.0312 - val_mae: 492.5778\n",
            "Epoch 541/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 503684.5000 - mae: 643.4081 - val_loss: 415555.9062 - val_mae: 500.9253\n",
            "Epoch 542/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 501413.3750 - mae: 642.0530 - val_loss: 415310.9688 - val_mae: 501.0710\n",
            "Epoch 543/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 502411.6562 - mae: 642.5618 - val_loss: 415544.2812 - val_mae: 500.9183\n",
            "Epoch 544/1000\n",
            "37/37 [==============================] - 6s 132ms/step - loss: 503940.5000 - mae: 643.9373 - val_loss: 415383.6250 - val_mae: 501.1133\n",
            "Epoch 545/1000\n",
            "37/37 [==============================] - 10s 278ms/step - loss: 497295.2812 - mae: 639.9216 - val_loss: 408061.9062 - val_mae: 493.7571\n",
            "Epoch 546/1000\n",
            "37/37 [==============================] - 6s 135ms/step - loss: 502191.6250 - mae: 641.9625 - val_loss: 425087.5312 - val_mae: 510.3929\n",
            "Epoch 547/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 498679.5312 - mae: 640.2875 - val_loss: 416466.2500 - val_mae: 501.7589\n",
            "Epoch 548/1000\n",
            "37/37 [==============================] - 6s 138ms/step - loss: 504444.6562 - mae: 643.4379 - val_loss: 432903.4688 - val_mae: 518.3724\n",
            "Epoch 549/1000\n",
            "37/37 [==============================] - 10s 272ms/step - loss: 503285.5938 - mae: 643.4103 - val_loss: 416469.3438 - val_mae: 502.2864\n",
            "Epoch 550/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 496403.6875 - mae: 638.2964 - val_loss: 399124.9062 - val_mae: 484.6615\n",
            "Epoch 551/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 501486.5000 - mae: 642.5128 - val_loss: 417195.7812 - val_mae: 502.6840\n",
            "Epoch 552/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 503679.8438 - mae: 643.1507 - val_loss: 425489.6562 - val_mae: 510.8898\n",
            "Epoch 553/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 498775.8125 - mae: 639.9289 - val_loss: 415688.5000 - val_mae: 501.5793\n",
            "Epoch 554/1000\n",
            "37/37 [==============================] - 6s 139ms/step - loss: 500687.4375 - mae: 641.4407 - val_loss: 425427.4062 - val_mae: 510.5964\n",
            "Epoch 555/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 500860.3125 - mae: 641.1542 - val_loss: 417291.1562 - val_mae: 502.2074\n",
            "Epoch 556/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 501759.3438 - mae: 642.5502 - val_loss: 408296.3438 - val_mae: 493.6237\n",
            "Epoch 557/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 499971.9688 - mae: 640.5452 - val_loss: 408156.5000 - val_mae: 493.5334\n",
            "Epoch 558/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 501972.2188 - mae: 642.7980 - val_loss: 416537.6562 - val_mae: 501.7850\n",
            "Epoch 559/1000\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 503807.4375 - mae: 643.3674 - val_loss: 408151.4688 - val_mae: 493.5306\n",
            "Epoch 560/1000\n",
            "37/37 [==============================] - 6s 141ms/step - loss: 501335.6875 - mae: 641.9705 - val_loss: 398243.1250 - val_mae: 484.1466\n",
            "Epoch 561/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 501530.4375 - mae: 642.1644 - val_loss: 399855.3438 - val_mae: 485.0710\n",
            "Epoch 562/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 494259.3125 - mae: 637.3264 - val_loss: 399366.0938 - val_mae: 485.0612\n",
            "Epoch 563/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 503553.7500 - mae: 643.2679 - val_loss: 416171.7500 - val_mae: 501.5722\n",
            "Epoch 564/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 496290.0312 - mae: 640.1992 - val_loss: 408306.6562 - val_mae: 493.3495\n",
            "Epoch 565/1000\n",
            "37/37 [==============================] - 11s 274ms/step - loss: 500362.8438 - mae: 641.9180 - val_loss: 399680.4062 - val_mae: 485.2377\n",
            "Epoch 566/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 502710.7188 - mae: 643.4378 - val_loss: 417420.7812 - val_mae: 502.2826\n",
            "Epoch 567/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 504981.7812 - mae: 645.0731 - val_loss: 417295.0312 - val_mae: 502.4799\n",
            "Epoch 568/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 500870.3125 - mae: 642.1961 - val_loss: 407348.8438 - val_mae: 493.3636\n",
            "Epoch 569/1000\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 497767.7500 - mae: 639.7270 - val_loss: 406963.5938 - val_mae: 492.5742\n",
            "Epoch 570/1000\n",
            "37/37 [==============================] - 11s 270ms/step - loss: 501403.5938 - mae: 641.8085 - val_loss: 417256.6562 - val_mae: 502.1874\n",
            "Epoch 571/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 497301.0625 - mae: 639.3253 - val_loss: 407212.0312 - val_mae: 493.0037\n",
            "Epoch 572/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 503294.5625 - mae: 643.3212 - val_loss: 408250.4062 - val_mae: 493.2951\n",
            "Epoch 573/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 500712.3125 - mae: 641.7247 - val_loss: 405986.9062 - val_mae: 492.0154\n",
            "Epoch 574/1000\n",
            "37/37 [==============================] - 6s 145ms/step - loss: 493591.3750 - mae: 638.4623 - val_loss: 399516.3438 - val_mae: 485.1402\n",
            "Epoch 575/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 502789.6562 - mae: 642.1154 - val_loss: 415060.0312 - val_mae: 501.2260\n",
            "Epoch 576/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 502366.2500 - mae: 642.9109 - val_loss: 408280.0312 - val_mae: 493.8764\n",
            "Epoch 577/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 501076.0000 - mae: 642.1090 - val_loss: 406751.4062 - val_mae: 493.0776\n",
            "Epoch 578/1000\n",
            "37/37 [==============================] - 6s 140ms/step - loss: 500086.5000 - mae: 642.2458 - val_loss: 398479.0938 - val_mae: 484.5737\n",
            "Epoch 579/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 504649.1875 - mae: 644.8375 - val_loss: 415366.6562 - val_mae: 500.8111\n",
            "Epoch 580/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 505834.5625 - mae: 645.6252 - val_loss: 406913.6562 - val_mae: 493.1237\n",
            "Epoch 581/1000\n",
            "37/37 [==============================] - 11s 276ms/step - loss: 499001.9062 - mae: 639.7917 - val_loss: 407580.3438 - val_mae: 493.4915\n",
            "Epoch 582/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 501360.4375 - mae: 641.8652 - val_loss: 408606.6562 - val_mae: 493.7804\n",
            "Epoch 583/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 503718.0000 - mae: 643.7671 - val_loss: 424946.6562 - val_mae: 510.3224\n",
            "Epoch 584/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 498551.0312 - mae: 639.8163 - val_loss: 400120.6562 - val_mae: 485.4846\n",
            "Epoch 585/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 500967.8125 - mae: 641.5971 - val_loss: 390796.4688 - val_mae: 476.4506\n",
            "Epoch 586/1000\n",
            "37/37 [==============================] - 11s 274ms/step - loss: 504206.2812 - mae: 644.6639 - val_loss: 408671.9688 - val_mae: 494.0917\n",
            "Epoch 587/1000\n",
            "37/37 [==============================] - 10s 272ms/step - loss: 494874.4375 - mae: 640.1168 - val_loss: 425212.1250 - val_mae: 510.7366\n",
            "Epoch 588/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 499394.4688 - mae: 640.5203 - val_loss: 416281.0938 - val_mae: 501.9119\n",
            "Epoch 589/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 492540.0000 - mae: 637.7580 - val_loss: 406927.8438 - val_mae: 493.1316\n",
            "Epoch 590/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 499980.2188 - mae: 640.8728 - val_loss: 399315.2812 - val_mae: 485.0326\n",
            "Epoch 591/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 504645.0000 - mae: 644.2498 - val_loss: 415066.9062 - val_mae: 500.9127\n",
            "Epoch 592/1000\n",
            "37/37 [==============================] - 11s 279ms/step - loss: 502457.6875 - mae: 642.4850 - val_loss: 406767.5312 - val_mae: 492.7381\n",
            "Epoch 593/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 498141.6875 - mae: 642.0438 - val_loss: 407387.7500 - val_mae: 492.8261\n",
            "Epoch 594/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 502148.4062 - mae: 643.4387 - val_loss: 406867.0312 - val_mae: 492.8061\n",
            "Epoch 595/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 495372.5938 - mae: 638.6736 - val_loss: 425069.5938 - val_mae: 510.3827\n",
            "Epoch 596/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 504978.4062 - mae: 644.1879 - val_loss: 416293.9062 - val_mae: 501.9191\n",
            "Epoch 597/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 499018.9062 - mae: 640.9562 - val_loss: 400344.6250 - val_mae: 485.3398\n",
            "Epoch 598/1000\n",
            "37/37 [==============================] - 11s 274ms/step - loss: 502985.7188 - mae: 643.3477 - val_loss: 424828.0312 - val_mae: 509.9664\n",
            "Epoch 599/1000\n",
            "37/37 [==============================] - 10s 272ms/step - loss: 502056.2500 - mae: 642.4780 - val_loss: 416176.3438 - val_mae: 501.8531\n",
            "Epoch 600/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 499050.4062 - mae: 641.7876 - val_loss: 407387.9062 - val_mae: 493.0937\n",
            "Epoch 601/1000\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 499786.0625 - mae: 640.0787 - val_loss: 423727.8438 - val_mae: 509.9194\n",
            "Epoch 602/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 493242.4062 - mae: 639.0637 - val_loss: 408040.6562 - val_mae: 493.4567\n",
            "Epoch 603/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 498405.3438 - mae: 640.9952 - val_loss: 406963.2500 - val_mae: 492.8503\n",
            "Epoch 604/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 502265.4062 - mae: 642.5566 - val_loss: 415953.0000 - val_mae: 501.4294\n",
            "Epoch 605/1000\n",
            "37/37 [==============================] - 6s 143ms/step - loss: 501238.5312 - mae: 641.9666 - val_loss: 415632.3438 - val_mae: 501.5529\n",
            "Epoch 606/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 499245.9688 - mae: 640.5557 - val_loss: 399259.1250 - val_mae: 484.7398\n",
            "Epoch 607/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 500565.3750 - mae: 641.5948 - val_loss: 415640.0000 - val_mae: 501.2784\n",
            "Epoch 608/1000\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 501365.3750 - mae: 641.2161 - val_loss: 404981.6562 - val_mae: 491.7345\n",
            "Epoch 609/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 501754.7812 - mae: 642.2615 - val_loss: 413987.9688 - val_mae: 500.9435\n",
            "Epoch 610/1000\n",
            "37/37 [==============================] - 6s 152ms/step - loss: 502760.9688 - mae: 643.6520 - val_loss: 415739.9062 - val_mae: 501.6082\n",
            "Epoch 611/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 503086.6250 - mae: 643.4895 - val_loss: 399605.3750 - val_mae: 485.1956\n",
            "Epoch 612/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 497322.5000 - mae: 639.0710 - val_loss: 406269.4688 - val_mae: 492.1835\n",
            "Epoch 613/1000\n",
            "37/37 [==============================] - 11s 270ms/step - loss: 504049.5938 - mae: 643.8574 - val_loss: 424811.7500 - val_mae: 510.2455\n",
            "Epoch 614/1000\n",
            "37/37 [==============================] - 6s 140ms/step - loss: 497143.0312 - mae: 641.7279 - val_loss: 416893.5312 - val_mae: 502.2552\n",
            "Epoch 615/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 500177.4375 - mae: 641.0770 - val_loss: 417671.7500 - val_mae: 502.9403\n",
            "Epoch 616/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 503030.7500 - mae: 643.4353 - val_loss: 410729.8438 - val_mae: 494.9994\n",
            "Epoch 617/1000\n",
            "37/37 [==============================] - 6s 144ms/step - loss: 496291.6250 - mae: 640.9976 - val_loss: 393093.5000 - val_mae: 477.7516\n",
            "Epoch 618/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 496992.0625 - mae: 639.5546 - val_loss: 400823.0000 - val_mae: 485.6339\n",
            "Epoch 619/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 501497.7812 - mae: 642.1750 - val_loss: 417664.1562 - val_mae: 502.2189\n",
            "Epoch 620/1000\n",
            "37/37 [==============================] - 10s 273ms/step - loss: 501640.4688 - mae: 642.5621 - val_loss: 403546.9062 - val_mae: 487.1960\n",
            "Epoch 621/1000\n",
            "37/37 [==============================] - 6s 141ms/step - loss: 502442.3438 - mae: 643.7078 - val_loss: 419463.7812 - val_mae: 503.4795\n",
            "Epoch 622/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 502295.1875 - mae: 644.5505 - val_loss: 411745.8438 - val_mae: 495.3777\n",
            "Epoch 623/1000\n",
            "37/37 [==============================] - 11s 274ms/step - loss: 501002.6562 - mae: 643.7176 - val_loss: 426311.3438 - val_mae: 510.8609\n",
            "Epoch 624/1000\n",
            "37/37 [==============================] - 6s 143ms/step - loss: 499097.2500 - mae: 640.8564 - val_loss: 409752.8438 - val_mae: 494.6846\n",
            "Epoch 625/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 503476.6875 - mae: 644.4896 - val_loss: 434987.0938 - val_mae: 520.1013\n",
            "Epoch 626/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 497652.7188 - mae: 640.2911 - val_loss: 410525.7188 - val_mae: 495.1088\n",
            "Epoch 627/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 501121.9375 - mae: 641.7267 - val_loss: 408595.2812 - val_mae: 493.7841\n",
            "Epoch 628/1000\n",
            "37/37 [==============================] - 6s 136ms/step - loss: 501750.7188 - mae: 641.5751 - val_loss: 409404.6562 - val_mae: 493.9990\n",
            "Epoch 629/1000\n",
            "37/37 [==============================] - 11s 274ms/step - loss: 500607.3438 - mae: 641.2909 - val_loss: 417404.2812 - val_mae: 502.5456\n",
            "Epoch 630/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 500205.5938 - mae: 641.5652 - val_loss: 400815.2500 - val_mae: 485.6451\n",
            "Epoch 631/1000\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 497829.3750 - mae: 639.7991 - val_loss: 434371.4688 - val_mae: 519.4202\n",
            "Epoch 632/1000\n",
            "37/37 [==============================] - 11s 274ms/step - loss: 499542.0938 - mae: 641.0642 - val_loss: 417057.6250 - val_mae: 502.3470\n",
            "Epoch 633/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 500872.3438 - mae: 641.2497 - val_loss: 400203.9062 - val_mae: 485.2739\n",
            "Epoch 634/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 501090.5312 - mae: 641.6772 - val_loss: 425519.1562 - val_mae: 510.6487\n",
            "Epoch 635/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 498843.8125 - mae: 640.2899 - val_loss: 399026.2500 - val_mae: 484.8701\n",
            "Epoch 636/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 504864.8750 - mae: 643.8976 - val_loss: 425300.6562 - val_mae: 509.9788\n",
            "Epoch 637/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 503488.5625 - mae: 644.0809 - val_loss: 409684.7812 - val_mae: 494.4150\n",
            "Epoch 638/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 502102.9375 - mae: 643.2706 - val_loss: 408773.9062 - val_mae: 493.8962\n",
            "Epoch 639/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 503264.3750 - mae: 643.8748 - val_loss: 418032.0312 - val_mae: 503.2292\n",
            "Epoch 640/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 498620.6562 - mae: 640.6462 - val_loss: 401540.5938 - val_mae: 486.0504\n",
            "Epoch 641/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 503309.9688 - mae: 643.7623 - val_loss: 417237.3438 - val_mae: 502.1913\n",
            "Epoch 642/1000\n",
            "37/37 [==============================] - 11s 271ms/step - loss: 502029.2500 - mae: 641.8930 - val_loss: 400131.2188 - val_mae: 485.2637\n",
            "Epoch 643/1000\n",
            "37/37 [==============================] - 11s 279ms/step - loss: 498101.3438 - mae: 639.2394 - val_loss: 409773.6250 - val_mae: 494.4656\n",
            "Epoch 644/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 501970.4688 - mae: 642.8107 - val_loss: 418466.0000 - val_mae: 502.8884\n",
            "Epoch 645/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 504056.3125 - mae: 644.0223 - val_loss: 426497.7500 - val_mae: 510.9510\n",
            "Epoch 646/1000\n",
            "37/37 [==============================] - 6s 136ms/step - loss: 502736.7812 - mae: 642.4142 - val_loss: 402415.2500 - val_mae: 486.7628\n",
            "Epoch 647/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 481214.5000 - mae: 633.8328 - val_loss: 417431.6562 - val_mae: 502.5518\n",
            "Epoch 648/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 500790.0625 - mae: 641.3328 - val_loss: 416293.4062 - val_mae: 501.6584\n",
            "Epoch 649/1000\n",
            "37/37 [==============================] - 6s 137ms/step - loss: 502552.1250 - mae: 642.5492 - val_loss: 418354.0938 - val_mae: 502.8236\n",
            "Epoch 650/1000\n",
            "37/37 [==============================] - 11s 276ms/step - loss: 499828.9375 - mae: 641.5413 - val_loss: 417547.4062 - val_mae: 502.6211\n",
            "Epoch 651/1000\n",
            "37/37 [==============================] - 6s 136ms/step - loss: 492112.5938 - mae: 637.1146 - val_loss: 417290.6562 - val_mae: 502.4775\n",
            "Epoch 652/1000\n",
            "37/37 [==============================] - 11s 271ms/step - loss: 498402.3750 - mae: 638.9056 - val_loss: 398400.9062 - val_mae: 484.5240\n",
            "Epoch 653/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 502892.6875 - mae: 643.0105 - val_loss: 407313.4062 - val_mae: 493.0510\n",
            "Epoch 654/1000\n",
            "37/37 [==============================] - 10s 273ms/step - loss: 501780.5000 - mae: 642.0857 - val_loss: 414808.0312 - val_mae: 500.4739\n",
            "Epoch 655/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 498643.0312 - mae: 639.5402 - val_loss: 423605.2188 - val_mae: 509.5800\n",
            "Epoch 656/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 492664.2500 - mae: 638.1412 - val_loss: 405964.5312 - val_mae: 492.5993\n",
            "Epoch 657/1000\n",
            "37/37 [==============================] - 11s 277ms/step - loss: 503979.0938 - mae: 643.1646 - val_loss: 408468.0312 - val_mae: 493.9802\n",
            "Epoch 658/1000\n",
            "37/37 [==============================] - 11s 274ms/step - loss: 502218.6562 - mae: 642.6821 - val_loss: 409419.0312 - val_mae: 494.2440\n",
            "Epoch 659/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 495725.1562 - mae: 639.0752 - val_loss: 426321.0312 - val_mae: 510.8469\n",
            "Epoch 660/1000\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 504915.8438 - mae: 645.5161 - val_loss: 410159.0938 - val_mae: 494.6751\n",
            "Epoch 661/1000\n",
            "37/37 [==============================] - 6s 151ms/step - loss: 506107.5938 - mae: 645.6009 - val_loss: 408922.4688 - val_mae: 493.7557\n",
            "Epoch 662/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 504803.8438 - mae: 644.9999 - val_loss: 409487.2188 - val_mae: 494.8779\n",
            "Epoch 663/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 497114.2188 - mae: 639.6257 - val_loss: 435060.7812 - val_mae: 519.3274\n",
            "Epoch 664/1000\n",
            "37/37 [==============================] - 11s 278ms/step - loss: 504574.7500 - mae: 644.8868 - val_loss: 411056.2812 - val_mae: 494.9724\n",
            "Epoch 665/1000\n",
            "37/37 [==============================] - 11s 279ms/step - loss: 503551.8750 - mae: 643.8091 - val_loss: 418815.3438 - val_mae: 503.0905\n",
            "Epoch 666/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 503714.9688 - mae: 643.3489 - val_loss: 426556.3438 - val_mae: 511.0050\n",
            "Epoch 667/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 504536.0312 - mae: 644.1394 - val_loss: 426319.4688 - val_mae: 510.8656\n",
            "Epoch 668/1000\n",
            "37/37 [==============================] - 10s 273ms/step - loss: 501224.5625 - mae: 642.3085 - val_loss: 419335.7500 - val_mae: 503.1695\n",
            "Epoch 669/1000\n",
            "37/37 [==============================] - 11s 271ms/step - loss: 502851.1875 - mae: 643.5984 - val_loss: 409673.0000 - val_mae: 494.1985\n",
            "Epoch 670/1000\n",
            "37/37 [==============================] - 11s 276ms/step - loss: 497937.9375 - mae: 639.8282 - val_loss: 402997.2812 - val_mae: 486.8637\n",
            "Epoch 671/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 505557.1562 - mae: 645.1244 - val_loss: 417621.0000 - val_mae: 502.4287\n",
            "Epoch 672/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 499120.7188 - mae: 640.8513 - val_loss: 417532.4062 - val_mae: 502.3624\n",
            "Epoch 673/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 498814.2188 - mae: 640.7750 - val_loss: 425913.2812 - val_mae: 510.8635\n",
            "Epoch 674/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 499923.1875 - mae: 641.5056 - val_loss: 415615.9688 - val_mae: 501.8255\n",
            "Epoch 675/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 497919.4375 - mae: 639.2367 - val_loss: 400056.3438 - val_mae: 485.1880\n",
            "Epoch 676/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 501590.3750 - mae: 641.6926 - val_loss: 407717.2188 - val_mae: 493.5669\n",
            "Epoch 677/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 500156.8750 - mae: 641.7234 - val_loss: 397735.2812 - val_mae: 483.8496\n",
            "Epoch 678/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 503712.7812 - mae: 642.9167 - val_loss: 423790.2500 - val_mae: 509.9538\n",
            "Epoch 679/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 501322.4375 - mae: 642.2421 - val_loss: 415884.8750 - val_mae: 501.6895\n",
            "Epoch 680/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 495535.7812 - mae: 638.8404 - val_loss: 432243.5938 - val_mae: 518.5267\n",
            "Epoch 681/1000\n",
            "37/37 [==============================] - 6s 142ms/step - loss: 500866.6875 - mae: 641.8382 - val_loss: 415429.8750 - val_mae: 500.8493\n",
            "Epoch 682/1000\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 501558.3125 - mae: 642.0457 - val_loss: 415802.5312 - val_mae: 501.0740\n",
            "Epoch 683/1000\n",
            "37/37 [==============================] - 6s 151ms/step - loss: 498432.2812 - mae: 640.0270 - val_loss: 399227.8438 - val_mae: 484.9889\n",
            "Epoch 684/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 491903.4375 - mae: 637.5342 - val_loss: 415237.3438 - val_mae: 500.7332\n",
            "Epoch 685/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 500208.5938 - mae: 640.8491 - val_loss: 406106.7812 - val_mae: 492.3700\n",
            "Epoch 686/1000\n",
            "37/37 [==============================] - 11s 270ms/step - loss: 495102.4688 - mae: 638.2878 - val_loss: 414088.1562 - val_mae: 500.3570\n",
            "Epoch 687/1000\n",
            "37/37 [==============================] - 11s 276ms/step - loss: 497387.9375 - mae: 639.4060 - val_loss: 406091.2188 - val_mae: 492.6693\n",
            "Epoch 688/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 493628.6562 - mae: 636.0926 - val_loss: 414436.9062 - val_mae: 500.8806\n",
            "Epoch 689/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 498199.6562 - mae: 639.9071 - val_loss: 406074.2188 - val_mae: 492.0234\n",
            "Epoch 690/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 498929.3125 - mae: 639.8181 - val_loss: 415623.5312 - val_mae: 502.1743\n",
            "Epoch 691/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 501015.5312 - mae: 641.7446 - val_loss: 406527.0000 - val_mae: 492.9105\n",
            "Epoch 692/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 502592.4375 - mae: 642.6949 - val_loss: 416134.9062 - val_mae: 501.8249\n",
            "Epoch 693/1000\n",
            "37/37 [==============================] - 6s 140ms/step - loss: 495171.5625 - mae: 637.7789 - val_loss: 424666.7500 - val_mae: 510.4905\n",
            "Epoch 694/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 498025.2812 - mae: 638.9680 - val_loss: 399865.2188 - val_mae: 485.3362\n",
            "Epoch 695/1000\n",
            "37/37 [==============================] - 6s 152ms/step - loss: 498335.7188 - mae: 639.7443 - val_loss: 407250.7500 - val_mae: 493.3097\n",
            "Epoch 696/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 502762.8750 - mae: 642.6703 - val_loss: 400433.0312 - val_mae: 485.3912\n",
            "Epoch 697/1000\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 503861.8750 - mae: 644.1827 - val_loss: 407598.7500 - val_mae: 492.9726\n",
            "Epoch 698/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 498878.5000 - mae: 640.3033 - val_loss: 408136.3438 - val_mae: 493.2698\n",
            "Epoch 699/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 494601.4062 - mae: 637.3959 - val_loss: 417717.2812 - val_mae: 502.7161\n",
            "Epoch 700/1000\n",
            "37/37 [==============================] - 11s 277ms/step - loss: 502425.4062 - mae: 643.0489 - val_loss: 417246.7188 - val_mae: 502.4575\n",
            "Epoch 701/1000\n",
            "37/37 [==============================] - 6s 143ms/step - loss: 499979.2812 - mae: 640.6312 - val_loss: 400680.5000 - val_mae: 485.7982\n",
            "Epoch 702/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 492185.0312 - mae: 636.7202 - val_loss: 424609.2500 - val_mae: 510.4050\n",
            "Epoch 703/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 501351.0938 - mae: 642.1109 - val_loss: 408190.7188 - val_mae: 493.5530\n",
            "Epoch 704/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 502829.2500 - mae: 642.2985 - val_loss: 398262.5000 - val_mae: 484.1580\n",
            "Epoch 705/1000\n",
            "37/37 [==============================] - 11s 278ms/step - loss: 502556.0938 - mae: 643.0546 - val_loss: 432545.2500 - val_mae: 518.6899\n",
            "Epoch 706/1000\n",
            "37/37 [==============================] - 11s 277ms/step - loss: 504552.5625 - mae: 644.2834 - val_loss: 415626.8750 - val_mae: 501.2550\n",
            "Epoch 707/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 502642.1562 - mae: 642.1810 - val_loss: 415623.8750 - val_mae: 501.5430\n",
            "Epoch 708/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 502312.5625 - mae: 642.2070 - val_loss: 399365.7188 - val_mae: 485.0663\n",
            "Epoch 709/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 498804.5000 - mae: 640.6343 - val_loss: 408603.8750 - val_mae: 493.5465\n",
            "Epoch 710/1000\n",
            "37/37 [==============================] - 6s 145ms/step - loss: 502147.8438 - mae: 642.8060 - val_loss: 424965.7188 - val_mae: 510.6012\n",
            "Epoch 711/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 500479.6562 - mae: 641.8498 - val_loss: 399737.3750 - val_mae: 485.2644\n",
            "Epoch 712/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 498975.8750 - mae: 640.6497 - val_loss: 405554.4688 - val_mae: 492.0525\n",
            "Epoch 713/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 500201.0625 - mae: 642.1617 - val_loss: 396278.5000 - val_mae: 483.3260\n",
            "Epoch 714/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 501826.3125 - mae: 641.5142 - val_loss: 413785.4062 - val_mae: 500.5134\n",
            "Epoch 715/1000\n",
            "37/37 [==============================] - 11s 278ms/step - loss: 502256.1250 - mae: 642.2843 - val_loss: 406660.8438 - val_mae: 492.9841\n",
            "Epoch 716/1000\n",
            "37/37 [==============================] - 11s 274ms/step - loss: 504363.6562 - mae: 644.2925 - val_loss: 416169.6562 - val_mae: 501.5710\n",
            "Epoch 717/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 500346.9375 - mae: 640.3172 - val_loss: 424538.4062 - val_mae: 509.5134\n",
            "Epoch 718/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 497502.1875 - mae: 640.4033 - val_loss: 425770.7500 - val_mae: 510.5227\n",
            "Epoch 719/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 499236.5625 - mae: 640.2896 - val_loss: 424106.4688 - val_mae: 510.1281\n",
            "Epoch 720/1000\n",
            "37/37 [==============================] - 11s 271ms/step - loss: 485460.8438 - mae: 635.6313 - val_loss: 408377.9062 - val_mae: 493.6599\n",
            "Epoch 721/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 493587.6875 - mae: 638.7364 - val_loss: 416884.6562 - val_mae: 501.9713\n",
            "Epoch 722/1000\n",
            "37/37 [==============================] - 10s 272ms/step - loss: 500592.2812 - mae: 641.8918 - val_loss: 423700.3438 - val_mae: 509.0314\n",
            "Epoch 723/1000\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 502271.9375 - mae: 642.9563 - val_loss: 409042.7500 - val_mae: 494.0394\n",
            "Epoch 724/1000\n",
            "37/37 [==============================] - 11s 279ms/step - loss: 500875.8750 - mae: 642.2976 - val_loss: 399656.0312 - val_mae: 485.2240\n",
            "Epoch 725/1000\n",
            "37/37 [==============================] - 10s 272ms/step - loss: 504284.5312 - mae: 644.6131 - val_loss: 407540.4062 - val_mae: 493.2024\n",
            "Epoch 726/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 498721.2188 - mae: 640.0668 - val_loss: 391213.7812 - val_mae: 476.6673\n",
            "Epoch 727/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 495099.5938 - mae: 638.6270 - val_loss: 432390.8750 - val_mae: 518.3112\n",
            "Epoch 728/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 498534.2812 - mae: 639.7828 - val_loss: 407138.3438 - val_mae: 492.9398\n",
            "Epoch 729/1000\n",
            "37/37 [==============================] - 6s 143ms/step - loss: 497407.0625 - mae: 639.3669 - val_loss: 414092.5312 - val_mae: 501.0051\n",
            "Epoch 730/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 503320.9062 - mae: 643.5752 - val_loss: 414424.2500 - val_mae: 500.8736\n",
            "Epoch 731/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 502601.9375 - mae: 642.4406 - val_loss: 413833.6250 - val_mae: 500.8794\n",
            "Epoch 732/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 497918.1250 - mae: 639.2650 - val_loss: 414556.6250 - val_mae: 500.9369\n",
            "Epoch 733/1000\n",
            "37/37 [==============================] - 6s 149ms/step - loss: 504810.4375 - mae: 643.6702 - val_loss: 406884.3438 - val_mae: 493.1074\n",
            "Epoch 734/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 500069.5938 - mae: 640.7610 - val_loss: 407295.2812 - val_mae: 493.0406\n",
            "Epoch 735/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 498296.4062 - mae: 640.1962 - val_loss: 405768.7500 - val_mae: 492.1758\n",
            "Epoch 736/1000\n",
            "37/37 [==============================] - 11s 278ms/step - loss: 501693.1875 - mae: 641.6546 - val_loss: 423094.1250 - val_mae: 509.5696\n",
            "Epoch 737/1000\n",
            "37/37 [==============================] - 11s 276ms/step - loss: 500459.4375 - mae: 643.1934 - val_loss: 407479.4688 - val_mae: 492.8590\n",
            "Epoch 738/1000\n",
            "37/37 [==============================] - 11s 289ms/step - loss: 503277.1875 - mae: 643.5002 - val_loss: 424505.0938 - val_mae: 510.3480\n",
            "Epoch 739/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 498647.3750 - mae: 639.9756 - val_loss: 406791.5000 - val_mae: 492.7628\n",
            "Epoch 740/1000\n",
            "37/37 [==============================] - 6s 134ms/step - loss: 498498.1875 - mae: 639.5518 - val_loss: 416089.7188 - val_mae: 501.7995\n",
            "Epoch 741/1000\n",
            "37/37 [==============================] - 6s 131ms/step - loss: 505880.4688 - mae: 645.0472 - val_loss: 398436.6250 - val_mae: 484.5442\n",
            "Epoch 742/1000\n",
            "37/37 [==============================] - 11s 273ms/step - loss: 497261.4688 - mae: 639.4998 - val_loss: 406719.0000 - val_mae: 493.0163\n",
            "Epoch 743/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 497946.1250 - mae: 638.8770 - val_loss: 407257.1250 - val_mae: 493.6518\n",
            "Epoch 744/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 500325.2188 - mae: 641.8810 - val_loss: 398950.7500 - val_mae: 484.5433\n",
            "Epoch 745/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 495581.8438 - mae: 639.7209 - val_loss: 399978.9688 - val_mae: 485.1429\n",
            "Epoch 746/1000\n",
            "37/37 [==============================] - 11s 278ms/step - loss: 493710.9062 - mae: 637.4399 - val_loss: 408145.4062 - val_mae: 493.2751\n",
            "Epoch 747/1000\n",
            "37/37 [==============================] - 11s 276ms/step - loss: 499744.3438 - mae: 640.7067 - val_loss: 417902.1562 - val_mae: 503.0643\n",
            "Epoch 748/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 498293.8438 - mae: 639.8569 - val_loss: 424901.8750 - val_mae: 510.2870\n",
            "Epoch 749/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 492918.2188 - mae: 637.9182 - val_loss: 416511.8750 - val_mae: 502.0413\n",
            "Epoch 750/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 499867.5000 - mae: 641.2966 - val_loss: 407037.9062 - val_mae: 493.1923\n",
            "Epoch 751/1000\n",
            "37/37 [==============================] - 6s 133ms/step - loss: 492876.1562 - mae: 637.7540 - val_loss: 416450.3438 - val_mae: 501.7343\n",
            "Epoch 752/1000\n",
            "37/37 [==============================] - 11s 278ms/step - loss: 501743.4375 - mae: 641.8168 - val_loss: 424958.9688 - val_mae: 510.8788\n",
            "Epoch 753/1000\n",
            "37/37 [==============================] - 10s 272ms/step - loss: 504280.9688 - mae: 643.2680 - val_loss: 425614.0312 - val_mae: 510.4303\n",
            "Epoch 754/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 504113.6562 - mae: 643.8516 - val_loss: 397573.0312 - val_mae: 483.7545\n",
            "Epoch 755/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 496952.6250 - mae: 638.9437 - val_loss: 389912.5938 - val_mae: 475.9437\n",
            "Epoch 756/1000\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 501500.5312 - mae: 641.7773 - val_loss: 415266.3438 - val_mae: 501.0291\n",
            "Epoch 757/1000\n",
            "37/37 [==============================] - 11s 274ms/step - loss: 500257.0000 - mae: 640.2581 - val_loss: 407073.0000 - val_mae: 493.2116\n",
            "Epoch 758/1000\n",
            "37/37 [==============================] - 11s 274ms/step - loss: 497578.1250 - mae: 640.3510 - val_loss: 405258.4062 - val_mae: 491.8938\n",
            "Epoch 759/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 503248.9375 - mae: 643.0227 - val_loss: 423426.8750 - val_mae: 509.1578\n",
            "Epoch 760/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 502534.8750 - mae: 642.8765 - val_loss: 432982.5938 - val_mae: 518.6993\n",
            "Epoch 761/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 495399.1875 - mae: 638.6411 - val_loss: 408080.3438 - val_mae: 493.2578\n",
            "Epoch 762/1000\n",
            "37/37 [==============================] - 11s 268ms/step - loss: 501743.0625 - mae: 641.9088 - val_loss: 415804.1562 - val_mae: 501.6443\n",
            "Epoch 763/1000\n",
            "37/37 [==============================] - 6s 143ms/step - loss: 498444.2500 - mae: 640.1689 - val_loss: 399132.1562 - val_mae: 484.6822\n",
            "Epoch 764/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 505635.9062 - mae: 644.9700 - val_loss: 408047.7500 - val_mae: 493.7489\n",
            "Epoch 765/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 499857.2188 - mae: 641.3779 - val_loss: 408032.4688 - val_mae: 493.7401\n",
            "Epoch 766/1000\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 500789.0000 - mae: 641.7747 - val_loss: 408773.5000 - val_mae: 494.1475\n",
            "Epoch 767/1000\n",
            "37/37 [==============================] - 11s 280ms/step - loss: 498850.6875 - mae: 640.1607 - val_loss: 406533.4688 - val_mae: 492.6148\n",
            "Epoch 768/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 503807.9375 - mae: 643.7360 - val_loss: 408141.6562 - val_mae: 493.2517\n",
            "Epoch 769/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 503833.2500 - mae: 643.6813 - val_loss: 406555.5938 - val_mae: 492.6165\n",
            "Epoch 770/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 503818.8438 - mae: 644.2124 - val_loss: 431596.3438 - val_mae: 518.1760\n",
            "Epoch 771/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 504774.6562 - mae: 644.4597 - val_loss: 408102.0000 - val_mae: 493.2071\n",
            "Epoch 772/1000\n",
            "37/37 [==============================] - 11s 277ms/step - loss: 501084.2188 - mae: 641.2834 - val_loss: 406286.0000 - val_mae: 492.4728\n",
            "Epoch 773/1000\n",
            "37/37 [==============================] - 6s 145ms/step - loss: 499713.3125 - mae: 640.5775 - val_loss: 407524.5312 - val_mae: 493.4607\n",
            "Epoch 774/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 498534.8750 - mae: 639.6382 - val_loss: 414315.3750 - val_mae: 500.8122\n",
            "Epoch 775/1000\n",
            "37/37 [==============================] - 11s 277ms/step - loss: 502164.9062 - mae: 642.7509 - val_loss: 414925.2500 - val_mae: 501.1446\n",
            "Epoch 776/1000\n",
            "37/37 [==============================] - 11s 283ms/step - loss: 495619.7500 - mae: 637.8675 - val_loss: 414822.8750 - val_mae: 500.7862\n",
            "Epoch 777/1000\n",
            "37/37 [==============================] - 10s 272ms/step - loss: 498972.0312 - mae: 640.1727 - val_loss: 414694.0000 - val_mae: 500.7110\n",
            "Epoch 778/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 504519.3125 - mae: 644.0518 - val_loss: 414457.7500 - val_mae: 500.2621\n",
            "Epoch 779/1000\n",
            "37/37 [==============================] - 10s 263ms/step - loss: 501682.4062 - mae: 642.0047 - val_loss: 416043.8750 - val_mae: 501.2194\n",
            "Epoch 780/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 503265.2500 - mae: 643.5696 - val_loss: 414830.7812 - val_mae: 500.8069\n",
            "Epoch 781/1000\n",
            "37/37 [==============================] - 11s 279ms/step - loss: 497949.6875 - mae: 640.0028 - val_loss: 397994.8438 - val_mae: 483.9845\n",
            "Epoch 782/1000\n",
            "37/37 [==============================] - 6s 160ms/step - loss: 495555.4062 - mae: 639.3957 - val_loss: 406622.4062 - val_mae: 492.6548\n",
            "Epoch 783/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 504681.6875 - mae: 643.8501 - val_loss: 388493.7812 - val_mae: 475.1398\n",
            "Epoch 784/1000\n",
            "37/37 [==============================] - 11s 273ms/step - loss: 494865.9375 - mae: 636.8754 - val_loss: 424363.7188 - val_mae: 509.9796\n",
            "Epoch 785/1000\n",
            "37/37 [==============================] - 11s 277ms/step - loss: 496628.4688 - mae: 638.4612 - val_loss: 424718.2500 - val_mae: 510.4650\n",
            "Epoch 786/1000\n",
            "37/37 [==============================] - 6s 141ms/step - loss: 503481.5625 - mae: 642.9750 - val_loss: 398317.4688 - val_mae: 484.4712\n",
            "Epoch 787/1000\n",
            "37/37 [==============================] - 11s 272ms/step - loss: 495108.1250 - mae: 639.2418 - val_loss: 422630.7188 - val_mae: 508.9982\n",
            "Epoch 788/1000\n",
            "37/37 [==============================] - 11s 279ms/step - loss: 497484.5312 - mae: 639.3719 - val_loss: 405659.8438 - val_mae: 492.1245\n",
            "Epoch 789/1000\n",
            "37/37 [==============================] - 11s 279ms/step - loss: 501773.0938 - mae: 641.6742 - val_loss: 405999.9062 - val_mae: 492.3086\n",
            "Epoch 790/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 500023.6875 - mae: 639.9983 - val_loss: 406873.5000 - val_mae: 492.5208\n",
            "Epoch 791/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 505041.1562 - mae: 644.4080 - val_loss: 416188.0312 - val_mae: 501.5663\n",
            "Epoch 792/1000\n",
            "37/37 [==============================] - 11s 276ms/step - loss: 500279.1875 - mae: 640.9970 - val_loss: 409101.5938 - val_mae: 493.8199\n",
            "Epoch 793/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 504233.2812 - mae: 644.1252 - val_loss: 409184.2812 - val_mae: 494.1301\n",
            "Epoch 794/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 500243.3125 - mae: 640.8477 - val_loss: 391065.6562 - val_mae: 476.5935\n",
            "Epoch 795/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 499248.7812 - mae: 640.3065 - val_loss: 425509.3750 - val_mae: 510.6431\n",
            "Epoch 796/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 494267.4375 - mae: 638.8055 - val_loss: 417000.2500 - val_mae: 502.0689\n",
            "Epoch 797/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 501321.8438 - mae: 642.1765 - val_loss: 400990.7188 - val_mae: 485.9717\n",
            "Epoch 798/1000\n",
            "37/37 [==============================] - 11s 280ms/step - loss: 503405.5312 - mae: 644.6478 - val_loss: 401106.8750 - val_mae: 486.3695\n",
            "Epoch 799/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 500731.8125 - mae: 641.6141 - val_loss: 401465.7500 - val_mae: 486.2328\n",
            "Epoch 800/1000\n",
            "37/37 [==============================] - 6s 135ms/step - loss: 500528.9375 - mae: 642.6477 - val_loss: 418162.3750 - val_mae: 502.5174\n",
            "Epoch 801/1000\n",
            "37/37 [==============================] - 11s 284ms/step - loss: 498948.6875 - mae: 639.7728 - val_loss: 435183.5000 - val_mae: 519.6360\n",
            "Epoch 802/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 501851.6562 - mae: 643.3116 - val_loss: 419499.3750 - val_mae: 503.5000\n",
            "Epoch 803/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 493570.5938 - mae: 639.6140 - val_loss: 400912.6562 - val_mae: 485.9233\n",
            "Epoch 804/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 493582.2500 - mae: 639.9855 - val_loss: 416251.1562 - val_mae: 501.9001\n",
            "Epoch 805/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 503353.2500 - mae: 643.9314 - val_loss: 417461.1562 - val_mae: 502.5729\n",
            "Epoch 806/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 500068.5000 - mae: 641.0276 - val_loss: 415721.1562 - val_mae: 501.8878\n",
            "Epoch 807/1000\n",
            "37/37 [==============================] - 11s 282ms/step - loss: 500629.5000 - mae: 642.4822 - val_loss: 416362.3438 - val_mae: 501.9575\n",
            "Epoch 808/1000\n",
            "37/37 [==============================] - 11s 283ms/step - loss: 495697.4375 - mae: 639.0418 - val_loss: 409307.0938 - val_mae: 494.1802\n",
            "Epoch 809/1000\n",
            "37/37 [==============================] - 10s 272ms/step - loss: 499721.3438 - mae: 640.6526 - val_loss: 416784.8438 - val_mae: 502.1942\n",
            "Epoch 810/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 501663.0625 - mae: 641.8994 - val_loss: 417792.3438 - val_mae: 502.7536\n",
            "Epoch 811/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 497683.1250 - mae: 639.4682 - val_loss: 426036.1562 - val_mae: 511.1890\n",
            "Epoch 812/1000\n",
            "37/37 [==============================] - 11s 274ms/step - loss: 498101.0625 - mae: 640.6816 - val_loss: 401251.4688 - val_mae: 485.8671\n",
            "Epoch 813/1000\n",
            "37/37 [==============================] - 11s 285ms/step - loss: 499666.8438 - mae: 642.2470 - val_loss: 409094.7500 - val_mae: 494.0591\n",
            "Epoch 814/1000\n",
            "37/37 [==============================] - 11s 280ms/step - loss: 503986.6875 - mae: 643.8804 - val_loss: 417777.0000 - val_mae: 502.7450\n",
            "Epoch 815/1000\n",
            "37/37 [==============================] - 11s 274ms/step - loss: 500753.5000 - mae: 641.5631 - val_loss: 401118.6250 - val_mae: 485.8056\n",
            "Epoch 816/1000\n",
            "37/37 [==============================] - 11s 273ms/step - loss: 499681.0312 - mae: 640.1463 - val_loss: 408950.7188 - val_mae: 493.9768\n",
            "Epoch 817/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 502802.4688 - mae: 642.6127 - val_loss: 417649.3438 - val_mae: 502.6737\n",
            "Epoch 818/1000\n",
            "37/37 [==============================] - 11s 271ms/step - loss: 505485.1562 - mae: 645.3442 - val_loss: 434540.0000 - val_mae: 519.5144\n",
            "Epoch 819/1000\n",
            "37/37 [==============================] - 11s 285ms/step - loss: 501840.6562 - mae: 642.0285 - val_loss: 410787.2500 - val_mae: 494.8141\n",
            "Epoch 820/1000\n",
            "37/37 [==============================] - 11s 284ms/step - loss: 501313.4375 - mae: 641.9011 - val_loss: 409121.2812 - val_mae: 494.0942\n",
            "Epoch 821/1000\n",
            "37/37 [==============================] - 11s 273ms/step - loss: 503157.9375 - mae: 643.4748 - val_loss: 419448.2812 - val_mae: 503.2615\n",
            "Epoch 822/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 502539.8750 - mae: 643.5806 - val_loss: 427055.7500 - val_mae: 512.0866\n",
            "Epoch 823/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 500978.0312 - mae: 642.2075 - val_loss: 399689.0938 - val_mae: 485.0065\n",
            "Epoch 824/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 498430.8438 - mae: 640.3751 - val_loss: 425908.5000 - val_mae: 510.6237\n",
            "Epoch 825/1000\n",
            "37/37 [==============================] - 11s 281ms/step - loss: 493256.4688 - mae: 636.6961 - val_loss: 408871.7188 - val_mae: 493.9419\n",
            "Epoch 826/1000\n",
            "37/37 [==============================] - 11s 277ms/step - loss: 498673.9688 - mae: 641.2891 - val_loss: 425257.9688 - val_mae: 510.7618\n",
            "Epoch 827/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 502910.9062 - mae: 642.7947 - val_loss: 418131.5000 - val_mae: 502.7243\n",
            "Epoch 828/1000\n",
            "37/37 [==============================] - 10s 272ms/step - loss: 499548.9062 - mae: 640.9508 - val_loss: 418597.1562 - val_mae: 502.9643\n",
            "Epoch 829/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 496459.4375 - mae: 641.0057 - val_loss: 426927.2500 - val_mae: 511.4400\n",
            "Epoch 830/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 499500.8125 - mae: 640.5047 - val_loss: 418808.4062 - val_mae: 503.3210\n",
            "Epoch 831/1000\n",
            "37/37 [==============================] - 11s 284ms/step - loss: 497278.2500 - mae: 639.5225 - val_loss: 426307.1250 - val_mae: 511.3376\n",
            "Epoch 832/1000\n",
            "37/37 [==============================] - 11s 277ms/step - loss: 503786.4375 - mae: 643.7919 - val_loss: 416715.0000 - val_mae: 502.2249\n",
            "Epoch 833/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 501702.2812 - mae: 641.6325 - val_loss: 417263.2500 - val_mae: 501.9528\n",
            "Epoch 834/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 498383.4062 - mae: 640.0004 - val_loss: 426512.3750 - val_mae: 510.9596\n",
            "Epoch 835/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 501912.9062 - mae: 641.9997 - val_loss: 408021.5312 - val_mae: 493.4668\n",
            "Epoch 836/1000\n",
            "37/37 [==============================] - 11s 269ms/step - loss: 500524.4688 - mae: 640.8931 - val_loss: 417623.5000 - val_mae: 503.0011\n",
            "Epoch 837/1000\n",
            "37/37 [==============================] - 11s 280ms/step - loss: 500548.4688 - mae: 640.9611 - val_loss: 425109.4062 - val_mae: 510.4153\n",
            "Epoch 838/1000\n",
            "37/37 [==============================] - 11s 284ms/step - loss: 502502.0938 - mae: 643.1530 - val_loss: 417196.7500 - val_mae: 502.6785\n",
            "Epoch 839/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 500096.5938 - mae: 641.4193 - val_loss: 425332.8438 - val_mae: 510.2644\n",
            "Epoch 840/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 499923.8438 - mae: 640.2349 - val_loss: 425013.9688 - val_mae: 510.3608\n",
            "Epoch 841/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 502198.5000 - mae: 642.5035 - val_loss: 408233.7188 - val_mae: 493.5776\n",
            "Epoch 842/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 495254.0625 - mae: 638.8884 - val_loss: 416285.0938 - val_mae: 501.3647\n",
            "Epoch 843/1000\n",
            "37/37 [==============================] - 11s 283ms/step - loss: 500195.6875 - mae: 641.5634 - val_loss: 407673.5938 - val_mae: 493.2678\n",
            "Epoch 844/1000\n",
            "37/37 [==============================] - 11s 277ms/step - loss: 499607.5938 - mae: 640.9308 - val_loss: 407617.4062 - val_mae: 493.2357\n",
            "Epoch 845/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 501514.5625 - mae: 641.3831 - val_loss: 408195.3438 - val_mae: 493.5557\n",
            "Epoch 846/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 504904.0312 - mae: 644.3668 - val_loss: 416666.5938 - val_mae: 502.1232\n",
            "Epoch 847/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 500526.3438 - mae: 641.6317 - val_loss: 397958.1562 - val_mae: 484.2688\n",
            "Epoch 848/1000\n",
            "37/37 [==============================] - 6s 135ms/step - loss: 504214.5938 - mae: 643.7565 - val_loss: 433264.7812 - val_mae: 519.3591\n",
            "Epoch 849/1000\n",
            "37/37 [==============================] - 11s 269ms/step - loss: 493274.1250 - mae: 638.4818 - val_loss: 399430.6562 - val_mae: 484.8071\n",
            "Epoch 850/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 495529.8438 - mae: 639.0828 - val_loss: 417036.2812 - val_mae: 502.0594\n",
            "Epoch 851/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 500843.0938 - mae: 641.5146 - val_loss: 408037.1250 - val_mae: 493.1898\n",
            "Epoch 852/1000\n",
            "37/37 [==============================] - 11s 281ms/step - loss: 492716.5938 - mae: 636.9092 - val_loss: 416693.3438 - val_mae: 502.1382\n",
            "Epoch 853/1000\n",
            "37/37 [==============================] - 11s 278ms/step - loss: 501682.5312 - mae: 641.3611 - val_loss: 416588.2500 - val_mae: 502.0841\n",
            "Epoch 854/1000\n",
            "37/37 [==============================] - 10s 273ms/step - loss: 503126.3125 - mae: 643.4163 - val_loss: 417932.9062 - val_mae: 502.5796\n",
            "Epoch 855/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 500511.6250 - mae: 640.8376 - val_loss: 409149.2812 - val_mae: 494.3546\n",
            "Epoch 856/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 502567.5938 - mae: 642.4179 - val_loss: 418787.5000 - val_mae: 503.5465\n",
            "Epoch 857/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 501787.1562 - mae: 643.0210 - val_loss: 410358.6250 - val_mae: 494.7886\n",
            "Epoch 858/1000\n",
            "37/37 [==============================] - 11s 279ms/step - loss: 499630.6875 - mae: 640.5036 - val_loss: 427075.5000 - val_mae: 512.0974\n",
            "Epoch 859/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 499563.1250 - mae: 641.2217 - val_loss: 417838.7500 - val_mae: 503.0364\n",
            "Epoch 860/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 502307.1875 - mae: 643.6968 - val_loss: 409504.3750 - val_mae: 494.5494\n",
            "Epoch 861/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 496159.0625 - mae: 639.9672 - val_loss: 416408.6562 - val_mae: 501.9883\n",
            "Epoch 862/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 503046.7500 - mae: 643.1322 - val_loss: 401109.7188 - val_mae: 485.8004\n",
            "Epoch 863/1000\n",
            "37/37 [==============================] - 11s 270ms/step - loss: 501602.1875 - mae: 641.9189 - val_loss: 426022.7812 - val_mae: 510.9353\n",
            "Epoch 864/1000\n",
            "37/37 [==============================] - 6s 148ms/step - loss: 498214.6562 - mae: 642.2421 - val_loss: 427168.1562 - val_mae: 511.3645\n",
            "Epoch 865/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 502397.7500 - mae: 642.9216 - val_loss: 425956.8438 - val_mae: 511.2254\n",
            "Epoch 866/1000\n",
            "37/37 [==============================] - 6s 148ms/step - loss: 500977.8750 - mae: 641.5502 - val_loss: 418536.9688 - val_mae: 502.9441\n",
            "Epoch 867/1000\n",
            "37/37 [==============================] - 11s 284ms/step - loss: 505111.3750 - mae: 645.3079 - val_loss: 410911.9688 - val_mae: 495.1028\n",
            "Epoch 868/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 504991.2812 - mae: 645.1534 - val_loss: 419712.6250 - val_mae: 503.8285\n",
            "Epoch 869/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 492420.0625 - mae: 638.6511 - val_loss: 409514.2500 - val_mae: 494.3279\n",
            "Epoch 870/1000\n",
            "37/37 [==============================] - 6s 150ms/step - loss: 500823.7500 - mae: 641.8528 - val_loss: 417756.9062 - val_mae: 502.7426\n",
            "Epoch 871/1000\n",
            "37/37 [==============================] - 11s 278ms/step - loss: 504694.0938 - mae: 644.1496 - val_loss: 418085.6562 - val_mae: 502.9262\n",
            "Epoch 872/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 498848.2812 - mae: 640.5497 - val_loss: 418421.1562 - val_mae: 503.1091\n",
            "Epoch 873/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 506406.3750 - mae: 645.6571 - val_loss: 418723.5312 - val_mae: 503.2737\n",
            "Epoch 874/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 498900.6875 - mae: 641.1115 - val_loss: 426835.1250 - val_mae: 511.1494\n",
            "Epoch 875/1000\n",
            "37/37 [==============================] - 11s 276ms/step - loss: 501278.6875 - mae: 641.7321 - val_loss: 409325.7188 - val_mae: 494.2207\n",
            "Epoch 876/1000\n",
            "37/37 [==============================] - 11s 283ms/step - loss: 496006.1562 - mae: 638.5111 - val_loss: 417583.2812 - val_mae: 502.3919\n",
            "Epoch 877/1000\n",
            "37/37 [==============================] - 11s 278ms/step - loss: 497708.2188 - mae: 639.4966 - val_loss: 418051.1250 - val_mae: 502.9026\n",
            "Epoch 878/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 503291.7812 - mae: 643.7305 - val_loss: 417393.1250 - val_mae: 502.2816\n",
            "Epoch 879/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 497818.7188 - mae: 639.0634 - val_loss: 416302.3750 - val_mae: 501.9239\n",
            "Epoch 880/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 501319.4375 - mae: 641.8495 - val_loss: 417907.7188 - val_mae: 502.8181\n",
            "Epoch 881/1000\n",
            "37/37 [==============================] - 11s 272ms/step - loss: 499701.2188 - mae: 640.6994 - val_loss: 391539.6250 - val_mae: 476.8539\n",
            "Epoch 882/1000\n",
            "37/37 [==============================] - 11s 293ms/step - loss: 501840.0000 - mae: 642.1129 - val_loss: 417494.5000 - val_mae: 502.3405\n",
            "Epoch 883/1000\n",
            "37/37 [==============================] - 11s 281ms/step - loss: 499668.8438 - mae: 640.4515 - val_loss: 409563.1250 - val_mae: 494.0720\n",
            "Epoch 884/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 501664.1250 - mae: 642.6894 - val_loss: 392620.0000 - val_mae: 477.4713\n",
            "Epoch 885/1000\n",
            "37/37 [==============================] - 6s 151ms/step - loss: 501676.5312 - mae: 641.7706 - val_loss: 417045.2188 - val_mae: 502.3401\n",
            "Epoch 886/1000\n",
            "37/37 [==============================] - 11s 283ms/step - loss: 499508.0625 - mae: 640.4315 - val_loss: 408430.3438 - val_mae: 493.6899\n",
            "Epoch 887/1000\n",
            "37/37 [==============================] - 11s 278ms/step - loss: 493951.9375 - mae: 639.5865 - val_loss: 409999.0000 - val_mae: 494.8216\n",
            "Epoch 888/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 498630.5938 - mae: 639.6924 - val_loss: 408501.0000 - val_mae: 493.9978\n",
            "Epoch 889/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 498173.1562 - mae: 640.7021 - val_loss: 416461.5000 - val_mae: 502.3510\n",
            "Epoch 890/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 496469.0000 - mae: 638.7056 - val_loss: 399442.9062 - val_mae: 485.1043\n",
            "Epoch 891/1000\n",
            "37/37 [==============================] - 11s 273ms/step - loss: 499437.8125 - mae: 639.8998 - val_loss: 408436.7812 - val_mae: 493.4477\n",
            "Epoch 892/1000\n",
            "37/37 [==============================] - 11s 285ms/step - loss: 491622.0000 - mae: 637.8163 - val_loss: 417072.5938 - val_mae: 502.3554\n",
            "Epoch 893/1000\n",
            "37/37 [==============================] - 11s 277ms/step - loss: 502270.2500 - mae: 642.5938 - val_loss: 417982.7812 - val_mae: 502.8601\n",
            "Epoch 894/1000\n",
            "37/37 [==============================] - 11s 277ms/step - loss: 496421.8438 - mae: 637.9816 - val_loss: 400541.8438 - val_mae: 485.4546\n",
            "Epoch 895/1000\n",
            "37/37 [==============================] - 11s 271ms/step - loss: 500030.4062 - mae: 641.2803 - val_loss: 399814.7500 - val_mae: 485.0473\n",
            "Epoch 896/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 502885.1250 - mae: 643.8151 - val_loss: 424315.8438 - val_mae: 509.9524\n",
            "Epoch 897/1000\n",
            "37/37 [==============================] - 11s 287ms/step - loss: 498661.5625 - mae: 640.3186 - val_loss: 407790.9688 - val_mae: 493.0439\n",
            "Epoch 898/1000\n",
            "37/37 [==============================] - 11s 278ms/step - loss: 501443.3125 - mae: 641.2516 - val_loss: 415072.4062 - val_mae: 500.6599\n",
            "Epoch 899/1000\n",
            "37/37 [==============================] - 11s 274ms/step - loss: 496717.1562 - mae: 638.6771 - val_loss: 407514.2188 - val_mae: 493.4548\n",
            "Epoch 900/1000\n",
            "37/37 [==============================] - 10s 273ms/step - loss: 500884.1875 - mae: 641.9287 - val_loss: 398488.7500 - val_mae: 484.2902\n",
            "Epoch 901/1000\n",
            "37/37 [==============================] - 6s 137ms/step - loss: 500132.7188 - mae: 641.1644 - val_loss: 425145.4688 - val_mae: 510.4260\n",
            "Epoch 902/1000\n",
            "37/37 [==============================] - 6s 149ms/step - loss: 503207.5625 - mae: 643.5844 - val_loss: 416742.3438 - val_mae: 501.9039\n",
            "Epoch 903/1000\n",
            "37/37 [==============================] - 6s 151ms/step - loss: 497621.8438 - mae: 639.0413 - val_loss: 424422.8750 - val_mae: 509.7472\n",
            "Epoch 904/1000\n",
            "37/37 [==============================] - 11s 283ms/step - loss: 501141.3438 - mae: 641.9884 - val_loss: 408037.3750 - val_mae: 493.2112\n",
            "Epoch 905/1000\n",
            "37/37 [==============================] - 11s 279ms/step - loss: 499372.3750 - mae: 640.0798 - val_loss: 408777.3750 - val_mae: 493.8880\n",
            "Epoch 906/1000\n",
            "37/37 [==============================] - 11s 278ms/step - loss: 490763.8750 - mae: 636.0872 - val_loss: 409338.1562 - val_mae: 494.2178\n",
            "Epoch 907/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 500532.6250 - mae: 641.1959 - val_loss: 418399.4688 - val_mae: 503.0929\n",
            "Epoch 908/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 503630.1875 - mae: 643.7190 - val_loss: 435783.1250 - val_mae: 520.4352\n",
            "Epoch 909/1000\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 501919.6562 - mae: 642.8378 - val_loss: 418868.9062 - val_mae: 503.3628\n",
            "Epoch 910/1000\n",
            "37/37 [==============================] - 11s 280ms/step - loss: 503923.6875 - mae: 644.9385 - val_loss: 419243.4062 - val_mae: 503.3379\n",
            "Epoch 911/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 501243.7188 - mae: 641.9268 - val_loss: 419011.3438 - val_mae: 503.4420\n",
            "Epoch 912/1000\n",
            "37/37 [==============================] - 11s 272ms/step - loss: 501657.2500 - mae: 642.0261 - val_loss: 418758.1250 - val_mae: 502.8739\n",
            "Epoch 913/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 501333.0625 - mae: 642.1763 - val_loss: 401744.2500 - val_mae: 486.3883\n",
            "Epoch 914/1000\n",
            "37/37 [==============================] - 11s 271ms/step - loss: 492831.1875 - mae: 638.3729 - val_loss: 409970.5938 - val_mae: 494.5776\n",
            "Epoch 915/1000\n",
            "37/37 [==============================] - 11s 283ms/step - loss: 495277.0938 - mae: 639.0099 - val_loss: 417832.6250 - val_mae: 502.5365\n",
            "Epoch 916/1000\n",
            "37/37 [==============================] - 11s 280ms/step - loss: 499365.3438 - mae: 639.8876 - val_loss: 416835.9688 - val_mae: 502.2277\n",
            "Epoch 917/1000\n",
            "37/37 [==============================] - 11s 276ms/step - loss: 498150.6562 - mae: 639.9282 - val_loss: 409200.9062 - val_mae: 493.8994\n",
            "Epoch 918/1000\n",
            "37/37 [==============================] - 11s 274ms/step - loss: 500787.3125 - mae: 642.9064 - val_loss: 408579.4062 - val_mae: 493.5321\n",
            "Epoch 919/1000\n",
            "37/37 [==============================] - 10s 272ms/step - loss: 502738.9688 - mae: 643.4221 - val_loss: 427005.9062 - val_mae: 511.0171\n",
            "Epoch 920/1000\n",
            "37/37 [==============================] - 11s 272ms/step - loss: 500163.7500 - mae: 641.8048 - val_loss: 417631.4062 - val_mae: 502.6637\n",
            "Epoch 921/1000\n",
            "37/37 [==============================] - 11s 284ms/step - loss: 496039.9688 - mae: 640.9863 - val_loss: 401872.0312 - val_mae: 486.4554\n",
            "Epoch 922/1000\n",
            "37/37 [==============================] - 6s 149ms/step - loss: 503683.1250 - mae: 643.4026 - val_loss: 409035.0938 - val_mae: 494.0351\n",
            "Epoch 923/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 489766.6562 - mae: 636.7214 - val_loss: 418165.0938 - val_mae: 502.7141\n",
            "Epoch 924/1000\n",
            "37/37 [==============================] - 11s 287ms/step - loss: 501419.4375 - mae: 641.5372 - val_loss: 426499.3750 - val_mae: 511.4430\n",
            "Epoch 925/1000\n",
            "37/37 [==============================] - 11s 282ms/step - loss: 496681.1875 - mae: 639.5451 - val_loss: 417482.9062 - val_mae: 502.3488\n",
            "Epoch 926/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 497122.5312 - mae: 640.8699 - val_loss: 426414.8750 - val_mae: 511.3966\n",
            "Epoch 927/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 504049.9688 - mae: 643.6700 - val_loss: 410428.7188 - val_mae: 494.8284\n",
            "Epoch 928/1000\n",
            "37/37 [==============================] - 10s 272ms/step - loss: 505482.1562 - mae: 644.6674 - val_loss: 418084.0000 - val_mae: 503.1557\n",
            "Epoch 929/1000\n",
            "37/37 [==============================] - 11s 274ms/step - loss: 496282.4375 - mae: 639.3914 - val_loss: 418430.5000 - val_mae: 502.8825\n",
            "Epoch 930/1000\n",
            "37/37 [==============================] - 11s 285ms/step - loss: 489863.0312 - mae: 636.9839 - val_loss: 425812.5938 - val_mae: 510.5673\n",
            "Epoch 931/1000\n",
            "37/37 [==============================] - 6s 148ms/step - loss: 502532.9375 - mae: 642.5105 - val_loss: 408139.6250 - val_mae: 493.7999\n",
            "Epoch 932/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 499215.8438 - mae: 639.9056 - val_loss: 424071.4062 - val_mae: 510.1088\n",
            "Epoch 933/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 497450.1250 - mae: 639.5571 - val_loss: 416806.2500 - val_mae: 501.6782\n",
            "Epoch 934/1000\n",
            "37/37 [==============================] - 11s 282ms/step - loss: 501585.0938 - mae: 642.5096 - val_loss: 399578.2500 - val_mae: 484.9095\n",
            "Epoch 935/1000\n",
            "37/37 [==============================] - 7s 171ms/step - loss: 499477.7812 - mae: 640.8533 - val_loss: 408531.0000 - val_mae: 494.3524\n",
            "Epoch 936/1000\n",
            "37/37 [==============================] - 10s 273ms/step - loss: 503427.5625 - mae: 642.8702 - val_loss: 414729.5000 - val_mae: 500.4530\n",
            "Epoch 937/1000\n",
            "37/37 [==============================] - 11s 277ms/step - loss: 501357.1875 - mae: 641.7752 - val_loss: 400251.0000 - val_mae: 485.5526\n",
            "Epoch 938/1000\n",
            "37/37 [==============================] - 11s 284ms/step - loss: 500619.3125 - mae: 641.4354 - val_loss: 408089.0938 - val_mae: 494.1103\n",
            "Epoch 939/1000\n",
            "37/37 [==============================] - 11s 279ms/step - loss: 500323.5625 - mae: 641.8260 - val_loss: 397449.2500 - val_mae: 483.6992\n",
            "Epoch 940/1000\n",
            "37/37 [==============================] - 10s 273ms/step - loss: 502149.2188 - mae: 644.1776 - val_loss: 416893.4062 - val_mae: 502.2504\n",
            "Epoch 941/1000\n",
            "37/37 [==============================] - 10s 273ms/step - loss: 491044.6250 - mae: 635.8480 - val_loss: 399077.1562 - val_mae: 484.8933\n",
            "Epoch 942/1000\n",
            "37/37 [==============================] - 11s 273ms/step - loss: 495941.5625 - mae: 640.2792 - val_loss: 397782.5938 - val_mae: 483.8772\n",
            "Epoch 943/1000\n",
            "37/37 [==============================] - 11s 279ms/step - loss: 501942.8750 - mae: 641.8837 - val_loss: 397213.3438 - val_mae: 483.5091\n",
            "Epoch 944/1000\n",
            "37/37 [==============================] - 11s 286ms/step - loss: 500835.6875 - mae: 640.2328 - val_loss: 413224.3438 - val_mae: 500.5285\n",
            "Epoch 945/1000\n",
            "37/37 [==============================] - 11s 282ms/step - loss: 497585.9688 - mae: 638.7141 - val_loss: 413378.3438 - val_mae: 499.6085\n",
            "Epoch 946/1000\n",
            "37/37 [==============================] - 11s 273ms/step - loss: 503315.9062 - mae: 643.0239 - val_loss: 413609.9688 - val_mae: 500.0937\n",
            "Epoch 947/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 502019.7500 - mae: 642.2836 - val_loss: 398068.2812 - val_mae: 484.0105\n",
            "Epoch 948/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 503581.9688 - mae: 642.7189 - val_loss: 389968.2500 - val_mae: 475.9524\n",
            "Epoch 949/1000\n",
            "37/37 [==============================] - 11s 274ms/step - loss: 497592.5312 - mae: 638.6530 - val_loss: 407616.0000 - val_mae: 493.5619\n",
            "Epoch 950/1000\n",
            "37/37 [==============================] - 6s 149ms/step - loss: 496148.4688 - mae: 638.9963 - val_loss: 422884.6250 - val_mae: 508.5316\n",
            "Epoch 951/1000\n",
            "37/37 [==============================] - 11s 280ms/step - loss: 503052.8750 - mae: 642.8668 - val_loss: 416809.8438 - val_mae: 502.2035\n",
            "Epoch 952/1000\n",
            "37/37 [==============================] - 6s 148ms/step - loss: 501590.7500 - mae: 642.5665 - val_loss: 407420.6562 - val_mae: 493.1017\n",
            "Epoch 953/1000\n",
            "37/37 [==============================] - 11s 281ms/step - loss: 500299.2812 - mae: 640.9691 - val_loss: 400249.5312 - val_mae: 485.5468\n",
            "Epoch 954/1000\n",
            "37/37 [==============================] - 6s 154ms/step - loss: 498774.9062 - mae: 641.1238 - val_loss: 399765.2188 - val_mae: 485.2853\n",
            "Epoch 955/1000\n",
            "37/37 [==============================] - 11s 272ms/step - loss: 503528.6875 - mae: 643.9597 - val_loss: 391154.0000 - val_mae: 476.6219\n",
            "Epoch 956/1000\n",
            "37/37 [==============================] - 11s 273ms/step - loss: 500979.0312 - mae: 641.7123 - val_loss: 407154.3750 - val_mae: 493.2564\n",
            "Epoch 957/1000\n",
            "37/37 [==============================] - 11s 287ms/step - loss: 499515.5000 - mae: 640.7562 - val_loss: 407469.4688 - val_mae: 492.8531\n",
            "Epoch 958/1000\n",
            "37/37 [==============================] - 11s 283ms/step - loss: 499981.1875 - mae: 641.3430 - val_loss: 415551.5312 - val_mae: 501.2112\n",
            "Epoch 959/1000\n",
            "37/37 [==============================] - 11s 285ms/step - loss: 501549.6250 - mae: 641.0942 - val_loss: 397608.4688 - val_mae: 483.7752\n",
            "Epoch 960/1000\n",
            "37/37 [==============================] - 10s 272ms/step - loss: 498826.8750 - mae: 639.7815 - val_loss: 406757.8438 - val_mae: 492.7435\n",
            "Epoch 961/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 500520.0938 - mae: 641.1894 - val_loss: 416165.0938 - val_mae: 501.8468\n",
            "Epoch 962/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 496750.4062 - mae: 639.4031 - val_loss: 417290.8750 - val_mae: 501.9438\n",
            "Epoch 963/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 502434.2500 - mae: 641.7714 - val_loss: 414939.7500 - val_mae: 500.5534\n",
            "Epoch 964/1000\n",
            "37/37 [==============================] - 11s 285ms/step - loss: 499557.0000 - mae: 641.0417 - val_loss: 406874.8438 - val_mae: 493.1022\n",
            "Epoch 965/1000\n",
            "37/37 [==============================] - 11s 284ms/step - loss: 499799.0938 - mae: 640.0334 - val_loss: 424362.8750 - val_mae: 509.9792\n",
            "Epoch 966/1000\n",
            "37/37 [==============================] - 11s 275ms/step - loss: 503001.0312 - mae: 642.2015 - val_loss: 399433.6562 - val_mae: 484.7924\n",
            "Epoch 967/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 497404.0938 - mae: 639.3994 - val_loss: 415664.8750 - val_mae: 501.2772\n",
            "Epoch 968/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 497240.0312 - mae: 641.1899 - val_loss: 397572.3750 - val_mae: 483.7370\n",
            "Epoch 969/1000\n",
            "37/37 [==============================] - 11s 273ms/step - loss: 497188.7188 - mae: 639.3813 - val_loss: 422830.0312 - val_mae: 509.4234\n",
            "Epoch 970/1000\n",
            "37/37 [==============================] - 11s 277ms/step - loss: 498054.1562 - mae: 639.0551 - val_loss: 413763.7812 - val_mae: 500.1837\n",
            "Epoch 971/1000\n",
            "37/37 [==============================] - 6s 149ms/step - loss: 495230.1875 - mae: 638.7941 - val_loss: 431903.1250 - val_mae: 517.7349\n",
            "Epoch 972/1000\n",
            "37/37 [==============================] - 6s 137ms/step - loss: 495222.4375 - mae: 639.2819 - val_loss: 407280.7188 - val_mae: 492.7411\n",
            "Epoch 973/1000\n",
            "37/37 [==============================] - 11s 280ms/step - loss: 501535.3438 - mae: 641.7360 - val_loss: 423047.9688 - val_mae: 509.2267\n",
            "Epoch 974/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 493766.6562 - mae: 636.5446 - val_loss: 422664.3438 - val_mae: 508.7056\n",
            "Epoch 975/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 499882.9375 - mae: 640.5739 - val_loss: 413993.3750 - val_mae: 499.9811\n",
            "Epoch 976/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 498927.5625 - mae: 640.1232 - val_loss: 414833.5312 - val_mae: 501.0985\n",
            "Epoch 977/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 500435.3438 - mae: 641.2364 - val_loss: 397312.0312 - val_mae: 483.9041\n",
            "Epoch 978/1000\n",
            "37/37 [==============================] - 11s 280ms/step - loss: 501679.5000 - mae: 641.9451 - val_loss: 431441.3438 - val_mae: 518.0919\n",
            "Epoch 979/1000\n",
            "37/37 [==============================] - 11s 281ms/step - loss: 501286.4375 - mae: 642.0558 - val_loss: 406457.6562 - val_mae: 492.5603\n",
            "Epoch 980/1000\n",
            "37/37 [==============================] - 11s 274ms/step - loss: 502238.8438 - mae: 642.4488 - val_loss: 407526.2500 - val_mae: 492.8654\n",
            "Epoch 981/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 502467.3125 - mae: 641.8722 - val_loss: 424159.5000 - val_mae: 510.2008\n",
            "Epoch 982/1000\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 500298.4062 - mae: 641.3489 - val_loss: 407006.8750 - val_mae: 493.1751\n",
            "Epoch 983/1000\n",
            "37/37 [==============================] - 11s 271ms/step - loss: 501619.8438 - mae: 641.7626 - val_loss: 424455.9688 - val_mae: 510.0425\n",
            "Epoch 984/1000\n",
            "37/37 [==============================] - 11s 279ms/step - loss: 497108.0000 - mae: 638.5038 - val_loss: 414881.0312 - val_mae: 500.8363\n",
            "Epoch 985/1000\n",
            "37/37 [==============================] - 11s 282ms/step - loss: 497236.2188 - mae: 639.3440 - val_loss: 414709.5000 - val_mae: 501.0286\n",
            "Epoch 986/1000\n",
            "37/37 [==============================] - 11s 274ms/step - loss: 499064.9062 - mae: 640.0314 - val_loss: 405784.9688 - val_mae: 492.1737\n",
            "Epoch 987/1000\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 491761.2500 - mae: 637.8588 - val_loss: 397358.0312 - val_mae: 483.6113\n",
            "Epoch 988/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 498641.8750 - mae: 639.6151 - val_loss: 413769.7188 - val_mae: 500.4987\n",
            "Epoch 989/1000\n",
            "37/37 [==============================] - 11s 273ms/step - loss: 505316.1875 - mae: 644.6091 - val_loss: 404396.7500 - val_mae: 491.3976\n",
            "Epoch 990/1000\n",
            "37/37 [==============================] - 11s 281ms/step - loss: 504919.1562 - mae: 644.0335 - val_loss: 413879.3750 - val_mae: 500.2513\n",
            "Epoch 991/1000\n",
            "37/37 [==============================] - 11s 283ms/step - loss: 500572.1562 - mae: 641.0679 - val_loss: 414437.7188 - val_mae: 500.8755\n",
            "Epoch 992/1000\n",
            "37/37 [==============================] - 11s 279ms/step - loss: 498243.7812 - mae: 640.9729 - val_loss: 406259.2500 - val_mae: 492.1335\n",
            "Epoch 993/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 502587.8750 - mae: 643.3561 - val_loss: 414832.5000 - val_mae: 500.4621\n",
            "Epoch 994/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 501922.6250 - mae: 641.7873 - val_loss: 415846.9062 - val_mae: 501.3675\n",
            "Epoch 995/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 500389.5625 - mae: 642.4758 - val_loss: 398041.7500 - val_mae: 484.0119\n",
            "Epoch 996/1000\n",
            "37/37 [==============================] - 11s 271ms/step - loss: 495082.3438 - mae: 638.2539 - val_loss: 415728.9062 - val_mae: 501.6071\n",
            "Epoch 997/1000\n",
            "37/37 [==============================] - 11s 284ms/step - loss: 504294.3125 - mae: 644.5052 - val_loss: 407590.1562 - val_mae: 493.2201\n",
            "Epoch 998/1000\n",
            "37/37 [==============================] - 11s 278ms/step - loss: 499824.2812 - mae: 641.0432 - val_loss: 415464.3438 - val_mae: 501.1446\n",
            "Epoch 999/1000\n",
            "37/37 [==============================] - 11s 274ms/step - loss: 495090.4688 - mae: 638.5630 - val_loss: 414302.8750 - val_mae: 500.4825\n",
            "Epoch 1000/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 502110.4688 - mae: 641.8683 - val_loss: 406062.3750 - val_mae: 492.6534\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "mae = history.history['mae']\n",
        "val_mae = history.history['val_mae']\n",
        "\n",
        "epochs_x = range(len(loss))\n",
        "\n",
        "plt.plot(epochs_x, mae, 'co', label='Training MAE')\n",
        "plt.plot(epochs_x, val_mae, 'k', label='Validation MAE')\n",
        "plt.title('Training and Mean squared error')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'co', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "     "
      ],
      "metadata": {
        "id": "Y3K89-CM-dfg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "eaa38e34-64c8-485c-be8a-c85721974c94"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_x"
      ],
      "metadata": {
        "id": "N_sP_ZmSY-Jv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efd929bc-e678-4e8b-87ad-3028e583ee8b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "range(0, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download the model\n"
      ],
      "metadata": {
        "id": "R19IJQSYoW7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('./content/drive/My Drive/new', exist_ok=True)\n",
        "model.save('./content/drive/My Drive/new/regression_unfreeze.h5')"
      ],
      "metadata": {
        "id": "Zed4TdFcG2iJ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n"
      ],
      "metadata": {
        "id": "P5eMxm1NV-oY"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('./content/drive/My Drive/new/regression_unfreeze.h5')"
      ],
      "metadata": {
        "id": "wY_pDlxkRwxS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "fac22706-8fb0-4737-c156-d60813ec7f39"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a0a4317b-cf63-42b7-b0b1-18f1fb23dcfe\", \"regression_unfreeze.h5\", 49132744)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}