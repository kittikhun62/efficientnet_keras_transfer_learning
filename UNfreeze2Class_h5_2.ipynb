{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNX6JFvkNFt1Ky5XHjFKNyO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kittikhun62/efficientnet_keras_transfer_learning/blob/master/UNfreeze2Class_h5_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# import from drive"
      ],
      "metadata": {
        "id": "bB2gfuYWczY-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpXyZ9k5YIJu",
        "outputId": "6aec6004-66c3-405c-eaca-947e14ee7195"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (r'/content/drive/My Drive/data - 2 class.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "7mqo2OLAc2pG",
        "outputId": "2d609cf1-face-46dd-a410-149ef12ad5ac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      No                      Name_file  \\\n",
              "0      1                        pore-sb   \n",
              "1      2                        pore-sb   \n",
              "2      3                        pore-sb   \n",
              "3      4                        pore-sb   \n",
              "4      5                        pore-sb   \n",
              "..   ...                            ...   \n",
              "795  796  1-s2.0-S2095268622000210-main   \n",
              "796  797  1-s2.0-S2095268622000210-main   \n",
              "797  798  1-s2.0-S2095268622000210-main   \n",
              "798  799  1-s2.0-S2095268622000210-main   \n",
              "799  800  1-s2.0-S2095268622000210-main   \n",
              "\n",
              "                                            Name_Paper  \\\n",
              "0    Preparation and electrochemical behaviour of b...   \n",
              "1    Preparation and electrochemical behaviour of b...   \n",
              "2    Preparation and electrochemical behaviour of b...   \n",
              "3    Preparation and electrochemical behaviour of b...   \n",
              "4    Preparation and electrochemical behaviour of b...   \n",
              "..                                                 ...   \n",
              "795  Integration of preparation of K, Na-embedded a...   \n",
              "796  Integration of preparation of K, Na-embedded a...   \n",
              "797  Integration of preparation of K, Na-embedded a...   \n",
              "798  Integration of preparation of K, Na-embedded a...   \n",
              "799  Integration of preparation of K, Na-embedded a...   \n",
              "\n",
              "                                               journal  \\\n",
              "0                                  Korean J. Chem. Eng   \n",
              "1                                  Korean J. Chem. Eng   \n",
              "2                                  Korean J. Chem. Eng   \n",
              "3                                  Korean J. Chem. Eng   \n",
              "4                                  Korean J. Chem. Eng   \n",
              "..                                                 ...   \n",
              "795  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "796  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "797  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "798  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "799  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "\n",
              "                                          path_Picture  detail  Class     BET  \\\n",
              "0    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom1  0-800  135.06   \n",
              "1    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom2  0-800  135.06   \n",
              "2    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom3  0-800  135.06   \n",
              "3    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom4  0-800  135.06   \n",
              "4    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom5  0-800  135.06   \n",
              "..                                                 ...     ...    ...     ...   \n",
              "795  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom21  0-800  301.70   \n",
              "796  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom22  0-800  301.70   \n",
              "797  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom23  0-800  301.70   \n",
              "798  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom24  0-800  301.70   \n",
              "799  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom25  0-800  301.70   \n",
              "\n",
              "     Size(mico)  \n",
              "0            10  \n",
              "1            10  \n",
              "2            10  \n",
              "3            10  \n",
              "4            10  \n",
              "..          ...  \n",
              "795          10  \n",
              "796          10  \n",
              "797          10  \n",
              "798          10  \n",
              "799          10  \n",
              "\n",
              "[800 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e78163ba-10fe-40c0-8ce8-ae29fdd33b23\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>No</th>\n",
              "      <th>Name_file</th>\n",
              "      <th>Name_Paper</th>\n",
              "      <th>journal</th>\n",
              "      <th>path_Picture</th>\n",
              "      <th>detail</th>\n",
              "      <th>Class</th>\n",
              "      <th>BET</th>\n",
              "      <th>Size(mico)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom1</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom2</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom3</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom4</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom5</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>795</th>\n",
              "      <td>796</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom21</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>796</th>\n",
              "      <td>797</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom22</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>797</th>\n",
              "      <td>798</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom23</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>798</th>\n",
              "      <td>799</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom24</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799</th>\n",
              "      <td>800</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom25</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>800 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e78163ba-10fe-40c0-8ce8-ae29fdd33b23')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e78163ba-10fe-40c0-8ce8-ae29fdd33b23 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e78163ba-10fe-40c0-8ce8-ae29fdd33b23');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports library"
      ],
      "metadata": {
        "id": "VkYa-4LeTbir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "myAsBcVhTW7j"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## hyper parameter\n"
      ],
      "metadata": {
        "id": "T529UM_tVV-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "width = 150\n",
        "height = 150\n",
        "\n",
        "epochs = 1000 #จำนวนรอบในการ Train\n",
        "\n",
        "NUM_TRAIN = 598  # จำนวนภาพ Train\n",
        "NUM_TEST = 101 #จำนวนภาพ Test\n",
        "\n",
        "dropout_rate = 0.3\n",
        "input_shape = (height, width, 3) #ขนาด image enter"
      ],
      "metadata": {
        "id": "zXpmkJ2GVZ1l"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone efficientnet repo"
      ],
      "metadata": {
        "id": "DSSZIFGhUyQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/"
      ],
      "metadata": {
        "id": "nFvKcuBDTj1N",
        "outputId": "4944987c-7b5b-468a-c941-22cfd89b9fe4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 837, done.\u001b[K\n",
            "remote: Counting objects: 100% (359/359), done.\u001b[K\n",
            "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
            "remote: Total 837 (delta 255), reused 328 (delta 235), pack-reused 478\u001b[K\n",
            "Receiving objects: 100% (837/837), 13.82 MiB | 19.82 MiB/s, done.\n",
            "Resolving deltas: 100% (495/495), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import efficientnet and load the conv base model"
      ],
      "metadata": {
        "id": "j3EgSOiSZHaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "iI3DQ18HU2TF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "#EfficientNet สร้างขึ้นสำหรับการจำแนกประเภท ImageNet ประกอบด้วยป้ายกำกับคลาส 1,000 รายการ เรามีเพียง 2 เลเยอร์เท่านั้น ซึ่งหมายความว่าเลเยอร์สองสามเลเยอร์สุดท้ายสำหรับการจำแนกไม่มีประโยชน์สำหรับเรา สามารถยกเว้นได้ขณะโหลดโมเดลโดยระบุอาร์กิวเมนต์ include_top เป็น False และนำไปใช้กับโมเดล ImageNet อื่นๆ ที่มีอยู่ในแอปพลิเคชัน Keras เช่นกัน\n",
        "\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "UmBDAgF_VAjq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca354ce2-ed34-4a20-d65f-aba55112e911"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "id": "rRXoFFzfU2Oi",
        "outputId": "3453abd2-5ffb-4856-a84f-b08281575585",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 4,007,548\n",
            "Non-trainable params: 42,016\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/new/2Class_2000.h5')\n",
        "\n",
        "from efficientnet.layers import Swish, DropConnect\n",
        "from efficientnet.model import ConvKernalInitializer\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "\n",
        "get_custom_objects().update({\n",
        "    'ConvKernalInitializer': ConvKernalInitializer,\n",
        "    'Swish': Swish,\n",
        "    'DropConnect':DropConnect\n",
        "})"
      ],
      "metadata": {
        "id": "MwNk3sNbc2Qx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load model \n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/drive/My Drive/new/2Class_2000.h5')\n",
        "height = width = model.input_shape[1]"
      ],
      "metadata": {
        "id": "4v4nzKQtJZ4z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/My Drive/new project'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Directories for our training,\n",
        "# validation and test splits\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.makedirs(test_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "UDxvF-b8Jcq1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, # image input 0-255 --> 0-1 เปลี่ยนค่าสี\n",
        "      rotation_range=40,# หมุนภาพในองศา\n",
        "      width_shift_range=0.2, #เปลี่ยนความกว้าง\n",
        "      height_shift_range=0.2, #ปลี่ยนความสูง\n",
        "      shear_range=0.2, #ทำให้ภาพเบี้ยว\n",
        "      zoom_range=0.2, # Randomly zoom image\n",
        "      horizontal_flip=True, \n",
        "      #โดย Default เมื่อมีการเลื่อนภาพ บิดภาพ หมุนภาพ จะเกิดพื้นที่ว่างที่มุม \n",
        "      #ซึ่งจะมีการเติมภาพให้เต็มโดยใช้เทคนิคแบบ Nearest neighbor ซึ่งเป็นการดึงสีบริเวณใหล้าเคียงมาระบายให้เต็ม แต่เราก็ยังสามารถกำหนดวิธีการ Fill ภาพด้วยเทคนิคอื่นได้จาก Parameter fill_mode\n",
        "      fill_mode='nearest')\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory #ไดเรกเป้าหมาย\n",
        "        train_dir,\n",
        "        # รูปภาพทั้งหมดจะถูกปรับขนาดตามความสูงและความกว้างของเป้าหมาย\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        #เนื่องจากเราใช้ categorical_crossentropy loss เราจึงต้องมีป้ายกำกับตามหมวดหมู่\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory( #การดึงภาพจาก Directory มาเข้าโมเดล \n",
        "        validation_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "     \n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znE38DtIJeN-",
        "outputId": "3c841a64-11e6-4d92-8e1a-4b6cf6a37cbc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 598 images belonging to 2 classes.\n",
            "Found 101 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multiply_16\n",
        "# set 'multiply_16' and following layers trainable\n",
        "conv_base.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'multiply_16':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False  \n",
        "     "
      ],
      "metadata": {
        "id": "tEaPoHJCJq13"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7ERVUfUJsQq",
        "outputId": "69f69274-d5ae-44ea-d82a-bef409b6fb3e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-caa7b37242a8>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "37/37 [==============================] - 67s 1s/step - loss: 0.4950 - acc: 0.7646 - val_loss: 0.6836 - val_acc: 0.6562\n",
            "Epoch 2/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5099 - acc: 0.7388 - val_loss: 0.6963 - val_acc: 0.6354\n",
            "Epoch 3/1000\n",
            "37/37 [==============================] - 8s 201ms/step - loss: 0.5028 - acc: 0.7526 - val_loss: 0.6772 - val_acc: 0.6146\n",
            "Epoch 4/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5182 - acc: 0.7595 - val_loss: 0.6707 - val_acc: 0.6562\n",
            "Epoch 5/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.5289 - acc: 0.7285 - val_loss: 0.6527 - val_acc: 0.6458\n",
            "Epoch 6/1000\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 0.5101 - acc: 0.7646 - val_loss: 0.6693 - val_acc: 0.6250\n",
            "Epoch 7/1000\n",
            "37/37 [==============================] - 8s 205ms/step - loss: 0.5038 - acc: 0.7457 - val_loss: 0.6775 - val_acc: 0.6250\n",
            "Epoch 8/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5263 - acc: 0.7302 - val_loss: 0.6767 - val_acc: 0.6250\n",
            "Epoch 9/1000\n",
            "37/37 [==============================] - 8s 205ms/step - loss: 0.5176 - acc: 0.7320 - val_loss: 0.6545 - val_acc: 0.6562\n",
            "Epoch 10/1000\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.5026 - acc: 0.7474 - val_loss: 0.6617 - val_acc: 0.6458\n",
            "Epoch 11/1000\n",
            "37/37 [==============================] - 8s 206ms/step - loss: 0.5134 - acc: 0.7509 - val_loss: 0.6590 - val_acc: 0.6667\n",
            "Epoch 12/1000\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.4870 - acc: 0.7612 - val_loss: 0.6731 - val_acc: 0.6562\n",
            "Epoch 13/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.4934 - acc: 0.7440 - val_loss: 0.6666 - val_acc: 0.6667\n",
            "Epoch 14/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.5367 - acc: 0.7320 - val_loss: 0.6807 - val_acc: 0.6146\n",
            "Epoch 15/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5158 - acc: 0.7302 - val_loss: 0.6689 - val_acc: 0.6354\n",
            "Epoch 16/1000\n",
            "37/37 [==============================] - 3s 71ms/step - loss: 0.5244 - acc: 0.7199 - val_loss: 0.6613 - val_acc: 0.6354\n",
            "Epoch 17/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.5030 - acc: 0.7491 - val_loss: 0.6511 - val_acc: 0.6458\n",
            "Epoch 18/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5205 - acc: 0.7474 - val_loss: 0.6652 - val_acc: 0.6250\n",
            "Epoch 19/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5358 - acc: 0.7216 - val_loss: 0.6536 - val_acc: 0.6458\n",
            "Epoch 20/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5226 - acc: 0.7320 - val_loss: 0.6779 - val_acc: 0.6250\n",
            "Epoch 21/1000\n",
            "37/37 [==============================] - 8s 204ms/step - loss: 0.5201 - acc: 0.7491 - val_loss: 0.6596 - val_acc: 0.6458\n",
            "Epoch 22/1000\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.5291 - acc: 0.7354 - val_loss: 0.6790 - val_acc: 0.6354\n",
            "Epoch 23/1000\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.4880 - acc: 0.7732 - val_loss: 0.6768 - val_acc: 0.6146\n",
            "Epoch 24/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.5249 - acc: 0.7371 - val_loss: 0.6447 - val_acc: 0.6562\n",
            "Epoch 25/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5002 - acc: 0.7371 - val_loss: 0.6588 - val_acc: 0.6354\n",
            "Epoch 26/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.5247 - acc: 0.7440 - val_loss: 0.6667 - val_acc: 0.6250\n",
            "Epoch 27/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.5057 - acc: 0.7371 - val_loss: 0.6374 - val_acc: 0.6562\n",
            "Epoch 28/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5044 - acc: 0.7509 - val_loss: 0.6679 - val_acc: 0.6250\n",
            "Epoch 29/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.4932 - acc: 0.7577 - val_loss: 0.6729 - val_acc: 0.6354\n",
            "Epoch 30/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5335 - acc: 0.7440 - val_loss: 0.6410 - val_acc: 0.6667\n",
            "Epoch 31/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.5300 - acc: 0.7165 - val_loss: 0.6526 - val_acc: 0.6354\n",
            "Epoch 32/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5002 - acc: 0.7543 - val_loss: 0.6544 - val_acc: 0.6250\n",
            "Epoch 33/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5068 - acc: 0.7251 - val_loss: 0.6470 - val_acc: 0.6458\n",
            "Epoch 34/1000\n",
            "37/37 [==============================] - 3s 84ms/step - loss: 0.5401 - acc: 0.7131 - val_loss: 0.6523 - val_acc: 0.6458\n",
            "Epoch 35/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5231 - acc: 0.7423 - val_loss: 0.6616 - val_acc: 0.6250\n",
            "Epoch 36/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5224 - acc: 0.7457 - val_loss: 0.6438 - val_acc: 0.6771\n",
            "Epoch 37/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5109 - acc: 0.7663 - val_loss: 0.6478 - val_acc: 0.6458\n",
            "Epoch 38/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.4925 - acc: 0.7354 - val_loss: 0.6631 - val_acc: 0.6354\n",
            "Epoch 39/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.4852 - acc: 0.7852 - val_loss: 0.6630 - val_acc: 0.6354\n",
            "Epoch 40/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.4786 - acc: 0.7577 - val_loss: 0.6399 - val_acc: 0.6562\n",
            "Epoch 41/1000\n",
            "37/37 [==============================] - 8s 207ms/step - loss: 0.5138 - acc: 0.7457 - val_loss: 0.6617 - val_acc: 0.6250\n",
            "Epoch 42/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.5069 - acc: 0.7577 - val_loss: 0.6649 - val_acc: 0.6250\n",
            "Epoch 43/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5322 - acc: 0.7337 - val_loss: 0.6567 - val_acc: 0.6250\n",
            "Epoch 44/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.4927 - acc: 0.7595 - val_loss: 0.6802 - val_acc: 0.6354\n",
            "Epoch 45/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.5300 - acc: 0.7405 - val_loss: 0.6524 - val_acc: 0.6354\n",
            "Epoch 46/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5257 - acc: 0.7285 - val_loss: 0.6420 - val_acc: 0.6458\n",
            "Epoch 47/1000\n",
            "37/37 [==============================] - 9s 219ms/step - loss: 0.5185 - acc: 0.7216 - val_loss: 0.6700 - val_acc: 0.6146\n",
            "Epoch 48/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.5085 - acc: 0.7560 - val_loss: 0.6502 - val_acc: 0.6354\n",
            "Epoch 49/1000\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.5137 - acc: 0.7371 - val_loss: 0.6442 - val_acc: 0.6354\n",
            "Epoch 50/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.4939 - acc: 0.7551 - val_loss: 0.6479 - val_acc: 0.6458\n",
            "Epoch 51/1000\n",
            "37/37 [==============================] - 8s 208ms/step - loss: 0.5119 - acc: 0.7457 - val_loss: 0.6547 - val_acc: 0.6250\n",
            "Epoch 52/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5103 - acc: 0.7320 - val_loss: 0.6628 - val_acc: 0.6250\n",
            "Epoch 53/1000\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 0.5297 - acc: 0.7371 - val_loss: 0.6497 - val_acc: 0.6458\n",
            "Epoch 54/1000\n",
            "37/37 [==============================] - 9s 220ms/step - loss: 0.5061 - acc: 0.7543 - val_loss: 0.6559 - val_acc: 0.6354\n",
            "Epoch 55/1000\n",
            "37/37 [==============================] - 8s 207ms/step - loss: 0.5279 - acc: 0.7405 - val_loss: 0.6511 - val_acc: 0.6354\n",
            "Epoch 56/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5044 - acc: 0.7595 - val_loss: 0.6605 - val_acc: 0.6354\n",
            "Epoch 57/1000\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.5089 - acc: 0.7474 - val_loss: 0.6470 - val_acc: 0.6458\n",
            "Epoch 58/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.4885 - acc: 0.7526 - val_loss: 0.6645 - val_acc: 0.6458\n",
            "Epoch 59/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.5261 - acc: 0.7268 - val_loss: 0.6655 - val_acc: 0.6458\n",
            "Epoch 60/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5298 - acc: 0.7268 - val_loss: 0.6617 - val_acc: 0.6354\n",
            "Epoch 61/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.5298 - acc: 0.7320 - val_loss: 0.6586 - val_acc: 0.6354\n",
            "Epoch 62/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.4900 - acc: 0.7509 - val_loss: 0.6724 - val_acc: 0.6458\n",
            "Epoch 63/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.4957 - acc: 0.7612 - val_loss: 0.6784 - val_acc: 0.6146\n",
            "Epoch 64/1000\n",
            "37/37 [==============================] - 8s 207ms/step - loss: 0.5176 - acc: 0.7543 - val_loss: 0.6594 - val_acc: 0.6562\n",
            "Epoch 65/1000\n",
            "37/37 [==============================] - 8s 207ms/step - loss: 0.5121 - acc: 0.7491 - val_loss: 0.6816 - val_acc: 0.6146\n",
            "Epoch 66/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5299 - acc: 0.7526 - val_loss: 0.6723 - val_acc: 0.6458\n",
            "Epoch 67/1000\n",
            "37/37 [==============================] - 8s 207ms/step - loss: 0.5046 - acc: 0.7491 - val_loss: 0.6783 - val_acc: 0.6146\n",
            "Epoch 68/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5081 - acc: 0.7388 - val_loss: 0.6570 - val_acc: 0.6354\n",
            "Epoch 69/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.5079 - acc: 0.7354 - val_loss: 0.6437 - val_acc: 0.6458\n",
            "Epoch 70/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.5156 - acc: 0.7354 - val_loss: 0.6656 - val_acc: 0.6250\n",
            "Epoch 71/1000\n",
            "37/37 [==============================] - 8s 208ms/step - loss: 0.4921 - acc: 0.7405 - val_loss: 0.6603 - val_acc: 0.6250\n",
            "Epoch 72/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.4967 - acc: 0.7543 - val_loss: 0.6409 - val_acc: 0.6354\n",
            "Epoch 73/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.5014 - acc: 0.7612 - val_loss: 0.6563 - val_acc: 0.6250\n",
            "Epoch 74/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5377 - acc: 0.7354 - val_loss: 0.6601 - val_acc: 0.6250\n",
            "Epoch 75/1000\n",
            "37/37 [==============================] - 8s 205ms/step - loss: 0.4986 - acc: 0.7371 - val_loss: 0.6454 - val_acc: 0.6146\n",
            "Epoch 76/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5498 - acc: 0.7234 - val_loss: 0.6531 - val_acc: 0.5521\n",
            "Epoch 77/1000\n",
            "37/37 [==============================] - 8s 207ms/step - loss: 0.5053 - acc: 0.7457 - val_loss: 0.6661 - val_acc: 0.6458\n",
            "Epoch 78/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.5295 - acc: 0.7268 - val_loss: 0.6708 - val_acc: 0.6146\n",
            "Epoch 79/1000\n",
            "37/37 [==============================] - 8s 207ms/step - loss: 0.4999 - acc: 0.7629 - val_loss: 0.6532 - val_acc: 0.6354\n",
            "Epoch 80/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.5190 - acc: 0.7509 - val_loss: 0.6526 - val_acc: 0.6562\n",
            "Epoch 81/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5343 - acc: 0.7509 - val_loss: 0.6545 - val_acc: 0.6354\n",
            "Epoch 82/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5225 - acc: 0.7560 - val_loss: 0.6614 - val_acc: 0.6354\n",
            "Epoch 83/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.4955 - acc: 0.7416 - val_loss: 0.6706 - val_acc: 0.6146\n",
            "Epoch 84/1000\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.4988 - acc: 0.7371 - val_loss: 0.6492 - val_acc: 0.6562\n",
            "Epoch 85/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5252 - acc: 0.7268 - val_loss: 0.6741 - val_acc: 0.6354\n",
            "Epoch 86/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.5299 - acc: 0.7560 - val_loss: 0.6564 - val_acc: 0.6562\n",
            "Epoch 87/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.5033 - acc: 0.7526 - val_loss: 0.6888 - val_acc: 0.6354\n",
            "Epoch 88/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.4970 - acc: 0.7388 - val_loss: 0.6631 - val_acc: 0.6458\n",
            "Epoch 89/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.5042 - acc: 0.7474 - val_loss: 0.6698 - val_acc: 0.6250\n",
            "Epoch 90/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.5099 - acc: 0.7551 - val_loss: 0.6466 - val_acc: 0.6458\n",
            "Epoch 91/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.4810 - acc: 0.7749 - val_loss: 0.6447 - val_acc: 0.6667\n",
            "Epoch 92/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5030 - acc: 0.7517 - val_loss: 0.6642 - val_acc: 0.6458\n",
            "Epoch 93/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5355 - acc: 0.7010 - val_loss: 0.6519 - val_acc: 0.6667\n",
            "Epoch 94/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.5316 - acc: 0.7199 - val_loss: 0.6601 - val_acc: 0.6562\n",
            "Epoch 95/1000\n",
            "37/37 [==============================] - 4s 81ms/step - loss: 0.5304 - acc: 0.7423 - val_loss: 0.6548 - val_acc: 0.6354\n",
            "Epoch 96/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5058 - acc: 0.7457 - val_loss: 0.6672 - val_acc: 0.6250\n",
            "Epoch 97/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.5125 - acc: 0.7491 - val_loss: 0.6582 - val_acc: 0.6354\n",
            "Epoch 98/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.5098 - acc: 0.7337 - val_loss: 0.6710 - val_acc: 0.6250\n",
            "Epoch 99/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5101 - acc: 0.7526 - val_loss: 0.6428 - val_acc: 0.6667\n",
            "Epoch 100/1000\n",
            "37/37 [==============================] - 8s 208ms/step - loss: 0.5258 - acc: 0.7302 - val_loss: 0.6563 - val_acc: 0.6354\n",
            "Epoch 101/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.5108 - acc: 0.7285 - val_loss: 0.6496 - val_acc: 0.6354\n",
            "Epoch 102/1000\n",
            "37/37 [==============================] - 4s 81ms/step - loss: 0.4870 - acc: 0.7732 - val_loss: 0.6569 - val_acc: 0.6354\n",
            "Epoch 103/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.4998 - acc: 0.7612 - val_loss: 0.6618 - val_acc: 0.6250\n",
            "Epoch 104/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5121 - acc: 0.7314 - val_loss: 0.6532 - val_acc: 0.6250\n",
            "Epoch 105/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5370 - acc: 0.7199 - val_loss: 0.6533 - val_acc: 0.6354\n",
            "Epoch 106/1000\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.5265 - acc: 0.7251 - val_loss: 0.6463 - val_acc: 0.6562\n",
            "Epoch 107/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.4855 - acc: 0.7784 - val_loss: 0.6716 - val_acc: 0.6146\n",
            "Epoch 108/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5561 - acc: 0.7285 - val_loss: 0.6572 - val_acc: 0.6250\n",
            "Epoch 109/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.4810 - acc: 0.7801 - val_loss: 0.6559 - val_acc: 0.6354\n",
            "Epoch 110/1000\n",
            "37/37 [==============================] - 8s 207ms/step - loss: 0.5340 - acc: 0.7285 - val_loss: 0.6507 - val_acc: 0.6250\n",
            "Epoch 111/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5286 - acc: 0.7302 - val_loss: 0.6544 - val_acc: 0.6042\n",
            "Epoch 112/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5237 - acc: 0.7182 - val_loss: 0.6701 - val_acc: 0.5729\n",
            "Epoch 113/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5137 - acc: 0.7612 - val_loss: 0.6709 - val_acc: 0.6146\n",
            "Epoch 114/1000\n",
            "37/37 [==============================] - 3s 83ms/step - loss: 0.5024 - acc: 0.7612 - val_loss: 0.6682 - val_acc: 0.6146\n",
            "Epoch 115/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.5005 - acc: 0.7560 - val_loss: 0.6702 - val_acc: 0.6250\n",
            "Epoch 116/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.5194 - acc: 0.7595 - val_loss: 0.6556 - val_acc: 0.6354\n",
            "Epoch 117/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.4841 - acc: 0.7612 - val_loss: 0.6694 - val_acc: 0.6250\n",
            "Epoch 118/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5079 - acc: 0.7337 - val_loss: 0.6517 - val_acc: 0.6458\n",
            "Epoch 119/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5306 - acc: 0.7078 - val_loss: 0.6543 - val_acc: 0.6354\n",
            "Epoch 120/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.4855 - acc: 0.7698 - val_loss: 0.6600 - val_acc: 0.6250\n",
            "Epoch 121/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.4967 - acc: 0.7560 - val_loss: 0.6630 - val_acc: 0.6354\n",
            "Epoch 122/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5072 - acc: 0.7457 - val_loss: 0.6544 - val_acc: 0.6667\n",
            "Epoch 123/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5306 - acc: 0.7474 - val_loss: 0.6454 - val_acc: 0.6667\n",
            "Epoch 124/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5048 - acc: 0.7371 - val_loss: 0.6615 - val_acc: 0.6354\n",
            "Epoch 125/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.4860 - acc: 0.7680 - val_loss: 0.6446 - val_acc: 0.6562\n",
            "Epoch 126/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.5339 - acc: 0.7388 - val_loss: 0.6521 - val_acc: 0.6562\n",
            "Epoch 127/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.5329 - acc: 0.7560 - val_loss: 0.6690 - val_acc: 0.6146\n",
            "Epoch 128/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5225 - acc: 0.7371 - val_loss: 0.6561 - val_acc: 0.6354\n",
            "Epoch 129/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.5039 - acc: 0.7268 - val_loss: 0.6499 - val_acc: 0.6458\n",
            "Epoch 130/1000\n",
            "37/37 [==============================] - 4s 82ms/step - loss: 0.5386 - acc: 0.7285 - val_loss: 0.6591 - val_acc: 0.6458\n",
            "Epoch 131/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5084 - acc: 0.7577 - val_loss: 0.6719 - val_acc: 0.6146\n",
            "Epoch 132/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.5256 - acc: 0.7337 - val_loss: 0.6601 - val_acc: 0.6562\n",
            "Epoch 133/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.5338 - acc: 0.7162 - val_loss: 0.6744 - val_acc: 0.6562\n",
            "Epoch 134/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.4950 - acc: 0.7526 - val_loss: 0.6733 - val_acc: 0.6458\n",
            "Epoch 135/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5396 - acc: 0.7199 - val_loss: 0.6616 - val_acc: 0.6562\n",
            "Epoch 136/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5308 - acc: 0.7320 - val_loss: 0.6324 - val_acc: 0.6667\n",
            "Epoch 137/1000\n",
            "37/37 [==============================] - 8s 223ms/step - loss: 0.5360 - acc: 0.7131 - val_loss: 0.6389 - val_acc: 0.6562\n",
            "Epoch 138/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5080 - acc: 0.7280 - val_loss: 0.6588 - val_acc: 0.6250\n",
            "Epoch 139/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5158 - acc: 0.7526 - val_loss: 0.6534 - val_acc: 0.6458\n",
            "Epoch 140/1000\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.5362 - acc: 0.7285 - val_loss: 0.6548 - val_acc: 0.6458\n",
            "Epoch 141/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5179 - acc: 0.7560 - val_loss: 0.6566 - val_acc: 0.6354\n",
            "Epoch 142/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5005 - acc: 0.7526 - val_loss: 0.6393 - val_acc: 0.6354\n",
            "Epoch 143/1000\n",
            "37/37 [==============================] - 8s 208ms/step - loss: 0.4964 - acc: 0.7457 - val_loss: 0.6493 - val_acc: 0.6458\n",
            "Epoch 144/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.5337 - acc: 0.7251 - val_loss: 0.6491 - val_acc: 0.6667\n",
            "Epoch 145/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5399 - acc: 0.7440 - val_loss: 0.6530 - val_acc: 0.6458\n",
            "Epoch 146/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.5385 - acc: 0.7027 - val_loss: 0.6632 - val_acc: 0.6458\n",
            "Epoch 147/1000\n",
            "37/37 [==============================] - 8s 208ms/step - loss: 0.5480 - acc: 0.7216 - val_loss: 0.6620 - val_acc: 0.6562\n",
            "Epoch 148/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.5228 - acc: 0.7148 - val_loss: 0.6680 - val_acc: 0.6458\n",
            "Epoch 149/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5397 - acc: 0.7302 - val_loss: 0.6618 - val_acc: 0.6458\n",
            "Epoch 150/1000\n",
            "37/37 [==============================] - 8s 208ms/step - loss: 0.5146 - acc: 0.7474 - val_loss: 0.6544 - val_acc: 0.6562\n",
            "Epoch 151/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.4950 - acc: 0.7440 - val_loss: 0.6688 - val_acc: 0.6250\n",
            "Epoch 152/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5032 - acc: 0.7698 - val_loss: 0.6637 - val_acc: 0.6354\n",
            "Epoch 153/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.5244 - acc: 0.7457 - val_loss: 0.6617 - val_acc: 0.6458\n",
            "Epoch 154/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5211 - acc: 0.7629 - val_loss: 0.6573 - val_acc: 0.6458\n",
            "Epoch 155/1000\n",
            "37/37 [==============================] - 8s 208ms/step - loss: 0.5263 - acc: 0.7474 - val_loss: 0.6684 - val_acc: 0.6250\n",
            "Epoch 156/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.4969 - acc: 0.7715 - val_loss: 0.6665 - val_acc: 0.6250\n",
            "Epoch 157/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.4842 - acc: 0.7474 - val_loss: 0.6726 - val_acc: 0.6250\n",
            "Epoch 158/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5205 - acc: 0.7354 - val_loss: 0.6327 - val_acc: 0.6562\n",
            "Epoch 159/1000\n",
            "37/37 [==============================] - 4s 80ms/step - loss: 0.5047 - acc: 0.7732 - val_loss: 0.6605 - val_acc: 0.6458\n",
            "Epoch 160/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5102 - acc: 0.7440 - val_loss: 0.6601 - val_acc: 0.6354\n",
            "Epoch 161/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.5237 - acc: 0.7354 - val_loss: 0.6499 - val_acc: 0.6562\n",
            "Epoch 162/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.4960 - acc: 0.7543 - val_loss: 0.6446 - val_acc: 0.6458\n",
            "Epoch 163/1000\n",
            "37/37 [==============================] - 8s 208ms/step - loss: 0.4964 - acc: 0.7629 - val_loss: 0.6639 - val_acc: 0.6458\n",
            "Epoch 164/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.5096 - acc: 0.7440 - val_loss: 0.6417 - val_acc: 0.6771\n",
            "Epoch 165/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.5485 - acc: 0.7405 - val_loss: 0.6604 - val_acc: 0.6250\n",
            "Epoch 166/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5453 - acc: 0.7247 - val_loss: 0.6654 - val_acc: 0.6250\n",
            "Epoch 167/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5209 - acc: 0.7405 - val_loss: 0.6459 - val_acc: 0.6354\n",
            "Epoch 168/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.5309 - acc: 0.7526 - val_loss: 0.6597 - val_acc: 0.6250\n",
            "Epoch 169/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.4944 - acc: 0.7543 - val_loss: 0.6511 - val_acc: 0.6562\n",
            "Epoch 170/1000\n",
            "37/37 [==============================] - 8s 208ms/step - loss: 0.4740 - acc: 0.7595 - val_loss: 0.6695 - val_acc: 0.6458\n",
            "Epoch 171/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.4889 - acc: 0.7560 - val_loss: 0.6623 - val_acc: 0.6458\n",
            "Epoch 172/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.4924 - acc: 0.7732 - val_loss: 0.6466 - val_acc: 0.6354\n",
            "Epoch 173/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.5216 - acc: 0.7354 - val_loss: 0.6520 - val_acc: 0.6250\n",
            "Epoch 174/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.5112 - acc: 0.7440 - val_loss: 0.6647 - val_acc: 0.6250\n",
            "Epoch 175/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.5324 - acc: 0.7320 - val_loss: 0.6533 - val_acc: 0.6354\n",
            "Epoch 176/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.5021 - acc: 0.7509 - val_loss: 0.6604 - val_acc: 0.6354\n",
            "Epoch 177/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.5172 - acc: 0.7440 - val_loss: 0.6662 - val_acc: 0.6146\n",
            "Epoch 178/1000\n",
            "37/37 [==============================] - 4s 109ms/step - loss: 0.5058 - acc: 0.7491 - val_loss: 0.6593 - val_acc: 0.6458\n",
            "Epoch 179/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.4937 - acc: 0.7423 - val_loss: 0.6722 - val_acc: 0.6354\n",
            "Epoch 180/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5094 - acc: 0.7663 - val_loss: 0.6516 - val_acc: 0.6458\n",
            "Epoch 181/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5137 - acc: 0.7474 - val_loss: 0.6471 - val_acc: 0.6562\n",
            "Epoch 182/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.4860 - acc: 0.7646 - val_loss: 0.6645 - val_acc: 0.6354\n",
            "Epoch 183/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.4752 - acc: 0.7560 - val_loss: 0.6634 - val_acc: 0.6354\n",
            "Epoch 184/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5185 - acc: 0.7423 - val_loss: 0.6559 - val_acc: 0.6250\n",
            "Epoch 185/1000\n",
            "37/37 [==============================] - 8s 208ms/step - loss: 0.5247 - acc: 0.7474 - val_loss: 0.6451 - val_acc: 0.6354\n",
            "Epoch 186/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.5058 - acc: 0.7595 - val_loss: 0.6592 - val_acc: 0.6250\n",
            "Epoch 187/1000\n",
            "37/37 [==============================] - 8s 208ms/step - loss: 0.5145 - acc: 0.7216 - val_loss: 0.6441 - val_acc: 0.6354\n",
            "Epoch 188/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5064 - acc: 0.7302 - val_loss: 0.6361 - val_acc: 0.6354\n",
            "Epoch 189/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5230 - acc: 0.7285 - val_loss: 0.6536 - val_acc: 0.6562\n",
            "Epoch 190/1000\n",
            "37/37 [==============================] - 8s 208ms/step - loss: 0.5456 - acc: 0.7251 - val_loss: 0.6668 - val_acc: 0.6354\n",
            "Epoch 191/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5085 - acc: 0.7509 - val_loss: 0.6231 - val_acc: 0.6562\n",
            "Epoch 192/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.5428 - acc: 0.7234 - val_loss: 0.6567 - val_acc: 0.6458\n",
            "Epoch 193/1000\n",
            "37/37 [==============================] - 4s 79ms/step - loss: 0.4982 - acc: 0.7612 - val_loss: 0.6524 - val_acc: 0.6458\n",
            "Epoch 194/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5015 - acc: 0.7577 - val_loss: 0.6579 - val_acc: 0.6562\n",
            "Epoch 195/1000\n",
            "37/37 [==============================] - 3s 84ms/step - loss: 0.5307 - acc: 0.7216 - val_loss: 0.6615 - val_acc: 0.6458\n",
            "Epoch 196/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.5249 - acc: 0.7457 - val_loss: 0.6633 - val_acc: 0.6562\n",
            "Epoch 197/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.5276 - acc: 0.7251 - val_loss: 0.6548 - val_acc: 0.6667\n",
            "Epoch 198/1000\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.5171 - acc: 0.7096 - val_loss: 0.6755 - val_acc: 0.6354\n",
            "Epoch 199/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5005 - acc: 0.7595 - val_loss: 0.6396 - val_acc: 0.6562\n",
            "Epoch 200/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5162 - acc: 0.7371 - val_loss: 0.6526 - val_acc: 0.6354\n",
            "Epoch 201/1000\n",
            "37/37 [==============================] - 3s 85ms/step - loss: 0.5581 - acc: 0.7045 - val_loss: 0.6541 - val_acc: 0.6458\n",
            "Epoch 202/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5214 - acc: 0.7405 - val_loss: 0.6464 - val_acc: 0.6458\n",
            "Epoch 203/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.5097 - acc: 0.7457 - val_loss: 0.6558 - val_acc: 0.6458\n",
            "Epoch 204/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.4987 - acc: 0.7526 - val_loss: 0.6424 - val_acc: 0.6667\n",
            "Epoch 205/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5054 - acc: 0.7320 - val_loss: 0.6647 - val_acc: 0.6354\n",
            "Epoch 206/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.5144 - acc: 0.7491 - val_loss: 0.6452 - val_acc: 0.6562\n",
            "Epoch 207/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5303 - acc: 0.7148 - val_loss: 0.6371 - val_acc: 0.6667\n",
            "Epoch 208/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5224 - acc: 0.7388 - val_loss: 0.6304 - val_acc: 0.6562\n",
            "Epoch 209/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.5141 - acc: 0.7551 - val_loss: 0.6393 - val_acc: 0.6667\n",
            "Epoch 210/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5302 - acc: 0.7388 - val_loss: 0.6527 - val_acc: 0.6562\n",
            "Epoch 211/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5374 - acc: 0.7234 - val_loss: 0.6378 - val_acc: 0.6771\n",
            "Epoch 212/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5136 - acc: 0.7388 - val_loss: 0.6372 - val_acc: 0.6667\n",
            "Epoch 213/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.5392 - acc: 0.7320 - val_loss: 0.6398 - val_acc: 0.6667\n",
            "Epoch 214/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.5691 - acc: 0.7165 - val_loss: 0.6535 - val_acc: 0.6458\n",
            "Epoch 215/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.5044 - acc: 0.7405 - val_loss: 0.6410 - val_acc: 0.6667\n",
            "Epoch 216/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5256 - acc: 0.7423 - val_loss: 0.6343 - val_acc: 0.6354\n",
            "Epoch 217/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.4820 - acc: 0.7595 - val_loss: 0.6444 - val_acc: 0.6250\n",
            "Epoch 218/1000\n",
            "37/37 [==============================] - 3s 85ms/step - loss: 0.5319 - acc: 0.7457 - val_loss: 0.6432 - val_acc: 0.6458\n",
            "Epoch 219/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.5056 - acc: 0.7423 - val_loss: 0.6426 - val_acc: 0.6458\n",
            "Epoch 220/1000\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.5320 - acc: 0.7440 - val_loss: 0.6475 - val_acc: 0.6354\n",
            "Epoch 221/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5530 - acc: 0.7182 - val_loss: 0.6277 - val_acc: 0.6458\n",
            "Epoch 222/1000\n",
            "37/37 [==============================] - 4s 80ms/step - loss: 0.5015 - acc: 0.7801 - val_loss: 0.6490 - val_acc: 0.6458\n",
            "Epoch 223/1000\n",
            "37/37 [==============================] - 4s 80ms/step - loss: 0.5174 - acc: 0.7560 - val_loss: 0.6294 - val_acc: 0.6562\n",
            "Epoch 224/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.4834 - acc: 0.7663 - val_loss: 0.6660 - val_acc: 0.6250\n",
            "Epoch 225/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.4978 - acc: 0.7629 - val_loss: 0.6547 - val_acc: 0.6562\n",
            "Epoch 226/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5284 - acc: 0.7388 - val_loss: 0.6554 - val_acc: 0.6562\n",
            "Epoch 227/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.5344 - acc: 0.7526 - val_loss: 0.6609 - val_acc: 0.6250\n",
            "Epoch 228/1000\n",
            "37/37 [==============================] - 5s 110ms/step - loss: 0.5160 - acc: 0.7551 - val_loss: 0.6567 - val_acc: 0.6354\n",
            "Epoch 229/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5478 - acc: 0.7302 - val_loss: 0.6421 - val_acc: 0.6667\n",
            "Epoch 230/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.5164 - acc: 0.7457 - val_loss: 0.6650 - val_acc: 0.6354\n",
            "Epoch 231/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5013 - acc: 0.7612 - val_loss: 0.6601 - val_acc: 0.6458\n",
            "Epoch 232/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5095 - acc: 0.7320 - val_loss: 0.6684 - val_acc: 0.6250\n",
            "Epoch 233/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.4936 - acc: 0.7440 - val_loss: 0.6352 - val_acc: 0.6667\n",
            "Epoch 234/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.4882 - acc: 0.7646 - val_loss: 0.6480 - val_acc: 0.6458\n",
            "Epoch 235/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5283 - acc: 0.7251 - val_loss: 0.6406 - val_acc: 0.6667\n",
            "Epoch 236/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.5049 - acc: 0.7612 - val_loss: 0.6338 - val_acc: 0.6562\n",
            "Epoch 237/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5006 - acc: 0.7543 - val_loss: 0.6531 - val_acc: 0.6458\n",
            "Epoch 238/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.5239 - acc: 0.7371 - val_loss: 0.6467 - val_acc: 0.6458\n",
            "Epoch 239/1000\n",
            "37/37 [==============================] - 8s 207ms/step - loss: 0.5542 - acc: 0.7062 - val_loss: 0.6495 - val_acc: 0.6667\n",
            "Epoch 240/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.4966 - acc: 0.7526 - val_loss: 0.6675 - val_acc: 0.6354\n",
            "Epoch 241/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.5099 - acc: 0.7423 - val_loss: 0.6656 - val_acc: 0.6354\n",
            "Epoch 242/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.4743 - acc: 0.7698 - val_loss: 0.6632 - val_acc: 0.6354\n",
            "Epoch 243/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5118 - acc: 0.7371 - val_loss: 0.6414 - val_acc: 0.6562\n",
            "Epoch 244/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.5157 - acc: 0.7423 - val_loss: 0.6577 - val_acc: 0.6354\n",
            "Epoch 245/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.4893 - acc: 0.7818 - val_loss: 0.6448 - val_acc: 0.6562\n",
            "Epoch 246/1000\n",
            "37/37 [==============================] - 3s 71ms/step - loss: 0.5066 - acc: 0.7371 - val_loss: 0.6481 - val_acc: 0.6562\n",
            "Epoch 247/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.5326 - acc: 0.7509 - val_loss: 0.6699 - val_acc: 0.6354\n",
            "Epoch 248/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.4973 - acc: 0.7680 - val_loss: 0.6616 - val_acc: 0.6250\n",
            "Epoch 249/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.4874 - acc: 0.7526 - val_loss: 0.6631 - val_acc: 0.6250\n",
            "Epoch 250/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.5187 - acc: 0.7474 - val_loss: 0.6442 - val_acc: 0.6667\n",
            "Epoch 251/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5466 - acc: 0.7182 - val_loss: 0.6602 - val_acc: 0.6354\n",
            "Epoch 252/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.5075 - acc: 0.7509 - val_loss: 0.6672 - val_acc: 0.6354\n",
            "Epoch 253/1000\n",
            "37/37 [==============================] - 8s 223ms/step - loss: 0.4942 - acc: 0.7680 - val_loss: 0.6519 - val_acc: 0.6354\n",
            "Epoch 254/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.5375 - acc: 0.7302 - val_loss: 0.6554 - val_acc: 0.6562\n",
            "Epoch 255/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5287 - acc: 0.7096 - val_loss: 0.6640 - val_acc: 0.6354\n",
            "Epoch 256/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.4872 - acc: 0.7612 - val_loss: 0.6718 - val_acc: 0.6250\n",
            "Epoch 257/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5038 - acc: 0.7595 - val_loss: 0.6601 - val_acc: 0.6354\n",
            "Epoch 258/1000\n",
            "37/37 [==============================] - 8s 223ms/step - loss: 0.5056 - acc: 0.7285 - val_loss: 0.6673 - val_acc: 0.6354\n",
            "Epoch 259/1000\n",
            "37/37 [==============================] - 3s 83ms/step - loss: 0.5230 - acc: 0.7354 - val_loss: 0.6734 - val_acc: 0.6354\n",
            "Epoch 260/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5200 - acc: 0.7543 - val_loss: 0.6569 - val_acc: 0.6562\n",
            "Epoch 261/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.4986 - acc: 0.7663 - val_loss: 0.6664 - val_acc: 0.6354\n",
            "Epoch 262/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5197 - acc: 0.7698 - val_loss: 0.6525 - val_acc: 0.6562\n",
            "Epoch 263/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.4674 - acc: 0.7543 - val_loss: 0.6718 - val_acc: 0.6354\n",
            "Epoch 264/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.4973 - acc: 0.7354 - val_loss: 0.6709 - val_acc: 0.6458\n",
            "Epoch 265/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.5210 - acc: 0.7440 - val_loss: 0.6659 - val_acc: 0.6458\n",
            "Epoch 266/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5215 - acc: 0.7457 - val_loss: 0.6633 - val_acc: 0.6562\n",
            "Epoch 267/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.5289 - acc: 0.7268 - val_loss: 0.6648 - val_acc: 0.6354\n",
            "Epoch 268/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5168 - acc: 0.7491 - val_loss: 0.6415 - val_acc: 0.6562\n",
            "Epoch 269/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.4802 - acc: 0.7543 - val_loss: 0.6400 - val_acc: 0.6562\n",
            "Epoch 270/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5228 - acc: 0.7354 - val_loss: 0.6693 - val_acc: 0.6354\n",
            "Epoch 271/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5471 - acc: 0.7285 - val_loss: 0.6728 - val_acc: 0.6354\n",
            "Epoch 272/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.5001 - acc: 0.7577 - val_loss: 0.6638 - val_acc: 0.6354\n",
            "Epoch 273/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5356 - acc: 0.7337 - val_loss: 0.6670 - val_acc: 0.6458\n",
            "Epoch 274/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5191 - acc: 0.7680 - val_loss: 0.6693 - val_acc: 0.6562\n",
            "Epoch 275/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5345 - acc: 0.7423 - val_loss: 0.6580 - val_acc: 0.6667\n",
            "Epoch 276/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.5223 - acc: 0.7285 - val_loss: 0.6654 - val_acc: 0.6354\n",
            "Epoch 277/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5288 - acc: 0.7320 - val_loss: 0.6620 - val_acc: 0.6354\n",
            "Epoch 278/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.5107 - acc: 0.7216 - val_loss: 0.6698 - val_acc: 0.6458\n",
            "Epoch 279/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.5158 - acc: 0.7526 - val_loss: 0.6806 - val_acc: 0.6458\n",
            "Epoch 280/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5012 - acc: 0.7629 - val_loss: 0.6844 - val_acc: 0.6250\n",
            "Epoch 281/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.4781 - acc: 0.7784 - val_loss: 0.6508 - val_acc: 0.6667\n",
            "Epoch 282/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.4952 - acc: 0.7612 - val_loss: 0.6693 - val_acc: 0.6562\n",
            "Epoch 283/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.4792 - acc: 0.7646 - val_loss: 0.6781 - val_acc: 0.6458\n",
            "Epoch 284/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5165 - acc: 0.7440 - val_loss: 0.6691 - val_acc: 0.6458\n",
            "Epoch 285/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.4892 - acc: 0.7560 - val_loss: 0.6716 - val_acc: 0.6458\n",
            "Epoch 286/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5145 - acc: 0.7457 - val_loss: 0.6515 - val_acc: 0.6667\n",
            "Epoch 287/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.5110 - acc: 0.7251 - val_loss: 0.6754 - val_acc: 0.6354\n",
            "Epoch 288/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.5377 - acc: 0.7543 - val_loss: 0.6603 - val_acc: 0.6458\n",
            "Epoch 289/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.4947 - acc: 0.7526 - val_loss: 0.6584 - val_acc: 0.6458\n",
            "Epoch 290/1000\n",
            "37/37 [==============================] - 3s 83ms/step - loss: 0.4864 - acc: 0.7680 - val_loss: 0.6649 - val_acc: 0.6458\n",
            "Epoch 291/1000\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.4899 - acc: 0.7577 - val_loss: 0.6718 - val_acc: 0.6354\n",
            "Epoch 292/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.4832 - acc: 0.7483 - val_loss: 0.6459 - val_acc: 0.6562\n",
            "Epoch 293/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5025 - acc: 0.7646 - val_loss: 0.6715 - val_acc: 0.6354\n",
            "Epoch 294/1000\n",
            "37/37 [==============================] - 3s 84ms/step - loss: 0.5139 - acc: 0.7509 - val_loss: 0.6748 - val_acc: 0.6354\n",
            "Epoch 295/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.5389 - acc: 0.7234 - val_loss: 0.6448 - val_acc: 0.6667\n",
            "Epoch 296/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.4910 - acc: 0.7663 - val_loss: 0.6697 - val_acc: 0.6354\n",
            "Epoch 297/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.5110 - acc: 0.7302 - val_loss: 0.6724 - val_acc: 0.6354\n",
            "Epoch 298/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.4979 - acc: 0.7577 - val_loss: 0.6599 - val_acc: 0.6458\n",
            "Epoch 299/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5008 - acc: 0.7509 - val_loss: 0.6613 - val_acc: 0.6562\n",
            "Epoch 300/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5387 - acc: 0.7268 - val_loss: 0.6733 - val_acc: 0.6354\n",
            "Epoch 301/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.5345 - acc: 0.7096 - val_loss: 0.6600 - val_acc: 0.6458\n",
            "Epoch 302/1000\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.5179 - acc: 0.7251 - val_loss: 0.6644 - val_acc: 0.6458\n",
            "Epoch 303/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.4530 - acc: 0.7869 - val_loss: 0.6595 - val_acc: 0.6458\n",
            "Epoch 304/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5130 - acc: 0.7337 - val_loss: 0.6645 - val_acc: 0.6458\n",
            "Epoch 305/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.5290 - acc: 0.7371 - val_loss: 0.6666 - val_acc: 0.6354\n",
            "Epoch 306/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.4943 - acc: 0.7629 - val_loss: 0.6751 - val_acc: 0.6354\n",
            "Epoch 307/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.4721 - acc: 0.7818 - val_loss: 0.6807 - val_acc: 0.6354\n",
            "Epoch 308/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.4916 - acc: 0.7629 - val_loss: 0.6708 - val_acc: 0.6458\n",
            "Epoch 309/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.5217 - acc: 0.7199 - val_loss: 0.6944 - val_acc: 0.6354\n",
            "Epoch 310/1000\n",
            "37/37 [==============================] - 4s 81ms/step - loss: 0.5017 - acc: 0.7612 - val_loss: 0.6681 - val_acc: 0.6458\n",
            "Epoch 311/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5012 - acc: 0.7474 - val_loss: 0.6682 - val_acc: 0.6562\n",
            "Epoch 312/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5123 - acc: 0.7405 - val_loss: 0.6661 - val_acc: 0.6562\n",
            "Epoch 313/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5179 - acc: 0.7646 - val_loss: 0.6784 - val_acc: 0.6562\n",
            "Epoch 314/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5174 - acc: 0.7285 - val_loss: 0.6641 - val_acc: 0.6667\n",
            "Epoch 315/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5016 - acc: 0.7595 - val_loss: 0.6681 - val_acc: 0.6354\n",
            "Epoch 316/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.4981 - acc: 0.7618 - val_loss: 0.6643 - val_acc: 0.6458\n",
            "Epoch 317/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.5041 - acc: 0.7457 - val_loss: 0.6631 - val_acc: 0.6667\n",
            "Epoch 318/1000\n",
            "37/37 [==============================] - 9s 219ms/step - loss: 0.5090 - acc: 0.7285 - val_loss: 0.6697 - val_acc: 0.6562\n",
            "Epoch 319/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5176 - acc: 0.7629 - val_loss: 0.6757 - val_acc: 0.6250\n",
            "Epoch 320/1000\n",
            "37/37 [==============================] - 4s 78ms/step - loss: 0.4752 - acc: 0.7835 - val_loss: 0.6724 - val_acc: 0.6354\n",
            "Epoch 321/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5179 - acc: 0.7526 - val_loss: 0.6436 - val_acc: 0.6562\n",
            "Epoch 322/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5060 - acc: 0.7491 - val_loss: 0.6515 - val_acc: 0.6562\n",
            "Epoch 323/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5092 - acc: 0.7440 - val_loss: 0.6580 - val_acc: 0.6458\n",
            "Epoch 324/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5020 - acc: 0.7423 - val_loss: 0.6624 - val_acc: 0.6354\n",
            "Epoch 325/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.5073 - acc: 0.7337 - val_loss: 0.6666 - val_acc: 0.6354\n",
            "Epoch 326/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.4861 - acc: 0.7560 - val_loss: 0.6721 - val_acc: 0.6354\n",
            "Epoch 327/1000\n",
            "37/37 [==============================] - 4s 82ms/step - loss: 0.5367 - acc: 0.7491 - val_loss: 0.6644 - val_acc: 0.6354\n",
            "Epoch 328/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.4941 - acc: 0.7560 - val_loss: 0.6415 - val_acc: 0.6667\n",
            "Epoch 329/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.4966 - acc: 0.7543 - val_loss: 0.6501 - val_acc: 0.6667\n",
            "Epoch 330/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5234 - acc: 0.7234 - val_loss: 0.6689 - val_acc: 0.6771\n",
            "Epoch 331/1000\n",
            "37/37 [==============================] - 4s 109ms/step - loss: 0.4908 - acc: 0.7423 - val_loss: 0.6574 - val_acc: 0.6667\n",
            "Epoch 332/1000\n",
            "37/37 [==============================] - 3s 83ms/step - loss: 0.5085 - acc: 0.7474 - val_loss: 0.6598 - val_acc: 0.6667\n",
            "Epoch 333/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5148 - acc: 0.7371 - val_loss: 0.6728 - val_acc: 0.6458\n",
            "Epoch 334/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5331 - acc: 0.7440 - val_loss: 0.6681 - val_acc: 0.6354\n",
            "Epoch 335/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5052 - acc: 0.7509 - val_loss: 0.6522 - val_acc: 0.6562\n",
            "Epoch 336/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.4921 - acc: 0.7509 - val_loss: 0.6542 - val_acc: 0.6562\n",
            "Epoch 337/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5019 - acc: 0.7474 - val_loss: 0.6669 - val_acc: 0.6354\n",
            "Epoch 338/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.5039 - acc: 0.7440 - val_loss: 0.6574 - val_acc: 0.6354\n",
            "Epoch 339/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.4998 - acc: 0.7491 - val_loss: 0.6820 - val_acc: 0.6250\n",
            "Epoch 340/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5117 - acc: 0.7526 - val_loss: 0.6557 - val_acc: 0.6562\n",
            "Epoch 341/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5167 - acc: 0.7337 - val_loss: 0.6638 - val_acc: 0.6458\n",
            "Epoch 342/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.4959 - acc: 0.7543 - val_loss: 0.6642 - val_acc: 0.6354\n",
            "Epoch 343/1000\n",
            "37/37 [==============================] - 9s 218ms/step - loss: 0.5041 - acc: 0.7568 - val_loss: 0.6548 - val_acc: 0.6562\n",
            "Epoch 344/1000\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.5345 - acc: 0.7466 - val_loss: 0.6589 - val_acc: 0.6354\n",
            "Epoch 345/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.5384 - acc: 0.7216 - val_loss: 0.6794 - val_acc: 0.6250\n",
            "Epoch 346/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5070 - acc: 0.7595 - val_loss: 0.6748 - val_acc: 0.6354\n",
            "Epoch 347/1000\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.5153 - acc: 0.7423 - val_loss: 0.6783 - val_acc: 0.6250\n",
            "Epoch 348/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5120 - acc: 0.7526 - val_loss: 0.6738 - val_acc: 0.6562\n",
            "Epoch 349/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5309 - acc: 0.7302 - val_loss: 0.6700 - val_acc: 0.6771\n",
            "Epoch 350/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.4851 - acc: 0.7698 - val_loss: 0.6654 - val_acc: 0.6562\n",
            "Epoch 351/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5002 - acc: 0.7423 - val_loss: 0.6673 - val_acc: 0.6458\n",
            "Epoch 352/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5382 - acc: 0.7337 - val_loss: 0.6670 - val_acc: 0.6667\n",
            "Epoch 353/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.4929 - acc: 0.7680 - val_loss: 0.6854 - val_acc: 0.6250\n",
            "Epoch 354/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.4853 - acc: 0.7766 - val_loss: 0.6849 - val_acc: 0.6354\n",
            "Epoch 355/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5315 - acc: 0.7234 - val_loss: 0.6702 - val_acc: 0.6562\n",
            "Epoch 356/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5438 - acc: 0.7131 - val_loss: 0.6696 - val_acc: 0.6562\n",
            "Epoch 357/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5117 - acc: 0.7474 - val_loss: 0.6712 - val_acc: 0.6562\n",
            "Epoch 358/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5052 - acc: 0.7560 - val_loss: 0.6620 - val_acc: 0.6458\n",
            "Epoch 359/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.4832 - acc: 0.7749 - val_loss: 0.6617 - val_acc: 0.6458\n",
            "Epoch 360/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5263 - acc: 0.7405 - val_loss: 0.6580 - val_acc: 0.6562\n",
            "Epoch 361/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5136 - acc: 0.7577 - val_loss: 0.6905 - val_acc: 0.6354\n",
            "Epoch 362/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.5035 - acc: 0.7483 - val_loss: 0.6787 - val_acc: 0.6458\n",
            "Epoch 363/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5118 - acc: 0.7423 - val_loss: 0.6703 - val_acc: 0.6458\n",
            "Epoch 364/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5185 - acc: 0.7509 - val_loss: 0.6557 - val_acc: 0.6562\n",
            "Epoch 365/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5210 - acc: 0.7354 - val_loss: 0.6534 - val_acc: 0.6562\n",
            "Epoch 366/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5446 - acc: 0.7268 - val_loss: 0.6686 - val_acc: 0.6458\n",
            "Epoch 367/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5198 - acc: 0.7491 - val_loss: 0.6753 - val_acc: 0.6354\n",
            "Epoch 368/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.4648 - acc: 0.7749 - val_loss: 0.6434 - val_acc: 0.6667\n",
            "Epoch 369/1000\n",
            "37/37 [==============================] - 10s 243ms/step - loss: 0.4979 - acc: 0.7474 - val_loss: 0.6753 - val_acc: 0.6354\n",
            "Epoch 370/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5238 - acc: 0.7371 - val_loss: 0.6635 - val_acc: 0.6458\n",
            "Epoch 371/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.5311 - acc: 0.7302 - val_loss: 0.6715 - val_acc: 0.6562\n",
            "Epoch 372/1000\n",
            "37/37 [==============================] - 4s 80ms/step - loss: 0.4899 - acc: 0.7577 - val_loss: 0.6701 - val_acc: 0.6458\n",
            "Epoch 373/1000\n",
            "37/37 [==============================] - 5s 108ms/step - loss: 0.5403 - acc: 0.7337 - val_loss: 0.6561 - val_acc: 0.6667\n",
            "Epoch 374/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5546 - acc: 0.7285 - val_loss: 0.6667 - val_acc: 0.6458\n",
            "Epoch 375/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5016 - acc: 0.7766 - val_loss: 0.6777 - val_acc: 0.6458\n",
            "Epoch 376/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5088 - acc: 0.7526 - val_loss: 0.6613 - val_acc: 0.6562\n",
            "Epoch 377/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.5231 - acc: 0.7371 - val_loss: 0.6628 - val_acc: 0.6562\n",
            "Epoch 378/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5408 - acc: 0.7337 - val_loss: 0.6743 - val_acc: 0.6354\n",
            "Epoch 379/1000\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.4773 - acc: 0.7680 - val_loss: 0.6605 - val_acc: 0.6562\n",
            "Epoch 380/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5154 - acc: 0.7509 - val_loss: 0.6615 - val_acc: 0.6667\n",
            "Epoch 381/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5316 - acc: 0.7388 - val_loss: 0.6788 - val_acc: 0.6354\n",
            "Epoch 382/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.5476 - acc: 0.7320 - val_loss: 0.6618 - val_acc: 0.6458\n",
            "Epoch 383/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.4735 - acc: 0.7629 - val_loss: 0.6719 - val_acc: 0.6354\n",
            "Epoch 384/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.4940 - acc: 0.7543 - val_loss: 0.6701 - val_acc: 0.6354\n",
            "Epoch 385/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5292 - acc: 0.7371 - val_loss: 0.6646 - val_acc: 0.6458\n",
            "Epoch 386/1000\n",
            "37/37 [==============================] - 3s 85ms/step - loss: 0.5224 - acc: 0.7457 - val_loss: 0.6602 - val_acc: 0.6562\n",
            "Epoch 387/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.5234 - acc: 0.7285 - val_loss: 0.6800 - val_acc: 0.6354\n",
            "Epoch 388/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.5029 - acc: 0.7285 - val_loss: 0.6607 - val_acc: 0.6562\n",
            "Epoch 389/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.4778 - acc: 0.7698 - val_loss: 0.6718 - val_acc: 0.6354\n",
            "Epoch 390/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5284 - acc: 0.7199 - val_loss: 0.6725 - val_acc: 0.6354\n",
            "Epoch 391/1000\n",
            "37/37 [==============================] - 9s 215ms/step - loss: 0.5419 - acc: 0.7285 - val_loss: 0.6833 - val_acc: 0.6250\n",
            "Epoch 392/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.4690 - acc: 0.7801 - val_loss: 0.6701 - val_acc: 0.6354\n",
            "Epoch 393/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.5192 - acc: 0.7457 - val_loss: 0.6404 - val_acc: 0.6562\n",
            "Epoch 394/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.5072 - acc: 0.7663 - val_loss: 0.6741 - val_acc: 0.6354\n",
            "Epoch 395/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.5126 - acc: 0.7509 - val_loss: 0.6743 - val_acc: 0.6354\n",
            "Epoch 396/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.4912 - acc: 0.7749 - val_loss: 0.6604 - val_acc: 0.6458\n",
            "Epoch 397/1000\n",
            "37/37 [==============================] - 4s 79ms/step - loss: 0.5011 - acc: 0.7577 - val_loss: 0.6603 - val_acc: 0.6458\n",
            "Epoch 398/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.5234 - acc: 0.7560 - val_loss: 0.6523 - val_acc: 0.6771\n",
            "Epoch 399/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5156 - acc: 0.7491 - val_loss: 0.6931 - val_acc: 0.6458\n",
            "Epoch 400/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5021 - acc: 0.7646 - val_loss: 0.6766 - val_acc: 0.6458\n",
            "Epoch 401/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5173 - acc: 0.7405 - val_loss: 0.6576 - val_acc: 0.6458\n",
            "Epoch 402/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.5008 - acc: 0.7680 - val_loss: 0.6770 - val_acc: 0.6354\n",
            "Epoch 403/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.5262 - acc: 0.7131 - val_loss: 0.6704 - val_acc: 0.6354\n",
            "Epoch 404/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.5012 - acc: 0.7331 - val_loss: 0.6829 - val_acc: 0.6458\n",
            "Epoch 405/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5143 - acc: 0.7216 - val_loss: 0.6796 - val_acc: 0.6354\n",
            "Epoch 406/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.5441 - acc: 0.7302 - val_loss: 0.6778 - val_acc: 0.6354\n",
            "Epoch 407/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.5041 - acc: 0.7268 - val_loss: 0.6873 - val_acc: 0.6250\n",
            "Epoch 408/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.5469 - acc: 0.7285 - val_loss: 0.6729 - val_acc: 0.6354\n",
            "Epoch 409/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.4875 - acc: 0.7560 - val_loss: 0.6842 - val_acc: 0.6250\n",
            "Epoch 410/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.5023 - acc: 0.7491 - val_loss: 0.6926 - val_acc: 0.6250\n",
            "Epoch 411/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.4852 - acc: 0.7732 - val_loss: 0.6874 - val_acc: 0.6354\n",
            "Epoch 412/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5056 - acc: 0.7577 - val_loss: 0.6711 - val_acc: 0.6458\n",
            "Epoch 413/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.5073 - acc: 0.7543 - val_loss: 0.6904 - val_acc: 0.6458\n",
            "Epoch 414/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5155 - acc: 0.7440 - val_loss: 0.6798 - val_acc: 0.6354\n",
            "Epoch 415/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5001 - acc: 0.7423 - val_loss: 0.6751 - val_acc: 0.6354\n",
            "Epoch 416/1000\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.5027 - acc: 0.7526 - val_loss: 0.6684 - val_acc: 0.6458\n",
            "Epoch 417/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.4899 - acc: 0.7560 - val_loss: 0.6819 - val_acc: 0.6354\n",
            "Epoch 418/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.5109 - acc: 0.7388 - val_loss: 0.6716 - val_acc: 0.6354\n",
            "Epoch 419/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.5013 - acc: 0.7405 - val_loss: 0.6880 - val_acc: 0.6354\n",
            "Epoch 420/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.5076 - acc: 0.7577 - val_loss: 0.6796 - val_acc: 0.6354\n",
            "Epoch 421/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5006 - acc: 0.7440 - val_loss: 0.6667 - val_acc: 0.6354\n",
            "Epoch 422/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.5115 - acc: 0.7543 - val_loss: 0.6707 - val_acc: 0.6354\n",
            "Epoch 423/1000\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 0.4970 - acc: 0.7663 - val_loss: 0.6668 - val_acc: 0.6458\n",
            "Epoch 424/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.5215 - acc: 0.7302 - val_loss: 0.6596 - val_acc: 0.6562\n",
            "Epoch 425/1000\n",
            "37/37 [==============================] - 3s 83ms/step - loss: 0.5368 - acc: 0.7302 - val_loss: 0.6637 - val_acc: 0.6562\n",
            "Epoch 426/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.4893 - acc: 0.7629 - val_loss: 0.6810 - val_acc: 0.6042\n",
            "Epoch 427/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.5356 - acc: 0.7268 - val_loss: 0.6795 - val_acc: 0.6458\n",
            "Epoch 428/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.5070 - acc: 0.7509 - val_loss: 0.6646 - val_acc: 0.6458\n",
            "Epoch 429/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.5053 - acc: 0.7440 - val_loss: 0.6706 - val_acc: 0.6354\n",
            "Epoch 430/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5064 - acc: 0.7491 - val_loss: 0.6494 - val_acc: 0.6562\n",
            "Epoch 431/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5336 - acc: 0.7388 - val_loss: 0.6565 - val_acc: 0.6562\n",
            "Epoch 432/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.5245 - acc: 0.7423 - val_loss: 0.6592 - val_acc: 0.6458\n",
            "Epoch 433/1000\n",
            "37/37 [==============================] - 4s 82ms/step - loss: 0.5104 - acc: 0.7457 - val_loss: 0.6690 - val_acc: 0.6354\n",
            "Epoch 434/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.5018 - acc: 0.7577 - val_loss: 0.6772 - val_acc: 0.6354\n",
            "Epoch 435/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.4916 - acc: 0.7852 - val_loss: 0.6546 - val_acc: 0.6562\n",
            "Epoch 436/1000\n",
            "37/37 [==============================] - 9s 218ms/step - loss: 0.5358 - acc: 0.7234 - val_loss: 0.6660 - val_acc: 0.6458\n",
            "Epoch 437/1000\n",
            "37/37 [==============================] - 3s 84ms/step - loss: 0.5264 - acc: 0.7354 - val_loss: 0.6745 - val_acc: 0.6354\n",
            "Epoch 438/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5564 - acc: 0.7251 - val_loss: 0.6708 - val_acc: 0.6354\n",
            "Epoch 439/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.5063 - acc: 0.7474 - val_loss: 0.6732 - val_acc: 0.6458\n",
            "Epoch 440/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.5477 - acc: 0.7302 - val_loss: 0.6799 - val_acc: 0.6354\n",
            "Epoch 441/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.5264 - acc: 0.7131 - val_loss: 0.6633 - val_acc: 0.6458\n",
            "Epoch 442/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5268 - acc: 0.7491 - val_loss: 0.6647 - val_acc: 0.6250\n",
            "Epoch 443/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5116 - acc: 0.7354 - val_loss: 0.6605 - val_acc: 0.6458\n",
            "Epoch 444/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5193 - acc: 0.7423 - val_loss: 0.6833 - val_acc: 0.6354\n",
            "Epoch 445/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5171 - acc: 0.7457 - val_loss: 0.6710 - val_acc: 0.6458\n",
            "Epoch 446/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.4774 - acc: 0.7749 - val_loss: 0.6693 - val_acc: 0.6354\n",
            "Epoch 447/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5510 - acc: 0.7234 - val_loss: 0.6693 - val_acc: 0.6458\n",
            "Epoch 448/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5146 - acc: 0.7337 - val_loss: 0.6760 - val_acc: 0.6250\n",
            "Epoch 449/1000\n",
            "37/37 [==============================] - 9s 239ms/step - loss: 0.4759 - acc: 0.7577 - val_loss: 0.6830 - val_acc: 0.6250\n",
            "Epoch 450/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.5088 - acc: 0.7577 - val_loss: 0.6876 - val_acc: 0.6458\n",
            "Epoch 451/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.5152 - acc: 0.7388 - val_loss: 0.6820 - val_acc: 0.6354\n",
            "Epoch 452/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.5206 - acc: 0.7568 - val_loss: 0.6782 - val_acc: 0.6354\n",
            "Epoch 453/1000\n",
            "37/37 [==============================] - 5s 104ms/step - loss: 0.4991 - acc: 0.7509 - val_loss: 0.6699 - val_acc: 0.6458\n",
            "Epoch 454/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5043 - acc: 0.7491 - val_loss: 0.6794 - val_acc: 0.6250\n",
            "Epoch 455/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.5139 - acc: 0.7474 - val_loss: 0.6761 - val_acc: 0.6458\n",
            "Epoch 456/1000\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.5205 - acc: 0.7526 - val_loss: 0.6889 - val_acc: 0.6250\n",
            "Epoch 457/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5113 - acc: 0.7457 - val_loss: 0.6466 - val_acc: 0.6562\n",
            "Epoch 458/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.4848 - acc: 0.7595 - val_loss: 0.6811 - val_acc: 0.6250\n",
            "Epoch 459/1000\n",
            "37/37 [==============================] - 9s 218ms/step - loss: 0.4984 - acc: 0.7543 - val_loss: 0.6596 - val_acc: 0.6458\n",
            "Epoch 460/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.4772 - acc: 0.7835 - val_loss: 0.6746 - val_acc: 0.6458\n",
            "Epoch 461/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5004 - acc: 0.7595 - val_loss: 0.6777 - val_acc: 0.6354\n",
            "Epoch 462/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.4799 - acc: 0.7440 - val_loss: 0.6710 - val_acc: 0.6458\n",
            "Epoch 463/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.5295 - acc: 0.7320 - val_loss: 0.6594 - val_acc: 0.6667\n",
            "Epoch 464/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.4934 - acc: 0.7577 - val_loss: 0.6684 - val_acc: 0.6458\n",
            "Epoch 465/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5281 - acc: 0.7474 - val_loss: 0.6802 - val_acc: 0.6250\n",
            "Epoch 466/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5071 - acc: 0.7560 - val_loss: 0.6619 - val_acc: 0.6562\n",
            "Epoch 467/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5336 - acc: 0.7285 - val_loss: 0.6797 - val_acc: 0.6354\n",
            "Epoch 468/1000\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.5204 - acc: 0.7474 - val_loss: 0.6900 - val_acc: 0.6250\n",
            "Epoch 469/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.5018 - acc: 0.7491 - val_loss: 0.6570 - val_acc: 0.6354\n",
            "Epoch 470/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.4927 - acc: 0.7474 - val_loss: 0.6663 - val_acc: 0.6562\n",
            "Epoch 471/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5098 - acc: 0.7491 - val_loss: 0.6766 - val_acc: 0.6354\n",
            "Epoch 472/1000\n",
            "37/37 [==============================] - 9s 216ms/step - loss: 0.5006 - acc: 0.7577 - val_loss: 0.6700 - val_acc: 0.6562\n",
            "Epoch 473/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5264 - acc: 0.7577 - val_loss: 0.6811 - val_acc: 0.6354\n",
            "Epoch 474/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.4794 - acc: 0.7635 - val_loss: 0.6755 - val_acc: 0.6458\n",
            "Epoch 475/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5083 - acc: 0.7543 - val_loss: 0.6694 - val_acc: 0.6562\n",
            "Epoch 476/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.4772 - acc: 0.7835 - val_loss: 0.6625 - val_acc: 0.6562\n",
            "Epoch 477/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.4868 - acc: 0.7629 - val_loss: 0.6592 - val_acc: 0.6458\n",
            "Epoch 478/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.5303 - acc: 0.7268 - val_loss: 0.6630 - val_acc: 0.6458\n",
            "Epoch 479/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.4933 - acc: 0.7457 - val_loss: 0.6692 - val_acc: 0.6458\n",
            "Epoch 480/1000\n",
            "37/37 [==============================] - 8s 226ms/step - loss: 0.5259 - acc: 0.7405 - val_loss: 0.6584 - val_acc: 0.6562\n",
            "Epoch 481/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5092 - acc: 0.7509 - val_loss: 0.6608 - val_acc: 0.6458\n",
            "Epoch 482/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5144 - acc: 0.7491 - val_loss: 0.6707 - val_acc: 0.6458\n",
            "Epoch 483/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.5164 - acc: 0.7423 - val_loss: 0.6917 - val_acc: 0.6250\n",
            "Epoch 484/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.5155 - acc: 0.7577 - val_loss: 0.6734 - val_acc: 0.6354\n",
            "Epoch 485/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.5172 - acc: 0.7388 - val_loss: 0.6725 - val_acc: 0.6354\n",
            "Epoch 486/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.5002 - acc: 0.7457 - val_loss: 0.6626 - val_acc: 0.6562\n",
            "Epoch 487/1000\n",
            "37/37 [==============================] - 5s 107ms/step - loss: 0.5328 - acc: 0.7285 - val_loss: 0.6681 - val_acc: 0.6354\n",
            "Epoch 488/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5443 - acc: 0.7131 - val_loss: 0.6641 - val_acc: 0.6354\n",
            "Epoch 489/1000\n",
            "37/37 [==============================] - 4s 110ms/step - loss: 0.4806 - acc: 0.7715 - val_loss: 0.6804 - val_acc: 0.6354\n",
            "Epoch 490/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.5051 - acc: 0.7509 - val_loss: 0.6491 - val_acc: 0.6667\n",
            "Epoch 491/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.4938 - acc: 0.7509 - val_loss: 0.6645 - val_acc: 0.6458\n",
            "Epoch 492/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5062 - acc: 0.7526 - val_loss: 0.6481 - val_acc: 0.6562\n",
            "Epoch 493/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.4820 - acc: 0.7612 - val_loss: 0.6748 - val_acc: 0.6250\n",
            "Epoch 494/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5027 - acc: 0.7595 - val_loss: 0.6725 - val_acc: 0.6146\n",
            "Epoch 495/1000\n",
            "37/37 [==============================] - 5s 109ms/step - loss: 0.5368 - acc: 0.7354 - val_loss: 0.6561 - val_acc: 0.6250\n",
            "Epoch 496/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5337 - acc: 0.7182 - val_loss: 0.6744 - val_acc: 0.6354\n",
            "Epoch 497/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.5052 - acc: 0.7517 - val_loss: 0.6674 - val_acc: 0.6458\n",
            "Epoch 498/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.5357 - acc: 0.7165 - val_loss: 0.6563 - val_acc: 0.6458\n",
            "Epoch 499/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5376 - acc: 0.7199 - val_loss: 0.6622 - val_acc: 0.6667\n",
            "Epoch 500/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5162 - acc: 0.7354 - val_loss: 0.6550 - val_acc: 0.6458\n",
            "Epoch 501/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.4841 - acc: 0.7801 - val_loss: 0.6637 - val_acc: 0.6354\n",
            "Epoch 502/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5054 - acc: 0.7543 - val_loss: 0.6467 - val_acc: 0.6458\n",
            "Epoch 503/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5056 - acc: 0.7491 - val_loss: 0.6701 - val_acc: 0.6146\n",
            "Epoch 504/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.4997 - acc: 0.7543 - val_loss: 0.6465 - val_acc: 0.6354\n",
            "Epoch 505/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5326 - acc: 0.7234 - val_loss: 0.6728 - val_acc: 0.6146\n",
            "Epoch 506/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.4811 - acc: 0.7612 - val_loss: 0.6573 - val_acc: 0.6562\n",
            "Epoch 507/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.5090 - acc: 0.7595 - val_loss: 0.6609 - val_acc: 0.6354\n",
            "Epoch 508/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5354 - acc: 0.7182 - val_loss: 0.6537 - val_acc: 0.6458\n",
            "Epoch 509/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.4942 - acc: 0.7423 - val_loss: 0.6581 - val_acc: 0.6042\n",
            "Epoch 510/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5504 - acc: 0.7320 - val_loss: 0.6597 - val_acc: 0.6458\n",
            "Epoch 511/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5211 - acc: 0.7337 - val_loss: 0.6715 - val_acc: 0.6354\n",
            "Epoch 512/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5251 - acc: 0.7474 - val_loss: 0.6689 - val_acc: 0.6458\n",
            "Epoch 513/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5315 - acc: 0.7526 - val_loss: 0.6789 - val_acc: 0.6354\n",
            "Epoch 514/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.5032 - acc: 0.7715 - val_loss: 0.6452 - val_acc: 0.6562\n",
            "Epoch 515/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5254 - acc: 0.7302 - val_loss: 0.6593 - val_acc: 0.6562\n",
            "Epoch 516/1000\n",
            "37/37 [==============================] - 4s 79ms/step - loss: 0.5297 - acc: 0.7371 - val_loss: 0.6671 - val_acc: 0.6354\n",
            "Epoch 517/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5170 - acc: 0.7440 - val_loss: 0.6752 - val_acc: 0.6250\n",
            "Epoch 518/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.4725 - acc: 0.7680 - val_loss: 0.6636 - val_acc: 0.6458\n",
            "Epoch 519/1000\n",
            "37/37 [==============================] - 9s 220ms/step - loss: 0.5055 - acc: 0.7509 - val_loss: 0.6581 - val_acc: 0.6458\n",
            "Epoch 520/1000\n",
            "37/37 [==============================] - 8s 224ms/step - loss: 0.4966 - acc: 0.7474 - val_loss: 0.6684 - val_acc: 0.6458\n",
            "Epoch 521/1000\n",
            "37/37 [==============================] - 10s 249ms/step - loss: 0.5144 - acc: 0.7474 - val_loss: 0.6649 - val_acc: 0.6458\n",
            "Epoch 522/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.5197 - acc: 0.7251 - val_loss: 0.6756 - val_acc: 0.6250\n",
            "Epoch 523/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5182 - acc: 0.7268 - val_loss: 0.6577 - val_acc: 0.6354\n",
            "Epoch 524/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5316 - acc: 0.7285 - val_loss: 0.6658 - val_acc: 0.6458\n",
            "Epoch 525/1000\n",
            "37/37 [==============================] - 5s 108ms/step - loss: 0.4893 - acc: 0.7766 - val_loss: 0.6729 - val_acc: 0.6354\n",
            "Epoch 526/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5293 - acc: 0.7423 - val_loss: 0.6591 - val_acc: 0.6562\n",
            "Epoch 527/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.4937 - acc: 0.7663 - val_loss: 0.6618 - val_acc: 0.6250\n",
            "Epoch 528/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.5029 - acc: 0.7577 - val_loss: 0.6565 - val_acc: 0.6458\n",
            "Epoch 529/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.4855 - acc: 0.7646 - val_loss: 0.6617 - val_acc: 0.6354\n",
            "Epoch 530/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.5057 - acc: 0.7405 - val_loss: 0.6534 - val_acc: 0.6458\n",
            "Epoch 531/1000\n",
            "37/37 [==============================] - 9s 215ms/step - loss: 0.4879 - acc: 0.7509 - val_loss: 0.6546 - val_acc: 0.6354\n",
            "Epoch 532/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5092 - acc: 0.7251 - val_loss: 0.6279 - val_acc: 0.6771\n",
            "Epoch 533/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.4643 - acc: 0.7955 - val_loss: 0.6522 - val_acc: 0.6562\n",
            "Epoch 534/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.5417 - acc: 0.6993 - val_loss: 0.6518 - val_acc: 0.6458\n",
            "Epoch 535/1000\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 0.5119 - acc: 0.7423 - val_loss: 0.6493 - val_acc: 0.6458\n",
            "Epoch 536/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.5145 - acc: 0.7371 - val_loss: 0.6646 - val_acc: 0.6250\n",
            "Epoch 537/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5337 - acc: 0.7268 - val_loss: 0.6765 - val_acc: 0.6458\n",
            "Epoch 538/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5201 - acc: 0.7474 - val_loss: 0.6527 - val_acc: 0.6354\n",
            "Epoch 539/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.4875 - acc: 0.7440 - val_loss: 0.6655 - val_acc: 0.6250\n",
            "Epoch 540/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.4923 - acc: 0.7629 - val_loss: 0.6539 - val_acc: 0.6458\n",
            "Epoch 541/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.5259 - acc: 0.7474 - val_loss: 0.6514 - val_acc: 0.6458\n",
            "Epoch 542/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.5270 - acc: 0.7543 - val_loss: 0.6470 - val_acc: 0.6562\n",
            "Epoch 543/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.5072 - acc: 0.7423 - val_loss: 0.6612 - val_acc: 0.6458\n",
            "Epoch 544/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.5341 - acc: 0.7474 - val_loss: 0.6514 - val_acc: 0.6562\n",
            "Epoch 545/1000\n",
            "37/37 [==============================] - 4s 81ms/step - loss: 0.5058 - acc: 0.7405 - val_loss: 0.6706 - val_acc: 0.6354\n",
            "Epoch 546/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5078 - acc: 0.7423 - val_loss: 0.6649 - val_acc: 0.6458\n",
            "Epoch 547/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5122 - acc: 0.7491 - val_loss: 0.6744 - val_acc: 0.6354\n",
            "Epoch 548/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5151 - acc: 0.7577 - val_loss: 0.6744 - val_acc: 0.6250\n",
            "Epoch 549/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5047 - acc: 0.7543 - val_loss: 0.6455 - val_acc: 0.6354\n",
            "Epoch 550/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.4772 - acc: 0.7663 - val_loss: 0.6563 - val_acc: 0.6458\n",
            "Epoch 551/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.4974 - acc: 0.7491 - val_loss: 0.6541 - val_acc: 0.6458\n",
            "Epoch 552/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5217 - acc: 0.7423 - val_loss: 0.6660 - val_acc: 0.6354\n",
            "Epoch 553/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5350 - acc: 0.7457 - val_loss: 0.6641 - val_acc: 0.6458\n",
            "Epoch 554/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5072 - acc: 0.7440 - val_loss: 0.6622 - val_acc: 0.6458\n",
            "Epoch 555/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5066 - acc: 0.7354 - val_loss: 0.6316 - val_acc: 0.6667\n",
            "Epoch 556/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5060 - acc: 0.7491 - val_loss: 0.6774 - val_acc: 0.6250\n",
            "Epoch 557/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5396 - acc: 0.7216 - val_loss: 0.6626 - val_acc: 0.6354\n",
            "Epoch 558/1000\n",
            "37/37 [==============================] - 5s 112ms/step - loss: 0.5317 - acc: 0.7199 - val_loss: 0.6614 - val_acc: 0.6250\n",
            "Epoch 559/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5177 - acc: 0.7388 - val_loss: 0.6617 - val_acc: 0.6354\n",
            "Epoch 560/1000\n",
            "37/37 [==============================] - 5s 116ms/step - loss: 0.4975 - acc: 0.7509 - val_loss: 0.6598 - val_acc: 0.6458\n",
            "Epoch 561/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.4966 - acc: 0.7509 - val_loss: 0.6728 - val_acc: 0.6250\n",
            "Epoch 562/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.4907 - acc: 0.7732 - val_loss: 0.6639 - val_acc: 0.6458\n",
            "Epoch 563/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.5215 - acc: 0.7423 - val_loss: 0.6527 - val_acc: 0.6458\n",
            "Epoch 564/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.4778 - acc: 0.7784 - val_loss: 0.6716 - val_acc: 0.6354\n",
            "Epoch 565/1000\n",
            "37/37 [==============================] - 5s 118ms/step - loss: 0.4794 - acc: 0.7663 - val_loss: 0.6817 - val_acc: 0.6458\n",
            "Epoch 566/1000\n",
            "37/37 [==============================] - 8s 223ms/step - loss: 0.5092 - acc: 0.7354 - val_loss: 0.6570 - val_acc: 0.6458\n",
            "Epoch 567/1000\n",
            "37/37 [==============================] - 5s 109ms/step - loss: 0.5312 - acc: 0.7234 - val_loss: 0.6590 - val_acc: 0.6354\n",
            "Epoch 568/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.5061 - acc: 0.7543 - val_loss: 0.6527 - val_acc: 0.6562\n",
            "Epoch 569/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.5092 - acc: 0.7491 - val_loss: 0.6641 - val_acc: 0.6354\n",
            "Epoch 570/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5159 - acc: 0.7509 - val_loss: 0.6548 - val_acc: 0.6667\n",
            "Epoch 571/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5141 - acc: 0.7423 - val_loss: 0.6691 - val_acc: 0.6458\n",
            "Epoch 572/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.5023 - acc: 0.7491 - val_loss: 0.6709 - val_acc: 0.6250\n",
            "Epoch 573/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5015 - acc: 0.7595 - val_loss: 0.6782 - val_acc: 0.6250\n",
            "Epoch 574/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.4846 - acc: 0.7612 - val_loss: 0.6477 - val_acc: 0.6667\n",
            "Epoch 575/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.4986 - acc: 0.7543 - val_loss: 0.6541 - val_acc: 0.6458\n",
            "Epoch 576/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5222 - acc: 0.7509 - val_loss: 0.6673 - val_acc: 0.6354\n",
            "Epoch 577/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.5199 - acc: 0.7268 - val_loss: 0.6619 - val_acc: 0.6562\n",
            "Epoch 578/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.5152 - acc: 0.7491 - val_loss: 0.6418 - val_acc: 0.6458\n",
            "Epoch 579/1000\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.5129 - acc: 0.7612 - val_loss: 0.6661 - val_acc: 0.6458\n",
            "Epoch 580/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.4954 - acc: 0.7766 - val_loss: 0.6637 - val_acc: 0.6354\n",
            "Epoch 581/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5123 - acc: 0.7405 - val_loss: 0.6643 - val_acc: 0.6354\n",
            "Epoch 582/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5034 - acc: 0.7749 - val_loss: 0.6739 - val_acc: 0.6354\n",
            "Epoch 583/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.5019 - acc: 0.7517 - val_loss: 0.6636 - val_acc: 0.6354\n",
            "Epoch 584/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.5158 - acc: 0.7348 - val_loss: 0.6735 - val_acc: 0.6250\n",
            "Epoch 585/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.4891 - acc: 0.7509 - val_loss: 0.6783 - val_acc: 0.6458\n",
            "Epoch 586/1000\n",
            "37/37 [==============================] - 6s 142ms/step - loss: 0.4930 - acc: 0.7543 - val_loss: 0.6674 - val_acc: 0.6562\n",
            "Epoch 587/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5398 - acc: 0.7474 - val_loss: 0.6673 - val_acc: 0.6667\n",
            "Epoch 588/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5264 - acc: 0.7302 - val_loss: 0.6834 - val_acc: 0.6458\n",
            "Epoch 589/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.4801 - acc: 0.7646 - val_loss: 0.6628 - val_acc: 0.6354\n",
            "Epoch 590/1000\n",
            "37/37 [==============================] - 4s 82ms/step - loss: 0.5167 - acc: 0.7268 - val_loss: 0.6732 - val_acc: 0.6354\n",
            "Epoch 591/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.5205 - acc: 0.7199 - val_loss: 0.6671 - val_acc: 0.6458\n",
            "Epoch 592/1000\n",
            "37/37 [==============================] - 5s 101ms/step - loss: 0.5215 - acc: 0.7165 - val_loss: 0.6802 - val_acc: 0.6458\n",
            "Epoch 593/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.4763 - acc: 0.7646 - val_loss: 0.6487 - val_acc: 0.6562\n",
            "Epoch 594/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.4663 - acc: 0.7784 - val_loss: 0.6711 - val_acc: 0.6354\n",
            "Epoch 595/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.4931 - acc: 0.7663 - val_loss: 0.6620 - val_acc: 0.6458\n",
            "Epoch 596/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5068 - acc: 0.7560 - val_loss: 0.6607 - val_acc: 0.6458\n",
            "Epoch 597/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.4834 - acc: 0.7440 - val_loss: 0.6682 - val_acc: 0.6458\n",
            "Epoch 598/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5207 - acc: 0.7216 - val_loss: 0.6646 - val_acc: 0.6458\n",
            "Epoch 599/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5078 - acc: 0.7526 - val_loss: 0.6645 - val_acc: 0.6458\n",
            "Epoch 600/1000\n",
            "37/37 [==============================] - 5s 117ms/step - loss: 0.4832 - acc: 0.7509 - val_loss: 0.6727 - val_acc: 0.6354\n",
            "Epoch 601/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.5108 - acc: 0.7680 - val_loss: 0.6759 - val_acc: 0.6250\n",
            "Epoch 602/1000\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.5083 - acc: 0.7526 - val_loss: 0.6531 - val_acc: 0.6562\n",
            "Epoch 603/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.5344 - acc: 0.7234 - val_loss: 0.6486 - val_acc: 0.6771\n",
            "Epoch 604/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.5287 - acc: 0.7474 - val_loss: 0.6733 - val_acc: 0.6354\n",
            "Epoch 605/1000\n",
            "37/37 [==============================] - 5s 109ms/step - loss: 0.5444 - acc: 0.7337 - val_loss: 0.6485 - val_acc: 0.6771\n",
            "Epoch 606/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5260 - acc: 0.7440 - val_loss: 0.6665 - val_acc: 0.6354\n",
            "Epoch 607/1000\n",
            "37/37 [==============================] - 6s 141ms/step - loss: 0.5288 - acc: 0.7405 - val_loss: 0.6742 - val_acc: 0.6354\n",
            "Epoch 608/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5094 - acc: 0.7302 - val_loss: 0.6665 - val_acc: 0.6458\n",
            "Epoch 609/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.4786 - acc: 0.7595 - val_loss: 0.6717 - val_acc: 0.6354\n",
            "Epoch 610/1000\n",
            "37/37 [==============================] - 3s 83ms/step - loss: 0.4951 - acc: 0.7526 - val_loss: 0.6642 - val_acc: 0.6458\n",
            "Epoch 611/1000\n",
            "37/37 [==============================] - 10s 242ms/step - loss: 0.4765 - acc: 0.7766 - val_loss: 0.6552 - val_acc: 0.6667\n",
            "Epoch 612/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.4935 - acc: 0.7526 - val_loss: 0.6563 - val_acc: 0.6562\n",
            "Epoch 613/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.5252 - acc: 0.7491 - val_loss: 0.6472 - val_acc: 0.6458\n",
            "Epoch 614/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.5181 - acc: 0.7388 - val_loss: 0.6504 - val_acc: 0.6458\n",
            "Epoch 615/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.5616 - acc: 0.7251 - val_loss: 0.6799 - val_acc: 0.6354\n",
            "Epoch 616/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5336 - acc: 0.7268 - val_loss: 0.6587 - val_acc: 0.6458\n",
            "Epoch 617/1000\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.5213 - acc: 0.7474 - val_loss: 0.6574 - val_acc: 0.6458\n",
            "Epoch 618/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5282 - acc: 0.7131 - val_loss: 0.6467 - val_acc: 0.6562\n",
            "Epoch 619/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.4759 - acc: 0.7612 - val_loss: 0.6573 - val_acc: 0.6458\n",
            "Epoch 620/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.5303 - acc: 0.7234 - val_loss: 0.6639 - val_acc: 0.6354\n",
            "Epoch 621/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5157 - acc: 0.7423 - val_loss: 0.6660 - val_acc: 0.6562\n",
            "Epoch 622/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5275 - acc: 0.7543 - val_loss: 0.6682 - val_acc: 0.6354\n",
            "Epoch 623/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5081 - acc: 0.7612 - val_loss: 0.6503 - val_acc: 0.6562\n",
            "Epoch 624/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5191 - acc: 0.7491 - val_loss: 0.6515 - val_acc: 0.6562\n",
            "Epoch 625/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.4828 - acc: 0.7577 - val_loss: 0.6705 - val_acc: 0.6354\n",
            "Epoch 626/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5614 - acc: 0.7079 - val_loss: 0.6479 - val_acc: 0.6458\n",
            "Epoch 627/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5282 - acc: 0.7320 - val_loss: 0.6280 - val_acc: 0.6771\n",
            "Epoch 628/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.4882 - acc: 0.7595 - val_loss: 0.6510 - val_acc: 0.6562\n",
            "Epoch 629/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5187 - acc: 0.7560 - val_loss: 0.6550 - val_acc: 0.6667\n",
            "Epoch 630/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.4782 - acc: 0.7835 - val_loss: 0.6485 - val_acc: 0.6562\n",
            "Epoch 631/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.4876 - acc: 0.7612 - val_loss: 0.6434 - val_acc: 0.6562\n",
            "Epoch 632/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.4974 - acc: 0.7509 - val_loss: 0.6556 - val_acc: 0.6354\n",
            "Epoch 633/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5175 - acc: 0.7280 - val_loss: 0.6474 - val_acc: 0.6354\n",
            "Epoch 634/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5253 - acc: 0.7354 - val_loss: 0.6584 - val_acc: 0.6354\n",
            "Epoch 635/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5220 - acc: 0.7371 - val_loss: 0.6623 - val_acc: 0.6354\n",
            "Epoch 636/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.4965 - acc: 0.7646 - val_loss: 0.6443 - val_acc: 0.6458\n",
            "Epoch 637/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.5011 - acc: 0.7595 - val_loss: 0.6625 - val_acc: 0.6250\n",
            "Epoch 638/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.4861 - acc: 0.7652 - val_loss: 0.6431 - val_acc: 0.6562\n",
            "Epoch 639/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.4928 - acc: 0.7543 - val_loss: 0.6504 - val_acc: 0.6354\n",
            "Epoch 640/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.5322 - acc: 0.7095 - val_loss: 0.6420 - val_acc: 0.6562\n",
            "Epoch 641/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.5130 - acc: 0.7698 - val_loss: 0.6775 - val_acc: 0.6458\n",
            "Epoch 642/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5059 - acc: 0.7491 - val_loss: 0.6466 - val_acc: 0.6562\n",
            "Epoch 643/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5039 - acc: 0.7354 - val_loss: 0.6462 - val_acc: 0.6562\n",
            "Epoch 644/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.4833 - acc: 0.7732 - val_loss: 0.6616 - val_acc: 0.6458\n",
            "Epoch 645/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.4646 - acc: 0.7784 - val_loss: 0.6497 - val_acc: 0.6458\n",
            "Epoch 646/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5074 - acc: 0.7320 - val_loss: 0.6697 - val_acc: 0.6458\n",
            "Epoch 647/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.4573 - acc: 0.7904 - val_loss: 0.6511 - val_acc: 0.6562\n",
            "Epoch 648/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.5034 - acc: 0.7663 - val_loss: 0.6486 - val_acc: 0.6562\n",
            "Epoch 649/1000\n",
            "37/37 [==============================] - 9s 244ms/step - loss: 0.5399 - acc: 0.7491 - val_loss: 0.6635 - val_acc: 0.6354\n",
            "Epoch 650/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5116 - acc: 0.7285 - val_loss: 0.6468 - val_acc: 0.6667\n",
            "Epoch 651/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.4807 - acc: 0.7680 - val_loss: 0.6681 - val_acc: 0.6354\n",
            "Epoch 652/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.5450 - acc: 0.7079 - val_loss: 0.6813 - val_acc: 0.6250\n",
            "Epoch 653/1000\n",
            "37/37 [==============================] - 4s 81ms/step - loss: 0.4957 - acc: 0.7577 - val_loss: 0.6751 - val_acc: 0.6250\n",
            "Epoch 654/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.5397 - acc: 0.7457 - val_loss: 0.6601 - val_acc: 0.6562\n",
            "Epoch 655/1000\n",
            "37/37 [==============================] - 10s 250ms/step - loss: 0.5189 - acc: 0.7371 - val_loss: 0.6644 - val_acc: 0.6562\n",
            "Epoch 656/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.5110 - acc: 0.7543 - val_loss: 0.6701 - val_acc: 0.6458\n",
            "Epoch 657/1000\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 0.5573 - acc: 0.6959 - val_loss: 0.6758 - val_acc: 0.6354\n",
            "Epoch 658/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.4975 - acc: 0.7715 - val_loss: 0.6823 - val_acc: 0.6354\n",
            "Epoch 659/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.4804 - acc: 0.7577 - val_loss: 0.6646 - val_acc: 0.6458\n",
            "Epoch 660/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5378 - acc: 0.7388 - val_loss: 0.6606 - val_acc: 0.6667\n",
            "Epoch 661/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.4904 - acc: 0.7921 - val_loss: 0.6395 - val_acc: 0.6667\n",
            "Epoch 662/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.5109 - acc: 0.7388 - val_loss: 0.6730 - val_acc: 0.6562\n",
            "Epoch 663/1000\n",
            "37/37 [==============================] - 9s 219ms/step - loss: 0.5102 - acc: 0.7285 - val_loss: 0.6775 - val_acc: 0.6250\n",
            "Epoch 664/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5433 - acc: 0.7268 - val_loss: 0.6504 - val_acc: 0.6667\n",
            "Epoch 665/1000\n",
            "37/37 [==============================] - 9s 218ms/step - loss: 0.5169 - acc: 0.7457 - val_loss: 0.6529 - val_acc: 0.6562\n",
            "Epoch 666/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.4856 - acc: 0.7560 - val_loss: 0.6769 - val_acc: 0.6667\n",
            "Epoch 667/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.5031 - acc: 0.7629 - val_loss: 0.6722 - val_acc: 0.6562\n",
            "Epoch 668/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5146 - acc: 0.7526 - val_loss: 0.6596 - val_acc: 0.6458\n",
            "Epoch 669/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.5064 - acc: 0.7509 - val_loss: 0.6758 - val_acc: 0.6458\n",
            "Epoch 670/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.5005 - acc: 0.7440 - val_loss: 0.6795 - val_acc: 0.6562\n",
            "Epoch 671/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.5005 - acc: 0.7371 - val_loss: 0.6524 - val_acc: 0.6562\n",
            "Epoch 672/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.5036 - acc: 0.7663 - val_loss: 0.6539 - val_acc: 0.6562\n",
            "Epoch 673/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.5065 - acc: 0.7302 - val_loss: 0.6753 - val_acc: 0.6250\n",
            "Epoch 674/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5128 - acc: 0.7543 - val_loss: 0.6676 - val_acc: 0.6354\n",
            "Epoch 675/1000\n",
            "37/37 [==============================] - 9s 216ms/step - loss: 0.5286 - acc: 0.7131 - val_loss: 0.6666 - val_acc: 0.6458\n",
            "Epoch 676/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5077 - acc: 0.7423 - val_loss: 0.6525 - val_acc: 0.6458\n",
            "Epoch 677/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5084 - acc: 0.7577 - val_loss: 0.6447 - val_acc: 0.6562\n",
            "Epoch 678/1000\n",
            "37/37 [==============================] - 9s 245ms/step - loss: 0.4949 - acc: 0.7457 - val_loss: 0.6644 - val_acc: 0.6354\n",
            "Epoch 679/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.5224 - acc: 0.7302 - val_loss: 0.6637 - val_acc: 0.6354\n",
            "Epoch 680/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.5187 - acc: 0.7474 - val_loss: 0.6531 - val_acc: 0.6354\n",
            "Epoch 681/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.4910 - acc: 0.7509 - val_loss: 0.6337 - val_acc: 0.6667\n",
            "Epoch 682/1000\n",
            "37/37 [==============================] - 5s 109ms/step - loss: 0.5096 - acc: 0.7423 - val_loss: 0.6639 - val_acc: 0.6354\n",
            "Epoch 683/1000\n",
            "37/37 [==============================] - 9s 218ms/step - loss: 0.4978 - acc: 0.7715 - val_loss: 0.6661 - val_acc: 0.6354\n",
            "Epoch 684/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.4927 - acc: 0.7354 - val_loss: 0.6558 - val_acc: 0.6562\n",
            "Epoch 685/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.5304 - acc: 0.7509 - val_loss: 0.6601 - val_acc: 0.6354\n",
            "Epoch 686/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.5072 - acc: 0.7388 - val_loss: 0.6509 - val_acc: 0.6562\n",
            "Epoch 687/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5193 - acc: 0.7320 - val_loss: 0.6628 - val_acc: 0.6667\n",
            "Epoch 688/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5493 - acc: 0.7320 - val_loss: 0.6604 - val_acc: 0.6562\n",
            "Epoch 689/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5430 - acc: 0.7182 - val_loss: 0.6633 - val_acc: 0.6562\n",
            "Epoch 690/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.4589 - acc: 0.7835 - val_loss: 0.6530 - val_acc: 0.6458\n",
            "Epoch 691/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.4994 - acc: 0.7680 - val_loss: 0.6738 - val_acc: 0.6250\n",
            "Epoch 692/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.4937 - acc: 0.7577 - val_loss: 0.6763 - val_acc: 0.6458\n",
            "Epoch 693/1000\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.5120 - acc: 0.7595 - val_loss: 0.6769 - val_acc: 0.6458\n",
            "Epoch 694/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.5146 - acc: 0.7526 - val_loss: 0.6561 - val_acc: 0.6458\n",
            "Epoch 695/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.5292 - acc: 0.7354 - val_loss: 0.6771 - val_acc: 0.6354\n",
            "Epoch 696/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.4791 - acc: 0.7629 - val_loss: 0.6566 - val_acc: 0.6354\n",
            "Epoch 697/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5131 - acc: 0.7371 - val_loss: 0.6569 - val_acc: 0.6562\n",
            "Epoch 698/1000\n",
            "37/37 [==============================] - 5s 118ms/step - loss: 0.5034 - acc: 0.7268 - val_loss: 0.6613 - val_acc: 0.6562\n",
            "Epoch 699/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.5232 - acc: 0.7474 - val_loss: 0.6654 - val_acc: 0.6458\n",
            "Epoch 700/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.4824 - acc: 0.7663 - val_loss: 0.6698 - val_acc: 0.6250\n",
            "Epoch 701/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.4989 - acc: 0.7474 - val_loss: 0.6649 - val_acc: 0.6562\n",
            "Epoch 702/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.5140 - acc: 0.7268 - val_loss: 0.6507 - val_acc: 0.6562\n",
            "Epoch 703/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.4772 - acc: 0.7784 - val_loss: 0.6599 - val_acc: 0.6562\n",
            "Epoch 704/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.4913 - acc: 0.7560 - val_loss: 0.6634 - val_acc: 0.6562\n",
            "Epoch 705/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5112 - acc: 0.7457 - val_loss: 0.6744 - val_acc: 0.6250\n",
            "Epoch 706/1000\n",
            "37/37 [==============================] - 9s 239ms/step - loss: 0.5117 - acc: 0.7629 - val_loss: 0.6518 - val_acc: 0.6562\n",
            "Epoch 707/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.4820 - acc: 0.7629 - val_loss: 0.6611 - val_acc: 0.6562\n",
            "Epoch 708/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5335 - acc: 0.7268 - val_loss: 0.6670 - val_acc: 0.6562\n",
            "Epoch 709/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5217 - acc: 0.7268 - val_loss: 0.6603 - val_acc: 0.6562\n",
            "Epoch 710/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5239 - acc: 0.7234 - val_loss: 0.6489 - val_acc: 0.6458\n",
            "Epoch 711/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5102 - acc: 0.7595 - val_loss: 0.6455 - val_acc: 0.6250\n",
            "Epoch 712/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.4794 - acc: 0.7698 - val_loss: 0.6349 - val_acc: 0.6667\n",
            "Epoch 713/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.4847 - acc: 0.7749 - val_loss: 0.6605 - val_acc: 0.6354\n",
            "Epoch 714/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5280 - acc: 0.7405 - val_loss: 0.6658 - val_acc: 0.6458\n",
            "Epoch 715/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.5118 - acc: 0.7629 - val_loss: 0.6577 - val_acc: 0.6562\n",
            "Epoch 716/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5187 - acc: 0.7354 - val_loss: 0.6553 - val_acc: 0.6458\n",
            "Epoch 717/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5222 - acc: 0.7440 - val_loss: 0.6346 - val_acc: 0.6771\n",
            "Epoch 718/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.4883 - acc: 0.7474 - val_loss: 0.6595 - val_acc: 0.6562\n",
            "Epoch 719/1000\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.4843 - acc: 0.7618 - val_loss: 0.6604 - val_acc: 0.6458\n",
            "Epoch 720/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5351 - acc: 0.7423 - val_loss: 0.6704 - val_acc: 0.6354\n",
            "Epoch 721/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5095 - acc: 0.7474 - val_loss: 0.6356 - val_acc: 0.6875\n",
            "Epoch 722/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.4723 - acc: 0.7749 - val_loss: 0.6707 - val_acc: 0.6458\n",
            "Epoch 723/1000\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.5337 - acc: 0.7388 - val_loss: 0.6586 - val_acc: 0.6458\n",
            "Epoch 724/1000\n",
            "37/37 [==============================] - 9s 218ms/step - loss: 0.5171 - acc: 0.7526 - val_loss: 0.6739 - val_acc: 0.6354\n",
            "Epoch 725/1000\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 0.4805 - acc: 0.7818 - val_loss: 0.6479 - val_acc: 0.6562\n",
            "Epoch 726/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.4865 - acc: 0.7560 - val_loss: 0.6792 - val_acc: 0.6354\n",
            "Epoch 727/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5028 - acc: 0.7526 - val_loss: 0.6579 - val_acc: 0.6458\n",
            "Epoch 728/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5102 - acc: 0.7423 - val_loss: 0.6629 - val_acc: 0.6354\n",
            "Epoch 729/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.5401 - acc: 0.7234 - val_loss: 0.6546 - val_acc: 0.6458\n",
            "Epoch 730/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5084 - acc: 0.7371 - val_loss: 0.6429 - val_acc: 0.6562\n",
            "Epoch 731/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.4934 - acc: 0.7577 - val_loss: 0.6684 - val_acc: 0.6458\n",
            "Epoch 732/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.5064 - acc: 0.7405 - val_loss: 0.6410 - val_acc: 0.6562\n",
            "Epoch 733/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.4840 - acc: 0.7595 - val_loss: 0.6690 - val_acc: 0.6354\n",
            "Epoch 734/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.5086 - acc: 0.7423 - val_loss: 0.6626 - val_acc: 0.6354\n",
            "Epoch 735/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5250 - acc: 0.7405 - val_loss: 0.6645 - val_acc: 0.6562\n",
            "Epoch 736/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5380 - acc: 0.6993 - val_loss: 0.6567 - val_acc: 0.6562\n",
            "Epoch 737/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5013 - acc: 0.7526 - val_loss: 0.6517 - val_acc: 0.6562\n",
            "Epoch 738/1000\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 0.5205 - acc: 0.7302 - val_loss: 0.6519 - val_acc: 0.6562\n",
            "Epoch 739/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.4812 - acc: 0.7801 - val_loss: 0.6253 - val_acc: 0.6667\n",
            "Epoch 740/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.5036 - acc: 0.7568 - val_loss: 0.6414 - val_acc: 0.6667\n",
            "Epoch 741/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.5294 - acc: 0.7337 - val_loss: 0.6498 - val_acc: 0.6458\n",
            "Epoch 742/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5183 - acc: 0.7337 - val_loss: 0.6172 - val_acc: 0.6771\n",
            "Epoch 743/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.4952 - acc: 0.7440 - val_loss: 0.6743 - val_acc: 0.6458\n",
            "Epoch 744/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.5018 - acc: 0.7474 - val_loss: 0.6486 - val_acc: 0.6458\n",
            "Epoch 745/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.4777 - acc: 0.7715 - val_loss: 0.6502 - val_acc: 0.6354\n",
            "Epoch 746/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5140 - acc: 0.7337 - val_loss: 0.6602 - val_acc: 0.6458\n",
            "Epoch 747/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.5334 - acc: 0.7234 - val_loss: 0.6652 - val_acc: 0.6458\n",
            "Epoch 748/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.5210 - acc: 0.7337 - val_loss: 0.6250 - val_acc: 0.6667\n",
            "Epoch 749/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5009 - acc: 0.7560 - val_loss: 0.6407 - val_acc: 0.6562\n",
            "Epoch 750/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5295 - acc: 0.7405 - val_loss: 0.6568 - val_acc: 0.6458\n",
            "Epoch 751/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5240 - acc: 0.7285 - val_loss: 0.6708 - val_acc: 0.6250\n",
            "Epoch 752/1000\n",
            "37/37 [==============================] - 9s 216ms/step - loss: 0.5190 - acc: 0.7423 - val_loss: 0.6594 - val_acc: 0.6354\n",
            "Epoch 753/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.5272 - acc: 0.7371 - val_loss: 0.6420 - val_acc: 0.6354\n",
            "Epoch 754/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.5316 - acc: 0.7113 - val_loss: 0.6543 - val_acc: 0.6354\n",
            "Epoch 755/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.5181 - acc: 0.7371 - val_loss: 0.6457 - val_acc: 0.6458\n",
            "Epoch 756/1000\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 0.5116 - acc: 0.7509 - val_loss: 0.6393 - val_acc: 0.6667\n",
            "Epoch 757/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5154 - acc: 0.7440 - val_loss: 0.6530 - val_acc: 0.6562\n",
            "Epoch 758/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.5005 - acc: 0.7543 - val_loss: 0.6588 - val_acc: 0.6562\n",
            "Epoch 759/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5638 - acc: 0.7234 - val_loss: 0.6474 - val_acc: 0.6458\n",
            "Epoch 760/1000\n",
            "37/37 [==============================] - 9s 241ms/step - loss: 0.4744 - acc: 0.7732 - val_loss: 0.6485 - val_acc: 0.6458\n",
            "Epoch 761/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.5497 - acc: 0.7285 - val_loss: 0.6568 - val_acc: 0.6562\n",
            "Epoch 762/1000\n",
            "37/37 [==============================] - 10s 236ms/step - loss: 0.5187 - acc: 0.7577 - val_loss: 0.6661 - val_acc: 0.6562\n",
            "Epoch 763/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.4949 - acc: 0.7526 - val_loss: 0.6713 - val_acc: 0.6458\n",
            "Epoch 764/1000\n",
            "37/37 [==============================] - 9s 245ms/step - loss: 0.5147 - acc: 0.7388 - val_loss: 0.6593 - val_acc: 0.6458\n",
            "Epoch 765/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.4984 - acc: 0.7543 - val_loss: 0.6577 - val_acc: 0.6458\n",
            "Epoch 766/1000\n",
            "37/37 [==============================] - 9s 244ms/step - loss: 0.4961 - acc: 0.7509 - val_loss: 0.6527 - val_acc: 0.6458\n",
            "Epoch 767/1000\n",
            "37/37 [==============================] - 3s 85ms/step - loss: 0.5212 - acc: 0.7405 - val_loss: 0.6618 - val_acc: 0.6354\n",
            "Epoch 768/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.5120 - acc: 0.7491 - val_loss: 0.6551 - val_acc: 0.6562\n",
            "Epoch 769/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.4798 - acc: 0.7766 - val_loss: 0.6716 - val_acc: 0.6250\n",
            "Epoch 770/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5457 - acc: 0.7113 - val_loss: 0.6513 - val_acc: 0.6562\n",
            "Epoch 771/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5335 - acc: 0.7474 - val_loss: 0.6584 - val_acc: 0.6250\n",
            "Epoch 772/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.4804 - acc: 0.7577 - val_loss: 0.6557 - val_acc: 0.6458\n",
            "Epoch 773/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.4897 - acc: 0.7612 - val_loss: 0.6428 - val_acc: 0.6562\n",
            "Epoch 774/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 0.5644 - acc: 0.7543 - val_loss: 0.6688 - val_acc: 0.6458\n",
            "Epoch 775/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.4669 - acc: 0.7904 - val_loss: 0.6587 - val_acc: 0.6458\n",
            "Epoch 776/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.5432 - acc: 0.7251 - val_loss: 0.6643 - val_acc: 0.6458\n",
            "Epoch 777/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.4957 - acc: 0.7320 - val_loss: 0.6664 - val_acc: 0.6458\n",
            "Epoch 778/1000\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.5321 - acc: 0.7320 - val_loss: 0.6454 - val_acc: 0.6771\n",
            "Epoch 779/1000\n",
            "37/37 [==============================] - 9s 241ms/step - loss: 0.5328 - acc: 0.7182 - val_loss: 0.6657 - val_acc: 0.6354\n",
            "Epoch 780/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.4776 - acc: 0.7680 - val_loss: 0.6625 - val_acc: 0.6562\n",
            "Epoch 781/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5380 - acc: 0.7268 - val_loss: 0.6637 - val_acc: 0.6458\n",
            "Epoch 782/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.4756 - acc: 0.7703 - val_loss: 0.6572 - val_acc: 0.6354\n",
            "Epoch 783/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.5425 - acc: 0.7165 - val_loss: 0.6808 - val_acc: 0.6146\n",
            "Epoch 784/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.5098 - acc: 0.7491 - val_loss: 0.6598 - val_acc: 0.6562\n",
            "Epoch 785/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.5329 - acc: 0.7388 - val_loss: 0.6652 - val_acc: 0.6562\n",
            "Epoch 786/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.5158 - acc: 0.7251 - val_loss: 0.6715 - val_acc: 0.6354\n",
            "Epoch 787/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5037 - acc: 0.7595 - val_loss: 0.6674 - val_acc: 0.6354\n",
            "Epoch 788/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5147 - acc: 0.7423 - val_loss: 0.6485 - val_acc: 0.6667\n",
            "Epoch 789/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.5175 - acc: 0.7491 - val_loss: 0.6755 - val_acc: 0.6354\n",
            "Epoch 790/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5075 - acc: 0.7388 - val_loss: 0.6678 - val_acc: 0.6354\n",
            "Epoch 791/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.5480 - acc: 0.7268 - val_loss: 0.6728 - val_acc: 0.6354\n",
            "Epoch 792/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5315 - acc: 0.7302 - val_loss: 0.6572 - val_acc: 0.6667\n",
            "Epoch 793/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5190 - acc: 0.7354 - val_loss: 0.6718 - val_acc: 0.6354\n",
            "Epoch 794/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.4738 - acc: 0.7646 - val_loss: 0.6788 - val_acc: 0.6354\n",
            "Epoch 795/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.4931 - acc: 0.7612 - val_loss: 0.6658 - val_acc: 0.6562\n",
            "Epoch 796/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.5195 - acc: 0.7354 - val_loss: 0.6900 - val_acc: 0.6354\n",
            "Epoch 797/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5133 - acc: 0.7560 - val_loss: 0.6682 - val_acc: 0.6458\n",
            "Epoch 798/1000\n",
            "37/37 [==============================] - 4s 81ms/step - loss: 0.5173 - acc: 0.7264 - val_loss: 0.6471 - val_acc: 0.6562\n",
            "Epoch 799/1000\n",
            "37/37 [==============================] - 10s 240ms/step - loss: 0.4814 - acc: 0.7818 - val_loss: 0.6725 - val_acc: 0.6354\n",
            "Epoch 800/1000\n",
            "37/37 [==============================] - 3s 83ms/step - loss: 0.5303 - acc: 0.7388 - val_loss: 0.6432 - val_acc: 0.6562\n",
            "Epoch 801/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.4920 - acc: 0.7612 - val_loss: 0.6650 - val_acc: 0.6354\n",
            "Epoch 802/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.5047 - acc: 0.7302 - val_loss: 0.6499 - val_acc: 0.6562\n",
            "Epoch 803/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.4996 - acc: 0.7577 - val_loss: 0.6490 - val_acc: 0.6562\n",
            "Epoch 804/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5374 - acc: 0.7165 - val_loss: 0.6703 - val_acc: 0.6458\n",
            "Epoch 805/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.4858 - acc: 0.7595 - val_loss: 0.6598 - val_acc: 0.6667\n",
            "Epoch 806/1000\n",
            "37/37 [==============================] - 5s 100ms/step - loss: 0.4952 - acc: 0.7543 - val_loss: 0.6630 - val_acc: 0.6354\n",
            "Epoch 807/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.5084 - acc: 0.7457 - val_loss: 0.6482 - val_acc: 0.6562\n",
            "Epoch 808/1000\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 0.5239 - acc: 0.7509 - val_loss: 0.6770 - val_acc: 0.6250\n",
            "Epoch 809/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.5168 - acc: 0.7440 - val_loss: 0.6769 - val_acc: 0.6250\n",
            "Epoch 810/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5130 - acc: 0.7474 - val_loss: 0.6624 - val_acc: 0.6562\n",
            "Epoch 811/1000\n",
            "37/37 [==============================] - 5s 109ms/step - loss: 0.5027 - acc: 0.7405 - val_loss: 0.6625 - val_acc: 0.6458\n",
            "Epoch 812/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.4712 - acc: 0.7732 - val_loss: 0.6574 - val_acc: 0.6667\n",
            "Epoch 813/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.5143 - acc: 0.7405 - val_loss: 0.6690 - val_acc: 0.6250\n",
            "Epoch 814/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.4712 - acc: 0.7440 - val_loss: 0.6541 - val_acc: 0.6458\n",
            "Epoch 815/1000\n",
            "37/37 [==============================] - 9s 220ms/step - loss: 0.4916 - acc: 0.7577 - val_loss: 0.6692 - val_acc: 0.6354\n",
            "Epoch 816/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5183 - acc: 0.7216 - val_loss: 0.6757 - val_acc: 0.6458\n",
            "Epoch 817/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5089 - acc: 0.7268 - val_loss: 0.6597 - val_acc: 0.6458\n",
            "Epoch 818/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5055 - acc: 0.7365 - val_loss: 0.6470 - val_acc: 0.6562\n",
            "Epoch 819/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.5032 - acc: 0.7595 - val_loss: 0.6630 - val_acc: 0.6458\n",
            "Epoch 820/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.5079 - acc: 0.7337 - val_loss: 0.6646 - val_acc: 0.6562\n",
            "Epoch 821/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.4938 - acc: 0.7526 - val_loss: 0.6727 - val_acc: 0.6458\n",
            "Epoch 822/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.4861 - acc: 0.7543 - val_loss: 0.6721 - val_acc: 0.6562\n",
            "Epoch 823/1000\n",
            "37/37 [==============================] - 5s 109ms/step - loss: 0.5052 - acc: 0.7560 - val_loss: 0.6656 - val_acc: 0.6562\n",
            "Epoch 824/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.4914 - acc: 0.7577 - val_loss: 0.6811 - val_acc: 0.6354\n",
            "Epoch 825/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.4842 - acc: 0.7560 - val_loss: 0.6509 - val_acc: 0.6771\n",
            "Epoch 826/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.5132 - acc: 0.7388 - val_loss: 0.6768 - val_acc: 0.6562\n",
            "Epoch 827/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.5020 - acc: 0.7543 - val_loss: 0.6623 - val_acc: 0.6562\n",
            "Epoch 828/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5289 - acc: 0.7148 - val_loss: 0.6601 - val_acc: 0.6667\n",
            "Epoch 829/1000\n",
            "37/37 [==============================] - 9s 241ms/step - loss: 0.5020 - acc: 0.7646 - val_loss: 0.6694 - val_acc: 0.6354\n",
            "Epoch 830/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5101 - acc: 0.7440 - val_loss: 0.6467 - val_acc: 0.6667\n",
            "Epoch 831/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.4987 - acc: 0.7818 - val_loss: 0.6742 - val_acc: 0.6458\n",
            "Epoch 832/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.4999 - acc: 0.7405 - val_loss: 0.6687 - val_acc: 0.6458\n",
            "Epoch 833/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.5013 - acc: 0.7652 - val_loss: 0.6668 - val_acc: 0.6667\n",
            "Epoch 834/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.4771 - acc: 0.7749 - val_loss: 0.6695 - val_acc: 0.6562\n",
            "Epoch 835/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.4895 - acc: 0.7595 - val_loss: 0.6586 - val_acc: 0.6667\n",
            "Epoch 836/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.5091 - acc: 0.7423 - val_loss: 0.6678 - val_acc: 0.6562\n",
            "Epoch 837/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.5032 - acc: 0.7405 - val_loss: 0.6691 - val_acc: 0.6354\n",
            "Epoch 838/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5160 - acc: 0.7371 - val_loss: 0.6603 - val_acc: 0.6562\n",
            "Epoch 839/1000\n",
            "37/37 [==============================] - 9s 216ms/step - loss: 0.5141 - acc: 0.7457 - val_loss: 0.6671 - val_acc: 0.6458\n",
            "Epoch 840/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5184 - acc: 0.7302 - val_loss: 0.6638 - val_acc: 0.6458\n",
            "Epoch 841/1000\n",
            "37/37 [==============================] - 9s 216ms/step - loss: 0.5031 - acc: 0.7612 - val_loss: 0.6515 - val_acc: 0.6562\n",
            "Epoch 842/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5258 - acc: 0.7337 - val_loss: 0.6447 - val_acc: 0.6562\n",
            "Epoch 843/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.5181 - acc: 0.7371 - val_loss: 0.6525 - val_acc: 0.6562\n",
            "Epoch 844/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5089 - acc: 0.7457 - val_loss: 0.6506 - val_acc: 0.6562\n",
            "Epoch 845/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.5099 - acc: 0.7509 - val_loss: 0.6633 - val_acc: 0.6562\n",
            "Epoch 846/1000\n",
            "37/37 [==============================] - 9s 219ms/step - loss: 0.5082 - acc: 0.7577 - val_loss: 0.6548 - val_acc: 0.6667\n",
            "Epoch 847/1000\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 0.5064 - acc: 0.7491 - val_loss: 0.6647 - val_acc: 0.6458\n",
            "Epoch 848/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.4928 - acc: 0.7440 - val_loss: 0.6566 - val_acc: 0.6667\n",
            "Epoch 849/1000\n",
            "37/37 [==============================] - 5s 112ms/step - loss: 0.5174 - acc: 0.7577 - val_loss: 0.6534 - val_acc: 0.6562\n",
            "Epoch 850/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5313 - acc: 0.7388 - val_loss: 0.6609 - val_acc: 0.6458\n",
            "Epoch 851/1000\n",
            "37/37 [==============================] - 9s 239ms/step - loss: 0.5200 - acc: 0.7405 - val_loss: 0.6608 - val_acc: 0.6458\n",
            "Epoch 852/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5230 - acc: 0.7663 - val_loss: 0.6662 - val_acc: 0.6667\n",
            "Epoch 853/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5066 - acc: 0.7405 - val_loss: 0.6711 - val_acc: 0.6458\n",
            "Epoch 854/1000\n",
            "37/37 [==============================] - 6s 138ms/step - loss: 0.4973 - acc: 0.7423 - val_loss: 0.6671 - val_acc: 0.6458\n",
            "Epoch 855/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5222 - acc: 0.7354 - val_loss: 0.6556 - val_acc: 0.6562\n",
            "Epoch 856/1000\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.4966 - acc: 0.7669 - val_loss: 0.6469 - val_acc: 0.6562\n",
            "Epoch 857/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5084 - acc: 0.7423 - val_loss: 0.6445 - val_acc: 0.6458\n",
            "Epoch 858/1000\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 0.5057 - acc: 0.7715 - val_loss: 0.6630 - val_acc: 0.6458\n",
            "Epoch 859/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.4957 - acc: 0.7715 - val_loss: 0.6588 - val_acc: 0.6562\n",
            "Epoch 860/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.5181 - acc: 0.7371 - val_loss: 0.6541 - val_acc: 0.6458\n",
            "Epoch 861/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.5397 - acc: 0.7199 - val_loss: 0.6471 - val_acc: 0.6667\n",
            "Epoch 862/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5399 - acc: 0.7423 - val_loss: 0.6622 - val_acc: 0.6458\n",
            "Epoch 863/1000\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 0.5025 - acc: 0.7629 - val_loss: 0.6669 - val_acc: 0.6458\n",
            "Epoch 864/1000\n",
            "37/37 [==============================] - 4s 81ms/step - loss: 0.4883 - acc: 0.7509 - val_loss: 0.6740 - val_acc: 0.6250\n",
            "Epoch 865/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5133 - acc: 0.7371 - val_loss: 0.6539 - val_acc: 0.6562\n",
            "Epoch 866/1000\n",
            "37/37 [==============================] - 9s 243ms/step - loss: 0.5120 - acc: 0.7423 - val_loss: 0.6653 - val_acc: 0.6458\n",
            "Epoch 867/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.5203 - acc: 0.7096 - val_loss: 0.6472 - val_acc: 0.6458\n",
            "Epoch 868/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.4917 - acc: 0.7526 - val_loss: 0.6743 - val_acc: 0.6562\n",
            "Epoch 869/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.4996 - acc: 0.7612 - val_loss: 0.6699 - val_acc: 0.6458\n",
            "Epoch 870/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5170 - acc: 0.7595 - val_loss: 0.6678 - val_acc: 0.6250\n",
            "Epoch 871/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5123 - acc: 0.7509 - val_loss: 0.6490 - val_acc: 0.6562\n",
            "Epoch 872/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5212 - acc: 0.7354 - val_loss: 0.6625 - val_acc: 0.6458\n",
            "Epoch 873/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.5327 - acc: 0.7320 - val_loss: 0.6482 - val_acc: 0.6562\n",
            "Epoch 874/1000\n",
            "37/37 [==============================] - 3s 83ms/step - loss: 0.5224 - acc: 0.7457 - val_loss: 0.6513 - val_acc: 0.6458\n",
            "Epoch 875/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.4972 - acc: 0.7405 - val_loss: 0.6520 - val_acc: 0.6354\n",
            "Epoch 876/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.5155 - acc: 0.7526 - val_loss: 0.6594 - val_acc: 0.6250\n",
            "Epoch 877/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5392 - acc: 0.7320 - val_loss: 0.6493 - val_acc: 0.6667\n",
            "Epoch 878/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.5042 - acc: 0.7595 - val_loss: 0.6492 - val_acc: 0.6562\n",
            "Epoch 879/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5300 - acc: 0.7629 - val_loss: 0.6672 - val_acc: 0.6354\n",
            "Epoch 880/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.5307 - acc: 0.7457 - val_loss: 0.6442 - val_acc: 0.6667\n",
            "Epoch 881/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.5176 - acc: 0.7320 - val_loss: 0.6415 - val_acc: 0.6562\n",
            "Epoch 882/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.5124 - acc: 0.7388 - val_loss: 0.6467 - val_acc: 0.6562\n",
            "Epoch 883/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.4811 - acc: 0.7801 - val_loss: 0.6665 - val_acc: 0.6354\n",
            "Epoch 884/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.5219 - acc: 0.7440 - val_loss: 0.6583 - val_acc: 0.6667\n",
            "Epoch 885/1000\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.5048 - acc: 0.7388 - val_loss: 0.6615 - val_acc: 0.6562\n",
            "Epoch 886/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5145 - acc: 0.7526 - val_loss: 0.6576 - val_acc: 0.6354\n",
            "Epoch 887/1000\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 0.5062 - acc: 0.7560 - val_loss: 0.6388 - val_acc: 0.6562\n",
            "Epoch 888/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5127 - acc: 0.7382 - val_loss: 0.6644 - val_acc: 0.6354\n",
            "Epoch 889/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.4981 - acc: 0.7509 - val_loss: 0.6514 - val_acc: 0.6667\n",
            "Epoch 890/1000\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.4979 - acc: 0.7680 - val_loss: 0.6481 - val_acc: 0.6562\n",
            "Epoch 891/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5358 - acc: 0.7234 - val_loss: 0.6603 - val_acc: 0.6562\n",
            "Epoch 892/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5117 - acc: 0.7509 - val_loss: 0.6526 - val_acc: 0.6562\n",
            "Epoch 893/1000\n",
            "37/37 [==============================] - 5s 116ms/step - loss: 0.5083 - acc: 0.7320 - val_loss: 0.6499 - val_acc: 0.6562\n",
            "Epoch 894/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5351 - acc: 0.7354 - val_loss: 0.6664 - val_acc: 0.6354\n",
            "Epoch 895/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5065 - acc: 0.7466 - val_loss: 0.6557 - val_acc: 0.6458\n",
            "Epoch 896/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.5070 - acc: 0.7354 - val_loss: 0.6426 - val_acc: 0.6562\n",
            "Epoch 897/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5438 - acc: 0.7354 - val_loss: 0.6372 - val_acc: 0.6771\n",
            "Epoch 898/1000\n",
            "37/37 [==============================] - 10s 250ms/step - loss: 0.4745 - acc: 0.7784 - val_loss: 0.6350 - val_acc: 0.6771\n",
            "Epoch 899/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5305 - acc: 0.7577 - val_loss: 0.6566 - val_acc: 0.6562\n",
            "Epoch 900/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5136 - acc: 0.7388 - val_loss: 0.6571 - val_acc: 0.6562\n",
            "Epoch 901/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5305 - acc: 0.7199 - val_loss: 0.6722 - val_acc: 0.6354\n",
            "Epoch 902/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5309 - acc: 0.7365 - val_loss: 0.6473 - val_acc: 0.6667\n",
            "Epoch 903/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5095 - acc: 0.7646 - val_loss: 0.6456 - val_acc: 0.6562\n",
            "Epoch 904/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.5109 - acc: 0.7784 - val_loss: 0.6534 - val_acc: 0.6354\n",
            "Epoch 905/1000\n",
            "37/37 [==============================] - 9s 241ms/step - loss: 0.5083 - acc: 0.7457 - val_loss: 0.6375 - val_acc: 0.6562\n",
            "Epoch 906/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.4997 - acc: 0.7423 - val_loss: 0.6609 - val_acc: 0.6458\n",
            "Epoch 907/1000\n",
            "37/37 [==============================] - 5s 105ms/step - loss: 0.5236 - acc: 0.7371 - val_loss: 0.6360 - val_acc: 0.6667\n",
            "Epoch 908/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5211 - acc: 0.7371 - val_loss: 0.6570 - val_acc: 0.6458\n",
            "Epoch 909/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.4885 - acc: 0.7491 - val_loss: 0.6550 - val_acc: 0.6562\n",
            "Epoch 910/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5105 - acc: 0.7560 - val_loss: 0.6572 - val_acc: 0.6458\n",
            "Epoch 911/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.4877 - acc: 0.7629 - val_loss: 0.6571 - val_acc: 0.6458\n",
            "Epoch 912/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5033 - acc: 0.7509 - val_loss: 0.6593 - val_acc: 0.6458\n",
            "Epoch 913/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5133 - acc: 0.7509 - val_loss: 0.6540 - val_acc: 0.6771\n",
            "Epoch 914/1000\n",
            "37/37 [==============================] - 5s 114ms/step - loss: 0.5060 - acc: 0.7629 - val_loss: 0.6576 - val_acc: 0.6667\n",
            "Epoch 915/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5442 - acc: 0.7543 - val_loss: 0.6583 - val_acc: 0.6458\n",
            "Epoch 916/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.5105 - acc: 0.7509 - val_loss: 0.6520 - val_acc: 0.6562\n",
            "Epoch 917/1000\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 0.5311 - acc: 0.7268 - val_loss: 0.6627 - val_acc: 0.6458\n",
            "Epoch 918/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.4785 - acc: 0.7784 - val_loss: 0.6569 - val_acc: 0.6667\n",
            "Epoch 919/1000\n",
            "37/37 [==============================] - 9s 239ms/step - loss: 0.5346 - acc: 0.7337 - val_loss: 0.6572 - val_acc: 0.6562\n",
            "Epoch 920/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.5067 - acc: 0.7405 - val_loss: 0.6522 - val_acc: 0.6458\n",
            "Epoch 921/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.5139 - acc: 0.7629 - val_loss: 0.6500 - val_acc: 0.6562\n",
            "Epoch 922/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5179 - acc: 0.7302 - val_loss: 0.6619 - val_acc: 0.6250\n",
            "Epoch 923/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5252 - acc: 0.7113 - val_loss: 0.6606 - val_acc: 0.6458\n",
            "Epoch 924/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5353 - acc: 0.7285 - val_loss: 0.6724 - val_acc: 0.6458\n",
            "Epoch 925/1000\n",
            "37/37 [==============================] - 5s 108ms/step - loss: 0.4991 - acc: 0.7337 - val_loss: 0.6546 - val_acc: 0.6458\n",
            "Epoch 926/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.4956 - acc: 0.7663 - val_loss: 0.6688 - val_acc: 0.6354\n",
            "Epoch 927/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5044 - acc: 0.7423 - val_loss: 0.6624 - val_acc: 0.6458\n",
            "Epoch 928/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5282 - acc: 0.7371 - val_loss: 0.6703 - val_acc: 0.6354\n",
            "Epoch 929/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5052 - acc: 0.7440 - val_loss: 0.6426 - val_acc: 0.6458\n",
            "Epoch 930/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5050 - acc: 0.7474 - val_loss: 0.6578 - val_acc: 0.6562\n",
            "Epoch 931/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5132 - acc: 0.7268 - val_loss: 0.6594 - val_acc: 0.6458\n",
            "Epoch 932/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5113 - acc: 0.7612 - val_loss: 0.6667 - val_acc: 0.6458\n",
            "Epoch 933/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.4945 - acc: 0.7715 - val_loss: 0.6585 - val_acc: 0.6354\n",
            "Epoch 934/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.4856 - acc: 0.7680 - val_loss: 0.6670 - val_acc: 0.6458\n",
            "Epoch 935/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5116 - acc: 0.7348 - val_loss: 0.6654 - val_acc: 0.6458\n",
            "Epoch 936/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5012 - acc: 0.7457 - val_loss: 0.6623 - val_acc: 0.6667\n",
            "Epoch 937/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5309 - acc: 0.7543 - val_loss: 0.6548 - val_acc: 0.6771\n",
            "Epoch 938/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.4922 - acc: 0.7595 - val_loss: 0.6717 - val_acc: 0.6354\n",
            "Epoch 939/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.4791 - acc: 0.7560 - val_loss: 0.6497 - val_acc: 0.6458\n",
            "Epoch 940/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5108 - acc: 0.7354 - val_loss: 0.6607 - val_acc: 0.6562\n",
            "Epoch 941/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5099 - acc: 0.7388 - val_loss: 0.6660 - val_acc: 0.6458\n",
            "Epoch 942/1000\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 0.4840 - acc: 0.7663 - val_loss: 0.6536 - val_acc: 0.6458\n",
            "Epoch 943/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.5092 - acc: 0.7526 - val_loss: 0.6333 - val_acc: 0.6771\n",
            "Epoch 944/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5039 - acc: 0.7732 - val_loss: 0.6518 - val_acc: 0.6458\n",
            "Epoch 945/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5258 - acc: 0.7560 - val_loss: 0.6535 - val_acc: 0.6562\n",
            "Epoch 946/1000\n",
            "37/37 [==============================] - 5s 137ms/step - loss: 0.5662 - acc: 0.7079 - val_loss: 0.6715 - val_acc: 0.6250\n",
            "Epoch 947/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5212 - acc: 0.7491 - val_loss: 0.6704 - val_acc: 0.6458\n",
            "Epoch 948/1000\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.5536 - acc: 0.7165 - val_loss: 0.6692 - val_acc: 0.6250\n",
            "Epoch 949/1000\n",
            "37/37 [==============================] - 8s 223ms/step - loss: 0.5056 - acc: 0.7612 - val_loss: 0.6398 - val_acc: 0.6458\n",
            "Epoch 950/1000\n",
            "37/37 [==============================] - 6s 147ms/step - loss: 0.5309 - acc: 0.7285 - val_loss: 0.6507 - val_acc: 0.6458\n",
            "Epoch 951/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5165 - acc: 0.7646 - val_loss: 0.6259 - val_acc: 0.6667\n",
            "Epoch 952/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.5238 - acc: 0.7509 - val_loss: 0.6414 - val_acc: 0.6562\n",
            "Epoch 953/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.5103 - acc: 0.7595 - val_loss: 0.6533 - val_acc: 0.6562\n",
            "Epoch 954/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.4839 - acc: 0.7457 - val_loss: 0.6525 - val_acc: 0.6458\n",
            "Epoch 955/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.5189 - acc: 0.7216 - val_loss: 0.6493 - val_acc: 0.6562\n",
            "Epoch 956/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.5088 - acc: 0.7440 - val_loss: 0.6499 - val_acc: 0.6458\n",
            "Epoch 957/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.4803 - acc: 0.7784 - val_loss: 0.6504 - val_acc: 0.6354\n",
            "Epoch 958/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.5095 - acc: 0.7354 - val_loss: 0.6408 - val_acc: 0.6562\n",
            "Epoch 959/1000\n",
            "37/37 [==============================] - 9s 239ms/step - loss: 0.5017 - acc: 0.7440 - val_loss: 0.6378 - val_acc: 0.6562\n",
            "Epoch 960/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5057 - acc: 0.7251 - val_loss: 0.6506 - val_acc: 0.6562\n",
            "Epoch 961/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5277 - acc: 0.7199 - val_loss: 0.6475 - val_acc: 0.6562\n",
            "Epoch 962/1000\n",
            "37/37 [==============================] - 9s 245ms/step - loss: 0.5359 - acc: 0.7079 - val_loss: 0.6395 - val_acc: 0.6458\n",
            "Epoch 963/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.4887 - acc: 0.7577 - val_loss: 0.6472 - val_acc: 0.6458\n",
            "Epoch 964/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5205 - acc: 0.7388 - val_loss: 0.6561 - val_acc: 0.6354\n",
            "Epoch 965/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.4874 - acc: 0.7577 - val_loss: 0.6489 - val_acc: 0.6354\n",
            "Epoch 966/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5272 - acc: 0.7388 - val_loss: 0.6406 - val_acc: 0.6667\n",
            "Epoch 967/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5315 - acc: 0.7302 - val_loss: 0.6662 - val_acc: 0.6354\n",
            "Epoch 968/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.5008 - acc: 0.7423 - val_loss: 0.6424 - val_acc: 0.6458\n",
            "Epoch 969/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.5185 - acc: 0.7320 - val_loss: 0.6379 - val_acc: 0.6667\n",
            "Epoch 970/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.5042 - acc: 0.7612 - val_loss: 0.6606 - val_acc: 0.6458\n",
            "Epoch 971/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.4805 - acc: 0.7801 - val_loss: 0.6418 - val_acc: 0.6771\n",
            "Epoch 972/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5134 - acc: 0.7337 - val_loss: 0.6542 - val_acc: 0.6458\n",
            "Epoch 973/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.5150 - acc: 0.7526 - val_loss: 0.6499 - val_acc: 0.6562\n",
            "Epoch 974/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.4942 - acc: 0.7629 - val_loss: 0.6722 - val_acc: 0.6354\n",
            "Epoch 975/1000\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.4771 - acc: 0.7818 - val_loss: 0.6570 - val_acc: 0.6458\n",
            "Epoch 976/1000\n",
            "37/37 [==============================] - 9s 219ms/step - loss: 0.4835 - acc: 0.7698 - val_loss: 0.6649 - val_acc: 0.6458\n",
            "Epoch 977/1000\n",
            "37/37 [==============================] - 9s 246ms/step - loss: 0.5208 - acc: 0.7646 - val_loss: 0.6687 - val_acc: 0.6354\n",
            "Epoch 978/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.5425 - acc: 0.7320 - val_loss: 0.6406 - val_acc: 0.6667\n",
            "Epoch 979/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.4992 - acc: 0.7500 - val_loss: 0.6502 - val_acc: 0.6562\n",
            "Epoch 980/1000\n",
            "37/37 [==============================] - 9s 242ms/step - loss: 0.4717 - acc: 0.7577 - val_loss: 0.6635 - val_acc: 0.6562\n",
            "Epoch 981/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.4912 - acc: 0.7663 - val_loss: 0.6543 - val_acc: 0.6562\n",
            "Epoch 982/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.5178 - acc: 0.7474 - val_loss: 0.6341 - val_acc: 0.6771\n",
            "Epoch 983/1000\n",
            "37/37 [==============================] - 9s 220ms/step - loss: 0.4974 - acc: 0.7732 - val_loss: 0.6398 - val_acc: 0.6667\n",
            "Epoch 984/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.4882 - acc: 0.7577 - val_loss: 0.6448 - val_acc: 0.6562\n",
            "Epoch 985/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.5076 - acc: 0.7440 - val_loss: 0.6708 - val_acc: 0.6354\n",
            "Epoch 986/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.5065 - acc: 0.7698 - val_loss: 0.6583 - val_acc: 0.6562\n",
            "Epoch 987/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5372 - acc: 0.7354 - val_loss: 0.6524 - val_acc: 0.6562\n",
            "Epoch 988/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.4963 - acc: 0.7595 - val_loss: 0.6263 - val_acc: 0.6771\n",
            "Epoch 989/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5330 - acc: 0.7440 - val_loss: 0.6439 - val_acc: 0.6562\n",
            "Epoch 990/1000\n",
            "37/37 [==============================] - 5s 110ms/step - loss: 0.5038 - acc: 0.7509 - val_loss: 0.6568 - val_acc: 0.6250\n",
            "Epoch 991/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5023 - acc: 0.7595 - val_loss: 0.6525 - val_acc: 0.6458\n",
            "Epoch 992/1000\n",
            "37/37 [==============================] - 6s 142ms/step - loss: 0.5211 - acc: 0.7474 - val_loss: 0.6383 - val_acc: 0.6667\n",
            "Epoch 993/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.4916 - acc: 0.7543 - val_loss: 0.6450 - val_acc: 0.6458\n",
            "Epoch 994/1000\n",
            "37/37 [==============================] - 5s 112ms/step - loss: 0.5096 - acc: 0.7595 - val_loss: 0.6310 - val_acc: 0.6562\n",
            "Epoch 995/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5141 - acc: 0.7440 - val_loss: 0.6483 - val_acc: 0.6458\n",
            "Epoch 996/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.5220 - acc: 0.7500 - val_loss: 0.6378 - val_acc: 0.6667\n",
            "Epoch 997/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5047 - acc: 0.7509 - val_loss: 0.6561 - val_acc: 0.6354\n",
            "Epoch 998/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.4928 - acc: 0.7629 - val_loss: 0.6703 - val_acc: 0.6250\n",
            "Epoch 999/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5119 - acc: 0.7388 - val_loss: 0.6465 - val_acc: 0.6354\n",
            "Epoch 1000/1000\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.5226 - acc: 0.7440 - val_loss: 0.6423 - val_acc: 0.6771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot training performance"
      ],
      "metadata": {
        "id": "YFxMJycOpEew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'co', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'k', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'co', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "l9PYKbRNpEK8",
        "outputId": "0c61610e-8184-4e58-b17f-28fbe744f26b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAABln0lEQVR4nO2deXhURfb3v6e7kw4QMBIg7NuYQFwQZFFAFBUVkMF1EEQMojLCqLiMjo4bLryOP5kZcBQUGRURB9dRVBw3REFRWUQWwyaCAhIhCLKEQJLz/tG3mtu36659O5009XkeHtJ3rXtv1alT55w6RcwMhUKhUKQvgVQXQKFQKBTJRQl6hUKhSHOUoFcoFIo0Rwl6hUKhSHOUoFcoFIo0Rwl6hUKhSHOUoFe4gojeI6Iiv49NJUS0iYj6JeG6TETHaX8/RUT3OjnWw32GE9EHXstpcd2+RLTF7+sqqp9QqgugSD5EtE/3sy6AcgCV2u8/MvMsp9di5gHJODbdYebr/bgOEbUF8AOADGau0K49C4Djb6g4+lCC/iiAmbPF30S0CcC1zPyR8TgiCgnhoVAo0gdlujmKEUNzIvoLEW0H8BwRHUtE7xDRDiL6Vfu7pe6c+UR0rfb3SCJaSEQTtWN/IKIBHo9tR0SfEdFeIvqIiJ4kohdNyu2kjA8R0efa9T4goka6/SOIaDMRlRLR3Rbv51Qi2k5EQd22i4lohfZ3DyJaRES7iehnInqCiDJNrvU8ET2s+327ds42IhplOPYCIvqGiH4jop+IaLxu92fa/7uJaB8R9RTvVnd+LyJaTER7tP97OX03VhBRoXb+biJaTUSDdfsGEtF32jW3EtGfte2NtO+zm4h2EdECIlJyp5pRL1zRFEBDAG0AjEakTjyn/W4NoAzAExbnnwpgLYBGAP4PwL+JiDwc+xKArwHkAhgPYITFPZ2U8QoAVwNoAiATgBA8xwOYql2/uXa/lpDAzF8B2A/gbMN1X9L+rgRwi/Y8PQGcA2CsRbmhlaG/Vp5zAeQDMPoH9gO4CkAOgAsAjCGii7R9Z2j/5zBzNjMvMly7IYB3ATyuPds/ALxLRLmGZ4h7NzZlzgDwNoAPtPNuBDCLiDpoh/wbETNgfQAnApinbb8NwBYAjQHkAfgrAJV3pZpRgl5RBeB+Zi5n5jJmLmXm15n5ADPvBTABwJkW529m5meYuRLADADNEGnQjo8lotYAugO4j5kPMfNCAHPMbuiwjM8x8zpmLgPwCoDO2vbLALzDzJ8xczmAe7V3YMZ/AAwDACKqD2Cgtg3MvJSZv2TmCmbeBOBpSTlkDNHKt4qZ9yPSsemfbz4zr2TmKmZeod3PyXWBSMewnplnauX6D4A1AH6vO8bs3VhxGoBsAH/TvtE8AO9AezcADgM4nogaMPOvzLxMt70ZgDbMfJiZF7BKsFXtKEGv2MHMB8UPIqpLRE9rpo3fEDEV5OjNFwa2iz+Y+YD2Z7bLY5sD2KXbBgA/mRXYYRm36/4+oCtTc/21NUFbanYvRLT3S4goDOASAMuYebNWjgLNLLFdK8f/Q0S7tyOmDAA2G57vVCL6RDNN7QFwvcPrimtvNmzbDKCF7rfZu7EtMzPrO0X9dS9FpBPcTESfElFPbftjADYA+ICINhLRnc4eQ+EnStArjNrVbQA6ADiVmRvgiKnAzBzjBz8DaEhEdXXbWlkcn0gZf9ZfW7tnrtnBzPwdIgJtAGLNNkDEBLQGQL5Wjr96KQMi5ic9LyEyomnFzMcAeEp3XTtteBsiJi09rQFsdVAuu+u2MtjXo9dl5sXMfCEiZp03ERkpgJn3MvNtzNwewGAAtxLROQmWReESJegVRuojYvPerdl770/2DTUNeQmA8USUqWmDv7c4JZEyvgZgEBGdrjlOH4R9O3gJwDhEOpRXDeX4DcA+IuoIYIzDMrwCYCQRHa91NMby10dkhHOQiHog0sEIdiBiampvcu25AAqI6AoiChHR5QCOR8TMkghfIaL930FEGUTUF5FvNFv7ZsOJ6BhmPozIO6kCACIaRETHab6YPYj4NaxMZYokoAS9wsgkAHUA7ATwJYD/VdN9hyPi0CwF8DCAlxGJ95cxCR7LyMyrAfwJEeH9M4BfEXEWWiFs5POYeadu+58REcJ7ATyjldlJGd7TnmEeImaNeYZDxgJ4kIj2ArgPmnasnXsAEZ/E51oky2mGa5cCGITIqKcUwB0ABhnK7RpmPoSIYB+AyHufAuAqZl6jHTICwCbNhHU9It8TiDibPwKwD8AiAFOY+ZNEyqJwDym/iKImQkQvA1jDzEkfUSgU6Y7S6BU1AiLqTkS/I6KAFn54ISK2XoVCkSBqZqyiptAUwBuIOEa3ABjDzN+ktkgKRXqgTDcKhUKR5ijTjUKhUKQ5Nc5006hRI27btm2qi6FQKBS1iqVLl+5k5sayfTVO0Ldt2xZLlixJdTEUCoWiVkFExhnRUZTpRqFQKNIcJegVCoUizXEk6ImoPxGtJaINsqRERPRPIlqu/VtHRLt1+4qIaL32r8YvK6dQKBTphq2NXssI+CQiubO3AFhMRHO0ZE8AAGa+RXf8jQC6aH+LPCTdEEnGtFQ791dfn0KhUCgUpjjR6HsA2MDMG7V8F7MRmbVoxjBo+boBnA/gQ2bepQn3DwH0T6TACoVCoXCHE0HfArG5s7cgNrd1FCJqA6AdjiRpcnQuEY0moiVEtGTHjh1Oyq1QKBQKh/jtjB0K4DVtBSHHMPM0Zu7GzN0aN5aGgSoUCoXCI04E/VbELpLQEuaLGAzFEbON23MT5quvvsI336j0KAqFQqHHyYSpxQDyiagdIkJ6KGIXQgAAaAsvHItIzmnB+wD+HxEdq/0+D8BdCZXYgtNOi6TmVvl7FAqF4gi2Gj0zVwC4ARGhXQzgFWZeTUQPEtFg3aFDAczWL/zLzLsAPIRIZ7EYwIPaNkWasHr1ahARVqxYkeqiKBQKExzZ6Jl5LjMXMPPvmHmCtu0+Zp6jO2Y8M8fF2DPzs8x8nPbvOf+KrqgJvP766wCAV1991eZIfxg0aBBuuSUSzbt9+/bo/RUKhTlqZqyiVvHuu+9i0qRJAIDBgwfjsssuw549e3y9x969e1FUVIRff1XTPRTpgRL0ioQQlrrI2s/uWbVqFS677DIcPnzY9bmbN0dyON16662e7i0oLi7GDz/8EP09depUvPDCC3jkkUcSuq7CG4sXL45+W4U/KEHvgRUrVmDbtm2pLkaNwqugLyoqwuuvv45vv/3W9bl16tQBADz77LOuzvvll19iTE3HH3882rdv7/r+iuTQo0cPqFTl/qIEvQdOPvlktGrVyv5AhS0ZGRkA4Fqjr6qqgn5y3XPPPYennnrK8pyKigq8+uqr6N+/P4YMGYLdu3dbHq+itxTpQo3LR++V6m6UVVVV1Xq/mkqi7z0zMxMAcOjQIVfnjR8/HgcOHIj+HjVqFADg+uuvNz3nww8/xJAhQ2yvLUYnStAr0oW0EfRebLwK/3BrunniiSfQuHFjz4L+vffec3U8AOzcudPRcUrQK9KNtDHdHDx4MNVFSDvKyspw8skn47PPPvP92jfeeCOGDh3q2XRTUVHh+p5GU43ZqMyrv0GhqKkoQa8w5dtvv8WKFSvw5z//2fSYRLVeIeitNPply5aBiLBq1arotuXLlzu+x+7du0FEmDVrVsz2qqoqy/KnSqP/5ptvQES+L6lZUVGhTI5HKWkj6Bs0aIDWrVv7dr3Vq1fjtdde8+16tZFffvkFANCkSRPbY6204AMHDuDEE0/E559/HrcvEIhUQSuN/uWXXwYAvP3227blAOIFdHFxMYBILiQ9Bw8eRHl5efT3vn37LK/jJ/v27cONN94Yd0/gyHO+9dZbvtxr27Zt2Lp1KzIyMjB06FBfrplKmBkqy6070kbQZ2VlYciQIcjKygIQES69evXCsmXLLM9buHChtNKceOKJ+MMf/pCUstYWSkpKAAB5eXmmxzz44IO211m5ciVWr14tjXcXwtRM0B84cACrV68GcKRTsGLcuHFxx/3222/SYzt37hwzSqhfvz4WLVoU7bS2bt2Khx9+OCkCf+LEiXjiiSfwr3/9K26f0Lrnz5+PXbvkGUP27NmDykpnSWJbtGiBli1bAqi+Gcxu6NevH8aNG+f4+KeffhpNmjTBd999Z3+wAkAaCXogYgYQAmPJkiVYtGgRbrrpJqxbt85U4Pfp0wdnnHFGdRaz1rB3714AkdFSIghB+fPPP+PMM8+MjhT0+/SaNRARdl999RWGDBmCd999F4AzQf/4448DADZt2gQAmD59Ovr3l691U1paiu7du8dsmz9/flTQv/rqq7j33ntjOgM9ixcv9mwyFBFDsmcS72ThwoUYPHhw3P6Kigrk5ORgzJgxnu4NRN5Pp06dsH37ds/XqKiowEMPPSQdlbjh448/jn43J+9z7ty5AID169cndN+jibQT9JWVlVi5ciWCwSAAYP/+/ejQoQO6du0ad7xoUGvWrInZvmHDhujfM2fOTGKJazbCbj5p0iRs2bLF8tjx48fj6aeftjzmp59+wmeffRYzQhDaq17Qv/XWW/jb3/6G0047LSrkAXdO0p9//hkA8Oabbzo+B4g4oJ3c54cffkCPHj1w0003ubr+3r17UVFREVVIMjIy8MADD2D69OkAgF27dsWMksRoRo84d8aMGab3Wbt2rekoacOGDXjsscewcuVKvPLKK67Kr2f27Nm47777cN9993m+hpHLL7/c9hjhiA+F0iZoMOmklaAXoXqdOnXClClTAMQ67fRx14B55Mb//ve/6N9XXXWVz6WsPegdpDKzi9Gxd8cdd7i+h+hshSb31Vdf4aKLLsLdd98dd6wTjV6wYcMGEFFMR+GEsrKyOFONUBr0iFGJ2YzetWvXYuPGjXHbGzRogGuuuSb6bjMzMzF+/Hhcd911AID3338/5njhrNYj3ruZSemnn35Cx44dTZ3o+fn50fYhM8tt3boVRITOnTtLzxeIzlmM/Pxgzpw5Mb9LS0vRu3dvvPHGG9FtwmSVSCd1tJFWgr5evXrRv2WOVL3JADAX9Pv37ze9R02KrX788cdtNe1E0Av61157LW6obHxP+/btw+DBg/Hjjz/GbHcS2bJx40aMHz/ecuEYN4L+k08+cXysnrKyMkehm0LIrV69GkuXLsUdd9wRYzPv2LEjfve738WcI571hRdeiNHo9RjNIKFQCF9++SWIKNpxiPuYvVcxX8BJWOxHH30Ut034puzSUoiRj1+RPJMnT47btnbtWnzxxRe49dZbMXHiRDz99NPR+73wwgu+3PdoIK0E/THHHBP9Wzb8NjqvvAh6Y2fhhocffjgaQZIoP/74I8aNG4cLL7Rapz0x9PZSZkaHDh3QrFkzDBo0CEC8k7Oqqgpvv/22VBs3Q3yTf/3rX3jggQcs7c4PP/yw4+t61TLLysriTB4nnHACcnNzY4SwEPT79+9Ht27d8Nhjj0mFJgA8//zzGDlyZEx902v0ehYvXhzzOxQKRe3Xr732GmbNmhW9jp3S4UQpmT59elynaDQXzZs3DxMnTow7VyQeM95n6tSp0tGMHTfffHPcNlE/KioqcPvtt+P666+PaceTJk1CWVmZ7bU//vhjTJ069ahdgS5tBb3RuQdEHFD6obGZoDeaePScc845nst37733moa37d27NyaDoh1CUNjla3HCG2+8gVNOOSWqKS1fvhzff/99XANiZmzfvh3vvvsuzjnnHDz3nHx5AX0H8Pnnn1smgHPjzCwtLXV8bCKCXlYvdu3ahSeffBI7d+7El19+KY37f/7556XXvPrqqzFjxoyYmbnCoai3M//yyy945plnYs7NyMiI+hv+8pe/4Morr4xGQ9lN+HI6+jQ6ZI0d+DnnnIPbb7897jzhS9CXo6ysDGPHjvUlwOHw4cPRb6EX7p9++mn071tuucXWR7Bw4UL069cPY8eOxSmnnJJQmezmXtRU0lbQy+jXr19MBIYTQW8cWsucY4KlS5ea7reb4NOnTx/TDIqDBg3C+PHjY7aJxiWzH7th27ZtuPTSS/HNN9/gnnvuwb59+9ClSxccd9xxlkJ43rx5uPfee6X7du3ahe7du2PevHk4/fTTcdlll5lex2laArd4FfT79u2zDPXs06cPevbsie+//z5u/+zZs6NCWYb+uiKkVz9KkHXaoVAoLvxXzAfwS+AkOtlQVg7Zd927dy8OHz6MV155xdEaApdffnmMRi8wdnBGU6ERu/1GCgsLTVNfB4PBGBmyevVqvPPOOwAiZjArs9+9996Lc88911VZfIOZa9S/rl27slcWL17MAGz/CbZt2xbdVllZGd1+3XXXRbePGDGCmZmfffZZvvnmm+Ou8+ijj3JOTg5zpLYzAL7ooov47rvvjilbgwYNovurqqriym4sm92+4uJiBsAFBQUe3hTzoUOHmJm5b9++Mc80YsSI6N/Dhg1z9D6N/9q3b88AOD8/39P5Tv/p341f/04//XS+8847pftuv/122/O3bt0aU64dO3ZE/96wYUPc8Q8//HD0b/FNjf9yc3Mt38Gzzz7LxcXF0W+7fPlyBsAnnXSSo3c0ZcoUaX0zvmM9//rXv+LaCDPz/v37GQBnZGTwCy+8wMOGDYu5btu2bRkAX3LJJdL7Gf/dcccdDIBzcnJMj+nfv39c/X7ggQcYiLS16dOnxz2TFVbHiX1LliyJ+b1ixQoGwNddd52j627bto0HDhzIv/76KzNH2uM777xjWzabci9hE7macsFu/JeIoP/uu+8cCwhm5h9//DG67c4774xuv+aaa6Lbr7jiCvES4/6tXLnSUug89NBDzMy8ffv2mO1CyDIzV1VV8e7du+PK9sknn/DEiRNjrqtn9erVDIA7duzo+j2J537mmWe4c+fOMWUTDRHwLqh/97vfMQBu3ry5p/Od/mNm/vzzz12dU6dOHcv9eXl53K5dO+m+8847z/b6P/zwQ8w3Kyoqiv4tE+SXX3559O+lS5d6egcAODMzM/p9haAHIsLe7hr/+Mc/YuqH1b2Ymffu3Ruz/corr+SVK1fywYMHed++fQyAg8Fg3Hn6c0444QTeuXOn5f3c/Hv++eelz1BaWhrTKenLY4bVcbJ3D0QEv931xf5Dhw7xDTfcwAB48uTJzMxR5eLjjz+2LZ/F9U0FfVqZbmShaFboh1mzZ8+O/q0fGloNxewiO4Rpo2nTpjHbxVD50KFD6Nq1K3JycuLOPeussyxzzIgyOolEmTx5Mh544AEAERuqMDu88MILcQ5qMdEI8D4hRZggkrk4ixha9+rVy9V5CxYssAyZLSkpMfWViFQKVsh8QwKZXV9MxmrTpo2lb8iMf/7zn3HX1gcirFy50vYabk03xnK++OKLOOmkk3DttddG66XRvGJ89tWrV6NRo0au7mvFyJEjYxzAwqS5ffv2uOfz8p7tcJOUr2nTplHfjJAvoq258UO54agU9KzZFPVCXGwDYiup1QfU73MTYiYq3iOPPGIbBaAvFxAJQ3z++eejAtqJoL/55psxfvx4LFy4EHXr1sUXX3wBICL0nAgCtzitrH7lJpo3bx5uuOEG2+NWrFiBrl274tJLL5Xub9OmjeX5eoFhVnajoM/Ozo7+LatLwpewefNmXHvttZb3l2GVVsIpTmfHiglxZp3Z//73P2mMf1VVlanPxE/B9tBDD0X/FrLg559/jgsq2LhxI5566imcf/75+PLLL6PbS0pKLNu78b3qAzPcpNnetWtXVNAbQ2XdhBC7Ia0EvTFUzQxRGWWCvrS0NGbG4X//+19TZ45eSDrNOwIgWvG2bt0q3a/XHI25ZE499VRcffXV0bKbVYxdu3YhMzMT8+fPjyuvnxNNAoFAdNEPt/Tr18/zffWN7qyzzopzVssQjcvsnYl8MGbo64uZ4CovL4/p9PVRNd26dYs7Xq9drl271vL+TnEb1/7ll1/iq6++QjgcNq2TQGRRl8mTJ5vmy9m/f7+0kykvLzdNk+CnVq+PehLvYM+ePXH3Li8vx5gxY/DBBx+gZ8+e+Oabb1BZWYmmTZvi6quvNr2+UZjPmzcv+vc111xjel6zZs1QWFgYs02MOETH4maE7oW0EvRONXohlPXakHjR559/ftzxZrlSPvjgg+jfbvKjC81Q1iD37NmD448/PvpbL8Dmz58fjWYQWlUgEMA555wTt4zekiVLcPjwYZx11lnRbc2aNQPgzAThlOOOOy46y9Ipffr0Qffu3W1nXlphFCi5ubnSWG89doK+RYsWlufrv7FZ1Eh5eXmMxiubBKQnGVFHbpQOAPj666/Rs2dPHDp0CF9//bXlsTfffDNuu+026b6ysjLpvcvKynydPWvF2rVr0atXr6hQPnDgQFw0k1Frf/rpp6OjXGMqaz1W8fr6tClGtm/fHpdmxWi6UYLeBW4E/XvvvReT6mD37t1Ys2YNli5dGne8mUavt0GbNS4RL61HCPp///vfcftk9nqBXmj/97//BRCpGPPmzYubaCQb3YhK5XY1Jyt27NiBcDjsygzz2Wef4euvv0bdunV9Kwdgn3xN1A+zXDZ2Gr1eWJlpzUZBnwrcCnrgSMeZ6GhP1nEdPHiw2gR9x44dsWjRoujvV155JS7kWSbo7eL+f/3114STt+l59NFHAShB7wmnppvt27dj4MCBMdv27duHwsJC5Obmxh1vNVNWYJa7/oILLojb5sciKUJ7NasYsnfhp4AXiLkLmzZtcm2K0aescIvMRKC3h8sQWpSZoLfT6J3w97//3dFMTTMaNGggzdvvFCLCaaed5vl8fVCCF2RzAQ4ePOirkHQzEnz77bfj3qfbyVxVVVVo2LCh4/Oc+EiME8GEoE/W6mZpJeidavRmE5MA784hK9ueET9Xw3Ij6JOxrq5eeH744Yc49dRTHZ8ryyiaCGbmMxH1JBqgWUPUC/o6deq4SrkgeO+99zBp0iTX5wnuuece9OrVy1M99KLJ+82vv/4at81v041YcyLZ/OEPf8DBgwejHbfTmetuvoPRRq8EvQMSnSVaXVRWVvo2q9FM0Mu2V8cC6m5Sx+bn51vud7vwi5nJRISWHnvssQDMBX3z5s2jf+fk5HiexZhInnTx/ho2bBjdds899zg6187e36pVK8/lcoqZRu+noK+udi5yC7ld6cuNv85ouknWUo9pJehry6LOZ599tm+r45gJLVmF8dN0c9FFFwGIJLDS41cjrKysxMsvv4wtW7ZIw/9kzz106FBceeWVcWGKo0ePBjPbmnb04ZVt2rTx/Cx2nbiVCUDWUVrNp9BjlX5h7Nix0tWs/Eam0T/yyCMYOXKkb/dIlh1bxrXXXovhw4e7OseNRm803XhZ9N4JaSXojdx///2ez/3www9tNU636Ieczz77rC/XNDMDGQV9MBh0pdHbhb09+uijYOY4u7zbRmhM5au/DhGhRYsW0pzpMudvdnY2Zs6cGaOZyxCCeMCAAWDmqHBt0qQJdu7cicsuuwwzZ85MmuZ45ZVXmu6TCXqnoySrBHfnn3++785vp2V4/fXXfb2HsY7dddddUjNbqhQ/N4L+22+/xYYNG5SgT4Q6dep4Oq9u3bro16+f7xVFbzf/xz/+EbPPOHvWKWY5w42VjYhMNfozzzwzbtvrr79uqZmaCR+3ESdr1qzBsGHDXJ3TuHFjaUpbgVPHn/i+06dPR+vWrREOh5Gbm4tXX30Vxx13nGNBz8xYtmxZNCzWrkMNh8Om+xIR9MbFz43XcDtz3Atesqnm5OREl3Rs3rx5dLRohvG73HjjjejSpUvcccl+XjNfjL7tPfHEE5bX+PTTT5Gfn68EfSJ4HeIJzdtvjc6q47jzzjt9vZdM0JsJIJlz2u7ZzYSPcXr5SSedZHsdfVhk37598fbbb1uec+6551qWz0mUlJ6ioiJs3rw57vvon/G8886zvEaXLl2iYX12q1pZ1UvZPqcCy6oOhUIh10vvvf76644j2QQy040dL774YrQOTpw4UTrK088tMX77UCgkddAme6lBs3ejF9Y33nijo2vJZuv7SdoK+tNPP92zoBYNPhFBL9NSZRpyKBSKW6DaK/v27cNFF12ELVu2xJluAoEAXnrpJel5MjON3bOb7TeGFooOZ/To0Xj22WexcOHCuHP0Hc3AgQOjC5uYYZerRJShYcOGmDZtWtx+p45wvdC1mkgjcLqIulsFRH+815FfIBBwpeEOHToUl1xyietIHi+Cnoiiz1hVVSVViPQdrbHuBYPBlAj6YDAovceUKVNickY5oUZo9ETUn4jWEtEGIpKqDUQ0hIi+I6LVRPSSbnslES3X/s2Rnes34XAYCxYsSNiZlojTRzbJStZo3nnnHXz99de+ROHUr18fb731Fu655564e5WXl5vmym/cuHHcNrtGYrbfqE3/9NNPACIRNldffTV69+4dd47bHC92kQlC0E+ZMiW6Fqse8a7tTHP6dxgMBmM6xERWCrOqV3b1wGudZGZXgl7M/3Ar6M3mk9hht1jKww8/HE0HYjzGqNEPGDAAkyZN8kXQZ2RkxOVAEukOAoGAdEW08ePHo127dq7uI8yqKRP0RBQE8CSAAQCOBzCMiI43HJMP4C4AvZn5BAA363aXMXNn7d9g30puwtq1a6NLnAlbqJ2GaMRsUQ/Z0NgsFlwWWSGrxMYYbxnGyV1OcBOmNXjwYKxatSpGa03UdCOGtbfddhsuuOACy1wgDRs2dBxZctttt9mmXBCC3sxH40XQh0KhmOOHDBkiPcdqKUQBEWH16tXYtGkT3n77bbRt2zaubFbnekHvdAYi3+fJJ5+U5in64IMPLB3GibBs2TLpdjuNPhwOR006skADvaAfMmQIxo0b54uNPjMzEy+++GLMNr18sBLMstGrGcKvlEqNvgeADcy8kZkPAZgN4ELDMdcBeJKZfwUAZva+sGqCFBQURKM0rr76atxyyy1xicHsMBP0I0aMiDtW5hQcN24cHnzwwbjMlLKhvRNBX79+/bhtVjHmzOzYKTp27Fh06NABJ5xwAq644orodvHsw4YNw7XXXosPPvggJgrJTNALISvKnJ+fj3feeScaw54oEydOtJ3BaifonWLU6J1o0/rveOKJJwKANB7/+OOPR5s2bTBo0KAY53GyNPqqqqoYwVdUVISxY8eiZ8+eMcd169YtZtT1yCOPAHCWcK1jx462x3Tp0iVmOU+BXqOXCXp9Wzz22GNjZpyHQqGYNiL8Qn5p9KeffnrMdxH1wk7Q9+nTx/F9RJ1NpaBvAeAn3e8t2jY9BQAKiOhzIvqSiPRZwLKIaIm2/SLZDYhotHbMEuOyaYkQDofxj3/8I2byiRPMBL2oTPqKaPww5513XnTYeNxxx8WURTbcF+YAqwZut0SiEWaWpl6QYaYhikby0ksv4ZlnnsG5554bc6xZIxLhnkLDSlTYekF0WHoHnhf06TBCoZBrIStCQDt06BCz3fit3aQHMJahdevWjuq3UaMXoyJjBNDixYtjwjDvvPNOMLOjjtquHKL+yEa74rnMBD0RRbcTUXT5PiDSTvVKlBhl+6HR69/33Llz8emnn8YIerPlNN0icunXdGdsCEA+gL4AhgF4hohytH1tmLkbgCsATCKiOJc6M09j5m7M3E1mL04Up8NdkW/bTNBnZ2dj586d2LVrV3Sb+DCiMett1PoG88ADD8QM0QXiHlaCXpbozOqZzEIuZZhdx6vpRiAESCL5bLwyatQoVFZWmmr+Tk03rVq1imYuNZpu7HjggQeipgbjjFXjty4oKJDu++STT/Dee+8BQFSwGZOONW7cGJ06dbItj95GX69evej3swr11ONE0NvVCaHxy6JV7rnnHnTt2hWDB8dad/UKi5kdPxgMSifDWZVHJqBlYZ36bz5gwACcccYZMYK+VatWePPNN03vY0SWqlpPKgX9VgD6udMttW16tgCYw8yHmfkHAOsQEfxg5q3a/xsBzAcQH/CaZJw6lIQDRUyZN2pP9evXR25ubozgFdcWmrl+n/78zMzMOOGp1/TMBP0ZZ5yBoqKiuO1WQmfFihWm+5xex2vUjUA05lQIesDaxCGyVDrJtfPuu+/i4MGD0XTQdojvmJOTg6FDhwKIXwXL+K31k/P0+/r27RvtaC644AIwM3r06IEpU6ZETS5nnHGGZV0Qsd75+flRwae3cTvNG2MmNEV6X6tjBCKtt/HbEBGOO+44LFmyBA0bNoyZifrOO+9E34l4j8Lfc+GFF0bPl9VH/Why6tSp6Nq1K7Zs2QJmximnnBJz7AUXXIABAwZYll9gVATdjBzslIVkJB4EIpq4HYsB5BNRO0QE/FBEtHM9byKiyT9HRI0QMeVsJKJjARxg5nJte28A/+dX4Z3itJds1apVTEOTxeuaXfvkk09GUVERLr74Yum1s7KyLK8nE/Rr165FixYtUK9ePezduzfGDunVKVevXr2YUYcbQf/II49EV2eyE/SiMadK0FvRtWtXLFu2zJEmHAgEolrvM888g4EDB6JHjx6254VCIfTq1QvMHJer3OhMbNKkCc4++2ysX7/eUfTVmDFjMGbMGBQXFyM/P980xn/o0KG46aabUFRUhJycHJSUlACIrWtONXoz9PMkrOpE7969TdNAG0NGzeZetG7dOqbsL7/8suUErbZt22LlypV47bXXcOmll+L666+P7jO25czMTOnMYVn7MK7uZjbJTSZ37Mx/KVtKkJkrANwA4H0AxQBeYebVRPQgEYlx1vsASonoOwCfALidmUsBFAJYQkTfatv/xsz+JHlxgdNkTmJhDoFesBodSLfeeiuGDh0a/ZihUAjXXXddXEz6f/7zHwCRxUvcCPrvvvsOBQUFUUGZnZ0d5zjzgrF8ZjH8ssp7ySWX4MMPP8RVV13lWDOpjmn3XujSpYvr8NtwOIyhQ4dG4/6XLVsWl7NIFpp73HHHYf369dG5FTJhbhdeKKOwsNBSi37ooYdARNFRpkyjd5NtVIZ+RGBVFjNN9csvv5TOanVCOByOSY8xaNCg6GgciAQaAHJfjdF8xMyO66po81YavVff1C+/JCeOxZGNnpnnMnMBM/+OmSdo2+5j5jna38zMtzLz8cx8EjPP1rZ/of0+Wfs/fqWNaiArKytm+bPhw4fHRQhMmTIlzuk5ffr06N/GyvL3v/8d//nPf6IOOzNtZejQoWBmtGvXLq4hWAl6mSAdPXq05X4niHu+9dZbWLdunWkYnZkQ7NevX8xSi0Y+/PBDTJgwIRr149Q0IMxTZiOimkiXLl3ilogTGL+PPqWCX5lLZehnFRvzIAmBpL9/Tk6Op7QFAn0dtuo4zQS9WUfjdtF3IPLs9913X/R3//79UVVVJf1GxlxJVVVVUkEv08CFP0AIc5mgN+s07NJjiFGX36TtzFgr2rRpEw2LFJVT2Pv05OXlRYeVZoL1iiuuwEsvvSRdpNmIG41e5oDVm0GcCnrjIhRCo8/KyrJM2uZ1slm/fv3w17/+NeoIdaolnXjiiWDmmEildMNKaxeRKHYpI6yu+/rrr2PQoEH4v/+LWEeNzmghkIymo0SjU8TI141Gv3DhQnz//femxy9YsMCX/Ppm7cQ4oclM0MvOf/zxx/Hwww9Hw2Zlz22m0dvZ4P0KQzZyVAp6vXPzmmuuQVVVlWnGw0mTJiEnJ0c6exSI9PjDhg1zJBitBL1ofLfddhtWrVolnepuZk/95z//aXrPGTNmxMRxP/3003j00UdNV4MSjT7RVLBvvvkmZs+e7eviz7UBK23dStAPGzYMW7ZscRV7bUTUp9tvv10aEikz3QCJC/p58+ahU6dOUtPiY489BiBewPXu3dtyAaBAIJDUdMThcBhvvPFGNHUzMzs2tzRs2BB33313tHyy9yebM3PVVVeZrj8tSHQpRzOOGkEvGtkll1yCgoICDBs2DL///e9x3333WWrHl19+OX799VfXyZ1kGHt+fTyxaPzhcBgnnHCC9Hx9GYgInTt3RteuXaUTqgTGSR2NGzfGHXfcYdqIvv32W9x8880JC+i8vDxcfvnlCV1Dz9atW31d1DzZyOqUPlZchtelDMW9nKatMCbaSnRiUbdu3fDtt99K53sIv5fTiJbq5OKLL452NsFg0LFGb0QIer0ipjcNCXNkVlYWHnnkETzzzDMJldsLyc36U4Np0KAB5sypltQ7UfQa/apVq2L8BE5iu42ag5h5a6UFGPPQ22lvhYWFliOEVNG8eXPbPPM1Aa8avR/YjSpFBlPjcU7NgMFg0NKcIrt/Xl4efvrpJ+maAjWB8847DzfeeCPuuusuz0t8ig68ffv2UWWkc+fOeOedd/Doo4+iW7du+O9//4uWLVsiFArF5c6pDo4aQX/eeeehV69emDBhQsrKoG8IRq3diaA3avQCK40+EAjEaPTJzuiniGD1HZMl6J2YOhL5/pmZmZYLn8ueKzMz0zRQoSYQCoXw+OOPAwD27NkT3T5x4kT8+c9/dhX0oD/2+uuvR9u2bTFixAhkZmbi448/jprlzDoUY8oUPzlqTDf169fH559/7igfR7Jw0vitjtFP8JEJepkjJxgMxnQE1bH4hEJOsjX6ZGNXd2SJ9BKN069O9KanG264AQBc5cnSt8k6dergmmuuiSpnZ599dvT9maW8MKbK8JOjRtDXdJwI+rp16+K5556LO06Ee8mm/QeDQbzwwgvR30qjTy6pMN1U15J5M2bMiI5Ezz333Lg1amWC3g/fVnXyxBNPYNasWQiHw2BmRym0Zd/TqoMzc/om810pQV9DEB/fywQjobFXVVVh+fLleOONN6L7AoEAmjZtiq+//hq33HJLrdKw0o1ka/SJXHf06NGmC9MILrroIqxatQoVFRV4//334yLDZPb72ibo//SnP8VkcXWCcDjr56RYtbMLL7wQs2bNiovASdYaxcBRZKOvKQwaNEiay3zcuHEoKyvDuHHjXF9TL+gbNWoUM9NQNP7u3bv7tpKVwhtCMLrNRmqHHxq9SOjnBDOBVNtNN15p1KgRDhw4gKysLNx1110ArEfORIQrrrgiLs99MlGCvpoxWw81KysL48ePtz1fZuLR534HYp1ybhYgUfiHTPjee++9aNeunemiJYmSatt/Omj0XvGS8kC0ze7du7tKROgFZbqpZcgEfZ06dfDWW2/hf//7X9zxqcgHr5CTmZmJUaNGVZtNvbpJBxt9dSI6xocffthzaKdTlKCvZZg5bQcPHixN1yBLpaBIHiLySZYfPVmIkVyyps87RQl6d4j3lcwZwAJluqmlWGmFLVu2xK233mq5TqsiOTz44INo2bJl0swzMv7+9787Tp+cTGSmm6PBRu8V/QImyUZp9LUMJ3ZYIsLf//73hJfSU7inTp06GDduXLVoaYKsrCzHS0cmuxxGjjaN3sliNoInn3wSAwYM8CX9uB1K0NdS0tXOq6i9jBkzJvr373//ezRv3vyom7exaNEiy9nDek444QTMnTvXcSrvRFCCvpYhko3V5GnliqOTcDgcTeBVVFSErVu3HnUKSUZGRrUIbrccXd1tGnDhhRfi5ZdfrlULdCiOHmp7mod0RQn6WgYRVaujT6Fwg10qZkVqUKYbhULhG0KjVxP1ahZK0CsUCt9QppuaiRL0CoXCN8Si3lbLBCqqHyXoFQqFb9x0001Yu3ZtyidvKWJRgl6hUPgGEaGgoCDVxVAYUIJeoVAo0hwl6BUKhSLNUYJeoVAo0hwl6BUKhSLNUYJeoVAo0hwl6BUKhSLNUYJeoVAo0hwl6BUKhSLNcSToiag/Ea0log1EdKfJMUOI6DsiWk1EL+m2FxHReu1fkV8FVygUCoUzbNMUE1EQwJMAzgWwBcBiIprDzN/pjskHcBeA3sz8KxE10bY3BHA/gG4AGMBS7dxf/X8UhUKhUMhwotH3ALCBmTcy8yEAswFcaDjmOgBPCgHOzL9o288H8CEz79L2fQigvz9FVygUCoUTnAj6FgB+0v3eom3TUwCggIg+J6Iviai/i3NBRKOJaAkRLdmxY4fz0isUCoXCFr+csSEA+QD6AhgG4BkiynF6MjNPY+ZuzNytcePGPhVJoVAoFIAzQb8VQCvd75baNj1bAMxh5sPM/AOAdYgIfifnKhQKhSKJOBH0iwHkE1E7IsoEMBTAHMMxbyKizYOIGiFiytkI4H0A5xHRsUR0LIDztG0KhUKhqCZso26YuYKIbkBEQAcBPMvMq4noQQBLmHkOjgj07wBUAridmUsBgIgeQqSzAIAHmXlXMh5EoVAoFHKopq3t2K1bN16yZEmqi6FQHFUcPnwYW7ZswcGDB1NdFIUNWVlZaNmyJTIyMmK2E9FSZu4mO8dWo1coFOnPli1bUL9+fbRt2za6wLei5sHMKC0txZYtW9CuXTvH56kUCAqFAgcPHkRubq4S8jUcIkJubq7rkZcS9AqFAgCUkK8lePlOStArFIqUU1pais6dO6Nz585o2rQpWrRoEf196NAhy3OXLFmCm266yfYevXr18qWs8+fPx6BBg3y5VnWhbPQKhcI1s0pKcPfGjfixvBytw2FMaN8ew/PyPF8vNzcXy5cvBwCMHz8e2dnZ+POf/xzdX1FRgVBILq66deuGbt2kPsgYvvjiC8/lq+0ojV6hULhiVkkJRq9di83l5WAAm8vLMXrtWswqKfH1PiNHjsT111+PU089FXfccQe+/vpr9OzZE126dEGvXr2wdu1aALEa9vjx4zFq1Cj07dsX7du3x+OPPx69XnZ2dvT4vn374rLLLkPHjh0xfPhwiOjDuXPnomPHjujatStuuukmW819165duOiii9CpUyecdtppWLFiBQDg008/jY5IunTpgr179+Lnn3/GGWecgc6dO+PEE0/EggULfH1fViiNXqFQuOLujRtxoKoqZtuBqircvXFjQlq9jC1btuCLL75AMBjEb7/9hgULFiAUCuGjjz7CX//6V7z++utx56xZswaffPIJ9u7diw4dOmDMmDFxoYjffPMNVq9ejebNm6N37974/PPP0a1bN/zxj3/EZ599hnbt2mHYsGG25bv//vvRpUsXvPnmm5g3bx6uuuoqLF++HBMnTsSTTz6J3r17Y9++fcjKysK0adNw/vnn4+6770ZlZSUOHDjg23uyQwl6hULhih/Ly11tT4Q//OEPCAaDAIA9e/agqKgI69evBxHh8OHD0nMuuOAChMNhhMNhNGnSBCUlJWjZsmXMMT169Ihu69y5MzZt2oTs7Gy0b98+GrY4bNgwTJs2zbJ8CxcujHY2Z599NkpLS/Hbb7+hd+/euPXWWzF8+HBccsklaNmyJbp3745Ro0bh8OHDuOiii9C5c+dEXo0rlOlGoVC4onU47Gp7ItSrVy/697333ouzzjoLq1atwttvv20aYhjWlSMYDKKiosLTMYlw5513Yvr06SgrK0Pv3r2xZs0anHHGGfjss8/QokULjBw5Ei+88IKv97RCCXqFQuGKCe3bo24gVnTUDQQwoX37pN53z549aNEikuX8+eef9/36HTp0wMaNG7Fp0yYAwMsvv2x7Tp8+fTBr1iwAEdt/o0aN0KBBA3z//fc46aST8Je//AXdu3fHmjVrsHnzZuTl5eG6667Dtddei2XLlvn+DGYoQa9QKFwxPC8P0zp0QJtwGASgTTiMaR06+G6fN3LHHXfgrrvuQpcuXXzXwAGgTp06mDJlCvr374+uXbuifv36OOaYYyzPGT9+PJYuXYpOnTrhzjvvxIwZMwAAkyZNwoknnohOnTohIyMDAwYMwPz583HyySejS5cuePnllzFu3Djfn8EMletGoVCguLgYhYWFqS5Gytm3bx+ys7PBzPjTn/6E/Px83HLLLakuVhyy72WV60Zp9AqFQqHxzDPPoHPnzjjhhBOwZ88e/PGPf0x1kXxBRd0oFAqFxi233FIjNfhEURq9QqFQpDlK0CsUCkWaowS9QqFQpDlK0KcRs0pK0HbRIgTmz0fbRYt8zz2iUChqJ0rQpwnVlWhKoUgGZ511Ft5///2YbZMmTcKYMWNMz+nbty9EKPbAgQOxe/fuuGPGjx+PiRMnWt77zTffxHfffRf9fd999+Gjjz5yUXo5NSmdsRL0aYJVoimFoqYzbNgwzJ49O2bb7NmzHSUWAyJZJ3Nycjzd2yjoH3zwQfTr18/VNUoPH8aKffuwZO9erNi3D6UmeXhShRL0aUJ1JppSKBJBJhQvu+wyvPvuu9FFRjZt2oRt27ahT58+GDNmDLp164YTTjgB999/v/Sabdu2xc6dOwEAEyZMQEFBAU4//fRoKmMgEiPfvXt3nHzyybj00ktx4MABfPHFF5gzZw5uv/12dO7cGd9//z1GjhyJ1157DQDw8ccfo0uXLjjppJMwatQolGvtqW3btrj//vtxyimn4PgTT8T8FStwSJt8eogZmw8exB7d7N1UpzNWcfRpQutwGJslQj0ZiaYU6c3NN98cXQTEDw4zo92JJ+Lmv/0NIQCVAMR8fCEU29Svjx49euC9997DhRdeiNmzZ2PIkCEgIkyYMAENGzZEZWUlzjnnHKxYsQKdOnWS3mvp0qWYPXs2li9fjoqKCpxyyino2rUrAOCSSy7BddddBwC455578O9//xs33ngjBg8ejEGDBuGyyy6LudbBgwcxcuRIfPzxxygoKMBVV12FqVOn4uabbwYANGrUCMuWLcPd//wnZj7+OO554onouVUAduq0+lSnM1YafZqQqkRTCoUVh5lRXlWFSk3brcARIS+oArC1vDzGfKM327zyyis45ZRT0KVLF6xevTrGzGJkwYIFuPjii1G3bl00aNAAgwcPju5btWoV+vTpg5NOOgmzZs3C6tWrLcu+du1atGvXDgUFBQCAoqIifPbZZ9H9l1xyCQAg/+STse3HH+POr9Cll1m4cCFGjBgBQJ7O+PHHH8fu3bsRCoXQvXt3PPfccxg/fjxWrlyJ+vXrW5bTCUqjTxNEQik/l3dT1Ez0y/g1DAYBIuyqqPDtm0+aNMmfggJYsW9f1KRhxSFmXHjhhbjllluwbNkyHDhwAF27dsUPP/yAiRMnYvHixTj22GMxcuRI0/TEdowcORJvvvkmTj75ZDz//POYP3++p+sIRKrjcCiESkmStZCDRbzvvPNOXHDBBZg7dy569+6N999/P5rO+N1338XIkSNx66234qqrrkqorEqjTyOG5+VhU8+eqOrbF5t69lRCPg0xRleVVlaitKKixkZaORHyAJBJhOzsbJx11lkYNWpUVJv/7bffUK9ePRxzzDEoKSnBe++9Z3mdM844A2+++SbKysqwd+9evP3229F9e/fuRbNmzXD48OFoamEAqF+/Pvbu3Rt3rQ4dOmDTpk3YsGEDAGDmzJk488wz445rnJkJo0gPAGikW9Uq1emMlUZfi/F7gWZFzUcWXaUnWUv6eSWTyFbYBwC00LTjYcOG4eKLL46acERa344dO6JVq1bo3bu35bVOOeUUXH755Tj55JPRpEkTdO/ePbrvoYcewqmnnorGjRvj1FNPjQr3oUOH4rrrrsPjjz8edcICQFZWFp577jn84Q9/QEVFBbp3747rr78+7p45oRDCgUD0WTOJ0CIcxm+6xczFWradOnVC3bp1Y9IZf/LJJwgEAjjhhBMwYMAAzJ49G4899hgyMjKQnZ3tywIlKk1xLUVodvpGXzcQqJa84IrUEZg/P87GbYQAVPXtG7PNTilIVpri0sOHsfngQei7JgIQRMReL4RirmFNV4U1Kk1xiqjuWakqbt6edJwp7CSKynhMKifT5WZkoE1WFjI1e3UmEdpmZaFz/froVr8+OmVnKyFfDShB7wOpaEjpGDfvp2BO15nCsugqPbJIq1QrBbkZGeiUna0EewpRgt4HUtGQ3C7QXNO1W78Fc6qFW7IwLuOXGwwiNxSyXNIvHZWCmkZNnxmrnLE+kIqGNKF9e6mNfkL79nH22IG5uZixfXv0WCFEAdQYe76VYPZSxnQWbsPz8ly9E6eT6ZgZ5CAkUBGL0Q8hJoEBSMroxYtfVWn0PuBWu/YDswWaAcRpxk9t21bjtVu/BbPZu2egRo5okomTyXRZWVkoLS31JESOdraWl8MYByUmgfkNM6O0tBRZWVmuznOk0RNRfwCTEXGWT2fmvxn2jwTwGICt2qYnmHm6tq8SwEpt+4/MPBi1DLuIBSvtOpnINLu2ixbFCXWzpluTtFu/UzjIvokg0RFNbQtrdTKZrmXLltiyZQt27Njh+/33V1bi14oKVDIjSIRjQyHUCwZ9v0+q2GYxgSvDpUB2QlZWFlq2bOnqHFtBT0RBAE8COBfAFgCLiWgOMxvnIb/MzDdILlHGzJ1dlaoGYQxjlAkJP2elJipE3AjvmpQHx+/OUv9NZB2IV7OQk/pQE7Ez92RkZOCLunVx9/btvnZgR0MY8IBFi6R1rE04jE1duqSgRPE4Md30ALCBmTcy8yEAswFcmNxi1RycOvXczkqVOUf9cEg6Fd5mQjRVTluZk7FOIIARxcVJK4eXEU26OnmTFaXk9H3V9GABK2pDnikngr4FgJ90v7do24xcSkQriOg1Imql255FREuI6Esiukh2AyIarR2zJBlDx0RIhlPPrFGNW78+YSFiFX4n3GxtwmEUNW2Kuzdu9L2jSQTRWc4sLEQZs+XUfjvBoH8WM7yMaNLVyZusDszJ+0p1vUsUM39ZTRqx+OWMfRtAW2buBOBDADN0+9pos7WuADCJiH5nPJmZpzFzN2bu1rhxY5+K5A/JcLSaNapSSWIk4EijcKL1iEons4AyIpVwQvv2mLF9e1I6Gj+wEzpOBINdqgCvGlcqHO+J4FRTTlYH5sQpng6jpJqeZ8qJoN8KQK+ht8QRpysAgJlLmVnUiOkAuur2bdX+3whgPoCaYbRySDKGZW4bT8Ng0JXWMzwvLy4KQH9vrx2Nn+gFUKMFC9Bo4cKoMDLTwkU5nHRIVmV2onGZCchUDdO9mDbc1JlkdWBWI0xRHrvvXV2YmVNrq0lJjxNBvxhAPhG1I6JMAEMBzNEfQETNdD8HAyjWth9LRGHt70YAegMwTyZdA0nGsMys8Zh+DCJT4Txu3TpX92gdDrtuQH5rq3YZGM0iuVuHw5hVUuKoQzIrc5tw2FbjshKQqRimezVtmNWZouJiaQdmjPjO0LYngv59ybAadVXnKEn2jq8uLsaoNWt8MymlstOwFfTMXAHgBgDvIyLAX2Hm1UT0IBGJUMmbiGg1EX0L4CYAI7XthQCWaNs/AfA3SbROjcfvYZmZVmhW5XdVVJgK59LKSmmFsdI8zRpQbjBYLdqqnVmFAamw31dZiXHr15uep3+uRDRvO1OCVX1IRmP2atowqzNihSej4DJOlvJr8pR4X26uVt3OTNk7Poz4NMteTUqp9kM4iqNn5rkA5hq23af7+y4Ad0nO+wLASQmW0VdqQgz08Lw8fL5nD57ati0a4x4gQm4oJNVWhQAzG+LKwgTtQj5lIW+TtZV0kv1+nIwoZLH/Zpq8QC8YEgl59Wqv9iP0UlY/vZanoUl90qMXXEahdojZMgTVbVsymythJAj4Nkoau24dpm3bhkrtuqObN8cUrZ7rcTPK9Ttaqzrkz1GVAiFVMdCzSkowbt06lFZWAgDqEeEAc4ww21dZiTLE5+/WazZXFhdLr/9jeblpo5M9l50QtGvYm8vLEUREM2zjUIDqyxfQzvWT3GBQ2tl5+a5eJ2/ZNWY7wWhWP80EtlV5ZpWU4DcbIS+wElxm+7y0JatJbHqqLK7hhrHr1mHqtm3R35UApm7bhnUHDmBDWVnMd3DaCQG1M1rrqEqB4GUInOhQfFZJCa4uLo4KeQDYbxDygkoA9QMBqf13eF4eckPyfrlhMBhnSxy1Zo1lWYfn5UUruHDQmh0/q6QEjRYswJXFxdHGIJ7GyRDUOGz1W8jrRyN+IDP7ECLP6jVyxWuk0IGqKoDZtRnq7o0b4TStVutw2LUz1qysV1rMe7CKCDPe0w8T2DSdkNfz8e7dcd9hYG5u3DvOAKLplQV+R2tVV0qOtBX0soritld1alezqpRuGhwA7KqsNLX/Ts7Plzb4csiH3Vb2bDfPNnrt2piOyoixszS+D1mUTCLkBoPSztAv+7jMgSjertfIFSdKhlk93FVZ6doB7FRTFILLrU/D6vp2EWEzCgvjHL+CTCIMzM31xZ7tVKE4UFWFuaWlce/4ucJCPNuxoy+OdyfRR8kU9mm5wpRs2jUBqBcMYp9EYIlIDCNmoX7CXCHMGIRYm7J+ireTFYGclEX/bMbhv5lJBwDYsNKQwMmzuTGziFWNZO/eCcIUZIfZ9HkxcpJ1qk7NS0ZmlZRgRHGx6fczXtdqur/ZN9KvBmX1TazqhAyrMFVBEMCMwsKY8juxuc8qKUFRcbHt97Iqd6OFC6XmqNxgENmhkC/vITR/vqfRY24ohMn5+dI65tQnITsWME/JAXj7znqsVphKS0HvpJILrPJuWAlpu7UwRSMat369rUNMz4u6hucUsljNvo1mmjFWTKtnywBcjULEfTb17Onq3RupGwhIOwjRkVoJ7EYLFliOOqw6CLPG6+RZjNc1+mMCgGk0FRDbuM06iqKmTTG3tDQm7bT+t+ydOOlwZUsOytC/o4bBIPZWVTla9Nvq+mb1TxhKzPY5Ka/AaKN3QyYRnu3YMTpS1H9TgVWdssrvY/Xsbp4v7vyjbSlBp8NWAlDUtKmpYLVyuthV9EoAVxcXY5cLIT+meXNPoXq5FpkAZcPfWSUlph+e4F7IA8DA3FwA3p1LYlgszCVB3faZhYVgm9BWKyEPmOdXMTMRzCopcdRhya5bpqsbVkKeEB8pZDQfFDVtGjeLeeq2bbZmDbv4dcCZU1E258GJkAfk9mdRp82uEEAkWshrefVMKSjAmObNo3WJAIQdhoyKiCMr06WZf8/OTGf2HA2TmNHzqNfoAXNN0asZwgu5wSB29uljeW8vZgvZfcqYpc9kplE7IRGNngCcnZMTjYRoGAwCRNhVUeE4LNJqVKO/j15jMiur1TsyIzcUwq6KCtcRRQRYPqPT9ynev5nJwGsGyURGaHpyQyEMadIkZgEcNzgtr9kIzUtbFt/G6vllWrjVaPlFbUFvWXvVjyK8cNSZbuxsqzIIwPXNm6P3McfEhULur4Z3pK8wVjZQow29YTCIg1VVCZdRmJqs7P1GX4Ss/MnoHJ00cjObrx6jDdSt/ySZmD2jmzK+WFhoKtAB6zkFZgLSz3dkVX+sMLOZG7FSjqxs44kQRGTUpjepWd1HlMfMpJuInf6oEfT6ylq3mgS0X+g1MjtBmYjmbcWY5s3x9LZtUnNDPSLsO/NMSy1YjEhmlZRYdhheMDoOjcwqKcGoNWtMzQoEYKbB8ejEoVidyBq5U42aYD5Bykx46OdFGIWw+O3USQ5E6oCdCc0Lsk5Q1jGZCXPhp6op0sCqPInY6Y8KG73RlrifudY8nD6MzS49QBDW+UHssHonU02EPBCx288qKZHmRAGAvVVVUVvs8Lw8S9uwFyoBjCguxliT3D7D8/LwbMeOUn+FGK0Zo2NqkpAH5P4N4fuwg2E+c1h2XX17Eecbrwc4F/IZiNSBZCAL35X5VqySo9Wk7KJW5UlWOWuLLLRFJiCTb1n3B31ueLthX6LCyes70U+HbyBxlon9Aqu4Ya8wIp2RPtOl3tE3PC8PO/v0wYuFhXEx8FO3bUNw/nyMXbfOtjNNBk7ehGjkeie82aQfN8iEh9t3IHNh6tc3aBAKOY7E8YK+szJzdpq5MoXG73d99IpZeZKZ36dmPLkP1NaFH3KDwZioCjNE/o9UrrQp3rFZJJH+G8giSMxm9rrFakESce8J7dvHVe4qIBqx4oY24TBeLCyM60DcQIifZalHNHK/ZxGbCQ+37UVWN/Uhr05DiM/OybGMEjND31lZJWszIp5f1MeawMDc3GrPgpo2gr4mDc2ckkmEctibYuoGAhjdvDnu3rgxpeYG8Y6dDjuNWR5lM3tlEJxrfmZhk0XFxb6M6DKJYvIGmZmu7KhExLyhXyoxNxSKa+R+jjaswof9ai/6HDdO2FBWFjPqEs8vOlIz05s+/YTTsueGQjHCc3heHsY0by499pycHFNheI7HzsmMuaWl0fJU12IlaZPUzG6GaCKEiFCRBMfuIWYcsnFetdG8+V7D0qywm/SlR68ZOlnI22oikl0EhNs3LVuWzq5DdBoBYszg6DalhZ79zNhnE1Hh58iUcUSoGJF9Q/FO3ETHuPUZieezSrhn5iQWnYqYW2B339KKipjU0gCimStlGS1nlZTgj2vWxAVxbCgrA3xK2QyY+0ySmTU2raJunITYeWFM8+aeZ9glggjdSka2R0CeRVNGdjCIpwoKpFEPskyWgH3ctl/x2UBsxJKTSBrRuPVpoq3QR0LYhRvaCUkC4uYJ6Ge6+v2traI4jDM+RRijMYW2n+jDEe2EmdM0HXbltAqdzgoG4+ZrJHv+jDEKauy6dXHv2+m8AT1HVXil3x9I2GSTEYNbWzCGJgrM4pbrBAK2YX5+fStRNiC+c7GjHhEOM+OQzXH6clt1UOK47E8/rTGhvcaJeHrcfj8ZXmPjxb2shJnTVAF+KQ1eYu7tUlwYMabz+HzPHlMl0m1M/VERXgk4T4PqFGGOsBpOWznYUk3dQCAhB6KAAVdTvZ2E+Ylvlajtk7VrebFt73cg5I0mKatwx32VlRi7bp1jc1i1QGSaSsPt95ORyJPKwiYbLVgAmj8/8s/kPKON3q+IGlEeN3my/ti8uSufjd4MdXVxsaWlwE8zXloJejEU9Tr0raet8gQcsT3evXEj6pkIo3ralGUhSGuayBfakqwhZMDdx99ssIN70aJkztqDCWr04t372SiCgGkkhJnNG4jYhKdu2+bZhp8MSisqTPP51IRINVEG2boNZjVjn2T5TPKpc/1RM0XaIRy9UwoKpOHGTrCrJ34GmKSNM9ZNvhcz9jPjUEVFjJPSSphlBQIxTqWaNNsyiMiKVKI8ucEg6mj5WEQGwiqXjaPtokWeHcP6yAm9LTQREwfhiIbtZoUgO4STbnN5OYqKi/H5nj1RJ15NEI5ukDlLxQIhbma9JgshzMatX++47YrOS5BouzeWx0k9KtO9UzeJC51iTHiX8PXSxUbvp3PPKW4TGqW6YWUS4ZpmzaIRB17wYpOVnSNGTok6z8W1cyXpc/1MFXGOlnStNvlqErGfJ+M6suvOLCy0tFNb4bf/TJTHqfnGj9TcZowxWdvWiqPCRu9U08okisbsJopsaGU23GoTDqdcezrEjKkJCHnAW4M3W+jbjwgpce3Sykowc1xsul/+GrH8XG1COP38uE4yJuqJb+c1ou3H8nJfv4nw9zi1+QuZM6F9e1/Ntufk5LgW8nakjaB3Ys8KAHi2Y0cAcDXJQ4bZjMOBublxH10c67SxpHL2a23mMCKhoPoJKE46NdE5+DkpJhl4Kd0+zRSZKJXw3weVGwxinEnuIickY5TRb/nyqJPa7n2LfPt+l2XRb7/5vqxg2gh6JzMWE4nQ0CO0RSDyoWn+fIS0SAFjPKx+dqITodMmHEZF376+JwU7WjAu4O0k7YLoHLJ9StGQDNqEw5hRWOg6ukQsFOJHQ3cSr+6Gg1VVScl2mQj6kZuTkm0uL8eI4mJkWwRsuOVAVVVCHaCMtBH0w/Py8FxhoeUDtfbBpqePbdVnzBOVQpYFUERqOBHeQlAdV6dOtUXxBBGxCdaUpE+JIhofzZ/vyDwkvmF1OVrdvmXhyL5740YUNW3qSQlIdgo3sXiMG2rKXINEYUC6FjUBuKpZM09CtlQSWZQI6dGycSS00qpCi6RRXgWoPvFUUXGx41GB3pbnRJhuLi/Hx7t3V0v+bEIkz/uUggLbpeeqCz86OLfvrtHChZbnyMwfXst5bDBoqgHK0MdeP6UlZcsNBuPKlMqOmhExObhNXJdMZcavJHpeYQBPWaT+BqzLKJu74pW0EPSyGFwjucFg1GzjVYAKc43bXOZ1idB20SJcWVwcE5aVbOoR2TYkYc4CjiRZSrWw13+f3FCoWhqsleZ/Tk6ONNe913pUWlmJAx5NFnrnc4XOJBMEPGv7fiEmW7nxCSRTmUlGOhS3WD1fbjCI3yzKqCZMGbBLNFU3EMBkLWlRImabz/fs8TwDU7bAQwaSp3XUDQSQFQw6akjGvO41KVa8rKoKnbOz4zqs6pyctqGsDMPz8kxt+F6cpH5091W661QCmLF9Owbm5qbcBFepRT8prCmtrLSUW35OmEoLQW8nmKZ16IDP9+zBiASzW3rJZW6FiBLxWwsTk2ScajSby8txZXExGi1c6CoNbHVwoKoK8wxmLGEPrq70E5vLyy0XhUmGO9FL53GgqgpzS0vRs0ED38vjhkpE6vWLHpzH6Yybdu73IiRp8RWsBJN4uVOTlI0vUX4sL/d9VRmvgkfMOHSjFbpNpeAFmYP74927qzWnTHXWnTbhMHI8asSby8sxb/duX8pB8B7q+2N5edziGsYc/KnQ+kVdTUW6EpHp1Y4A4PsiJGkxvprQvj2ukiw0QYh4w5OVp94PGiYYS+w3QisUWfx+LC+PSatrTLFrl4HPDW4zAaYjuaFQQgtZ+zn7WqxwFTT872SmbAAR35lZ3nkgOdlm7Tg2GEQZc7UvJSlw8m1CSRippoVGD8h7aKsFk5OJ088kFlSuabHEmzVtTKx+s7NPH+w8/XTMLCxEtpYvRwh5AHjap1z9R7uQB44sk2hHPSJp1I1VTSLAVbSPoFK79ozCQnDfvphpshKU8RyrxdyBiPO/qGlT1+VJhNLKypQJeacY11/2g7TIdZOKPDfpTBBARd++MaveNJTkkklXsoNBaVx0TUC/CIxxVaKBubm2I6tE8tY4zctvRIzURA52vYav2q4cqwVjTM+xyHXjyHRDRP0BTEZEBkxn5r8Z9o8E8BiArdqmJ5h5uravCMA92vaHmXmGq9I7IJEoEbE+ac3u46uXSiCaD1wfzne0UNOEPEG+IpMxc6qTtB6JdNP6duamzYm2pV9fVpS7JkV41ST8DoiwFfREFATwJIBzAWwBsJiI5jDzd4ZDX2bmGwznNgRwP4BuiNSxpdq5v/pSeg2vKWoztXzyADBqzZqjQlvVY2fPPbrehv/UI0JWICDtJOsROZ4Z6kSz82tRcSuNv6HOXOO1zR2oqkKR5jMbnpfna3ppPwgBCLhYSzkZ+B1xAziz0fcAsIGZNzLzIQCzAVzo8PrnA/iQmXdpwv1DAP29FdUcJ3luZOgXfhYLiIiIALPV4quDbC06IdnULL01vagbCODpjh2xs08fjGnePCbaguB8+r/TeuBEWDrxHVmVam9VVXS+RSKrOlUC0cVPZNfxwxXp1flYASQs5BMpfzIibsR17WgB4Cfd7y3aNiOXEtEKInqNiFq5OZeIRhPREiJasmPHDodFP4LIc+MlgZB+VXrhfJzQvj1e8Tl7nCiZE1fYvspKlFZUJMX7XtuojvBNvxGrDwk7+ozt22M6VadiJJMIk/PzbY9zmtYjUR1V7yTUh0564UBVFa4qLsaI4mLU0VZ2E0qWVTmdtPF6RCkzxQYRWYjcSyeYSYQXJGsz+4FfbehtAG2ZuRMiWrsrOzwzT2PmbszcrXHjxp4L0SgzE8ARYeokVtdoCxO2Tr9t0iKnt5urVjBHG3Cq0xKkiucKC/GCx4k3ASAlMdvZWroNIDGTyjXNmsU0equ1X82Eo9/KgnHd3009e3qeGFUFLTKushJlVVWYWVhomYIjNxjEvjPPtF1L4mASzC5O3qKITBJ5o9ymvTZ+bz9xUvu3Amil+90SR5yuAABm1i+kOR3A/+nO7Ws4d77bQtphjMcVsb765E+y4Zg+SZmIXgggeSYNL9dlHHkWpx1FbYpHJwD1TKJcgoiE6LUOh1HUtCnmlpbGmCgIQJAIFSYNm3HEvu00ZtvMRl2PCAeZHaeuFTHkiTgbn9q2Da/88kvM8o/6JS5HaMscWt3D7N14RaYYic4skYge/ULh+0xCondXVqLRwoXYVVFheq/cYNB3Ja1uIIAAkaWTXp+OHDjiKBfJFp2UyWo94kSxDa8kohCAdQDOQURwLwZwBTOv1h3TjJl/1v6+GMBfmPk0zRm7FMAp2qHLAHRl5l1m90tGeKWV4PNjmbTcYBDZ2kSX1uFw1PSSCuoGAihq2tTTuq6pIgMA2TjA6gYCUtul1Tq9+nBAcazTRpcoGQAahEJJrwcEoKHH+7gdYRq/QaKdp9k9vNbbDADXNm+e8OS9IIAcw3yREcXFts+QGwxiZ58+cdvdhJDKQlCdklB4JTNXENENAN5H5B08y8yriehBAEuYeQ6Am4hoMCK+jF0ARmrn7iKihxDpHADgQSsh7xU7rcmq2iQq5AnAZC2uWZDsGX9BRJ5JxE7PLS2NdjKikvQ+5pgas1C5HYcB5AYC0c5SNqoS0RpCwxfPKd678X1nIOLrCMyfH3d8dSzifhjOJ+uFLEYldjAAaCY+N1fwIlDrGMwzTs1STsslW8jcjoB2fdEWZmzf7ur8DERs48I5nhsKYXJ+fpygdbKOrMghbzzXzahOFoLqB2rCVAIQIo4X2fqOyTQHOZ1MYbVQuQx9B+J1VOLVbOR2YWahXQJHGqGVsDNqo27fjV9kAjhk2OZkRGOFqIduNFmvi7Pr36PTd+hk5JCIJp+rad9u21kQkbUYnAhUp8qbcRQJeJNPsuvYkfaLgycS6uUF4eCbqTleZOijeJwuAef0CZxOpnAz6UI4ksR6q5Pz8z2FrNZxkANfRsNgMGbFLjvEcmv6c6yEjt4GDHifkGJ8NjfviAA0k9z3MID6gYDnBGINg0FH9l192UsrKixzoZshRlaB+fMd1de6gQBG20ShCPu214ADkTbCrTJVBXOt2ej4BuAoykivvYtrCCXEDX5PJEsLQZ9oqJcb2oTDMYtPm0VCmJVPdBIvFhbixcLCmG0vaNuscDOZws38AuOwfHheHhp4iFQ5wOx6bdG6gQBA5Fqjc5u3RN94vCgHdQMBXN+8ecw3c/OOWofDpg14V2UlRtvM3ZCVVuRLsuog24TD0rBFq1zoVlQCpoJVrLEg3s+0Dh1sVy8Ty21OaN++WrNKmnX2QnvfrCWX0zu+N/XsCe7b1zSKS1xTLIbkRAlxUzavpEX2SiDWy311cbHnSmyFUcgah3Mir/u49esxpEkTvFJSEnX8mdn+jL+F9mCGUSBbMTwvD+PWr3c0PBcpivVl2uVB47Mz+whnsdGvYLVWgF8ZGfWNRzyjlXM2AOBYg1PO+L0C8+c7vr/wp8iEcutw2FIrF046ADH5bexMbJlEtu/XDLdmOLM6Dhxpn2bmHpHW+PM9e/CUjynFzcx5BJgqTDLfg1gWsPcxx2B4Xh6GNGkSV069fBi3bp1nGWRVNq+khUavx261KYHbYbLQTvSV2MwZVVpRganbtsUIkNKKCoxas8Z2wV+7IZsQyE4XDnYjrBM1b9QNBDAwN9fUJJAbCqGoaVO8oq30pV9U2exebcJhx6Yvu7KJxiNGYSOKi5EdCsXNXBVUIRITrx/BGXHzjoTWKpsJurm83FQrJyB6f71JcFPPnrbfV/jgrMppzIJJiCwW73b+gpNlMs3KIbZPKShwlB3TiiCOmFfNOgz9EppGzNogI9LmxSQ442I4+vBKr5Fdwt+SipmxtQonti1CrIZYNxAwHYoRgBe1iRyJeNMB8/SjevOPkw9iFMgyxDXdakZuzRvGYfrc0lJpR5sbDGJyfj6mSzrAK4uLsfPQIWnaXaFF601fTtFPNtPPVDUOy40zV/WI92FmonNjAjIuxiHKaPeNGJEkc2IFMD12Hc1hAEXFxRiYm2v67uoHAjHmKOF7cmsSFfZ7KyVE9r6MI2WrZRvtMPqazMpu9UxW7/TH8nJTjX/atm0Yu26d7ajcDDu/XyKkjelGYJckSdawDlRVoQ5RnOffrnf1kpDJ2DnIJnt5uY64lpMIFCtk5g2rhVt2nn56zG8zE8GuykrL0dZ+5qh9V2Yq0YdSWkUx6MPtZKYWWSM9UFVlah5qGAyi0YIFMZ2TLATOyeI24t2KZ3EbjSFGhfr7OklNLNaTNasPuyorpfHf+vrkFJHHRl9GPfoZw8aQYD1enJGyGPQJ7dvHRcvY+bms4uat/CyVgKcYfrM5In6Sdhq9VZIkq6HcrsrKOIepWe+aiDfdqC2YmX/E8NNsAGuWusHO+SNmCsuQNYDheXmmZZBttxqa2zVesYaulakEsLZfitmwZudbNVKZZl5aWSkdhuu11+F5ebamBtm79SLM9KNCYUJwgpXTWvbNjPXJDXaavdH8JJsE51YwiXBEmQ/M2K5FWK5ZEMXwvDxc37y5NGhgQvv2vjpKg0hOEjMjaSfoZR92prYyjtVQrnU4bFsBAecCVYZwjOkxa+xVgGlopkxoOJm8QgB29ukTzdQJxOYFKmraFHdv3BhX+c1GGbLtVkNzJw3EifAbnpdnG/Vghtn+ekSo4zIvjD4L4+SCAtMIJ5l/x0qY2XUa4h35kZrYTLtN9Nr6d6NnVkkJGi1YEFnvQGKOEu3LLKLHDKt6Y2zX0MqmN98Zyyp8BcYOYnhenq/h3FYhnn6SdoIesNYYzDT+gbm5jq5t1gDsXmQAwLMdO8Z9VDvnlJlG4mWoq7+mCBOr6NsXrGXsnLF9e0zlv7q4GNmffmp6PVmnaVVeJ+GeTrWlyfn5jjpAI2Zl2M/syYEm/CUig6oxhJYlddBOmO21EbAMfyYJ6rNs6pmlOcsTxehLEhFxVkEKViPc5woLPXfweszMd0a/l2gnM7WQ5xHFxTEx9X4IT7/DKM1IOxu9HbIQLkbEhilCp6yw0sDNsLLBObEhWi2wLLDzF9gJQVnlPwzgsMlsTavrmZXXLqRRlmROthi5/vp2tl4gdpZy63AY4WAQh33Md6NPde3k/qUVFabCzGl+HDs/jFkiPz36LJv6sjpZqcop+jpp5qM5xBxdjMSqfZmluwAi0Vuy9AMyzO5h5vcyhlCPXrsWRU2bRmeSeyUZC4yYkZYavR1zS0ulDlknC/Ka9cBWdmwrG5xTjd0OO9+E3TXd2IsTsSsOz8vDzj59wH37xk0YE7ZT/bC6VIsTlw2x3ZraxDX8XirQSitzc/8quAuHtRLjTmbayr65XytVCQiIfi+rOiZMPQ1tNHbRXozmLTdhx3ajaD1m2v+0bdsSnqujD8dMNkeloHfToxsxs0HLpnmLUC+7j+nEOeVl9u1ME9OBDDdDSDO7opNyGstsfG47QeO0Qxb4KbjqEZmGgPpx/9bhsG9D+V2VlbbzD2T38nvqPSMygnMS6nugqgoHKys9h186rRtmbXhgbm5c/bVy3idKMtMSGznqTDeAuZnDSSOzMhn0PuYYR6YEO4ymC2MecrPwNTsTj9GEoC+fzIRkhlWUhnGIKyunFU4EjRthlKjgMi7MbfUOE72/EGZOUuLaIYILALmpzKyD8rqGq1VSMrPIJRn7mQHmaLirWdreRJQ1WRsWmS+N9dcsBbRZOG5uMIgyZkftqDoXRk+L7JVukWWiq45YVickkiXP7XVl+cX1Hczuysq4yiwWVDcKPbPMgW7L6cTJ6OaaiTgt7e7jROg7vb8+lzm5SKsgQ1aXnXZQTuofAagrSe3rNubey3MIzN6rl6yPVteTCW6zNR+MGVX1PhmZuc5rWc1I++yVbvHLLp4MnA713WoDTiIN9KaUnX36YIZhKnpuKBQj5PW2Z7uZpU6xS2zl1oHlNVGW3X1ktneZjdhJKF7dQACTdfM1zEKAnTRWs7rsxJ8hjjPO3NWTASBDJ+SBI6kP/M4iK+rn2HXrENLCMUPz52PsunWOZti6wSrZnExW6BO1GWWI8V0/VVAgfS/CgVwdHJUafU3GaY5vt9qA2XWd5rY34lRT9ZRX20KjfdHD4slj162LS0AlVoAS0TxmC7iY4UajNGrTdvcyG31ZrRyWrBGpsexmSdTEc7s5PpGV2MY0b+6bqRTwf4RgxGx1Mz+/W0IrTCmqFyc2Ui+aSyJ+CRlONHWvGlYbi3cgRiBuGsaUggJfhQLgzkbsJDzWeDxg7QfSryGcyPJzTsqiv65Ztk6zEFOzTkvUC68rsU3bti2aj8cPvKRKcIMINDAKev08jGSiBH0NQ1bhjNqnl0ZtVZHdOhgB845Dv0qVV+Fj5Rj26uR1K2zt8LvjNGI1FyGVJka3z+1kvoNZfiYrB6/fy0C6mZfhlUQcyImiBH0NI1kVzuy6ADxFy5h1HH4MQ/VllQmV6tKCrEi2Buil860OvDy3TMtvu2hR3LPJntlsbV/vSYzNSXYnmmzlwAploz/KScQ26ZcwsrqO374FP0mWMPYjKiyZHUUi13b7bGPXrZNmhBxjslZzTSbZ0X5WNnol6I9yUi1I7Sp/sp1kfuOHgE30mWty+LCXZxu7bh2mbduGSkQ0+dG1UMgLktkBK2eswpRUDicB67DP4Xl5STeR+EmyJ405teXavdNU4uXZphQU1FrBbiRVPpajMo5ecQS/45HdYtfwa/KcByNOsyLa4SYXi4xUOv3sSPTZFN5Qgv4oJ9WC1EnDdzrZJ9X4JWAT7XxrsjBNtWJxtKIEvSKlgjSdGr5fAjbRzjeRd+o2MZ1bUq1YHK0oZ6wi5dTUUEK31CQnqBcHZk0qv8I9KupGoagmakKn5VVg17YIJ0UsKupGoagmUj1zFfAedVOTnbiKxFA2eoUizfAqsGuyE1eRGErQKzyRbKedwjteBXY6OcYVsShBr3CN01zsitTgVWCriJj0xZGgJ6L+RLSWiDYQ0Z0Wx11KRExE3bTfbYmojIiWa/+e8qvgitTh18QgRXJIRGDXljkLCnfYOmOJKAjgSQDnAtgCYDERzWHm7wzH1QcwDsBXhkt8z8yd/SmuoiagnHY1n5rgFFbUHJxo9D0AbGDmjcx8CMBsABdKjnsIwKMADvpYPkUNRDntFIrahRNB3wLAT7rfW7RtUYjoFACtmPldyfntiOgbIvqUiPrIbkBEo4loCREt2bFjh9OyK1KEctopFLWLhJ2xRBQA8A8At0l2/wygNTN3AXArgJeIqIHxIGaexszdmLlb48aNEy2SIskop51CUbtwMmFqK4BWut8ttW2C+gBOBDCfiACgKYA5RDSYmZcAKAcAZl5KRN8DKACgpr7WcpQNWKGoPTjR6BcDyCeidkSUCWAogDliJzPvYeZGzNyWmdsC+BLAYGZeQkSNNWcuiKg9gHwAKjRDoVAoqhFbjZ6ZK4joBgDvI5If6VlmXk1EDwJYwsxzLE4/A8CDRHQYkTWjr2fmXX4UXKFQKBTOUEnNFAqFIg2wSmqmZsYqFApFmqMEvUKhUKQ5Nc50Q0Q7AGxO4BKNAOz0qTi1BfXM6c/R9ryAema3tGFmaXx6jRP0iUJES8zsVOmKeub052h7XkA9s58o041CoVCkOUrQKxQKRZqTjoJ+WqoLkALUM6c/R9vzAuqZfSPtbPQKhUKhiCUdNXqFQqFQ6FCCXqFQKNKctBH0Tpc7rG0QUSsi+oSIviOi1UQ0TtvekIg+JKL12v/HatuJiB7X3sMKba2AWgkRBbW1DN7Rfrcjoq+0Z3tZS7IHIgprvzdo+9umtOAeIaIcInqNiNYQUTER9Uz370xEt2j1ehUR/YeIstLtOxPRs0T0CxGt0m1z/V2JqEg7fj0RFbkpQ1oIet1yhwMAHA9gGBEdn9pS+UYFgNuY+XgApwH4k/ZsdwL4mJnzAXys/QYi7yBf+zcawNTqL7JvjANQrPv9KIB/MvNxAH4FcI22/RoAv2rb/6kdVxuZDOB/zNwRwMmIPHvafmciagHgJgDdmPlERJImDkX6fefnAfQ3bHP1XYmoIYD7AZyKyKp/94vOwRHMXOv/AegJ4H3d77sA3JXqciXpWd9CZP3etQCaaduaAVir/f00gGG646PH1aZ/iKx78DGAswG8A4AQmTEYMn5zRDKr9tT+DmnHUaqfweXzHgPgB2O50/k748jqdQ217/YOgPPT8TsDaAtgldfvCmAYgKd122OOs/uXFho9HCx3mA5oQ9UuiCzAnsfMP2u7tgMQq4Cky7uYBOAORNJbA0AugN3MXKH91j9X9Jm1/Xu042sT7QDsAPCcZq6aTkT1kMbfmZm3ApgI4EdEVqPbA2Ap0vs7C9x+14S+d7oI+rSHiLIBvA7gZmb+Tb+PI1182sTJEtEgAL8w89JUl6UaCQE4BcBUjiy9uR9HhvMA0vI7HwvgQkQ6ueYA6iHexJH2VMd3TRdBb7fcYa2GiDIQEfKzmPkNbXMJETXT9jcD8Iu2PR3eRW8Ag4loE4DZiJhvJgPIISKxWI7+uaLPrO0/BkBpdRbYB7YA2MLMX2m/X0NE8Kfzd+4H4Adm3sHMhwG8gci3T+fvLHD7XRP63uki6C2XO6zNEBEB+DeAYmb+h27XHADC816EiO1ebL9K896fBmCPbohYK2Dmu5i5JUeWphwKYB4zDwfwCYDLtMOMzyzexWXa8bVK82Xm7QB+IqIO2qZzAHyHNP7OiJhsTiOiulo9F8+ctt9Zh9vv+j6A84joWG0kdJ62zRmpdlL46OwYCGAdgO8B3J3q8vj4XKcjMqxbAWC59m8gIrbJjwGsB/ARgIba8YRIBNL3AFYiEtGQ8udI4Pn7AnhH+7s9gK8BbADwKoCwtj1L+71B298+1eX2+KydASzRvvWbAI5N9+8M4AEAawCsAjATQDjdvjOA/yDigziMyMjtGi/fFcAo7dk3ALjaTRlUCgSFQqFIc9LFdKNQKBQKE5SgVygUijRHCXqFQqFIc5SgVygUijRHCXqFQqFIc5SgVygUijRHCXqFQqFIc/4/I02Cm2IMx1QAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SAVE model"
      ],
      "metadata": {
        "id": "kNtlq_LZpKNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('./content/drive/My Drive/new', exist_ok=True)\n",
        "model.save('./content/drive/My Drive/new/2Class_UNfreeze_2000.h5')"
      ],
      "metadata": {
        "id": "TegSVqblpLEZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "KdsdaIgMpMeG"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"./content/drive/My Drive/new/2Class_UNfreeze_2000.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "sZFZ1c_kpMcN",
        "outputId": "7fd001d5-013c-4ded-f668-208c44a465b0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e487558f-616a-4fd4-8f4c-0b4f38e30fab\", \"2Class_UNfreeze_2000.h5\", 16604936)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gEfCB1RfpMZ6"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}