{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNl632AfpaLNssUfFUtLJKD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kittikhun62/efficientnet_keras_transfer_learning/blob/master/regression_2Class_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# import from drive"
      ],
      "metadata": {
        "id": "_2DRC-anSxem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "BVIqfqC1DtDt",
        "outputId": "1a20c72f-90ca-41ae-e72f-c849acad6550",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (r'/content/drive/My Drive/data - 2 class Regress.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "gABRUdVwDtBk",
        "outputId": "d07b9ef7-1b82-4a09-af74-9966e2549e3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      No                      Name_file  \\\n",
              "0      1                        pore-sb   \n",
              "1      2                        pore-sb   \n",
              "2      3                        pore-sb   \n",
              "3      4                        pore-sb   \n",
              "4      5                        pore-sb   \n",
              "..   ...                            ...   \n",
              "795  796  1-s2.0-S2095268622000210-main   \n",
              "796  797  1-s2.0-S2095268622000210-main   \n",
              "797  798  1-s2.0-S2095268622000210-main   \n",
              "798  799  1-s2.0-S2095268622000210-main   \n",
              "799  800  1-s2.0-S2095268622000210-main   \n",
              "\n",
              "                                            Name_Paper  \\\n",
              "0    Preparation and electrochemical behaviour of b...   \n",
              "1    Preparation and electrochemical behaviour of b...   \n",
              "2    Preparation and electrochemical behaviour of b...   \n",
              "3    Preparation and electrochemical behaviour of b...   \n",
              "4    Preparation and electrochemical behaviour of b...   \n",
              "..                                                 ...   \n",
              "795  Integration of preparation of K, Na-embedded a...   \n",
              "796  Integration of preparation of K, Na-embedded a...   \n",
              "797  Integration of preparation of K, Na-embedded a...   \n",
              "798  Integration of preparation of K, Na-embedded a...   \n",
              "799  Integration of preparation of K, Na-embedded a...   \n",
              "\n",
              "                                               journal  \\\n",
              "0                                  Korean J. Chem. Eng   \n",
              "1                                  Korean J. Chem. Eng   \n",
              "2                                  Korean J. Chem. Eng   \n",
              "3                                  Korean J. Chem. Eng   \n",
              "4                                  Korean J. Chem. Eng   \n",
              "..                                                 ...   \n",
              "795  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "796  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "797  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "798  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "799  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "\n",
              "                                          path_Picture  detail  Class     BET  \\\n",
              "0    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom1  0-800  135.06   \n",
              "1    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom2  0-800  135.06   \n",
              "2    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom3  0-800  135.06   \n",
              "3    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom4  0-800  135.06   \n",
              "4    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom5  0-800  135.06   \n",
              "..                                                 ...     ...    ...     ...   \n",
              "795  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom21  0-800  301.70   \n",
              "796  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom22  0-800  301.70   \n",
              "797  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom23  0-800  301.70   \n",
              "798  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom24  0-800  301.70   \n",
              "799  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom25  0-800  301.70   \n",
              "\n",
              "     Size(mico)  Class_01  \n",
              "0            10         0  \n",
              "1            10         0  \n",
              "2            10         0  \n",
              "3            10         0  \n",
              "4            10         0  \n",
              "..          ...       ...  \n",
              "795          10         0  \n",
              "796          10         0  \n",
              "797          10         0  \n",
              "798          10         0  \n",
              "799          10         0  \n",
              "\n",
              "[800 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-43f013e1-1ff2-4aa9-a0f8-66e3cf785dbe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>No</th>\n",
              "      <th>Name_file</th>\n",
              "      <th>Name_Paper</th>\n",
              "      <th>journal</th>\n",
              "      <th>path_Picture</th>\n",
              "      <th>detail</th>\n",
              "      <th>Class</th>\n",
              "      <th>BET</th>\n",
              "      <th>Size(mico)</th>\n",
              "      <th>Class_01</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom1</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom2</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom3</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom4</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom5</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>795</th>\n",
              "      <td>796</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom21</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>796</th>\n",
              "      <td>797</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom22</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>797</th>\n",
              "      <td>798</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom23</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>798</th>\n",
              "      <td>799</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom24</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799</th>\n",
              "      <td>800</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom25</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>800 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43f013e1-1ff2-4aa9-a0f8-66e3cf785dbe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-43f013e1-1ff2-4aa9-a0f8-66e3cf785dbe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-43f013e1-1ff2-4aa9-a0f8-66e3cf785dbe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## hist check class"
      ],
      "metadata": {
        "id": "WMazXBQcTMl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "W34NcexJDs_Z"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.hist();"
      ],
      "metadata": {
        "id": "Fm07UpEbDs5X",
        "outputId": "4381774a-ee48-4030-8163-54960d624232",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEICAYAAABVv+9nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de7hcVZnn8e9P7iZIEoJHDEhA4yXIiJAHQWgnmhEhKoFuR4MMBMUJPQ3TMIZxoj6ttI4zgFy6ZWx8gtBEG7mIIFFQichRaRskoQNJCJcEgxBDIhACJyqS8M4faxUURZ2cqlO3fXZ+n+fZz9m19q7ab+2z6q1da6+9tiICMzMrn1f1OgAzM+sMJ3gzs5JygjczKykneDOzknKCNzMrKSd4M7OScoI3MyspJ/gCkbRa0npJo6rKPiWpv4dhmbVVrud/lDQgaYOkmyTtnZddIenPeVllukfSX1Q93iQpatZ5Q6/fVxE5wRfPdsAZvQ7CrMM+HBGjgT2BdcDFVcvOi4jRVdM7IuKXlcfA/nm9MVXr/Lbbb2AkcIIvnq8CZ0kaU7tA0rsl3SVpY/777h7EZ9Y2EfEn4Dpgcq9jKSMn+OJZBPQDZ1UXShoH3AR8DdgduBC4SdLu3Q7QrF0kvRr4GHBHr2MpIyf4YvoC8N8l7VFV9kHgoYj4dkRsjoirgPuBD/ckQrPWfF/S08BG4P2kX64VZ0l6umqa35sQRz4n+AKKiGXAD4G5VcWvBx6pWfURYEK34jJro2MjYgywM3A68HNJr8vLzo+IMVXTrN6FObI5wRfXF4H/yksJ/HfAPjXrvAFY082gzNopIrZExPXAFuCIXsdTNk7wBRURK4FrgL/NRTcDb5b0cUnbS/oY6cTUD3sVo1mrlMwAxgIreh1P2TjBF9uXgFEAEfEk8CFgDvAk8BngQxHxRO/CMxu2H0gaAJ4BvgLMiojledlnavq4u44Pk3zDDzOzcvIRvJlZSTnBm5mVlBO8mVlJOcGbmZXU9r0OAGD8+PExceLEuss2bdrEqFGj6i4rCsfYPq3EuXjx4iciYo+h1+w91/nuGAlxdrTOR0TPp4MPPjgGc9tttw26rCgcY/u0EiewKNpQH4G9gduA+4DlwBm5fBywEHgo/x2by0UaI2glcC9w0FDbcJ3vjpEQZyfrvJtozF5pMzAnIiYDhwKnSZpMGjri1oiYBNzKS0NJHA1MytNs4JLuh2z2Sk7wZjUiYm1E3J3nnyVdYTkBmAFUBr6aDxyb52cA38oHVXcAYyTt2eWwzV6hEG3wZkUlaSLwTuBOoC8i1uZFjwN9eX4C8GjV0x7LZWurypA0m3SET19fH/39/XW3OTAwMOiyohgJMcLIiLOTMRY+wS9ds5GT597U6zC2as4Bmx1jmwwV5+pzPti1WCSNBr4HnBkRz0h6cVlEhKSmLgOPiHnAPIApU6bE1KlT66538ZU3csHtm5qKtZv7BaC/v5/B4i+SkRBnJ2N0E41ZHZJ2ICX3KyONdgiwrtL0kv+uz+VrSCdmK/bCo3xaAQw7wUt6i6QlVdMzks6UdLakNVXl09sZsFmnKR2qXwasiIgLqxYtACpjk88CbqwqPymPjHgosLGqKcesZ4bdRBMRDwAHAkjajnTEcgPwCeCiiDi/LRGadd/hwInAUklLctnngHOAayWdQrrZykfzspuB6aRukn8gfQbMeq5dbfDTgFUR8Uh1O6XZSBQRt5P6ttczrc76AZzW0aDMhqFdCX4mcFXV49MlnUS6gfSciNhQ+4RGexT07ZJOvBWZY2yfoeIseo8IsyJpOcFL2hE4BvhsLroE+DIQ+e8FwCdrn9dUj4Klxe7sM+eAzY6xTYaKc/UJU7sXjNkI145eNEcDd0fEOoCIWBfpPosvAJcCh7RhG2Zm1qR2JPjjqWqeqbmC7zhgWRu2YWZmTWrpN7ukUcD7gVOris+TdCCpiWZ1zTIzM+uSlhJ8RGwCdq8pO7GliMzMrC18JauZWUk5wZuZlZQTvJlZSTnBm5mVlBO8mVlJOcGbmZWUE7yZWUk5wZuZlZQTvJlZSRV/eEEzG9LEYd5vt9v3crXu8hG8mVlJOcGbmZWUE7yZWUk5wZuZlZQTvJlZSTnBm5mVlBO8mVlJOcGbmZWUE7yZWUm1etPt1cCzwBZgc0RMkTQOuAaYSLrp9kcjYkNrYZqZWbPacQT/3og4MCKm5MdzgVsjYhJwa35sZmZd1okmmhnA/Dw/Hzi2A9swM7MhtJrgA7hF0mJJs3NZX0SszfOPA30tbsPMzIah1dEkj4iINZJeCyyUdH/1wogISVHvifkLYTZAX18f/f39dTfQtwvMOWBzi2F2lmNsn6HiHKyemNkrtZTgI2JN/rte0g3AIcA6SXtGxFpJewLrB3nuPGAewJQpU2Lq1Kl1t3HxlTdywdJij2o854DNjrFNhopz9QlTuxeM2Qg37CYaSaMk7VqZB44ElgELgFl5tVnAja0GaWZmzWvlkK4PuEFS5XW+ExE/lnQXcK2kU4BHgI+2HqaZmTVr2Ak+Ih4G3lGn/ElgWitBmZlZ64rfKGtmHTOcW/0N5zZ/3dqOvZyHKjAzKykneLM6JF0uab2kZVVl4yQtlPRQ/js2l0vS1yStlHSvpIN6F7nZS5zgzeq7AjiqpmywYTiOBiblaTZwSZdiNNsqJ3izOiLiF8BTNcWDDcMxA/hWJHcAY/I1IGY95ZOsZo0bbBiOCcCjVes9lsvWVpWV5urt/v5+BgYGmrqqeDjvpx1XLTcbZy90MkYneLNh2NowHFt5Timu3l59wlT6+/sZLP56Th5OL5o2XLXcbJy90MkY3URj1rh1laaXmmE41gB7V623Vy4z66niHiaYFU9lGI5zePkwHAuA0yVdDbwL2FjVlGPD5L7zrXOCN6tD0lXAVGC8pMeAL5ISe71hOG4GpgMrgT8An+h6wGZ1OMGb1RERxw+y6BXDcEREAKd1NiKz5rkN3syspJzgzcxKygnezKyknODNzErKCd7MrKSc4M3MSsoJ3syspJzgzcxKygnezKykhp3gJe0t6TZJ90laLumMXH62pDWSluRpevvCNTOzRrUyVMFmYE5E3C1pV2CxpIV52UURcX7r4ZmZ2XANO8Hn0fLW5vlnJa0g3eTAzMwKoC2DjUmaCLwTuBM4nDR06knAItJR/oY6zynF3W3AMbbTUHEW/e48ZkXScoKXNBr4HnBmRDwj6RLgy0DkvxcAn6x9XlnubgMpITnG9hgqznbc5cdsW9FSLxpJO5CS+5URcT1ARKyLiC0R8QJwKXBI62GamVmzWulFI+AyYEVEXFhVXn03+eOAZcMPz8zMhquV3+yHAycCSyUtyWWfA46XdCCpiWY1cGpLEZqZNaj2Nn9zDtjc0A2/y3qrv1Z60dwOqM6im4cfjpmZtYuvZDUzKykneDOzkip+vzkzK5SJc29quG3bestH8GZmJeUEb2ZWUk7wZmYl5QRvZlZSTvBmZiXlBG9mVlLuJmlmNgy1wyI0ottDIvgI3syspJzgzcxKygnezKyknODNzErKCd7MrKSc4M3MSsoJ3syspJzgzcxKygnezKykOpbgJR0l6QFJKyXN7dR2zIrCdd6KpiNDFUjaDvg68H7gMeAuSQsi4r5ObM+s11znrRH1hjcY6u5YrQxv0KmxaA4BVkbEwwCSrgZmAK7sVlau8yPYcMaVGQkUEe1/UekjwFER8an8+ETgXRFxetU6s4HZ+eFbgAcGebnxwBNtD7K9HGP7tBLnPhGxRzuDaZTrfGGNhDg7Vud7NppkRMwD5g21nqRFETGlCyENm2Nsn5ES53C4znffSIizkzF26iTrGmDvqsd75TKzsnKdt8LpVIK/C5gkaV9JOwIzgQUd2pZZEbjOW+F0pIkmIjZLOh34CbAdcHlELB/myw35k7YAHGP7jJQ4X8Z1vrBGQpwdi7EjJ1nNzKz3fCWrmVlJOcGbmZVUYRN8US77lrS3pNsk3SdpuaQzcvnZktZIWpKn6VXP+WyO+wFJH+hirKslLc3xLMpl4yQtlPRQ/js2l0vS13Kc90o6qAvxvaVqfy2R9IykM4u4L3ull/Ve0uWS1ktaVlXWdP2RNCuv/5CkWW2OcbDPY2HilLSzpF9LuifH+Pe5fF9Jd+ZYrskn45G0U368Mi+fWPVardX/iCjcRDpJtQrYD9gRuAeY3KNY9gQOyvO7Ag8Ck4GzgbPqrD85x7sTsG9+H9t1KdbVwPiasvOAuXl+LnBunp8O/AgQcChwZw/+x48D+xRxX/aorvW03gPvAQ4Clg23/gDjgIfz37F5fmwbYxzs81iYOPO2Ruf5HYA787avBWbm8m8A/y3P/w3wjTw/E7gmz7dc/4t6BP/iZd8R8Wegctl310XE2oi4O88/C6wAJmzlKTOAqyPiuYj4DbCS9H56ZQYwP8/PB46tKv9WJHcAYyTt2cW4pgGrIuKRraxTtH3ZaT2t9xHxC+CpmuJm688HgIUR8VREbAAWAke1McbBPo+FiTNvayA/3CFPAbwPuG6QGCuxXwdMkyTaUP+LmuAnAI9WPX6MrSfVrsg/nd5J+kYGOD3/7Lu88pOQ3sYewC2SFitdFg/QFxFr8/zjQF+e7/U+nglcVfW4aPuyF4r4fputP117DzWfx0LFKWk7SUuA9aQvj1XA0xGxuc72XowlL98I7N6OGIua4AtH0mjge8CZEfEMcAnwRuBAYC1wQQ/DqzgiIg4CjgZOk/Se6oWRfvf1vF9sbns8BvhuLirivrQaRak/UPfz+KIixBkRWyLiQNIVzYcAb+1FHEVN8IW67FvSDqTKdGVEXA8QEevyP/EF4FLg/ZJuocXYJe0h6X5JuzQbZ0SskTQAjAZuIFWsdZWml/x3fV590DjzCaL9m91+E44G7o6IdTnu2n1Z+RlaqHrQBUV8v83Wn46/h3qfxyLGCRARTwO3AYeRmocqF5dWb+/FWPLy3YAn2xFjURN8YS77zm1hlwErIuJCSUdI+lXuAfKUpH8F/hb414g4Msc5M58Z3xeYBPy6iU3OBa6IiD82GecoSbtGxGhgHXAksCzHU+khMAu4Mc8vAE7KvQwOBTZW/cQ9H/hSM9tv0vFUNc/UtP0fl+OuxNjKvhxpClPvqzRbf34CfFTStbmp7chc1ha1n8cW4zxS0th2x5kP0sbk+V1I9whYQUr0HxkkxkrsHwF+ln+FtF7/23HWuBMT6ez3g6S2q8/3MI4jSD/37s3TFuBc4F9IiehhoB/Ys+o5n89xPwAc3cS2diING7rXMOLcj3TG/R5geWWfkdrybgUeAn4KjIuXzvR/Pce5FJhS9Vo7k062va4D+3MU6ehkt6qyb+cY7s2VuuV9OVKnXtZ70pfuWuB5UnvvKUPUn1uAP+XPxBOk3ipHkBLXs6STgp9oc4zVn8cleZqe4/w5MJDjeRT4eFU9Xw08A/w+P38i8MkcY1vjBP4D8O85xmXAF3L5fqQEvZLUPLlTLt85P16Zl+/Xrvrf8wo9kiZgCulESb1lJwO35/nP5IpWmZ4nHZVD+vl1Wf4grQH+N7nrE6mb2sqa1+3P6/wqv9YPcmW+MlfYu4CJVesH8KY8vwupPfsR0omb24Fd8rJjSF8ET+dtvK1muwuBWb3e556KOQGfJjWD/CXpS3sH4MPAV0ndXv+lBzFdBVxDaqI8Itf5/fOyPlJ3xMMqCb7X+7AbU1GbaIrqQWCLpPmSjq7q7fEyEXFeRIyO1FzyNtJRwzV58RXAZuBNpB4ARwKfyssOoP5NIGYCJ5LOoL8R+Dfgn0l9eFcAXxwk3vOBg4F353U/A7wg6c2kD8OZwB7AzcAPKhdeZCuAdwy6J2ybJWk3UhPeaRFxfURsiojnI+IHEfE/66z/XUmPS9oo6RfV53ckTVe6aOlZpYvdzsrl4yX9UNLTuSn0l5IGzVeSRgF/BfxdRAxExO2kX4Mnwovnef6JdEC0zXCCb0Kks/WVn4iXAr+XtEBSX731c/vb94F/jIgf5fWmk878b4qI9cBFpAQOMIb007bWP0fEqojYSPoZvCoifhqpS9V3SV8Utdt+Fekn6BkRsSbSScxfRcRzwMeAmyJiYUQ8T/oi2IX0RVDxbI7HrNZhpGaFGxpc/0ek9uPXAneTfn1WXAacGhG7Am8HfpbL55CaifYgHX1/jq33jHkzsDkiHqwquwfoZGeBwuvZHZ1GqohYQWqOQdJbSW3x/0D9EzSXAQ9ExLn58T6kn7Jr07kiIH3JVvq6biBdnVdrXdX8H+s8Hl3nOeNJH8JVdZa9ntRsU3lPL0h6lJf3sd2V1HxjVmt34Il4qU/3VkXE5ZV5SWcDGyTtlg9YngcmS7on0gVHG/Kqz5OuWt0nIlYCvxxiM6NJTZbVNlL/87TN8BF8CyLiflKTy9trlymNI/Jm0omqikeB50jDCYzJ02sionKUcW9+Tjs8QToB9sY6y35H+rKpxCpSd6zqLlhvIx0BmdV6Ehhf1eVvUPmCn3MkrZL0DOlkJ6QDEEjNKtOBRyT9XNJhufyrpJOOt0h6WEOPyzMAvKam7DXU/0W8zXCCb4Kkt0qaI2mv/HhvUpe/O2rWO5rUdfK4qOruGKl71i3ABZJeI+lVkt4o6T/mVX5N6ivb8hV1kfqUXw5cKOn1+YN2mKSdSGNifFDStNyneA7pi+dXOf6dSW33C1uNw0rp30j15dihViT1ZJkB/CdSB4OJuVwAEXFXRMwgNd98n1Q3iYhnI2JOROxH6hDwaUnTtrKdB4HtJU2qKnsHqSPBNssJvjnPAu8C7pS0iZTYl5ESZLWPkdoOV0gayNM38rKTSANJ3Uf6OXod6acokcYfuQL4L22K9yxS98O7SN0ezwVeFREP5G1cTDrS/zDw4bx98uP+iPhdm+KwEslNK18Avi7pWEmvlrRD7nhwXs3qu5K+DJ4EXg38n8oCSTtKOiE31zxPamJ5IS/7kKQ35V+XG0ldH1/YSkybgOuBL+VrQg4nfbF8u2p7O5O6IgPslB+XW6+78Xh6+UT6Yrif3J2xRzHcCby91/vCU7En4ARgEbCJNP7LTaQT9WeTu0mS2sYr/eIfIR3gBKkX2Y7Aj0kHOpUuv0fk5/0PUnPOJtLJ1r9rIJ5xpF8Bm4DfAh+vWR61U6/3Yacn37LPzKyk3ERjZlZS7iZpZiOCpDeQzl3VMzkiftvNeEYCN9GYmZVUIY7gx48fHxMnTqy7bNOmTYwaNaq7ARWQ90Oytf2wePHiJyJijy6HNCyu80PzfkhaqfOFSPATJ05k0aJFdZf19/czderU7gZUQN4Pydb2g6St3f6vUFznh+b9kLRS532S1WwQ+eKwf5f0w/x4X6W73q+UdE1lcLY8Xvc1ufxOpVvJmfWcE7zZ4M4gjapZcS5wUUS8idR3uzIMxSnAhlx+UV7PrOec4M3qyMNRfBD4Zn4s4H2kK48B5vPSpfoz8mPy8mmqGk3OrFcK0QZvQ1u6ZiMnz72pqeesPueDHYpmm/APpPHzK6MR7k662UtlBMXqO9xPII8IGhGbJW3M6z9R/YKSZgOzAfr6+ujv76+74fVPbeTiK2+su2wwB0zYran1R4KBgYFB99FItXTNxqafs+9u2w17PzjBm9WQ9CFgfUQsljS1Xa8bEfOAeQBTpkyJwU6cXXzljVywtLmP5uoT6r/WSFbGk6zNHqQBXHHUqGHvhyGbaCS9RdKSqukZSWdKOjvfgaVSPr3qOZ/NJ5wekPSBYUVm1juHA8dIWg1cTWqa+UfSSJ+VzFt9h/s1pOGWyct3Iw2uZdZTQyb4iHggIg6MiANJQ8j+gZfu5HJRZVlE3AwgaTLpDkX7A0cB/yRpu86Eb9Z+EfHZiNgrIiaS6vLPIuIE4DbSXe8BZpEG0YJ0a7hZef4jeX1fQWg91+xJ1mmk28Vtre/lDODqiHguIn5DGrT/kOEGaFYg/4s0LvlKUhv7Zbn8MmD3XP5pYKibU5h1RbNt8DNJN2uuOF3SSaQhQ+dEuuXWBF5+A4zqk1EvavSEUxlPtAxH3y4w54CG7pD2ojLut27Xh4joB/rz/MPUOViJiD8B/7lrQZk1qOEEny/qOAb4bC66BPgyaVzlLwMXkG7y3JBGTziV8UTLcPjEW+L6YNa4Zppojgbujoh1ABGxLiK2RLo13KW8dGTz4gmnrPpklJmZdUkzCf54qppnJO1Ztew40q3rIJ1wmpkv394XmES616iZmXVRQ7/5JY0C3g+cWlV8nqQDSU00qyvLImK5pGtJ4zZvBk6LiC3tDNrMzIbWUIKPdEPb3WvKTtzK+l8BvtJaaGZm1gqPRWNmVlJO8GZmJeUEb2ZWUk7wZmYl5QRvZlZSTvBmZiXlBG9mVlJO8GZmJeUEb2ZWUk7wZmYl5QRvZlZSTvBmZiXlBG9mVlJO8GZmJeUEb2ZWUk7wZmYl5QRvZlZSTvBmZiXlBG9mVlINJXhJqyUtlbRE0qJcNk7SQkkP5b9jc7kkfU3SSkn3Sjqok2/AzMzqa+YI/r0RcWBETMmP5wK3RsQk4Nb8GOBoYFKeZgOXtCtYMzNrXCtNNDOA+Xl+PnBsVfm3IrkDGCNpzxa2Y2Zmw9Bogg/gFkmLJc3OZX0RsTbPPw705fkJwKNVz30sl5mZWRdt3+B6R0TEGkmvBRZKur96YUSEpGhmw/mLYjZAX18f/f39ddcbGBgYdNm2pG8XmHPA5qaeU8b95vpg1riGEnxErMl/10u6ATgEWCdpz4hYm5tg1ufV1wB7Vz19r1xW+5rzgHkAU6ZMialTp9bddn9/P4Mt25ZcfOWNXLC00e/jZPUJUzsTTA+5Ppg1bsgmGkmjJO1amQeOBJYBC4BZebVZwI15fgFwUu5Ncyiwsaopx8zMuqSRQ8I+4AZJlfW/ExE/lnQXcK2kU4BHgI/m9W8GpgMrgT8An2h71GZmNqQhE3xEPAy8o075k8C0OuUBnNaW6MzMbNh8JauZWUk5wZuZlZQTvJlZSTnBm9WQtLek2yTdJ2m5pDNyucdfshHFCd7slTYDcyJiMnAocJqkyXj8JRthnODNakTE2oi4O88/C6wgDbfh8ZdsRGnu0kizbYykicA7gTtpfvyll13g1+jwHB6WIinjsBTN/l+htf3gBG82CEmjge8BZ0bEM/liP2B44y81OjyHh6VIyjgsxclzb2r6OVccNWrY+8FNNGZ1SNqBlNyvjIjrc/G6StPLcMZfMus2J3izGkqH6pcBKyLiwqpFHn/JRhQ30Zi90uHAicBSSUty2eeAc/D4SzaCOMGb1YiI2wENstjjL9mI4SYaM7OScoI3MyspJ3gzs5JygjczKykneDOzknKCNzMrKSd4M7OScoI3MyupIRP8Vm5+cLakNZKW5Gl61XM+m29+8ICkD3TyDZiZWX2NXMlaufnB3ZJ2BRZLWpiXXRQR51evnG+MMBPYH3g98FNJb46ILe0M3MzMtm7II/it3PxgMDOAqyPiuYj4DWl8jkPaEayZmTWuqbFoam5+cDhwuqSTgEWko/wNpOR/R9XTKjc/qH2thm5+UMZB/4fDN4FIXB/MGtdwgq9z84NLgC8Dkf9eAHyy0ddr9OYHZRz0fzh8E4jE9cGscQ31oql384OIWBcRWyLiBeBSXmqG8c0PzMwKoJFeNHVvflBzU+HjgGV5fgEwU9JOkvYl3Wn+1+0L2czMGtHIb/7Bbn5wvKQDSU00q4FTASJiuaRrgftIPXBOcw8aM7PuGzLBb+XmBzdv5TlfAb7SQlxmZtYiX8lqZlZSTvBmZiXlBG9mVlJO8GZmJeUEb2ZWUk7wZmYl5QRvZlZSTvBmZiXlBG9mVlJO8GZmJeUEb2ZWUk7wZmYl5QRvZlZSTvBmZiXlBG9mVlJO8GZmJeUEb2ZWUk7wZmYl5QRvZlZSHUvwko6S9ICklZLmdmo7ZkXhOm9F05EEL2k74OvA0cBk4HhJkzuxLbMicJ23IurUEfwhwMqIeDgi/gxcDczo0LbMisB13gpn+w697gTg0arHjwHvql5B0mxgdn44IOmBQV5rPPBE2yMceZreDzq3Q5H01tb2wz7dDKRGT+v8Nvi/3ma899zh1/lOJfghRcQ8YN5Q60laFBFTuhBSoXk/JCN5P7jON8f7IWllP3SqiWYNsHfV471ymVlZuc5b4XQqwd8FTJK0r6QdgZnAgg5ty6wIXOetcDrSRBMRmyWdDvwE2A64PCKWD/PlhvxJu43wfkgKuR9c5zvC+yEZ9n5QRLQzEDMzKwhfyWpmVlJO8GZmJVWIBC/pDEnLJC2XdGad5VMlbZS0JE9f6EWcnSDpcknrJS2rKhsnaaGkh/LfsYM8d1Ze5yFJs7oXdfu1uB+2VNWNEXNic6ihDSTtJOmavPxOSRO7H2XnNbAfTpb0+6r/8ad6EWen1fsM1CyXpK/l/XSvpIOGfNGI6OkEvB1YBryadNL3p8CbataZCvyw17F26P2/BzgIWFZVdh4wN8/PBc6t87xxwMP579g8P7bX76fb+yEvG+h1/MN4v9sBq4D9gB2Be4DJNev8DfCNPD8TuKbXcfdoP5wM/L9ex9qFffGKz0DN8unAjwABhwJ3DvWaRTiCfxsp0D9ExGbg58Bf9jimromIXwBP1RTPAObn+fnAsXWe+gFgYUQ8FREbgIXAUR0LtMNa2A8jVSNDG1S//+uAaZLUxRi7wUM8ZIN8BqrNAL4VyR3AGEl7bu01i5DglwF/IWl3Sa8mfUvtXWe9wyTdI+lHkvbvbohd1xcRa/P840BfnXXqXRo/odOBdVkj+wFgZ0mLJN0haaR8CTTy/3txnXzwsxHYvSvRdU+j9fivcrPEdZLq5YdtQdOf+Z4NVVARESsknQvcAmwClgBbala7G9gnIgYkTQe+D0zqbqS9EREhaZvvyzrEftgnItZI2g/4maSlEbGqm/FZR/0AuCoinpN0KulXzft6HNOIUIQjeCLisog4OCLeA2wAHqxZ/kxEDOT5m4EdJI3vQajdsq7y0yv/XV9nnW3h0vhG9gMRsSb/fRjoB97ZrQBb0Mj/78V1JG0P7AY82ZXoumfI/RART0bEc/nhN4GDuxRb0TT9mS9Egpf02vz3DaT29+/ULH9dpe1R0iGkuA7btNkAAAEdSURBVMtW0astACq9YmYBN9ZZ5yfAkZLG5t4lR+ayMhlyP+T3v1OeHw8cDtzXtQiHr5GhDarf/0eAn0U+21YiQ+6HmnbmY4AVXYyvSBYAJ+XeNIcCG6uaMOvr9ZnjXF9/SfpQ3gNMy2V/Dfx1nj8dWJ6X3wG8u9cxt/G9XwWsBZ4ntamdQmpnvRV4iNSraFxedwrwzarnfhJYmadP9Pq99GI/AO8Glua6sRQ4pdfvpYn3PJ30a3UV8Plc9iXgmDy/M/Dd/P/9NbBfr2Pu0X74v1Wf/9uAt/Y65g7th3qfgeo8KNJNZVbluj5lqNf0UAVmZiVViCYaMzNrPyd4M7OScoI3MyspJ3gzs5JygjczKykneDOzknKCNzMrqf8PWE7lfM3FZIAAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = df['BET']\n",
        "\n",
        "fig, ax = plt.subplots(figsize =(10, 5))\n",
        "ax.hist(a, bins = 200)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bxfNFKW2TXAY",
        "outputId": "8ba4681a-ad28-46ba-9f5d-c639cb20c94c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ['0-800','801-3200']\n",
        "len(classes)"
      ],
      "metadata": {
        "id": "TBsLszHgTW-D",
        "outputId": "7ac9fdcf-f7f5-4bc1-a345-dcfa4450dcfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone efficientnet repo"
      ],
      "metadata": {
        "id": "DSSZIFGhUyQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/"
      ],
      "metadata": {
        "id": "nFvKcuBDTj1N",
        "outputId": "15b68afa-0c6d-4952-bac2-b6d4c208a262",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# การเเบ่งข้อมูล train/validation/test sets"
      ],
      "metadata": {
        "id": "JDJCDzEDWnVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# base_dir = '/content/drive/My Drive/new Regress'\n",
        "# os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# # Directories for our training,\n",
        "# # validation and test splits\n",
        "# train_dir = os.path.join(base_dir, 'train')\n",
        "# os.makedirs(train_dir, exist_ok=True)\n",
        "# validation_dir = os.path.join(base_dir, 'validation')\n",
        "# os.makedirs(validation_dir, exist_ok=True)\n",
        "# test_dir = os.path.join(base_dir, 'test')\n",
        "# os.makedirs(test_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "R7L0rJNRU2MY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val = df[df['No'].between(599,699)]\n",
        "train = df[df['No'].between(1,598)]\n",
        "test = df[df['No'].between(700,800)] \n",
        "\n",
        "# #Path Train\n",
        "# T1_train = train[train['Class']=='0-800']\n",
        "# T1_path_train = T1_train['path_Picture'].tolist() \n",
        "# T2_train = train[train['Class']=='801-3200']\n",
        "# T2_path_train = T2_train['path_Picture'].tolist() \n",
        "\n",
        "\n",
        "# #Path Validation\n",
        "# T1_val = val[val['Class']=='0-800']\n",
        "# T1_path_val = T1_val['path_Picture'].tolist() \n",
        "# T2_val = val[val['Class']=='801-3200']\n",
        "# T2_path_val = T2_val['path_Picture'].tolist() \n",
        "\n",
        "\n",
        "\n",
        "# #Path Test\n",
        "# T1_test = test[test['Class']=='0-800']\n",
        "# T1_path_test = T1_test['path_Picture'].tolist() \n",
        "# T2_test = test[test['Class']=='801-3200']\n",
        "# T2_path_test = T2_test['path_Picture'].tolist() \n"
      ],
      "metadata": {
        "id": "mlmd_kyhW2LZ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "DATA_PATH = '/content/drive/My Drive/new Regress'\n",
        "os.chdir(DATA_PATH)\n",
        "train_dir = os.path.join(DATA_PATH, 'train')\n",
        "print(train_dir)\n",
        "validation_dir = os.path.join(DATA_PATH, 'validation')\n",
        "print(validation_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyxDPsEi6yYJ",
        "outputId": "f0eb6930-de18-409d-886a-5bb32660ac28"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/new Regress/train\n",
            "/content/drive/My Drive/new Regress/validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "ZkfPduNQW43l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fnames = T1_path_train\n",
        "# for fname in fnames:\n",
        "#     dst = os.path.join(train_1_dir, os.path.basename(fname))\n",
        "#     shutil.copyfile(fname, dst)\n",
        "\n",
        "# fnames = T2_path_train\n",
        "# for fname in fnames:\n",
        "#     dst = os.path.join(train_2_dir, os.path.basename(fname))\n",
        "#     shutil.copyfile(fname, dst)\n",
        "    \n"
      ],
      "metadata": {
        "id": "9jMgUluKU2Hp"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test"
      ],
      "metadata": {
        "id": "Mj3sViKJaLSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fnames = T1_path_test\n",
        "# for fname in fnames:\n",
        "#     dst = os.path.join(validation_1_dir, os.path.basename(fname))\n",
        "#     shutil.copyfile(fname, dst)\n",
        "\n",
        "# fnames = T2_path_test\n",
        "# for fname in fnames:\n",
        "#     dst = os.path.join(validation_2_dir, os.path.basename(fname))\n",
        "#     shutil.copyfile(fname, dst)\n",
        "    \n"
      ],
      "metadata": {
        "id": "WvK0Y2FIYat1"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Validation"
      ],
      "metadata": {
        "id": "rc4HwwbPaD6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fnames = T1_path_val\n",
        "# for fname in fnames:\n",
        "#     dst = os.path.join(test_1_dir, os.path.basename(fname))\n",
        "#     shutil.copyfile(fname, dst)\n",
        "\n",
        "# fnames = T2_path_val\n",
        "# for fname in fnames:\n",
        "#     dst = os.path.join(test_2_dir, os.path.basename(fname))\n",
        "#     shutil.copyfile(fname, dst)\n"
      ],
      "metadata": {
        "id": "XxtmCbyUYarp"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# print('total training 1 images:', len(os.listdir(train_1_dir))) \n",
        "# print('total training 2 images:', len(os.listdir(train_2_dir)),'\\n')\n",
        "\n",
        "# print('total validation 1 images:', len(os.listdir(validation_1_dir)))\n",
        "# print('total validation 2 images:', len(os.listdir(validation_2_dir)),'\\n')\n",
        "\n",
        "# print('total test 1 images:', len(os.listdir(test_1_dir)))\n",
        "# print('total test 2 images:', len(os.listdir(test_2_dir)),'\\n')\n"
      ],
      "metadata": {
        "id": "Tvk53f-WYapl"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports library"
      ],
      "metadata": {
        "id": "VkYa-4LeTbir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "myAsBcVhTW7j"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "tYeLut2ByGeC"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## hyper parameter\n"
      ],
      "metadata": {
        "id": "T529UM_tVV-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "width = 150\n",
        "height = 150\n",
        "\n",
        "epochs = 1000 #จำนวนรอบในการ Train\n",
        "\n",
        "NUM_TRAIN = 598  # จำนวนภาพ Train\n",
        "NUM_TEST = 101 #จำนวนภาพ Test\n",
        "\n",
        "dropout_rate = 0.3\n",
        "input_shape = (height, width, 3) #ขนาด image enter"
      ],
      "metadata": {
        "id": "zXpmkJ2GVZ1l"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import efficientnet and load the conv base model"
      ],
      "metadata": {
        "id": "j3EgSOiSZHaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "iI3DQ18HU2TF"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "#EfficientNet สร้างขึ้นสำหรับการจำแนกประเภท ImageNet ประกอบด้วยป้ายกำกับคลาส 1,000 รายการ เรามีเพียง 2 เลเยอร์เท่านั้น ซึ่งหมายความว่าเลเยอร์สองสามเลเยอร์สุดท้ายสำหรับการจำแนกไม่มีประโยชน์สำหรับเรา สามารถยกเว้นได้ขณะโหลดโมเดลโดยระบุอาร์กิวเมนต์ include_top เป็น False และนำไปใช้กับโมเดล ImageNet อื่นๆ ที่มีอยู่ในแอปพลิเคชัน Keras เช่นกัน\n",
        "\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "UmBDAgF_VAjq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3d3514b-bb69-4194-d4f0-a57e42aa14fe"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "id": "rRXoFFzfU2Oi",
        "outputId": "40371c19-9e46-4572-b32e-a71fff94e7e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 4,007,548\n",
            "Non-trainable params: 42,016\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Show architecture model"
      ],
      "metadata": {
        "id": "W1JJhCEWZjiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดัดแปลง GlobalMaxPooling2D เพื่อแปลง 4D the (batch_size, rows, cols,channels) tensor เป็น 2D tensor with shape (batch_size,channels)\n",
        "#GlobalMaxPooling2D ส่งผลให้มีจำนวนฟีเจอร์น้อยกว่ามากเมื่อเทียบกับเลเยอร์ Flatten ซึ่งช่วยลดจำนวนพารามิเตอร์ได้อย่างมีประสิทธิภาพ\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
        "# model.add(layers.Flatten(name=\"flatten\"))\n",
        "if dropout_rate > 0:\n",
        "    model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n",
        "# model.add(layers.Dense(256, activation='relu', name=\"fc1\"))\n",
        "model.add(layers.Dense(2, activation='softmax', name=\"fc_out\"))\n",
        "model.add(layers.Dense(1))"
      ],
      "metadata": {
        "id": "-9EQ5AdjZT9s"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "wmBUcgsMZVkW",
        "outputId": "63cdcf91-49af-453c-b5f7-c2b7cc9a49f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 2)                 2562      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,052,129\n",
            "Trainable params: 4,010,113\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('This is the number of trainable layers '\n",
        "      'before freezing the conv base:', len(model.trainable_weights))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "print('This is the number of trainable layers '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ],
      "metadata": {
        "id": "xRyPafCIZXzU",
        "outputId": "9b808d71-a8cf-43b8-e54f-ad19a7419974",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable layers before freezing the conv base: 215\n",
            "This is the number of trainable layers after freezing the conv base: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting data augmentation"
      ],
      "metadata": {
        "id": "X9Xfp10TY9xE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "#Image Augmentation \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, # image input 0-255 --> 0-1 เปลี่ยนค่าสี\n",
        "      rotation_range=40,# หมุนภาพในองศา\n",
        "      width_shift_range=0.2, #เปลี่ยนความกว้าง\n",
        "      height_shift_range=0.2, #ปลี่ยนความสูง\n",
        "      shear_range=0.2, #ทำให้ภาพเบี้ยว\n",
        "      zoom_range=0.2, # Randomly zoom image\n",
        "      horizontal_flip=True, \n",
        "      #โดย Default เมื่อมีการเลื่อนภาพ บิดภาพ หมุนภาพ จะเกิดพื้นที่ว่างที่มุม \n",
        "      #ซึ่งจะมีการเติมภาพให้เต็มโดยใช้เทคนิคแบบ Nearest neighbor ซึ่งเป็นการดึงสีบริเวณใหล้าเคียงมาระบายให้เต็ม แต่เราก็ยังสามารถกำหนดวิธีการ Fill ภาพด้วยเทคนิคอื่นได้จาก Parameter fill_mode\n",
        "      fill_mode='nearest')\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe = train,\n",
        "        directory = train_dir,\n",
        "        x_col = 'path_Picture',\n",
        "        y_col = 'Class_01',\n",
        "        class_mode = 'other',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)\n",
        "\n",
        "validation_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe = val,\n",
        "        directory = validation_dir,\n",
        "        x_col = 'path_Picture',\n",
        "        y_col = 'Class_01',\n",
        "        class_mode = 'other',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)"
      ],
      "metadata": {
        "id": "GC-vPos9Y9HD",
        "outputId": "8f90cf72-c96b-472b-a1a8-0bcd9aa9927d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 598 validated image filenames.\n",
            "Found 101 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# unfreeze"
      ],
      "metadata": {
        "id": "wcg1SJsalDvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model, to_file='conv_base.png', show_shapes=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "NYCPRqN2c2gF",
        "outputId": "e4499994-da46-4c89-b956-c65eb1ff221f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image(filename='/content/unfreeze.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "enZMbj9Nc2iX",
        "outputId": "f68b979e-4b1f-49b2-c926-08624fb8ca30"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set 'multiply_16' and following layers trainable (Unfreeze --> multiply_16 ) ให้เป็น layers ที่ train ชุดข้อมูลใหม่\n",
        "conv_base.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'multiply_15':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "print('This is the number of trainable layers '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__Oz62foc2dq",
        "outputId": "107f5aa9-54e2-474a-adf0-67da9d0cd912"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable layers after freezing the conv base: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "8S60IpOWcB7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer=Adam(lr=2e-5),\n",
        "              metrics=['mse'])\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "Od8zqlOwb9Iw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "550962a2-c532-4b9b-ef7f-3d34b4e3c12c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "<ipython-input-46-5a61ec28a7f4>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "37/37 [==============================] - 120s 3s/step - loss: 0.4038 - mse: 0.4038 - val_loss: 0.3081 - val_mse: 0.3081\n",
            "Epoch 2/1000\n",
            "37/37 [==============================] - 3s 70ms/step - loss: 0.3083 - mse: 0.3083 - val_loss: 0.2926 - val_mse: 0.2926\n",
            "Epoch 3/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.2846 - mse: 0.2846 - val_loss: 0.2653 - val_mse: 0.2653\n",
            "Epoch 4/1000\n",
            "37/37 [==============================] - 3s 83ms/step - loss: 0.2687 - mse: 0.2687 - val_loss: 0.2611 - val_mse: 0.2611\n",
            "Epoch 5/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.2613 - mse: 0.2613 - val_loss: 0.2573 - val_mse: 0.2573\n",
            "Epoch 6/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.2561 - mse: 0.2561 - val_loss: 0.2524 - val_mse: 0.2524\n",
            "Epoch 7/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.2528 - mse: 0.2528 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 8/1000\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.2517 - mse: 0.2517 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 9/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.2507 - mse: 0.2507 - val_loss: 0.2496 - val_mse: 0.2496\n",
            "Epoch 10/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 11/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 12/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 13/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 14/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 15/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 16/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 17/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 18/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 19/1000\n",
            "37/37 [==============================] - 8s 208ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 20/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 21/1000\n",
            "37/37 [==============================] - 8s 207ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 22/1000\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 23/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 24/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 25/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 26/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 27/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 28/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 29/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 30/1000\n",
            "37/37 [==============================] - 8s 223ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 31/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 32/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 33/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 34/1000\n",
            "37/37 [==============================] - 8s 205ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 35/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 36/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 37/1000\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 38/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 39/1000\n",
            "37/37 [==============================] - 4s 81ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 40/1000\n",
            "37/37 [==============================] - 8s 207ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 41/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 42/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 43/1000\n",
            "37/37 [==============================] - 8s 207ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 44/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 45/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 46/1000\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 47/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 48/1000\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 49/1000\n",
            "37/37 [==============================] - 9s 220ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 50/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 51/1000\n",
            "37/37 [==============================] - 8s 207ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 52/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 53/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 54/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 55/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 56/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 57/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 58/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 59/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 60/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 61/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 62/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 63/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 64/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 65/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 66/1000\n",
            "37/37 [==============================] - 8s 208ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 67/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 68/1000\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 69/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 70/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 71/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 72/1000\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 73/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 74/1000\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.2504 - mse: 0.2504 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 75/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 76/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 77/1000\n",
            "37/37 [==============================] - 8s 206ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 78/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 79/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 80/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 81/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 82/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 83/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 84/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.2505 - mse: 0.2505 - val_loss: 0.2506 - val_mse: 0.2506\n",
            "Epoch 85/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 86/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 87/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 88/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 89/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 90/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 91/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 92/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.2504 - mse: 0.2504 - val_loss: 0.2505 - val_mse: 0.2505\n",
            "Epoch 93/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 94/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 95/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 96/1000\n",
            "37/37 [==============================] - 8s 207ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 97/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 98/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 99/1000\n",
            "37/37 [==============================] - 9s 218ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 100/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 101/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.2638 - mse: 0.2638 - val_loss: 0.2498 - val_mse: 0.2498\n",
            "Epoch 102/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 103/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 104/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 105/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 106/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 107/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 108/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 109/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 110/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.2503 - mse: 0.2503Epoch 111/1000\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 112/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 113/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 114/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 115/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 116/1000\n",
            "37/37 [==============================] - 8s 208ms/step - loss: 0.2504 - mse: 0.2504 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 117/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 118/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 119/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 120/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 121/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 122/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 123/1000\n",
            "37/37 [==============================] - 3s 83ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2505 - val_mse: 0.2505\n",
            "Epoch 124/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 125/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 126/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 127/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 128/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 129/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2497 - val_mse: 0.2497\n",
            "Epoch 130/1000\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 131/1000\n",
            "37/37 [==============================] - 3s 83ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 132/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.2504 - mse: 0.2504 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 133/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 134/1000\n",
            "37/37 [==============================] - 4s 82ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 135/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 136/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 137/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 138/1000\n",
            "37/37 [==============================] - 9s 219ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 139/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.2499 - mse: 0.2499 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 140/1000\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.2504 - mse: 0.2504 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 141/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 142/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 143/1000\n",
            "37/37 [==============================] - 4s 82ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 144/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2504 - val_mse: 0.2504\n",
            "Epoch 145/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 146/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 147/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 148/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2504 - val_mse: 0.2504\n",
            "Epoch 149/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 150/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 151/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 152/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 153/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 154/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 155/1000\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 156/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 157/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 158/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 159/1000\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 160/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 161/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 162/1000\n",
            "37/37 [==============================] - 4s 81ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 163/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 164/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2497 - val_mse: 0.2497\n",
            "Epoch 165/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.2504 - mse: 0.2504 - val_loss: 0.2505 - val_mse: 0.2505\n",
            "Epoch 166/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 167/1000\n",
            "37/37 [==============================] - 9s 218ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 168/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 169/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 170/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 171/1000\n",
            "37/37 [==============================] - 8s 206ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 172/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 173/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 174/1000\n",
            "37/37 [==============================] - 4s 81ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2498 - val_mse: 0.2498\n",
            "Epoch 175/1000\n",
            "37/37 [==============================] - 5s 110ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 176/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 177/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 178/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.2504 - mse: 0.2504 - val_loss: 0.2504 - val_mse: 0.2504\n",
            "Epoch 179/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.2504 - mse: 0.2504 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 180/1000\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 181/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 182/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 183/1000\n",
            "37/37 [==============================] - 4s 81ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 184/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 185/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 186/1000\n",
            "37/37 [==============================] - 9s 219ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 187/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 188/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 189/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 190/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 191/1000\n",
            "37/37 [==============================] - 8s 208ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 192/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 193/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 194/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 195/1000\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 196/1000\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 197/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 198/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 199/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2505 - val_mse: 0.2505\n",
            "Epoch 200/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 201/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 202/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 203/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 204/1000\n",
            "37/37 [==============================] - 8s 208ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 205/1000\n",
            "37/37 [==============================] - 8s 208ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 206/1000\n",
            "37/37 [==============================] - 4s 82ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 207/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 208/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 209/1000\n",
            "37/37 [==============================] - 8s 207ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 210/1000\n",
            "37/37 [==============================] - 9s 220ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 211/1000\n",
            "37/37 [==============================] - 3s 84ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 212/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 213/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 214/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 215/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 216/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 217/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 218/1000\n",
            "37/37 [==============================] - 4s 82ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 219/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 220/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 221/1000\n",
            "37/37 [==============================] - 8s 208ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 222/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 223/1000\n",
            "37/37 [==============================] - 8s 207ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 224/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 225/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 226/1000\n",
            "37/37 [==============================] - 8s 208ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 227/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 228/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2498 - val_mse: 0.2498\n",
            "Epoch 229/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 230/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 231/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 232/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 233/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 234/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 235/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 236/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 237/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 238/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 239/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 240/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 241/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 242/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 243/1000\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2504 - val_mse: 0.2504\n",
            "Epoch 244/1000\n",
            "37/37 [==============================] - 4s 81ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2505 - val_mse: 0.2505\n",
            "Epoch 245/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 246/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 247/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 248/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 249/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 250/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 251/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 252/1000\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 253/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 254/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2504 - val_mse: 0.2504\n",
            "Epoch 255/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.2499 - mse: 0.2499 - val_loss: 0.2505 - val_mse: 0.2505\n",
            "Epoch 256/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 257/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 258/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 259/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 260/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 261/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 262/1000\n",
            "37/37 [==============================] - 8s 208ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 263/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 264/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 265/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 266/1000\n",
            "37/37 [==============================] - 8s 208ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 267/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 268/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 269/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 270/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 271/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 272/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 273/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 274/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 275/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 276/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 277/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 278/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 279/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 280/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 281/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2505 - val_mse: 0.2505\n",
            "Epoch 282/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 283/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 284/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 285/1000\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 286/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 287/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 288/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 289/1000\n",
            "37/37 [==============================] - 8s 208ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 290/1000\n",
            "37/37 [==============================] - 3s 83ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 291/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 292/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 293/1000\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 294/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 295/1000\n",
            "37/37 [==============================] - 8s 207ms/step - loss: 0.2504 - mse: 0.2504 - val_loss: 0.2498 - val_mse: 0.2498\n",
            "Epoch 296/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 297/1000\n",
            "37/37 [==============================] - 9s 216ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 298/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 299/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 300/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 301/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 302/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 303/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 304/1000\n",
            "37/37 [==============================] - 9s 220ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 305/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 306/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 307/1000\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 308/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 309/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 310/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 311/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 312/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 313/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2507 - val_mse: 0.2507\n",
            "Epoch 314/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 315/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 316/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 317/1000\n",
            "37/37 [==============================] - 9s 215ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 318/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 319/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 320/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 321/1000\n",
            "37/37 [==============================] - 8s 208ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 322/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 323/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 324/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 325/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.2504 - mse: 0.2504 - val_loss: 0.2505 - val_mse: 0.2505\n",
            "Epoch 326/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 327/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 328/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 329/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 330/1000\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 331/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 332/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 333/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 334/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 335/1000\n",
            "37/37 [==============================] - 9s 219ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 336/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 337/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 338/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 339/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 340/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 341/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 342/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 343/1000\n",
            "37/37 [==============================] - 5s 102ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 344/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 345/1000\n",
            "37/37 [==============================] - 5s 111ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 346/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 347/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 348/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 349/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2504 - val_mse: 0.2504\n",
            "Epoch 350/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 351/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 352/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 353/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2498 - val_mse: 0.2498\n",
            "Epoch 354/1000\n",
            "37/37 [==============================] - 5s 111ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 355/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 356/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 357/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 358/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 359/1000\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 360/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 361/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 362/1000\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 363/1000\n",
            "37/37 [==============================] - 9s 218ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 364/1000\n",
            "37/37 [==============================] - 3s 83ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 365/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 366/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 367/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 368/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 369/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 370/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2497 - val_mse: 0.2497\n",
            "Epoch 371/1000\n",
            "37/37 [==============================] - 4s 79ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 372/1000\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 373/1000\n",
            "37/37 [==============================] - 9s 218ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 374/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 375/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 376/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2504 - val_mse: 0.2504\n",
            "Epoch 377/1000\n",
            "37/37 [==============================] - 8s 208ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 378/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2504 - val_mse: 0.2504\n",
            "Epoch 379/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 380/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 381/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 382/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 383/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 384/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 385/1000\n",
            "37/37 [==============================] - 9s 218ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2498 - val_mse: 0.2498\n",
            "Epoch 386/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 387/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 388/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 389/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 390/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 391/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2504 - val_mse: 0.2504\n",
            "Epoch 392/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 393/1000\n",
            "37/37 [==============================] - 9s 220ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 394/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 395/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2497 - val_mse: 0.2497\n",
            "Epoch 396/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 397/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 398/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 399/1000\n",
            "37/37 [==============================] - 4s 109ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 400/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 401/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 402/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 403/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 404/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.2505 - mse: 0.2505 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 405/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 406/1000\n",
            "37/37 [==============================] - 4s 80ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2504 - val_mse: 0.2504\n",
            "Epoch 407/1000\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 408/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 409/1000\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 410/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 411/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 412/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 413/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 414/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 415/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 416/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 417/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 418/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 419/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 420/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 421/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 422/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 423/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 424/1000\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 425/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 426/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 427/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 428/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 429/1000\n",
            "37/37 [==============================] - 3s 83ms/step - loss: 0.2499 - mse: 0.2499 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 430/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 431/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 432/1000\n",
            "37/37 [==============================] - 9s 217ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 433/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 434/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 435/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 436/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 437/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 438/1000\n",
            "37/37 [==============================] - 4s 79ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 439/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 440/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 441/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 442/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 443/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2504 - val_mse: 0.2504\n",
            "Epoch 444/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 445/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 446/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 447/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 448/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2504 - val_mse: 0.2504\n",
            "Epoch 449/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 450/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 451/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 452/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 453/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 454/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 455/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 456/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 457/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.2504 - mse: 0.2504 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 458/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 459/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 460/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 461/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 462/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 463/1000\n",
            "37/37 [==============================] - 4s 82ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 464/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.2505 - mse: 0.2505 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 465/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 466/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 467/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 468/1000\n",
            "37/37 [==============================] - 9s 215ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 469/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 470/1000\n",
            "37/37 [==============================] - 4s 82ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 471/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 472/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 473/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 474/1000\n",
            "37/37 [==============================] - 5s 106ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 475/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 476/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 477/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 478/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 479/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 480/1000\n",
            "37/37 [==============================] - 9s 217ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 481/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 482/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 483/1000\n",
            "37/37 [==============================] - 4s 82ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 484/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 485/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 486/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 487/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 488/1000\n",
            "37/37 [==============================] - 9s 239ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 489/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.2499 - mse: 0.2499 - val_loss: 0.2504 - val_mse: 0.2504\n",
            "Epoch 490/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 491/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2506 - val_mse: 0.2506\n",
            "Epoch 492/1000\n",
            "37/37 [==============================] - 5s 115ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 493/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.2505 - mse: 0.2505 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 494/1000\n",
            "37/37 [==============================] - 5s 114ms/step - loss: 0.2505 - mse: 0.2505 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 495/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 496/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 497/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 498/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 499/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 500/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 501/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 502/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 503/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 504/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 505/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 506/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 507/1000\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 508/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.2504 - mse: 0.2504 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 509/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 510/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 511/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 512/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 513/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 514/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 515/1000\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 0.2505 - mse: 0.2505 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 516/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.2505 - mse: 0.2505 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 517/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.2506 - mse: 0.2506 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 518/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 519/1000\n",
            "37/37 [==============================] - 5s 113ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 520/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 521/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 522/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 523/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2498 - val_mse: 0.2498\n",
            "Epoch 524/1000\n",
            "37/37 [==============================] - 5s 109ms/step - loss: 0.2504 - mse: 0.2504 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 525/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 526/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 527/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 528/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 529/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 530/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 531/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 532/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 533/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 534/1000\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.2504 - mse: 0.2504 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 535/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 536/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 537/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 538/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 539/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 540/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 541/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 542/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 543/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 544/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 545/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2504 - val_mse: 0.2504\n",
            "Epoch 546/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 547/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 548/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 549/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 550/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 551/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 552/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 553/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 554/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 555/1000\n",
            "37/37 [==============================] - 5s 114ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 556/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.2504 - mse: 0.2504 - val_loss: 0.2505 - val_mse: 0.2505\n",
            "Epoch 557/1000\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.2504 - mse: 0.2504 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 558/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 559/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 560/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 561/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 562/1000\n",
            "37/37 [==============================] - 5s 110ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 563/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 564/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 565/1000\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 566/1000\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 567/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 568/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 569/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 570/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 571/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 572/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 573/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 574/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 575/1000\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 576/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 577/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 578/1000\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 579/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 580/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 581/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 582/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 583/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.2813 - mse: 0.2813 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 584/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 585/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 586/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 587/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 588/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 589/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 590/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 591/1000\n",
            "37/37 [==============================] - 4s 111ms/step - loss: 0.2504 - mse: 0.2504 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 592/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.2499 - mse: 0.2499 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 593/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 594/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 595/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 596/1000\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 597/1000\n",
            "37/37 [==============================] - 4s 81ms/step - loss: 0.2499 - mse: 0.2499 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 598/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 599/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 600/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 601/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 602/1000\n",
            "37/37 [==============================] - 9s 217ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 603/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 604/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 605/1000\n",
            "37/37 [==============================] - 4s 82ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 606/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 607/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 608/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 609/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2504 - val_mse: 0.2504\n",
            "Epoch 610/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 611/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 612/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 613/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 614/1000\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 615/1000\n",
            "37/37 [==============================] - 6s 131ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 616/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 617/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2504 - val_mse: 0.2504\n",
            "Epoch 618/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 619/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 620/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 621/1000\n",
            "37/37 [==============================] - 4s 81ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 622/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 623/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 624/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 625/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 626/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 627/1000\n",
            "37/37 [==============================] - 9s 216ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 628/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 629/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 630/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 631/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 632/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 633/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 634/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 635/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 636/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 637/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 638/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 639/1000\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2504 - val_mse: 0.2504\n",
            "Epoch 640/1000\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 641/1000\n",
            "37/37 [==============================] - 4s 80ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2507 - val_mse: 0.2507\n",
            "Epoch 642/1000\n",
            "37/37 [==============================] - 5s 108ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 643/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 644/1000\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 645/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 646/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 647/1000\n",
            "37/37 [==============================] - 9s 243ms/step - loss: 0.2505 - mse: 0.2505 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 648/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 649/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 650/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.2505 - mse: 0.2505 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 651/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 652/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 653/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 654/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 655/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 656/1000\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 657/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 658/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 659/1000\n",
            "37/37 [==============================] - 9s 242ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 660/1000\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 661/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 662/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 663/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 664/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 665/1000\n",
            "37/37 [==============================] - 10s 240ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 666/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 667/1000\n",
            "37/37 [==============================] - 3s 83ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 668/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 669/1000\n",
            "37/37 [==============================] - 5s 110ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 670/1000\n",
            "37/37 [==============================] - 4s 82ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 671/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 672/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 673/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 674/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 675/1000\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 676/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 677/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.2504 - mse: 0.2504 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 678/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.2504 - mse: 0.2504 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 679/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 680/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 681/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.2505 - mse: 0.2505 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 682/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.2504 - mse: 0.2504 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 683/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.2504 - mse: 0.2504 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 684/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 685/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 686/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 687/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 688/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 689/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 690/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 691/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 692/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 693/1000\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2505 - val_mse: 0.2505\n",
            "Epoch 694/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 695/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 696/1000\n",
            "37/37 [==============================] - 4s 82ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 697/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 698/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 699/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2505 - val_mse: 0.2505\n",
            "Epoch 700/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 701/1000\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 702/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 703/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 704/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2498 - val_mse: 0.2498\n",
            "Epoch 705/1000\n",
            "37/37 [==============================] - 9s 215ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 706/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 707/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.2505 - mse: 0.2505 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 708/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 709/1000\n",
            "37/37 [==============================] - 9s 241ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 710/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 711/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 712/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 713/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 714/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 715/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 716/1000\n",
            "37/37 [==============================] - 5s 116ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 717/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 718/1000\n",
            "37/37 [==============================] - 5s 110ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 719/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 720/1000\n",
            "37/37 [==============================] - 6s 146ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 721/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 722/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.2504 - mse: 0.2504 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 723/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 724/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 725/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 726/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2504 - val_mse: 0.2504\n",
            "Epoch 727/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 728/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2498 - val_mse: 0.2498\n",
            "Epoch 729/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 730/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 731/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 732/1000\n",
            "37/37 [==============================] - 8s 223ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 733/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 734/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2504 - val_mse: 0.2504\n",
            "Epoch 735/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 736/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 737/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 738/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 739/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2504 - val_mse: 0.2504\n",
            "Epoch 740/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 741/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 742/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 743/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 744/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 745/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 746/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 747/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 748/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 749/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 750/1000\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 751/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 752/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 753/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 754/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.2504 - mse: 0.2504 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 755/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 756/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 757/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 758/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 759/1000\n",
            "37/37 [==============================] - 5s 108ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 760/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 761/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 762/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 763/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 764/1000\n",
            "37/37 [==============================] - 5s 117ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 765/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.2505 - mse: 0.2505 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 766/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 767/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 768/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 769/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 770/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 771/1000\n",
            "37/37 [==============================] - 9s 242ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 772/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 773/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 774/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 775/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 776/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 777/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 778/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 779/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 780/1000\n",
            "37/37 [==============================] - 9s 220ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 781/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 782/1000\n",
            "37/37 [==============================] - 5s 114ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 783/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 784/1000\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 785/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 786/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 787/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 788/1000\n",
            "37/37 [==============================] - 3s 83ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 789/1000\n",
            "37/37 [==============================] - 6s 142ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 790/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 791/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 792/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 793/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 794/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 795/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 796/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 797/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 798/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 799/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 800/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 801/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 802/1000\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 803/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 804/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2506 - val_mse: 0.2506\n",
            "Epoch 805/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 806/1000\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 807/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 808/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 809/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 810/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 811/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 812/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 813/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 814/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 815/1000\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 816/1000\n",
            "37/37 [==============================] - 5s 110ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 817/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 818/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 819/1000\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 820/1000\n",
            "37/37 [==============================] - 5s 117ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 821/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 822/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 823/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 824/1000\n",
            "37/37 [==============================] - 9s 241ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 825/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 826/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 827/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 828/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 829/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.2499 - mse: 0.2499 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 830/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 831/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 832/1000\n",
            "37/37 [==============================] - 5s 100ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 833/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 834/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 835/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 836/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 837/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 838/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 839/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 840/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 841/1000\n",
            "37/37 [==============================] - 6s 139ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 842/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 843/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 844/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 845/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 846/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 847/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 848/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 849/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 850/1000\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 851/1000\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 852/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 853/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 854/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 855/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 856/1000\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 857/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 858/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 859/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 860/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 861/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 862/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 863/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 864/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 865/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 866/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 867/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 868/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 869/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2504 - val_mse: 0.2504\n",
            "Epoch 870/1000\n",
            "37/37 [==============================] - 9s 220ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 871/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 872/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 873/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 874/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 875/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 876/1000\n",
            "37/37 [==============================] - 9s 245ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 877/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 878/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.2505 - mse: 0.2505 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 879/1000\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 880/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 881/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 882/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 883/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 884/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 885/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2498 - val_mse: 0.2498\n",
            "Epoch 886/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 887/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 888/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 889/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 890/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 891/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 892/1000\n",
            "37/37 [==============================] - 9s 241ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 893/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 894/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.2505 - mse: 0.2505 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 895/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 896/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 897/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 898/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.2504 - mse: 0.2504 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 899/1000\n",
            "37/37 [==============================] - 6s 142ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 900/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 901/1000\n",
            "37/37 [==============================] - 6s 143ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 902/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 903/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 904/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 905/1000\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 906/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 907/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 908/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 909/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 910/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 911/1000\n",
            "37/37 [==============================] - 5s 111ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 912/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 913/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 914/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.2504 - mse: 0.2504 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 915/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 916/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 917/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 918/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.2504 - mse: 0.2504 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 919/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 920/1000\n",
            "37/37 [==============================] - 9s 239ms/step - loss: 0.2504 - mse: 0.2504 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 921/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 922/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 923/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 924/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 925/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 926/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 927/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 928/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 929/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 930/1000\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 931/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 932/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 933/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 934/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 935/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 936/1000\n",
            "37/37 [==============================] - 4s 111ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 937/1000\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 938/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 939/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 940/1000\n",
            "37/37 [==============================] - 9s 243ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 941/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 942/1000\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 943/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 944/1000\n",
            "37/37 [==============================] - 4s 82ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 945/1000\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 946/1000\n",
            "37/37 [==============================] - 5s 113ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 947/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 948/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 949/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 950/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 951/1000\n",
            "37/37 [==============================] - 5s 111ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 952/1000\n",
            "37/37 [==============================] - 9s 219ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 953/1000\n",
            "37/37 [==============================] - 9s 244ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 954/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 955/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 956/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 957/1000\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 958/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 959/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 960/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 961/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 962/1000\n",
            "37/37 [==============================] - 5s 106ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 963/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 964/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 965/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 966/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 967/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 968/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 969/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 970/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2498 - val_mse: 0.2498\n",
            "Epoch 971/1000\n",
            "37/37 [==============================] - 5s 113ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 972/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 973/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 974/1000\n",
            "37/37 [==============================] - 10s 247ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 975/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.2506 - mse: 0.2506 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 976/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 977/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 978/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 979/1000\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 980/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2504 - val_mse: 0.2504\n",
            "Epoch 981/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 982/1000\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 983/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 984/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 985/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 986/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 987/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 988/1000\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 989/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.2505 - mse: 0.2505 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 990/1000\n",
            "37/37 [==============================] - 9s 250ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 991/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 992/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 993/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 994/1000\n",
            "37/37 [==============================] - 5s 109ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 995/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 996/1000\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 997/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 998/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 999/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 1000/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2502 - val_mse: 0.2502\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.history "
      ],
      "metadata": {
        "id": "tO_KJFVJu6ya",
        "outputId": "1e1deab0-e503-47b4-b652-3617b6995a0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': [0.4037855565547943,\n",
              "  0.30825313925743103,\n",
              "  0.28462326526641846,\n",
              "  0.26867586374282837,\n",
              "  0.2613040506839752,\n",
              "  0.25613442063331604,\n",
              "  0.2528182864189148,\n",
              "  0.2516881823539734,\n",
              "  0.25066202878952026,\n",
              "  0.2502664625644684,\n",
              "  0.25012779235839844,\n",
              "  0.2501896023750305,\n",
              "  0.2500578761100769,\n",
              "  0.250104695558548,\n",
              "  0.2500353753566742,\n",
              "  0.25006571412086487,\n",
              "  0.25015124678611755,\n",
              "  0.25010034441947937,\n",
              "  0.25011664628982544,\n",
              "  0.250235915184021,\n",
              "  0.25006309151649475,\n",
              "  0.25015392899513245,\n",
              "  0.25009915232658386,\n",
              "  0.2500876784324646,\n",
              "  0.2500804364681244,\n",
              "  0.25030091404914856,\n",
              "  0.2501148581504822,\n",
              "  0.2501574754714966,\n",
              "  0.250099241733551,\n",
              "  0.25009697675704956,\n",
              "  0.25004658102989197,\n",
              "  0.250092089176178,\n",
              "  0.2500333786010742,\n",
              "  0.2500717043876648,\n",
              "  0.25028494000434875,\n",
              "  0.2501043379306793,\n",
              "  0.25002577900886536,\n",
              "  0.25007057189941406,\n",
              "  0.2500317692756653,\n",
              "  0.25000330805778503,\n",
              "  0.25008663535118103,\n",
              "  0.2500711977481842,\n",
              "  0.2500937581062317,\n",
              "  0.25000083446502686,\n",
              "  0.2501813471317291,\n",
              "  0.2501200735569,\n",
              "  0.2500520944595337,\n",
              "  0.25005021691322327,\n",
              "  0.2501475512981415,\n",
              "  0.2501224875450134,\n",
              "  0.2500874102115631,\n",
              "  0.25009894371032715,\n",
              "  0.2500704526901245,\n",
              "  0.2501193881034851,\n",
              "  0.25009894371032715,\n",
              "  0.25007617473602295,\n",
              "  0.2501957416534424,\n",
              "  0.25011512637138367,\n",
              "  0.2500356435775757,\n",
              "  0.25028151273727417,\n",
              "  0.2501155436038971,\n",
              "  0.2502193748950958,\n",
              "  0.2500455677509308,\n",
              "  0.250122994184494,\n",
              "  0.25000062584877014,\n",
              "  0.2500239908695221,\n",
              "  0.25011375546455383,\n",
              "  0.25004813075065613,\n",
              "  0.25015246868133545,\n",
              "  0.25013503432273865,\n",
              "  0.25010374188423157,\n",
              "  0.25010398030281067,\n",
              "  0.2501564621925354,\n",
              "  0.25041326880455017,\n",
              "  0.25006309151649475,\n",
              "  0.25011956691741943,\n",
              "  0.2501457631587982,\n",
              "  0.25012722611427307,\n",
              "  0.2501460015773773,\n",
              "  0.25012099742889404,\n",
              "  0.2500735819339752,\n",
              "  0.25015294551849365,\n",
              "  0.2500644028186798,\n",
              "  0.25052300095558167,\n",
              "  0.25022411346435547,\n",
              "  0.25014597177505493,\n",
              "  0.2502024173736572,\n",
              "  0.25008445978164673,\n",
              "  0.25018152594566345,\n",
              "  0.2500576376914978,\n",
              "  0.2499748319387436,\n",
              "  0.2503698468208313,\n",
              "  0.2502729892730713,\n",
              "  0.2501513361930847,\n",
              "  0.25008079409599304,\n",
              "  0.25004658102989197,\n",
              "  0.25009071826934814,\n",
              "  0.25025346875190735,\n",
              "  0.25001099705696106,\n",
              "  0.25008708238601685,\n",
              "  0.26376453042030334,\n",
              "  0.2500794529914856,\n",
              "  0.2501212954521179,\n",
              "  0.2501179575920105,\n",
              "  0.2501058280467987,\n",
              "  0.25016993284225464,\n",
              "  0.250189870595932,\n",
              "  0.25023385882377625,\n",
              "  0.2502639591693878,\n",
              "  0.2503085434436798,\n",
              "  0.25005650520324707,\n",
              "  0.25013530254364014,\n",
              "  0.2501330077648163,\n",
              "  0.2501816153526306,\n",
              "  0.25004392862319946,\n",
              "  0.2503759562969208,\n",
              "  0.2501504123210907,\n",
              "  0.2500721216201782,\n",
              "  0.25006887316703796,\n",
              "  0.24999643862247467,\n",
              "  0.25032469630241394,\n",
              "  0.25021111965179443,\n",
              "  0.2500796616077423,\n",
              "  0.25015026330947876,\n",
              "  0.24999696016311646,\n",
              "  0.25021910667419434,\n",
              "  0.2500571310520172,\n",
              "  0.2502390146255493,\n",
              "  0.2500517666339874,\n",
              "  0.2500433325767517,\n",
              "  0.2501022517681122,\n",
              "  0.25035759806632996,\n",
              "  0.25012436509132385,\n",
              "  0.2500856816768646,\n",
              "  0.2501874268054962,\n",
              "  0.2501535713672638,\n",
              "  0.2500436007976532,\n",
              "  0.2500837743282318,\n",
              "  0.24992746114730835,\n",
              "  0.2504240572452545,\n",
              "  0.25011107325553894,\n",
              "  0.2501268684864044,\n",
              "  0.250215619802475,\n",
              "  0.250020295381546,\n",
              "  0.25014111399650574,\n",
              "  0.2500125467777252,\n",
              "  0.2500852644443512,\n",
              "  0.250087171792984,\n",
              "  0.2501773238182068,\n",
              "  0.2501772344112396,\n",
              "  0.2501409351825714,\n",
              "  0.2503047585487366,\n",
              "  0.25009268522262573,\n",
              "  0.2500150501728058,\n",
              "  0.24999122321605682,\n",
              "  0.2500055730342865,\n",
              "  0.2501412630081177,\n",
              "  0.25002697110176086,\n",
              "  0.2502328157424927,\n",
              "  0.25010228157043457,\n",
              "  0.25018393993377686,\n",
              "  0.2501332759857178,\n",
              "  0.2501310110092163,\n",
              "  0.2500933110713959,\n",
              "  0.25039994716644287,\n",
              "  0.25012701749801636,\n",
              "  0.25011929869651794,\n",
              "  0.25020650029182434,\n",
              "  0.25003781914711,\n",
              "  0.25013330578804016,\n",
              "  0.2500138282775879,\n",
              "  0.2501259744167328,\n",
              "  0.25009885430336,\n",
              "  0.2500402331352234,\n",
              "  0.25010523200035095,\n",
              "  0.25014159083366394,\n",
              "  0.25009849667549133,\n",
              "  0.25041529536247253,\n",
              "  0.25040602684020996,\n",
              "  0.2499801516532898,\n",
              "  0.2501174509525299,\n",
              "  0.25016316771507263,\n",
              "  0.2500791549682617,\n",
              "  0.25014257431030273,\n",
              "  0.2501975893974304,\n",
              "  0.250198096036911,\n",
              "  0.2503025233745575,\n",
              "  0.2500609755516052,\n",
              "  0.25016093254089355,\n",
              "  0.2500486373901367,\n",
              "  0.25012311339378357,\n",
              "  0.2500660717487335,\n",
              "  0.2501958906650543,\n",
              "  0.2500409781932831,\n",
              "  0.2500585615634918,\n",
              "  0.2500530779361725,\n",
              "  0.25007304549217224,\n",
              "  0.25004446506500244,\n",
              "  0.25014349818229675,\n",
              "  0.25008565187454224,\n",
              "  0.25014838576316833,\n",
              "  0.2501702606678009,\n",
              "  0.25026145577430725,\n",
              "  0.2502366304397583,\n",
              "  0.2500292658805847,\n",
              "  0.25013479590415955,\n",
              "  0.25020506978034973,\n",
              "  0.25017601251602173,\n",
              "  0.2501158118247986,\n",
              "  0.2500424087047577,\n",
              "  0.2501993775367737,\n",
              "  0.2502857446670532,\n",
              "  0.2501203119754791,\n",
              "  0.2501089870929718,\n",
              "  0.25018206238746643,\n",
              "  0.25016817450523376,\n",
              "  0.25011253356933594,\n",
              "  0.25019603967666626,\n",
              "  0.2500694990158081,\n",
              "  0.25027796626091003,\n",
              "  0.25004157423973083,\n",
              "  0.250108927488327,\n",
              "  0.25013816356658936,\n",
              "  0.25004544854164124,\n",
              "  0.2501249313354492,\n",
              "  0.25004273653030396,\n",
              "  0.2500555217266083,\n",
              "  0.25017058849334717,\n",
              "  0.25012192130088806,\n",
              "  0.2502018213272095,\n",
              "  0.2500428557395935,\n",
              "  0.25001955032348633,\n",
              "  0.2501436769962311,\n",
              "  0.25001075863838196,\n",
              "  0.2501922845840454,\n",
              "  0.25015538930892944,\n",
              "  0.2501862645149231,\n",
              "  0.25009384751319885,\n",
              "  0.25012651085853577,\n",
              "  0.2500317096710205,\n",
              "  0.250027060508728,\n",
              "  0.2501264810562134,\n",
              "  0.2501372694969177,\n",
              "  0.2501280903816223,\n",
              "  0.2500748634338379,\n",
              "  0.25008752942085266,\n",
              "  0.2501072883605957,\n",
              "  0.2499815970659256,\n",
              "  0.250156044960022,\n",
              "  0.2501213252544403,\n",
              "  0.2502268850803375,\n",
              "  0.250315397977829,\n",
              "  0.2500118911266327,\n",
              "  0.25015825033187866,\n",
              "  0.2499307543039322,\n",
              "  0.2501017451286316,\n",
              "  0.25003963708877563,\n",
              "  0.2501869797706604,\n",
              "  0.25006890296936035,\n",
              "  0.25011682510375977,\n",
              "  0.2502397298812866,\n",
              "  0.25025779008865356,\n",
              "  0.2501446306705475,\n",
              "  0.25018763542175293,\n",
              "  0.2501770853996277,\n",
              "  0.2501508295536041,\n",
              "  0.25008875131607056,\n",
              "  0.25003087520599365,\n",
              "  0.2500693202018738,\n",
              "  0.250156044960022,\n",
              "  0.2501353621482849,\n",
              "  0.2501138746738434,\n",
              "  0.2501465380191803,\n",
              "  0.2500794529914856,\n",
              "  0.25009623169898987,\n",
              "  0.25011172890663147,\n",
              "  0.25012892484664917,\n",
              "  0.2500931918621063,\n",
              "  0.2502209544181824,\n",
              "  0.2500298023223877,\n",
              "  0.25007539987564087,\n",
              "  0.2500404417514801,\n",
              "  0.25028979778289795,\n",
              "  0.2500426471233368,\n",
              "  0.25008904933929443,\n",
              "  0.2502189576625824,\n",
              "  0.25023457407951355,\n",
              "  0.25023749470710754,\n",
              "  0.25018295645713806,\n",
              "  0.2500295639038086,\n",
              "  0.25009599328041077,\n",
              "  0.2502523362636566,\n",
              "  0.25006014108657837,\n",
              "  0.25011590123176575,\n",
              "  0.25036197900772095,\n",
              "  0.25008875131607056,\n",
              "  0.2501308023929596,\n",
              "  0.2502410113811493,\n",
              "  0.2500622570514679,\n",
              "  0.25008463859558105,\n",
              "  0.2503078281879425,\n",
              "  0.2500856816768646,\n",
              "  0.2501513361930847,\n",
              "  0.25017398595809937,\n",
              "  0.250173419713974,\n",
              "  0.2502056360244751,\n",
              "  0.2500564754009247,\n",
              "  0.2501330077648163,\n",
              "  0.2501419484615326,\n",
              "  0.25014060735702515,\n",
              "  0.25015926361083984,\n",
              "  0.2501797676086426,\n",
              "  0.250028520822525,\n",
              "  0.2501077651977539,\n",
              "  0.2500922381877899,\n",
              "  0.2501281499862671,\n",
              "  0.2502892017364502,\n",
              "  0.2502788305282593,\n",
              "  0.25016361474990845,\n",
              "  0.25022271275520325,\n",
              "  0.2502683103084564,\n",
              "  0.25008219480514526,\n",
              "  0.25017473101615906,\n",
              "  0.25011444091796875,\n",
              "  0.25043433904647827,\n",
              "  0.25009456276893616,\n",
              "  0.250079482793808,\n",
              "  0.2500768303871155,\n",
              "  0.2500685155391693,\n",
              "  0.2500682473182678,\n",
              "  0.25028860569000244,\n",
              "  0.25020626187324524,\n",
              "  0.2502325773239136,\n",
              "  0.250138521194458,\n",
              "  0.2502234876155853,\n",
              "  0.250078022480011,\n",
              "  0.25014662742614746,\n",
              "  0.2501474916934967,\n",
              "  0.250195175409317,\n",
              "  0.25011590123176575,\n",
              "  0.2502020001411438,\n",
              "  0.25027868151664734,\n",
              "  0.2500341236591339,\n",
              "  0.25018930435180664,\n",
              "  0.2500729560852051,\n",
              "  0.2501470148563385,\n",
              "  0.2501116991043091,\n",
              "  0.2500888407230377,\n",
              "  0.250006765127182,\n",
              "  0.25007104873657227,\n",
              "  0.2501843571662903,\n",
              "  0.25012460350990295,\n",
              "  0.2500416934490204,\n",
              "  0.2500418424606323,\n",
              "  0.25029677152633667,\n",
              "  0.2501724362373352,\n",
              "  0.2500474154949188,\n",
              "  0.2500932812690735,\n",
              "  0.2500515878200531,\n",
              "  0.25003913044929504,\n",
              "  0.25016674399375916,\n",
              "  0.2501455843448639,\n",
              "  0.2500608563423157,\n",
              "  0.25018757581710815,\n",
              "  0.2500711977481842,\n",
              "  0.25021785497665405,\n",
              "  0.25022730231285095,\n",
              "  0.2501252293586731,\n",
              "  0.2501271069049835,\n",
              "  0.2501051723957062,\n",
              "  0.2501739263534546,\n",
              "  0.2501884400844574,\n",
              "  0.25010746717453003,\n",
              "  0.2501702606678009,\n",
              "  0.2502315044403076,\n",
              "  0.2501881718635559,\n",
              "  0.2501755356788635,\n",
              "  0.2501448094844818,\n",
              "  0.25004062056541443,\n",
              "  0.25010812282562256,\n",
              "  0.2502087950706482,\n",
              "  0.25019001960754395,\n",
              "  0.2500559389591217,\n",
              "  0.25006216764450073,\n",
              "  0.25016868114471436,\n",
              "  0.25007569789886475,\n",
              "  0.2500653862953186,\n",
              "  0.2500462234020233,\n",
              "  0.2501147389411926,\n",
              "  0.2500883936882019,\n",
              "  0.25004515051841736,\n",
              "  0.2500933110713959,\n",
              "  0.25003013014793396,\n",
              "  0.25004640221595764,\n",
              "  0.2501910626888275,\n",
              "  0.2500462234020233,\n",
              "  0.2500371038913727,\n",
              "  0.2501196265220642,\n",
              "  0.2501235902309418,\n",
              "  0.250117689371109,\n",
              "  0.2501179575920105,\n",
              "  0.2500641644001007,\n",
              "  0.2500622272491455,\n",
              "  0.25048181414604187,\n",
              "  0.25019216537475586,\n",
              "  0.25010910630226135,\n",
              "  0.250199556350708,\n",
              "  0.25007158517837524,\n",
              "  0.2500978410243988,\n",
              "  0.2500637173652649,\n",
              "  0.2503169775009155,\n",
              "  0.25009626150131226,\n",
              "  0.25014179944992065,\n",
              "  0.2500685751438141,\n",
              "  0.2502613663673401,\n",
              "  0.2502273917198181,\n",
              "  0.25015175342559814,\n",
              "  0.2502171993255615,\n",
              "  0.2501513957977295,\n",
              "  0.25023263692855835,\n",
              "  0.25018516182899475,\n",
              "  0.2500053346157074,\n",
              "  0.25009995698928833,\n",
              "  0.25016751885414124,\n",
              "  0.25013309717178345,\n",
              "  0.2500149607658386,\n",
              "  0.25034454464912415,\n",
              "  0.2500329315662384,\n",
              "  0.24994687736034393,\n",
              "  0.2501663267612457,\n",
              "  0.25014254450798035,\n",
              "  0.24995939433574677,\n",
              "  0.25014111399650574,\n",
              "  0.25028368830680847,\n",
              "  0.2500511705875397,\n",
              "  0.2500227093696594,\n",
              "  0.25008532404899597,\n",
              "  0.2500748038291931,\n",
              "  0.2500973045825958,\n",
              "  0.2503249943256378,\n",
              "  0.2500282824039459,\n",
              "  0.2501704692840576,\n",
              "  0.25005605816841125,\n",
              "  0.25025931000709534,\n",
              "  0.2500438094139099,\n",
              "  0.25008073449134827,\n",
              "  0.2501114010810852,\n",
              "  0.2500856816768646,\n",
              "  0.2501092255115509,\n",
              "  0.25000739097595215,\n",
              "  0.2502036690711975,\n",
              "  0.25029510259628296,\n",
              "  0.25016480684280396,\n",
              "  0.25013649463653564,\n",
              "  0.2502041161060333,\n",
              "  0.2501426041126251,\n",
              "  0.2504193186759949,\n",
              "  0.2500154376029968,\n",
              "  0.25011593103408813,\n",
              "  0.25018638372421265,\n",
              "  0.2500932216644287,\n",
              "  0.2502245306968689,\n",
              "  0.2503465414047241,\n",
              "  0.2504992187023163,\n",
              "  0.2503414750099182,\n",
              "  0.25009167194366455,\n",
              "  0.2500686049461365,\n",
              "  0.2502162754535675,\n",
              "  0.25031498074531555,\n",
              "  0.25002574920654297,\n",
              "  0.25013306736946106,\n",
              "  0.2500700056552887,\n",
              "  0.2501237392425537,\n",
              "  0.25010767579078674,\n",
              "  0.2501290738582611,\n",
              "  0.2500101923942566,\n",
              "  0.2500729262828827,\n",
              "  0.25000014901161194,\n",
              "  0.24995870888233185,\n",
              "  0.2501250207424164,\n",
              "  0.2502579987049103,\n",
              "  0.25005459785461426,\n",
              "  0.25013014674186707,\n",
              "  0.2500265836715698,\n",
              "  0.2500685751438141,\n",
              "  0.2500496804714203,\n",
              "  0.250028133392334,\n",
              "  0.25010743737220764,\n",
              "  0.24994856119155884,\n",
              "  0.2500021457672119,\n",
              "  0.25027409195899963,\n",
              "  0.2500920593738556,\n",
              "  0.2504730820655823,\n",
              "  0.25052905082702637,\n",
              "  0.25001758337020874,\n",
              "  0.2501346468925476,\n",
              "  0.25007641315460205,\n",
              "  0.2500748634338379,\n",
              "  0.25016531348228455,\n",
              "  0.25003722310066223,\n",
              "  0.25018271803855896,\n",
              "  0.2501598596572876,\n",
              "  0.25021880865097046,\n",
              "  0.2500568628311157,\n",
              "  0.2500384747982025,\n",
              "  0.25034254789352417,\n",
              "  0.25000810623168945,\n",
              "  0.2503521740436554,\n",
              "  0.25026875734329224,\n",
              "  0.25008341670036316,\n",
              "  0.25009486079216003,\n",
              "  0.25004157423973083,\n",
              "  0.2500320076942444,\n",
              "  0.25005903840065,\n",
              "  0.25049155950546265,\n",
              "  0.2504768371582031,\n",
              "  0.2506260871887207,\n",
              "  0.25006306171417236,\n",
              "  0.2501789629459381,\n",
              "  0.25011342763900757,\n",
              "  0.250114381313324,\n",
              "  0.2501662075519562,\n",
              "  0.25021177530288696,\n",
              "  0.2503766119480133,\n",
              "  0.2502315938472748,\n",
              "  0.2501126527786255,\n",
              "  0.25008293986320496,\n",
              "  0.2500934302806854,\n",
              "  0.2500703036785126,\n",
              "  0.25020959973335266,\n",
              "  0.2502654194831848,\n",
              "  0.250029593706131,\n",
              "  0.2501187324523926,\n",
              "  0.2504386007785797,\n",
              "  0.25003156065940857,\n",
              "  0.25005409121513367,\n",
              "  0.2500877380371094,\n",
              "  0.2500939667224884,\n",
              "  0.2501184344291687,\n",
              "  0.2500896453857422,\n",
              "  0.25019872188568115,\n",
              "  0.25009840726852417,\n",
              "  0.25010886788368225,\n",
              "  0.2501557469367981,\n",
              "  0.250295490026474,\n",
              "  0.25009408593177795,\n",
              "  0.25012028217315674,\n",
              "  0.25013023614883423,\n",
              "  0.25007039308547974,\n",
              "  0.2501794695854187,\n",
              "  0.25015878677368164,\n",
              "  0.2500830590724945,\n",
              "  0.25010576844215393,\n",
              "  0.25006017088890076,\n",
              "  0.2502203583717346,\n",
              "  0.25042152404785156,\n",
              "  0.25037920475006104,\n",
              "  0.25011971592903137,\n",
              "  0.2500881850719452,\n",
              "  0.2501550614833832,\n",
              "  0.25008225440979004,\n",
              "  0.25009119510650635,\n",
              "  0.25012096762657166,\n",
              "  0.250079870223999,\n",
              "  0.2501368820667267,\n",
              "  0.2501387596130371,\n",
              "  0.25002726912498474,\n",
              "  0.25020837783813477,\n",
              "  0.2500631511211395,\n",
              "  0.2500666677951813,\n",
              "  0.25003698468208313,\n",
              "  0.2503105103969574,\n",
              "  0.2500176727771759,\n",
              "  0.2500305771827698,\n",
              "  0.2502829134464264,\n",
              "  0.25017276406288147,\n",
              "  0.2503054738044739,\n",
              "  0.25001946091651917,\n",
              "  0.2501344382762909,\n",
              "  0.2501024305820465,\n",
              "  0.2501646876335144,\n",
              "  0.2500174939632416,\n",
              "  0.2812720835208893,\n",
              "  0.25016313791275024,\n",
              "  0.25014528632164,\n",
              "  0.2501224875450134,\n",
              "  0.25012871623039246,\n",
              "  0.2503170669078827,\n",
              "  0.250101774930954,\n",
              "  0.2500636577606201,\n",
              "  0.250421404838562,\n",
              "  0.24993623793125153,\n",
              "  0.25014933943748474,\n",
              "  0.250066876411438,\n",
              "  0.25024551153182983,\n",
              "  0.25006818771362305,\n",
              "  0.24993175268173218,\n",
              "  0.2500920295715332,\n",
              "  0.2501707077026367,\n",
              "  0.25015029311180115,\n",
              "  0.2500457763671875,\n",
              "  0.2502537965774536,\n",
              "  0.2501576840877533,\n",
              "  0.25020015239715576,\n",
              "  0.2500297427177429,\n",
              "  0.25005921721458435,\n",
              "  0.25026389956474304,\n",
              "  0.25023457407951355,\n",
              "  0.24998699128627777,\n",
              "  0.25019189715385437,\n",
              "  0.2501220405101776,\n",
              "  0.25025150179862976,\n",
              "  0.2503356337547302,\n",
              "  0.2501658797264099,\n",
              "  0.24999554455280304,\n",
              "  0.2501150965690613,\n",
              "  0.25012701749801636,\n",
              "  0.25009000301361084,\n",
              "  0.25016942620277405,\n",
              "  0.2501840889453888,\n",
              "  0.25012820959091187,\n",
              "  0.25009381771087646,\n",
              "  0.25014257431030273,\n",
              "  0.25008463859558105,\n",
              "  0.2502394914627075,\n",
              "  0.2500486969947815,\n",
              "  0.25008732080459595,\n",
              "  0.2501527667045593,\n",
              "  0.2502278685569763,\n",
              "  0.2500486373901367,\n",
              "  0.250124990940094,\n",
              "  0.25031378865242004,\n",
              "  0.2502819895744324,\n",
              "  0.2500931918621063,\n",
              "  0.2501872777938843,\n",
              "  0.2502187490463257,\n",
              "  0.25006043910980225,\n",
              "  0.2500404715538025,\n",
              "  0.2502425014972687,\n",
              "  0.2501547336578369,\n",
              "  0.2502965033054352,\n",
              "  0.25008881092071533,\n",
              "  0.2500399351119995,\n",
              "  0.25014528632164,\n",
              "  0.2500501573085785,\n",
              "  0.25004813075065613,\n",
              "  0.25046730041503906,\n",
              "  0.25009340047836304,\n",
              "  0.2501165568828583,\n",
              "  0.25051090121269226,\n",
              "  0.25015679001808167,\n",
              "  0.2500953674316406,\n",
              "  0.25008994340896606,\n",
              "  0.250121533870697,\n",
              "  0.25012362003326416,\n",
              "  0.2500685453414917,\n",
              "  0.25013232231140137,\n",
              "  0.25000813603401184,\n",
              "  0.25009915232658386,\n",
              "  0.25018975138664246,\n",
              "  0.2500596046447754,\n",
              "  0.250152051448822,\n",
              "  0.2503100633621216,\n",
              "  0.25004681944847107,\n",
              "  0.2501683533191681,\n",
              "  0.2501664459705353,\n",
              "  0.25012290477752686,\n",
              "  0.2502685487270355,\n",
              "  0.25013065338134766,\n",
              "  0.25008392333984375,\n",
              "  0.2502649426460266,\n",
              "  0.25002580881118774,\n",
              "  0.25020813941955566,\n",
              "  0.25015488266944885,\n",
              "  0.25026294589042664,\n",
              "  0.2502366304397583,\n",
              "  0.25036492943763733,\n",
              "  0.2503895163536072,\n",
              "  0.25008174777030945,\n",
              "  0.25007444620132446,\n",
              "  0.25046566128730774,\n",
              "  0.25038573145866394,\n",
              "  0.25042974948883057,\n",
              "  0.2503473460674286,\n",
              "  0.2501494288444519,\n",
              "  0.2500375807285309,\n",
              "  0.2500004768371582,\n",
              "  0.2501170337200165,\n",
              "  0.25013262033462524,\n",
              "  0.2501494288444519,\n",
              "  0.2502623200416565,\n",
              "  0.2500416040420532,\n",
              "  0.25024840235710144,\n",
              "  0.250049889087677,\n",
              "  0.2500591278076172,\n",
              "  0.2500048577785492,\n",
              "  0.25004565715789795,\n",
              "  0.2501278519630432,\n",
              "  0.25008806586265564,\n",
              "  0.2501779794692993,\n",
              "  0.25024816393852234,\n",
              "  0.2500218451023102,\n",
              "  0.25005021691322327,\n",
              "  0.25017407536506653,\n",
              "  0.25002142786979675,\n",
              "  0.25017353892326355,\n",
              "  0.2505378723144531,\n",
              "  0.25010374188423157,\n",
              "  0.25007712841033936,\n",
              "  0.25012362003326416,\n",
              "  0.25004467368125916,\n",
              "  0.2501392662525177,\n",
              "  0.25014743208885193,\n",
              "  0.2501820921897888,\n",
              "  0.2500971853733063,\n",
              "  0.2501259446144104,\n",
              "  0.25029316544532776,\n",
              "  0.25015315413475037,\n",
              "  0.25006842613220215,\n",
              "  0.2503175735473633,\n",
              "  0.25011545419692993,\n",
              "  0.2503689229488373,\n",
              "  0.25020742416381836,\n",
              "  0.25008657574653625,\n",
              "  0.2500261664390564,\n",
              "  0.25012704730033875,\n",
              "  0.2500706911087036,\n",
              "  0.25010719895362854,\n",
              "  0.2501251995563507,\n",
              "  0.25010040402412415,\n",
              "  0.2500670850276947,\n",
              "  0.2501010596752167,\n",
              "  0.2500452399253845,\n",
              "  0.25012433528900146,\n",
              "  0.2501029372215271,\n",
              "  0.2500203847885132,\n",
              "  0.25018906593322754,\n",
              "  0.2500411570072174,\n",
              "  0.2501053810119629,\n",
              "  0.2500649094581604,\n",
              "  0.25025907158851624,\n",
              "  0.2500772774219513,\n",
              "  0.2501908242702484,\n",
              "  0.25034695863723755,\n",
              "  0.2502383291721344,\n",
              "  0.25008776783943176,\n",
              "  0.2500516176223755,\n",
              "  0.25004735589027405,\n",
              "  0.25011590123176575,\n",
              "  0.25009578466415405,\n",
              "  0.2501535713672638,\n",
              "  0.25007298588752747,\n",
              "  0.2501135766506195,\n",
              "  0.2504202723503113,\n",
              "  0.25012409687042236,\n",
              "  0.2502673268318176,\n",
              "  0.25002431869506836,\n",
              "  0.25009700655937195,\n",
              "  0.2501145005226135,\n",
              "  0.25014325976371765,\n",
              "  0.25021517276763916,\n",
              "  0.25015485286712646,\n",
              "  0.2500930726528168,\n",
              "  0.25011149048805237,\n",
              "  0.25050538778305054,\n",
              "  0.25014838576316833,\n",
              "  0.2501164376735687,\n",
              "  0.25018757581710815,\n",
              "  0.2500461935997009,\n",
              "  0.25009438395500183,\n",
              "  0.2501957416534424,\n",
              "  0.25013643503189087,\n",
              "  0.25021880865097046,\n",
              "  0.25010329484939575,\n",
              "  0.2500190734863281,\n",
              "  0.25010743737220764,\n",
              "  0.250105619430542,\n",
              "  0.25027650594711304,\n",
              "  0.25009894371032715,\n",
              "  0.2501542568206787,\n",
              "  0.25007960200309753,\n",
              "  0.2501165568828583,\n",
              "  0.25006014108657837,\n",
              "  0.2500705122947693,\n",
              "  0.25017040967941284,\n",
              "  0.25023749470710754,\n",
              "  0.2500770688056946,\n",
              "  0.2503035068511963,\n",
              "  0.25001996755599976,\n",
              "  0.25011494755744934,\n",
              "  0.2502115070819855,\n",
              "  0.2503354847431183,\n",
              "  0.25005903840065,\n",
              "  0.2500164210796356,\n",
              "  0.25016599893569946,\n",
              "  0.25015392899513245,\n",
              "  0.250095933675766,\n",
              "  0.25014662742614746,\n",
              "  0.25014761090278625,\n",
              "  0.2503196895122528,\n",
              "  0.25022420287132263,\n",
              "  0.25005900859832764,\n",
              "  0.2501130998134613,\n",
              "  0.2500207722187042,\n",
              "  0.2501366436481476,\n",
              "  0.2500690519809723,\n",
              "  0.2501693665981293,\n",
              "  0.2502756416797638,\n",
              "  0.25012677907943726,\n",
              "  0.25008898973464966,\n",
              "  0.25016459822654724,\n",
              "  0.25020942091941833,\n",
              "  0.2501048445701599,\n",
              "  0.2501521706581116,\n",
              "  0.2500437796115875,\n",
              "  0.25007009506225586,\n",
              "  0.25006920099258423,\n",
              "  0.2502557933330536,\n",
              "  0.2500966787338257,\n",
              "  0.2501664459705353,\n",
              "  0.25014832615852356,\n",
              "  0.2501251995563507,\n",
              "  0.2502157986164093,\n",
              "  0.2501829266548157,\n",
              "  0.2501651644706726,\n",
              "  0.2500520944595337,\n",
              "  0.2501516044139862,\n",
              "  0.24999716877937317,\n",
              "  0.24991852045059204,\n",
              "  0.2501557469367981,\n",
              "  0.25013595819473267,\n",
              "  0.25030994415283203,\n",
              "  0.2500796914100647,\n",
              "  0.2500869929790497,\n",
              "  0.24997760355472565,\n",
              "  0.24998654425144196,\n",
              "  0.25009503960609436,\n",
              "  0.250099778175354,\n",
              "  0.25011852383613586,\n",
              "  0.2502641975879669,\n",
              "  0.2501811981201172,\n",
              "  0.2500174939632416,\n",
              "  0.2502456605434418,\n",
              "  0.2501056492328644,\n",
              "  0.25015679001808167,\n",
              "  0.25032198429107666,\n",
              "  0.2501204311847687,\n",
              "  0.2500987648963928,\n",
              "  0.2502707540988922,\n",
              "  0.25003567337989807,\n",
              "  0.2500465512275696,\n",
              "  0.25007733702659607,\n",
              "  0.2501133382320404,\n",
              "  0.2500396966934204,\n",
              "  0.2500912845134735,\n",
              "  0.25006580352783203,\n",
              "  0.25010955333709717,\n",
              "  0.25030770897865295,\n",
              "  0.25005537271499634,\n",
              "  0.2501707673072815,\n",
              "  0.25027230381965637,\n",
              "  0.2500669062137604,\n",
              "  0.25005027651786804,\n",
              "  0.2500668168067932,\n",
              "  0.2502153515815735,\n",
              "  0.2503153085708618,\n",
              "  0.25008293986320496,\n",
              "  0.2500936686992645,\n",
              "  0.25008222460746765,\n",
              "  0.2501600384712219,\n",
              "  0.25010910630226135,\n",
              "  0.25027796626091003,\n",
              "  0.2500195801258087,\n",
              "  0.25015953183174133,\n",
              "  0.2501247227191925,\n",
              "  0.25005874037742615,\n",
              "  0.2501387894153595,\n",
              "  0.2505189776420593,\n",
              "  0.250101238489151,\n",
              "  0.25002700090408325,\n",
              "  0.2501971125602722,\n",
              "  0.25008225440979004,\n",
              "  0.25011688470840454,\n",
              "  0.25016602873802185,\n",
              "  0.2500775456428528,\n",
              "  0.25012871623039246,\n",
              "  0.25015953183174133,\n",
              "  0.25033465027809143,\n",
              "  0.2500615417957306,\n",
              "  0.2500794231891632,\n",
              "  0.2500477135181427,\n",
              "  0.25019994378089905,\n",
              "  0.2500602602958679,\n",
              "  0.25052592158317566,\n",
              "  0.2500268220901489,\n",
              "  0.2500518262386322,\n",
              "  0.2501642107963562,\n",
              "  0.250379741191864,\n",
              "  0.24998225271701813,\n",
              "  0.2500620186328888,\n",
              "  0.2501815855503082,\n",
              "  0.2500874400138855,\n",
              "  0.25012609362602234,\n",
              "  0.25006160140037537,\n",
              "  0.2501084804534912,\n",
              "  0.2500896453857422,\n",
              "  0.25008320808410645,\n",
              "  0.2501147985458374,\n",
              "  0.25019335746765137,\n",
              "  0.2502079904079437,\n",
              "  0.2501586675643921,\n",
              "  0.2501693665981293,\n",
              "  0.2501683533191681,\n",
              "  0.25040653347969055,\n",
              "  0.2502278983592987,\n",
              "  0.2501184046268463,\n",
              "  0.2502906918525696,\n",
              "  0.2503959536552429,\n",
              "  0.24999254941940308,\n",
              "  0.2504047155380249,\n",
              "  0.2501014769077301,\n",
              "  0.2503100633621216,\n",
              "  0.25007888674736023,\n",
              "  0.25019368529319763,\n",
              "  0.25007909536361694,\n",
              "  0.25013744831085205,\n",
              "  0.2501354217529297,\n",
              "  0.2501736283302307,\n",
              "  0.25018906593322754,\n",
              "  0.2503052055835724,\n",
              "  0.2501768171787262,\n",
              "  0.2501249611377716,\n",
              "  0.2501211166381836,\n",
              "  0.2501177191734314,\n",
              "  0.2501294016838074,\n",
              "  0.2503140866756439,\n",
              "  0.2502121329307556,\n",
              "  0.2501435875892639,\n",
              "  0.2501402795314789,\n",
              "  0.25005120038986206,\n",
              "  0.25022029876708984,\n",
              "  0.2501886487007141,\n",
              "  0.250043660402298,\n",
              "  0.2501835823059082,\n",
              "  0.25009873509407043,\n",
              "  0.25009384751319885,\n",
              "  0.25032615661621094,\n",
              "  0.25032955408096313,\n",
              "  0.25014564394950867,\n",
              "  0.2501401901245117,\n",
              "  0.2501256763935089,\n",
              "  0.2501309812068939,\n",
              "  0.2500928044319153,\n",
              "  0.2500205636024475,\n",
              "  0.2502272427082062,\n",
              "  0.2500779628753662,\n",
              "  0.25034967064857483,\n",
              "  0.25017592310905457,\n",
              "  0.2500952482223511,\n",
              "  0.25019630789756775,\n",
              "  0.2502257823944092,\n",
              "  0.2501453459262848,\n",
              "  0.25014203786849976,\n",
              "  0.2500358819961548,\n",
              "  0.25009122490882874,\n",
              "  0.25006893277168274,\n",
              "  0.2501542866230011,\n",
              "  0.2500568628311157,\n",
              "  0.2501254379749298,\n",
              "  0.250337153673172,\n",
              "  0.25016260147094727,\n",
              "  0.2501305043697357,\n",
              "  0.25010037422180176,\n",
              "  0.25033339858055115,\n",
              "  0.25061503052711487,\n",
              "  0.25009071826934814,\n",
              "  0.2500438988208771,\n",
              "  0.2501412630081177,\n",
              "  0.2502303719520569,\n",
              "  0.25031912326812744,\n",
              "  0.2501187324523926,\n",
              "  0.250099241733551,\n",
              "  0.2502317726612091,\n",
              "  0.2501077950000763,\n",
              "  0.25003549456596375,\n",
              "  0.2501537799835205,\n",
              "  0.2500779926776886,\n",
              "  0.25006812810897827,\n",
              "  0.25048065185546875,\n",
              "  0.2501762807369232,\n",
              "  0.25009843707084656,\n",
              "  0.2500419616699219,\n",
              "  0.25022903084754944,\n",
              "  0.25007256865501404,\n",
              "  0.25004029273986816,\n",
              "  0.25022605061531067,\n",
              "  0.2500799000263214,\n",
              "  0.2501010298728943,\n",
              "  0.25017842650413513,\n",
              "  0.25007960200309753],\n",
              " 'mse': [0.4037855565547943,\n",
              "  0.30825313925743103,\n",
              "  0.28462326526641846,\n",
              "  0.26867586374282837,\n",
              "  0.2613040506839752,\n",
              "  0.25613442063331604,\n",
              "  0.2528182864189148,\n",
              "  0.2516881823539734,\n",
              "  0.25066202878952026,\n",
              "  0.2502664625644684,\n",
              "  0.25012779235839844,\n",
              "  0.2501896023750305,\n",
              "  0.2500578761100769,\n",
              "  0.250104695558548,\n",
              "  0.2500353753566742,\n",
              "  0.25006571412086487,\n",
              "  0.25015124678611755,\n",
              "  0.25010034441947937,\n",
              "  0.25011664628982544,\n",
              "  0.250235915184021,\n",
              "  0.25006309151649475,\n",
              "  0.25015392899513245,\n",
              "  0.25009915232658386,\n",
              "  0.2500876784324646,\n",
              "  0.2500804364681244,\n",
              "  0.25030091404914856,\n",
              "  0.2501148581504822,\n",
              "  0.2501574754714966,\n",
              "  0.250099241733551,\n",
              "  0.25009697675704956,\n",
              "  0.25004658102989197,\n",
              "  0.250092089176178,\n",
              "  0.2500333786010742,\n",
              "  0.2500717043876648,\n",
              "  0.25028494000434875,\n",
              "  0.2501043379306793,\n",
              "  0.25002577900886536,\n",
              "  0.25007057189941406,\n",
              "  0.2500317692756653,\n",
              "  0.25000330805778503,\n",
              "  0.25008663535118103,\n",
              "  0.2500711977481842,\n",
              "  0.2500937581062317,\n",
              "  0.25000083446502686,\n",
              "  0.2501813471317291,\n",
              "  0.2501200735569,\n",
              "  0.2500520944595337,\n",
              "  0.25005021691322327,\n",
              "  0.2501475512981415,\n",
              "  0.2501224875450134,\n",
              "  0.2500874102115631,\n",
              "  0.25009894371032715,\n",
              "  0.2500704526901245,\n",
              "  0.2501193881034851,\n",
              "  0.25009894371032715,\n",
              "  0.25007617473602295,\n",
              "  0.2501957416534424,\n",
              "  0.25011512637138367,\n",
              "  0.2500356435775757,\n",
              "  0.25028151273727417,\n",
              "  0.2501155436038971,\n",
              "  0.2502193748950958,\n",
              "  0.2500455677509308,\n",
              "  0.250122994184494,\n",
              "  0.25000062584877014,\n",
              "  0.2500239908695221,\n",
              "  0.25011375546455383,\n",
              "  0.25004813075065613,\n",
              "  0.25015246868133545,\n",
              "  0.25013503432273865,\n",
              "  0.25010374188423157,\n",
              "  0.25010398030281067,\n",
              "  0.2501564621925354,\n",
              "  0.25041326880455017,\n",
              "  0.25006309151649475,\n",
              "  0.25011956691741943,\n",
              "  0.2501457631587982,\n",
              "  0.25012722611427307,\n",
              "  0.2501460015773773,\n",
              "  0.25012099742889404,\n",
              "  0.2500735819339752,\n",
              "  0.25015294551849365,\n",
              "  0.2500644028186798,\n",
              "  0.25052300095558167,\n",
              "  0.25022411346435547,\n",
              "  0.25014597177505493,\n",
              "  0.2502024173736572,\n",
              "  0.25008445978164673,\n",
              "  0.25018152594566345,\n",
              "  0.2500576376914978,\n",
              "  0.2499748319387436,\n",
              "  0.2503698468208313,\n",
              "  0.2502729892730713,\n",
              "  0.2501513361930847,\n",
              "  0.25008079409599304,\n",
              "  0.25004658102989197,\n",
              "  0.25009071826934814,\n",
              "  0.25025346875190735,\n",
              "  0.25001099705696106,\n",
              "  0.25008708238601685,\n",
              "  0.26376453042030334,\n",
              "  0.2500794529914856,\n",
              "  0.2501212954521179,\n",
              "  0.2501179575920105,\n",
              "  0.2501058280467987,\n",
              "  0.25016993284225464,\n",
              "  0.250189870595932,\n",
              "  0.25023385882377625,\n",
              "  0.2502639591693878,\n",
              "  0.2503085434436798,\n",
              "  0.25005650520324707,\n",
              "  0.25013530254364014,\n",
              "  0.2501330077648163,\n",
              "  0.2501816153526306,\n",
              "  0.25004392862319946,\n",
              "  0.2503759562969208,\n",
              "  0.2501504123210907,\n",
              "  0.2500721216201782,\n",
              "  0.25006887316703796,\n",
              "  0.24999643862247467,\n",
              "  0.25032469630241394,\n",
              "  0.25021111965179443,\n",
              "  0.2500796616077423,\n",
              "  0.25015026330947876,\n",
              "  0.24999696016311646,\n",
              "  0.25021910667419434,\n",
              "  0.2500571310520172,\n",
              "  0.2502390146255493,\n",
              "  0.2500517666339874,\n",
              "  0.2500433325767517,\n",
              "  0.2501022517681122,\n",
              "  0.25035759806632996,\n",
              "  0.25012436509132385,\n",
              "  0.2500856816768646,\n",
              "  0.2501874268054962,\n",
              "  0.2501535713672638,\n",
              "  0.2500436007976532,\n",
              "  0.2500837743282318,\n",
              "  0.24992746114730835,\n",
              "  0.2504240572452545,\n",
              "  0.25011107325553894,\n",
              "  0.2501268684864044,\n",
              "  0.250215619802475,\n",
              "  0.250020295381546,\n",
              "  0.25014111399650574,\n",
              "  0.2500125467777252,\n",
              "  0.2500852644443512,\n",
              "  0.250087171792984,\n",
              "  0.2501773238182068,\n",
              "  0.2501772344112396,\n",
              "  0.2501409351825714,\n",
              "  0.2503047585487366,\n",
              "  0.25009268522262573,\n",
              "  0.2500150501728058,\n",
              "  0.24999122321605682,\n",
              "  0.2500055730342865,\n",
              "  0.2501412630081177,\n",
              "  0.25002697110176086,\n",
              "  0.2502328157424927,\n",
              "  0.25010228157043457,\n",
              "  0.25018393993377686,\n",
              "  0.2501332759857178,\n",
              "  0.2501310110092163,\n",
              "  0.2500933110713959,\n",
              "  0.25039994716644287,\n",
              "  0.25012701749801636,\n",
              "  0.25011929869651794,\n",
              "  0.25020650029182434,\n",
              "  0.25003781914711,\n",
              "  0.25013330578804016,\n",
              "  0.2500138282775879,\n",
              "  0.2501259744167328,\n",
              "  0.25009885430336,\n",
              "  0.2500402331352234,\n",
              "  0.25010523200035095,\n",
              "  0.25014159083366394,\n",
              "  0.25009849667549133,\n",
              "  0.25041529536247253,\n",
              "  0.25040602684020996,\n",
              "  0.2499801516532898,\n",
              "  0.2501174509525299,\n",
              "  0.25016316771507263,\n",
              "  0.2500791549682617,\n",
              "  0.25014257431030273,\n",
              "  0.2501975893974304,\n",
              "  0.250198096036911,\n",
              "  0.2503025233745575,\n",
              "  0.2500609755516052,\n",
              "  0.25016093254089355,\n",
              "  0.2500486373901367,\n",
              "  0.25012311339378357,\n",
              "  0.2500660717487335,\n",
              "  0.2501958906650543,\n",
              "  0.2500409781932831,\n",
              "  0.2500585615634918,\n",
              "  0.2500530779361725,\n",
              "  0.25007304549217224,\n",
              "  0.25004446506500244,\n",
              "  0.25014349818229675,\n",
              "  0.25008565187454224,\n",
              "  0.25014838576316833,\n",
              "  0.2501702606678009,\n",
              "  0.25026145577430725,\n",
              "  0.2502366304397583,\n",
              "  0.2500292658805847,\n",
              "  0.25013479590415955,\n",
              "  0.25020506978034973,\n",
              "  0.25017601251602173,\n",
              "  0.2501158118247986,\n",
              "  0.2500424087047577,\n",
              "  0.2501993775367737,\n",
              "  0.2502857446670532,\n",
              "  0.2501203119754791,\n",
              "  0.2501089870929718,\n",
              "  0.25018206238746643,\n",
              "  0.25016817450523376,\n",
              "  0.25011253356933594,\n",
              "  0.25019603967666626,\n",
              "  0.2500694990158081,\n",
              "  0.25027796626091003,\n",
              "  0.25004157423973083,\n",
              "  0.250108927488327,\n",
              "  0.25013816356658936,\n",
              "  0.25004544854164124,\n",
              "  0.2501249313354492,\n",
              "  0.25004273653030396,\n",
              "  0.2500555217266083,\n",
              "  0.25017058849334717,\n",
              "  0.25012192130088806,\n",
              "  0.2502018213272095,\n",
              "  0.2500428557395935,\n",
              "  0.25001955032348633,\n",
              "  0.2501436769962311,\n",
              "  0.25001075863838196,\n",
              "  0.2501922845840454,\n",
              "  0.25015538930892944,\n",
              "  0.2501862645149231,\n",
              "  0.25009384751319885,\n",
              "  0.25012651085853577,\n",
              "  0.2500317096710205,\n",
              "  0.250027060508728,\n",
              "  0.2501264810562134,\n",
              "  0.2501372694969177,\n",
              "  0.2501280903816223,\n",
              "  0.2500748634338379,\n",
              "  0.25008752942085266,\n",
              "  0.2501072883605957,\n",
              "  0.2499815970659256,\n",
              "  0.250156044960022,\n",
              "  0.2501213252544403,\n",
              "  0.2502268850803375,\n",
              "  0.250315397977829,\n",
              "  0.2500118911266327,\n",
              "  0.25015825033187866,\n",
              "  0.2499307543039322,\n",
              "  0.2501017451286316,\n",
              "  0.25003963708877563,\n",
              "  0.2501869797706604,\n",
              "  0.25006890296936035,\n",
              "  0.25011682510375977,\n",
              "  0.2502397298812866,\n",
              "  0.25025779008865356,\n",
              "  0.2501446306705475,\n",
              "  0.25018763542175293,\n",
              "  0.2501770853996277,\n",
              "  0.2501508295536041,\n",
              "  0.25008875131607056,\n",
              "  0.25003087520599365,\n",
              "  0.2500693202018738,\n",
              "  0.250156044960022,\n",
              "  0.2501353621482849,\n",
              "  0.2501138746738434,\n",
              "  0.2501465380191803,\n",
              "  0.2500794529914856,\n",
              "  0.25009623169898987,\n",
              "  0.25011172890663147,\n",
              "  0.25012892484664917,\n",
              "  0.2500931918621063,\n",
              "  0.2502209544181824,\n",
              "  0.2500298023223877,\n",
              "  0.25007539987564087,\n",
              "  0.2500404417514801,\n",
              "  0.25028979778289795,\n",
              "  0.2500426471233368,\n",
              "  0.25008904933929443,\n",
              "  0.2502189576625824,\n",
              "  0.25023457407951355,\n",
              "  0.25023749470710754,\n",
              "  0.25018295645713806,\n",
              "  0.2500295639038086,\n",
              "  0.25009599328041077,\n",
              "  0.2502523362636566,\n",
              "  0.25006014108657837,\n",
              "  0.25011590123176575,\n",
              "  0.25036197900772095,\n",
              "  0.25008875131607056,\n",
              "  0.2501308023929596,\n",
              "  0.2502410113811493,\n",
              "  0.2500622570514679,\n",
              "  0.25008463859558105,\n",
              "  0.2503078281879425,\n",
              "  0.2500856816768646,\n",
              "  0.2501513361930847,\n",
              "  0.25017398595809937,\n",
              "  0.250173419713974,\n",
              "  0.2502056360244751,\n",
              "  0.2500564754009247,\n",
              "  0.2501330077648163,\n",
              "  0.2501419484615326,\n",
              "  0.25014060735702515,\n",
              "  0.25015926361083984,\n",
              "  0.2501797676086426,\n",
              "  0.250028520822525,\n",
              "  0.2501077651977539,\n",
              "  0.2500922381877899,\n",
              "  0.2501281499862671,\n",
              "  0.2502892017364502,\n",
              "  0.2502788305282593,\n",
              "  0.25016361474990845,\n",
              "  0.25022271275520325,\n",
              "  0.2502683103084564,\n",
              "  0.25008219480514526,\n",
              "  0.25017473101615906,\n",
              "  0.25011444091796875,\n",
              "  0.25043433904647827,\n",
              "  0.25009456276893616,\n",
              "  0.250079482793808,\n",
              "  0.2500768303871155,\n",
              "  0.2500685155391693,\n",
              "  0.2500682473182678,\n",
              "  0.25028860569000244,\n",
              "  0.25020626187324524,\n",
              "  0.2502325773239136,\n",
              "  0.250138521194458,\n",
              "  0.2502234876155853,\n",
              "  0.250078022480011,\n",
              "  0.25014662742614746,\n",
              "  0.2501474916934967,\n",
              "  0.250195175409317,\n",
              "  0.25011590123176575,\n",
              "  0.2502020001411438,\n",
              "  0.25027868151664734,\n",
              "  0.2500341236591339,\n",
              "  0.25018930435180664,\n",
              "  0.2500729560852051,\n",
              "  0.2501470148563385,\n",
              "  0.2501116991043091,\n",
              "  0.2500888407230377,\n",
              "  0.250006765127182,\n",
              "  0.25007104873657227,\n",
              "  0.2501843571662903,\n",
              "  0.25012460350990295,\n",
              "  0.2500416934490204,\n",
              "  0.2500418424606323,\n",
              "  0.25029677152633667,\n",
              "  0.2501724362373352,\n",
              "  0.2500474154949188,\n",
              "  0.2500932812690735,\n",
              "  0.2500515878200531,\n",
              "  0.25003913044929504,\n",
              "  0.25016674399375916,\n",
              "  0.2501455843448639,\n",
              "  0.2500608563423157,\n",
              "  0.25018757581710815,\n",
              "  0.2500711977481842,\n",
              "  0.25021785497665405,\n",
              "  0.25022730231285095,\n",
              "  0.2501252293586731,\n",
              "  0.2501271069049835,\n",
              "  0.2501051723957062,\n",
              "  0.2501739263534546,\n",
              "  0.2501884400844574,\n",
              "  0.25010746717453003,\n",
              "  0.2501702606678009,\n",
              "  0.2502315044403076,\n",
              "  0.2501881718635559,\n",
              "  0.2501755356788635,\n",
              "  0.2501448094844818,\n",
              "  0.25004062056541443,\n",
              "  0.25010812282562256,\n",
              "  0.2502087950706482,\n",
              "  0.25019001960754395,\n",
              "  0.2500559389591217,\n",
              "  0.25006216764450073,\n",
              "  0.25016868114471436,\n",
              "  0.25007569789886475,\n",
              "  0.2500653862953186,\n",
              "  0.2500462234020233,\n",
              "  0.2501147389411926,\n",
              "  0.2500883936882019,\n",
              "  0.25004515051841736,\n",
              "  0.2500933110713959,\n",
              "  0.25003013014793396,\n",
              "  0.25004640221595764,\n",
              "  0.2501910626888275,\n",
              "  0.2500462234020233,\n",
              "  0.2500371038913727,\n",
              "  0.2501196265220642,\n",
              "  0.2501235902309418,\n",
              "  0.250117689371109,\n",
              "  0.2501179575920105,\n",
              "  0.2500641644001007,\n",
              "  0.2500622272491455,\n",
              "  0.25048181414604187,\n",
              "  0.25019216537475586,\n",
              "  0.25010910630226135,\n",
              "  0.250199556350708,\n",
              "  0.25007158517837524,\n",
              "  0.2500978410243988,\n",
              "  0.2500637173652649,\n",
              "  0.2503169775009155,\n",
              "  0.25009626150131226,\n",
              "  0.25014179944992065,\n",
              "  0.2500685751438141,\n",
              "  0.2502613663673401,\n",
              "  0.2502273917198181,\n",
              "  0.25015175342559814,\n",
              "  0.2502171993255615,\n",
              "  0.2501513957977295,\n",
              "  0.25023263692855835,\n",
              "  0.25018516182899475,\n",
              "  0.2500053346157074,\n",
              "  0.25009995698928833,\n",
              "  0.25016751885414124,\n",
              "  0.25013309717178345,\n",
              "  0.2500149607658386,\n",
              "  0.25034454464912415,\n",
              "  0.2500329315662384,\n",
              "  0.24994687736034393,\n",
              "  0.2501663267612457,\n",
              "  0.25014254450798035,\n",
              "  0.24995939433574677,\n",
              "  0.25014111399650574,\n",
              "  0.25028368830680847,\n",
              "  0.2500511705875397,\n",
              "  0.2500227093696594,\n",
              "  0.25008532404899597,\n",
              "  0.2500748038291931,\n",
              "  0.2500973045825958,\n",
              "  0.2503249943256378,\n",
              "  0.2500282824039459,\n",
              "  0.2501704692840576,\n",
              "  0.25005605816841125,\n",
              "  0.25025931000709534,\n",
              "  0.2500438094139099,\n",
              "  0.25008073449134827,\n",
              "  0.2501114010810852,\n",
              "  0.2500856816768646,\n",
              "  0.2501092255115509,\n",
              "  0.25000739097595215,\n",
              "  0.2502036690711975,\n",
              "  0.25029510259628296,\n",
              "  0.25016480684280396,\n",
              "  0.25013649463653564,\n",
              "  0.2502041161060333,\n",
              "  0.2501426041126251,\n",
              "  0.2504193186759949,\n",
              "  0.2500154376029968,\n",
              "  0.25011593103408813,\n",
              "  0.25018638372421265,\n",
              "  0.2500932216644287,\n",
              "  0.2502245306968689,\n",
              "  0.2503465414047241,\n",
              "  0.2504992187023163,\n",
              "  0.2503414750099182,\n",
              "  0.25009167194366455,\n",
              "  0.2500686049461365,\n",
              "  0.2502162754535675,\n",
              "  0.25031498074531555,\n",
              "  0.25002574920654297,\n",
              "  0.25013306736946106,\n",
              "  0.2500700056552887,\n",
              "  0.2501237392425537,\n",
              "  0.25010767579078674,\n",
              "  0.2501290738582611,\n",
              "  0.2500101923942566,\n",
              "  0.2500729262828827,\n",
              "  0.25000014901161194,\n",
              "  0.24995870888233185,\n",
              "  0.2501250207424164,\n",
              "  0.2502579987049103,\n",
              "  0.25005459785461426,\n",
              "  0.25013014674186707,\n",
              "  0.2500265836715698,\n",
              "  0.2500685751438141,\n",
              "  0.2500496804714203,\n",
              "  0.250028133392334,\n",
              "  0.25010743737220764,\n",
              "  0.24994856119155884,\n",
              "  0.2500021457672119,\n",
              "  0.25027409195899963,\n",
              "  0.2500920593738556,\n",
              "  0.2504730820655823,\n",
              "  0.25052905082702637,\n",
              "  0.25001758337020874,\n",
              "  0.2501346468925476,\n",
              "  0.25007641315460205,\n",
              "  0.2500748634338379,\n",
              "  0.25016531348228455,\n",
              "  0.25003722310066223,\n",
              "  0.25018271803855896,\n",
              "  0.2501598596572876,\n",
              "  0.25021880865097046,\n",
              "  0.2500568628311157,\n",
              "  0.2500384747982025,\n",
              "  0.25034254789352417,\n",
              "  0.25000810623168945,\n",
              "  0.2503521740436554,\n",
              "  0.25026875734329224,\n",
              "  0.25008341670036316,\n",
              "  0.25009486079216003,\n",
              "  0.25004157423973083,\n",
              "  0.2500320076942444,\n",
              "  0.25005903840065,\n",
              "  0.25049155950546265,\n",
              "  0.2504768371582031,\n",
              "  0.2506260871887207,\n",
              "  0.25006306171417236,\n",
              "  0.2501789629459381,\n",
              "  0.25011342763900757,\n",
              "  0.250114381313324,\n",
              "  0.2501662075519562,\n",
              "  0.25021177530288696,\n",
              "  0.2503766119480133,\n",
              "  0.2502315938472748,\n",
              "  0.2501126527786255,\n",
              "  0.25008293986320496,\n",
              "  0.2500934302806854,\n",
              "  0.2500703036785126,\n",
              "  0.25020959973335266,\n",
              "  0.2502654194831848,\n",
              "  0.250029593706131,\n",
              "  0.2501187324523926,\n",
              "  0.2504386007785797,\n",
              "  0.25003156065940857,\n",
              "  0.25005409121513367,\n",
              "  0.2500877380371094,\n",
              "  0.2500939667224884,\n",
              "  0.2501184344291687,\n",
              "  0.2500896453857422,\n",
              "  0.25019872188568115,\n",
              "  0.25009840726852417,\n",
              "  0.25010886788368225,\n",
              "  0.2501557469367981,\n",
              "  0.250295490026474,\n",
              "  0.25009408593177795,\n",
              "  0.25012028217315674,\n",
              "  0.25013023614883423,\n",
              "  0.25007039308547974,\n",
              "  0.2501794695854187,\n",
              "  0.25015878677368164,\n",
              "  0.2500830590724945,\n",
              "  0.25010576844215393,\n",
              "  0.25006017088890076,\n",
              "  0.2502203583717346,\n",
              "  0.25042152404785156,\n",
              "  0.25037920475006104,\n",
              "  0.25011971592903137,\n",
              "  0.2500881850719452,\n",
              "  0.2501550614833832,\n",
              "  0.25008225440979004,\n",
              "  0.25009119510650635,\n",
              "  0.25012096762657166,\n",
              "  0.250079870223999,\n",
              "  0.2501368820667267,\n",
              "  0.2501387596130371,\n",
              "  0.25002726912498474,\n",
              "  0.25020837783813477,\n",
              "  0.2500631511211395,\n",
              "  0.2500666677951813,\n",
              "  0.25003698468208313,\n",
              "  0.2503105103969574,\n",
              "  0.2500176727771759,\n",
              "  0.2500305771827698,\n",
              "  0.2502829134464264,\n",
              "  0.25017276406288147,\n",
              "  0.2503054738044739,\n",
              "  0.25001946091651917,\n",
              "  0.2501344382762909,\n",
              "  0.2501024305820465,\n",
              "  0.2501646876335144,\n",
              "  0.2500174939632416,\n",
              "  0.2812720835208893,\n",
              "  0.25016313791275024,\n",
              "  0.25014528632164,\n",
              "  0.2501224875450134,\n",
              "  0.25012871623039246,\n",
              "  0.2503170669078827,\n",
              "  0.250101774930954,\n",
              "  0.2500636577606201,\n",
              "  0.250421404838562,\n",
              "  0.24993623793125153,\n",
              "  0.25014933943748474,\n",
              "  0.250066876411438,\n",
              "  0.25024551153182983,\n",
              "  0.25006818771362305,\n",
              "  0.24993175268173218,\n",
              "  0.2500920295715332,\n",
              "  0.2501707077026367,\n",
              "  0.25015029311180115,\n",
              "  0.2500457763671875,\n",
              "  0.2502537965774536,\n",
              "  0.2501576840877533,\n",
              "  0.25020015239715576,\n",
              "  0.2500297427177429,\n",
              "  0.25005921721458435,\n",
              "  0.25026389956474304,\n",
              "  0.25023457407951355,\n",
              "  0.24998699128627777,\n",
              "  0.25019189715385437,\n",
              "  0.2501220405101776,\n",
              "  0.25025150179862976,\n",
              "  0.2503356337547302,\n",
              "  0.2501658797264099,\n",
              "  0.24999554455280304,\n",
              "  0.2501150965690613,\n",
              "  0.25012701749801636,\n",
              "  0.25009000301361084,\n",
              "  0.25016942620277405,\n",
              "  0.2501840889453888,\n",
              "  0.25012820959091187,\n",
              "  0.25009381771087646,\n",
              "  0.25014257431030273,\n",
              "  0.25008463859558105,\n",
              "  0.2502394914627075,\n",
              "  0.2500486969947815,\n",
              "  0.25008732080459595,\n",
              "  0.2501527667045593,\n",
              "  0.2502278685569763,\n",
              "  0.2500486373901367,\n",
              "  0.250124990940094,\n",
              "  0.25031378865242004,\n",
              "  0.2502819895744324,\n",
              "  0.2500931918621063,\n",
              "  0.2501872777938843,\n",
              "  0.2502187490463257,\n",
              "  0.25006043910980225,\n",
              "  0.2500404715538025,\n",
              "  0.2502425014972687,\n",
              "  0.2501547336578369,\n",
              "  0.2502965033054352,\n",
              "  0.25008881092071533,\n",
              "  0.2500399351119995,\n",
              "  0.25014528632164,\n",
              "  0.2500501573085785,\n",
              "  0.25004813075065613,\n",
              "  0.25046730041503906,\n",
              "  0.25009340047836304,\n",
              "  0.2501165568828583,\n",
              "  0.25051090121269226,\n",
              "  0.25015679001808167,\n",
              "  0.2500953674316406,\n",
              "  0.25008994340896606,\n",
              "  0.250121533870697,\n",
              "  0.25012362003326416,\n",
              "  0.2500685453414917,\n",
              "  0.25013232231140137,\n",
              "  0.25000813603401184,\n",
              "  0.25009915232658386,\n",
              "  0.25018975138664246,\n",
              "  0.2500596046447754,\n",
              "  0.250152051448822,\n",
              "  0.2503100633621216,\n",
              "  0.25004681944847107,\n",
              "  0.2501683533191681,\n",
              "  0.2501664459705353,\n",
              "  0.25012290477752686,\n",
              "  0.2502685487270355,\n",
              "  0.25013065338134766,\n",
              "  0.25008392333984375,\n",
              "  0.2502649426460266,\n",
              "  0.25002580881118774,\n",
              "  0.25020813941955566,\n",
              "  0.25015488266944885,\n",
              "  0.25026294589042664,\n",
              "  0.2502366304397583,\n",
              "  0.25036492943763733,\n",
              "  0.2503895163536072,\n",
              "  0.25008174777030945,\n",
              "  0.25007444620132446,\n",
              "  0.25046566128730774,\n",
              "  0.25038573145866394,\n",
              "  0.25042974948883057,\n",
              "  0.2503473460674286,\n",
              "  0.2501494288444519,\n",
              "  0.2500375807285309,\n",
              "  0.2500004768371582,\n",
              "  0.2501170337200165,\n",
              "  0.25013262033462524,\n",
              "  0.2501494288444519,\n",
              "  0.2502623200416565,\n",
              "  0.2500416040420532,\n",
              "  0.25024840235710144,\n",
              "  0.250049889087677,\n",
              "  0.2500591278076172,\n",
              "  0.2500048577785492,\n",
              "  0.25004565715789795,\n",
              "  0.2501278519630432,\n",
              "  0.25008806586265564,\n",
              "  0.2501779794692993,\n",
              "  0.25024816393852234,\n",
              "  0.2500218451023102,\n",
              "  0.25005021691322327,\n",
              "  0.25017407536506653,\n",
              "  0.25002142786979675,\n",
              "  0.25017353892326355,\n",
              "  0.2505378723144531,\n",
              "  0.25010374188423157,\n",
              "  0.25007712841033936,\n",
              "  0.25012362003326416,\n",
              "  0.25004467368125916,\n",
              "  0.2501392662525177,\n",
              "  0.25014743208885193,\n",
              "  0.2501820921897888,\n",
              "  0.2500971853733063,\n",
              "  0.2501259446144104,\n",
              "  0.25029316544532776,\n",
              "  0.25015315413475037,\n",
              "  0.25006842613220215,\n",
              "  0.2503175735473633,\n",
              "  0.25011545419692993,\n",
              "  0.2503689229488373,\n",
              "  0.25020742416381836,\n",
              "  0.25008657574653625,\n",
              "  0.2500261664390564,\n",
              "  0.25012704730033875,\n",
              "  0.2500706911087036,\n",
              "  0.25010719895362854,\n",
              "  0.2501251995563507,\n",
              "  0.25010040402412415,\n",
              "  0.2500670850276947,\n",
              "  0.2501010596752167,\n",
              "  0.2500452399253845,\n",
              "  0.25012433528900146,\n",
              "  0.2501029372215271,\n",
              "  0.2500203847885132,\n",
              "  0.25018906593322754,\n",
              "  0.2500411570072174,\n",
              "  0.2501053810119629,\n",
              "  0.2500649094581604,\n",
              "  0.25025907158851624,\n",
              "  0.2500772774219513,\n",
              "  0.2501908242702484,\n",
              "  0.25034695863723755,\n",
              "  0.2502383291721344,\n",
              "  0.25008776783943176,\n",
              "  0.2500516176223755,\n",
              "  0.25004735589027405,\n",
              "  0.25011590123176575,\n",
              "  0.25009578466415405,\n",
              "  0.2501535713672638,\n",
              "  0.25007298588752747,\n",
              "  0.2501135766506195,\n",
              "  0.2504202723503113,\n",
              "  0.25012409687042236,\n",
              "  0.2502673268318176,\n",
              "  0.25002431869506836,\n",
              "  0.25009700655937195,\n",
              "  0.2501145005226135,\n",
              "  0.25014325976371765,\n",
              "  0.25021517276763916,\n",
              "  0.25015485286712646,\n",
              "  0.2500930726528168,\n",
              "  0.25011149048805237,\n",
              "  0.25050538778305054,\n",
              "  0.25014838576316833,\n",
              "  0.2501164376735687,\n",
              "  0.25018757581710815,\n",
              "  0.2500461935997009,\n",
              "  0.25009438395500183,\n",
              "  0.2501957416534424,\n",
              "  0.25013643503189087,\n",
              "  0.25021880865097046,\n",
              "  0.25010329484939575,\n",
              "  0.2500190734863281,\n",
              "  0.25010743737220764,\n",
              "  0.250105619430542,\n",
              "  0.25027650594711304,\n",
              "  0.25009894371032715,\n",
              "  0.2501542568206787,\n",
              "  0.25007960200309753,\n",
              "  0.2501165568828583,\n",
              "  0.25006014108657837,\n",
              "  0.2500705122947693,\n",
              "  0.25017040967941284,\n",
              "  0.25023749470710754,\n",
              "  0.2500770688056946,\n",
              "  0.2503035068511963,\n",
              "  0.25001996755599976,\n",
              "  0.25011494755744934,\n",
              "  0.2502115070819855,\n",
              "  0.2503354847431183,\n",
              "  0.25005903840065,\n",
              "  0.2500164210796356,\n",
              "  0.25016599893569946,\n",
              "  0.25015392899513245,\n",
              "  0.250095933675766,\n",
              "  0.25014662742614746,\n",
              "  0.25014761090278625,\n",
              "  0.2503196895122528,\n",
              "  0.25022420287132263,\n",
              "  0.25005900859832764,\n",
              "  0.2501130998134613,\n",
              "  0.2500207722187042,\n",
              "  0.2501366436481476,\n",
              "  0.2500690519809723,\n",
              "  0.2501693665981293,\n",
              "  0.2502756416797638,\n",
              "  0.25012677907943726,\n",
              "  0.25008898973464966,\n",
              "  0.25016459822654724,\n",
              "  0.25020942091941833,\n",
              "  0.2501048445701599,\n",
              "  0.2501521706581116,\n",
              "  0.2500437796115875,\n",
              "  0.25007009506225586,\n",
              "  0.25006920099258423,\n",
              "  0.2502557933330536,\n",
              "  0.2500966787338257,\n",
              "  0.2501664459705353,\n",
              "  0.25014832615852356,\n",
              "  0.2501251995563507,\n",
              "  0.2502157986164093,\n",
              "  0.2501829266548157,\n",
              "  0.2501651644706726,\n",
              "  0.2500520944595337,\n",
              "  0.2501516044139862,\n",
              "  0.24999716877937317,\n",
              "  0.24991852045059204,\n",
              "  0.2501557469367981,\n",
              "  0.25013595819473267,\n",
              "  0.25030994415283203,\n",
              "  0.2500796914100647,\n",
              "  0.2500869929790497,\n",
              "  0.24997760355472565,\n",
              "  0.24998654425144196,\n",
              "  0.25009503960609436,\n",
              "  0.250099778175354,\n",
              "  0.25011852383613586,\n",
              "  0.2502641975879669,\n",
              "  0.2501811981201172,\n",
              "  0.2500174939632416,\n",
              "  0.2502456605434418,\n",
              "  0.2501056492328644,\n",
              "  0.25015679001808167,\n",
              "  0.25032198429107666,\n",
              "  0.2501204311847687,\n",
              "  0.2500987648963928,\n",
              "  0.2502707540988922,\n",
              "  0.25003567337989807,\n",
              "  0.2500465512275696,\n",
              "  0.25007733702659607,\n",
              "  0.2501133382320404,\n",
              "  0.2500396966934204,\n",
              "  0.2500912845134735,\n",
              "  0.25006580352783203,\n",
              "  0.25010955333709717,\n",
              "  0.25030770897865295,\n",
              "  0.25005537271499634,\n",
              "  0.2501707673072815,\n",
              "  0.25027230381965637,\n",
              "  0.2500669062137604,\n",
              "  0.25005027651786804,\n",
              "  0.2500668168067932,\n",
              "  0.2502153515815735,\n",
              "  0.2503153085708618,\n",
              "  0.25008293986320496,\n",
              "  0.2500936686992645,\n",
              "  0.25008222460746765,\n",
              "  0.2501600384712219,\n",
              "  0.25010910630226135,\n",
              "  0.25027796626091003,\n",
              "  0.2500195801258087,\n",
              "  0.25015953183174133,\n",
              "  0.2501247227191925,\n",
              "  0.25005874037742615,\n",
              "  0.2501387894153595,\n",
              "  0.2505189776420593,\n",
              "  0.250101238489151,\n",
              "  0.25002700090408325,\n",
              "  0.2501971125602722,\n",
              "  0.25008225440979004,\n",
              "  0.25011688470840454,\n",
              "  0.25016602873802185,\n",
              "  0.2500775456428528,\n",
              "  0.25012871623039246,\n",
              "  0.25015953183174133,\n",
              "  0.25033465027809143,\n",
              "  0.2500615417957306,\n",
              "  0.2500794231891632,\n",
              "  0.2500477135181427,\n",
              "  0.25019994378089905,\n",
              "  0.2500602602958679,\n",
              "  0.25052592158317566,\n",
              "  0.2500268220901489,\n",
              "  0.2500518262386322,\n",
              "  0.2501642107963562,\n",
              "  0.250379741191864,\n",
              "  0.24998225271701813,\n",
              "  0.2500620186328888,\n",
              "  0.2501815855503082,\n",
              "  0.2500874400138855,\n",
              "  0.25012609362602234,\n",
              "  0.25006160140037537,\n",
              "  0.2501084804534912,\n",
              "  0.2500896453857422,\n",
              "  0.25008320808410645,\n",
              "  0.2501147985458374,\n",
              "  0.25019335746765137,\n",
              "  0.2502079904079437,\n",
              "  0.2501586675643921,\n",
              "  0.2501693665981293,\n",
              "  0.2501683533191681,\n",
              "  0.25040653347969055,\n",
              "  0.2502278983592987,\n",
              "  0.2501184046268463,\n",
              "  0.2502906918525696,\n",
              "  0.2503959536552429,\n",
              "  0.24999254941940308,\n",
              "  0.2504047155380249,\n",
              "  0.2501014769077301,\n",
              "  0.2503100633621216,\n",
              "  0.25007888674736023,\n",
              "  0.25019368529319763,\n",
              "  0.25007909536361694,\n",
              "  0.25013744831085205,\n",
              "  0.2501354217529297,\n",
              "  0.2501736283302307,\n",
              "  0.25018906593322754,\n",
              "  0.2503052055835724,\n",
              "  0.2501768171787262,\n",
              "  0.2501249611377716,\n",
              "  0.2501211166381836,\n",
              "  0.2501177191734314,\n",
              "  0.2501294016838074,\n",
              "  0.2503140866756439,\n",
              "  0.2502121329307556,\n",
              "  0.2501435875892639,\n",
              "  0.2501402795314789,\n",
              "  0.25005120038986206,\n",
              "  0.25022029876708984,\n",
              "  0.2501886487007141,\n",
              "  0.250043660402298,\n",
              "  0.2501835823059082,\n",
              "  0.25009873509407043,\n",
              "  0.25009384751319885,\n",
              "  0.25032615661621094,\n",
              "  0.25032955408096313,\n",
              "  0.25014564394950867,\n",
              "  0.2501401901245117,\n",
              "  0.2501256763935089,\n",
              "  0.2501309812068939,\n",
              "  0.2500928044319153,\n",
              "  0.2500205636024475,\n",
              "  0.2502272427082062,\n",
              "  0.2500779628753662,\n",
              "  0.25034967064857483,\n",
              "  0.25017592310905457,\n",
              "  0.2500952482223511,\n",
              "  0.25019630789756775,\n",
              "  0.2502257823944092,\n",
              "  0.2501453459262848,\n",
              "  0.25014203786849976,\n",
              "  0.2500358819961548,\n",
              "  0.25009122490882874,\n",
              "  0.25006893277168274,\n",
              "  0.2501542866230011,\n",
              "  0.2500568628311157,\n",
              "  0.2501254379749298,\n",
              "  0.250337153673172,\n",
              "  0.25016260147094727,\n",
              "  0.2501305043697357,\n",
              "  0.25010037422180176,\n",
              "  0.25033339858055115,\n",
              "  0.25061503052711487,\n",
              "  0.25009071826934814,\n",
              "  0.2500438988208771,\n",
              "  0.2501412630081177,\n",
              "  0.2502303719520569,\n",
              "  0.25031912326812744,\n",
              "  0.2501187324523926,\n",
              "  0.250099241733551,\n",
              "  0.2502317726612091,\n",
              "  0.2501077950000763,\n",
              "  0.25003549456596375,\n",
              "  0.2501537799835205,\n",
              "  0.2500779926776886,\n",
              "  0.25006812810897827,\n",
              "  0.25048065185546875,\n",
              "  0.2501762807369232,\n",
              "  0.25009843707084656,\n",
              "  0.2500419616699219,\n",
              "  0.25022903084754944,\n",
              "  0.25007256865501404,\n",
              "  0.25004029273986816,\n",
              "  0.25022605061531067,\n",
              "  0.2500799000263214,\n",
              "  0.2501010298728943,\n",
              "  0.25017842650413513,\n",
              "  0.25007960200309753],\n",
              " 'val_loss': [0.308056503534317,\n",
              "  0.29260894656181335,\n",
              "  0.26533111929893494,\n",
              "  0.2611239552497864,\n",
              "  0.2573321759700775,\n",
              "  0.2524290978908539,\n",
              "  0.25004085898399353,\n",
              "  0.25020089745521545,\n",
              "  0.2495681196451187,\n",
              "  0.24990050494670868,\n",
              "  0.25026199221611023,\n",
              "  0.25007790327072144,\n",
              "  0.2500448226928711,\n",
              "  0.2502357065677643,\n",
              "  0.2499634027481079,\n",
              "  0.2500171661376953,\n",
              "  0.2500123083591461,\n",
              "  0.2499762624502182,\n",
              "  0.2502681016921997,\n",
              "  0.24994899332523346,\n",
              "  0.25012338161468506,\n",
              "  0.25003430247306824,\n",
              "  0.25003674626350403,\n",
              "  0.2500021457672119,\n",
              "  0.2500079572200775,\n",
              "  0.2499322146177292,\n",
              "  0.25000742077827454,\n",
              "  0.25005853176116943,\n",
              "  0.25001609325408936,\n",
              "  0.24999888241291046,\n",
              "  0.2500002384185791,\n",
              "  0.2501786947250366,\n",
              "  0.2501368820667267,\n",
              "  0.2501131296157837,\n",
              "  0.25000378489494324,\n",
              "  0.2501722276210785,\n",
              "  0.25000497698783875,\n",
              "  0.24990952014923096,\n",
              "  0.25009873509407043,\n",
              "  0.25001516938209534,\n",
              "  0.24991975724697113,\n",
              "  0.2500005066394806,\n",
              "  0.25000178813934326,\n",
              "  0.25001680850982666,\n",
              "  0.2500443756580353,\n",
              "  0.2499348372220993,\n",
              "  0.2500058114528656,\n",
              "  0.25005805492401123,\n",
              "  0.25024572014808655,\n",
              "  0.24995918571949005,\n",
              "  0.25000110268592834,\n",
              "  0.24997560679912567,\n",
              "  0.25000470876693726,\n",
              "  0.24992735683918,\n",
              "  0.2499159425497055,\n",
              "  0.25003233551979065,\n",
              "  0.24993200600147247,\n",
              "  0.25001439452171326,\n",
              "  0.2500322163105011,\n",
              "  0.2501998841762543,\n",
              "  0.25000035762786865,\n",
              "  0.2500092685222626,\n",
              "  0.2500250041484833,\n",
              "  0.2500119209289551,\n",
              "  0.24991779029369354,\n",
              "  0.25008830428123474,\n",
              "  0.25005272030830383,\n",
              "  0.2500564754009247,\n",
              "  0.25016507506370544,\n",
              "  0.25007718801498413,\n",
              "  0.25005367398262024,\n",
              "  0.2501377761363983,\n",
              "  0.24989652633666992,\n",
              "  0.25013822317123413,\n",
              "  0.2500680685043335,\n",
              "  0.24990276992321014,\n",
              "  0.2500174045562744,\n",
              "  0.250159353017807,\n",
              "  0.2500724494457245,\n",
              "  0.2500075697898865,\n",
              "  0.2500952184200287,\n",
              "  0.2500059902667999,\n",
              "  0.250338077545166,\n",
              "  0.25063005089759827,\n",
              "  0.25000810623168945,\n",
              "  0.24992001056671143,\n",
              "  0.24998436868190765,\n",
              "  0.2500457763671875,\n",
              "  0.2500678300857544,\n",
              "  0.2500198781490326,\n",
              "  0.25010907649993896,\n",
              "  0.25047847628593445,\n",
              "  0.24991340935230255,\n",
              "  0.2501141130924225,\n",
              "  0.24994198977947235,\n",
              "  0.2500169575214386,\n",
              "  0.24990840256214142,\n",
              "  0.2500021755695343,\n",
              "  0.2500378489494324,\n",
              "  0.24989290535449982,\n",
              "  0.2497672438621521,\n",
              "  0.2500036954879761,\n",
              "  0.24999910593032837,\n",
              "  0.2501263916492462,\n",
              "  0.25011977553367615,\n",
              "  0.2500186562538147,\n",
              "  0.24989716708660126,\n",
              "  0.25012263655662537,\n",
              "  0.25009360909461975,\n",
              "  0.25002622604370117,\n",
              "  0.25000014901161194,\n",
              "  0.24999630451202393,\n",
              "  0.25001218914985657,\n",
              "  0.25007233023643494,\n",
              "  0.25002363324165344,\n",
              "  0.25001001358032227,\n",
              "  0.24985037744045258,\n",
              "  0.24999624490737915,\n",
              "  0.24997754395008087,\n",
              "  0.24989967048168182,\n",
              "  0.24997840821743011,\n",
              "  0.24992410838603973,\n",
              "  0.25054478645324707,\n",
              "  0.25019410252571106,\n",
              "  0.25001487135887146,\n",
              "  0.2500196397304535,\n",
              "  0.25012850761413574,\n",
              "  0.25001081824302673,\n",
              "  0.24973292648792267,\n",
              "  0.2502603530883789,\n",
              "  0.2499011754989624,\n",
              "  0.25005605816841125,\n",
              "  0.25003960728645325,\n",
              "  0.25002333521842957,\n",
              "  0.25000670552253723,\n",
              "  0.2500319182872772,\n",
              "  0.25002893805503845,\n",
              "  0.25012457370758057,\n",
              "  0.2500617504119873,\n",
              "  0.2500345706939697,\n",
              "  0.25019994378089905,\n",
              "  0.2500021159648895,\n",
              "  0.2502361238002777,\n",
              "  0.2503528892993927,\n",
              "  0.24991588294506073,\n",
              "  0.2502552568912506,\n",
              "  0.2500450909137726,\n",
              "  0.2504396140575409,\n",
              "  0.25002866983413696,\n",
              "  0.25004318356513977,\n",
              "  0.2500006854534149,\n",
              "  0.24994753301143646,\n",
              "  0.2500346302986145,\n",
              "  0.25016680359840393,\n",
              "  0.25021296739578247,\n",
              "  0.25031188130378723,\n",
              "  0.2501305937767029,\n",
              "  0.2499123066663742,\n",
              "  0.24999099969863892,\n",
              "  0.2500002980232239,\n",
              "  0.2499590516090393,\n",
              "  0.2500040829181671,\n",
              "  0.24998708069324493,\n",
              "  0.24973362684249878,\n",
              "  0.2504565715789795,\n",
              "  0.25002941489219666,\n",
              "  0.2500230073928833,\n",
              "  0.250002384185791,\n",
              "  0.2501618266105652,\n",
              "  0.24999158084392548,\n",
              "  0.2501208484172821,\n",
              "  0.2500366270542145,\n",
              "  0.24994318187236786,\n",
              "  0.24975354969501495,\n",
              "  0.25008711218833923,\n",
              "  0.25009509921073914,\n",
              "  0.2499382644891739,\n",
              "  0.25040629506111145,\n",
              "  0.25025609135627747,\n",
              "  0.25026068091392517,\n",
              "  0.2500045597553253,\n",
              "  0.25022274255752563,\n",
              "  0.25010526180267334,\n",
              "  0.24998682737350464,\n",
              "  0.25008705258369446,\n",
              "  0.249989315867424,\n",
              "  0.25000065565109253,\n",
              "  0.25002917647361755,\n",
              "  0.25023531913757324,\n",
              "  0.24996094405651093,\n",
              "  0.2500694692134857,\n",
              "  0.24994051456451416,\n",
              "  0.25002816319465637,\n",
              "  0.25012025237083435,\n",
              "  0.25013163685798645,\n",
              "  0.25000667572021484,\n",
              "  0.25004759430885315,\n",
              "  0.24992556869983673,\n",
              "  0.2504730224609375,\n",
              "  0.25001832842826843,\n",
              "  0.250347763299942,\n",
              "  0.25003519654273987,\n",
              "  0.2502076029777527,\n",
              "  0.24990642070770264,\n",
              "  0.25016316771507263,\n",
              "  0.25001418590545654,\n",
              "  0.250107079744339,\n",
              "  0.25011950731277466,\n",
              "  0.2500258982181549,\n",
              "  0.2502860426902771,\n",
              "  0.250175803899765,\n",
              "  0.2500723898410797,\n",
              "  0.25009456276893616,\n",
              "  0.25002291798591614,\n",
              "  0.2501560151576996,\n",
              "  0.2500104606151581,\n",
              "  0.2500208914279938,\n",
              "  0.25006699562072754,\n",
              "  0.25001487135887146,\n",
              "  0.25000908970832825,\n",
              "  0.2501099109649658,\n",
              "  0.25008612871170044,\n",
              "  0.24993209540843964,\n",
              "  0.250196248292923,\n",
              "  0.2500549554824829,\n",
              "  0.24999581277370453,\n",
              "  0.25000664591789246,\n",
              "  0.24979393184185028,\n",
              "  0.25005462765693665,\n",
              "  0.25010061264038086,\n",
              "  0.25000864267349243,\n",
              "  0.2499179244041443,\n",
              "  0.25010934472084045,\n",
              "  0.24995915591716766,\n",
              "  0.2501786947250366,\n",
              "  0.2500187158584595,\n",
              "  0.2500320374965668,\n",
              "  0.24999845027923584,\n",
              "  0.2500077188014984,\n",
              "  0.2501133680343628,\n",
              "  0.25002607703208923,\n",
              "  0.25015756487846375,\n",
              "  0.2503744065761566,\n",
              "  0.2505049705505371,\n",
              "  0.25015223026275635,\n",
              "  0.2502981424331665,\n",
              "  0.24990566074848175,\n",
              "  0.25003424286842346,\n",
              "  0.25032874941825867,\n",
              "  0.25017237663269043,\n",
              "  0.2499881237745285,\n",
              "  0.2502649426460266,\n",
              "  0.2501332759857178,\n",
              "  0.2504430115222931,\n",
              "  0.250505656003952,\n",
              "  0.25003373622894287,\n",
              "  0.2500286102294922,\n",
              "  0.24997688829898834,\n",
              "  0.25000572204589844,\n",
              "  0.24999648332595825,\n",
              "  0.24988408386707306,\n",
              "  0.25001463294029236,\n",
              "  0.2499246597290039,\n",
              "  0.2500002682209015,\n",
              "  0.25000038743019104,\n",
              "  0.24995696544647217,\n",
              "  0.25017616152763367,\n",
              "  0.2500065267086029,\n",
              "  0.2500002384185791,\n",
              "  0.249929741024971,\n",
              "  0.2500603497028351,\n",
              "  0.2500055730342865,\n",
              "  0.24997484683990479,\n",
              "  0.2499213069677353,\n",
              "  0.25001394748687744,\n",
              "  0.2500087320804596,\n",
              "  0.2500397861003876,\n",
              "  0.25003311038017273,\n",
              "  0.250295490026474,\n",
              "  0.25031331181526184,\n",
              "  0.2504708766937256,\n",
              "  0.25001609325408936,\n",
              "  0.25002267956733704,\n",
              "  0.25020158290863037,\n",
              "  0.25017502903938293,\n",
              "  0.24998831748962402,\n",
              "  0.2500583231449127,\n",
              "  0.2499757558107376,\n",
              "  0.25008630752563477,\n",
              "  0.2503286898136139,\n",
              "  0.2500580847263336,\n",
              "  0.2498513013124466,\n",
              "  0.2500130236148834,\n",
              "  0.2500949203968048,\n",
              "  0.24984455108642578,\n",
              "  0.25007376074790955,\n",
              "  0.24998532235622406,\n",
              "  0.2501659095287323,\n",
              "  0.25000616908073425,\n",
              "  0.25011685490608215,\n",
              "  0.2502008378505707,\n",
              "  0.2500368058681488,\n",
              "  0.25024208426475525,\n",
              "  0.25024354457855225,\n",
              "  0.2499321848154068,\n",
              "  0.2500002086162567,\n",
              "  0.2499380111694336,\n",
              "  0.2501962184906006,\n",
              "  0.25018981099128723,\n",
              "  0.2502218782901764,\n",
              "  0.24993151426315308,\n",
              "  0.24996550381183624,\n",
              "  0.25066375732421875,\n",
              "  0.25005868077278137,\n",
              "  0.2500176727771759,\n",
              "  0.2500000596046448,\n",
              "  0.24991464614868164,\n",
              "  0.25002601742744446,\n",
              "  0.2500913441181183,\n",
              "  0.2498915046453476,\n",
              "  0.250000923871994,\n",
              "  0.2499353438615799,\n",
              "  0.2500110864639282,\n",
              "  0.2499667853116989,\n",
              "  0.2504596412181854,\n",
              "  0.2500772178173065,\n",
              "  0.25005725026130676,\n",
              "  0.25021126866340637,\n",
              "  0.24999350309371948,\n",
              "  0.25002729892730713,\n",
              "  0.2501390278339386,\n",
              "  0.2500215470790863,\n",
              "  0.2500223219394684,\n",
              "  0.24994485080242157,\n",
              "  0.2501007616519928,\n",
              "  0.2500030994415283,\n",
              "  0.2500332295894623,\n",
              "  0.25023889541625977,\n",
              "  0.24993722140789032,\n",
              "  0.2500256597995758,\n",
              "  0.2499762326478958,\n",
              "  0.2499082088470459,\n",
              "  0.25000813603401184,\n",
              "  0.25000128149986267,\n",
              "  0.2500075697898865,\n",
              "  0.2499421238899231,\n",
              "  0.2499561905860901,\n",
              "  0.24998408555984497,\n",
              "  0.25042709708213806,\n",
              "  0.25026220083236694,\n",
              "  0.25003984570503235,\n",
              "  0.2500295341014862,\n",
              "  0.2497798204421997,\n",
              "  0.24995489418506622,\n",
              "  0.2500034272670746,\n",
              "  0.24994151294231415,\n",
              "  0.25016283988952637,\n",
              "  0.2500128746032715,\n",
              "  0.24998871982097626,\n",
              "  0.25000062584877014,\n",
              "  0.24999386072158813,\n",
              "  0.2500063180923462,\n",
              "  0.2500002682209015,\n",
              "  0.2500036656856537,\n",
              "  0.24993890523910522,\n",
              "  0.24989263713359833,\n",
              "  0.2502754032611847,\n",
              "  0.25001680850982666,\n",
              "  0.25000131130218506,\n",
              "  0.24967874586582184,\n",
              "  0.24998003244400024,\n",
              "  0.2499486654996872,\n",
              "  0.25001898407936096,\n",
              "  0.25007393956184387,\n",
              "  0.25001662969589233,\n",
              "  0.2504170536994934,\n",
              "  0.2500065565109253,\n",
              "  0.25038984417915344,\n",
              "  0.2500245273113251,\n",
              "  0.2500450313091278,\n",
              "  0.24999745190143585,\n",
              "  0.2500775158405304,\n",
              "  0.250014990568161,\n",
              "  0.2503419518470764,\n",
              "  0.24979831278324127,\n",
              "  0.2501021921634674,\n",
              "  0.25000324845314026,\n",
              "  0.2500055134296417,\n",
              "  0.2500934600830078,\n",
              "  0.2501295506954193,\n",
              "  0.25037655234336853,\n",
              "  0.24989159405231476,\n",
              "  0.24990446865558624,\n",
              "  0.24993430078029633,\n",
              "  0.24969632923603058,\n",
              "  0.2500021457672119,\n",
              "  0.24996238946914673,\n",
              "  0.24999690055847168,\n",
              "  0.25000402331352234,\n",
              "  0.2500000596046448,\n",
              "  0.24999640882015228,\n",
              "  0.25020745396614075,\n",
              "  0.24992655217647552,\n",
              "  0.2500406801700592,\n",
              "  0.24998772144317627,\n",
              "  0.2504144608974457,\n",
              "  0.2502942383289337,\n",
              "  0.2501036524772644,\n",
              "  0.2500460147857666,\n",
              "  0.25000789761543274,\n",
              "  0.2500488758087158,\n",
              "  0.2500000298023224,\n",
              "  0.2501131594181061,\n",
              "  0.25000712275505066,\n",
              "  0.2499309927225113,\n",
              "  0.25000762939453125,\n",
              "  0.24998025596141815,\n",
              "  0.250084787607193,\n",
              "  0.2500406801700592,\n",
              "  0.25031325221061707,\n",
              "  0.2500717341899872,\n",
              "  0.2499186396598816,\n",
              "  0.2502475082874298,\n",
              "  0.25016626715660095,\n",
              "  0.2500046491622925,\n",
              "  0.24997062981128693,\n",
              "  0.25001460313796997,\n",
              "  0.24991251528263092,\n",
              "  0.2502850592136383,\n",
              "  0.2498975545167923,\n",
              "  0.2502630949020386,\n",
              "  0.25005853176116943,\n",
              "  0.24998362362384796,\n",
              "  0.2500015199184418,\n",
              "  0.2500437796115875,\n",
              "  0.2500293254852295,\n",
              "  0.25001052021980286,\n",
              "  0.2501230537891388,\n",
              "  0.2500463128089905,\n",
              "  0.2499598115682602,\n",
              "  0.24993447959423065,\n",
              "  0.25010159611701965,\n",
              "  0.2503664493560791,\n",
              "  0.2500975430011749,\n",
              "  0.2501181960105896,\n",
              "  0.2500125467777252,\n",
              "  0.25005805492401123,\n",
              "  0.25042590498924255,\n",
              "  0.24990259110927582,\n",
              "  0.25004148483276367,\n",
              "  0.2500004470348358,\n",
              "  0.25002482533454895,\n",
              "  0.25000280141830444,\n",
              "  0.2502128779888153,\n",
              "  0.24987967312335968,\n",
              "  0.2502831518650055,\n",
              "  0.24995923042297363,\n",
              "  0.2501593828201294,\n",
              "  0.2500326335430145,\n",
              "  0.250104695558548,\n",
              "  0.25012367963790894,\n",
              "  0.25003936886787415,\n",
              "  0.24996574223041534,\n",
              "  0.250116229057312,\n",
              "  0.24996799230575562,\n",
              "  0.2500133812427521,\n",
              "  0.24999739229679108,\n",
              "  0.25004565715789795,\n",
              "  0.2500018775463104,\n",
              "  0.2501929998397827,\n",
              "  0.2500000298023224,\n",
              "  0.2502172291278839,\n",
              "  0.2502802014350891,\n",
              "  0.2503475248813629,\n",
              "  0.2500021755695343,\n",
              "  0.2500743269920349,\n",
              "  0.2500270903110504,\n",
              "  0.250200480222702,\n",
              "  0.2502498924732208,\n",
              "  0.2502855062484741,\n",
              "  0.2500722110271454,\n",
              "  0.25009605288505554,\n",
              "  0.2500237822532654,\n",
              "  0.24995851516723633,\n",
              "  0.24997419118881226,\n",
              "  0.25002923607826233,\n",
              "  0.24991190433502197,\n",
              "  0.2499421089887619,\n",
              "  0.2504206895828247,\n",
              "  0.2502056062221527,\n",
              "  0.250615656375885,\n",
              "  0.24990396201610565,\n",
              "  0.24993497133255005,\n",
              "  0.25011447072029114,\n",
              "  0.250095397233963,\n",
              "  0.2499704211950302,\n",
              "  0.25000521540641785,\n",
              "  0.2499227076768875,\n",
              "  0.24997466802597046,\n",
              "  0.2500048577785492,\n",
              "  0.25000008940696716,\n",
              "  0.2500015199184418,\n",
              "  0.2501576244831085,\n",
              "  0.2500700354576111,\n",
              "  0.25006672739982605,\n",
              "  0.2500499188899994,\n",
              "  0.2500016391277313,\n",
              "  0.25002071261405945,\n",
              "  0.25000065565109253,\n",
              "  0.24993784725666046,\n",
              "  0.25005626678466797,\n",
              "  0.2500281035900116,\n",
              "  0.2499806135892868,\n",
              "  0.250003844499588,\n",
              "  0.25004780292510986,\n",
              "  0.2499227374792099,\n",
              "  0.24992136657238007,\n",
              "  0.2502150237560272,\n",
              "  0.25017985701560974,\n",
              "  0.2500070035457611,\n",
              "  0.2500215768814087,\n",
              "  0.25000399351119995,\n",
              "  0.24981272220611572,\n",
              "  0.24998344480991364,\n",
              "  0.25005820393562317,\n",
              "  0.250034898519516,\n",
              "  0.25016555190086365,\n",
              "  0.25025030970573425,\n",
              "  0.25007370114326477,\n",
              "  0.24991603195667267,\n",
              "  0.25002607703208923,\n",
              "  0.25000113248825073,\n",
              "  0.2502531111240387,\n",
              "  0.2500058114528656,\n",
              "  0.2501412630081177,\n",
              "  0.2501514256000519,\n",
              "  0.2500629723072052,\n",
              "  0.2501468062400818,\n",
              "  0.2500324547290802,\n",
              "  0.2500027120113373,\n",
              "  0.24992911517620087,\n",
              "  0.250244140625,\n",
              "  0.25011229515075684,\n",
              "  0.2500002384185791,\n",
              "  0.2503540813922882,\n",
              "  0.24998259544372559,\n",
              "  0.2502351999282837,\n",
              "  0.2500021755695343,\n",
              "  0.25002938508987427,\n",
              "  0.24993102252483368,\n",
              "  0.25022682547569275,\n",
              "  0.25003257393836975,\n",
              "  0.25002792477607727,\n",
              "  0.24992044270038605,\n",
              "  0.25002244114875793,\n",
              "  0.2505352795124054,\n",
              "  0.25002622604370117,\n",
              "  0.2501390278339386,\n",
              "  0.24997620284557343,\n",
              "  0.2500015199184418,\n",
              "  0.25000742077827454,\n",
              "  0.2500990629196167,\n",
              "  0.24998529255390167,\n",
              "  0.2500138580799103,\n",
              "  0.25000131130218506,\n",
              "  0.25000330805778503,\n",
              "  0.250093549489975,\n",
              "  0.25,\n",
              "  0.25000306963920593,\n",
              "  0.2500499486923218,\n",
              "  0.2500148117542267,\n",
              "  0.24995845556259155,\n",
              "  0.24995343387126923,\n",
              "  0.24993427097797394,\n",
              "  0.25000762939453125,\n",
              "  0.25028279423713684,\n",
              "  0.2502313256263733,\n",
              "  0.250002920627594,\n",
              "  0.2500031888484955,\n",
              "  0.2500523030757904,\n",
              "  0.2499486356973648,\n",
              "  0.2501795291900635,\n",
              "  0.25012263655662537,\n",
              "  0.250153511762619,\n",
              "  0.25,\n",
              "  0.24996767938137054,\n",
              "  0.24999673664569855,\n",
              "  0.2500024139881134,\n",
              "  0.25000056624412537,\n",
              "  0.2500535547733307,\n",
              "  0.2502683699131012,\n",
              "  0.2500692307949066,\n",
              "  0.2500596046447754,\n",
              "  0.25024858117103577,\n",
              "  0.2500097453594208,\n",
              "  0.25006163120269775,\n",
              "  0.25023922324180603,\n",
              "  0.2500338852405548,\n",
              "  0.25018003582954407,\n",
              "  0.25000593066215515,\n",
              "  0.25002118945121765,\n",
              "  0.25000104308128357,\n",
              "  0.25004667043685913,\n",
              "  0.2499711662530899,\n",
              "  0.25002357363700867,\n",
              "  0.25005462765693665,\n",
              "  0.2500781714916229,\n",
              "  0.2499733567237854,\n",
              "  0.25035765767097473,\n",
              "  0.2503318786621094,\n",
              "  0.25001731514930725,\n",
              "  0.2500755190849304,\n",
              "  0.24989156424999237,\n",
              "  0.2500075399875641,\n",
              "  0.25022685527801514,\n",
              "  0.25028905272483826,\n",
              "  0.25038862228393555,\n",
              "  0.2500038743019104,\n",
              "  0.2500186264514923,\n",
              "  0.2500017583370209,\n",
              "  0.25001785159111023,\n",
              "  0.25001227855682373,\n",
              "  0.2500016391277313,\n",
              "  0.2499845176935196,\n",
              "  0.2500057518482208,\n",
              "  0.24992318451404572,\n",
              "  0.2500533163547516,\n",
              "  0.24990351498126984,\n",
              "  0.250079870223999,\n",
              "  0.25014975666999817,\n",
              "  0.24993108212947845,\n",
              "  0.2499709576368332,\n",
              "  0.2499772310256958,\n",
              "  0.2499188929796219,\n",
              "  0.2500767409801483,\n",
              "  0.25000008940696716,\n",
              "  0.25000131130218506,\n",
              "  0.25002333521842957,\n",
              "  0.2504238188266754,\n",
              "  0.2501325309276581,\n",
              "  0.2507447898387909,\n",
              "  0.25,\n",
              "  0.2500288188457489,\n",
              "  0.25000080466270447,\n",
              "  0.25004562735557556,\n",
              "  0.24991655349731445,\n",
              "  0.2501322329044342,\n",
              "  0.24998259544372559,\n",
              "  0.25004103779792786,\n",
              "  0.24989156424999237,\n",
              "  0.250007688999176,\n",
              "  0.2500537931919098,\n",
              "  0.25005683302879333,\n",
              "  0.25005796551704407,\n",
              "  0.2501058876514435,\n",
              "  0.25018981099128723,\n",
              "  0.2500559985637665,\n",
              "  0.2500937283039093,\n",
              "  0.25000134110450745,\n",
              "  0.2500028610229492,\n",
              "  0.25000473856925964,\n",
              "  0.25003883242607117,\n",
              "  0.24988140165805817,\n",
              "  0.24986064434051514,\n",
              "  0.25001707673072815,\n",
              "  0.25003519654273987,\n",
              "  0.24999690055847168,\n",
              "  0.2500286400318146,\n",
              "  0.25000450015068054,\n",
              "  0.25025007128715515,\n",
              "  0.2500975728034973,\n",
              "  0.2498917579650879,\n",
              "  0.25001588463783264,\n",
              "  0.2500598430633545,\n",
              "  0.2500985562801361,\n",
              "  0.25006240606307983,\n",
              "  0.24998454749584198,\n",
              "  0.250120609998703,\n",
              "  0.25000014901161194,\n",
              "  0.25001928210258484,\n",
              "  0.24985218048095703,\n",
              "  0.25004643201828003,\n",
              "  0.25002405047416687,\n",
              "  0.25002869963645935,\n",
              "  0.25000008940696716,\n",
              "  0.2500089108943939,\n",
              "  0.249893918633461,\n",
              "  0.25016412138938904,\n",
              "  0.24989742040634155,\n",
              "  0.25006434321403503,\n",
              "  0.2500152289867401,\n",
              "  0.24990062415599823,\n",
              "  0.25051844120025635,\n",
              "  0.24999113380908966,\n",
              "  0.2500019967556,\n",
              "  0.25007662177085876,\n",
              "  0.2500491440296173,\n",
              "  0.25013676285743713,\n",
              "  0.2505345642566681,\n",
              "  0.24990765750408173,\n",
              "  0.25001510977745056,\n",
              "  0.25027504563331604,\n",
              "  0.24990929663181305,\n",
              "  0.2497902512550354,\n",
              "  0.25002241134643555,\n",
              "  0.24990014731884003,\n",
              "  0.24989430606365204,\n",
              "  0.2500971257686615,\n",
              "  0.2501310408115387,\n",
              "  0.2502272129058838,\n",
              "  0.2499912530183792,\n",
              "  0.2500467002391815,\n",
              "  0.2500046491622925,\n",
              "  0.2500005066394806,\n",
              "  0.2500280439853668,\n",
              "  0.2500017583370209,\n",
              "  0.24991463124752045,\n",
              "  0.25012776255607605,\n",
              "  0.25004565715789795,\n",
              "  0.25023162364959717,\n",
              "  0.2500447928905487,\n",
              "  0.2500554323196411,\n",
              "  0.2500190734863281,\n",
              "  0.250000923871994,\n",
              "  0.25002220273017883,\n",
              "  0.2504453957080841,\n",
              "  0.25002044439315796,\n",
              "  0.2497834414243698,\n",
              "  0.25001856684684753,\n",
              "  0.25001394748687744,\n",
              "  0.25006821751594543,\n",
              "  0.25034114718437195,\n",
              "  0.2502024471759796,\n",
              "  0.2504254877567291,\n",
              "  0.25022128224372864,\n",
              "  0.25022122263908386,\n",
              "  0.25001415610313416,\n",
              "  0.2501690685749054,\n",
              "  0.2503810226917267,\n",
              "  0.25002768635749817,\n",
              "  0.25000008940696716,\n",
              "  0.249921515583992,\n",
              "  0.2498915195465088,\n",
              "  0.24994947016239166,\n",
              "  0.2500150203704834,\n",
              "  0.2499057650566101,\n",
              "  0.24995921552181244,\n",
              "  0.2501037120819092,\n",
              "  0.25000202655792236,\n",
              "  0.24990655481815338,\n",
              "  0.2502748370170593,\n",
              "  0.25021541118621826,\n",
              "  0.24994802474975586,\n",
              "  0.25000134110450745,\n",
              "  0.2500186264514923,\n",
              "  0.25005775690078735,\n",
              "  0.25013527274131775,\n",
              "  0.24991266429424286,\n",
              "  0.24997234344482422,\n",
              "  0.2500359117984772,\n",
              "  0.25004997849464417,\n",
              "  0.2500111758708954,\n",
              "  0.250312477350235,\n",
              "  0.25020983815193176,\n",
              "  0.2500350773334503,\n",
              "  0.250161737203598,\n",
              "  0.24995730817317963,\n",
              "  0.25000616908073425,\n",
              "  0.25000184774398804,\n",
              "  0.24991337954998016,\n",
              "  0.2499891072511673,\n",
              "  0.25001242756843567,\n",
              "  0.25006067752838135,\n",
              "  0.25000426173210144,\n",
              "  0.24999485909938812,\n",
              "  0.24997393786907196,\n",
              "  0.24999408423900604,\n",
              "  0.250000923871994,\n",
              "  0.2500286400318146,\n",
              "  0.25024107098579407,\n",
              "  0.24991708993911743,\n",
              "  0.2501316964626312,\n",
              "  0.2500033676624298,\n",
              "  0.2501644790172577,\n",
              "  0.24991004168987274,\n",
              "  0.2500176727771759,\n",
              "  0.2501218616962433,\n",
              "  0.24994266033172607,\n",
              "  0.25014033913612366,\n",
              "  0.25014716386795044,\n",
              "  0.2500249445438385,\n",
              "  0.2501177489757538,\n",
              "  0.2500982880592346,\n",
              "  0.2500576972961426,\n",
              "  0.25034430623054504,\n",
              "  0.25012317299842834,\n",
              "  0.24999606609344482,\n",
              "  0.2498675435781479,\n",
              "  0.2500136196613312,\n",
              "  0.24998366832733154,\n",
              "  0.24989180266857147,\n",
              "  0.2501331865787506,\n",
              "  0.2501482367515564,\n",
              "  0.2505802512168884,\n",
              "  0.25019216537475586,\n",
              "  0.2500227391719818,\n",
              "  0.24990296363830566,\n",
              "  0.2500767409801483,\n",
              "  0.2499089241027832,\n",
              "  0.25011226534843445,\n",
              "  0.2500368356704712,\n",
              "  0.2500896155834198,\n",
              "  0.24990642070770264,\n",
              "  0.25000134110450745,\n",
              "  0.24998962879180908,\n",
              "  0.25003254413604736,\n",
              "  0.2501074969768524,\n",
              "  0.25002190470695496,\n",
              "  0.25001588463783264,\n",
              "  0.24990278482437134,\n",
              "  0.2500702440738678,\n",
              "  0.24990756809711456,\n",
              "  0.24996714293956757,\n",
              "  0.2502228319644928,\n",
              "  0.2501227557659149,\n",
              "  0.2500012218952179,\n",
              "  0.2499474436044693,\n",
              "  0.24993084371089935,\n",
              "  0.24989299476146698,\n",
              "  0.24991631507873535,\n",
              "  0.25002211332321167,\n",
              "  0.250041127204895,\n",
              "  0.25003692507743835,\n",
              "  0.2500409483909607,\n",
              "  0.24989216029644012,\n",
              "  0.2500610053539276,\n",
              "  0.2503054440021515,\n",
              "  0.24989791214466095,\n",
              "  0.2500114142894745,\n",
              "  0.25010085105895996,\n",
              "  0.25005054473876953,\n",
              "  0.2499275803565979,\n",
              "  0.25017136335372925,\n",
              "  0.2500063180923462,\n",
              "  0.2499462366104126,\n",
              "  0.24992050230503082,\n",
              "  0.2500852942466736,\n",
              "  0.2500492334365845,\n",
              "  0.2503388524055481,\n",
              "  0.24994777143001556,\n",
              "  0.2500666677951813,\n",
              "  0.2500390410423279,\n",
              "  0.2500986158847809,\n",
              "  0.24993957579135895,\n",
              "  0.25001201033592224,\n",
              "  0.2500002682209015,\n",
              "  0.24992488324642181,\n",
              "  0.25004154443740845,\n",
              "  0.24993199110031128,\n",
              "  0.2500912845134735,\n",
              "  0.2500433921813965,\n",
              "  0.250000536441803,\n",
              "  0.2499413639307022,\n",
              "  0.2502746880054474,\n",
              "  0.2500002086162567,\n",
              "  0.24995531141757965,\n",
              "  0.2500027120113373,\n",
              "  0.25003865361213684,\n",
              "  0.25036442279815674,\n",
              "  0.2500092685222626,\n",
              "  0.25001755356788635,\n",
              "  0.2499304562807083,\n",
              "  0.2501833140850067,\n",
              "  0.2502988278865814,\n",
              "  0.24999256432056427,\n",
              "  0.24995087087154388,\n",
              "  0.25000515580177307,\n",
              "  0.2502954304218292,\n",
              "  0.2500028610229492,\n",
              "  0.25007081031799316,\n",
              "  0.24995894730091095,\n",
              "  0.25000062584877014,\n",
              "  0.2500826120376587,\n",
              "  0.2500207722187042,\n",
              "  0.24975860118865967,\n",
              "  0.25009408593177795,\n",
              "  0.24998001754283905,\n",
              "  0.24990379810333252,\n",
              "  0.250004380941391,\n",
              "  0.2499428242444992,\n",
              "  0.2500995099544525,\n",
              "  0.2500161826610565,\n",
              "  0.25001609325408936,\n",
              "  0.24996711313724518,\n",
              "  0.25021713972091675,\n",
              "  0.25003159046173096,\n",
              "  0.25001806020736694,\n",
              "  0.24996404349803925,\n",
              "  0.2500250041484833,\n",
              "  0.25002849102020264,\n",
              "  0.2501344084739685,\n",
              "  0.2500121593475342,\n",
              "  0.25009819865226746,\n",
              "  0.2500104308128357,\n",
              "  0.25003746151924133,\n",
              "  0.24997635185718536,\n",
              "  0.25007644295692444,\n",
              "  0.25,\n",
              "  0.25012069940567017,\n",
              "  0.250007688999176,\n",
              "  0.24993957579135895,\n",
              "  0.2500009536743164,\n",
              "  0.250002920627594,\n",
              "  0.2500041127204895,\n",
              "  0.2501833736896515,\n",
              "  0.2499016672372818,\n",
              "  0.2500058114528656,\n",
              "  0.25034844875335693,\n",
              "  0.25026360154151917,\n",
              "  0.24993896484375,\n",
              "  0.25000402331352234,\n",
              "  0.2500520646572113,\n",
              "  0.24993014335632324,\n",
              "  0.2500929832458496,\n",
              "  0.24993634223937988,\n",
              "  0.25001904368400574,\n",
              "  0.2500004768371582,\n",
              "  0.2501838207244873,\n",
              "  0.25001588463783264,\n",
              "  0.2500472068786621,\n",
              "  0.2500082850456238,\n",
              "  0.2500304877758026,\n",
              "  0.25002026557922363,\n",
              "  0.25018951296806335,\n",
              "  0.25001925230026245,\n",
              "  0.2499946802854538,\n",
              "  0.24994535744190216,\n",
              "  0.2500978708267212,\n",
              "  0.2500358819961548,\n",
              "  0.25000783801078796,\n",
              "  0.24992936849594116,\n",
              "  0.25023743510246277,\n",
              "  0.2500807046890259,\n",
              "  0.2500145733356476,\n",
              "  0.25000977516174316,\n",
              "  0.2500115931034088,\n",
              "  0.25000372529029846,\n",
              "  0.24994952976703644,\n",
              "  0.24991190433502197,\n",
              "  0.2501005232334137,\n",
              "  0.2500002682209015,\n",
              "  0.2501661777496338,\n",
              "  0.2501413822174072,\n",
              "  0.25015920400619507,\n",
              "  0.250087171792984,\n",
              "  0.25005707144737244,\n",
              "  0.2500341832637787,\n",
              "  0.25010743737220764,\n",
              "  0.24989712238311768,\n",
              "  0.2500093877315521,\n",
              "  0.2500233054161072,\n",
              "  0.25007009506225586,\n",
              "  0.2500249445438385,\n",
              "  0.25001588463783264,\n",
              "  0.25007936358451843,\n",
              "  0.25019142031669617,\n",
              "  0.25001707673072815,\n",
              "  0.2500475347042084,\n",
              "  0.2500474750995636,\n",
              "  0.2498132586479187,\n",
              "  0.24990983307361603,\n",
              "  0.25015708804130554,\n",
              "  0.2502322196960449,\n",
              "  0.2502763271331787,\n",
              "  0.24990923702716827,\n",
              "  0.25000032782554626,\n",
              "  0.2500063180923462,\n",
              "  0.2500747740268707,\n",
              "  0.2500113546848297,\n",
              "  0.25038573145866394,\n",
              "  0.2499595433473587,\n",
              "  0.250154972076416,\n",
              "  0.250167578458786,\n",
              "  0.2501182556152344,\n",
              "  0.2501438558101654,\n",
              "  0.25001177191734314,\n",
              "  0.2499847412109375,\n",
              "  0.25009575486183167,\n",
              "  0.2501890957355499,\n",
              "  0.25003692507743835,\n",
              "  0.25008904933929443,\n",
              "  0.25000086426734924,\n",
              "  0.2500097453594208,\n",
              "  0.25015386939048767,\n",
              "  0.2501060664653778,\n",
              "  0.25010406970977783,\n",
              "  0.25004419684410095,\n",
              "  0.2501527965068817,\n",
              "  0.2500455677509308,\n",
              "  0.25018346309661865],\n",
              " 'val_mse': [0.308056503534317,\n",
              "  0.29260894656181335,\n",
              "  0.26533111929893494,\n",
              "  0.2611239552497864,\n",
              "  0.2573321759700775,\n",
              "  0.2524290978908539,\n",
              "  0.25004085898399353,\n",
              "  0.25020089745521545,\n",
              "  0.2495681196451187,\n",
              "  0.24990050494670868,\n",
              "  0.25026199221611023,\n",
              "  0.25007790327072144,\n",
              "  0.2500448226928711,\n",
              "  0.2502357065677643,\n",
              "  0.2499634027481079,\n",
              "  0.2500171661376953,\n",
              "  0.2500123083591461,\n",
              "  0.2499762624502182,\n",
              "  0.2502681016921997,\n",
              "  0.24994899332523346,\n",
              "  0.25012338161468506,\n",
              "  0.25003430247306824,\n",
              "  0.25003674626350403,\n",
              "  0.2500021457672119,\n",
              "  0.2500079572200775,\n",
              "  0.2499322146177292,\n",
              "  0.25000742077827454,\n",
              "  0.25005853176116943,\n",
              "  0.25001609325408936,\n",
              "  0.24999888241291046,\n",
              "  0.2500002384185791,\n",
              "  0.2501786947250366,\n",
              "  0.2501368820667267,\n",
              "  0.2501131296157837,\n",
              "  0.25000378489494324,\n",
              "  0.2501722276210785,\n",
              "  0.25000497698783875,\n",
              "  0.24990952014923096,\n",
              "  0.25009873509407043,\n",
              "  0.25001516938209534,\n",
              "  0.24991975724697113,\n",
              "  0.2500005066394806,\n",
              "  0.25000178813934326,\n",
              "  0.25001680850982666,\n",
              "  0.2500443756580353,\n",
              "  0.2499348372220993,\n",
              "  0.2500058114528656,\n",
              "  0.25005805492401123,\n",
              "  0.25024572014808655,\n",
              "  0.24995918571949005,\n",
              "  0.25000110268592834,\n",
              "  0.24997560679912567,\n",
              "  0.25000470876693726,\n",
              "  0.24992735683918,\n",
              "  0.2499159425497055,\n",
              "  0.25003233551979065,\n",
              "  0.24993200600147247,\n",
              "  0.25001439452171326,\n",
              "  0.2500322163105011,\n",
              "  0.2501998841762543,\n",
              "  0.25000035762786865,\n",
              "  0.2500092685222626,\n",
              "  0.2500250041484833,\n",
              "  0.2500119209289551,\n",
              "  0.24991779029369354,\n",
              "  0.25008830428123474,\n",
              "  0.25005272030830383,\n",
              "  0.2500564754009247,\n",
              "  0.25016507506370544,\n",
              "  0.25007718801498413,\n",
              "  0.25005367398262024,\n",
              "  0.2501377761363983,\n",
              "  0.24989652633666992,\n",
              "  0.25013822317123413,\n",
              "  0.2500680685043335,\n",
              "  0.24990276992321014,\n",
              "  0.2500174045562744,\n",
              "  0.250159353017807,\n",
              "  0.2500724494457245,\n",
              "  0.2500075697898865,\n",
              "  0.2500952184200287,\n",
              "  0.2500059902667999,\n",
              "  0.250338077545166,\n",
              "  0.25063005089759827,\n",
              "  0.25000810623168945,\n",
              "  0.24992001056671143,\n",
              "  0.24998436868190765,\n",
              "  0.2500457763671875,\n",
              "  0.2500678300857544,\n",
              "  0.2500198781490326,\n",
              "  0.25010907649993896,\n",
              "  0.25047847628593445,\n",
              "  0.24991340935230255,\n",
              "  0.2501141130924225,\n",
              "  0.24994198977947235,\n",
              "  0.2500169575214386,\n",
              "  0.24990840256214142,\n",
              "  0.2500021755695343,\n",
              "  0.2500378489494324,\n",
              "  0.24989290535449982,\n",
              "  0.2497672438621521,\n",
              "  0.2500036954879761,\n",
              "  0.24999910593032837,\n",
              "  0.2501263916492462,\n",
              "  0.25011977553367615,\n",
              "  0.2500186562538147,\n",
              "  0.24989716708660126,\n",
              "  0.25012263655662537,\n",
              "  0.25009360909461975,\n",
              "  0.25002622604370117,\n",
              "  0.25000014901161194,\n",
              "  0.24999630451202393,\n",
              "  0.25001218914985657,\n",
              "  0.25007233023643494,\n",
              "  0.25002363324165344,\n",
              "  0.25001001358032227,\n",
              "  0.24985037744045258,\n",
              "  0.24999624490737915,\n",
              "  0.24997754395008087,\n",
              "  0.24989967048168182,\n",
              "  0.24997840821743011,\n",
              "  0.24992410838603973,\n",
              "  0.25054478645324707,\n",
              "  0.25019410252571106,\n",
              "  0.25001487135887146,\n",
              "  0.2500196397304535,\n",
              "  0.25012850761413574,\n",
              "  0.25001081824302673,\n",
              "  0.24973292648792267,\n",
              "  0.2502603530883789,\n",
              "  0.2499011754989624,\n",
              "  0.25005605816841125,\n",
              "  0.25003960728645325,\n",
              "  0.25002333521842957,\n",
              "  0.25000670552253723,\n",
              "  0.2500319182872772,\n",
              "  0.25002893805503845,\n",
              "  0.25012457370758057,\n",
              "  0.2500617504119873,\n",
              "  0.2500345706939697,\n",
              "  0.25019994378089905,\n",
              "  0.2500021159648895,\n",
              "  0.2502361238002777,\n",
              "  0.2503528892993927,\n",
              "  0.24991588294506073,\n",
              "  0.2502552568912506,\n",
              "  0.2500450909137726,\n",
              "  0.2504396140575409,\n",
              "  0.25002866983413696,\n",
              "  0.25004318356513977,\n",
              "  0.2500006854534149,\n",
              "  0.24994753301143646,\n",
              "  0.2500346302986145,\n",
              "  0.25016680359840393,\n",
              "  0.25021296739578247,\n",
              "  0.25031188130378723,\n",
              "  0.2501305937767029,\n",
              "  0.2499123066663742,\n",
              "  0.24999099969863892,\n",
              "  0.2500002980232239,\n",
              "  0.2499590516090393,\n",
              "  0.2500040829181671,\n",
              "  0.24998708069324493,\n",
              "  0.24973362684249878,\n",
              "  0.2504565715789795,\n",
              "  0.25002941489219666,\n",
              "  0.2500230073928833,\n",
              "  0.250002384185791,\n",
              "  0.2501618266105652,\n",
              "  0.24999158084392548,\n",
              "  0.2501208484172821,\n",
              "  0.2500366270542145,\n",
              "  0.24994318187236786,\n",
              "  0.24975354969501495,\n",
              "  0.25008711218833923,\n",
              "  0.25009509921073914,\n",
              "  0.2499382644891739,\n",
              "  0.25040629506111145,\n",
              "  0.25025609135627747,\n",
              "  0.25026068091392517,\n",
              "  0.2500045597553253,\n",
              "  0.25022274255752563,\n",
              "  0.25010526180267334,\n",
              "  0.24998682737350464,\n",
              "  0.25008705258369446,\n",
              "  0.249989315867424,\n",
              "  0.25000065565109253,\n",
              "  0.25002917647361755,\n",
              "  0.25023531913757324,\n",
              "  0.24996094405651093,\n",
              "  0.2500694692134857,\n",
              "  0.24994051456451416,\n",
              "  0.25002816319465637,\n",
              "  0.25012025237083435,\n",
              "  0.25013163685798645,\n",
              "  0.25000667572021484,\n",
              "  0.25004759430885315,\n",
              "  0.24992556869983673,\n",
              "  0.2504730224609375,\n",
              "  0.25001832842826843,\n",
              "  0.250347763299942,\n",
              "  0.25003519654273987,\n",
              "  0.2502076029777527,\n",
              "  0.24990642070770264,\n",
              "  0.25016316771507263,\n",
              "  0.25001418590545654,\n",
              "  0.250107079744339,\n",
              "  0.25011950731277466,\n",
              "  0.2500258982181549,\n",
              "  0.2502860426902771,\n",
              "  0.250175803899765,\n",
              "  0.2500723898410797,\n",
              "  0.25009456276893616,\n",
              "  0.25002291798591614,\n",
              "  0.2501560151576996,\n",
              "  0.2500104606151581,\n",
              "  0.2500208914279938,\n",
              "  0.25006699562072754,\n",
              "  0.25001487135887146,\n",
              "  0.25000908970832825,\n",
              "  0.2501099109649658,\n",
              "  0.25008612871170044,\n",
              "  0.24993209540843964,\n",
              "  0.250196248292923,\n",
              "  0.2500549554824829,\n",
              "  0.24999581277370453,\n",
              "  0.25000664591789246,\n",
              "  0.24979393184185028,\n",
              "  0.25005462765693665,\n",
              "  0.25010061264038086,\n",
              "  0.25000864267349243,\n",
              "  0.2499179244041443,\n",
              "  0.25010934472084045,\n",
              "  0.24995915591716766,\n",
              "  0.2501786947250366,\n",
              "  0.2500187158584595,\n",
              "  0.2500320374965668,\n",
              "  0.24999845027923584,\n",
              "  0.2500077188014984,\n",
              "  0.2501133680343628,\n",
              "  0.25002607703208923,\n",
              "  0.25015756487846375,\n",
              "  0.2503744065761566,\n",
              "  0.2505049705505371,\n",
              "  0.25015223026275635,\n",
              "  0.2502981424331665,\n",
              "  0.24990566074848175,\n",
              "  0.25003424286842346,\n",
              "  0.25032874941825867,\n",
              "  0.25017237663269043,\n",
              "  0.2499881237745285,\n",
              "  0.2502649426460266,\n",
              "  0.2501332759857178,\n",
              "  0.2504430115222931,\n",
              "  0.250505656003952,\n",
              "  0.25003373622894287,\n",
              "  0.2500286102294922,\n",
              "  0.24997688829898834,\n",
              "  0.25000572204589844,\n",
              "  0.24999648332595825,\n",
              "  0.24988408386707306,\n",
              "  0.25001463294029236,\n",
              "  0.2499246597290039,\n",
              "  0.2500002682209015,\n",
              "  0.25000038743019104,\n",
              "  0.24995696544647217,\n",
              "  0.25017616152763367,\n",
              "  0.2500065267086029,\n",
              "  0.2500002384185791,\n",
              "  0.249929741024971,\n",
              "  0.2500603497028351,\n",
              "  0.2500055730342865,\n",
              "  0.24997484683990479,\n",
              "  0.2499213069677353,\n",
              "  0.25001394748687744,\n",
              "  0.2500087320804596,\n",
              "  0.2500397861003876,\n",
              "  0.25003311038017273,\n",
              "  0.250295490026474,\n",
              "  0.25031331181526184,\n",
              "  0.2504708766937256,\n",
              "  0.25001609325408936,\n",
              "  0.25002267956733704,\n",
              "  0.25020158290863037,\n",
              "  0.25017502903938293,\n",
              "  0.24998831748962402,\n",
              "  0.2500583231449127,\n",
              "  0.2499757558107376,\n",
              "  0.25008630752563477,\n",
              "  0.2503286898136139,\n",
              "  0.2500580847263336,\n",
              "  0.2498513013124466,\n",
              "  0.2500130236148834,\n",
              "  0.2500949203968048,\n",
              "  0.24984455108642578,\n",
              "  0.25007376074790955,\n",
              "  0.24998532235622406,\n",
              "  0.2501659095287323,\n",
              "  0.25000616908073425,\n",
              "  0.25011685490608215,\n",
              "  0.2502008378505707,\n",
              "  0.2500368058681488,\n",
              "  0.25024208426475525,\n",
              "  0.25024354457855225,\n",
              "  0.2499321848154068,\n",
              "  0.2500002086162567,\n",
              "  0.2499380111694336,\n",
              "  0.2501962184906006,\n",
              "  0.25018981099128723,\n",
              "  0.2502218782901764,\n",
              "  0.24993151426315308,\n",
              "  0.24996550381183624,\n",
              "  0.25066375732421875,\n",
              "  0.25005868077278137,\n",
              "  0.2500176727771759,\n",
              "  0.2500000596046448,\n",
              "  0.24991464614868164,\n",
              "  0.25002601742744446,\n",
              "  0.2500913441181183,\n",
              "  0.2498915046453476,\n",
              "  0.250000923871994,\n",
              "  0.2499353438615799,\n",
              "  0.2500110864639282,\n",
              "  0.2499667853116989,\n",
              "  0.2504596412181854,\n",
              "  0.2500772178173065,\n",
              "  0.25005725026130676,\n",
              "  0.25021126866340637,\n",
              "  0.24999350309371948,\n",
              "  0.25002729892730713,\n",
              "  0.2501390278339386,\n",
              "  0.2500215470790863,\n",
              "  0.2500223219394684,\n",
              "  0.24994485080242157,\n",
              "  0.2501007616519928,\n",
              "  0.2500030994415283,\n",
              "  0.2500332295894623,\n",
              "  0.25023889541625977,\n",
              "  0.24993722140789032,\n",
              "  0.2500256597995758,\n",
              "  0.2499762326478958,\n",
              "  0.2499082088470459,\n",
              "  0.25000813603401184,\n",
              "  0.25000128149986267,\n",
              "  0.2500075697898865,\n",
              "  0.2499421238899231,\n",
              "  0.2499561905860901,\n",
              "  0.24998408555984497,\n",
              "  0.25042709708213806,\n",
              "  0.25026220083236694,\n",
              "  0.25003984570503235,\n",
              "  0.2500295341014862,\n",
              "  0.2497798204421997,\n",
              "  0.24995489418506622,\n",
              "  0.2500034272670746,\n",
              "  0.24994151294231415,\n",
              "  0.25016283988952637,\n",
              "  0.2500128746032715,\n",
              "  0.24998871982097626,\n",
              "  0.25000062584877014,\n",
              "  0.24999386072158813,\n",
              "  0.2500063180923462,\n",
              "  0.2500002682209015,\n",
              "  0.2500036656856537,\n",
              "  0.24993890523910522,\n",
              "  0.24989263713359833,\n",
              "  0.2502754032611847,\n",
              "  0.25001680850982666,\n",
              "  0.25000131130218506,\n",
              "  0.24967874586582184,\n",
              "  0.24998003244400024,\n",
              "  0.2499486654996872,\n",
              "  0.25001898407936096,\n",
              "  0.25007393956184387,\n",
              "  0.25001662969589233,\n",
              "  0.2504170536994934,\n",
              "  0.2500065565109253,\n",
              "  0.25038984417915344,\n",
              "  0.2500245273113251,\n",
              "  0.2500450313091278,\n",
              "  0.24999745190143585,\n",
              "  0.2500775158405304,\n",
              "  0.250014990568161,\n",
              "  0.2503419518470764,\n",
              "  0.24979831278324127,\n",
              "  0.2501021921634674,\n",
              "  0.25000324845314026,\n",
              "  0.2500055134296417,\n",
              "  0.2500934600830078,\n",
              "  0.2501295506954193,\n",
              "  0.25037655234336853,\n",
              "  0.24989159405231476,\n",
              "  0.24990446865558624,\n",
              "  0.24993430078029633,\n",
              "  0.24969632923603058,\n",
              "  0.2500021457672119,\n",
              "  0.24996238946914673,\n",
              "  0.24999690055847168,\n",
              "  0.25000402331352234,\n",
              "  0.2500000596046448,\n",
              "  0.24999640882015228,\n",
              "  0.25020745396614075,\n",
              "  0.24992655217647552,\n",
              "  0.2500406801700592,\n",
              "  0.24998772144317627,\n",
              "  0.2504144608974457,\n",
              "  0.2502942383289337,\n",
              "  0.2501036524772644,\n",
              "  0.2500460147857666,\n",
              "  0.25000789761543274,\n",
              "  0.2500488758087158,\n",
              "  0.2500000298023224,\n",
              "  0.2501131594181061,\n",
              "  0.25000712275505066,\n",
              "  0.2499309927225113,\n",
              "  0.25000762939453125,\n",
              "  0.24998025596141815,\n",
              "  0.250084787607193,\n",
              "  0.2500406801700592,\n",
              "  0.25031325221061707,\n",
              "  0.2500717341899872,\n",
              "  0.2499186396598816,\n",
              "  0.2502475082874298,\n",
              "  0.25016626715660095,\n",
              "  0.2500046491622925,\n",
              "  0.24997062981128693,\n",
              "  0.25001460313796997,\n",
              "  0.24991251528263092,\n",
              "  0.2502850592136383,\n",
              "  0.2498975545167923,\n",
              "  0.2502630949020386,\n",
              "  0.25005853176116943,\n",
              "  0.24998362362384796,\n",
              "  0.2500015199184418,\n",
              "  0.2500437796115875,\n",
              "  0.2500293254852295,\n",
              "  0.25001052021980286,\n",
              "  0.2501230537891388,\n",
              "  0.2500463128089905,\n",
              "  0.2499598115682602,\n",
              "  0.24993447959423065,\n",
              "  0.25010159611701965,\n",
              "  0.2503664493560791,\n",
              "  0.2500975430011749,\n",
              "  0.2501181960105896,\n",
              "  0.2500125467777252,\n",
              "  0.25005805492401123,\n",
              "  0.25042590498924255,\n",
              "  0.24990259110927582,\n",
              "  0.25004148483276367,\n",
              "  0.2500004470348358,\n",
              "  0.25002482533454895,\n",
              "  0.25000280141830444,\n",
              "  0.2502128779888153,\n",
              "  0.24987967312335968,\n",
              "  0.2502831518650055,\n",
              "  0.24995923042297363,\n",
              "  0.2501593828201294,\n",
              "  0.2500326335430145,\n",
              "  0.250104695558548,\n",
              "  0.25012367963790894,\n",
              "  0.25003936886787415,\n",
              "  0.24996574223041534,\n",
              "  0.250116229057312,\n",
              "  0.24996799230575562,\n",
              "  0.2500133812427521,\n",
              "  0.24999739229679108,\n",
              "  0.25004565715789795,\n",
              "  0.2500018775463104,\n",
              "  0.2501929998397827,\n",
              "  0.2500000298023224,\n",
              "  0.2502172291278839,\n",
              "  0.2502802014350891,\n",
              "  0.2503475248813629,\n",
              "  0.2500021755695343,\n",
              "  0.2500743269920349,\n",
              "  0.2500270903110504,\n",
              "  0.250200480222702,\n",
              "  0.2502498924732208,\n",
              "  0.2502855062484741,\n",
              "  0.2500722110271454,\n",
              "  0.25009605288505554,\n",
              "  0.2500237822532654,\n",
              "  0.24995851516723633,\n",
              "  0.24997419118881226,\n",
              "  0.25002923607826233,\n",
              "  0.24991190433502197,\n",
              "  0.2499421089887619,\n",
              "  0.2504206895828247,\n",
              "  0.2502056062221527,\n",
              "  0.250615656375885,\n",
              "  0.24990396201610565,\n",
              "  0.24993497133255005,\n",
              "  0.25011447072029114,\n",
              "  0.250095397233963,\n",
              "  0.2499704211950302,\n",
              "  0.25000521540641785,\n",
              "  0.2499227076768875,\n",
              "  0.24997466802597046,\n",
              "  0.2500048577785492,\n",
              "  0.25000008940696716,\n",
              "  0.2500015199184418,\n",
              "  0.2501576244831085,\n",
              "  0.2500700354576111,\n",
              "  0.25006672739982605,\n",
              "  0.2500499188899994,\n",
              "  0.2500016391277313,\n",
              "  0.25002071261405945,\n",
              "  0.25000065565109253,\n",
              "  0.24993784725666046,\n",
              "  0.25005626678466797,\n",
              "  0.2500281035900116,\n",
              "  0.2499806135892868,\n",
              "  0.250003844499588,\n",
              "  0.25004780292510986,\n",
              "  0.2499227374792099,\n",
              "  0.24992136657238007,\n",
              "  0.2502150237560272,\n",
              "  0.25017985701560974,\n",
              "  0.2500070035457611,\n",
              "  0.2500215768814087,\n",
              "  0.25000399351119995,\n",
              "  0.24981272220611572,\n",
              "  0.24998344480991364,\n",
              "  0.25005820393562317,\n",
              "  0.250034898519516,\n",
              "  0.25016555190086365,\n",
              "  0.25025030970573425,\n",
              "  0.25007370114326477,\n",
              "  0.24991603195667267,\n",
              "  0.25002607703208923,\n",
              "  0.25000113248825073,\n",
              "  0.2502531111240387,\n",
              "  0.2500058114528656,\n",
              "  0.2501412630081177,\n",
              "  0.2501514256000519,\n",
              "  0.2500629723072052,\n",
              "  0.2501468062400818,\n",
              "  0.2500324547290802,\n",
              "  0.2500027120113373,\n",
              "  0.24992911517620087,\n",
              "  0.250244140625,\n",
              "  0.25011229515075684,\n",
              "  0.2500002384185791,\n",
              "  0.2503540813922882,\n",
              "  0.24998259544372559,\n",
              "  0.2502351999282837,\n",
              "  0.2500021755695343,\n",
              "  0.25002938508987427,\n",
              "  0.24993102252483368,\n",
              "  0.25022682547569275,\n",
              "  0.25003257393836975,\n",
              "  0.25002792477607727,\n",
              "  0.24992044270038605,\n",
              "  0.25002244114875793,\n",
              "  0.2505352795124054,\n",
              "  0.25002622604370117,\n",
              "  0.2501390278339386,\n",
              "  0.24997620284557343,\n",
              "  0.2500015199184418,\n",
              "  0.25000742077827454,\n",
              "  0.2500990629196167,\n",
              "  0.24998529255390167,\n",
              "  0.2500138580799103,\n",
              "  0.25000131130218506,\n",
              "  0.25000330805778503,\n",
              "  0.250093549489975,\n",
              "  0.25,\n",
              "  0.25000306963920593,\n",
              "  0.2500499486923218,\n",
              "  0.2500148117542267,\n",
              "  0.24995845556259155,\n",
              "  0.24995343387126923,\n",
              "  0.24993427097797394,\n",
              "  0.25000762939453125,\n",
              "  0.25028279423713684,\n",
              "  0.2502313256263733,\n",
              "  0.250002920627594,\n",
              "  0.2500031888484955,\n",
              "  0.2500523030757904,\n",
              "  0.2499486356973648,\n",
              "  0.2501795291900635,\n",
              "  0.25012263655662537,\n",
              "  0.250153511762619,\n",
              "  0.25,\n",
              "  0.24996767938137054,\n",
              "  0.24999673664569855,\n",
              "  0.2500024139881134,\n",
              "  0.25000056624412537,\n",
              "  0.2500535547733307,\n",
              "  0.2502683699131012,\n",
              "  0.2500692307949066,\n",
              "  0.2500596046447754,\n",
              "  0.25024858117103577,\n",
              "  0.2500097453594208,\n",
              "  0.25006163120269775,\n",
              "  0.25023922324180603,\n",
              "  0.2500338852405548,\n",
              "  0.25018003582954407,\n",
              "  0.25000593066215515,\n",
              "  0.25002118945121765,\n",
              "  0.25000104308128357,\n",
              "  0.25004667043685913,\n",
              "  0.2499711662530899,\n",
              "  0.25002357363700867,\n",
              "  0.25005462765693665,\n",
              "  0.2500781714916229,\n",
              "  0.2499733567237854,\n",
              "  0.25035765767097473,\n",
              "  0.2503318786621094,\n",
              "  0.25001731514930725,\n",
              "  0.2500755190849304,\n",
              "  0.24989156424999237,\n",
              "  0.2500075399875641,\n",
              "  0.25022685527801514,\n",
              "  0.25028905272483826,\n",
              "  0.25038862228393555,\n",
              "  0.2500038743019104,\n",
              "  0.2500186264514923,\n",
              "  0.2500017583370209,\n",
              "  0.25001785159111023,\n",
              "  0.25001227855682373,\n",
              "  0.2500016391277313,\n",
              "  0.2499845176935196,\n",
              "  0.2500057518482208,\n",
              "  0.24992318451404572,\n",
              "  0.2500533163547516,\n",
              "  0.24990351498126984,\n",
              "  0.250079870223999,\n",
              "  0.25014975666999817,\n",
              "  0.24993108212947845,\n",
              "  0.2499709576368332,\n",
              "  0.2499772310256958,\n",
              "  0.2499188929796219,\n",
              "  0.2500767409801483,\n",
              "  0.25000008940696716,\n",
              "  0.25000131130218506,\n",
              "  0.25002333521842957,\n",
              "  0.2504238188266754,\n",
              "  0.2501325309276581,\n",
              "  0.2507447898387909,\n",
              "  0.25,\n",
              "  0.2500288188457489,\n",
              "  0.25000080466270447,\n",
              "  0.25004562735557556,\n",
              "  0.24991655349731445,\n",
              "  0.2501322329044342,\n",
              "  0.24998259544372559,\n",
              "  0.25004103779792786,\n",
              "  0.24989156424999237,\n",
              "  0.250007688999176,\n",
              "  0.2500537931919098,\n",
              "  0.25005683302879333,\n",
              "  0.25005796551704407,\n",
              "  0.2501058876514435,\n",
              "  0.25018981099128723,\n",
              "  0.2500559985637665,\n",
              "  0.2500937283039093,\n",
              "  0.25000134110450745,\n",
              "  0.2500028610229492,\n",
              "  0.25000473856925964,\n",
              "  0.25003883242607117,\n",
              "  0.24988140165805817,\n",
              "  0.24986064434051514,\n",
              "  0.25001707673072815,\n",
              "  0.25003519654273987,\n",
              "  0.24999690055847168,\n",
              "  0.2500286400318146,\n",
              "  0.25000450015068054,\n",
              "  0.25025007128715515,\n",
              "  0.2500975728034973,\n",
              "  0.2498917579650879,\n",
              "  0.25001588463783264,\n",
              "  0.2500598430633545,\n",
              "  0.2500985562801361,\n",
              "  0.25006240606307983,\n",
              "  0.24998454749584198,\n",
              "  0.250120609998703,\n",
              "  0.25000014901161194,\n",
              "  0.25001928210258484,\n",
              "  0.24985218048095703,\n",
              "  0.25004643201828003,\n",
              "  0.25002405047416687,\n",
              "  0.25002869963645935,\n",
              "  0.25000008940696716,\n",
              "  0.2500089108943939,\n",
              "  0.249893918633461,\n",
              "  0.25016412138938904,\n",
              "  0.24989742040634155,\n",
              "  0.25006434321403503,\n",
              "  0.2500152289867401,\n",
              "  0.24990062415599823,\n",
              "  0.25051844120025635,\n",
              "  0.24999113380908966,\n",
              "  0.2500019967556,\n",
              "  0.25007662177085876,\n",
              "  0.2500491440296173,\n",
              "  0.25013676285743713,\n",
              "  0.2505345642566681,\n",
              "  0.24990765750408173,\n",
              "  0.25001510977745056,\n",
              "  0.25027504563331604,\n",
              "  0.24990929663181305,\n",
              "  0.2497902512550354,\n",
              "  0.25002241134643555,\n",
              "  0.24990014731884003,\n",
              "  0.24989430606365204,\n",
              "  0.2500971257686615,\n",
              "  0.2501310408115387,\n",
              "  0.2502272129058838,\n",
              "  0.2499912530183792,\n",
              "  0.2500467002391815,\n",
              "  0.2500046491622925,\n",
              "  0.2500005066394806,\n",
              "  0.2500280439853668,\n",
              "  0.2500017583370209,\n",
              "  0.24991463124752045,\n",
              "  0.25012776255607605,\n",
              "  0.25004565715789795,\n",
              "  0.25023162364959717,\n",
              "  0.2500447928905487,\n",
              "  0.2500554323196411,\n",
              "  0.2500190734863281,\n",
              "  0.250000923871994,\n",
              "  0.25002220273017883,\n",
              "  0.2504453957080841,\n",
              "  0.25002044439315796,\n",
              "  0.2497834414243698,\n",
              "  0.25001856684684753,\n",
              "  0.25001394748687744,\n",
              "  0.25006821751594543,\n",
              "  0.25034114718437195,\n",
              "  0.2502024471759796,\n",
              "  0.2504254877567291,\n",
              "  0.25022128224372864,\n",
              "  0.25022122263908386,\n",
              "  0.25001415610313416,\n",
              "  0.2501690685749054,\n",
              "  0.2503810226917267,\n",
              "  0.25002768635749817,\n",
              "  0.25000008940696716,\n",
              "  0.249921515583992,\n",
              "  0.2498915195465088,\n",
              "  0.24994947016239166,\n",
              "  0.2500150203704834,\n",
              "  0.2499057650566101,\n",
              "  0.24995921552181244,\n",
              "  0.2501037120819092,\n",
              "  0.25000202655792236,\n",
              "  0.24990655481815338,\n",
              "  0.2502748370170593,\n",
              "  0.25021541118621826,\n",
              "  0.24994802474975586,\n",
              "  0.25000134110450745,\n",
              "  0.2500186264514923,\n",
              "  0.25005775690078735,\n",
              "  0.25013527274131775,\n",
              "  0.24991266429424286,\n",
              "  0.24997234344482422,\n",
              "  0.2500359117984772,\n",
              "  0.25004997849464417,\n",
              "  0.2500111758708954,\n",
              "  0.250312477350235,\n",
              "  0.25020983815193176,\n",
              "  0.2500350773334503,\n",
              "  0.250161737203598,\n",
              "  0.24995730817317963,\n",
              "  0.25000616908073425,\n",
              "  0.25000184774398804,\n",
              "  0.24991337954998016,\n",
              "  0.2499891072511673,\n",
              "  0.25001242756843567,\n",
              "  0.25006067752838135,\n",
              "  0.25000426173210144,\n",
              "  0.24999485909938812,\n",
              "  0.24997393786907196,\n",
              "  0.24999408423900604,\n",
              "  0.250000923871994,\n",
              "  0.2500286400318146,\n",
              "  0.25024107098579407,\n",
              "  0.24991708993911743,\n",
              "  0.2501316964626312,\n",
              "  0.2500033676624298,\n",
              "  0.2501644790172577,\n",
              "  0.24991004168987274,\n",
              "  0.2500176727771759,\n",
              "  0.2501218616962433,\n",
              "  0.24994266033172607,\n",
              "  0.25014033913612366,\n",
              "  0.25014716386795044,\n",
              "  0.2500249445438385,\n",
              "  0.2501177489757538,\n",
              "  0.2500982880592346,\n",
              "  0.2500576972961426,\n",
              "  0.25034430623054504,\n",
              "  0.25012317299842834,\n",
              "  0.24999606609344482,\n",
              "  0.2498675435781479,\n",
              "  0.2500136196613312,\n",
              "  0.24998366832733154,\n",
              "  0.24989180266857147,\n",
              "  0.2501331865787506,\n",
              "  0.2501482367515564,\n",
              "  0.2505802512168884,\n",
              "  0.25019216537475586,\n",
              "  0.2500227391719818,\n",
              "  0.24990296363830566,\n",
              "  0.2500767409801483,\n",
              "  0.2499089241027832,\n",
              "  0.25011226534843445,\n",
              "  0.2500368356704712,\n",
              "  0.2500896155834198,\n",
              "  0.24990642070770264,\n",
              "  0.25000134110450745,\n",
              "  0.24998962879180908,\n",
              "  0.25003254413604736,\n",
              "  0.2501074969768524,\n",
              "  0.25002190470695496,\n",
              "  0.25001588463783264,\n",
              "  0.24990278482437134,\n",
              "  0.2500702440738678,\n",
              "  0.24990756809711456,\n",
              "  0.24996714293956757,\n",
              "  0.2502228319644928,\n",
              "  0.2501227557659149,\n",
              "  0.2500012218952179,\n",
              "  0.2499474436044693,\n",
              "  0.24993084371089935,\n",
              "  0.24989299476146698,\n",
              "  0.24991631507873535,\n",
              "  0.25002211332321167,\n",
              "  0.250041127204895,\n",
              "  0.25003692507743835,\n",
              "  0.2500409483909607,\n",
              "  0.24989216029644012,\n",
              "  0.2500610053539276,\n",
              "  0.2503054440021515,\n",
              "  0.24989791214466095,\n",
              "  0.2500114142894745,\n",
              "  0.25010085105895996,\n",
              "  0.25005054473876953,\n",
              "  0.2499275803565979,\n",
              "  0.25017136335372925,\n",
              "  0.2500063180923462,\n",
              "  0.2499462366104126,\n",
              "  0.24992050230503082,\n",
              "  0.2500852942466736,\n",
              "  0.2500492334365845,\n",
              "  0.2503388524055481,\n",
              "  0.24994777143001556,\n",
              "  0.2500666677951813,\n",
              "  0.2500390410423279,\n",
              "  0.2500986158847809,\n",
              "  0.24993957579135895,\n",
              "  0.25001201033592224,\n",
              "  0.2500002682209015,\n",
              "  0.24992488324642181,\n",
              "  0.25004154443740845,\n",
              "  0.24993199110031128,\n",
              "  0.2500912845134735,\n",
              "  0.2500433921813965,\n",
              "  0.250000536441803,\n",
              "  0.2499413639307022,\n",
              "  0.2502746880054474,\n",
              "  0.2500002086162567,\n",
              "  0.24995531141757965,\n",
              "  0.2500027120113373,\n",
              "  0.25003865361213684,\n",
              "  0.25036442279815674,\n",
              "  0.2500092685222626,\n",
              "  0.25001755356788635,\n",
              "  0.2499304562807083,\n",
              "  0.2501833140850067,\n",
              "  0.2502988278865814,\n",
              "  0.24999256432056427,\n",
              "  0.24995087087154388,\n",
              "  0.25000515580177307,\n",
              "  0.2502954304218292,\n",
              "  0.2500028610229492,\n",
              "  0.25007081031799316,\n",
              "  0.24995894730091095,\n",
              "  0.25000062584877014,\n",
              "  0.2500826120376587,\n",
              "  0.2500207722187042,\n",
              "  0.24975860118865967,\n",
              "  0.25009408593177795,\n",
              "  0.24998001754283905,\n",
              "  0.24990379810333252,\n",
              "  0.250004380941391,\n",
              "  0.2499428242444992,\n",
              "  0.2500995099544525,\n",
              "  0.2500161826610565,\n",
              "  0.25001609325408936,\n",
              "  0.24996711313724518,\n",
              "  0.25021713972091675,\n",
              "  0.25003159046173096,\n",
              "  0.25001806020736694,\n",
              "  0.24996404349803925,\n",
              "  0.2500250041484833,\n",
              "  0.25002849102020264,\n",
              "  0.2501344084739685,\n",
              "  0.2500121593475342,\n",
              "  0.25009819865226746,\n",
              "  0.2500104308128357,\n",
              "  0.25003746151924133,\n",
              "  0.24997635185718536,\n",
              "  0.25007644295692444,\n",
              "  0.25,\n",
              "  0.25012069940567017,\n",
              "  0.250007688999176,\n",
              "  0.24993957579135895,\n",
              "  0.2500009536743164,\n",
              "  0.250002920627594,\n",
              "  0.2500041127204895,\n",
              "  0.2501833736896515,\n",
              "  0.2499016672372818,\n",
              "  0.2500058114528656,\n",
              "  0.25034844875335693,\n",
              "  0.25026360154151917,\n",
              "  0.24993896484375,\n",
              "  0.25000402331352234,\n",
              "  0.2500520646572113,\n",
              "  0.24993014335632324,\n",
              "  0.2500929832458496,\n",
              "  0.24993634223937988,\n",
              "  0.25001904368400574,\n",
              "  0.2500004768371582,\n",
              "  0.2501838207244873,\n",
              "  0.25001588463783264,\n",
              "  0.2500472068786621,\n",
              "  0.2500082850456238,\n",
              "  0.2500304877758026,\n",
              "  0.25002026557922363,\n",
              "  0.25018951296806335,\n",
              "  0.25001925230026245,\n",
              "  0.2499946802854538,\n",
              "  0.24994535744190216,\n",
              "  0.2500978708267212,\n",
              "  0.2500358819961548,\n",
              "  0.25000783801078796,\n",
              "  0.24992936849594116,\n",
              "  0.25023743510246277,\n",
              "  0.2500807046890259,\n",
              "  0.2500145733356476,\n",
              "  0.25000977516174316,\n",
              "  0.2500115931034088,\n",
              "  0.25000372529029846,\n",
              "  0.24994952976703644,\n",
              "  0.24991190433502197,\n",
              "  0.2501005232334137,\n",
              "  0.2500002682209015,\n",
              "  0.2501661777496338,\n",
              "  0.2501413822174072,\n",
              "  0.25015920400619507,\n",
              "  0.250087171792984,\n",
              "  0.25005707144737244,\n",
              "  0.2500341832637787,\n",
              "  0.25010743737220764,\n",
              "  0.24989712238311768,\n",
              "  0.2500093877315521,\n",
              "  0.2500233054161072,\n",
              "  0.25007009506225586,\n",
              "  0.2500249445438385,\n",
              "  0.25001588463783264,\n",
              "  0.25007936358451843,\n",
              "  0.25019142031669617,\n",
              "  0.25001707673072815,\n",
              "  0.2500475347042084,\n",
              "  0.2500474750995636,\n",
              "  0.2498132586479187,\n",
              "  0.24990983307361603,\n",
              "  0.25015708804130554,\n",
              "  0.2502322196960449,\n",
              "  0.2502763271331787,\n",
              "  0.24990923702716827,\n",
              "  0.25000032782554626,\n",
              "  0.2500063180923462,\n",
              "  0.2500747740268707,\n",
              "  0.2500113546848297,\n",
              "  0.25038573145866394,\n",
              "  0.2499595433473587,\n",
              "  0.250154972076416,\n",
              "  0.250167578458786,\n",
              "  0.2501182556152344,\n",
              "  0.2501438558101654,\n",
              "  0.25001177191734314,\n",
              "  0.2499847412109375,\n",
              "  0.25009575486183167,\n",
              "  0.2501890957355499,\n",
              "  0.25003692507743835,\n",
              "  0.25008904933929443,\n",
              "  0.25000086426734924,\n",
              "  0.2500097453594208,\n",
              "  0.25015386939048767,\n",
              "  0.2501060664653778,\n",
              "  0.25010406970977783,\n",
              "  0.25004419684410095,\n",
              "  0.2501527965068817,\n",
              "  0.2500455677509308,\n",
              "  0.25018346309661865]}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot training performance"
      ],
      "metadata": {
        "id": "54D1y5fZcRUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "mse = history.history['mse']\n",
        "val_mse = history.history['val_mse']\n",
        "\n",
        "epochs_x = range(len(loss))\n",
        "\n",
        "plt.plot(epochs_x, mse, 'co', label='Training MAE')\n",
        "plt.plot(epochs_x, val_mse, 'k', label='Validation MAE')\n",
        "plt.title('Training and Mean squared error')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'co', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Aig-yHOBcNrP",
        "outputId": "1a241344-e786-4b1b-ca20-45b9baec8511",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3hV1Z3/8fc3FwKEm0AMQtAkLaAoyCWAilq8dCrqiFo7lTIKP1tRq2Nb2yotrTK2/GZGfRzHZ9CW2trLYNHaDj+sOLQqjFqxEpSiXCIxgkY0AnIJBEKA7++PtRMOIZeTcCBh83k9Dw9nr7323t+198n3rLP2PnubuyMiIvGV1tYBiIjIkaVELyISc0r0IiIxp0QvIhJzSvQiIjGnRC8iEnNK9NIiZvacmU1Odd22ZGbrzOziI7BeN7PPRq9/YmY/TKZuK7Yzycz+1No4m1jvODMrT/V65ejLaOsA5Mgzsx0Jk52BamBfNH2Tu89Jdl3uPv5I1I07d785Fesxs3zgPSDT3fdG654DJH0M5fijRH8ccPcuta/NbB3wNXd/vn49M8uoTR4iEh8aujmO1X41N7O7zOxj4HEzO8HM/mhmG81sS/Q6L2GZxWb2tej1FDN7xcweiOq+Z2bjW1m3wMxeMrNKM3vezGaZ2X81EncyMf7IzP4Sre9PZtY7Yf51ZrbezDab2fQm9s8YM/vYzNITyq4ysxXR69FmtsTMtprZR2b2n2bWoZF1/dLMfpww/d1omQ1mdkO9upeZ2Ztmtt3MPjCzGQmzX4r+32pmO8zs7Np9m7D8OWa21My2Rf+fk+y+aYqZnRYtv9XMVprZFQnzLjWzVdE6PzSz70TlvaPjs9XMPjWzl81Meeco0w6XPkBP4BRgKuE98Xg0fTKwC/jPJpYfA5QAvYH7gJ+bmbWi7hPA60AvYAZwXRPbTCbGrwD/BzgR6ADUJp7BwKPR+vtG28ujAe7+V2AncGG99T4Rvd4HfCtqz9nARcDXm4ibKIZLong+DwwA6p8f2AlcD/QALgNuMbMro3nnR//3cPcu7r6k3rp7As8CD0dtexB41sx61WvDIfummZgzgWeAP0XL/RMwx8wGRVV+ThgG7AqcAbwYlX8bKAdygFzg+4Duu3KUKdHLfuAed692913uvtndf+/uVe5eCcwEPtfE8uvd/Wfuvg/4FXAS4Q866bpmdjIwCrjb3fe4+yvA/MY2mGSMj7v7O+6+C3gKGBaVXwP80d1fcvdq4IfRPmjMb4GJAGbWFbg0KsPdl7n7a+6+193XAT9tII6G/EMU39vuvpPwwZbYvsXu/pa773f3FdH2klkvhA+Gte7+myiu3wJrgL9PqNPYvmnKWUAX4F+jY/Qi8EeifQPUAIPNrJu7b3H3NxLKTwJOcfcad3/ZdYOto06JXja6++7aCTPrbGY/jYY2thOGCnokDl/U83HtC3evil52aWHdvsCnCWUAHzQWcJIxfpzwuiohpr6J644S7ebGtkXovV9tZlnA1cAb7r4+imNgNCzxcRTH/yX07ptzUAzA+nrtG2Nmi6KhqW3AzUmut3bd6+uVrQf6JUw3tm+ajdndEz8UE9f7RcKH4Hoz+18zOzsqvx8oBf5kZmVmNi25ZkgqKdFL/d7Vt4FBwBh378aBoYLGhmNS4SOgp5l1Tijr30T9w4nxo8R1R9vs1Vhld19FSGjjOXjYBsIQ0BpgQBTH91sTA2H4KdEThG80/d29O/CThPU21xveQBjSSnQy8GEScTW33v71xtfr1uvuS919AmFYZx7hmwLuXunu33b3QuAK4A4zu+gwY5EWUqKX+roSxry3RuO99xzpDUY95GJghpl1iHqDf9/EIocT49PA5WZ2bnTi9F6a/zt4AvgG4QPld/Xi2A7sMLNTgVuSjOEpYIqZDY4+aOrH35XwDWe3mY0mfMDU2kgYaipsZN0LgIFm9hUzyzCzLwODCcMsh+OvhN7/nWaWaWbjCMdobnTMJplZd3evIeyT/QBmdrmZfTY6F7ONcF6jqaEyOQKU6KW+h4BOwCbgNeB/jtJ2JxFOaG4Gfgw8SbjevyGtjtHdVwK3EpL3R8AWwsnCptSOkb/o7psSyr9DSMKVwM+imJOJ4bmoDS8ShjVerFfl68C9ZlYJ3E3UO46WrSKck/hLdCXLWfXWvRm4nPCtZzNwJ3B5vbhbzN33EBL7eMJ+fwS43t3XRFWuA9ZFQ1g3E44nhJPNzwM7gCXAI+6+6HBikZYznReR9sjMngTWuPsR/0YhEnfq0Uu7YGajzOwzZpYWXX44gTDWKyKHSb+MlfaiD/AHwonRcuAWd3+zbUMSiQcN3YiIxJyGbkREYq7dDd307t3b8/Pz2zoMEZFjyrJlyza5e05D89pdos/Pz6e4uLitwxAROaaYWf1fRNfR0I2ISMwp0YuIxJwSvYhIzLW7MXoROfpqamooLy9n9+7dzVeWNtWxY0fy8vLIzMxMehklehGhvLycrl27kp+fT+PPjZG25u5s3ryZ8vJyCgoKkl4uNkM3cyoqyF+yhLTFi8lfsoQ5FRVtHZLIMWP37t306tVLSb6dMzN69erV4m9esejRz6moYGpJCVX7w91P11dXM7WkBIBJuY097EhEEinJHxtac5xi0aOfXlZWl+RrVe3fz/SysjaKSESk/YhFon+/uuHbljdWLiLty+bNmxk2bBjDhg2jT58+9OvXr256z549TS5bXFzM7bff3uw2zjnnnJTEunjxYi6//PKUrOtoicXQzclZWaxvIKmfnJXVBtGIxN+cigqml5XxfnU1J2dlMbOw8LCGSXv16sXy5csBmDFjBl26dOE73/lO3fy9e/eSkdFwuioqKqKoqKjZbbz66qutju9Yl1SP3swuMbMSMytt6uG+ZvZFM3MzK0oo+160XImZfSEVQdc3s7CQzmkHN6VzWhozCxt72pqItFbtObH11dU4B86JpfoCiClTpnDzzTczZswY7rzzTl5//XXOPvtshg8fzjnnnENJdB4usYc9Y8YMbrjhBsaNG0dhYSEPP/xw3fq6dOlSV3/cuHFcc801nHrqqUyaNInau/guWLCAU089lZEjR3L77bc323P/9NNPufLKKxk6dChnnXUWK1asAOB///d/676RDB8+nMrKSj766CPOP/98hg0bxhlnnMHLL7+c0v3VlGZ79GaWDswCPk+4T/hSM5sfPTQ5sV5XwnM1/5pQNhi4Fjid8BT5581soLvvS10TDpxwTWUPQ0Qa1tQ5sVT/zZWXl/Pqq6+Snp7O9u3befnll8nIyOD555/n+9//Pr///e8PWWbNmjUsWrSIyspKBg0axC233HLINedvvvkmK1eupG/fvowdO5a//OUvFBUVcdNNN/HSSy9RUFDAxIkTm43vnnvuYfjw4cybN48XX3yR66+/nuXLl/PAAw8wa9Ysxo4dy44dO+jYsSOzZ8/mC1/4AtOnT2ffvn1UVVWlbD81J5mhm9FAqbuXAZjZXMLTf1bVq/cj4N+A7yaUTQDmuns18J6ZlUbrW3K4gdc3KTdXiV3kKDia58S+9KUvkZ6eDsC2bduYPHkya9euxcyoqalpcJnLLruMrKwssrKyOPHEE6moqCAvL++gOqNHj64rGzZsGOvWraNLly4UFhbWXZ8+ceJEZs+e3WR8r7zySt2HzYUXXsjmzZvZvn07Y8eO5Y477mDSpElcffXV5OXlMWrUKG644QZqamq48sorGTZs2GHtm5ZIZuimH/BBwnR5VFbHzEYA/d392ZYuGy0/1cyKzax448aNSQUuIm2jsXNfR+KcWHZ2dt3rH/7wh1xwwQW8/fbbPPPMM41eS56VEEd6ejp79+5tVZ3DMW3aNB577DF27drF2LFjWbNmDeeffz4vvfQS/fr1Y8qUKfz6179O6TabcthX3ZhZGvAg4anzreLus929yN2LcnIavJ2yiLQTbXVObNu2bfTrF/qJv/zlL1O+/kGDBlFWVsa6desAePLJJ5td5rzzzmPOnDlAGPvv3bs33bp1491332XIkCHcddddjBo1ijVr1rB+/Xpyc3O58cYb+drXvsYbb7yR8jY0JplE/yHQP2E6Lyqr1RU4A1hsZuuAs4D50QnZ5pYVkWPMpNxcZg8axClZWRhwSlYWswcNOuJDp3feeSff+973GD58eMp74ACdOnXikUce4ZJLLmHkyJF07dqV7t27N7nMjBkzWLZsGUOHDmXatGn86le/AuChhx7ijDPOYOjQoWRmZjJ+/HgWL17MmWeeyfDhw3nyySf5xje+kfI2NKbZZ8aaWQbwDnARIUkvBb7i7isbqb8Y+I67F5vZ6cAThHH5vsALwICmTsYWFRW5HjwicnStXr2a0047ra3DaHM7duygS5cuuDu33norAwYM4Fvf+lZbh3WIho6XmS1z9wavM222R+/ue4HbgIXAauApd19pZvea2RXNLLsSeIpw4vZ/gFtTfcWNiEiq/OxnP2PYsGGcfvrpbNu2jZtuuqmtQ0qJZnv0R5t69CJHn3r0x5aU9+hFROTYpkQvIhJzSvQiIjGnRC8iEnNK9CLS5i644AIWLlx4UNlDDz3ELbfc0ugy48aNo/bCjUsvvZStW7ceUmfGjBk88MADTW573rx5rFp14I4ud999N88//3xLwm9Qe7qdsRK9iLS5iRMnMnfu3IPK5s6dm9SNxSDcdbJHjx6t2nb9RH/vvfdy8cUXt2pd7ZUSvYi0uWuuuYZnn3227iEj69atY8OGDZx33nnccsstFBUVcfrpp3PPPfc0uHx+fj6bNm0CYObMmQwcOJBzzz237lbGEK6RHzVqFGeeeSZf/OIXqaqq4tVXX2X+/Pl897vfZdiwYbz77rtMmTKFp59+GoAXXniB4cOHM2TIEG644Qaqoxu35efnc8899zBixAiGDBnCmjVrmmxfW9/OOBYPHhGR1PnmN79Z9xCQVBk2bBgPPfRQo/N79uzJ6NGjee6555gwYQJz587lH/7hHzAzZs6cSc+ePdm3bx8XXXQRK1asYOjQoQ2uZ9myZcydO5fly5ezd+9eRowYwciRIwG4+uqrufHGGwH4wQ9+wM9//nP+6Z/+iSuuuILLL7+ca6655qB17d69mylTpvDCCy8wcOBArr/+eh599FG++c1vAtC7d2/eeOMNHnnkER544AEee+yxRtvX1rczVo9eRNqFxOGbxGGbp556ihEjRjB8+HBWrlx50DBLfS+//DJXXXUVnTt3plu3blxxxYEf77/99tucd955DBkyhDlz5rByZYN3calTUlJCQUEBAwcOBGDy5Mm89NJLdfOvvvpqAEaOHFl3I7TGvPLKK1x33XVAw7czfvjhh9m6dSsZGRmMGjWKxx9/nBkzZvDWW2/RtWvXJtedDPXoReQgTfW8j6QJEybwrW99izfeeIOqqipGjhzJe++9xwMPPMDSpUs54YQTmDJlSqO3J27OlClTmDdvHmeeeSa//OUvWbx48WHFW3ur48O5zfG0adO47LLLWLBgAWPHjmXhwoV1tzN+9tlnmTJlCnfccQfXX3/9YcWqHr2ItAtdunThggsu4IYbbqjrzW/fvp3s7Gy6d+9ORUUFzz33XJPrOP/885k3bx67du2isrKSZ555pm5eZWUlJ510EjU1NXW3Fgbo2rUrlZWVh6xr0KBBrFu3jtLSUgB+85vf8LnPfa5VbWvr2xmrRy8i7cbEiRO56qqr6oZwam/re+qpp9K/f3/Gjh3b5PIjRozgy1/+MmeeeSYnnngio0aNqpv3ox/9iDFjxpCTk8OYMWPqkvu1117LjTfeyMMPP1x3EhagY8eOPP7443zpS19i7969jBo1iptvvrlV7ap9lu3QoUPp3LnzQbczXrRoEWlpaZx++umMHz+euXPncv/995OZmUmXLl1S8oAS3dRMRHRTs2OMbmomIiIHUaIXEYk5JXoRAaC9DeNKw1pznJToRYSOHTuyefNmJft2zt3ZvHkzHTt2bNFySV11Y2aXAP8BpAOPufu/1pt/M3ArsA/YAUx191Vmlgk8BoyItvVrd/+XFkUoIkdcXl4e5eXlbNy4sa1DkWZ07NiRvLy8Fi3TbKI3s3RgFvB5oBxYambz3T3x52lPuPtPovpXAA8ClwBfArLcfYiZdQZWmdlv3X1di6IUkSMqMzOTgoKCtg5DjpBkhm5GA6XuXubue4C5wITECu6+PWEyG6j9/udAtpllAJ2APUBiXREROcKSSfT9gA8SpsujsoOY2a1m9i5wH3B7VPw0sBP4CHgfeMDdP21g2almVmxmxfrqKCKSWik7Gevus9z9M8BdwA+i4tGEcfu+QAHwbTMrbGDZ2e5e5O5FOTk5qQpJRERILtF/CPRPmM6LyhozF7gyev0V4H/cvcbdPwH+AjT4yy0RETkykkn0S4EBZlZgZh2Aa4H5iRXMbEDC5GXA2uj1+8CFUZ1s4Cyg6Tv0i4hISjV71Y277zWz24CFhMsrf+HuK83sXqDY3ecDt5nZxUANsAWYHC0+C3jczFYCBjzu7iuORENERKRhuqmZiEgM6KZmIiLHMSV6EZGYU6IXEYk5JXoRkZhTohcRiTklehGRmFOiFxGJOSV6EZGYU6IXEYk5JXoRkZhTohcRiTklehGRmFOiFxGJOSV6EZGYU6IXEYk5JXoRkZhLKtGb2SVmVmJmpWY2rYH5N5vZW2a23MxeMbPBCfOGmtkSM1sZ1emYygaIiEjTmk30ZpZOeCTgeGAwMDExkUeecPch7j4MuA94MFo2A/gv4GZ3Px0YR3jcoIiIHCXJ9OhHA6XuXubue4C5wITECu6+PWEyG6h9PuHfASvc/W9Rvc3uvu/wwxYRkWQlk+j7AR8kTJdHZQcxs1vN7F1Cj/72qHgg4Ga20MzeMLM7G9qAmU01s2IzK964cWPLWiAiIk1K2clYd5/l7p8B7gJ+EBVnAOcCk6L/rzKzixpYdra7F7l7UU5OTqpCEhERkkv0HwL9E6bzorLGzAWujF6XAy+5+yZ3rwIWACNaE6iIiLROMol+KTDAzArMrANwLTA/sYKZDUiYvAxYG71eCAwxs87RidnPAasOP2wREUlWRnMV3H2vmd1GSNrpwC/cfaWZ3QsUu/t84DYzu5hwRc0WYHK07BYze5DwYeHAAnd/9gi1RUREGmDu3nyto6ioqMiLi4vbOgwRkWOKmS1z96KG5umXsSIiMadELyISc0r0IiIxp0QvIhJzSvQiIjGnRC8iEnNK9CIiMadELyISc0r0IiIxp0QvIhJzSvQiIjGnRC8iEnNK9CIiMadELyISc0r0IiIxp0QvIhJzSvQiIjGXVKI3s0vMrMTMSs1sWgPzbzazt8xsuZm9YmaD680/2cx2mNl3UhW4iIgkp9lEb2bpwCxgPDAYmFg/kQNPuPsQdx8G3Ac8WG/+g8BzKYhXRERaKJke/Wig1N3L3H0PMBeYkFjB3bcnTGYTHgQOgJldCbwHrDz8cEVEpKWSSfT9gA8SpsujsoOY2a1m9i6hR397VNYFuAv456Y2YGZTzazYzIo3btyYbOwiIpKElJ2MdfdZ7v4ZQmL/QVQ8A/h3d9/RzLKz3b3I3YtycnJSFZKIiAAZSdT5EOifMJ0XlTVmLvBo9HoMcI2Z3Qf0APab2W53/8/WBCsiIi2XTKJfCgwwswJCgr8W+EpiBTMb4O5ro8nLgLUA7n5eQp0ZwA4leRGRo6vZRO/ue83sNmAhkA78wt1Xmtm9QLG7zwduM7OLgRpgCzD5SAYtIiLJM3dvvtZRVFRU5MXFxW0dhojIMcXMlrl7UUPz9MtYEZGYU6IXEYk5JXoRkZhTohcRiTklehGRmFOiFxGJOSV6EZGYU6IXEYk5JXoRkZhTohcRiTklehGRmFOiFxGJOSV6EZGYU6IXEYk5JXoRkZhTohcRibmkEr2ZXWJmJWZWambTGph/s5m9ZWbLzewVMxsclX/ezJZF85aZ2YWpboCIiDSt2URvZunALGA8MBiYWJvIEzzh7kPcfRhwH/BgVL4J+Ht3H0J4vOBvUha5iIgkJZke/Wig1N3L3H0PMBeYkFjB3bcnTGYDHpW/6e4bovKVQCczyzr8sEVEJFnNPhwc6Ad8kDBdDoypX8nMbgXuADoADQ3RfBF4w92rWxGniIi0UspOxrr7LHf/DHAX8IPEeWZ2OvBvwE0NLWtmU82s2MyKN27cmKqQRESE5BL9h0D/hOm8qKwxc4ErayfMLA/4b+B6d3+3oQXcfba7F7l7UU5OThIhiYhIspJJ9EuBAWZWYGYdgGuB+YkVzGxAwuRlwNqovAfwLDDN3f+SmpBFRKQlmk307r4XuA1YCKwGnnL3lWZ2r5ldEVW7zcxWmtlywjj95Npy4LPA3dGll8vN7MTUN0NERBpj7t7WMRykqKjIi4uL2zoMEZFjipktc/eihubpl7EiIjGnRC8iEnNK9CIiMadELyISc0r0IiIxp0QvIhJzSvQiIjEXm0Q/p6KC/CVLSFu8mPwlS5hTUdHWIYmItAvJ3L2y3ZtTUcHUkhKq9u8HYH11NVNLSgCYlJvblqGJiLS5WPTop5eVUbV1K0ydCosWAVC1fz/Ty8raODIRkbYXi0T/fnU1uMPatbBly8HlIiLHuVgk+pOzsiA9PUzs23dwuYjIcS4WiX5mYSGdMqLTDVGi75yWxszCwjaMSkSkfYhFop+Um8us004LE/v2cUpWFrMHDdKJWBERYpLoAa7r1w+AH51yCuvOPltJXkQkEptEnx6N0e/du7eNIxERaV9ik+jNjPT0dCV6EZF6kkr0ZnaJmZWYWamZTWtg/s1m9lb0qMBXzGxwwrzvRcuVmNkXUhl8fRkZGUr0IiL1NJvozSwdmAWMBwYDExMTeeQJdx/i7sOA+4AHo2UHEx4mfjpwCfBItL4jQoleRORQyfToRwOl7l7m7nuAucCExAruvj1hMhuofRDtBGCuu1e7+3tAabS+I0KJXkTkUMnc66Yf8EHCdDkwpn4lM7sVuAPoAFyYsOxr9Zbt18CyU4GpACeffHIycTdIiV5E5FApOxnr7rPc/TPAXcAPWrjsbHcvcveinJycVsegRC8icqhkEv2HQP+E6byorDFzgStbuexhUaIXETlUMol+KTDAzArMrAPh5Or8xApmNiBh8jJgbfR6PnCtmWWZWQEwAHj98MNumBK9iMihmh2jd/e9ZnYbsBBIB37h7ivN7F6g2N3nA7eZ2cVADbAFmBwtu9LMngJWAXuBW919X4MbSgElehGRQyX14BF3XwAsqFd2d8LrbzSx7ExgZmsDbAklehGRQ8Xml7GgRC8i0hAlehGRmFOiFxGJuVglet3UTETkULFL9Pv372/rMERE2pVYJfq0tDT27TtiV2+KiByTYpXo1aMXETlUrBJ9WlqaEr2ISD1K9CIiMadELyISc7FL9DoZKyJysNgk+jkVFbxUWclft20jf8kS5lRUtHVIIiLtQiwS/ZyKCqaWlLDbHfbvZ311NVNLSpTsRUSISaKfXlZG1f79kJYGHh5XW7V/P9PLyto4MhGRtheLRP9+dXV4YQYJY/R15SIix7FYJPqTs7LCi4Qe/UHlIseAORUV5C9ZQtrixTrPJCkVi0Q/s7CQzmlpIdFHl1d2TktjZmFhG0cmkpza80zrq6tx0HkmSamkEr2ZXWJmJWZWambTGph/h5mtMrMVZvaCmZ2SMO8+M1tpZqvN7GEzs1Q2AGBSbi6zBw2ic0YGuHNKVhazBw1iUm5uqjclckTUnWdKoPNMkirNJnozSwdmAeOBwcBEMxtcr9qbQJG7DwWeBu6Llj0HGAsMBc4ARgGfS1n0CSbl5nJFTg4DsrJYd/bZSvJyTGnsfJLOM0kqJNOjHw2UunuZu+8B5gITEiu4+yJ3r4omXwPyamcBHYEOQBaQCRyx76L6Zawcqxo7n6TzTJIKyST6fsAHCdPlUVljvgo8B+DuS4BFwEfRv4Xuvrr+AmY21cyKzax448aNycZ+CN29Uo5VdeeZEug8k6RKSk/Gmtk/AkXA/dH0Z4HTCD38fsCFZnZe/eXcfba7F7l7UU5OTqu3rx69HKtqzzOdkpWFgc4zSUplJFHnQ6B/wnReVHYQM7sYmA58zt1rBxavAl5z9x1RneeAs4GXDyfoxijRy7FsUm6uErscEcn06JcCA8yswMw6ANcC8xMrmNlw4KfAFe7+ScKs94HPmVmGmWUSTsQeMnSTKrqpmYjIoZpN9O6+F7gNWEhI0k+5+0ozu9fMroiq3Q90AX5nZsvNrPaD4GngXeAt4G/A39z9mVQ3opbG6EVEDpXM0A3uvgBYUK/s7oTXFzey3D7gpsMJsCU0dCMicqhY/DK2lhK9iMihYpfoNUYvInKwWCV6jdGLiBwqVoleQzciIodSohcRiblYJfo1u3ZRVVOj+3mLiCRI6vLKY8GcigoWbt2KRw8eqb2fN6BfG4rIcS02PfrpZWXsNat78Ajoft4iIhCjRP9+dfUhjxKsKxcROY7FJtGfnJUVHg6+f7+eGysikiA2iX5mYSGZ6elhIkr0up+3iEiMEv2k3FwmnHhimNBzY0VE6sTmqhuA4d268TSw+9xzyTpKQzZzKiqYXlbG+9XVnJyVxczCQn24iEi7EqtEn52dDcDOnTuPSqKfU1HB1JISqqIrfXRJp4i0R7EZugHo1q0bANu3bz8q25teVlaX5Gvpkk4RaW9ilej/Fp2ELXjhhaPyy9jGLt3UJZ0i0p4klejN7BIzKzGzUjOb1sD8O8xslZmtMLMXzOyUhHknm9mfzGx1VCc/deEfMKeigp9s3Romdu6sG0Y5ksm+sUs3dUmniLQnzSZ6M0sHZgHjgcHARDMbXK/am0CRuw8lPD7wvoR5vwbud/fTgNHAJxwB08vKqO7UKUzs3Akc+WGUmYWFdE47eBfqkk4RaW+S6dGPBkrdvczd9wBzgQmJFdx9kbtXRZOvAXkA0QdChrv/Oaq3I6FeSr1fXQ3RyViqqg4uP0Im5eYye9AgTsnKwkCXdIpIu5TMVTf9gA8SpsuBMU3U/yrwXPR6ILDVzP4AFADPA9OiZ8mm1MlZWazv3DlMRD362vIjaVJurhK7iLRrKT0Za2b/CEUzqVMAAAv5SURBVBQB90dFGcB5wHeAUUAhMKWB5aaaWbGZFW/cuLFV255ZWEinrl3DRNSj1zCKiEhyif5DoH/CdF5UdhAzuxiYDlzh7rXjJeXA8mjYZy8wDxhRf1l3n+3uRe5elJOT09I2AKFnPTk/P9zYbOdO0oHJffqoty0ix71kEv1SYICZFZhZB+BaYH5iBTMbDvyUkOQ/qbdsDzOrzd4XAqsOP+xDzamo4NcVFdC5M+zcyT7gVx9/rIePiMhxr9lEH/XEbwMWAquBp9x9pZnda2ZXRNXuB7oAvzOz5WY2P1p2H2HY5gUzewsw4GdHoB0HfryUnV03dKMfL4mIJHkLBHdfACyoV3Z3wuuLm1j2z8DQ1gaYrLqrazp3PmpX3YiIHAti88vYuqtroqGbQ8pFRI5TsUn0MwsLyQTo0qWuR58ZlYuIHM9ik+gBzOygHn0N8Jdt29o2KBGRNhabRD+9rIw97ocM3fxkwwZdeSMix7XY3I++7qRr165QWRkeJ2iGA/+4ejX/uHp1m8YnIpKsW/r25ZGBA1O2vtj06OtOuvbsCTU1IdkfCdXV4V+y9u4NDyxvTxIenn7Q68NRURHaGjdVVbB7d+rWt29f6vZ5U1atgj17Wr98bYz7Un63kpY5nDYcwx7dsIGvv/NOytYXmx79zMLC0Gvv1SsUfPnLMGYMdOoEq1fD5ZdDx46wZQts3Qq7dkFBQZhfWQnvvw9nnBE+JD7+GHr0CH/ku3bB2rVwyinQoQM8/XR4PXIk/OEPMGECFBbCjh0h2WVnh2U7dAjbe/BBOO208AfToQOcdRZ8+in87W+wZk2I9brr4MMPQ+wnnACzZ8PYsdCnT6i7aBF06wbjx4f6n34KeXnw+OMHdsDFF4d25OdD9+4hOa1ZE9roHtZfUBDK580LSblTp9C+fv3g6qtD7KWlkJsLWVmwbRu8+GJY79lnw8aNkJkZ9kuvXmGd2dlh/UuXwsCBMG4cvPcevPkmDB8e2l5VBSUlMGJE2O4zz8DgwXDiieGXzL17h+3u3h3Kf/KTsMw558Abb4R2v/NOOJ49e8L69bBgQTgOo0YdOK4LF8Lpp4dtvP46fP3rkJ4OGzaExFddDWahDWvWwBe/GI5Jjx7w2muwfXtYV/fuoS3btsF//3fYvzfdFNq8fn341tilS4i3sjJsu0+fEPPmzeG9sG9fqL9qFbz7blhfQQH8+c+h7qWXQkZGiC8rK7QvPT0MPXbrFl7/7W9hPTt2wOjRYZtPPx3eI127wqZN8IUvhPKtW0O9Hj1g/nz44IOwrosugv79w7yqqrDtrKzwurQ0HHv3kFB79w71Fi2Cdevg1FPDfjr11HBcy8tDnbS0ML9797DfPvOZcJy6dg3rHj8+vH7ttbDu/PwQy4oVYX8PHRr+NwvHZuFCGDYs7OfOncPf4tCh4T2zYkVoe0FBODb794dYN20K7699++Dtt8P+KywM+7yiIhynCRPC9j/66MB7tbQ0vIcyMsK+6tMnHMfsbPjkk/A3UXtss7JCjBkZ8Oyzof7AgeHYZGaGWDp0CEPF27eHNuzYEfZ9z54hzu7dw/soMzOU79lzIL6rrjrwftyzJ9Tr2zfkA2D2hg0p69WbH43eRQsUFRV5cXFxq5a1xYvDzrz++tQGFSeZmeHDTBqnfSRHQ1raod/2zzkHfvzj8AEA+LhxSa/OzJa5e1FD82LTowdIB/b17w//8i+h93HZZeGTNisr7NCqqtDT6NQplG/bFl67h/+rqsKnc15e6Kl17Bjqf/xx+MTt0yds6JNPwid1Tc2B9ezdG3odHTqEA/jJJ6EsKyv0goqLw6d1374hkbiH7WVnhx76iSeG3k1NTfjEP+200KsoKYEzzww9nV27QjsqK0PvorIScnLC8j16HOhlVFWFOHbsCL2jnj1DW7p1C+up7Ul1736g3Z9+Gurn5oZ1mIV/PXqEOGqHHEpLwzoGDAj1ysvDMjt2hNh37gzL9esX5tfUhB7Qrl2hTm2vr7w87Kc+fQ4st2lT6BGfe26If9++0Bvu1y8s//rrYb+ccEJY5qSTwjp37w7rqh2+27w5LJ+REcqqqw/0VisrQ7l76P1VVoY4O3UK+6i6OrRvy5bwr3fvsL5OncJ2au/F9Omn4dht2RLaX1ISvmFkZYXj3rVreM/s2hXKdu8O20xLC7HVvt6zJ2y/djn3sL9qasK+j841sXNnKMvMDPultre4c2fYxu7dB97L3bodiG3XrrBcfv6BuD/66MC3tl27QqwbNoS4qqvDOrKzw36u7aHu3h161lVVoezEEw+8/zdtgiFDDrxHNm4M+7W2d5yZGb5x5OQc+IaVlRVeZ2QciDE7O7xXa99nXbqE/f/OO+FY134r/uST8L7ZtOnA35L7gb/zTp0OxFJ7DKurw/Zq933tB/mGDWG/n3TSgW9StXbtCvt+z56wfHZ2eJ2ZeeDvaMeOA73y2uNQUBDWWV4e2typU/hm1K1bKO/VK2wnLS0sW10d2mp20PYTIjlsserRf/2dd3h0w4YURyQicvS19IRsUz362JyMBXhk4EBu6du3rcMQETksqb7qJlZDNxCSfSp3kIjIsS5WPXoRETmUEr2ISMwp0YuIxJwSvYhIzCnRi4jEnBK9iEjMtbsfTJnZRmD9YayiN7ApReEcK9Tm+Dve2gtqc0ud4u45Dc1od4n+cJlZcWO/DosrtTn+jrf2gtqcShq6ERGJOSV6EZGYi2Oin93WAbQBtTn+jrf2gtqcMrEboxcRkYPFsUcvIiIJlOhFRGIuNonezC4xsxIzKzWzaW0dT6qYWX8zW2Rmq8xspZl9IyrvaWZ/NrO10f8nROVmZg9H+2GFmY1o2xa0npmlm9mbZvbHaLrAzP4ate1JM+sQlWdF06XR/Py2jLu1zKyHmT1tZmvMbLWZnR3342xm34re12+b2W/NrGPcjrOZ/cLMPjGztxPKWnxczWxyVH+tmU1uSQyxSPRmlg7MAsYDg4GJZja4baNKmb3At919MHAWcGvUtmnAC+4+AHghmoawDwZE/6YCjx79kFPmG8DqhOl/A/7d3T8LbAG+GpV/FdgSlf97VO9Y9B/A/7j7qcCZhLbH9jibWT/gdqDI3c8gPD3vWuJ3nH8JXFKvrEXH1cx6AvcAY4DRwD21Hw5Jcfdj/h9wNrAwYfp7wPfaOq4j1Nb/B3weKAFOispOAkqi1z8FJibUr6t3LP0D8qI/gAuBPwJG+MVgRv1jDiwEzo5eZ0T1rK3b0ML2dgfeqx93nI8z0A/4AOgZHbc/Al+I43EG8oG3W3tcgYnATxPKD6rX3L9Y9Og58IapVR6VxUr0VXU48Fcg190/imZ9DORGr+OyLx4C7gT2R9O9gK3uvjeaTmxXXZuj+dui+seSAmAj8Hg0XPWYmWUT4+Ps7h8CDwDvAx8Rjtsy4n2ca7X0uB7W8Y5Loo89M+sC/B74prtvT5zn4SM+NtfJmtnlwCfuvqytYzmKMoARwKPuPhzYyYGv80Asj/MJwATCh1xfIJtDhzhi72gc17gk+g+B/gnTeVFZLJhZJiHJz3H3P0TFFWZ2UjT/JOCTqDwO+2IscIWZrQPmEoZv/gPoYWa1zzlObFddm6P53YHNRzPgFCgHyt39r9H004TEH+fjfDHwnrtvdPca4A+EYx/n41yrpcf1sI53XBL9UmBAdLa+A+GEzvw2jiklzMyAnwOr3f3BhFnzgdoz75MJY/e15ddHZ+/PArYlfEU8Jrj799w9z93zCcfyRXefBCwCromq1W9z7b64Jqp/TPV83f1j4AMzGxQVXQSsIsbHmTBkc5aZdY7e57Vtju1xTtDS47oQ+DszOyH6JvR3UVly2vokRQpPdlwKvAO8C0xv63hS2K5zCV/rVgDLo3+XEsYmXwDWAs8DPaP6RrgC6V3gLcIVDW3ejsNo/zjgj9HrQuB1oBT4HZAVlXeMpkuj+YVtHXcr2zoMKI6O9TzghLgfZ+CfgTXA28BvgKy4HWfgt4RzEDWEb25fbc1xBW6I2l4K/J+WxKBbIIiIxFxchm5ERKQRSvQiIjGnRC8iEnNK9CIiMadELyISc0r0IiIxp0QvIhJz/x/+SZE5VztrHgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SAVE model** "
      ],
      "metadata": {
        "id": "okE8lIwPkoSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('./content/drive/My Drive/new', exist_ok=True)\n",
        "model.save('./content/drive/My Drive/new/2Class_regression.h5')"
      ],
      "metadata": {
        "id": "f_Xlg2XSuT9L"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "HuBli3HajIR2"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"./content/drive/My Drive/new/2Class_regression.h5\")"
      ],
      "metadata": {
        "id": "zblzwvRGkSCR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "fa3d051b-713e-4969-a7bf-01dd3ffa415d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3f5c8f54-c3fb-4add-aaac-ccce0563360d\", \"2Class_regression.h5\", 22888208)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}