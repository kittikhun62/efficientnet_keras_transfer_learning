{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMYp+3yUC8CV3ecb+ANgWND",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kittikhun62/efficientnet_keras_transfer_learning/blob/master/UNfreeze2Class_h5_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# import from drive"
      ],
      "metadata": {
        "id": "bB2gfuYWczY-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpXyZ9k5YIJu",
        "outputId": "4f891cbb-3255-4b27-ab8b-f191efac5058"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (r'/content/drive/My Drive/data - 2 class.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "7mqo2OLAc2pG",
        "outputId": "700c2254-6ee0-4c3c-b384-deda2aaba1a4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      No                      Name_file  \\\n",
              "0      1                        pore-sb   \n",
              "1      2                        pore-sb   \n",
              "2      3                        pore-sb   \n",
              "3      4                        pore-sb   \n",
              "4      5                        pore-sb   \n",
              "..   ...                            ...   \n",
              "795  796  1-s2.0-S2095268622000210-main   \n",
              "796  797  1-s2.0-S2095268622000210-main   \n",
              "797  798  1-s2.0-S2095268622000210-main   \n",
              "798  799  1-s2.0-S2095268622000210-main   \n",
              "799  800  1-s2.0-S2095268622000210-main   \n",
              "\n",
              "                                            Name_Paper  \\\n",
              "0    Preparation and electrochemical behaviour of b...   \n",
              "1    Preparation and electrochemical behaviour of b...   \n",
              "2    Preparation and electrochemical behaviour of b...   \n",
              "3    Preparation and electrochemical behaviour of b...   \n",
              "4    Preparation and electrochemical behaviour of b...   \n",
              "..                                                 ...   \n",
              "795  Integration of preparation of K, Na-embedded a...   \n",
              "796  Integration of preparation of K, Na-embedded a...   \n",
              "797  Integration of preparation of K, Na-embedded a...   \n",
              "798  Integration of preparation of K, Na-embedded a...   \n",
              "799  Integration of preparation of K, Na-embedded a...   \n",
              "\n",
              "                                               journal  \\\n",
              "0                                  Korean J. Chem. Eng   \n",
              "1                                  Korean J. Chem. Eng   \n",
              "2                                  Korean J. Chem. Eng   \n",
              "3                                  Korean J. Chem. Eng   \n",
              "4                                  Korean J. Chem. Eng   \n",
              "..                                                 ...   \n",
              "795  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "796  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "797  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "798  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "799  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "\n",
              "                                          path_Picture  detail  Class     BET  \\\n",
              "0    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom1  0-800  135.06   \n",
              "1    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom2  0-800  135.06   \n",
              "2    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom3  0-800  135.06   \n",
              "3    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom4  0-800  135.06   \n",
              "4    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom5  0-800  135.06   \n",
              "..                                                 ...     ...    ...     ...   \n",
              "795  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom21  0-800  301.70   \n",
              "796  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom22  0-800  301.70   \n",
              "797  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom23  0-800  301.70   \n",
              "798  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom24  0-800  301.70   \n",
              "799  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom25  0-800  301.70   \n",
              "\n",
              "     Size(mico)  \n",
              "0            10  \n",
              "1            10  \n",
              "2            10  \n",
              "3            10  \n",
              "4            10  \n",
              "..          ...  \n",
              "795          10  \n",
              "796          10  \n",
              "797          10  \n",
              "798          10  \n",
              "799          10  \n",
              "\n",
              "[800 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a072db08-9dd7-401f-898d-d3e7b5173b34\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>No</th>\n",
              "      <th>Name_file</th>\n",
              "      <th>Name_Paper</th>\n",
              "      <th>journal</th>\n",
              "      <th>path_Picture</th>\n",
              "      <th>detail</th>\n",
              "      <th>Class</th>\n",
              "      <th>BET</th>\n",
              "      <th>Size(mico)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom1</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom2</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom3</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom4</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom5</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>795</th>\n",
              "      <td>796</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom21</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>796</th>\n",
              "      <td>797</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom22</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>797</th>\n",
              "      <td>798</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom23</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>798</th>\n",
              "      <td>799</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom24</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799</th>\n",
              "      <td>800</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom25</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>800 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a072db08-9dd7-401f-898d-d3e7b5173b34')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a072db08-9dd7-401f-898d-d3e7b5173b34 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a072db08-9dd7-401f-898d-d3e7b5173b34');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports library"
      ],
      "metadata": {
        "id": "VkYa-4LeTbir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "myAsBcVhTW7j"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## hyper parameter\n"
      ],
      "metadata": {
        "id": "T529UM_tVV-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "width = 150\n",
        "height = 150\n",
        "\n",
        "epochs = 1000 #จำนวนรอบในการ Train\n",
        "\n",
        "NUM_TRAIN = 598  # จำนวนภาพ Train\n",
        "NUM_TEST = 101 #จำนวนภาพ Test\n",
        "\n",
        "dropout_rate = 0.3\n",
        "input_shape = (height, width, 3) #ขนาด image enter"
      ],
      "metadata": {
        "id": "zXpmkJ2GVZ1l"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone efficientnet repo"
      ],
      "metadata": {
        "id": "DSSZIFGhUyQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/"
      ],
      "metadata": {
        "id": "nFvKcuBDTj1N",
        "outputId": "213e1e55-3ab6-4b24-d700-2d41a52a9840",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 837, done.\u001b[K\n",
            "remote: Counting objects: 100% (359/359), done.\u001b[K\n",
            "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
            "remote: Total 837 (delta 255), reused 328 (delta 235), pack-reused 478\u001b[K\n",
            "Receiving objects: 100% (837/837), 13.82 MiB | 6.90 MiB/s, done.\n",
            "Resolving deltas: 100% (495/495), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import efficientnet and load the conv base model"
      ],
      "metadata": {
        "id": "j3EgSOiSZHaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "iI3DQ18HU2TF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "#EfficientNet สร้างขึ้นสำหรับการจำแนกประเภท ImageNet ประกอบด้วยป้ายกำกับคลาส 1,000 รายการ เรามีเพียง 2 เลเยอร์เท่านั้น ซึ่งหมายความว่าเลเยอร์สองสามเลเยอร์สุดท้ายสำหรับการจำแนกไม่มีประโยชน์สำหรับเรา สามารถยกเว้นได้ขณะโหลดโมเดลโดยระบุอาร์กิวเมนต์ include_top เป็น False และนำไปใช้กับโมเดล ImageNet อื่นๆ ที่มีอยู่ในแอปพลิเคชัน Keras เช่นกัน\n",
        "\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "UmBDAgF_VAjq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c29211a-1890-4514-9351-e2c3bd7127eb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "id": "rRXoFFzfU2Oi",
        "outputId": "a1dc87e0-cd8f-44f0-e32d-6e9edb8ec05d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 4,007,548\n",
            "Non-trainable params: 42,016\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/new/2Class_3000.h5')\n",
        "\n",
        "from efficientnet.layers import Swish, DropConnect\n",
        "from efficientnet.model import ConvKernalInitializer\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "\n",
        "get_custom_objects().update({\n",
        "    'ConvKernalInitializer': ConvKernalInitializer,\n",
        "    'Swish': Swish,\n",
        "    'DropConnect':DropConnect\n",
        "})"
      ],
      "metadata": {
        "id": "MwNk3sNbc2Qx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load model \n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/drive/My Drive/new/2Class_3000.h5')\n",
        "height = width = model.input_shape[1]"
      ],
      "metadata": {
        "id": "4v4nzKQtJZ4z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/My Drive/new project'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Directories for our training,\n",
        "# validation and test splits\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.makedirs(test_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "UDxvF-b8Jcq1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, # image input 0-255 --> 0-1 เปลี่ยนค่าสี\n",
        "      rotation_range=40,# หมุนภาพในองศา\n",
        "      width_shift_range=0.2, #เปลี่ยนความกว้าง\n",
        "      height_shift_range=0.2, #ปลี่ยนความสูง\n",
        "      shear_range=0.2, #ทำให้ภาพเบี้ยว\n",
        "      zoom_range=0.2, # Randomly zoom image\n",
        "      horizontal_flip=True, \n",
        "      #โดย Default เมื่อมีการเลื่อนภาพ บิดภาพ หมุนภาพ จะเกิดพื้นที่ว่างที่มุม \n",
        "      #ซึ่งจะมีการเติมภาพให้เต็มโดยใช้เทคนิคแบบ Nearest neighbor ซึ่งเป็นการดึงสีบริเวณใหล้าเคียงมาระบายให้เต็ม แต่เราก็ยังสามารถกำหนดวิธีการ Fill ภาพด้วยเทคนิคอื่นได้จาก Parameter fill_mode\n",
        "      fill_mode='nearest')\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory #ไดเรกเป้าหมาย\n",
        "        train_dir,\n",
        "        # รูปภาพทั้งหมดจะถูกปรับขนาดตามความสูงและความกว้างของเป้าหมาย\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        #เนื่องจากเราใช้ categorical_crossentropy loss เราจึงต้องมีป้ายกำกับตามหมวดหมู่\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory( #การดึงภาพจาก Directory มาเข้าโมเดล \n",
        "        validation_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "     \n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znE38DtIJeN-",
        "outputId": "7bd37270-ee55-4448-8467-b84e2ed641ca"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 598 images belonging to 2 classes.\n",
            "Found 101 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multiply_16\n",
        "# set 'multiply_16' and following layers trainable\n",
        "model.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'multiply_16':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False  \n",
        "     "
      ],
      "metadata": {
        "id": "tEaPoHJCJq13"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "xkN8n36elECN",
        "outputId": "f61c4411-5db8-4e81-e0ed-58826627dec8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 2)                 2562      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,052,126\n",
            "Trainable params: 4,010,110\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7ERVUfUJsQq",
        "outputId": "61d071d2-4dc3-4b5a-da43-5c89d1fbf3ff"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-caa7b37242a8>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "37/37 [==============================] - 63s 1s/step - loss: 0.5202 - acc: 0.7354 - val_loss: 0.6662 - val_acc: 0.6667\n",
            "Epoch 2/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5089 - acc: 0.7432 - val_loss: 0.6693 - val_acc: 0.6562\n",
            "Epoch 3/1000\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.5192 - acc: 0.7474 - val_loss: 0.6478 - val_acc: 0.6771\n",
            "Epoch 4/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.4905 - acc: 0.7618 - val_loss: 0.6625 - val_acc: 0.6458\n",
            "Epoch 5/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5142 - acc: 0.7612 - val_loss: 0.6550 - val_acc: 0.6562\n",
            "Epoch 6/1000\n",
            "37/37 [==============================] - 6s 143ms/step - loss: 0.5085 - acc: 0.7526 - val_loss: 0.6637 - val_acc: 0.6562\n",
            "Epoch 7/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.5398 - acc: 0.7251 - val_loss: 0.6564 - val_acc: 0.6562\n",
            "Epoch 8/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.5224 - acc: 0.7251 - val_loss: 0.6630 - val_acc: 0.6562\n",
            "Epoch 9/1000\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 0.5008 - acc: 0.7629 - val_loss: 0.6778 - val_acc: 0.6458\n",
            "Epoch 10/1000\n",
            "37/37 [==============================] - 4s 80ms/step - loss: 0.5152 - acc: 0.7595 - val_loss: 0.6502 - val_acc: 0.6667\n",
            "Epoch 11/1000\n",
            "37/37 [==============================] - 9s 242ms/step - loss: 0.5173 - acc: 0.7560 - val_loss: 0.6769 - val_acc: 0.6354\n",
            "Epoch 12/1000\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 0.5017 - acc: 0.7663 - val_loss: 0.6557 - val_acc: 0.6667\n",
            "Epoch 13/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5042 - acc: 0.7612 - val_loss: 0.6590 - val_acc: 0.6562\n",
            "Epoch 14/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5136 - acc: 0.7423 - val_loss: 0.6575 - val_acc: 0.6562\n",
            "Epoch 15/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.4930 - acc: 0.7560 - val_loss: 0.6802 - val_acc: 0.6354\n",
            "Epoch 16/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.4894 - acc: 0.7440 - val_loss: 0.6559 - val_acc: 0.6667\n",
            "Epoch 17/1000\n",
            "37/37 [==============================] - 4s 82ms/step - loss: 0.5104 - acc: 0.7491 - val_loss: 0.6738 - val_acc: 0.6458\n",
            "Epoch 18/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.4911 - acc: 0.7595 - val_loss: 0.6547 - val_acc: 0.6562\n",
            "Epoch 19/1000\n",
            "37/37 [==============================] - 10s 253ms/step - loss: 0.5577 - acc: 0.7440 - val_loss: 0.6557 - val_acc: 0.6562\n",
            "Epoch 20/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5087 - acc: 0.7629 - val_loss: 0.6703 - val_acc: 0.6458\n",
            "Epoch 21/1000\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 0.5237 - acc: 0.7320 - val_loss: 0.6651 - val_acc: 0.6562\n",
            "Epoch 22/1000\n",
            "37/37 [==============================] - 5s 107ms/step - loss: 0.4716 - acc: 0.7749 - val_loss: 0.6554 - val_acc: 0.6667\n",
            "Epoch 23/1000\n",
            "37/37 [==============================] - 9s 239ms/step - loss: 0.4815 - acc: 0.7612 - val_loss: 0.6649 - val_acc: 0.6562\n",
            "Epoch 24/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5206 - acc: 0.7354 - val_loss: 0.6600 - val_acc: 0.6562\n",
            "Epoch 25/1000\n",
            "37/37 [==============================] - 5s 116ms/step - loss: 0.5085 - acc: 0.7612 - val_loss: 0.6759 - val_acc: 0.6562\n",
            "Epoch 26/1000\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 0.4890 - acc: 0.7560 - val_loss: 0.6522 - val_acc: 0.6667\n",
            "Epoch 27/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5088 - acc: 0.7612 - val_loss: 0.6708 - val_acc: 0.6562\n",
            "Epoch 28/1000\n",
            "37/37 [==============================] - 6s 149ms/step - loss: 0.4957 - acc: 0.7440 - val_loss: 0.6948 - val_acc: 0.6354\n",
            "Epoch 29/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.5320 - acc: 0.7320 - val_loss: 0.6819 - val_acc: 0.6562\n",
            "Epoch 30/1000\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 0.4818 - acc: 0.7835 - val_loss: 0.6736 - val_acc: 0.6458\n",
            "Epoch 31/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5514 - acc: 0.7251 - val_loss: 0.6542 - val_acc: 0.6354\n",
            "Epoch 32/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5174 - acc: 0.7509 - val_loss: 0.6561 - val_acc: 0.6562\n",
            "Epoch 33/1000\n",
            "37/37 [==============================] - 5s 114ms/step - loss: 0.5255 - acc: 0.7320 - val_loss: 0.6515 - val_acc: 0.6667\n",
            "Epoch 34/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.4905 - acc: 0.7354 - val_loss: 0.6532 - val_acc: 0.6667\n",
            "Epoch 35/1000\n",
            "37/37 [==============================] - 5s 113ms/step - loss: 0.5249 - acc: 0.7526 - val_loss: 0.6571 - val_acc: 0.6667\n",
            "Epoch 36/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.5217 - acc: 0.7354 - val_loss: 0.6812 - val_acc: 0.6354\n",
            "Epoch 37/1000\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 0.5170 - acc: 0.7285 - val_loss: 0.6642 - val_acc: 0.6458\n",
            "Epoch 38/1000\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 0.5357 - acc: 0.7148 - val_loss: 0.6623 - val_acc: 0.6562\n",
            "Epoch 39/1000\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.5270 - acc: 0.7526 - val_loss: 0.6658 - val_acc: 0.6562\n",
            "Epoch 40/1000\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 0.5557 - acc: 0.7337 - val_loss: 0.6603 - val_acc: 0.6562\n",
            "Epoch 41/1000\n",
            "37/37 [==============================] - 5s 112ms/step - loss: 0.5181 - acc: 0.7474 - val_loss: 0.6595 - val_acc: 0.6562\n",
            "Epoch 42/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5398 - acc: 0.7199 - val_loss: 0.6481 - val_acc: 0.6458\n",
            "Epoch 43/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.5090 - acc: 0.7268 - val_loss: 0.6667 - val_acc: 0.6458\n",
            "Epoch 44/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.4672 - acc: 0.7801 - val_loss: 0.6600 - val_acc: 0.6354\n",
            "Epoch 45/1000\n",
            "37/37 [==============================] - 5s 115ms/step - loss: 0.4885 - acc: 0.7629 - val_loss: 0.6558 - val_acc: 0.6562\n",
            "Epoch 46/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5011 - acc: 0.7629 - val_loss: 0.6511 - val_acc: 0.6562\n",
            "Epoch 47/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.5251 - acc: 0.7509 - val_loss: 0.6756 - val_acc: 0.6458\n",
            "Epoch 48/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.4995 - acc: 0.7526 - val_loss: 0.6469 - val_acc: 0.6667\n",
            "Epoch 49/1000\n",
            "37/37 [==============================] - 5s 109ms/step - loss: 0.5000 - acc: 0.7560 - val_loss: 0.6670 - val_acc: 0.6458\n",
            "Epoch 50/1000\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 0.5183 - acc: 0.7405 - val_loss: 0.6608 - val_acc: 0.6667\n",
            "Epoch 51/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.4927 - acc: 0.7577 - val_loss: 0.6623 - val_acc: 0.6562\n",
            "Epoch 52/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5007 - acc: 0.7457 - val_loss: 0.6604 - val_acc: 0.6458\n",
            "Epoch 53/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.5422 - acc: 0.7268 - val_loss: 0.6604 - val_acc: 0.6562\n",
            "Epoch 54/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.5209 - acc: 0.7388 - val_loss: 0.6612 - val_acc: 0.6562\n",
            "Epoch 55/1000\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 0.5099 - acc: 0.7405 - val_loss: 0.6533 - val_acc: 0.6667\n",
            "Epoch 56/1000\n",
            "37/37 [==============================] - 8s 220ms/step - loss: 0.5254 - acc: 0.7320 - val_loss: 0.6594 - val_acc: 0.6667\n",
            "Epoch 57/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5107 - acc: 0.7440 - val_loss: 0.6638 - val_acc: 0.6771\n",
            "Epoch 58/1000\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 0.4937 - acc: 0.7698 - val_loss: 0.6463 - val_acc: 0.6771\n",
            "Epoch 59/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.4812 - acc: 0.7629 - val_loss: 0.6720 - val_acc: 0.6562\n",
            "Epoch 60/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5142 - acc: 0.7371 - val_loss: 0.6664 - val_acc: 0.6562\n",
            "Epoch 61/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.5307 - acc: 0.7148 - val_loss: 0.6691 - val_acc: 0.6354\n",
            "Epoch 62/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5216 - acc: 0.7491 - val_loss: 0.6590 - val_acc: 0.6562\n",
            "Epoch 63/1000\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 0.5282 - acc: 0.7405 - val_loss: 0.6703 - val_acc: 0.6458\n",
            "Epoch 64/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5124 - acc: 0.7526 - val_loss: 0.6372 - val_acc: 0.6771\n",
            "Epoch 65/1000\n",
            "37/37 [==============================] - 9s 214ms/step - loss: 0.5147 - acc: 0.7320 - val_loss: 0.6679 - val_acc: 0.6667\n",
            "Epoch 66/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5338 - acc: 0.7113 - val_loss: 0.6699 - val_acc: 0.6458\n",
            "Epoch 67/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.5043 - acc: 0.7560 - val_loss: 0.6675 - val_acc: 0.6354\n",
            "Epoch 68/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5281 - acc: 0.7423 - val_loss: 0.6677 - val_acc: 0.6458\n",
            "Epoch 69/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5159 - acc: 0.7337 - val_loss: 0.6728 - val_acc: 0.6562\n",
            "Epoch 70/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5574 - acc: 0.7010 - val_loss: 0.6631 - val_acc: 0.6562\n",
            "Epoch 71/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.4935 - acc: 0.7601 - val_loss: 0.6393 - val_acc: 0.6771\n",
            "Epoch 72/1000\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 0.5054 - acc: 0.7517 - val_loss: 0.6812 - val_acc: 0.6354\n",
            "Epoch 73/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5395 - acc: 0.7199 - val_loss: 0.6669 - val_acc: 0.6458\n",
            "Epoch 74/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5529 - acc: 0.7302 - val_loss: 0.6792 - val_acc: 0.6354\n",
            "Epoch 75/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.4774 - acc: 0.7646 - val_loss: 0.6630 - val_acc: 0.6667\n",
            "Epoch 76/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.4891 - acc: 0.7371 - val_loss: 0.6656 - val_acc: 0.6458\n",
            "Epoch 77/1000\n",
            "37/37 [==============================] - 5s 104ms/step - loss: 0.5006 - acc: 0.7388 - val_loss: 0.6451 - val_acc: 0.6667\n",
            "Epoch 78/1000\n",
            "37/37 [==============================] - 9s 239ms/step - loss: 0.4716 - acc: 0.7698 - val_loss: 0.6597 - val_acc: 0.6667\n",
            "Epoch 79/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5445 - acc: 0.7268 - val_loss: 0.6611 - val_acc: 0.6667\n",
            "Epoch 80/1000\n",
            "37/37 [==============================] - 5s 109ms/step - loss: 0.5110 - acc: 0.7526 - val_loss: 0.6528 - val_acc: 0.6667\n",
            "Epoch 81/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.4998 - acc: 0.7612 - val_loss: 0.6632 - val_acc: 0.6562\n",
            "Epoch 82/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.4645 - acc: 0.7835 - val_loss: 0.6704 - val_acc: 0.6458\n",
            "Epoch 83/1000\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.4938 - acc: 0.7354 - val_loss: 0.6469 - val_acc: 0.6667\n",
            "Epoch 84/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.4871 - acc: 0.7595 - val_loss: 0.6614 - val_acc: 0.6458\n",
            "Epoch 85/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.4979 - acc: 0.7595 - val_loss: 0.6645 - val_acc: 0.6562\n",
            "Epoch 86/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5078 - acc: 0.7560 - val_loss: 0.6473 - val_acc: 0.6562\n",
            "Epoch 87/1000\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 0.5325 - acc: 0.7500 - val_loss: 0.6488 - val_acc: 0.6667\n",
            "Epoch 88/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5168 - acc: 0.7526 - val_loss: 0.6807 - val_acc: 0.6354\n",
            "Epoch 89/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.4629 - acc: 0.7869 - val_loss: 0.6470 - val_acc: 0.6667\n",
            "Epoch 90/1000\n",
            "37/37 [==============================] - 10s 250ms/step - loss: 0.5350 - acc: 0.7216 - val_loss: 0.6638 - val_acc: 0.6458\n",
            "Epoch 91/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5045 - acc: 0.7595 - val_loss: 0.6607 - val_acc: 0.6562\n",
            "Epoch 92/1000\n",
            "37/37 [==============================] - 10s 246ms/step - loss: 0.4919 - acc: 0.7663 - val_loss: 0.6511 - val_acc: 0.6667\n",
            "Epoch 93/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5106 - acc: 0.7663 - val_loss: 0.6631 - val_acc: 0.6562\n",
            "Epoch 94/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5030 - acc: 0.7423 - val_loss: 0.6450 - val_acc: 0.6771\n",
            "Epoch 95/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5040 - acc: 0.7629 - val_loss: 0.6620 - val_acc: 0.6667\n",
            "Epoch 96/1000\n",
            "37/37 [==============================] - 5s 117ms/step - loss: 0.5250 - acc: 0.7371 - val_loss: 0.6565 - val_acc: 0.6562\n",
            "Epoch 97/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.4927 - acc: 0.7577 - val_loss: 0.6792 - val_acc: 0.6458\n",
            "Epoch 98/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 0.5080 - acc: 0.7371 - val_loss: 0.6646 - val_acc: 0.6458\n",
            "Epoch 99/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5259 - acc: 0.7423 - val_loss: 0.6642 - val_acc: 0.6458\n",
            "Epoch 100/1000\n",
            "37/37 [==============================] - 10s 244ms/step - loss: 0.5197 - acc: 0.7457 - val_loss: 0.6519 - val_acc: 0.6667\n",
            "Epoch 101/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5247 - acc: 0.7354 - val_loss: 0.6560 - val_acc: 0.6562\n",
            "Epoch 102/1000\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.4953 - acc: 0.7509 - val_loss: 0.6787 - val_acc: 0.6458\n",
            "Epoch 103/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.4798 - acc: 0.7560 - val_loss: 0.6729 - val_acc: 0.6458\n",
            "Epoch 104/1000\n",
            "37/37 [==============================] - 7s 161ms/step - loss: 0.5048 - acc: 0.7509 - val_loss: 0.6522 - val_acc: 0.6562\n",
            "Epoch 105/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.4902 - acc: 0.7474 - val_loss: 0.6630 - val_acc: 0.6354\n",
            "Epoch 106/1000\n",
            "37/37 [==============================] - 9s 243ms/step - loss: 0.5324 - acc: 0.7423 - val_loss: 0.6622 - val_acc: 0.6354\n",
            "Epoch 107/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5045 - acc: 0.7698 - val_loss: 0.6468 - val_acc: 0.6667\n",
            "Epoch 108/1000\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.5172 - acc: 0.7348 - val_loss: 0.6712 - val_acc: 0.6562\n",
            "Epoch 109/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.5242 - acc: 0.7337 - val_loss: 0.6515 - val_acc: 0.6667\n",
            "Epoch 110/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5152 - acc: 0.7457 - val_loss: 0.6640 - val_acc: 0.6667\n",
            "Epoch 111/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5306 - acc: 0.7371 - val_loss: 0.6467 - val_acc: 0.6667\n",
            "Epoch 112/1000\n",
            "37/37 [==============================] - 5s 114ms/step - loss: 0.5076 - acc: 0.7440 - val_loss: 0.6682 - val_acc: 0.6458\n",
            "Epoch 113/1000\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 0.5150 - acc: 0.7474 - val_loss: 0.6737 - val_acc: 0.6562\n",
            "Epoch 114/1000\n",
            "37/37 [==============================] - 6s 143ms/step - loss: 0.5133 - acc: 0.7526 - val_loss: 0.6918 - val_acc: 0.6354\n",
            "Epoch 115/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5147 - acc: 0.7612 - val_loss: 0.6722 - val_acc: 0.6458\n",
            "Epoch 116/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.4965 - acc: 0.7560 - val_loss: 0.6644 - val_acc: 0.6562\n",
            "Epoch 117/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5060 - acc: 0.7560 - val_loss: 0.6852 - val_acc: 0.6354\n",
            "Epoch 118/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.4927 - acc: 0.7491 - val_loss: 0.6586 - val_acc: 0.6562\n",
            "Epoch 119/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.5231 - acc: 0.7423 - val_loss: 0.6626 - val_acc: 0.6667\n",
            "Epoch 120/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.4716 - acc: 0.7646 - val_loss: 0.6509 - val_acc: 0.6458\n",
            "Epoch 121/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.5024 - acc: 0.7354 - val_loss: 0.6725 - val_acc: 0.6458\n",
            "Epoch 122/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.5156 - acc: 0.7595 - val_loss: 0.6540 - val_acc: 0.6458\n",
            "Epoch 123/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5546 - acc: 0.7320 - val_loss: 0.6629 - val_acc: 0.6562\n",
            "Epoch 124/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.5226 - acc: 0.7509 - val_loss: 0.6455 - val_acc: 0.6667\n",
            "Epoch 125/1000\n",
            "37/37 [==============================] - 10s 254ms/step - loss: 0.4880 - acc: 0.7646 - val_loss: 0.6587 - val_acc: 0.6771\n",
            "Epoch 126/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5254 - acc: 0.7354 - val_loss: 0.6551 - val_acc: 0.6667\n",
            "Epoch 127/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.4770 - acc: 0.7595 - val_loss: 0.6425 - val_acc: 0.6667\n",
            "Epoch 128/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5109 - acc: 0.7423 - val_loss: 0.6710 - val_acc: 0.6458\n",
            "Epoch 129/1000\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.4961 - acc: 0.7629 - val_loss: 0.6795 - val_acc: 0.6562\n",
            "Epoch 130/1000\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 0.4925 - acc: 0.7612 - val_loss: 0.6918 - val_acc: 0.6458\n",
            "Epoch 131/1000\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.5201 - acc: 0.7199 - val_loss: 0.6932 - val_acc: 0.6458\n",
            "Epoch 132/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5009 - acc: 0.7509 - val_loss: 0.6889 - val_acc: 0.6562\n",
            "Epoch 133/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5404 - acc: 0.7440 - val_loss: 0.6679 - val_acc: 0.6667\n",
            "Epoch 134/1000\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.5467 - acc: 0.7251 - val_loss: 0.6821 - val_acc: 0.6667\n",
            "Epoch 135/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5258 - acc: 0.7629 - val_loss: 0.6940 - val_acc: 0.6458\n",
            "Epoch 136/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.5130 - acc: 0.7457 - val_loss: 0.6716 - val_acc: 0.6667\n",
            "Epoch 137/1000\n",
            "37/37 [==============================] - 5s 116ms/step - loss: 0.5169 - acc: 0.7595 - val_loss: 0.6892 - val_acc: 0.6562\n",
            "Epoch 138/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5188 - acc: 0.7405 - val_loss: 0.6800 - val_acc: 0.6458\n",
            "Epoch 139/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5163 - acc: 0.7354 - val_loss: 0.6828 - val_acc: 0.6458\n",
            "Epoch 140/1000\n",
            "37/37 [==============================] - 10s 247ms/step - loss: 0.4921 - acc: 0.7560 - val_loss: 0.6461 - val_acc: 0.6667\n",
            "Epoch 141/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.5172 - acc: 0.7302 - val_loss: 0.6774 - val_acc: 0.6458\n",
            "Epoch 142/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.5021 - acc: 0.7663 - val_loss: 0.6589 - val_acc: 0.6875\n",
            "Epoch 143/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.4969 - acc: 0.7577 - val_loss: 0.6870 - val_acc: 0.6354\n",
            "Epoch 144/1000\n",
            "37/37 [==============================] - 5s 106ms/step - loss: 0.5021 - acc: 0.7457 - val_loss: 0.6567 - val_acc: 0.6667\n",
            "Epoch 145/1000\n",
            "37/37 [==============================] - 5s 105ms/step - loss: 0.5354 - acc: 0.7405 - val_loss: 0.6719 - val_acc: 0.6667\n",
            "Epoch 146/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5171 - acc: 0.7251 - val_loss: 0.6735 - val_acc: 0.6458\n",
            "Epoch 147/1000\n",
            "37/37 [==============================] - 5s 106ms/step - loss: 0.4993 - acc: 0.7509 - val_loss: 0.6695 - val_acc: 0.6875\n",
            "Epoch 148/1000\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.4851 - acc: 0.7526 - val_loss: 0.6909 - val_acc: 0.6562\n",
            "Epoch 149/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5060 - acc: 0.7199 - val_loss: 0.6808 - val_acc: 0.6562\n",
            "Epoch 150/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.4858 - acc: 0.7766 - val_loss: 0.6702 - val_acc: 0.6562\n",
            "Epoch 151/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5496 - acc: 0.7371 - val_loss: 0.6692 - val_acc: 0.6771\n",
            "Epoch 152/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5241 - acc: 0.7474 - val_loss: 0.6833 - val_acc: 0.6667\n",
            "Epoch 153/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.5138 - acc: 0.7371 - val_loss: 0.6851 - val_acc: 0.6562\n",
            "Epoch 154/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.5457 - acc: 0.7354 - val_loss: 0.6839 - val_acc: 0.6562\n",
            "Epoch 155/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.5324 - acc: 0.7509 - val_loss: 0.6755 - val_acc: 0.6562\n",
            "Epoch 156/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.4788 - acc: 0.7629 - val_loss: 0.6897 - val_acc: 0.6354\n",
            "Epoch 157/1000\n",
            "37/37 [==============================] - 5s 106ms/step - loss: 0.4974 - acc: 0.7388 - val_loss: 0.6963 - val_acc: 0.6458\n",
            "Epoch 158/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.5013 - acc: 0.7491 - val_loss: 0.6894 - val_acc: 0.6354\n",
            "Epoch 159/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5069 - acc: 0.7646 - val_loss: 0.6760 - val_acc: 0.6458\n",
            "Epoch 160/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5292 - acc: 0.7234 - val_loss: 0.6823 - val_acc: 0.6667\n",
            "Epoch 161/1000\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.5233 - acc: 0.7491 - val_loss: 0.6595 - val_acc: 0.6667\n",
            "Epoch 162/1000\n",
            "37/37 [==============================] - 10s 253ms/step - loss: 0.4709 - acc: 0.7646 - val_loss: 0.6538 - val_acc: 0.6771\n",
            "Epoch 163/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.5245 - acc: 0.7162 - val_loss: 0.6618 - val_acc: 0.6667\n",
            "Epoch 164/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.5181 - acc: 0.7388 - val_loss: 0.6856 - val_acc: 0.6354\n",
            "Epoch 165/1000\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.5055 - acc: 0.7405 - val_loss: 0.6711 - val_acc: 0.6562\n",
            "Epoch 166/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.4753 - acc: 0.7646 - val_loss: 0.6662 - val_acc: 0.6771\n",
            "Epoch 167/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.4868 - acc: 0.7526 - val_loss: 0.6770 - val_acc: 0.6458\n",
            "Epoch 168/1000\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 0.5005 - acc: 0.7629 - val_loss: 0.6844 - val_acc: 0.6458\n",
            "Epoch 169/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.5146 - acc: 0.7595 - val_loss: 0.6799 - val_acc: 0.6667\n",
            "Epoch 170/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.4973 - acc: 0.7629 - val_loss: 0.6667 - val_acc: 0.6667\n",
            "Epoch 171/1000\n",
            "37/37 [==============================] - 6s 140ms/step - loss: 0.5092 - acc: 0.7474 - val_loss: 0.6596 - val_acc: 0.6562\n",
            "Epoch 172/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5048 - acc: 0.7474 - val_loss: 0.6645 - val_acc: 0.6667\n",
            "Epoch 173/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5207 - acc: 0.7457 - val_loss: 0.6772 - val_acc: 0.6562\n",
            "Epoch 174/1000\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.5233 - acc: 0.7517 - val_loss: 0.6685 - val_acc: 0.6667\n",
            "Epoch 175/1000\n",
            "37/37 [==============================] - 5s 111ms/step - loss: 0.5134 - acc: 0.7491 - val_loss: 0.6690 - val_acc: 0.6562\n",
            "Epoch 176/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.5112 - acc: 0.7320 - val_loss: 0.6834 - val_acc: 0.6458\n",
            "Epoch 177/1000\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.5163 - acc: 0.7423 - val_loss: 0.6668 - val_acc: 0.6458\n",
            "Epoch 178/1000\n",
            "37/37 [==============================] - 5s 108ms/step - loss: 0.5187 - acc: 0.7577 - val_loss: 0.6663 - val_acc: 0.6667\n",
            "Epoch 179/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.4789 - acc: 0.7646 - val_loss: 0.6626 - val_acc: 0.6667\n",
            "Epoch 180/1000\n",
            "37/37 [==============================] - 10s 242ms/step - loss: 0.5328 - acc: 0.7388 - val_loss: 0.6486 - val_acc: 0.6667\n",
            "Epoch 181/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.4858 - acc: 0.7595 - val_loss: 0.6602 - val_acc: 0.6667\n",
            "Epoch 182/1000\n",
            "37/37 [==============================] - 10s 242ms/step - loss: 0.5145 - acc: 0.7526 - val_loss: 0.6671 - val_acc: 0.6458\n",
            "Epoch 183/1000\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.4963 - acc: 0.7371 - val_loss: 0.6580 - val_acc: 0.6458\n",
            "Epoch 184/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 0.5258 - acc: 0.7423 - val_loss: 0.6605 - val_acc: 0.6458\n",
            "Epoch 185/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5304 - acc: 0.7251 - val_loss: 0.6479 - val_acc: 0.6562\n",
            "Epoch 186/1000\n",
            "37/37 [==============================] - 5s 115ms/step - loss: 0.4950 - acc: 0.7474 - val_loss: 0.6483 - val_acc: 0.6667\n",
            "Epoch 187/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5148 - acc: 0.7423 - val_loss: 0.6498 - val_acc: 0.6667\n",
            "Epoch 188/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5298 - acc: 0.7474 - val_loss: 0.6640 - val_acc: 0.6458\n",
            "Epoch 189/1000\n",
            "37/37 [==============================] - 5s 110ms/step - loss: 0.4915 - acc: 0.7698 - val_loss: 0.6587 - val_acc: 0.6667\n",
            "Epoch 190/1000\n",
            "37/37 [==============================] - 5s 103ms/step - loss: 0.5285 - acc: 0.7234 - val_loss: 0.6748 - val_acc: 0.6562\n",
            "Epoch 191/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5025 - acc: 0.7629 - val_loss: 0.6569 - val_acc: 0.6562\n",
            "Epoch 192/1000\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.5030 - acc: 0.7491 - val_loss: 0.6725 - val_acc: 0.6562\n",
            "Epoch 193/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5023 - acc: 0.7491 - val_loss: 0.6463 - val_acc: 0.6667\n",
            "Epoch 194/1000\n",
            "37/37 [==============================] - 5s 109ms/step - loss: 0.5203 - acc: 0.7354 - val_loss: 0.6526 - val_acc: 0.6875\n",
            "Epoch 195/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5270 - acc: 0.7337 - val_loss: 0.6683 - val_acc: 0.6667\n",
            "Epoch 196/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5355 - acc: 0.7388 - val_loss: 0.6550 - val_acc: 0.6667\n",
            "Epoch 197/1000\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.5147 - acc: 0.7440 - val_loss: 0.6677 - val_acc: 0.6562\n",
            "Epoch 198/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.4944 - acc: 0.7509 - val_loss: 0.6686 - val_acc: 0.6667\n",
            "Epoch 199/1000\n",
            "37/37 [==============================] - 5s 106ms/step - loss: 0.5446 - acc: 0.7302 - val_loss: 0.6712 - val_acc: 0.6562\n",
            "Epoch 200/1000\n",
            "37/37 [==============================] - 5s 120ms/step - loss: 0.4929 - acc: 0.7543 - val_loss: 0.6970 - val_acc: 0.6458\n",
            "Epoch 201/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.5146 - acc: 0.7577 - val_loss: 0.6904 - val_acc: 0.6562\n",
            "Epoch 202/1000\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.5020 - acc: 0.7680 - val_loss: 0.6662 - val_acc: 0.6667\n",
            "Epoch 203/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5647 - acc: 0.7165 - val_loss: 0.6705 - val_acc: 0.6667\n",
            "Epoch 204/1000\n",
            "37/37 [==============================] - 10s 238ms/step - loss: 0.5131 - acc: 0.7457 - val_loss: 0.6505 - val_acc: 0.6771\n",
            "Epoch 205/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.4856 - acc: 0.7663 - val_loss: 0.6839 - val_acc: 0.6458\n",
            "Epoch 206/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.5000 - acc: 0.7474 - val_loss: 0.6713 - val_acc: 0.6562\n",
            "Epoch 207/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.5160 - acc: 0.7509 - val_loss: 0.6734 - val_acc: 0.6667\n",
            "Epoch 208/1000\n",
            "37/37 [==============================] - 6s 137ms/step - loss: 0.5016 - acc: 0.7732 - val_loss: 0.6587 - val_acc: 0.6562\n",
            "Epoch 209/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.5094 - acc: 0.7663 - val_loss: 0.6745 - val_acc: 0.6458\n",
            "Epoch 210/1000\n",
            "37/37 [==============================] - 5s 117ms/step - loss: 0.4972 - acc: 0.7560 - val_loss: 0.6667 - val_acc: 0.6562\n",
            "Epoch 211/1000\n",
            "37/37 [==============================] - 5s 102ms/step - loss: 0.5452 - acc: 0.7388 - val_loss: 0.6567 - val_acc: 0.6562\n",
            "Epoch 212/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5246 - acc: 0.7457 - val_loss: 0.6435 - val_acc: 0.6562\n",
            "Epoch 213/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 0.5047 - acc: 0.7388 - val_loss: 0.6486 - val_acc: 0.6667\n",
            "Epoch 214/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.5309 - acc: 0.7251 - val_loss: 0.6747 - val_acc: 0.6354\n",
            "Epoch 215/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.5260 - acc: 0.7440 - val_loss: 0.6553 - val_acc: 0.6562\n",
            "Epoch 216/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.4968 - acc: 0.7577 - val_loss: 0.6637 - val_acc: 0.6354\n",
            "Epoch 217/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.4845 - acc: 0.7543 - val_loss: 0.6560 - val_acc: 0.6458\n",
            "Epoch 218/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.5076 - acc: 0.7732 - val_loss: 0.6506 - val_acc: 0.6667\n",
            "Epoch 219/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5214 - acc: 0.7509 - val_loss: 0.6674 - val_acc: 0.6354\n",
            "Epoch 220/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.5087 - acc: 0.7440 - val_loss: 0.6534 - val_acc: 0.6562\n",
            "Epoch 221/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.4913 - acc: 0.7560 - val_loss: 0.6477 - val_acc: 0.6667\n",
            "Epoch 222/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.4978 - acc: 0.7612 - val_loss: 0.6616 - val_acc: 0.6562\n",
            "Epoch 223/1000\n",
            "37/37 [==============================] - 5s 118ms/step - loss: 0.4918 - acc: 0.7560 - val_loss: 0.6613 - val_acc: 0.6562\n",
            "Epoch 224/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.4880 - acc: 0.7612 - val_loss: 0.6653 - val_acc: 0.6458\n",
            "Epoch 225/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.5174 - acc: 0.7388 - val_loss: 0.6622 - val_acc: 0.6354\n",
            "Epoch 226/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5005 - acc: 0.7509 - val_loss: 0.6614 - val_acc: 0.6458\n",
            "Epoch 227/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.5065 - acc: 0.7423 - val_loss: 0.6617 - val_acc: 0.6562\n",
            "Epoch 228/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5153 - acc: 0.7423 - val_loss: 0.6593 - val_acc: 0.6667\n",
            "Epoch 229/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5375 - acc: 0.7268 - val_loss: 0.6520 - val_acc: 0.6667\n",
            "Epoch 230/1000\n",
            "37/37 [==============================] - 5s 113ms/step - loss: 0.5063 - acc: 0.7612 - val_loss: 0.6536 - val_acc: 0.6667\n",
            "Epoch 231/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.5125 - acc: 0.7388 - val_loss: 0.6772 - val_acc: 0.6562\n",
            "Epoch 232/1000\n",
            "37/37 [==============================] - 9s 239ms/step - loss: 0.4766 - acc: 0.7612 - val_loss: 0.6776 - val_acc: 0.6458\n",
            "Epoch 233/1000\n",
            "37/37 [==============================] - 5s 118ms/step - loss: 0.5042 - acc: 0.7595 - val_loss: 0.6619 - val_acc: 0.6667\n",
            "Epoch 234/1000\n",
            "37/37 [==============================] - 5s 101ms/step - loss: 0.4861 - acc: 0.7680 - val_loss: 0.6687 - val_acc: 0.6458\n",
            "Epoch 235/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.5351 - acc: 0.7440 - val_loss: 0.6616 - val_acc: 0.6667\n",
            "Epoch 236/1000\n",
            "37/37 [==============================] - 5s 113ms/step - loss: 0.4935 - acc: 0.7577 - val_loss: 0.6800 - val_acc: 0.6562\n",
            "Epoch 237/1000\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 0.5219 - acc: 0.7337 - val_loss: 0.6614 - val_acc: 0.6562\n",
            "Epoch 238/1000\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 0.4788 - acc: 0.7732 - val_loss: 0.6617 - val_acc: 0.6562\n",
            "Epoch 239/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5248 - acc: 0.7509 - val_loss: 0.6551 - val_acc: 0.6562\n",
            "Epoch 240/1000\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 0.5099 - acc: 0.7457 - val_loss: 0.6747 - val_acc: 0.6562\n",
            "Epoch 241/1000\n",
            "37/37 [==============================] - 5s 137ms/step - loss: 0.5009 - acc: 0.7354 - val_loss: 0.6473 - val_acc: 0.6667\n",
            "Epoch 242/1000\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 0.4900 - acc: 0.7852 - val_loss: 0.6487 - val_acc: 0.6562\n",
            "Epoch 243/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5004 - acc: 0.7457 - val_loss: 0.6642 - val_acc: 0.6354\n",
            "Epoch 244/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.5258 - acc: 0.7423 - val_loss: 0.6524 - val_acc: 0.6562\n",
            "Epoch 245/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5250 - acc: 0.7457 - val_loss: 0.6652 - val_acc: 0.6562\n",
            "Epoch 246/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5216 - acc: 0.7560 - val_loss: 0.6655 - val_acc: 0.6667\n",
            "Epoch 247/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5149 - acc: 0.7509 - val_loss: 0.6656 - val_acc: 0.6562\n",
            "Epoch 248/1000\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 0.5281 - acc: 0.7423 - val_loss: 0.6715 - val_acc: 0.6458\n",
            "Epoch 249/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.4987 - acc: 0.7457 - val_loss: 0.6507 - val_acc: 0.6667\n",
            "Epoch 250/1000\n",
            "37/37 [==============================] - 5s 114ms/step - loss: 0.4933 - acc: 0.7474 - val_loss: 0.6776 - val_acc: 0.6458\n",
            "Epoch 251/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.4682 - acc: 0.7749 - val_loss: 0.6777 - val_acc: 0.6458\n",
            "Epoch 252/1000\n",
            "37/37 [==============================] - 5s 118ms/step - loss: 0.5025 - acc: 0.7302 - val_loss: 0.6502 - val_acc: 0.6771\n",
            "Epoch 253/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5144 - acc: 0.7388 - val_loss: 0.6654 - val_acc: 0.6458\n",
            "Epoch 254/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5166 - acc: 0.7371 - val_loss: 0.6585 - val_acc: 0.6667\n",
            "Epoch 255/1000\n",
            "37/37 [==============================] - 10s 248ms/step - loss: 0.5138 - acc: 0.7500 - val_loss: 0.6745 - val_acc: 0.6562\n",
            "Epoch 256/1000\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 0.4929 - acc: 0.7423 - val_loss: 0.6692 - val_acc: 0.6458\n",
            "Epoch 257/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.4909 - acc: 0.7543 - val_loss: 0.6548 - val_acc: 0.6667\n",
            "Epoch 258/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 0.5095 - acc: 0.7405 - val_loss: 0.6579 - val_acc: 0.6354\n",
            "Epoch 259/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5219 - acc: 0.7474 - val_loss: 0.6415 - val_acc: 0.6875\n",
            "Epoch 260/1000\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.5364 - acc: 0.7027 - val_loss: 0.6649 - val_acc: 0.6458\n",
            "Epoch 261/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.5147 - acc: 0.7560 - val_loss: 0.6618 - val_acc: 0.6562\n",
            "Epoch 262/1000\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.5368 - acc: 0.7354 - val_loss: 0.6699 - val_acc: 0.6562\n",
            "Epoch 263/1000\n",
            "37/37 [==============================] - 6s 143ms/step - loss: 0.5347 - acc: 0.7440 - val_loss: 0.6694 - val_acc: 0.6458\n",
            "Epoch 264/1000\n",
            "37/37 [==============================] - 9s 241ms/step - loss: 0.5035 - acc: 0.7264 - val_loss: 0.6669 - val_acc: 0.6562\n",
            "Epoch 265/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5081 - acc: 0.7371 - val_loss: 0.6520 - val_acc: 0.6562\n",
            "Epoch 266/1000\n",
            "37/37 [==============================] - 10s 253ms/step - loss: 0.5039 - acc: 0.7551 - val_loss: 0.6586 - val_acc: 0.6667\n",
            "Epoch 267/1000\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 0.5467 - acc: 0.7251 - val_loss: 0.6557 - val_acc: 0.6562\n",
            "Epoch 268/1000\n",
            "37/37 [==============================] - 9s 239ms/step - loss: 0.5092 - acc: 0.7560 - val_loss: 0.6492 - val_acc: 0.6771\n",
            "Epoch 269/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.4933 - acc: 0.7770 - val_loss: 0.6485 - val_acc: 0.6562\n",
            "Epoch 270/1000\n",
            "37/37 [==============================] - 6s 137ms/step - loss: 0.5025 - acc: 0.7560 - val_loss: 0.6551 - val_acc: 0.6562\n",
            "Epoch 271/1000\n",
            "37/37 [==============================] - 10s 255ms/step - loss: 0.5083 - acc: 0.7320 - val_loss: 0.6401 - val_acc: 0.6562\n",
            "Epoch 272/1000\n",
            "37/37 [==============================] - 6s 146ms/step - loss: 0.4960 - acc: 0.7629 - val_loss: 0.6331 - val_acc: 0.6771\n",
            "Epoch 273/1000\n",
            "37/37 [==============================] - 5s 113ms/step - loss: 0.4773 - acc: 0.7784 - val_loss: 0.6560 - val_acc: 0.6562\n",
            "Epoch 274/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.4981 - acc: 0.7302 - val_loss: 0.6686 - val_acc: 0.6458\n",
            "Epoch 275/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.5154 - acc: 0.7491 - val_loss: 0.6678 - val_acc: 0.6354\n",
            "Epoch 276/1000\n",
            "37/37 [==============================] - 5s 117ms/step - loss: 0.5094 - acc: 0.7560 - val_loss: 0.6479 - val_acc: 0.6667\n",
            "Epoch 277/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5120 - acc: 0.7457 - val_loss: 0.6676 - val_acc: 0.6458\n",
            "Epoch 278/1000\n",
            "37/37 [==============================] - 10s 231ms/step - loss: 0.4622 - acc: 0.7784 - val_loss: 0.6594 - val_acc: 0.6354\n",
            "Epoch 279/1000\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.4951 - acc: 0.7543 - val_loss: 0.6620 - val_acc: 0.6562\n",
            "Epoch 280/1000\n",
            "37/37 [==============================] - 10s 236ms/step - loss: 0.5087 - acc: 0.7371 - val_loss: 0.6429 - val_acc: 0.6458\n",
            "Epoch 281/1000\n",
            "37/37 [==============================] - 10s 248ms/step - loss: 0.5295 - acc: 0.7440 - val_loss: 0.6512 - val_acc: 0.6458\n",
            "Epoch 282/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5033 - acc: 0.7474 - val_loss: 0.6537 - val_acc: 0.6667\n",
            "Epoch 283/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.4977 - acc: 0.7509 - val_loss: 0.6709 - val_acc: 0.6458\n",
            "Epoch 284/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5166 - acc: 0.7560 - val_loss: 0.6634 - val_acc: 0.6458\n",
            "Epoch 285/1000\n",
            "37/37 [==============================] - 10s 248ms/step - loss: 0.4814 - acc: 0.7663 - val_loss: 0.6750 - val_acc: 0.6354\n",
            "Epoch 286/1000\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 0.5132 - acc: 0.7285 - val_loss: 0.6787 - val_acc: 0.6354\n",
            "Epoch 287/1000\n",
            "37/37 [==============================] - 7s 163ms/step - loss: 0.5072 - acc: 0.7646 - val_loss: 0.6637 - val_acc: 0.6458\n",
            "Epoch 288/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5280 - acc: 0.7646 - val_loss: 0.6650 - val_acc: 0.6458\n",
            "Epoch 289/1000\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.5087 - acc: 0.7543 - val_loss: 0.6600 - val_acc: 0.6562\n",
            "Epoch 290/1000\n",
            "37/37 [==============================] - 6s 138ms/step - loss: 0.4931 - acc: 0.7595 - val_loss: 0.6509 - val_acc: 0.6667\n",
            "Epoch 291/1000\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.4891 - acc: 0.7612 - val_loss: 0.6748 - val_acc: 0.6562\n",
            "Epoch 292/1000\n",
            "37/37 [==============================] - 10s 246ms/step - loss: 0.5028 - acc: 0.7405 - val_loss: 0.6715 - val_acc: 0.6458\n",
            "Epoch 293/1000\n",
            "37/37 [==============================] - 6s 144ms/step - loss: 0.4898 - acc: 0.7612 - val_loss: 0.6648 - val_acc: 0.6562\n",
            "Epoch 294/1000\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.4943 - acc: 0.7612 - val_loss: 0.6604 - val_acc: 0.6667\n",
            "Epoch 295/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.5121 - acc: 0.7423 - val_loss: 0.6735 - val_acc: 0.6562\n",
            "Epoch 296/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5401 - acc: 0.7354 - val_loss: 0.6685 - val_acc: 0.6562\n",
            "Epoch 297/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.4916 - acc: 0.7715 - val_loss: 0.6556 - val_acc: 0.6667\n",
            "Epoch 298/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.5196 - acc: 0.7509 - val_loss: 0.6711 - val_acc: 0.6667\n",
            "Epoch 299/1000\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.5152 - acc: 0.7440 - val_loss: 0.6762 - val_acc: 0.6562\n",
            "Epoch 300/1000\n",
            "37/37 [==============================] - 5s 106ms/step - loss: 0.5380 - acc: 0.7320 - val_loss: 0.6660 - val_acc: 0.6562\n",
            "Epoch 301/1000\n",
            "37/37 [==============================] - 5s 102ms/step - loss: 0.4800 - acc: 0.7595 - val_loss: 0.6649 - val_acc: 0.6562\n",
            "Epoch 302/1000\n",
            "37/37 [==============================] - 6s 129ms/step - loss: 0.4666 - acc: 0.7715 - val_loss: 0.6529 - val_acc: 0.6667\n",
            "Epoch 303/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.5092 - acc: 0.7337 - val_loss: 0.6483 - val_acc: 0.6458\n",
            "Epoch 304/1000\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.5043 - acc: 0.7388 - val_loss: 0.6631 - val_acc: 0.6458\n",
            "Epoch 305/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.5264 - acc: 0.7131 - val_loss: 0.6516 - val_acc: 0.6562\n",
            "Epoch 306/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.5382 - acc: 0.7199 - val_loss: 0.6664 - val_acc: 0.6667\n",
            "Epoch 307/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5153 - acc: 0.7354 - val_loss: 0.6689 - val_acc: 0.6562\n",
            "Epoch 308/1000\n",
            "37/37 [==============================] - 6s 140ms/step - loss: 0.5488 - acc: 0.7096 - val_loss: 0.6401 - val_acc: 0.6667\n",
            "Epoch 309/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5099 - acc: 0.7302 - val_loss: 0.6390 - val_acc: 0.6667\n",
            "Epoch 310/1000\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.5103 - acc: 0.7457 - val_loss: 0.6677 - val_acc: 0.6458\n",
            "Epoch 311/1000\n",
            "37/37 [==============================] - 10s 250ms/step - loss: 0.4796 - acc: 0.7732 - val_loss: 0.6599 - val_acc: 0.6458\n",
            "Epoch 312/1000\n",
            "37/37 [==============================] - 4s 109ms/step - loss: 0.4996 - acc: 0.7543 - val_loss: 0.6672 - val_acc: 0.6562\n",
            "Epoch 313/1000\n",
            "37/37 [==============================] - 10s 253ms/step - loss: 0.5098 - acc: 0.7371 - val_loss: 0.6562 - val_acc: 0.6667\n",
            "Epoch 314/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5052 - acc: 0.7509 - val_loss: 0.6714 - val_acc: 0.6458\n",
            "Epoch 315/1000\n",
            "37/37 [==============================] - 10s 246ms/step - loss: 0.5214 - acc: 0.7526 - val_loss: 0.6538 - val_acc: 0.6562\n",
            "Epoch 316/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.5204 - acc: 0.7320 - val_loss: 0.6727 - val_acc: 0.6667\n",
            "Epoch 317/1000\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.5088 - acc: 0.7612 - val_loss: 0.6541 - val_acc: 0.6667\n",
            "Epoch 318/1000\n",
            "37/37 [==============================] - 5s 102ms/step - loss: 0.4950 - acc: 0.7766 - val_loss: 0.6541 - val_acc: 0.6562\n",
            "Epoch 319/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.5043 - acc: 0.7629 - val_loss: 0.6634 - val_acc: 0.6562\n",
            "Epoch 320/1000\n",
            "37/37 [==============================] - 6s 134ms/step - loss: 0.5229 - acc: 0.7560 - val_loss: 0.6598 - val_acc: 0.6667\n",
            "Epoch 321/1000\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.5185 - acc: 0.7526 - val_loss: 0.6618 - val_acc: 0.6562\n",
            "Epoch 322/1000\n",
            "37/37 [==============================] - 5s 112ms/step - loss: 0.4885 - acc: 0.7560 - val_loss: 0.6687 - val_acc: 0.6562\n",
            "Epoch 323/1000\n",
            "37/37 [==============================] - 5s 113ms/step - loss: 0.4692 - acc: 0.7646 - val_loss: 0.6771 - val_acc: 0.6458\n",
            "Epoch 324/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.4994 - acc: 0.7440 - val_loss: 0.6588 - val_acc: 0.6771\n",
            "Epoch 325/1000\n",
            "37/37 [==============================] - 5s 113ms/step - loss: 0.4901 - acc: 0.7869 - val_loss: 0.6660 - val_acc: 0.6667\n",
            "Epoch 326/1000\n",
            "37/37 [==============================] - 10s 245ms/step - loss: 0.4846 - acc: 0.7732 - val_loss: 0.6578 - val_acc: 0.6667\n",
            "Epoch 327/1000\n",
            "37/37 [==============================] - 6s 138ms/step - loss: 0.4987 - acc: 0.7491 - val_loss: 0.6658 - val_acc: 0.6354\n",
            "Epoch 328/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5208 - acc: 0.7388 - val_loss: 0.6501 - val_acc: 0.6771\n",
            "Epoch 329/1000\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 0.4911 - acc: 0.7474 - val_loss: 0.6518 - val_acc: 0.6667\n",
            "Epoch 330/1000\n",
            "37/37 [==============================] - 5s 108ms/step - loss: 0.5201 - acc: 0.7543 - val_loss: 0.6766 - val_acc: 0.6458\n",
            "Epoch 331/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.5109 - acc: 0.7715 - val_loss: 0.6626 - val_acc: 0.6562\n",
            "Epoch 332/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5115 - acc: 0.7423 - val_loss: 0.6517 - val_acc: 0.6562\n",
            "Epoch 333/1000\n",
            "37/37 [==============================] - 5s 105ms/step - loss: 0.4883 - acc: 0.7663 - val_loss: 0.6684 - val_acc: 0.6458\n",
            "Epoch 334/1000\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.5263 - acc: 0.7509 - val_loss: 0.6738 - val_acc: 0.6458\n",
            "Epoch 335/1000\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.5233 - acc: 0.7405 - val_loss: 0.6507 - val_acc: 0.6667\n",
            "Epoch 336/1000\n",
            "37/37 [==============================] - 10s 235ms/step - loss: 0.5102 - acc: 0.7577 - val_loss: 0.6706 - val_acc: 0.6458\n",
            "Epoch 337/1000\n",
            "37/37 [==============================] - 9s 242ms/step - loss: 0.4954 - acc: 0.7680 - val_loss: 0.6632 - val_acc: 0.6458\n",
            "Epoch 338/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.4987 - acc: 0.7766 - val_loss: 0.6725 - val_acc: 0.6458\n",
            "Epoch 339/1000\n",
            "37/37 [==============================] - 6s 150ms/step - loss: 0.5089 - acc: 0.7509 - val_loss: 0.6647 - val_acc: 0.6562\n",
            "Epoch 340/1000\n",
            "37/37 [==============================] - 5s 109ms/step - loss: 0.5148 - acc: 0.7500 - val_loss: 0.6760 - val_acc: 0.6354\n",
            "Epoch 341/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.5203 - acc: 0.7612 - val_loss: 0.6687 - val_acc: 0.6458\n",
            "Epoch 342/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.5028 - acc: 0.7560 - val_loss: 0.6546 - val_acc: 0.6562\n",
            "Epoch 343/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.5414 - acc: 0.7216 - val_loss: 0.6517 - val_acc: 0.6562\n",
            "Epoch 344/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.4846 - acc: 0.7818 - val_loss: 0.6776 - val_acc: 0.6354\n",
            "Epoch 345/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.5201 - acc: 0.7405 - val_loss: 0.6502 - val_acc: 0.6667\n",
            "Epoch 346/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.5043 - acc: 0.7577 - val_loss: 0.6722 - val_acc: 0.6458\n",
            "Epoch 347/1000\n",
            "37/37 [==============================] - 6s 138ms/step - loss: 0.4961 - acc: 0.7474 - val_loss: 0.6585 - val_acc: 0.6667\n",
            "Epoch 348/1000\n",
            "37/37 [==============================] - 9s 245ms/step - loss: 0.5205 - acc: 0.7509 - val_loss: 0.6678 - val_acc: 0.6458\n",
            "Epoch 349/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.4776 - acc: 0.7749 - val_loss: 0.6501 - val_acc: 0.6562\n",
            "Epoch 350/1000\n",
            "37/37 [==============================] - 6s 131ms/step - loss: 0.5358 - acc: 0.7371 - val_loss: 0.6350 - val_acc: 0.6667\n",
            "Epoch 351/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.4784 - acc: 0.7509 - val_loss: 0.6530 - val_acc: 0.6458\n",
            "Epoch 352/1000\n",
            "37/37 [==============================] - 5s 120ms/step - loss: 0.5152 - acc: 0.7251 - val_loss: 0.6470 - val_acc: 0.6458\n",
            "Epoch 353/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5324 - acc: 0.7354 - val_loss: 0.6628 - val_acc: 0.6458\n",
            "Epoch 354/1000\n",
            "37/37 [==============================] - 6s 144ms/step - loss: 0.5168 - acc: 0.7371 - val_loss: 0.6349 - val_acc: 0.6667\n",
            "Epoch 355/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.5148 - acc: 0.7423 - val_loss: 0.6701 - val_acc: 0.6562\n",
            "Epoch 356/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5356 - acc: 0.7440 - val_loss: 0.6590 - val_acc: 0.6562\n",
            "Epoch 357/1000\n",
            "37/37 [==============================] - 5s 120ms/step - loss: 0.5231 - acc: 0.7302 - val_loss: 0.6579 - val_acc: 0.6667\n",
            "Epoch 358/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.5091 - acc: 0.7474 - val_loss: 0.6502 - val_acc: 0.6562\n",
            "Epoch 359/1000\n",
            "37/37 [==============================] - 10s 248ms/step - loss: 0.5146 - acc: 0.7474 - val_loss: 0.6696 - val_acc: 0.6562\n",
            "Epoch 360/1000\n",
            "37/37 [==============================] - 5s 115ms/step - loss: 0.5291 - acc: 0.7595 - val_loss: 0.6621 - val_acc: 0.6354\n",
            "Epoch 361/1000\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 0.5289 - acc: 0.7268 - val_loss: 0.6672 - val_acc: 0.6458\n",
            "Epoch 362/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5159 - acc: 0.7423 - val_loss: 0.6771 - val_acc: 0.6354\n",
            "Epoch 363/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.5238 - acc: 0.7354 - val_loss: 0.6472 - val_acc: 0.6667\n",
            "Epoch 364/1000\n",
            "37/37 [==============================] - 6s 131ms/step - loss: 0.4767 - acc: 0.7766 - val_loss: 0.6513 - val_acc: 0.6667\n",
            "Epoch 365/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.4984 - acc: 0.7491 - val_loss: 0.6572 - val_acc: 0.6562\n",
            "Epoch 366/1000\n",
            "37/37 [==============================] - 10s 239ms/step - loss: 0.4999 - acc: 0.7474 - val_loss: 0.6549 - val_acc: 0.6562\n",
            "Epoch 367/1000\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.5064 - acc: 0.7423 - val_loss: 0.6669 - val_acc: 0.6458\n",
            "Epoch 368/1000\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.4827 - acc: 0.7629 - val_loss: 0.6440 - val_acc: 0.6667\n",
            "Epoch 369/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.5219 - acc: 0.7457 - val_loss: 0.6678 - val_acc: 0.6354\n",
            "Epoch 370/1000\n",
            "37/37 [==============================] - 6s 145ms/step - loss: 0.5065 - acc: 0.7663 - val_loss: 0.6511 - val_acc: 0.6562\n",
            "Epoch 371/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.4851 - acc: 0.7801 - val_loss: 0.6649 - val_acc: 0.6562\n",
            "Epoch 372/1000\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 0.5015 - acc: 0.7543 - val_loss: 0.6495 - val_acc: 0.6771\n",
            "Epoch 373/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.5032 - acc: 0.7577 - val_loss: 0.6484 - val_acc: 0.6562\n",
            "Epoch 374/1000\n",
            "37/37 [==============================] - 6s 137ms/step - loss: 0.5195 - acc: 0.7423 - val_loss: 0.6798 - val_acc: 0.6458\n",
            "Epoch 375/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5186 - acc: 0.7440 - val_loss: 0.6532 - val_acc: 0.6667\n",
            "Epoch 376/1000\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.4917 - acc: 0.7595 - val_loss: 0.6637 - val_acc: 0.6562\n",
            "Epoch 377/1000\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 0.4918 - acc: 0.7663 - val_loss: 0.6564 - val_acc: 0.6667\n",
            "Epoch 378/1000\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.4963 - acc: 0.7629 - val_loss: 0.6627 - val_acc: 0.6562\n",
            "Epoch 379/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.5000 - acc: 0.7646 - val_loss: 0.6822 - val_acc: 0.6562\n",
            "Epoch 380/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5058 - acc: 0.7354 - val_loss: 0.6516 - val_acc: 0.6667\n",
            "Epoch 381/1000\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.5282 - acc: 0.7216 - val_loss: 0.6570 - val_acc: 0.6562\n",
            "Epoch 382/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.5363 - acc: 0.7388 - val_loss: 0.6588 - val_acc: 0.6562\n",
            "Epoch 383/1000\n",
            "37/37 [==============================] - 5s 112ms/step - loss: 0.4871 - acc: 0.7784 - val_loss: 0.6553 - val_acc: 0.6562\n",
            "Epoch 384/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5102 - acc: 0.7285 - val_loss: 0.6679 - val_acc: 0.6354\n",
            "Epoch 385/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5492 - acc: 0.7509 - val_loss: 0.6601 - val_acc: 0.6562\n",
            "Epoch 386/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5435 - acc: 0.7302 - val_loss: 0.6551 - val_acc: 0.6667\n",
            "Epoch 387/1000\n",
            "37/37 [==============================] - 7s 158ms/step - loss: 0.5178 - acc: 0.7440 - val_loss: 0.6623 - val_acc: 0.6562\n",
            "Epoch 388/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.5174 - acc: 0.7423 - val_loss: 0.6708 - val_acc: 0.6458\n",
            "Epoch 389/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.5280 - acc: 0.7268 - val_loss: 0.6391 - val_acc: 0.6667\n",
            "Epoch 390/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5202 - acc: 0.7268 - val_loss: 0.6198 - val_acc: 0.6875\n",
            "Epoch 391/1000\n",
            "37/37 [==============================] - 6s 148ms/step - loss: 0.5080 - acc: 0.7698 - val_loss: 0.6487 - val_acc: 0.6667\n",
            "Epoch 392/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.4668 - acc: 0.7905 - val_loss: 0.6709 - val_acc: 0.6458\n",
            "Epoch 393/1000\n",
            "37/37 [==============================] - 5s 108ms/step - loss: 0.5025 - acc: 0.7474 - val_loss: 0.6723 - val_acc: 0.6458\n",
            "Epoch 394/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 0.4956 - acc: 0.7595 - val_loss: 0.6418 - val_acc: 0.6771\n",
            "Epoch 395/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.5041 - acc: 0.7491 - val_loss: 0.6616 - val_acc: 0.6562\n",
            "Epoch 396/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5370 - acc: 0.7337 - val_loss: 0.6556 - val_acc: 0.6458\n",
            "Epoch 397/1000\n",
            "37/37 [==============================] - 9s 239ms/step - loss: 0.4876 - acc: 0.7474 - val_loss: 0.6679 - val_acc: 0.6354\n",
            "Epoch 398/1000\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.5056 - acc: 0.7663 - val_loss: 0.6583 - val_acc: 0.6562\n",
            "Epoch 399/1000\n",
            "37/37 [==============================] - 10s 242ms/step - loss: 0.5101 - acc: 0.7474 - val_loss: 0.6519 - val_acc: 0.6667\n",
            "Epoch 400/1000\n",
            "37/37 [==============================] - 5s 109ms/step - loss: 0.4647 - acc: 0.7784 - val_loss: 0.6491 - val_acc: 0.6458\n",
            "Epoch 401/1000\n",
            "37/37 [==============================] - 5s 108ms/step - loss: 0.5030 - acc: 0.7509 - val_loss: 0.6527 - val_acc: 0.6458\n",
            "Epoch 402/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5192 - acc: 0.7560 - val_loss: 0.6682 - val_acc: 0.6562\n",
            "Epoch 403/1000\n",
            "37/37 [==============================] - 9s 239ms/step - loss: 0.4803 - acc: 0.7612 - val_loss: 0.6767 - val_acc: 0.6562\n",
            "Epoch 404/1000\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.5184 - acc: 0.7509 - val_loss: 0.6654 - val_acc: 0.6562\n",
            "Epoch 405/1000\n",
            "37/37 [==============================] - 6s 142ms/step - loss: 0.5074 - acc: 0.7509 - val_loss: 0.6511 - val_acc: 0.6562\n",
            "Epoch 406/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5236 - acc: 0.7337 - val_loss: 0.6634 - val_acc: 0.6458\n",
            "Epoch 407/1000\n",
            "37/37 [==============================] - 5s 113ms/step - loss: 0.5387 - acc: 0.7182 - val_loss: 0.6477 - val_acc: 0.6458\n",
            "Epoch 408/1000\n",
            "37/37 [==============================] - 5s 112ms/step - loss: 0.5080 - acc: 0.7715 - val_loss: 0.6416 - val_acc: 0.6771\n",
            "Epoch 409/1000\n",
            "37/37 [==============================] - 5s 116ms/step - loss: 0.4719 - acc: 0.7680 - val_loss: 0.6708 - val_acc: 0.6562\n",
            "Epoch 410/1000\n",
            "37/37 [==============================] - 6s 144ms/step - loss: 0.5173 - acc: 0.7629 - val_loss: 0.6629 - val_acc: 0.6458\n",
            "Epoch 411/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.4990 - acc: 0.7595 - val_loss: 0.6776 - val_acc: 0.6354\n",
            "Epoch 412/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.4941 - acc: 0.7543 - val_loss: 0.6611 - val_acc: 0.6562\n",
            "Epoch 413/1000\n",
            "37/37 [==============================] - 10s 242ms/step - loss: 0.4871 - acc: 0.7612 - val_loss: 0.6627 - val_acc: 0.6562\n",
            "Epoch 414/1000\n",
            "37/37 [==============================] - 5s 112ms/step - loss: 0.5122 - acc: 0.7405 - val_loss: 0.6623 - val_acc: 0.6562\n",
            "Epoch 415/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.5170 - acc: 0.7457 - val_loss: 0.6468 - val_acc: 0.6667\n",
            "Epoch 416/1000\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.5183 - acc: 0.7595 - val_loss: 0.6640 - val_acc: 0.6458\n",
            "Epoch 417/1000\n",
            "37/37 [==============================] - 10s 237ms/step - loss: 0.4918 - acc: 0.7612 - val_loss: 0.6405 - val_acc: 0.6354\n",
            "Epoch 418/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5291 - acc: 0.7423 - val_loss: 0.6592 - val_acc: 0.6354\n",
            "Epoch 419/1000\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.5194 - acc: 0.7285 - val_loss: 0.6673 - val_acc: 0.6562\n",
            "Epoch 420/1000\n",
            "37/37 [==============================] - 9s 225ms/step - loss: 0.5196 - acc: 0.7320 - val_loss: 0.6651 - val_acc: 0.6458\n",
            "Epoch 421/1000\n",
            "37/37 [==============================] - 9s 239ms/step - loss: 0.5012 - acc: 0.7595 - val_loss: 0.6641 - val_acc: 0.6458\n",
            "Epoch 422/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.4988 - acc: 0.7509 - val_loss: 0.6624 - val_acc: 0.6562\n",
            "Epoch 423/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.4848 - acc: 0.7457 - val_loss: 0.6614 - val_acc: 0.6250\n",
            "Epoch 424/1000\n",
            "37/37 [==============================] - 5s 117ms/step - loss: 0.5414 - acc: 0.7165 - val_loss: 0.6394 - val_acc: 0.6771\n",
            "Epoch 425/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.5704 - acc: 0.7131 - val_loss: 0.6515 - val_acc: 0.6250\n",
            "Epoch 426/1000\n",
            "37/37 [==============================] - 5s 115ms/step - loss: 0.5422 - acc: 0.7096 - val_loss: 0.6522 - val_acc: 0.6562\n",
            "Epoch 427/1000\n",
            "37/37 [==============================] - 5s 107ms/step - loss: 0.5177 - acc: 0.7388 - val_loss: 0.6562 - val_acc: 0.6562\n",
            "Epoch 428/1000\n",
            "37/37 [==============================] - 5s 110ms/step - loss: 0.5527 - acc: 0.7165 - val_loss: 0.6525 - val_acc: 0.6562\n",
            "Epoch 429/1000\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 0.4972 - acc: 0.7491 - val_loss: 0.6431 - val_acc: 0.6667\n",
            "Epoch 430/1000\n",
            "37/37 [==============================] - 5s 114ms/step - loss: 0.5125 - acc: 0.7440 - val_loss: 0.6530 - val_acc: 0.6667\n",
            "Epoch 431/1000\n",
            "37/37 [==============================] - 6s 137ms/step - loss: 0.4913 - acc: 0.7440 - val_loss: 0.6551 - val_acc: 0.6250\n",
            "Epoch 432/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.5124 - acc: 0.7560 - val_loss: 0.6602 - val_acc: 0.6562\n",
            "Epoch 433/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 0.5471 - acc: 0.7268 - val_loss: 0.6562 - val_acc: 0.6667\n",
            "Epoch 434/1000\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.5051 - acc: 0.7509 - val_loss: 0.6729 - val_acc: 0.6562\n",
            "Epoch 435/1000\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.5152 - acc: 0.7423 - val_loss: 0.6681 - val_acc: 0.6458\n",
            "Epoch 436/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.4857 - acc: 0.7405 - val_loss: 0.6653 - val_acc: 0.6458\n",
            "Epoch 437/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.5239 - acc: 0.7423 - val_loss: 0.6673 - val_acc: 0.6458\n",
            "Epoch 438/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.5010 - acc: 0.7595 - val_loss: 0.6522 - val_acc: 0.6458\n",
            "Epoch 439/1000\n",
            "37/37 [==============================] - 9s 239ms/step - loss: 0.4872 - acc: 0.7698 - val_loss: 0.6496 - val_acc: 0.6562\n",
            "Epoch 440/1000\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.5170 - acc: 0.7509 - val_loss: 0.6455 - val_acc: 0.6667\n",
            "Epoch 441/1000\n",
            "37/37 [==============================] - 5s 110ms/step - loss: 0.4946 - acc: 0.7698 - val_loss: 0.6740 - val_acc: 0.6354\n",
            "Epoch 442/1000\n",
            "37/37 [==============================] - 5s 117ms/step - loss: 0.5154 - acc: 0.7440 - val_loss: 0.6659 - val_acc: 0.6354\n",
            "Epoch 443/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.5343 - acc: 0.7165 - val_loss: 0.6596 - val_acc: 0.6250\n",
            "Epoch 444/1000\n",
            "37/37 [==============================] - 5s 120ms/step - loss: 0.4951 - acc: 0.7526 - val_loss: 0.6623 - val_acc: 0.6354\n",
            "Epoch 445/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.5007 - acc: 0.7560 - val_loss: 0.6683 - val_acc: 0.6458\n",
            "Epoch 446/1000\n",
            "37/37 [==============================] - 5s 108ms/step - loss: 0.5071 - acc: 0.7474 - val_loss: 0.6756 - val_acc: 0.6354\n",
            "Epoch 447/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.4912 - acc: 0.7543 - val_loss: 0.6648 - val_acc: 0.6458\n",
            "Epoch 448/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5309 - acc: 0.7423 - val_loss: 0.6576 - val_acc: 0.6667\n",
            "Epoch 449/1000\n",
            "37/37 [==============================] - 10s 253ms/step - loss: 0.4967 - acc: 0.7577 - val_loss: 0.6897 - val_acc: 0.6458\n",
            "Epoch 450/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5130 - acc: 0.7595 - val_loss: 0.6654 - val_acc: 0.6458\n",
            "Epoch 451/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 0.4807 - acc: 0.7440 - val_loss: 0.6647 - val_acc: 0.6562\n",
            "Epoch 452/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.5099 - acc: 0.7474 - val_loss: 0.6386 - val_acc: 0.6771\n",
            "Epoch 453/1000\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.4910 - acc: 0.7612 - val_loss: 0.6564 - val_acc: 0.6562\n",
            "Epoch 454/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.4728 - acc: 0.7715 - val_loss: 0.6509 - val_acc: 0.6354\n",
            "Epoch 455/1000\n",
            "37/37 [==============================] - 5s 108ms/step - loss: 0.5201 - acc: 0.7354 - val_loss: 0.6555 - val_acc: 0.6562\n",
            "Epoch 456/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.5049 - acc: 0.7405 - val_loss: 0.6506 - val_acc: 0.6562\n",
            "Epoch 457/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5408 - acc: 0.7388 - val_loss: 0.6511 - val_acc: 0.6354\n",
            "Epoch 458/1000\n",
            "37/37 [==============================] - 5s 109ms/step - loss: 0.4768 - acc: 0.7732 - val_loss: 0.6748 - val_acc: 0.6354\n",
            "Epoch 459/1000\n",
            "37/37 [==============================] - 10s 243ms/step - loss: 0.5351 - acc: 0.7457 - val_loss: 0.6598 - val_acc: 0.6458\n",
            "Epoch 460/1000\n",
            "37/37 [==============================] - 5s 111ms/step - loss: 0.4967 - acc: 0.7663 - val_loss: 0.6569 - val_acc: 0.6458\n",
            "Epoch 461/1000\n",
            "37/37 [==============================] - 5s 106ms/step - loss: 0.4966 - acc: 0.7595 - val_loss: 0.6642 - val_acc: 0.6458\n",
            "Epoch 462/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.4800 - acc: 0.7457 - val_loss: 0.6643 - val_acc: 0.6458\n",
            "Epoch 463/1000\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.4897 - acc: 0.7732 - val_loss: 0.6686 - val_acc: 0.6458\n",
            "Epoch 464/1000\n",
            "37/37 [==============================] - 5s 116ms/step - loss: 0.4916 - acc: 0.7577 - val_loss: 0.6574 - val_acc: 0.6562\n",
            "Epoch 465/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 0.5119 - acc: 0.7388 - val_loss: 0.6702 - val_acc: 0.6458\n",
            "Epoch 466/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5155 - acc: 0.7440 - val_loss: 0.6646 - val_acc: 0.6458\n",
            "Epoch 467/1000\n",
            "37/37 [==============================] - 10s 247ms/step - loss: 0.5202 - acc: 0.7457 - val_loss: 0.6766 - val_acc: 0.6458\n",
            "Epoch 468/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.4596 - acc: 0.7801 - val_loss: 0.6510 - val_acc: 0.6562\n",
            "Epoch 469/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.5341 - acc: 0.7457 - val_loss: 0.6618 - val_acc: 0.6562\n",
            "Epoch 470/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5214 - acc: 0.7612 - val_loss: 0.6590 - val_acc: 0.6562\n",
            "Epoch 471/1000\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 0.5134 - acc: 0.7423 - val_loss: 0.6711 - val_acc: 0.6458\n",
            "Epoch 472/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.5021 - acc: 0.7766 - val_loss: 0.6459 - val_acc: 0.6771\n",
            "Epoch 473/1000\n",
            "37/37 [==============================] - 5s 112ms/step - loss: 0.5635 - acc: 0.7027 - val_loss: 0.6541 - val_acc: 0.6562\n",
            "Epoch 474/1000\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.5032 - acc: 0.7766 - val_loss: 0.6582 - val_acc: 0.6667\n",
            "Epoch 475/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.4846 - acc: 0.7801 - val_loss: 0.6501 - val_acc: 0.6562\n",
            "Epoch 476/1000\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.4959 - acc: 0.7491 - val_loss: 0.6581 - val_acc: 0.6354\n",
            "Epoch 477/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5073 - acc: 0.7526 - val_loss: 0.6618 - val_acc: 0.6771\n",
            "Epoch 478/1000\n",
            "37/37 [==============================] - 7s 161ms/step - loss: 0.4858 - acc: 0.7577 - val_loss: 0.6914 - val_acc: 0.6458\n",
            "Epoch 479/1000\n",
            "37/37 [==============================] - 5s 118ms/step - loss: 0.5191 - acc: 0.7268 - val_loss: 0.6656 - val_acc: 0.6458\n",
            "Epoch 480/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.4969 - acc: 0.7595 - val_loss: 0.6798 - val_acc: 0.6354\n",
            "Epoch 481/1000\n",
            "37/37 [==============================] - 6s 139ms/step - loss: 0.4823 - acc: 0.7595 - val_loss: 0.6558 - val_acc: 0.6667\n",
            "Epoch 482/1000\n",
            "37/37 [==============================] - 10s 248ms/step - loss: 0.5270 - acc: 0.7440 - val_loss: 0.6750 - val_acc: 0.6458\n",
            "Epoch 483/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.4855 - acc: 0.7698 - val_loss: 0.6592 - val_acc: 0.6562\n",
            "Epoch 484/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.4874 - acc: 0.7680 - val_loss: 0.6444 - val_acc: 0.6562\n",
            "Epoch 485/1000\n",
            "37/37 [==============================] - 10s 253ms/step - loss: 0.4959 - acc: 0.7509 - val_loss: 0.6563 - val_acc: 0.6562\n",
            "Epoch 486/1000\n",
            "37/37 [==============================] - 5s 113ms/step - loss: 0.5149 - acc: 0.7285 - val_loss: 0.6845 - val_acc: 0.6354\n",
            "Epoch 487/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 0.5424 - acc: 0.7251 - val_loss: 0.6701 - val_acc: 0.6458\n",
            "Epoch 488/1000\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.4836 - acc: 0.7577 - val_loss: 0.6595 - val_acc: 0.6562\n",
            "Epoch 489/1000\n",
            "37/37 [==============================] - 10s 242ms/step - loss: 0.4914 - acc: 0.7595 - val_loss: 0.6713 - val_acc: 0.6354\n",
            "Epoch 490/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5217 - acc: 0.7509 - val_loss: 0.6604 - val_acc: 0.6562\n",
            "Epoch 491/1000\n",
            "37/37 [==============================] - 10s 245ms/step - loss: 0.4903 - acc: 0.7595 - val_loss: 0.6611 - val_acc: 0.6458\n",
            "Epoch 492/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.4840 - acc: 0.7680 - val_loss: 0.6479 - val_acc: 0.6562\n",
            "Epoch 493/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.5013 - acc: 0.7474 - val_loss: 0.6508 - val_acc: 0.6562\n",
            "Epoch 494/1000\n",
            "37/37 [==============================] - 4s 111ms/step - loss: 0.5074 - acc: 0.7440 - val_loss: 0.6489 - val_acc: 0.6458\n",
            "Epoch 495/1000\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 0.5176 - acc: 0.7354 - val_loss: 0.6623 - val_acc: 0.6458\n",
            "Epoch 496/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.5265 - acc: 0.7405 - val_loss: 0.6502 - val_acc: 0.6562\n",
            "Epoch 497/1000\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.4933 - acc: 0.7646 - val_loss: 0.6527 - val_acc: 0.6458\n",
            "Epoch 498/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.5019 - acc: 0.7577 - val_loss: 0.6587 - val_acc: 0.6250\n",
            "Epoch 499/1000\n",
            "37/37 [==============================] - 5s 109ms/step - loss: 0.5333 - acc: 0.7371 - val_loss: 0.6746 - val_acc: 0.6354\n",
            "Epoch 500/1000\n",
            "37/37 [==============================] - 5s 118ms/step - loss: 0.5327 - acc: 0.7268 - val_loss: 0.6453 - val_acc: 0.6354\n",
            "Epoch 501/1000\n",
            "37/37 [==============================] - 10s 238ms/step - loss: 0.5050 - acc: 0.7405 - val_loss: 0.6402 - val_acc: 0.6771\n",
            "Epoch 502/1000\n",
            "37/37 [==============================] - 10s 253ms/step - loss: 0.5074 - acc: 0.7646 - val_loss: 0.6641 - val_acc: 0.6458\n",
            "Epoch 503/1000\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.5077 - acc: 0.7577 - val_loss: 0.6611 - val_acc: 0.6667\n",
            "Epoch 504/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.4891 - acc: 0.7526 - val_loss: 0.6641 - val_acc: 0.6562\n",
            "Epoch 505/1000\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 0.4761 - acc: 0.7749 - val_loss: 0.6682 - val_acc: 0.6458\n",
            "Epoch 506/1000\n",
            "37/37 [==============================] - 5s 110ms/step - loss: 0.4977 - acc: 0.7560 - val_loss: 0.6568 - val_acc: 0.6562\n",
            "Epoch 507/1000\n",
            "37/37 [==============================] - 10s 247ms/step - loss: 0.4933 - acc: 0.7835 - val_loss: 0.6693 - val_acc: 0.6562\n",
            "Epoch 508/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5057 - acc: 0.7474 - val_loss: 0.6584 - val_acc: 0.6562\n",
            "Epoch 509/1000\n",
            "37/37 [==============================] - 7s 167ms/step - loss: 0.4894 - acc: 0.7629 - val_loss: 0.6706 - val_acc: 0.6354\n",
            "Epoch 510/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5402 - acc: 0.7388 - val_loss: 0.6546 - val_acc: 0.6562\n",
            "Epoch 511/1000\n",
            "37/37 [==============================] - 5s 112ms/step - loss: 0.4921 - acc: 0.7629 - val_loss: 0.6597 - val_acc: 0.6458\n",
            "Epoch 512/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.5396 - acc: 0.7320 - val_loss: 0.6683 - val_acc: 0.6458\n",
            "Epoch 513/1000\n",
            "37/37 [==============================] - 5s 105ms/step - loss: 0.5100 - acc: 0.7577 - val_loss: 0.6541 - val_acc: 0.6562\n",
            "Epoch 514/1000\n",
            "37/37 [==============================] - 9s 239ms/step - loss: 0.5209 - acc: 0.7629 - val_loss: 0.6614 - val_acc: 0.6458\n",
            "Epoch 515/1000\n",
            "37/37 [==============================] - 5s 114ms/step - loss: 0.4923 - acc: 0.7466 - val_loss: 0.6450 - val_acc: 0.6667\n",
            "Epoch 516/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.5186 - acc: 0.7285 - val_loss: 0.6803 - val_acc: 0.6354\n",
            "Epoch 517/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.5106 - acc: 0.7474 - val_loss: 0.6487 - val_acc: 0.6667\n",
            "Epoch 518/1000\n",
            "37/37 [==============================] - 5s 113ms/step - loss: 0.5044 - acc: 0.7509 - val_loss: 0.6701 - val_acc: 0.6562\n",
            "Epoch 519/1000\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 0.5283 - acc: 0.7320 - val_loss: 0.6620 - val_acc: 0.6562\n",
            "Epoch 520/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5256 - acc: 0.7354 - val_loss: 0.6848 - val_acc: 0.6458\n",
            "Epoch 521/1000\n",
            "37/37 [==============================] - 10s 245ms/step - loss: 0.5058 - acc: 0.7646 - val_loss: 0.6668 - val_acc: 0.6562\n",
            "Epoch 522/1000\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.4999 - acc: 0.7732 - val_loss: 0.6742 - val_acc: 0.6458\n",
            "Epoch 523/1000\n",
            "37/37 [==============================] - 5s 101ms/step - loss: 0.5063 - acc: 0.7251 - val_loss: 0.6750 - val_acc: 0.6458\n",
            "Epoch 524/1000\n",
            "37/37 [==============================] - 5s 116ms/step - loss: 0.4967 - acc: 0.7698 - val_loss: 0.6863 - val_acc: 0.6354\n",
            "Epoch 525/1000\n",
            "37/37 [==============================] - 5s 117ms/step - loss: 0.4935 - acc: 0.7474 - val_loss: 0.6862 - val_acc: 0.6458\n",
            "Epoch 526/1000\n",
            "37/37 [==============================] - 5s 118ms/step - loss: 0.4879 - acc: 0.7543 - val_loss: 0.6875 - val_acc: 0.6354\n",
            "Epoch 527/1000\n",
            "37/37 [==============================] - 5s 101ms/step - loss: 0.5433 - acc: 0.7388 - val_loss: 0.6684 - val_acc: 0.6458\n",
            "Epoch 528/1000\n",
            "37/37 [==============================] - 5s 114ms/step - loss: 0.5174 - acc: 0.7285 - val_loss: 0.6693 - val_acc: 0.6562\n",
            "Epoch 529/1000\n",
            "37/37 [==============================] - 5s 116ms/step - loss: 0.4915 - acc: 0.7663 - val_loss: 0.6799 - val_acc: 0.6458\n",
            "Epoch 530/1000\n",
            "37/37 [==============================] - 10s 240ms/step - loss: 0.5581 - acc: 0.7234 - val_loss: 0.6626 - val_acc: 0.6667\n",
            "Epoch 531/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 0.4950 - acc: 0.7543 - val_loss: 0.6611 - val_acc: 0.6458\n",
            "Epoch 532/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5003 - acc: 0.7440 - val_loss: 0.6550 - val_acc: 0.6458\n",
            "Epoch 533/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 0.4653 - acc: 0.7715 - val_loss: 0.6782 - val_acc: 0.6458\n",
            "Epoch 534/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.4989 - acc: 0.7526 - val_loss: 0.6777 - val_acc: 0.6354\n",
            "Epoch 535/1000\n",
            "37/37 [==============================] - 5s 111ms/step - loss: 0.4954 - acc: 0.7526 - val_loss: 0.6458 - val_acc: 0.6458\n",
            "Epoch 536/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.5002 - acc: 0.7543 - val_loss: 0.6666 - val_acc: 0.6562\n",
            "Epoch 537/1000\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 0.5199 - acc: 0.7560 - val_loss: 0.6584 - val_acc: 0.6667\n",
            "Epoch 538/1000\n",
            "37/37 [==============================] - 6s 137ms/step - loss: 0.5295 - acc: 0.7440 - val_loss: 0.6412 - val_acc: 0.6771\n",
            "Epoch 539/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.4852 - acc: 0.7698 - val_loss: 0.6752 - val_acc: 0.6562\n",
            "Epoch 540/1000\n",
            "37/37 [==============================] - 10s 251ms/step - loss: 0.5218 - acc: 0.7491 - val_loss: 0.6507 - val_acc: 0.6771\n",
            "Epoch 541/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5178 - acc: 0.7388 - val_loss: 0.6628 - val_acc: 0.6562\n",
            "Epoch 542/1000\n",
            "37/37 [==============================] - 10s 249ms/step - loss: 0.4771 - acc: 0.7698 - val_loss: 0.6505 - val_acc: 0.6667\n",
            "Epoch 543/1000\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.5021 - acc: 0.7526 - val_loss: 0.6549 - val_acc: 0.6354\n",
            "Epoch 544/1000\n",
            "37/37 [==============================] - 6s 129ms/step - loss: 0.5384 - acc: 0.7405 - val_loss: 0.6554 - val_acc: 0.6667\n",
            "Epoch 545/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.4875 - acc: 0.7784 - val_loss: 0.6609 - val_acc: 0.6562\n",
            "Epoch 546/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5018 - acc: 0.7560 - val_loss: 0.6711 - val_acc: 0.6458\n",
            "Epoch 547/1000\n",
            "37/37 [==============================] - 5s 109ms/step - loss: 0.5460 - acc: 0.7560 - val_loss: 0.6566 - val_acc: 0.6562\n",
            "Epoch 548/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.5501 - acc: 0.7096 - val_loss: 0.6803 - val_acc: 0.6458\n",
            "Epoch 549/1000\n",
            "37/37 [==============================] - 10s 241ms/step - loss: 0.4819 - acc: 0.7680 - val_loss: 0.6791 - val_acc: 0.6458\n",
            "Epoch 550/1000\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.5177 - acc: 0.7388 - val_loss: 0.6752 - val_acc: 0.6562\n",
            "Epoch 551/1000\n",
            "37/37 [==============================] - 10s 255ms/step - loss: 0.5030 - acc: 0.7577 - val_loss: 0.6620 - val_acc: 0.6458\n",
            "Epoch 552/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.4730 - acc: 0.7680 - val_loss: 0.6724 - val_acc: 0.6458\n",
            "Epoch 553/1000\n",
            "37/37 [==============================] - 10s 262ms/step - loss: 0.4802 - acc: 0.7612 - val_loss: 0.6747 - val_acc: 0.6250\n",
            "Epoch 554/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.5291 - acc: 0.7216 - val_loss: 0.6686 - val_acc: 0.6354\n",
            "Epoch 555/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.5011 - acc: 0.7457 - val_loss: 0.6832 - val_acc: 0.6458\n",
            "Epoch 556/1000\n",
            "37/37 [==============================] - 9s 244ms/step - loss: 0.5325 - acc: 0.7182 - val_loss: 0.6610 - val_acc: 0.6667\n",
            "Epoch 557/1000\n",
            "37/37 [==============================] - 5s 110ms/step - loss: 0.5275 - acc: 0.7302 - val_loss: 0.6807 - val_acc: 0.6458\n",
            "Epoch 558/1000\n",
            "37/37 [==============================] - 10s 239ms/step - loss: 0.5254 - acc: 0.7302 - val_loss: 0.6859 - val_acc: 0.6562\n",
            "Epoch 559/1000\n",
            "37/37 [==============================] - 10s 252ms/step - loss: 0.5119 - acc: 0.7612 - val_loss: 0.6741 - val_acc: 0.6562\n",
            "Epoch 560/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.5274 - acc: 0.7320 - val_loss: 0.6636 - val_acc: 0.6562\n",
            "Epoch 561/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.4820 - acc: 0.7577 - val_loss: 0.6720 - val_acc: 0.6354\n",
            "Epoch 562/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5162 - acc: 0.7371 - val_loss: 0.6707 - val_acc: 0.6562\n",
            "Epoch 563/1000\n",
            "37/37 [==============================] - 5s 114ms/step - loss: 0.5375 - acc: 0.7302 - val_loss: 0.6561 - val_acc: 0.6771\n",
            "Epoch 564/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5135 - acc: 0.7371 - val_loss: 0.6626 - val_acc: 0.6667\n",
            "Epoch 565/1000\n",
            "37/37 [==============================] - 5s 107ms/step - loss: 0.5213 - acc: 0.7526 - val_loss: 0.6729 - val_acc: 0.6458\n",
            "Epoch 566/1000\n",
            "37/37 [==============================] - 10s 239ms/step - loss: 0.5282 - acc: 0.7234 - val_loss: 0.6886 - val_acc: 0.6354\n",
            "Epoch 567/1000\n",
            "37/37 [==============================] - 9s 243ms/step - loss: 0.5335 - acc: 0.7440 - val_loss: 0.6591 - val_acc: 0.6562\n",
            "Epoch 568/1000\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.4816 - acc: 0.7423 - val_loss: 0.6661 - val_acc: 0.6667\n",
            "Epoch 569/1000\n",
            "37/37 [==============================] - 6s 144ms/step - loss: 0.4961 - acc: 0.7526 - val_loss: 0.6704 - val_acc: 0.6562\n",
            "Epoch 570/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.5097 - acc: 0.7491 - val_loss: 0.6679 - val_acc: 0.6562\n",
            "Epoch 571/1000\n",
            "37/37 [==============================] - 5s 104ms/step - loss: 0.5152 - acc: 0.7568 - val_loss: 0.6772 - val_acc: 0.6458\n",
            "Epoch 572/1000\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 0.5193 - acc: 0.7457 - val_loss: 0.6730 - val_acc: 0.6562\n",
            "Epoch 573/1000\n",
            "37/37 [==============================] - 5s 109ms/step - loss: 0.4985 - acc: 0.7646 - val_loss: 0.6851 - val_acc: 0.6458\n",
            "Epoch 574/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.5014 - acc: 0.7629 - val_loss: 0.6794 - val_acc: 0.6458\n",
            "Epoch 575/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.5092 - acc: 0.7371 - val_loss: 0.6624 - val_acc: 0.6667\n",
            "Epoch 576/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.5185 - acc: 0.7388 - val_loss: 0.6537 - val_acc: 0.6667\n",
            "Epoch 577/1000\n",
            "37/37 [==============================] - 9s 241ms/step - loss: 0.5362 - acc: 0.7302 - val_loss: 0.6685 - val_acc: 0.6562\n",
            "Epoch 578/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.4986 - acc: 0.7526 - val_loss: 0.6863 - val_acc: 0.6458\n",
            "Epoch 579/1000\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 0.5082 - acc: 0.7680 - val_loss: 0.6799 - val_acc: 0.6458\n",
            "Epoch 580/1000\n",
            "37/37 [==============================] - 6s 139ms/step - loss: 0.5018 - acc: 0.7784 - val_loss: 0.6711 - val_acc: 0.6667\n",
            "Epoch 581/1000\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 0.5260 - acc: 0.7509 - val_loss: 0.6819 - val_acc: 0.6458\n",
            "Epoch 582/1000\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.4921 - acc: 0.7491 - val_loss: 0.6696 - val_acc: 0.6667\n",
            "Epoch 583/1000\n",
            "37/37 [==============================] - 6s 134ms/step - loss: 0.4803 - acc: 0.7749 - val_loss: 0.6608 - val_acc: 0.6562\n",
            "Epoch 584/1000\n",
            "37/37 [==============================] - 5s 113ms/step - loss: 0.5060 - acc: 0.7646 - val_loss: 0.6690 - val_acc: 0.6667\n",
            "Epoch 585/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 0.5000 - acc: 0.7732 - val_loss: 0.6461 - val_acc: 0.6667\n",
            "Epoch 586/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.5507 - acc: 0.7320 - val_loss: 0.6593 - val_acc: 0.6458\n",
            "Epoch 587/1000\n",
            "37/37 [==============================] - 5s 110ms/step - loss: 0.5293 - acc: 0.7388 - val_loss: 0.6638 - val_acc: 0.6354\n",
            "Epoch 588/1000\n",
            "37/37 [==============================] - 6s 145ms/step - loss: 0.4966 - acc: 0.7491 - val_loss: 0.6516 - val_acc: 0.6667\n",
            "Epoch 589/1000\n",
            "37/37 [==============================] - 4s 109ms/step - loss: 0.5380 - acc: 0.7388 - val_loss: 0.6800 - val_acc: 0.6354\n",
            "Epoch 590/1000\n",
            "37/37 [==============================] - 5s 110ms/step - loss: 0.5059 - acc: 0.7698 - val_loss: 0.6572 - val_acc: 0.6562\n",
            "Epoch 591/1000\n",
            "37/37 [==============================] - 10s 243ms/step - loss: 0.5302 - acc: 0.7491 - val_loss: 0.6648 - val_acc: 0.6354\n",
            "Epoch 592/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.4958 - acc: 0.7474 - val_loss: 0.6718 - val_acc: 0.6562\n",
            "Epoch 593/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.4761 - acc: 0.7663 - val_loss: 0.6737 - val_acc: 0.6562\n",
            "Epoch 594/1000\n",
            "37/37 [==============================] - 6s 140ms/step - loss: 0.5268 - acc: 0.7302 - val_loss: 0.6571 - val_acc: 0.6667\n",
            "Epoch 595/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.5059 - acc: 0.7491 - val_loss: 0.6666 - val_acc: 0.6458\n",
            "Epoch 596/1000\n",
            "37/37 [==============================] - 6s 135ms/step - loss: 0.5476 - acc: 0.7268 - val_loss: 0.6582 - val_acc: 0.6562\n",
            "Epoch 597/1000\n",
            "37/37 [==============================] - 9s 239ms/step - loss: 0.5000 - acc: 0.7509 - val_loss: 0.6665 - val_acc: 0.6458\n",
            "Epoch 598/1000\n",
            "37/37 [==============================] - 5s 118ms/step - loss: 0.4872 - acc: 0.7543 - val_loss: 0.6551 - val_acc: 0.6562\n",
            "Epoch 599/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.5005 - acc: 0.7405 - val_loss: 0.6566 - val_acc: 0.6562\n",
            "Epoch 600/1000\n",
            "37/37 [==============================] - 9s 243ms/step - loss: 0.4944 - acc: 0.7491 - val_loss: 0.6560 - val_acc: 0.6562\n",
            "Epoch 601/1000\n",
            "37/37 [==============================] - 10s 248ms/step - loss: 0.4873 - acc: 0.7612 - val_loss: 0.6682 - val_acc: 0.6458\n",
            "Epoch 602/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.5044 - acc: 0.7560 - val_loss: 0.6602 - val_acc: 0.6562\n",
            "Epoch 603/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5121 - acc: 0.7577 - val_loss: 0.6702 - val_acc: 0.6458\n",
            "Epoch 604/1000\n",
            "37/37 [==============================] - 6s 147ms/step - loss: 0.5042 - acc: 0.7732 - val_loss: 0.6636 - val_acc: 0.6250\n",
            "Epoch 605/1000\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 0.4653 - acc: 0.7904 - val_loss: 0.6652 - val_acc: 0.6458\n",
            "Epoch 606/1000\n",
            "37/37 [==============================] - 6s 141ms/step - loss: 0.4936 - acc: 0.7612 - val_loss: 0.6622 - val_acc: 0.6667\n",
            "Epoch 607/1000\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.5189 - acc: 0.7251 - val_loss: 0.6708 - val_acc: 0.6562\n",
            "Epoch 608/1000\n",
            "37/37 [==============================] - 6s 127ms/step - loss: 0.5167 - acc: 0.7423 - val_loss: 0.6567 - val_acc: 0.6667\n",
            "Epoch 609/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5281 - acc: 0.7320 - val_loss: 0.6852 - val_acc: 0.6354\n",
            "Epoch 610/1000\n",
            "37/37 [==============================] - 10s 235ms/step - loss: 0.4795 - acc: 0.7491 - val_loss: 0.6798 - val_acc: 0.6354\n",
            "Epoch 611/1000\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.4912 - acc: 0.7543 - val_loss: 0.6680 - val_acc: 0.6458\n",
            "Epoch 612/1000\n",
            "37/37 [==============================] - 9s 244ms/step - loss: 0.5270 - acc: 0.7663 - val_loss: 0.6711 - val_acc: 0.6354\n",
            "Epoch 613/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.5291 - acc: 0.7474 - val_loss: 0.6595 - val_acc: 0.6458\n",
            "Epoch 614/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 0.5326 - acc: 0.7251 - val_loss: 0.6567 - val_acc: 0.6458\n",
            "Epoch 615/1000\n",
            "37/37 [==============================] - 5s 113ms/step - loss: 0.4979 - acc: 0.7612 - val_loss: 0.6757 - val_acc: 0.6354\n",
            "Epoch 616/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 0.4964 - acc: 0.7423 - val_loss: 0.6660 - val_acc: 0.6562\n",
            "Epoch 617/1000\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.5288 - acc: 0.7371 - val_loss: 0.6763 - val_acc: 0.6667\n",
            "Epoch 618/1000\n",
            "37/37 [==============================] - 10s 248ms/step - loss: 0.5111 - acc: 0.7337 - val_loss: 0.6774 - val_acc: 0.6458\n",
            "Epoch 619/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.5106 - acc: 0.7423 - val_loss: 0.6750 - val_acc: 0.6458\n",
            "Epoch 620/1000\n",
            "37/37 [==============================] - 10s 252ms/step - loss: 0.5166 - acc: 0.7680 - val_loss: 0.6706 - val_acc: 0.6562\n",
            "Epoch 621/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5070 - acc: 0.7405 - val_loss: 0.6714 - val_acc: 0.6562\n",
            "Epoch 622/1000\n",
            "37/37 [==============================] - 7s 154ms/step - loss: 0.5273 - acc: 0.7354 - val_loss: 0.6863 - val_acc: 0.6562\n",
            "Epoch 623/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.4789 - acc: 0.7680 - val_loss: 0.6762 - val_acc: 0.6562\n",
            "Epoch 624/1000\n",
            "37/37 [==============================] - 5s 109ms/step - loss: 0.5524 - acc: 0.7079 - val_loss: 0.6767 - val_acc: 0.6354\n",
            "Epoch 625/1000\n",
            "37/37 [==============================] - 10s 248ms/step - loss: 0.4977 - acc: 0.7491 - val_loss: 0.6646 - val_acc: 0.6458\n",
            "Epoch 626/1000\n",
            "37/37 [==============================] - 5s 117ms/step - loss: 0.5109 - acc: 0.7526 - val_loss: 0.6555 - val_acc: 0.6562\n",
            "Epoch 627/1000\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.4911 - acc: 0.7749 - val_loss: 0.6653 - val_acc: 0.6458\n",
            "Epoch 628/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.5020 - acc: 0.7474 - val_loss: 0.6515 - val_acc: 0.6562\n",
            "Epoch 629/1000\n",
            "37/37 [==============================] - 5s 114ms/step - loss: 0.5013 - acc: 0.7526 - val_loss: 0.6606 - val_acc: 0.6562\n",
            "Epoch 630/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.4950 - acc: 0.7440 - val_loss: 0.6563 - val_acc: 0.6562\n",
            "Epoch 631/1000\n",
            "37/37 [==============================] - 6s 141ms/step - loss: 0.5100 - acc: 0.7491 - val_loss: 0.6611 - val_acc: 0.6458\n",
            "Epoch 632/1000\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.5163 - acc: 0.7440 - val_loss: 0.6603 - val_acc: 0.6562\n",
            "Epoch 633/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.5309 - acc: 0.7337 - val_loss: 0.6598 - val_acc: 0.6458\n",
            "Epoch 634/1000\n",
            "37/37 [==============================] - 5s 118ms/step - loss: 0.5137 - acc: 0.7577 - val_loss: 0.6812 - val_acc: 0.6562\n",
            "Epoch 635/1000\n",
            "37/37 [==============================] - 10s 241ms/step - loss: 0.5324 - acc: 0.7371 - val_loss: 0.6610 - val_acc: 0.6667\n",
            "Epoch 636/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 0.5352 - acc: 0.7297 - val_loss: 0.6677 - val_acc: 0.6562\n",
            "Epoch 637/1000\n",
            "37/37 [==============================] - 9s 239ms/step - loss: 0.5073 - acc: 0.7457 - val_loss: 0.6665 - val_acc: 0.6562\n",
            "Epoch 638/1000\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.4954 - acc: 0.7612 - val_loss: 0.6595 - val_acc: 0.6562\n",
            "Epoch 639/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.4731 - acc: 0.7595 - val_loss: 0.6691 - val_acc: 0.6458\n",
            "Epoch 640/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.4973 - acc: 0.7388 - val_loss: 0.6591 - val_acc: 0.6562\n",
            "Epoch 641/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.4771 - acc: 0.7732 - val_loss: 0.6689 - val_acc: 0.6562\n",
            "Epoch 642/1000\n",
            "37/37 [==============================] - 5s 120ms/step - loss: 0.5313 - acc: 0.7199 - val_loss: 0.6621 - val_acc: 0.6562\n",
            "Epoch 643/1000\n",
            "37/37 [==============================] - 5s 101ms/step - loss: 0.5213 - acc: 0.7337 - val_loss: 0.6667 - val_acc: 0.6562\n",
            "Epoch 644/1000\n",
            "37/37 [==============================] - 5s 97ms/step - loss: 0.5197 - acc: 0.7440 - val_loss: 0.6621 - val_acc: 0.6562\n",
            "Epoch 645/1000\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.5256 - acc: 0.7320 - val_loss: 0.6675 - val_acc: 0.6771\n",
            "Epoch 646/1000\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 0.4683 - acc: 0.7818 - val_loss: 0.6664 - val_acc: 0.6667\n",
            "Epoch 647/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.4990 - acc: 0.7595 - val_loss: 0.6627 - val_acc: 0.6562\n",
            "Epoch 648/1000\n",
            "37/37 [==============================] - 5s 116ms/step - loss: 0.5161 - acc: 0.7457 - val_loss: 0.6811 - val_acc: 0.6562\n",
            "Epoch 649/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.4975 - acc: 0.7595 - val_loss: 0.6838 - val_acc: 0.6562\n",
            "Epoch 650/1000\n",
            "37/37 [==============================] - 5s 115ms/step - loss: 0.5131 - acc: 0.7646 - val_loss: 0.6813 - val_acc: 0.6458\n",
            "Epoch 651/1000\n",
            "37/37 [==============================] - 10s 245ms/step - loss: 0.4995 - acc: 0.7371 - val_loss: 0.6777 - val_acc: 0.6771\n",
            "Epoch 652/1000\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.4977 - acc: 0.7509 - val_loss: 0.6822 - val_acc: 0.6562\n",
            "Epoch 653/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5074 - acc: 0.7543 - val_loss: 0.6813 - val_acc: 0.6562\n",
            "Epoch 654/1000\n",
            "37/37 [==============================] - 5s 113ms/step - loss: 0.5027 - acc: 0.7577 - val_loss: 0.6820 - val_acc: 0.6354\n",
            "Epoch 655/1000\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.5212 - acc: 0.7354 - val_loss: 0.6797 - val_acc: 0.6354\n",
            "Epoch 656/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.5082 - acc: 0.7382 - val_loss: 0.6808 - val_acc: 0.6458\n",
            "Epoch 657/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.5112 - acc: 0.7268 - val_loss: 0.6533 - val_acc: 0.6771\n",
            "Epoch 658/1000\n",
            "37/37 [==============================] - 10s 245ms/step - loss: 0.5112 - acc: 0.7680 - val_loss: 0.6882 - val_acc: 0.6458\n",
            "Epoch 659/1000\n",
            "37/37 [==============================] - 6s 149ms/step - loss: 0.5198 - acc: 0.7440 - val_loss: 0.6792 - val_acc: 0.6562\n",
            "Epoch 660/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.4848 - acc: 0.7732 - val_loss: 0.6446 - val_acc: 0.6771\n",
            "Epoch 661/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 0.5129 - acc: 0.7423 - val_loss: 0.6736 - val_acc: 0.6562\n",
            "Epoch 662/1000\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 0.4890 - acc: 0.7543 - val_loss: 0.6648 - val_acc: 0.6562\n",
            "Epoch 663/1000\n",
            "37/37 [==============================] - 9s 242ms/step - loss: 0.5184 - acc: 0.7509 - val_loss: 0.6738 - val_acc: 0.6354\n",
            "Epoch 664/1000\n",
            "37/37 [==============================] - 5s 113ms/step - loss: 0.5006 - acc: 0.7663 - val_loss: 0.6462 - val_acc: 0.6667\n",
            "Epoch 665/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.5030 - acc: 0.7560 - val_loss: 0.6459 - val_acc: 0.6667\n",
            "Epoch 666/1000\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 0.5282 - acc: 0.7509 - val_loss: 0.6636 - val_acc: 0.6562\n",
            "Epoch 667/1000\n",
            "37/37 [==============================] - 10s 253ms/step - loss: 0.5255 - acc: 0.7457 - val_loss: 0.6655 - val_acc: 0.6458\n",
            "Epoch 668/1000\n",
            "37/37 [==============================] - 9s 242ms/step - loss: 0.4936 - acc: 0.7526 - val_loss: 0.6382 - val_acc: 0.6562\n",
            "Epoch 669/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5155 - acc: 0.7526 - val_loss: 0.6665 - val_acc: 0.6458\n",
            "Epoch 670/1000\n",
            "37/37 [==============================] - 10s 247ms/step - loss: 0.4783 - acc: 0.7680 - val_loss: 0.6515 - val_acc: 0.6667\n",
            "Epoch 671/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.5236 - acc: 0.7354 - val_loss: 0.6627 - val_acc: 0.6458\n",
            "Epoch 672/1000\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.4763 - acc: 0.7612 - val_loss: 0.6571 - val_acc: 0.6458\n",
            "Epoch 673/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.4626 - acc: 0.7801 - val_loss: 0.6547 - val_acc: 0.6458\n",
            "Epoch 674/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.4778 - acc: 0.7852 - val_loss: 0.6502 - val_acc: 0.6667\n",
            "Epoch 675/1000\n",
            "37/37 [==============================] - 10s 246ms/step - loss: 0.4801 - acc: 0.7595 - val_loss: 0.6620 - val_acc: 0.6458\n",
            "Epoch 676/1000\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 0.4945 - acc: 0.7405 - val_loss: 0.6458 - val_acc: 0.6667\n",
            "Epoch 677/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.4942 - acc: 0.7474 - val_loss: 0.6456 - val_acc: 0.6667\n",
            "Epoch 678/1000\n",
            "37/37 [==============================] - 10s 248ms/step - loss: 0.5269 - acc: 0.7216 - val_loss: 0.6719 - val_acc: 0.6562\n",
            "Epoch 679/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.4832 - acc: 0.7835 - val_loss: 0.6725 - val_acc: 0.6562\n",
            "Epoch 680/1000\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.5130 - acc: 0.7612 - val_loss: 0.6659 - val_acc: 0.6562\n",
            "Epoch 681/1000\n",
            "37/37 [==============================] - 5s 114ms/step - loss: 0.5088 - acc: 0.7423 - val_loss: 0.6717 - val_acc: 0.6562\n",
            "Epoch 682/1000\n",
            "37/37 [==============================] - 5s 114ms/step - loss: 0.4813 - acc: 0.7887 - val_loss: 0.6648 - val_acc: 0.6458\n",
            "Epoch 683/1000\n",
            "37/37 [==============================] - 10s 240ms/step - loss: 0.5195 - acc: 0.7595 - val_loss: 0.6633 - val_acc: 0.6562\n",
            "Epoch 684/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.5181 - acc: 0.7337 - val_loss: 0.6517 - val_acc: 0.6771\n",
            "Epoch 685/1000\n",
            "37/37 [==============================] - 5s 113ms/step - loss: 0.5032 - acc: 0.7560 - val_loss: 0.6727 - val_acc: 0.6667\n",
            "Epoch 686/1000\n",
            "37/37 [==============================] - 10s 252ms/step - loss: 0.4988 - acc: 0.7474 - val_loss: 0.6763 - val_acc: 0.6771\n",
            "Epoch 687/1000\n",
            "37/37 [==============================] - 9s 245ms/step - loss: 0.4832 - acc: 0.7612 - val_loss: 0.6734 - val_acc: 0.6667\n",
            "Epoch 688/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.4738 - acc: 0.7698 - val_loss: 0.6807 - val_acc: 0.6562\n",
            "Epoch 689/1000\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 0.5300 - acc: 0.7337 - val_loss: 0.6831 - val_acc: 0.6667\n",
            "Epoch 690/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.5015 - acc: 0.7577 - val_loss: 0.6774 - val_acc: 0.6458\n",
            "Epoch 691/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.5255 - acc: 0.7577 - val_loss: 0.6625 - val_acc: 0.6667\n",
            "Epoch 692/1000\n",
            "37/37 [==============================] - 9s 241ms/step - loss: 0.5186 - acc: 0.7491 - val_loss: 0.6796 - val_acc: 0.6562\n",
            "Epoch 693/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.4859 - acc: 0.7698 - val_loss: 0.6892 - val_acc: 0.6562\n",
            "Epoch 694/1000\n",
            "37/37 [==============================] - 10s 248ms/step - loss: 0.5120 - acc: 0.7371 - val_loss: 0.6552 - val_acc: 0.6562\n",
            "Epoch 695/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.4983 - acc: 0.7543 - val_loss: 0.6742 - val_acc: 0.6354\n",
            "Epoch 696/1000\n",
            "37/37 [==============================] - 9s 228ms/step - loss: 0.5125 - acc: 0.7388 - val_loss: 0.6825 - val_acc: 0.6354\n",
            "Epoch 697/1000\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.5286 - acc: 0.7320 - val_loss: 0.6870 - val_acc: 0.6354\n",
            "Epoch 698/1000\n",
            "37/37 [==============================] - 10s 236ms/step - loss: 0.5097 - acc: 0.7432 - val_loss: 0.6710 - val_acc: 0.6562\n",
            "Epoch 699/1000\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.5020 - acc: 0.7517 - val_loss: 0.6768 - val_acc: 0.6458\n",
            "Epoch 700/1000\n",
            "37/37 [==============================] - 9s 239ms/step - loss: 0.4993 - acc: 0.7612 - val_loss: 0.6815 - val_acc: 0.6562\n",
            "Epoch 701/1000\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.4988 - acc: 0.7686 - val_loss: 0.6768 - val_acc: 0.6354\n",
            "Epoch 702/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.5014 - acc: 0.7749 - val_loss: 0.6523 - val_acc: 0.6667\n",
            "Epoch 703/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.5122 - acc: 0.7680 - val_loss: 0.6503 - val_acc: 0.6667\n",
            "Epoch 704/1000\n",
            "37/37 [==============================] - 10s 253ms/step - loss: 0.4853 - acc: 0.7612 - val_loss: 0.6861 - val_acc: 0.6354\n",
            "Epoch 705/1000\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.5163 - acc: 0.7526 - val_loss: 0.6572 - val_acc: 0.6562\n",
            "Epoch 706/1000\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.5356 - acc: 0.7388 - val_loss: 0.6724 - val_acc: 0.6458\n",
            "Epoch 707/1000\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 0.5191 - acc: 0.7595 - val_loss: 0.6669 - val_acc: 0.6458\n",
            "Epoch 708/1000\n",
            "37/37 [==============================] - 5s 116ms/step - loss: 0.4950 - acc: 0.7491 - val_loss: 0.6849 - val_acc: 0.6354\n",
            "Epoch 709/1000\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.5212 - acc: 0.7371 - val_loss: 0.6727 - val_acc: 0.6458\n",
            "Epoch 710/1000\n",
            "37/37 [==============================] - 10s 252ms/step - loss: 0.5403 - acc: 0.7474 - val_loss: 0.6487 - val_acc: 0.6667\n",
            "Epoch 711/1000\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.4902 - acc: 0.7646 - val_loss: 0.6773 - val_acc: 0.6354\n",
            "Epoch 712/1000\n",
            "37/37 [==============================] - 5s 107ms/step - loss: 0.4998 - acc: 0.7560 - val_loss: 0.6599 - val_acc: 0.6562\n",
            "Epoch 713/1000\n",
            "37/37 [==============================] - 9s 241ms/step - loss: 0.5109 - acc: 0.7365 - val_loss: 0.6393 - val_acc: 0.6771\n",
            "Epoch 714/1000\n",
            "37/37 [==============================] - 5s 112ms/step - loss: 0.5001 - acc: 0.7732 - val_loss: 0.6670 - val_acc: 0.6250\n",
            "Epoch 715/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5231 - acc: 0.7354 - val_loss: 0.6437 - val_acc: 0.6667\n",
            "Epoch 716/1000\n",
            "37/37 [==============================] - 6s 121ms/step - loss: 0.4639 - acc: 0.7698 - val_loss: 0.6736 - val_acc: 0.6250\n",
            "Epoch 717/1000\n",
            "37/37 [==============================] - 5s 102ms/step - loss: 0.5410 - acc: 0.7337 - val_loss: 0.6739 - val_acc: 0.6458\n",
            "Epoch 718/1000\n",
            "37/37 [==============================] - 6s 131ms/step - loss: 0.4877 - acc: 0.7423 - val_loss: 0.6515 - val_acc: 0.6354\n",
            "Epoch 719/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.5205 - acc: 0.7388 - val_loss: 0.6631 - val_acc: 0.6354\n",
            "Epoch 720/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 0.5093 - acc: 0.7388 - val_loss: 0.6539 - val_acc: 0.6458\n",
            "Epoch 721/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.5121 - acc: 0.7423 - val_loss: 0.6747 - val_acc: 0.6458\n",
            "Epoch 722/1000\n",
            "37/37 [==============================] - 10s 250ms/step - loss: 0.5245 - acc: 0.7449 - val_loss: 0.6640 - val_acc: 0.6354\n",
            "Epoch 723/1000\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.5048 - acc: 0.7371 - val_loss: 0.6557 - val_acc: 0.6667\n",
            "Epoch 724/1000\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 0.5108 - acc: 0.7440 - val_loss: 0.6719 - val_acc: 0.6146\n",
            "Epoch 725/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.5068 - acc: 0.7749 - val_loss: 0.6574 - val_acc: 0.6458\n",
            "Epoch 726/1000\n",
            "37/37 [==============================] - 10s 255ms/step - loss: 0.4962 - acc: 0.7629 - val_loss: 0.6520 - val_acc: 0.6354\n",
            "Epoch 727/1000\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 0.4563 - acc: 0.7973 - val_loss: 0.6589 - val_acc: 0.6562\n",
            "Epoch 728/1000\n",
            "37/37 [==============================] - 9s 241ms/step - loss: 0.5121 - acc: 0.7457 - val_loss: 0.6513 - val_acc: 0.6667\n",
            "Epoch 729/1000\n",
            "37/37 [==============================] - 5s 107ms/step - loss: 0.5038 - acc: 0.7595 - val_loss: 0.6540 - val_acc: 0.6562\n",
            "Epoch 730/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.5042 - acc: 0.7302 - val_loss: 0.6607 - val_acc: 0.6562\n",
            "Epoch 731/1000\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 0.5146 - acc: 0.7405 - val_loss: 0.6732 - val_acc: 0.6354\n",
            "Epoch 732/1000\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 0.4902 - acc: 0.7577 - val_loss: 0.6657 - val_acc: 0.6458\n",
            "Epoch 733/1000\n",
            "37/37 [==============================] - 5s 103ms/step - loss: 0.5322 - acc: 0.7182 - val_loss: 0.6858 - val_acc: 0.6354\n",
            "Epoch 734/1000\n",
            "37/37 [==============================] - 5s 115ms/step - loss: 0.5397 - acc: 0.7162 - val_loss: 0.6418 - val_acc: 0.6771\n",
            "Epoch 735/1000\n",
            "37/37 [==============================] - 10s 251ms/step - loss: 0.4789 - acc: 0.7646 - val_loss: 0.6658 - val_acc: 0.6458\n",
            "Epoch 736/1000\n",
            "37/37 [==============================] - 9s 245ms/step - loss: 0.5232 - acc: 0.7509 - val_loss: 0.6545 - val_acc: 0.6562\n",
            "Epoch 737/1000\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.4796 - acc: 0.7766 - val_loss: 0.6841 - val_acc: 0.6458\n",
            "Epoch 738/1000\n",
            "37/37 [==============================] - 5s 111ms/step - loss: 0.4899 - acc: 0.7595 - val_loss: 0.6630 - val_acc: 0.6562\n",
            "Epoch 739/1000\n",
            "37/37 [==============================] - 5s 109ms/step - loss: 0.5584 - acc: 0.7199 - val_loss: 0.6744 - val_acc: 0.6354\n",
            "Epoch 740/1000\n",
            "37/37 [==============================] - 5s 103ms/step - loss: 0.4730 - acc: 0.7835 - val_loss: 0.6430 - val_acc: 0.6458\n",
            "Epoch 741/1000\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 0.5057 - acc: 0.7526 - val_loss: 0.6592 - val_acc: 0.6458\n",
            "Epoch 742/1000\n",
            "37/37 [==============================] - 5s 110ms/step - loss: 0.5061 - acc: 0.7474 - val_loss: 0.6668 - val_acc: 0.6562\n",
            "Epoch 743/1000\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 0.5088 - acc: 0.7371 - val_loss: 0.6484 - val_acc: 0.6562\n",
            "Epoch 744/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 0.5149 - acc: 0.7320 - val_loss: 0.6545 - val_acc: 0.6562\n",
            "Epoch 745/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.5008 - acc: 0.7354 - val_loss: 0.6490 - val_acc: 0.6667\n",
            "Epoch 746/1000\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 0.4987 - acc: 0.7474 - val_loss: 0.6706 - val_acc: 0.6354\n",
            "Epoch 747/1000\n",
            "37/37 [==============================] - 5s 116ms/step - loss: 0.5314 - acc: 0.7285 - val_loss: 0.6534 - val_acc: 0.6562\n",
            "Epoch 748/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.5185 - acc: 0.7526 - val_loss: 0.6497 - val_acc: 0.6667\n",
            "Epoch 749/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.5278 - acc: 0.7354 - val_loss: 0.6562 - val_acc: 0.6562\n",
            "Epoch 750/1000\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.4886 - acc: 0.7663 - val_loss: 0.6551 - val_acc: 0.6354\n",
            "Epoch 751/1000\n",
            "37/37 [==============================] - 9s 244ms/step - loss: 0.5190 - acc: 0.7251 - val_loss: 0.6579 - val_acc: 0.6354\n",
            "Epoch 752/1000\n",
            "37/37 [==============================] - 10s 253ms/step - loss: 0.5039 - acc: 0.7560 - val_loss: 0.6690 - val_acc: 0.6354\n",
            "Epoch 753/1000\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 0.5181 - acc: 0.7405 - val_loss: 0.6537 - val_acc: 0.6667\n",
            "Epoch 754/1000\n",
            "37/37 [==============================] - 10s 245ms/step - loss: 0.4969 - acc: 0.7474 - val_loss: 0.6573 - val_acc: 0.6562\n",
            "Epoch 755/1000\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.5169 - acc: 0.7314 - val_loss: 0.6515 - val_acc: 0.6562\n",
            "Epoch 756/1000\n",
            "37/37 [==============================] - 5s 111ms/step - loss: 0.4972 - acc: 0.7577 - val_loss: 0.6602 - val_acc: 0.6458\n",
            "Epoch 757/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.5384 - acc: 0.7440 - val_loss: 0.6474 - val_acc: 0.6458\n",
            "Epoch 758/1000\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.5160 - acc: 0.7354 - val_loss: 0.6677 - val_acc: 0.6354\n",
            "Epoch 759/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.5190 - acc: 0.7560 - val_loss: 0.6382 - val_acc: 0.6667\n",
            "Epoch 760/1000\n",
            "37/37 [==============================] - 5s 109ms/step - loss: 0.5599 - acc: 0.7010 - val_loss: 0.6611 - val_acc: 0.6354\n",
            "Epoch 761/1000\n",
            "37/37 [==============================] - 10s 251ms/step - loss: 0.4989 - acc: 0.7577 - val_loss: 0.6634 - val_acc: 0.6458\n",
            "Epoch 762/1000\n",
            "37/37 [==============================] - 5s 110ms/step - loss: 0.4966 - acc: 0.7646 - val_loss: 0.6719 - val_acc: 0.6458\n",
            "Epoch 763/1000\n",
            "37/37 [==============================] - 6s 154ms/step - loss: 0.5091 - acc: 0.7371 - val_loss: 0.6670 - val_acc: 0.6667\n",
            "Epoch 764/1000\n",
            "37/37 [==============================] - 5s 113ms/step - loss: 0.5343 - acc: 0.7182 - val_loss: 0.6467 - val_acc: 0.6562\n",
            "Epoch 765/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.5390 - acc: 0.7302 - val_loss: 0.6368 - val_acc: 0.6667\n",
            "Epoch 766/1000\n",
            "37/37 [==============================] - 5s 116ms/step - loss: 0.5116 - acc: 0.7337 - val_loss: 0.6549 - val_acc: 0.6562\n",
            "Epoch 767/1000\n",
            "37/37 [==============================] - 6s 141ms/step - loss: 0.4943 - acc: 0.7646 - val_loss: 0.6533 - val_acc: 0.6354\n",
            "Epoch 768/1000\n",
            "37/37 [==============================] - 5s 112ms/step - loss: 0.5068 - acc: 0.7612 - val_loss: 0.6403 - val_acc: 0.6771\n",
            "Epoch 769/1000\n",
            "37/37 [==============================] - 5s 109ms/step - loss: 0.4998 - acc: 0.7577 - val_loss: 0.6572 - val_acc: 0.6458\n",
            "Epoch 770/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 0.5165 - acc: 0.7405 - val_loss: 0.6736 - val_acc: 0.6458\n",
            "Epoch 771/1000\n",
            "37/37 [==============================] - 5s 109ms/step - loss: 0.4786 - acc: 0.7646 - val_loss: 0.6476 - val_acc: 0.6667\n",
            "Epoch 772/1000\n",
            "37/37 [==============================] - 6s 126ms/step - loss: 0.5180 - acc: 0.7216 - val_loss: 0.6647 - val_acc: 0.6458\n",
            "Epoch 773/1000\n",
            "37/37 [==============================] - 10s 249ms/step - loss: 0.4904 - acc: 0.7663 - val_loss: 0.6592 - val_acc: 0.6458\n",
            "Epoch 774/1000\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.5232 - acc: 0.7491 - val_loss: 0.6747 - val_acc: 0.6354\n",
            "Epoch 775/1000\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.4930 - acc: 0.7595 - val_loss: 0.6407 - val_acc: 0.6667\n",
            "Epoch 776/1000\n",
            "37/37 [==============================] - 10s 241ms/step - loss: 0.5320 - acc: 0.7440 - val_loss: 0.6480 - val_acc: 0.6667\n",
            "Epoch 777/1000\n",
            "37/37 [==============================] - 6s 146ms/step - loss: 0.4856 - acc: 0.7543 - val_loss: 0.6509 - val_acc: 0.6562\n",
            "Epoch 778/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.4847 - acc: 0.7663 - val_loss: 0.6621 - val_acc: 0.6458\n",
            "Epoch 779/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 0.4868 - acc: 0.7388 - val_loss: 0.6748 - val_acc: 0.6458\n",
            "Epoch 780/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.5209 - acc: 0.7601 - val_loss: 0.6750 - val_acc: 0.6458\n",
            "Epoch 781/1000\n",
            "37/37 [==============================] - 9s 242ms/step - loss: 0.4980 - acc: 0.7595 - val_loss: 0.6590 - val_acc: 0.6562\n",
            "Epoch 782/1000\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.5223 - acc: 0.7423 - val_loss: 0.6677 - val_acc: 0.6354\n",
            "Epoch 783/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.4794 - acc: 0.7766 - val_loss: 0.6618 - val_acc: 0.6667\n",
            "Epoch 784/1000\n",
            "37/37 [==============================] - 6s 138ms/step - loss: 0.4980 - acc: 0.7646 - val_loss: 0.6557 - val_acc: 0.6562\n",
            "Epoch 785/1000\n",
            "37/37 [==============================] - 5s 118ms/step - loss: 0.5400 - acc: 0.7457 - val_loss: 0.6633 - val_acc: 0.6458\n",
            "Epoch 786/1000\n",
            "37/37 [==============================] - 10s 251ms/step - loss: 0.4963 - acc: 0.7577 - val_loss: 0.6545 - val_acc: 0.6667\n",
            "Epoch 787/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.5658 - acc: 0.7216 - val_loss: 0.6740 - val_acc: 0.6458\n",
            "Epoch 788/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.4982 - acc: 0.7440 - val_loss: 0.6417 - val_acc: 0.6667\n",
            "Epoch 789/1000\n",
            "37/37 [==============================] - 9s 242ms/step - loss: 0.5052 - acc: 0.7500 - val_loss: 0.6749 - val_acc: 0.6458\n",
            "Epoch 790/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 0.5201 - acc: 0.7612 - val_loss: 0.6705 - val_acc: 0.6562\n",
            "Epoch 791/1000\n",
            "37/37 [==============================] - 9s 244ms/step - loss: 0.5105 - acc: 0.7612 - val_loss: 0.6501 - val_acc: 0.6667\n",
            "Epoch 792/1000\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 0.4901 - acc: 0.7577 - val_loss: 0.6818 - val_acc: 0.6562\n",
            "Epoch 793/1000\n",
            "37/37 [==============================] - 10s 247ms/step - loss: 0.5498 - acc: 0.7216 - val_loss: 0.6787 - val_acc: 0.6458\n",
            "Epoch 794/1000\n",
            "37/37 [==============================] - 5s 114ms/step - loss: 0.5103 - acc: 0.7577 - val_loss: 0.6867 - val_acc: 0.6458\n",
            "Epoch 795/1000\n",
            "37/37 [==============================] - 10s 243ms/step - loss: 0.5218 - acc: 0.7251 - val_loss: 0.6586 - val_acc: 0.6667\n",
            "Epoch 796/1000\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.4965 - acc: 0.7543 - val_loss: 0.6680 - val_acc: 0.6562\n",
            "Epoch 797/1000\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 0.5129 - acc: 0.7491 - val_loss: 0.6460 - val_acc: 0.6667\n",
            "Epoch 798/1000\n",
            "37/37 [==============================] - 10s 266ms/step - loss: 0.5300 - acc: 0.7423 - val_loss: 0.6584 - val_acc: 0.6562\n",
            "Epoch 799/1000\n",
            "37/37 [==============================] - 9s 243ms/step - loss: 0.4953 - acc: 0.7732 - val_loss: 0.6504 - val_acc: 0.6562\n",
            "Epoch 800/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.4882 - acc: 0.7715 - val_loss: 0.6567 - val_acc: 0.6667\n",
            "Epoch 801/1000\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.4804 - acc: 0.7612 - val_loss: 0.6603 - val_acc: 0.6667\n",
            "Epoch 802/1000\n",
            "37/37 [==============================] - 6s 142ms/step - loss: 0.4524 - acc: 0.7784 - val_loss: 0.6590 - val_acc: 0.6667\n",
            "Epoch 803/1000\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.4931 - acc: 0.7595 - val_loss: 0.6585 - val_acc: 0.6667\n",
            "Epoch 804/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.5228 - acc: 0.7543 - val_loss: 0.6594 - val_acc: 0.6667\n",
            "Epoch 805/1000\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 0.4983 - acc: 0.7337 - val_loss: 0.6556 - val_acc: 0.6562\n",
            "Epoch 806/1000\n",
            "37/37 [==============================] - 9s 242ms/step - loss: 0.4773 - acc: 0.7732 - val_loss: 0.6709 - val_acc: 0.6562\n",
            "Epoch 807/1000\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.5011 - acc: 0.7491 - val_loss: 0.6599 - val_acc: 0.6458\n",
            "Epoch 808/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 0.5208 - acc: 0.7560 - val_loss: 0.6603 - val_acc: 0.6562\n",
            "Epoch 809/1000\n",
            "37/37 [==============================] - 9s 243ms/step - loss: 0.5131 - acc: 0.7371 - val_loss: 0.6666 - val_acc: 0.6458\n",
            "Epoch 810/1000\n",
            "37/37 [==============================] - 5s 114ms/step - loss: 0.4723 - acc: 0.7955 - val_loss: 0.6572 - val_acc: 0.6458\n",
            "Epoch 811/1000\n",
            "37/37 [==============================] - 6s 144ms/step - loss: 0.5000 - acc: 0.7680 - val_loss: 0.6634 - val_acc: 0.6667\n",
            "Epoch 812/1000\n",
            "37/37 [==============================] - 9s 241ms/step - loss: 0.4789 - acc: 0.7732 - val_loss: 0.6659 - val_acc: 0.6354\n",
            "Epoch 813/1000\n",
            "37/37 [==============================] - 10s 268ms/step - loss: 0.4736 - acc: 0.7629 - val_loss: 0.6758 - val_acc: 0.6458\n",
            "Epoch 814/1000\n",
            "37/37 [==============================] - 6s 141ms/step - loss: 0.4979 - acc: 0.7371 - val_loss: 0.6540 - val_acc: 0.6667\n",
            "Epoch 815/1000\n",
            "37/37 [==============================] - 10s 250ms/step - loss: 0.5101 - acc: 0.7405 - val_loss: 0.6641 - val_acc: 0.6458\n",
            "Epoch 816/1000\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.4945 - acc: 0.7526 - val_loss: 0.6744 - val_acc: 0.6458\n",
            "Epoch 817/1000\n",
            "37/37 [==============================] - 10s 243ms/step - loss: 0.5149 - acc: 0.7354 - val_loss: 0.6730 - val_acc: 0.6354\n",
            "Epoch 818/1000\n",
            "37/37 [==============================] - 7s 165ms/step - loss: 0.5023 - acc: 0.7526 - val_loss: 0.6658 - val_acc: 0.6458\n",
            "Epoch 819/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.5312 - acc: 0.7199 - val_loss: 0.6571 - val_acc: 0.6771\n",
            "Epoch 820/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 0.5119 - acc: 0.7526 - val_loss: 0.6599 - val_acc: 0.6771\n",
            "Epoch 821/1000\n",
            "37/37 [==============================] - 10s 249ms/step - loss: 0.4904 - acc: 0.7680 - val_loss: 0.6647 - val_acc: 0.6458\n",
            "Epoch 822/1000\n",
            "37/37 [==============================] - 5s 110ms/step - loss: 0.5244 - acc: 0.7320 - val_loss: 0.6613 - val_acc: 0.6667\n",
            "Epoch 823/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 0.4799 - acc: 0.7663 - val_loss: 0.6652 - val_acc: 0.6562\n",
            "Epoch 824/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.4943 - acc: 0.7543 - val_loss: 0.6616 - val_acc: 0.6354\n",
            "Epoch 825/1000\n",
            "37/37 [==============================] - 9s 241ms/step - loss: 0.5117 - acc: 0.7595 - val_loss: 0.6505 - val_acc: 0.6667\n",
            "Epoch 826/1000\n",
            "37/37 [==============================] - 10s 261ms/step - loss: 0.5033 - acc: 0.7440 - val_loss: 0.6624 - val_acc: 0.6562\n",
            "Epoch 827/1000\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.5378 - acc: 0.7560 - val_loss: 0.6449 - val_acc: 0.6562\n",
            "Epoch 828/1000\n",
            "37/37 [==============================] - 5s 112ms/step - loss: 0.5050 - acc: 0.7491 - val_loss: 0.6501 - val_acc: 0.6562\n",
            "Epoch 829/1000\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.4917 - acc: 0.7629 - val_loss: 0.6745 - val_acc: 0.6458\n",
            "Epoch 830/1000\n",
            "37/37 [==============================] - 6s 151ms/step - loss: 0.5065 - acc: 0.7302 - val_loss: 0.6660 - val_acc: 0.6458\n",
            "Epoch 831/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.4786 - acc: 0.7646 - val_loss: 0.6622 - val_acc: 0.6667\n",
            "Epoch 832/1000\n",
            "37/37 [==============================] - 5s 116ms/step - loss: 0.5153 - acc: 0.7474 - val_loss: 0.6650 - val_acc: 0.6562\n",
            "Epoch 833/1000\n",
            "37/37 [==============================] - 10s 243ms/step - loss: 0.5219 - acc: 0.7354 - val_loss: 0.6591 - val_acc: 0.6667\n",
            "Epoch 834/1000\n",
            "37/37 [==============================] - 10s 252ms/step - loss: 0.4859 - acc: 0.7629 - val_loss: 0.6370 - val_acc: 0.6667\n",
            "Epoch 835/1000\n",
            "37/37 [==============================] - 9s 241ms/step - loss: 0.5526 - acc: 0.7302 - val_loss: 0.6360 - val_acc: 0.6562\n",
            "Epoch 836/1000\n",
            "37/37 [==============================] - 9s 242ms/step - loss: 0.4810 - acc: 0.7595 - val_loss: 0.6633 - val_acc: 0.6458\n",
            "Epoch 837/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.5198 - acc: 0.7371 - val_loss: 0.6772 - val_acc: 0.6354\n",
            "Epoch 838/1000\n",
            "37/37 [==============================] - 6s 133ms/step - loss: 0.5214 - acc: 0.7337 - val_loss: 0.6592 - val_acc: 0.6562\n",
            "Epoch 839/1000\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 0.5056 - acc: 0.7577 - val_loss: 0.6660 - val_acc: 0.6458\n",
            "Epoch 840/1000\n",
            "37/37 [==============================] - 5s 109ms/step - loss: 0.5296 - acc: 0.7371 - val_loss: 0.6650 - val_acc: 0.6354\n",
            "Epoch 841/1000\n",
            "37/37 [==============================] - 10s 250ms/step - loss: 0.5286 - acc: 0.7405 - val_loss: 0.6648 - val_acc: 0.6354\n",
            "Epoch 842/1000\n",
            "37/37 [==============================] - 9s 241ms/step - loss: 0.4976 - acc: 0.7680 - val_loss: 0.6536 - val_acc: 0.6771\n",
            "Epoch 843/1000\n",
            "37/37 [==============================] - 9s 242ms/step - loss: 0.4906 - acc: 0.7543 - val_loss: 0.6680 - val_acc: 0.6458\n",
            "Epoch 844/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 0.5541 - acc: 0.7062 - val_loss: 0.6691 - val_acc: 0.6562\n",
            "Epoch 845/1000\n",
            "37/37 [==============================] - 9s 239ms/step - loss: 0.5277 - acc: 0.7423 - val_loss: 0.6560 - val_acc: 0.6562\n",
            "Epoch 846/1000\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.5365 - acc: 0.7440 - val_loss: 0.6639 - val_acc: 0.6354\n",
            "Epoch 847/1000\n",
            "37/37 [==============================] - 5s 104ms/step - loss: 0.5317 - acc: 0.7216 - val_loss: 0.6671 - val_acc: 0.6458\n",
            "Epoch 848/1000\n",
            "37/37 [==============================] - 10s 242ms/step - loss: 0.5594 - acc: 0.7165 - val_loss: 0.6626 - val_acc: 0.6458\n",
            "Epoch 849/1000\n",
            "37/37 [==============================] - 10s 248ms/step - loss: 0.4469 - acc: 0.7921 - val_loss: 0.6533 - val_acc: 0.6562\n",
            "Epoch 850/1000\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 0.5328 - acc: 0.7337 - val_loss: 0.6668 - val_acc: 0.6458\n",
            "Epoch 851/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.5106 - acc: 0.7457 - val_loss: 0.6537 - val_acc: 0.6458\n",
            "Epoch 852/1000\n",
            "37/37 [==============================] - 10s 242ms/step - loss: 0.5039 - acc: 0.7595 - val_loss: 0.6492 - val_acc: 0.6562\n",
            "Epoch 853/1000\n",
            "37/37 [==============================] - 5s 112ms/step - loss: 0.5454 - acc: 0.7474 - val_loss: 0.6696 - val_acc: 0.6354\n",
            "Epoch 854/1000\n",
            "37/37 [==============================] - 5s 120ms/step - loss: 0.5091 - acc: 0.7629 - val_loss: 0.6659 - val_acc: 0.6562\n",
            "Epoch 855/1000\n",
            "37/37 [==============================] - 10s 239ms/step - loss: 0.4924 - acc: 0.7526 - val_loss: 0.6724 - val_acc: 0.6458\n",
            "Epoch 856/1000\n",
            "37/37 [==============================] - 5s 115ms/step - loss: 0.5221 - acc: 0.7440 - val_loss: 0.6422 - val_acc: 0.6562\n",
            "Epoch 857/1000\n",
            "37/37 [==============================] - 5s 115ms/step - loss: 0.5100 - acc: 0.7405 - val_loss: 0.6543 - val_acc: 0.6458\n",
            "Epoch 858/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.4788 - acc: 0.7612 - val_loss: 0.6595 - val_acc: 0.6250\n",
            "Epoch 859/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 0.5164 - acc: 0.7440 - val_loss: 0.6471 - val_acc: 0.6458\n",
            "Epoch 860/1000\n",
            "37/37 [==============================] - 9s 243ms/step - loss: 0.4482 - acc: 0.7766 - val_loss: 0.6674 - val_acc: 0.6458\n",
            "Epoch 861/1000\n",
            "37/37 [==============================] - 5s 109ms/step - loss: 0.5214 - acc: 0.7268 - val_loss: 0.6629 - val_acc: 0.6458\n",
            "Epoch 862/1000\n",
            "37/37 [==============================] - 5s 104ms/step - loss: 0.4751 - acc: 0.7509 - val_loss: 0.6642 - val_acc: 0.6458\n",
            "Epoch 863/1000\n",
            "37/37 [==============================] - 6s 134ms/step - loss: 0.5215 - acc: 0.7491 - val_loss: 0.6496 - val_acc: 0.6354\n",
            "Epoch 864/1000\n",
            "37/37 [==============================] - 5s 110ms/step - loss: 0.4962 - acc: 0.7680 - val_loss: 0.6562 - val_acc: 0.6667\n",
            "Epoch 865/1000\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.4986 - acc: 0.7646 - val_loss: 0.6653 - val_acc: 0.6354\n",
            "Epoch 866/1000\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 0.4920 - acc: 0.7612 - val_loss: 0.6550 - val_acc: 0.6562\n",
            "Epoch 867/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5261 - acc: 0.7320 - val_loss: 0.6509 - val_acc: 0.6562\n",
            "Epoch 868/1000\n",
            "37/37 [==============================] - 10s 250ms/step - loss: 0.4863 - acc: 0.7646 - val_loss: 0.6601 - val_acc: 0.6562\n",
            "Epoch 869/1000\n",
            "37/37 [==============================] - 9s 246ms/step - loss: 0.4912 - acc: 0.7388 - val_loss: 0.6598 - val_acc: 0.6667\n",
            "Epoch 870/1000\n",
            "37/37 [==============================] - 5s 110ms/step - loss: 0.4749 - acc: 0.7715 - val_loss: 0.6738 - val_acc: 0.6458\n",
            "Epoch 871/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 0.5478 - acc: 0.7320 - val_loss: 0.6431 - val_acc: 0.6667\n",
            "Epoch 872/1000\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 0.5089 - acc: 0.7595 - val_loss: 0.6647 - val_acc: 0.6458\n",
            "Epoch 873/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.5042 - acc: 0.7491 - val_loss: 0.6549 - val_acc: 0.6354\n",
            "Epoch 874/1000\n",
            "37/37 [==============================] - 10s 257ms/step - loss: 0.4805 - acc: 0.7852 - val_loss: 0.6530 - val_acc: 0.6562\n",
            "Epoch 875/1000\n",
            "37/37 [==============================] - 6s 138ms/step - loss: 0.5197 - acc: 0.7526 - val_loss: 0.6421 - val_acc: 0.6667\n",
            "Epoch 876/1000\n",
            "37/37 [==============================] - 9s 243ms/step - loss: 0.5118 - acc: 0.7560 - val_loss: 0.6519 - val_acc: 0.6354\n",
            "Epoch 877/1000\n",
            "37/37 [==============================] - 9s 239ms/step - loss: 0.5407 - acc: 0.7285 - val_loss: 0.6566 - val_acc: 0.6354\n",
            "Epoch 878/1000\n",
            "37/37 [==============================] - 10s 260ms/step - loss: 0.4780 - acc: 0.7663 - val_loss: 0.6483 - val_acc: 0.6458\n",
            "Epoch 879/1000\n",
            "37/37 [==============================] - 9s 241ms/step - loss: 0.4850 - acc: 0.7612 - val_loss: 0.6474 - val_acc: 0.6771\n",
            "Epoch 880/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.4778 - acc: 0.7663 - val_loss: 0.6473 - val_acc: 0.6667\n",
            "Epoch 881/1000\n",
            "37/37 [==============================] - 5s 110ms/step - loss: 0.5101 - acc: 0.7302 - val_loss: 0.6452 - val_acc: 0.6771\n",
            "Epoch 882/1000\n",
            "37/37 [==============================] - 10s 245ms/step - loss: 0.4914 - acc: 0.7509 - val_loss: 0.6612 - val_acc: 0.6562\n",
            "Epoch 883/1000\n",
            "37/37 [==============================] - 10s 248ms/step - loss: 0.5367 - acc: 0.7268 - val_loss: 0.6613 - val_acc: 0.6458\n",
            "Epoch 884/1000\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 0.4818 - acc: 0.7749 - val_loss: 0.6572 - val_acc: 0.6562\n",
            "Epoch 885/1000\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.5171 - acc: 0.7595 - val_loss: 0.6653 - val_acc: 0.6458\n",
            "Epoch 886/1000\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 0.5356 - acc: 0.7354 - val_loss: 0.6362 - val_acc: 0.6875\n",
            "Epoch 887/1000\n",
            "37/37 [==============================] - 9s 241ms/step - loss: 0.5021 - acc: 0.7388 - val_loss: 0.6625 - val_acc: 0.6562\n",
            "Epoch 888/1000\n",
            "37/37 [==============================] - 9s 239ms/step - loss: 0.4966 - acc: 0.7423 - val_loss: 0.6536 - val_acc: 0.6667\n",
            "Epoch 889/1000\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.4965 - acc: 0.7560 - val_loss: 0.6610 - val_acc: 0.6562\n",
            "Epoch 890/1000\n",
            "37/37 [==============================] - 10s 241ms/step - loss: 0.4855 - acc: 0.7680 - val_loss: 0.6593 - val_acc: 0.6458\n",
            "Epoch 891/1000\n",
            "37/37 [==============================] - 10s 254ms/step - loss: 0.5243 - acc: 0.7216 - val_loss: 0.6719 - val_acc: 0.6458\n",
            "Epoch 892/1000\n",
            "37/37 [==============================] - 5s 113ms/step - loss: 0.5436 - acc: 0.7251 - val_loss: 0.6542 - val_acc: 0.6667\n",
            "Epoch 893/1000\n",
            "37/37 [==============================] - 5s 114ms/step - loss: 0.5358 - acc: 0.7371 - val_loss: 0.6532 - val_acc: 0.6667\n",
            "Epoch 894/1000\n",
            "37/37 [==============================] - 10s 238ms/step - loss: 0.4758 - acc: 0.7526 - val_loss: 0.6607 - val_acc: 0.6562\n",
            "Epoch 895/1000\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.4878 - acc: 0.7595 - val_loss: 0.6769 - val_acc: 0.6562\n",
            "Epoch 896/1000\n",
            "37/37 [==============================] - 10s 239ms/step - loss: 0.5235 - acc: 0.7234 - val_loss: 0.6764 - val_acc: 0.6458\n",
            "Epoch 897/1000\n",
            "37/37 [==============================] - 9s 241ms/step - loss: 0.5038 - acc: 0.7612 - val_loss: 0.6699 - val_acc: 0.6250\n",
            "Epoch 898/1000\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.4996 - acc: 0.7646 - val_loss: 0.6471 - val_acc: 0.6562\n",
            "Epoch 899/1000\n",
            "37/37 [==============================] - 10s 239ms/step - loss: 0.5305 - acc: 0.7285 - val_loss: 0.6458 - val_acc: 0.6354\n",
            "Epoch 900/1000\n",
            "37/37 [==============================] - 5s 118ms/step - loss: 0.5277 - acc: 0.7234 - val_loss: 0.6784 - val_acc: 0.6146\n",
            "Epoch 901/1000\n",
            "37/37 [==============================] - 9s 234ms/step - loss: 0.5157 - acc: 0.7405 - val_loss: 0.6715 - val_acc: 0.6250\n",
            "Epoch 902/1000\n",
            "37/37 [==============================] - 5s 110ms/step - loss: 0.4853 - acc: 0.7543 - val_loss: 0.6464 - val_acc: 0.6875\n",
            "Epoch 903/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.4967 - acc: 0.7732 - val_loss: 0.6758 - val_acc: 0.6458\n",
            "Epoch 904/1000\n",
            "37/37 [==============================] - 6s 141ms/step - loss: 0.5322 - acc: 0.7474 - val_loss: 0.6699 - val_acc: 0.6562\n",
            "Epoch 905/1000\n",
            "37/37 [==============================] - 9s 242ms/step - loss: 0.5714 - acc: 0.7302 - val_loss: 0.6707 - val_acc: 0.6354\n",
            "Epoch 906/1000\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.5203 - acc: 0.7543 - val_loss: 0.6600 - val_acc: 0.6667\n",
            "Epoch 907/1000\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.5075 - acc: 0.7526 - val_loss: 0.6563 - val_acc: 0.6458\n",
            "Epoch 908/1000\n",
            "37/37 [==============================] - 10s 256ms/step - loss: 0.5205 - acc: 0.7526 - val_loss: 0.6902 - val_acc: 0.6354\n",
            "Epoch 909/1000\n",
            "37/37 [==============================] - 5s 109ms/step - loss: 0.4922 - acc: 0.7526 - val_loss: 0.6607 - val_acc: 0.6667\n",
            "Epoch 910/1000\n",
            "37/37 [==============================] - 10s 265ms/step - loss: 0.4849 - acc: 0.7887 - val_loss: 0.6758 - val_acc: 0.6562\n",
            "Epoch 911/1000\n",
            "37/37 [==============================] - 9s 242ms/step - loss: 0.5074 - acc: 0.7423 - val_loss: 0.6607 - val_acc: 0.6667\n",
            "Epoch 912/1000\n",
            "37/37 [==============================] - 9s 241ms/step - loss: 0.5009 - acc: 0.7595 - val_loss: 0.6785 - val_acc: 0.6562\n",
            "Epoch 913/1000\n",
            "37/37 [==============================] - 10s 248ms/step - loss: 0.4877 - acc: 0.7560 - val_loss: 0.6860 - val_acc: 0.6458\n",
            "Epoch 914/1000\n",
            "37/37 [==============================] - 10s 251ms/step - loss: 0.5179 - acc: 0.7491 - val_loss: 0.6771 - val_acc: 0.6458\n",
            "Epoch 915/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.4846 - acc: 0.7595 - val_loss: 0.6762 - val_acc: 0.6458\n",
            "Epoch 916/1000\n",
            "37/37 [==============================] - 9s 244ms/step - loss: 0.4889 - acc: 0.7612 - val_loss: 0.6773 - val_acc: 0.6562\n",
            "Epoch 917/1000\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.4701 - acc: 0.7766 - val_loss: 0.6651 - val_acc: 0.6562\n",
            "Epoch 918/1000\n",
            "37/37 [==============================] - 10s 243ms/step - loss: 0.5028 - acc: 0.7577 - val_loss: 0.6692 - val_acc: 0.6562\n",
            "Epoch 919/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.5122 - acc: 0.7686 - val_loss: 0.6441 - val_acc: 0.6562\n",
            "Epoch 920/1000\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 0.4765 - acc: 0.7646 - val_loss: 0.6456 - val_acc: 0.6667\n",
            "Epoch 921/1000\n",
            "37/37 [==============================] - 6s 143ms/step - loss: 0.5089 - acc: 0.7612 - val_loss: 0.6571 - val_acc: 0.6562\n",
            "Epoch 922/1000\n",
            "37/37 [==============================] - 10s 253ms/step - loss: 0.5411 - acc: 0.7474 - val_loss: 0.6574 - val_acc: 0.6562\n",
            "Epoch 923/1000\n",
            "37/37 [==============================] - 5s 110ms/step - loss: 0.5024 - acc: 0.7491 - val_loss: 0.6567 - val_acc: 0.6458\n",
            "Epoch 924/1000\n",
            "37/37 [==============================] - 5s 107ms/step - loss: 0.5194 - acc: 0.7268 - val_loss: 0.6564 - val_acc: 0.6458\n",
            "Epoch 925/1000\n",
            "37/37 [==============================] - 6s 141ms/step - loss: 0.5490 - acc: 0.7199 - val_loss: 0.6612 - val_acc: 0.6458\n",
            "Epoch 926/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 0.4907 - acc: 0.7646 - val_loss: 0.6549 - val_acc: 0.6562\n",
            "Epoch 927/1000\n",
            "37/37 [==============================] - 9s 245ms/step - loss: 0.5234 - acc: 0.7543 - val_loss: 0.6586 - val_acc: 0.6458\n",
            "Epoch 928/1000\n",
            "37/37 [==============================] - 5s 116ms/step - loss: 0.5213 - acc: 0.7543 - val_loss: 0.6400 - val_acc: 0.6667\n",
            "Epoch 929/1000\n",
            "37/37 [==============================] - 6s 140ms/step - loss: 0.5039 - acc: 0.7320 - val_loss: 0.6405 - val_acc: 0.6562\n",
            "Epoch 930/1000\n",
            "37/37 [==============================] - 5s 115ms/step - loss: 0.5119 - acc: 0.7474 - val_loss: 0.6459 - val_acc: 0.6771\n",
            "Epoch 931/1000\n",
            "37/37 [==============================] - 10s 246ms/step - loss: 0.5553 - acc: 0.7216 - val_loss: 0.6631 - val_acc: 0.6562\n",
            "Epoch 932/1000\n",
            "37/37 [==============================] - 9s 242ms/step - loss: 0.5512 - acc: 0.7182 - val_loss: 0.6547 - val_acc: 0.6458\n",
            "Epoch 933/1000\n",
            "37/37 [==============================] - 9s 241ms/step - loss: 0.4912 - acc: 0.7560 - val_loss: 0.6685 - val_acc: 0.6354\n",
            "Epoch 934/1000\n",
            "37/37 [==============================] - 6s 149ms/step - loss: 0.4992 - acc: 0.7354 - val_loss: 0.6528 - val_acc: 0.6562\n",
            "Epoch 935/1000\n",
            "37/37 [==============================] - 5s 112ms/step - loss: 0.4984 - acc: 0.7577 - val_loss: 0.6614 - val_acc: 0.6458\n",
            "Epoch 936/1000\n",
            "37/37 [==============================] - 6s 138ms/step - loss: 0.4931 - acc: 0.7560 - val_loss: 0.6274 - val_acc: 0.6667\n",
            "Epoch 937/1000\n",
            "37/37 [==============================] - 5s 114ms/step - loss: 0.5140 - acc: 0.7560 - val_loss: 0.6663 - val_acc: 0.6458\n",
            "Epoch 938/1000\n",
            "37/37 [==============================] - 6s 144ms/step - loss: 0.5282 - acc: 0.7354 - val_loss: 0.6811 - val_acc: 0.6458\n",
            "Epoch 939/1000\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.5247 - acc: 0.7320 - val_loss: 0.6803 - val_acc: 0.6354\n",
            "Epoch 940/1000\n",
            "37/37 [==============================] - 5s 109ms/step - loss: 0.5133 - acc: 0.7474 - val_loss: 0.6503 - val_acc: 0.6562\n",
            "Epoch 941/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.5018 - acc: 0.7629 - val_loss: 0.6631 - val_acc: 0.6458\n",
            "Epoch 942/1000\n",
            "37/37 [==============================] - 10s 254ms/step - loss: 0.4826 - acc: 0.7491 - val_loss: 0.6666 - val_acc: 0.6562\n",
            "Epoch 943/1000\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 0.4880 - acc: 0.7423 - val_loss: 0.6600 - val_acc: 0.6354\n",
            "Epoch 944/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.5331 - acc: 0.7371 - val_loss: 0.6707 - val_acc: 0.6354\n",
            "Epoch 945/1000\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.5176 - acc: 0.7457 - val_loss: 0.6725 - val_acc: 0.6458\n",
            "Epoch 946/1000\n",
            "37/37 [==============================] - 10s 242ms/step - loss: 0.5672 - acc: 0.7199 - val_loss: 0.6733 - val_acc: 0.6458\n",
            "Epoch 947/1000\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.4975 - acc: 0.7457 - val_loss: 0.6792 - val_acc: 0.6562\n",
            "Epoch 948/1000\n",
            "37/37 [==============================] - 5s 104ms/step - loss: 0.4774 - acc: 0.7680 - val_loss: 0.6538 - val_acc: 0.6667\n",
            "Epoch 949/1000\n",
            "37/37 [==============================] - 10s 241ms/step - loss: 0.4918 - acc: 0.7509 - val_loss: 0.6728 - val_acc: 0.6458\n",
            "Epoch 950/1000\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.5228 - acc: 0.7199 - val_loss: 0.6776 - val_acc: 0.6354\n",
            "Epoch 951/1000\n",
            "37/37 [==============================] - 9s 239ms/step - loss: 0.5460 - acc: 0.7509 - val_loss: 0.6575 - val_acc: 0.6458\n",
            "Epoch 952/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.5154 - acc: 0.7440 - val_loss: 0.6631 - val_acc: 0.6458\n",
            "Epoch 953/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 0.4979 - acc: 0.7457 - val_loss: 0.6570 - val_acc: 0.6562\n",
            "Epoch 954/1000\n",
            "37/37 [==============================] - 9s 247ms/step - loss: 0.5263 - acc: 0.7268 - val_loss: 0.6688 - val_acc: 0.6562\n",
            "Epoch 955/1000\n",
            "37/37 [==============================] - 9s 239ms/step - loss: 0.4881 - acc: 0.7732 - val_loss: 0.6535 - val_acc: 0.6562\n",
            "Epoch 956/1000\n",
            "37/37 [==============================] - 10s 247ms/step - loss: 0.5212 - acc: 0.7314 - val_loss: 0.6829 - val_acc: 0.6354\n",
            "Epoch 957/1000\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 0.5180 - acc: 0.7440 - val_loss: 0.6736 - val_acc: 0.6354\n",
            "Epoch 958/1000\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.4862 - acc: 0.7646 - val_loss: 0.6489 - val_acc: 0.6667\n",
            "Epoch 959/1000\n",
            "37/37 [==============================] - 6s 136ms/step - loss: 0.5060 - acc: 0.7491 - val_loss: 0.6509 - val_acc: 0.6667\n",
            "Epoch 960/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.5307 - acc: 0.7388 - val_loss: 0.6575 - val_acc: 0.6562\n",
            "Epoch 961/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.5336 - acc: 0.7302 - val_loss: 0.6553 - val_acc: 0.6458\n",
            "Epoch 962/1000\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.5502 - acc: 0.7113 - val_loss: 0.6763 - val_acc: 0.6354\n",
            "Epoch 963/1000\n",
            "37/37 [==============================] - 10s 243ms/step - loss: 0.5078 - acc: 0.7354 - val_loss: 0.6422 - val_acc: 0.6667\n",
            "Epoch 964/1000\n",
            "37/37 [==============================] - 11s 276ms/step - loss: 0.5021 - acc: 0.7348 - val_loss: 0.6812 - val_acc: 0.6354\n",
            "Epoch 965/1000\n",
            "37/37 [==============================] - 10s 250ms/step - loss: 0.4952 - acc: 0.7526 - val_loss: 0.6780 - val_acc: 0.6458\n",
            "Epoch 966/1000\n",
            "37/37 [==============================] - 5s 118ms/step - loss: 0.5472 - acc: 0.7096 - val_loss: 0.6644 - val_acc: 0.6562\n",
            "Epoch 967/1000\n",
            "37/37 [==============================] - 7s 159ms/step - loss: 0.4983 - acc: 0.7577 - val_loss: 0.6709 - val_acc: 0.6354\n",
            "Epoch 968/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.5130 - acc: 0.7543 - val_loss: 0.6548 - val_acc: 0.6458\n",
            "Epoch 969/1000\n",
            "37/37 [==============================] - 10s 259ms/step - loss: 0.5124 - acc: 0.7371 - val_loss: 0.6632 - val_acc: 0.6458\n",
            "Epoch 970/1000\n",
            "37/37 [==============================] - 9s 241ms/step - loss: 0.4707 - acc: 0.7801 - val_loss: 0.6396 - val_acc: 0.6562\n",
            "Epoch 971/1000\n",
            "37/37 [==============================] - 10s 248ms/step - loss: 0.4832 - acc: 0.7618 - val_loss: 0.6574 - val_acc: 0.6458\n",
            "Epoch 972/1000\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 0.5066 - acc: 0.7491 - val_loss: 0.6575 - val_acc: 0.6562\n",
            "Epoch 973/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.5282 - acc: 0.7371 - val_loss: 0.6709 - val_acc: 0.6354\n",
            "Epoch 974/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.4844 - acc: 0.7680 - val_loss: 0.6462 - val_acc: 0.6562\n",
            "Epoch 975/1000\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.5159 - acc: 0.7526 - val_loss: 0.6703 - val_acc: 0.6562\n",
            "Epoch 976/1000\n",
            "37/37 [==============================] - 5s 110ms/step - loss: 0.4792 - acc: 0.7601 - val_loss: 0.6662 - val_acc: 0.6250\n",
            "Epoch 977/1000\n",
            "37/37 [==============================] - 6s 131ms/step - loss: 0.4921 - acc: 0.7474 - val_loss: 0.6724 - val_acc: 0.6146\n",
            "Epoch 978/1000\n",
            "37/37 [==============================] - 9s 244ms/step - loss: 0.4719 - acc: 0.7646 - val_loss: 0.6707 - val_acc: 0.6250\n",
            "Epoch 979/1000\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.5149 - acc: 0.7423 - val_loss: 0.6553 - val_acc: 0.6250\n",
            "Epoch 980/1000\n",
            "37/37 [==============================] - 10s 264ms/step - loss: 0.4773 - acc: 0.7612 - val_loss: 0.6482 - val_acc: 0.6562\n",
            "Epoch 981/1000\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 0.5008 - acc: 0.7509 - val_loss: 0.6577 - val_acc: 0.6354\n",
            "Epoch 982/1000\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.5189 - acc: 0.7509 - val_loss: 0.6561 - val_acc: 0.6458\n",
            "Epoch 983/1000\n",
            "37/37 [==============================] - 7s 160ms/step - loss: 0.4881 - acc: 0.7663 - val_loss: 0.6492 - val_acc: 0.6458\n",
            "Epoch 984/1000\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.5013 - acc: 0.7509 - val_loss: 0.6541 - val_acc: 0.6458\n",
            "Epoch 985/1000\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 0.4977 - acc: 0.7354 - val_loss: 0.6471 - val_acc: 0.6562\n",
            "Epoch 986/1000\n",
            "37/37 [==============================] - 9s 241ms/step - loss: 0.5417 - acc: 0.7354 - val_loss: 0.6419 - val_acc: 0.6667\n",
            "Epoch 987/1000\n",
            "37/37 [==============================] - 10s 255ms/step - loss: 0.5343 - acc: 0.7509 - val_loss: 0.6557 - val_acc: 0.6562\n",
            "Epoch 988/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 0.5205 - acc: 0.7663 - val_loss: 0.6431 - val_acc: 0.6354\n",
            "Epoch 989/1000\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 0.5107 - acc: 0.7595 - val_loss: 0.6555 - val_acc: 0.6354\n",
            "Epoch 990/1000\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.5091 - acc: 0.7646 - val_loss: 0.6583 - val_acc: 0.6354\n",
            "Epoch 991/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.5110 - acc: 0.7423 - val_loss: 0.6549 - val_acc: 0.6354\n",
            "Epoch 992/1000\n",
            "37/37 [==============================] - 9s 243ms/step - loss: 0.5154 - acc: 0.7182 - val_loss: 0.6541 - val_acc: 0.6354\n",
            "Epoch 993/1000\n",
            "37/37 [==============================] - 9s 243ms/step - loss: 0.5436 - acc: 0.7320 - val_loss: 0.6464 - val_acc: 0.6667\n",
            "Epoch 994/1000\n",
            "37/37 [==============================] - 7s 163ms/step - loss: 0.5086 - acc: 0.7698 - val_loss: 0.6537 - val_acc: 0.6458\n",
            "Epoch 995/1000\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.5238 - acc: 0.7337 - val_loss: 0.6710 - val_acc: 0.6250\n",
            "Epoch 996/1000\n",
            "37/37 [==============================] - 10s 258ms/step - loss: 0.4984 - acc: 0.7509 - val_loss: 0.6772 - val_acc: 0.6354\n",
            "Epoch 997/1000\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.4844 - acc: 0.7749 - val_loss: 0.6569 - val_acc: 0.6667\n",
            "Epoch 998/1000\n",
            "37/37 [==============================] - 9s 243ms/step - loss: 0.4820 - acc: 0.7669 - val_loss: 0.6619 - val_acc: 0.6354\n",
            "Epoch 999/1000\n",
            "37/37 [==============================] - 7s 172ms/step - loss: 0.5122 - acc: 0.7388 - val_loss: 0.6312 - val_acc: 0.6667\n",
            "Epoch 1000/1000\n",
            "37/37 [==============================] - 9s 242ms/step - loss: 0.5305 - acc: 0.7148 - val_loss: 0.6577 - val_acc: 0.6458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot training performance"
      ],
      "metadata": {
        "id": "YFxMJycOpEew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'co', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'k', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'co', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "     "
      ],
      "metadata": {
        "id": "l9PYKbRNpEK8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "7717f41f-63f1-4207-9d51-106491e305e2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SAVE model"
      ],
      "metadata": {
        "id": "kNtlq_LZpKNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('./content/drive/My Drive/new', exist_ok=True)\n",
        "model.save('./content/drive/My Drive/new/2Class_UNfreeze_3000.h5')"
      ],
      "metadata": {
        "id": "TegSVqblpLEZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "KdsdaIgMpMeG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"./content/drive/My Drive/new/2Class_UNfreeze_3000.h5\")"
      ],
      "metadata": {
        "id": "sZFZ1c_kpMcN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "7314e4f3-ebf2-4f35-9c51-6f66b5e62a1c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_75ce0cba-1e25-4742-99cc-3b0a2554fd27\", \"2Class_UNfreeze_3000.h5\", 16604952)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gEfCB1RfpMZ6"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}