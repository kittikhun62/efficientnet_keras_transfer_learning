{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZhl/UQqd3B2Gi9FK4ITTQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kittikhun62/efficientnet_keras_transfer_learning/blob/master/new_data_train_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# import from drive"
      ],
      "metadata": {
        "id": "_2DRC-anSxem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "BVIqfqC1DtDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1vTfbZAhkbI"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline\n",
        "     "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## hyper parameter\n"
      ],
      "metadata": {
        "id": "T529UM_tVV-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 20\n",
        "\n",
        "width = 150\n",
        "height = 150\n",
        "\n",
        "epochs = 1000 #จำนวนรอบในการ Train\n",
        "\n",
        "NUM_TRAIN = 681  # จำนวนภาพ Train\n",
        "NUM_TEST = 82 #จำนวนภาพ Test\n",
        "\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3) #ขนาด image enter"
      ],
      "metadata": {
        "id": "zXpmkJ2GVZ1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone efficientnet repo"
      ],
      "metadata": {
        "id": "DSSZIFGhUyQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/"
      ],
      "metadata": {
        "id": "nFvKcuBDTj1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import efficientnet and load the conv base model"
      ],
      "metadata": {
        "id": "j3EgSOiSZHaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "iI3DQ18HU2TF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/My Drive/new project'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Directories for our training,\n",
        "# validation and test splits\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.makedirs(test_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "fCWiYGPMhsCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load model"
      ],
      "metadata": {
        "id": "qyqFwhs8h-F4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/new/newdata_SEM1.h5')\n",
        "\n",
        "from efficientnet.layers import Swish, DropConnect\n",
        "from efficientnet.model import ConvKernalInitializer\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "\n",
        "get_custom_objects().update({\n",
        "    'ConvKernalInitializer': ConvKernalInitializer,\n",
        "    'Swish': Swish,\n",
        "    'DropConnect':DropConnect\n",
        "})"
      ],
      "metadata": {
        "id": "PD1ngaxDh9tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load model \n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/drive/My Drive/new/newdata_SEM1.h5')\n",
        "height = width = model.input_shape[1]"
      ],
      "metadata": {
        "id": "9d1GnaRniIaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "iqfZypmOiNsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting data augmentation"
      ],
      "metadata": {
        "id": "X9Xfp10TY9xE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "#Image Augmentation \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, # image input 0-255 --> 0-1 เปลี่ยนค่าสี\n",
        "      rotation_range=40,# หมุนภาพในองศา\n",
        "      width_shift_range=0.2, #เปลี่ยนความกว้าง\n",
        "      height_shift_range=0.2, #ปลี่ยนความสูง\n",
        "      shear_range=0.2, #ทำให้ภาพเบี้ยว\n",
        "      zoom_range=0.2, # Randomly zoom image\n",
        "      horizontal_flip=True, \n",
        "      #โดย Default เมื่อมีการเลื่อนภาพ บิดภาพ หมุนภาพ จะเกิดพื้นที่ว่างที่มุม \n",
        "      #ซึ่งจะมีการเติมภาพให้เต็มโดยใช้เทคนิคแบบ Nearest neighbor ซึ่งเป็นการดึงสีบริเวณใหล้าเคียงมาระบายให้เต็ม แต่เราก็ยังสามารถกำหนดวิธีการ Fill ภาพด้วยเทคนิคอื่นได้จาก Parameter fill_mode\n",
        "      fill_mode='nearest')\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory #ไดเรกเป้าหมาย\n",
        "        train_dir,\n",
        "        # รูปภาพทั้งหมดจะถูกปรับขนาดตามความสูงและความกว้างของเป้าหมาย\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        #เนื่องจากเราใช้ categorical_crossentropy loss เราจึงต้องมีป้ายกำกับตามหมวดหมู่\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory( #การดึงภาพจาก Directory มาเข้าโมเดล \n",
        "        validation_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "id": "GC-vPos9Y9HD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "8Egr3yJwiSQ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d31f941d-8480-4ad5-ef02-e0fdc329dfd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-12-caa7b37242a8>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "15/15 [==============================] - 37s 2s/step - loss: 0.9507 - acc: 0.5767 - val_loss: 1.4412 - val_acc: 0.4000\n",
            "Epoch 2/1000\n",
            "15/15 [==============================] - 13s 737ms/step - loss: 0.8954 - acc: 0.5900 - val_loss: 1.3945 - val_acc: 0.4000\n",
            "Epoch 3/1000\n",
            "15/15 [==============================] - 11s 677ms/step - loss: 0.8522 - acc: 0.5833 - val_loss: 1.0294 - val_acc: 0.5500\n",
            "Epoch 4/1000\n",
            "15/15 [==============================] - 11s 613ms/step - loss: 0.8668 - acc: 0.6370 - val_loss: 1.3789 - val_acc: 0.3000\n",
            "Epoch 5/1000\n",
            "15/15 [==============================] - 11s 618ms/step - loss: 0.8783 - acc: 0.5907 - val_loss: 1.5567 - val_acc: 0.2500\n",
            "Epoch 6/1000\n",
            "15/15 [==============================] - 11s 645ms/step - loss: 0.8607 - acc: 0.6567 - val_loss: 1.0041 - val_acc: 0.4000\n",
            "Epoch 7/1000\n",
            "15/15 [==============================] - 11s 653ms/step - loss: 0.8171 - acc: 0.6567 - val_loss: 1.2433 - val_acc: 0.3000\n",
            "Epoch 8/1000\n",
            "15/15 [==============================] - 11s 637ms/step - loss: 0.8638 - acc: 0.5967 - val_loss: 1.5469 - val_acc: 0.2500\n",
            "Epoch 9/1000\n",
            "15/15 [==============================] - 11s 603ms/step - loss: 0.8010 - acc: 0.6370 - val_loss: 1.4341 - val_acc: 0.3500\n",
            "Epoch 10/1000\n",
            "15/15 [==============================] - 11s 641ms/step - loss: 0.8053 - acc: 0.6333 - val_loss: 1.3403 - val_acc: 0.4000\n",
            "Epoch 11/1000\n",
            "15/15 [==============================] - 11s 611ms/step - loss: 0.7828 - acc: 0.6584 - val_loss: 1.0609 - val_acc: 0.5000\n",
            "Epoch 12/1000\n",
            "15/15 [==============================] - 11s 641ms/step - loss: 0.8528 - acc: 0.6233 - val_loss: 1.5125 - val_acc: 0.2500\n",
            "Epoch 13/1000\n",
            "15/15 [==============================] - 11s 603ms/step - loss: 0.9079 - acc: 0.6050 - val_loss: 1.3319 - val_acc: 0.3500\n",
            "Epoch 14/1000\n",
            "15/15 [==============================] - 13s 740ms/step - loss: 0.8657 - acc: 0.6267 - val_loss: 1.3895 - val_acc: 0.3000\n",
            "Epoch 15/1000\n",
            "15/15 [==============================] - 14s 725ms/step - loss: 0.8856 - acc: 0.6233 - val_loss: 1.3480 - val_acc: 0.3500\n",
            "Epoch 16/1000\n",
            "15/15 [==============================] - 12s 663ms/step - loss: 0.9472 - acc: 0.5833 - val_loss: 1.5662 - val_acc: 0.3000\n",
            "Epoch 17/1000\n",
            "15/15 [==============================] - 11s 651ms/step - loss: 0.8536 - acc: 0.6133 - val_loss: 1.2692 - val_acc: 0.4000\n",
            "Epoch 18/1000\n",
            "15/15 [==============================] - 11s 618ms/step - loss: 0.8726 - acc: 0.6085 - val_loss: 1.3119 - val_acc: 0.4000\n",
            "Epoch 19/1000\n",
            "15/15 [==============================] - 11s 634ms/step - loss: 0.9300 - acc: 0.6157 - val_loss: 1.2761 - val_acc: 0.4500\n",
            "Epoch 20/1000\n",
            "15/15 [==============================] - 11s 625ms/step - loss: 0.8557 - acc: 0.6192 - val_loss: 1.2625 - val_acc: 0.4000\n",
            "Epoch 21/1000\n",
            "15/15 [==============================] - 11s 657ms/step - loss: 0.8141 - acc: 0.6667 - val_loss: 1.2809 - val_acc: 0.4500\n",
            "Epoch 22/1000\n",
            "15/15 [==============================] - 11s 644ms/step - loss: 0.7843 - acc: 0.6867 - val_loss: 1.1901 - val_acc: 0.4500\n",
            "Epoch 23/1000\n",
            "15/15 [==============================] - 12s 669ms/step - loss: 0.8243 - acc: 0.6500 - val_loss: 1.5073 - val_acc: 0.3500\n",
            "Epoch 24/1000\n",
            "15/15 [==============================] - 11s 648ms/step - loss: 0.8479 - acc: 0.5967 - val_loss: 1.5955 - val_acc: 0.2500\n",
            "Epoch 25/1000\n",
            "15/15 [==============================] - 11s 625ms/step - loss: 0.7895 - acc: 0.6833 - val_loss: 1.0629 - val_acc: 0.4000\n",
            "Epoch 26/1000\n",
            "15/15 [==============================] - 11s 663ms/step - loss: 0.9542 - acc: 0.5867 - val_loss: 1.3197 - val_acc: 0.3500\n",
            "Epoch 27/1000\n",
            "15/15 [==============================] - 11s 625ms/step - loss: 0.9737 - acc: 0.5587 - val_loss: 1.3357 - val_acc: 0.4000\n",
            "Epoch 28/1000\n",
            "15/15 [==============================] - 12s 635ms/step - loss: 0.8949 - acc: 0.5979 - val_loss: 1.5876 - val_acc: 0.2500\n",
            "Epoch 29/1000\n",
            "15/15 [==============================] - 11s 668ms/step - loss: 0.9025 - acc: 0.5833 - val_loss: 1.3068 - val_acc: 0.4500\n",
            "Epoch 30/1000\n",
            "15/15 [==============================] - 11s 651ms/step - loss: 0.8144 - acc: 0.6767 - val_loss: 1.3401 - val_acc: 0.3500\n",
            "Epoch 31/1000\n",
            "15/15 [==============================] - 11s 627ms/step - loss: 0.8510 - acc: 0.6263 - val_loss: 1.1737 - val_acc: 0.4500\n",
            "Epoch 32/1000\n",
            "15/15 [==============================] - 11s 625ms/step - loss: 0.8819 - acc: 0.5765 - val_loss: 1.3443 - val_acc: 0.3000\n",
            "Epoch 33/1000\n",
            "15/15 [==============================] - 11s 632ms/step - loss: 0.8757 - acc: 0.6228 - val_loss: 1.3293 - val_acc: 0.3000\n",
            "Epoch 34/1000\n",
            "15/15 [==============================] - 11s 633ms/step - loss: 0.8287 - acc: 0.6267 - val_loss: 1.0114 - val_acc: 0.5000\n",
            "Epoch 35/1000\n",
            "15/15 [==============================] - 11s 629ms/step - loss: 0.9234 - acc: 0.6050 - val_loss: 1.4201 - val_acc: 0.4000\n",
            "Epoch 36/1000\n",
            "15/15 [==============================] - 11s 629ms/step - loss: 0.8784 - acc: 0.6050 - val_loss: 1.3538 - val_acc: 0.2500\n",
            "Epoch 37/1000\n",
            "15/15 [==============================] - 11s 629ms/step - loss: 0.8597 - acc: 0.6121 - val_loss: 1.0778 - val_acc: 0.5000\n",
            "Epoch 38/1000\n",
            "15/15 [==============================] - 12s 660ms/step - loss: 0.8520 - acc: 0.6133 - val_loss: 1.2577 - val_acc: 0.4000\n",
            "Epoch 39/1000\n",
            "15/15 [==============================] - 11s 645ms/step - loss: 0.8336 - acc: 0.6567 - val_loss: 1.3894 - val_acc: 0.3500\n",
            "Epoch 40/1000\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.8616 - acc: 0.6286"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'co', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'k', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'co', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iEZRZuH8iVGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('./content/drive/My Drive/new', exist_ok=True)\n",
        "model.save('./content/drive/My Drive/new/newdata_SEM2.h5')"
      ],
      "metadata": {
        "id": "VWrYGbQbiXjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"./content/drive/My Drive/new/newdata_SEM2.h5\")"
      ],
      "metadata": {
        "id": "XPm79yKMwkt3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}