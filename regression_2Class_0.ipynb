{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMJxMjagasqyYf13upfgYDK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kittikhun62/efficientnet_keras_transfer_learning/blob/master/regression_2Class_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# import from drive"
      ],
      "metadata": {
        "id": "_2DRC-anSxem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "BVIqfqC1DtDt",
        "outputId": "5a4b1ca1-4cbf-4074-8bd3-af6504af1231",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (r'/content/drive/My Drive/data - 2 class Regress.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "gABRUdVwDtBk",
        "outputId": "889adf83-9fbd-4ca8-a950-f3171201bc77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      No                      Name_file  \\\n",
              "0      1                        pore-sb   \n",
              "1      2                        pore-sb   \n",
              "2      3                        pore-sb   \n",
              "3      4                        pore-sb   \n",
              "4      5                        pore-sb   \n",
              "..   ...                            ...   \n",
              "795  796  1-s2.0-S2095268622000210-main   \n",
              "796  797  1-s2.0-S2095268622000210-main   \n",
              "797  798  1-s2.0-S2095268622000210-main   \n",
              "798  799  1-s2.0-S2095268622000210-main   \n",
              "799  800  1-s2.0-S2095268622000210-main   \n",
              "\n",
              "                                            Name_Paper  \\\n",
              "0    Preparation and electrochemical behaviour of b...   \n",
              "1    Preparation and electrochemical behaviour of b...   \n",
              "2    Preparation and electrochemical behaviour of b...   \n",
              "3    Preparation and electrochemical behaviour of b...   \n",
              "4    Preparation and electrochemical behaviour of b...   \n",
              "..                                                 ...   \n",
              "795  Integration of preparation of K, Na-embedded a...   \n",
              "796  Integration of preparation of K, Na-embedded a...   \n",
              "797  Integration of preparation of K, Na-embedded a...   \n",
              "798  Integration of preparation of K, Na-embedded a...   \n",
              "799  Integration of preparation of K, Na-embedded a...   \n",
              "\n",
              "                                               journal  \\\n",
              "0                                  Korean J. Chem. Eng   \n",
              "1                                  Korean J. Chem. Eng   \n",
              "2                                  Korean J. Chem. Eng   \n",
              "3                                  Korean J. Chem. Eng   \n",
              "4                                  Korean J. Chem. Eng   \n",
              "..                                                 ...   \n",
              "795  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "796  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "797  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "798  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "799  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "\n",
              "                                          path_Picture  detail  Class     BET  \\\n",
              "0    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom1  0-800  135.06   \n",
              "1    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom2  0-800  135.06   \n",
              "2    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom3  0-800  135.06   \n",
              "3    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom4  0-800  135.06   \n",
              "4    /content/drive/My Drive/new train/pore-sb/PCC(...   zoom5  0-800  135.06   \n",
              "..                                                 ...     ...    ...     ...   \n",
              "795  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom21  0-800  301.70   \n",
              "796  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom22  0-800  301.70   \n",
              "797  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom23  0-800  301.70   \n",
              "798  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom24  0-800  301.70   \n",
              "799  /content/drive/My Drive/new train/1-s2.0-S2095...  zoom25  0-800  301.70   \n",
              "\n",
              "     Size(mico)  Class_01  \n",
              "0            10         0  \n",
              "1            10         0  \n",
              "2            10         0  \n",
              "3            10         0  \n",
              "4            10         0  \n",
              "..          ...       ...  \n",
              "795          10         0  \n",
              "796          10         0  \n",
              "797          10         0  \n",
              "798          10         0  \n",
              "799          10         0  \n",
              "\n",
              "[800 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1f504d13-f7fc-4719-948f-fb7c50e2a55d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>No</th>\n",
              "      <th>Name_file</th>\n",
              "      <th>Name_Paper</th>\n",
              "      <th>journal</th>\n",
              "      <th>path_Picture</th>\n",
              "      <th>detail</th>\n",
              "      <th>Class</th>\n",
              "      <th>BET</th>\n",
              "      <th>Size(mico)</th>\n",
              "      <th>Class_01</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom1</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom2</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom3</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom4</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom5</td>\n",
              "      <td>0-800</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>795</th>\n",
              "      <td>796</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom21</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>796</th>\n",
              "      <td>797</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom22</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>797</th>\n",
              "      <td>798</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom23</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>798</th>\n",
              "      <td>799</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom24</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799</th>\n",
              "      <td>800</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom25</td>\n",
              "      <td>0-800</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>800 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f504d13-f7fc-4719-948f-fb7c50e2a55d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1f504d13-f7fc-4719-948f-fb7c50e2a55d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1f504d13-f7fc-4719-948f-fb7c50e2a55d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## hist check class"
      ],
      "metadata": {
        "id": "WMazXBQcTMl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "W34NcexJDs_Z"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.hist();"
      ],
      "metadata": {
        "id": "Fm07UpEbDs5X",
        "outputId": "b4328d38-8006-41e3-aeca-d62ee4d72457",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = df['BET']\n",
        "\n",
        "fig, ax = plt.subplots(figsize =(10, 5))\n",
        "ax.hist(a, bins = 200)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bxfNFKW2TXAY",
        "outputId": "355a3b67-508a-4b1d-ca59-4d897b158c39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ['0-800','801-3200']\n",
        "len(classes)"
      ],
      "metadata": {
        "id": "TBsLszHgTW-D",
        "outputId": "c706cd9b-7732-47f0-f4c7-fdc3732cf5a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# การเเบ่งข้อมูล train/validation/test sets"
      ],
      "metadata": {
        "id": "JDJCDzEDWnVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# base_dir = '/content/drive/My Drive/new Regress'\n",
        "# os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# # Directories for our training,\n",
        "# # validation and test splits\n",
        "# train_dir = os.path.join(base_dir, 'train')\n",
        "# os.makedirs(train_dir, exist_ok=True)\n",
        "# validation_dir = os.path.join(base_dir, 'validation')\n",
        "# os.makedirs(validation_dir, exist_ok=True)\n",
        "# test_dir = os.path.join(base_dir, 'test')\n",
        "# os.makedirs(test_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "R7L0rJNRU2MY"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val = df[df['No'].between(599,699)]\n",
        "train = df[df['No'].between(1,598)]\n",
        "test = df[df['No'].between(700,800)] \n",
        "\n",
        "# #Path Train\n",
        "# T1_train = train[train['Class']=='0-800']\n",
        "# T1_path_train = T1_train['path_Picture'].tolist() \n",
        "# T2_train = train[train['Class']=='801-3200']\n",
        "# T2_path_train = T2_train['path_Picture'].tolist() \n",
        "\n",
        "\n",
        "# #Path Validation\n",
        "# T1_val = val[val['Class']=='0-800']\n",
        "# T1_path_val = T1_val['path_Picture'].tolist() \n",
        "# T2_val = val[val['Class']=='801-3200']\n",
        "# T2_path_val = T2_val['path_Picture'].tolist() \n",
        "\n",
        "\n",
        "\n",
        "# #Path Test\n",
        "# T1_test = test[test['Class']=='0-800']\n",
        "# T1_path_test = T1_test['path_Picture'].tolist() \n",
        "# T2_test = test[test['Class']=='801-3200']\n",
        "# T2_path_test = T2_test['path_Picture'].tolist() \n"
      ],
      "metadata": {
        "id": "mlmd_kyhW2LZ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "r9N_9sFL1hYB"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = '/content/drive/My Drive/new Regress'\n",
        "os.chdir(DATA_PATH)\n",
        "train_dir = os.path.join(DATA_PATH, 'train')\n",
        "print(train_dir)\n",
        "validation_dir = os.path.join(DATA_PATH, 'validation')\n",
        "print(validation_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyxDPsEi6yYJ",
        "outputId": "4c1249eb-17dd-46c2-9b45-c44120fe9dda"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/new Regress/train\n",
            "/content/drive/My Drive/new Regress/validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "ZkfPduNQW43l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fnames = T1_path_train\n",
        "# for fname in fnames:\n",
        "#     dst = os.path.join(train_1_dir, os.path.basename(fname))\n",
        "#     shutil.copyfile(fname, dst)\n",
        "\n",
        "# fnames = T2_path_train\n",
        "# for fname in fnames:\n",
        "#     dst = os.path.join(train_2_dir, os.path.basename(fname))\n",
        "#     shutil.copyfile(fname, dst)\n",
        "    \n"
      ],
      "metadata": {
        "id": "9jMgUluKU2Hp"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test"
      ],
      "metadata": {
        "id": "Mj3sViKJaLSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fnames = T1_path_test\n",
        "# for fname in fnames:\n",
        "#     dst = os.path.join(validation_1_dir, os.path.basename(fname))\n",
        "#     shutil.copyfile(fname, dst)\n",
        "\n",
        "# fnames = T2_path_test\n",
        "# for fname in fnames:\n",
        "#     dst = os.path.join(validation_2_dir, os.path.basename(fname))\n",
        "#     shutil.copyfile(fname, dst)\n",
        "    \n"
      ],
      "metadata": {
        "id": "WvK0Y2FIYat1"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Validation"
      ],
      "metadata": {
        "id": "rc4HwwbPaD6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fnames = T1_path_val\n",
        "# for fname in fnames:\n",
        "#     dst = os.path.join(test_1_dir, os.path.basename(fname))\n",
        "#     shutil.copyfile(fname, dst)\n",
        "\n",
        "# fnames = T2_path_val\n",
        "# for fname in fnames:\n",
        "#     dst = os.path.join(test_2_dir, os.path.basename(fname))\n",
        "#     shutil.copyfile(fname, dst)\n"
      ],
      "metadata": {
        "id": "XxtmCbyUYarp"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# print('total training 1 images:', len(os.listdir(train_1_dir))) \n",
        "# print('total training 2 images:', len(os.listdir(train_2_dir)),'\\n')\n",
        "\n",
        "# print('total validation 1 images:', len(os.listdir(validation_1_dir)))\n",
        "# print('total validation 2 images:', len(os.listdir(validation_2_dir)),'\\n')\n",
        "\n",
        "# print('total test 1 images:', len(os.listdir(test_1_dir)))\n",
        "# print('total test 2 images:', len(os.listdir(test_2_dir)),'\\n')\n"
      ],
      "metadata": {
        "id": "Tvk53f-WYapl"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports library"
      ],
      "metadata": {
        "id": "VkYa-4LeTbir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "myAsBcVhTW7j"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "tYeLut2ByGeC"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## hyper parameter\n"
      ],
      "metadata": {
        "id": "T529UM_tVV-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "width = 150\n",
        "height = 150\n",
        "\n",
        "epochs = 200 #จำนวนรอบในการ Train\n",
        "\n",
        "NUM_TRAIN = 598  # จำนวนภาพ Train\n",
        "NUM_TEST = 101 #จำนวนภาพ Test\n",
        "\n",
        "dropout_rate = 0.3\n",
        "input_shape = (height, width, 3) #ขนาด image enter"
      ],
      "metadata": {
        "id": "zXpmkJ2GVZ1l"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone efficientnet repo"
      ],
      "metadata": {
        "id": "DSSZIFGhUyQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/"
      ],
      "metadata": {
        "id": "nFvKcuBDTj1N",
        "outputId": "32e809f1-188b-4de8-dfa7-0f264bc0014a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import efficientnet and load the conv base model"
      ],
      "metadata": {
        "id": "j3EgSOiSZHaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "iI3DQ18HU2TF"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "#EfficientNet สร้างขึ้นสำหรับการจำแนกประเภท ImageNet ประกอบด้วยป้ายกำกับคลาส 1,000 รายการ เรามีเพียง 2 เลเยอร์เท่านั้น ซึ่งหมายความว่าเลเยอร์สองสามเลเยอร์สุดท้ายสำหรับการจำแนกไม่มีประโยชน์สำหรับเรา สามารถยกเว้นได้ขณะโหลดโมเดลโดยระบุอาร์กิวเมนต์ include_top เป็น False และนำไปใช้กับโมเดล ImageNet อื่นๆ ที่มีอยู่ในแอปพลิเคชัน Keras เช่นกัน\n",
        "\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "UmBDAgF_VAjq"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "id": "rRXoFFzfU2Oi",
        "outputId": "8be68c1c-e501-4266-8716-56ec997b7ca0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 75, 75, 32)   864         ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 75, 75, 32)  128         ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_49 (Swish)               (None, 75, 75, 32)   0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_16 (Depthwise  (None, 75, 75, 32)  288         ['swish_49[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 75, 75, 32)  128         ['depthwise_conv2d_16[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_50 (Swish)               (None, 75, 75, 32)   0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_16 (Lambda)             (None, 1, 1, 32)     0           ['swish_50[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 1, 1, 8)      264         ['lambda_16[0][0]']              \n",
            "                                                                                                  \n",
            " swish_51 (Swish)               (None, 1, 1, 8)      0           ['conv2d_66[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 1, 1, 32)     288         ['swish_51[0][0]']               \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 1, 1, 32)     0           ['conv2d_67[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_16 (Multiply)         (None, 75, 75, 32)   0           ['activation_16[0][0]',          \n",
            "                                                                  'swish_50[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 75, 75, 16)   512         ['multiply_16[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 75, 75, 16)  64          ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 75, 75, 96)   1536        ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 75, 75, 96)  384         ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_52 (Swish)               (None, 75, 75, 96)   0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_17 (Depthwise  (None, 38, 38, 96)  864         ['swish_52[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 38, 38, 96)  384         ['depthwise_conv2d_17[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_53 (Swish)               (None, 38, 38, 96)   0           ['batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_17 (Lambda)             (None, 1, 1, 96)     0           ['swish_53[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 1, 1, 4)      388         ['lambda_17[0][0]']              \n",
            "                                                                                                  \n",
            " swish_54 (Swish)               (None, 1, 1, 4)      0           ['conv2d_70[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 1, 1, 96)     480         ['swish_54[0][0]']               \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 1, 1, 96)     0           ['conv2d_71[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_17 (Multiply)         (None, 38, 38, 96)   0           ['activation_17[0][0]',          \n",
            "                                                                  'swish_53[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 38, 38, 24)   2304        ['multiply_17[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 38, 38, 24)  96          ['conv2d_72[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 38, 38, 144)  3456        ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 38, 38, 144)  576        ['conv2d_73[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_55 (Swish)               (None, 38, 38, 144)  0           ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_18 (Depthwise  (None, 38, 38, 144)  1296       ['swish_55[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 38, 38, 144)  576        ['depthwise_conv2d_18[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_56 (Swish)               (None, 38, 38, 144)  0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_18 (Lambda)             (None, 1, 1, 144)    0           ['swish_56[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_18[0][0]']              \n",
            "                                                                                                  \n",
            " swish_57 (Swish)               (None, 1, 1, 6)      0           ['conv2d_74[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_57[0][0]']               \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 1, 1, 144)    0           ['conv2d_75[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_18 (Multiply)         (None, 38, 38, 144)  0           ['activation_18[0][0]',          \n",
            "                                                                  'swish_56[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_18[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 38, 38, 24)  96          ['conv2d_76[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_9 (DropConnect)   (None, 38, 38, 24)   0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 38, 38, 24)   0           ['drop_connect_9[0][0]',         \n",
            "                                                                  'batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 38, 38, 144)  3456        ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 38, 38, 144)  576        ['conv2d_77[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_58 (Swish)               (None, 38, 38, 144)  0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_19 (Depthwise  (None, 19, 19, 144)  3600       ['swish_58[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_19[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_59 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_19 (Lambda)             (None, 1, 1, 144)    0           ['swish_59[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_19[0][0]']              \n",
            "                                                                                                  \n",
            " swish_60 (Swish)               (None, 1, 1, 6)      0           ['conv2d_78[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_60[0][0]']               \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 1, 1, 144)    0           ['conv2d_79[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_19 (Multiply)         (None, 19, 19, 144)  0           ['activation_19[0][0]',          \n",
            "                                                                  'swish_59[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_19[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 19, 19, 40)  160         ['conv2d_80[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 19, 19, 240)  960        ['conv2d_81[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_61 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_20 (Depthwise  (None, 19, 19, 240)  6000       ['swish_61[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_20[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_62 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_20 (Lambda)             (None, 1, 1, 240)    0           ['swish_62[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_20[0][0]']              \n",
            "                                                                                                  \n",
            " swish_63 (Swish)               (None, 1, 1, 10)     0           ['conv2d_82[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_63[0][0]']               \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 1, 1, 240)    0           ['conv2d_83[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_20 (Multiply)         (None, 19, 19, 240)  0           ['activation_20[0][0]',          \n",
            "                                                                  'swish_62[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_20[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 19, 19, 40)  160         ['conv2d_84[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_10 (DropConnect)  (None, 19, 19, 40)   0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 19, 19, 40)   0           ['drop_connect_10[0][0]',        \n",
            "                                                                  'batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, 19, 19, 240)  9600        ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 19, 19, 240)  960        ['conv2d_85[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_64 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_21 (Depthwise  (None, 10, 10, 240)  2160       ['swish_64[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_21[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_65 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_21 (Lambda)             (None, 1, 1, 240)    0           ['swish_65[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_21[0][0]']              \n",
            "                                                                                                  \n",
            " swish_66 (Swish)               (None, 1, 1, 10)     0           ['conv2d_86[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_66[0][0]']               \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 1, 1, 240)    0           ['conv2d_87[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_21 (Multiply)         (None, 10, 10, 240)  0           ['activation_21[0][0]',          \n",
            "                                                                  'swish_65[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_21[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 10, 10, 80)  320         ['conv2d_88[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_89[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_67 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_22 (Depthwise  (None, 10, 10, 480)  4320       ['swish_67[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_22[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_68 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_22 (Lambda)             (None, 1, 1, 480)    0           ['swish_68[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_22[0][0]']              \n",
            "                                                                                                  \n",
            " swish_69 (Swish)               (None, 1, 1, 20)     0           ['conv2d_90[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_69[0][0]']               \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 1, 1, 480)    0           ['conv2d_91[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_22 (Multiply)         (None, 10, 10, 480)  0           ['activation_22[0][0]',          \n",
            "                                                                  'swish_68[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_22[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 10, 10, 80)  320         ['conv2d_92[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_11 (DropConnect)  (None, 10, 10, 80)   0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 10, 10, 80)   0           ['drop_connect_11[0][0]',        \n",
            "                                                                  'batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 10, 10, 480)  38400       ['add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_93[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_70 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_70[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_23 (Depthwise  (None, 10, 10, 480)  4320       ['swish_70[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_23[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_71 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_71[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_23 (Lambda)             (None, 1, 1, 480)    0           ['swish_71[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_94 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_23[0][0]']              \n",
            "                                                                                                  \n",
            " swish_72 (Swish)               (None, 1, 1, 20)     0           ['conv2d_94[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_95 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_72[0][0]']               \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 1, 1, 480)    0           ['conv2d_95[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_23 (Multiply)         (None, 10, 10, 480)  0           ['activation_23[0][0]',          \n",
            "                                                                  'swish_71[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_96 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_23[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_72 (BatchN  (None, 10, 10, 80)  320         ['conv2d_96[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_12 (DropConnect)  (None, 10, 10, 80)   0           ['batch_normalization_72[0][0]'] \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 10, 10, 80)   0           ['drop_connect_12[0][0]',        \n",
            "                                                                  'add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_97 (Conv2D)             (None, 10, 10, 480)  38400       ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_73 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_97[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_73 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_73[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_24 (Depthwise  (None, 10, 10, 480)  12000      ['swish_73[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_74 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_24[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_74 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_74[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_24 (Lambda)             (None, 1, 1, 480)    0           ['swish_74[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_98 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_24[0][0]']              \n",
            "                                                                                                  \n",
            " swish_75 (Swish)               (None, 1, 1, 20)     0           ['conv2d_98[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_99 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_75[0][0]']               \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 1, 1, 480)    0           ['conv2d_99[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_24 (Multiply)         (None, 10, 10, 480)  0           ['activation_24[0][0]',          \n",
            "                                                                  'swish_74[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_100 (Conv2D)            (None, 10, 10, 112)  53760       ['multiply_24[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_75 (BatchN  (None, 10, 10, 112)  448        ['conv2d_100[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_101 (Conv2D)            (None, 10, 10, 672)  75264       ['batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_76 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_101[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_76 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_76[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_25 (Depthwise  (None, 10, 10, 672)  16800      ['swish_76[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_77 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_25[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_77 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_77[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_25 (Lambda)             (None, 1, 1, 672)    0           ['swish_77[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_102 (Conv2D)            (None, 1, 1, 28)     18844       ['lambda_25[0][0]']              \n",
            "                                                                                                  \n",
            " swish_78 (Swish)               (None, 1, 1, 28)     0           ['conv2d_102[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_103 (Conv2D)            (None, 1, 1, 672)    19488       ['swish_78[0][0]']               \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 1, 1, 672)    0           ['conv2d_103[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_25 (Multiply)         (None, 10, 10, 672)  0           ['activation_25[0][0]',          \n",
            "                                                                  'swish_77[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_104 (Conv2D)            (None, 10, 10, 112)  75264       ['multiply_25[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_78 (BatchN  (None, 10, 10, 112)  448        ['conv2d_104[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_13 (DropConnect)  (None, 10, 10, 112)  0           ['batch_normalization_78[0][0]'] \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 10, 10, 112)  0           ['drop_connect_13[0][0]',        \n",
            "                                                                  'batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_105 (Conv2D)            (None, 10, 10, 672)  75264       ['add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_79 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_105[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_79 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_79[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_26 (Depthwise  (None, 10, 10, 672)  16800      ['swish_79[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_80 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_26[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_80 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_80[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_26 (Lambda)             (None, 1, 1, 672)    0           ['swish_80[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_106 (Conv2D)            (None, 1, 1, 28)     18844       ['lambda_26[0][0]']              \n",
            "                                                                                                  \n",
            " swish_81 (Swish)               (None, 1, 1, 28)     0           ['conv2d_106[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_107 (Conv2D)            (None, 1, 1, 672)    19488       ['swish_81[0][0]']               \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 1, 1, 672)    0           ['conv2d_107[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_26 (Multiply)         (None, 10, 10, 672)  0           ['activation_26[0][0]',          \n",
            "                                                                  'swish_80[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_108 (Conv2D)            (None, 10, 10, 112)  75264       ['multiply_26[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_81 (BatchN  (None, 10, 10, 112)  448        ['conv2d_108[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_14 (DropConnect)  (None, 10, 10, 112)  0           ['batch_normalization_81[0][0]'] \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 10, 10, 112)  0           ['drop_connect_14[0][0]',        \n",
            "                                                                  'add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_109 (Conv2D)            (None, 10, 10, 672)  75264       ['add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_82 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_109[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_82 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_82[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_27 (Depthwise  (None, 5, 5, 672)   16800       ['swish_82[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_83 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_27[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_83 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_83[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_27 (Lambda)             (None, 1, 1, 672)    0           ['swish_83[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_110 (Conv2D)            (None, 1, 1, 28)     18844       ['lambda_27[0][0]']              \n",
            "                                                                                                  \n",
            " swish_84 (Swish)               (None, 1, 1, 28)     0           ['conv2d_110[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_111 (Conv2D)            (None, 1, 1, 672)    19488       ['swish_84[0][0]']               \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 1, 1, 672)    0           ['conv2d_111[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_27 (Multiply)         (None, 5, 5, 672)    0           ['activation_27[0][0]',          \n",
            "                                                                  'swish_83[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_112 (Conv2D)            (None, 5, 5, 192)    129024      ['multiply_27[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_84 (BatchN  (None, 5, 5, 192)   768         ['conv2d_112[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_113 (Conv2D)            (None, 5, 5, 1152)   221184      ['batch_normalization_84[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_85 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_113[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_85 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_85[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_28 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_85[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_86 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_28[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_86 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_86[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_28 (Lambda)             (None, 1, 1, 1152)   0           ['swish_86[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_114 (Conv2D)            (None, 1, 1, 48)     55344       ['lambda_28[0][0]']              \n",
            "                                                                                                  \n",
            " swish_87 (Swish)               (None, 1, 1, 48)     0           ['conv2d_114[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_115 (Conv2D)            (None, 1, 1, 1152)   56448       ['swish_87[0][0]']               \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_115[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_28 (Multiply)         (None, 5, 5, 1152)   0           ['activation_28[0][0]',          \n",
            "                                                                  'swish_86[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_116 (Conv2D)            (None, 5, 5, 192)    221184      ['multiply_28[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_87 (BatchN  (None, 5, 5, 192)   768         ['conv2d_116[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_15 (DropConnect)  (None, 5, 5, 192)    0           ['batch_normalization_87[0][0]'] \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 5, 5, 192)    0           ['drop_connect_15[0][0]',        \n",
            "                                                                  'batch_normalization_84[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_117 (Conv2D)            (None, 5, 5, 1152)   221184      ['add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_88 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_117[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_88 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_88[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_29 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_88[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_89 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_29[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_89 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_89[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_29 (Lambda)             (None, 1, 1, 1152)   0           ['swish_89[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_118 (Conv2D)            (None, 1, 1, 48)     55344       ['lambda_29[0][0]']              \n",
            "                                                                                                  \n",
            " swish_90 (Swish)               (None, 1, 1, 48)     0           ['conv2d_118[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_119 (Conv2D)            (None, 1, 1, 1152)   56448       ['swish_90[0][0]']               \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_119[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_29 (Multiply)         (None, 5, 5, 1152)   0           ['activation_29[0][0]',          \n",
            "                                                                  'swish_89[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_120 (Conv2D)            (None, 5, 5, 192)    221184      ['multiply_29[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_90 (BatchN  (None, 5, 5, 192)   768         ['conv2d_120[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_16 (DropConnect)  (None, 5, 5, 192)    0           ['batch_normalization_90[0][0]'] \n",
            "                                                                                                  \n",
            " add_16 (Add)                   (None, 5, 5, 192)    0           ['drop_connect_16[0][0]',        \n",
            "                                                                  'add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_121 (Conv2D)            (None, 5, 5, 1152)   221184      ['add_16[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_91 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_121[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_91 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_91[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_30 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_91[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_92 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_30[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_92 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_92[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_30 (Lambda)             (None, 1, 1, 1152)   0           ['swish_92[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_122 (Conv2D)            (None, 1, 1, 48)     55344       ['lambda_30[0][0]']              \n",
            "                                                                                                  \n",
            " swish_93 (Swish)               (None, 1, 1, 48)     0           ['conv2d_122[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_123 (Conv2D)            (None, 1, 1, 1152)   56448       ['swish_93[0][0]']               \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_123[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_30 (Multiply)         (None, 5, 5, 1152)   0           ['activation_30[0][0]',          \n",
            "                                                                  'swish_92[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_124 (Conv2D)            (None, 5, 5, 192)    221184      ['multiply_30[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_93 (BatchN  (None, 5, 5, 192)   768         ['conv2d_124[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_17 (DropConnect)  (None, 5, 5, 192)    0           ['batch_normalization_93[0][0]'] \n",
            "                                                                                                  \n",
            " add_17 (Add)                   (None, 5, 5, 192)    0           ['drop_connect_17[0][0]',        \n",
            "                                                                  'add_16[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_125 (Conv2D)            (None, 5, 5, 1152)   221184      ['add_17[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_94 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_125[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_94 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_94[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_31 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_94[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_95 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_31[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_95 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_95[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_31 (Lambda)             (None, 1, 1, 1152)   0           ['swish_95[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_126 (Conv2D)            (None, 1, 1, 48)     55344       ['lambda_31[0][0]']              \n",
            "                                                                                                  \n",
            " swish_96 (Swish)               (None, 1, 1, 48)     0           ['conv2d_126[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_127 (Conv2D)            (None, 1, 1, 1152)   56448       ['swish_96[0][0]']               \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_127[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_31 (Multiply)         (None, 5, 5, 1152)   0           ['activation_31[0][0]',          \n",
            "                                                                  'swish_95[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_128 (Conv2D)            (None, 5, 5, 320)    368640      ['multiply_31[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_96 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_128[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_129 (Conv2D)            (None, 5, 5, 1280)   409600      ['batch_normalization_96[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_97 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_129[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_97 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_97[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 4,007,548\n",
            "Non-trainable params: 42,016\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Show architecture model"
      ],
      "metadata": {
        "id": "W1JJhCEWZjiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดัดแปลง GlobalMaxPooling2D เพื่อแปลง 4D the (batch_size, rows, cols,channels) tensor เป็น 2D tensor with shape (batch_size,channels)\n",
        "#GlobalMaxPooling2D ส่งผลให้มีจำนวนฟีเจอร์น้อยกว่ามากเมื่อเทียบกับเลเยอร์ Flatten ซึ่งช่วยลดจำนวนพารามิเตอร์ได้อย่างมีประสิทธิภาพ\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
        "# model.add(layers.Flatten(name=\"flatten\"))\n",
        "if dropout_rate > 0:\n",
        "    model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n",
        "# model.add(layers.Dense(256, activation='relu', name=\"fc1\"))\n",
        "model.add(layers.Dense(2, activation='softmax', name=\"fc_out\"))\n",
        "model.add(layers.Dense(1))"
      ],
      "metadata": {
        "id": "-9EQ5AdjZT9s"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "wmBUcgsMZVkW",
        "outputId": "39d6f2f4-d300-4dab-b23b-f0d82628a8bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 2)                 2562      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,052,129\n",
            "Trainable params: 4,010,113\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('This is the number of trainable layers '\n",
        "      'before freezing the conv base:', len(model.trainable_weights))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "print('This is the number of trainable layers '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ],
      "metadata": {
        "id": "xRyPafCIZXzU",
        "outputId": "4a108521-b87f-4da6-f95e-5f0533c96d40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable layers before freezing the conv base: 215\n",
            "This is the number of trainable layers after freezing the conv base: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting data augmentation"
      ],
      "metadata": {
        "id": "X9Xfp10TY9xE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "#Image Augmentation \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, # image input 0-255 --> 0-1 เปลี่ยนค่าสี\n",
        "      rotation_range=40,# หมุนภาพในองศา\n",
        "      width_shift_range=0.2, #เปลี่ยนความกว้าง\n",
        "      height_shift_range=0.2, #ปลี่ยนความสูง\n",
        "      shear_range=0.2, #ทำให้ภาพเบี้ยว\n",
        "      zoom_range=0.2, # Randomly zoom image\n",
        "      horizontal_flip=True, \n",
        "      #โดย Default เมื่อมีการเลื่อนภาพ บิดภาพ หมุนภาพ จะเกิดพื้นที่ว่างที่มุม \n",
        "      #ซึ่งจะมีการเติมภาพให้เต็มโดยใช้เทคนิคแบบ Nearest neighbor ซึ่งเป็นการดึงสีบริเวณใหล้าเคียงมาระบายให้เต็ม แต่เราก็ยังสามารถกำหนดวิธีการ Fill ภาพด้วยเทคนิคอื่นได้จาก Parameter fill_mode\n",
        "      fill_mode='nearest')\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe = train,\n",
        "        directory = train_dir,\n",
        "        x_col = 'path_Picture',\n",
        "        y_col = 'BET',\n",
        "        class_mode = 'other',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)\n",
        "\n",
        "validation_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe = val,\n",
        "        directory = validation_dir,\n",
        "        x_col = 'path_Picture',\n",
        "        y_col = 'BET',\n",
        "        class_mode = 'other',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)"
      ],
      "metadata": {
        "id": "GC-vPos9Y9HD",
        "outputId": "7245fd92-d27b-4b69-c931-94211d130854",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 598 validated image filenames.\n",
            "Found 101 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "8S60IpOWcB7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model.compile(\n",
        "#     loss=rmse,\n",
        "#     optimizer=Adam(),\n",
        "#     metrics=[rmse]"
      ],
      "metadata": {
        "id": "gOSRISmJXWec"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mse',\n",
        "              optimizer=Adam(learning_rate=2e-1),\n",
        "              metrics=['mae'])\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "Od8zqlOwb9Iw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90c3a1a6-31a9-436f-9aef-9069329b34d5"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-59-121c6c007c10>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37/37 [==============================] - 16s 255ms/step - loss: 1501082.5000 - mae: 997.7482 - val_loss: 534058.5625 - val_mae: 562.9104\n",
            "Epoch 2/200\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 1448123.0000 - mae: 975.3735 - val_loss: 498156.2500 - val_mae: 529.3901\n",
            "Epoch 3/200\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 1430092.2500 - mae: 965.4711 - val_loss: 491462.0000 - val_mae: 524.5332\n",
            "Epoch 4/200\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 1398895.6250 - mae: 954.0588 - val_loss: 464789.5000 - val_mae: 498.7621\n",
            "Epoch 5/200\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 1364619.3750 - mae: 936.8431 - val_loss: 458297.5312 - val_mae: 493.5039\n",
            "Epoch 6/200\n",
            "37/37 [==============================] - 4s 79ms/step - loss: 1370655.1250 - mae: 937.9224 - val_loss: 430079.7500 - val_mae: 463.0984\n",
            "Epoch 7/200\n",
            "37/37 [==============================] - 9s 216ms/step - loss: 1333659.8750 - mae: 922.0699 - val_loss: 435166.0000 - val_mae: 475.2218\n",
            "Epoch 8/200\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 1299310.3750 - mae: 903.5297 - val_loss: 412059.2812 - val_mae: 459.3333\n",
            "Epoch 9/200\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 1271174.8750 - mae: 889.1444 - val_loss: 396617.9688 - val_mae: 457.3021\n",
            "Epoch 10/200\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 1266018.2500 - mae: 888.1310 - val_loss: 408512.1562 - val_mae: 479.0417\n",
            "Epoch 11/200\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 1242101.3750 - mae: 875.4150 - val_loss: 374095.0000 - val_mae: 457.5833\n",
            "Epoch 12/200\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 1222221.1250 - mae: 865.4976 - val_loss: 357562.0000 - val_mae: 450.3254\n",
            "Epoch 13/200\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 1181734.5000 - mae: 846.0181 - val_loss: 365786.6562 - val_mae: 468.3459\n",
            "Epoch 14/200\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 1140045.2500 - mae: 828.8736 - val_loss: 343798.6562 - val_mae: 457.3021\n",
            "Epoch 15/200\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 1150647.0000 - mae: 833.1105 - val_loss: 335857.5938 - val_mae: 454.9277\n",
            "Epoch 16/200\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 1129384.0000 - mae: 820.7946 - val_loss: 336900.7500 - val_mae: 466.9659\n",
            "Epoch 17/200\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 1112630.7500 - mae: 810.5062 - val_loss: 336349.9062 - val_mae: 475.1929\n",
            "Epoch 18/200\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 1082675.8750 - mae: 796.4996 - val_loss: 312229.0312 - val_mae: 459.3333\n",
            "Epoch 19/200\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 1074828.3750 - mae: 793.0383 - val_loss: 315137.1875 - val_mae: 468.7649\n",
            "Epoch 20/200\n",
            "37/37 [==============================] - 4s 83ms/step - loss: 1036127.6875 - mae: 774.3033 - val_loss: 297351.3125 - val_mae: 459.6146\n",
            "Epoch 21/200\n",
            "37/37 [==============================] - 5s 113ms/step - loss: 1024304.6250 - mae: 770.4465 - val_loss: 290281.1562 - val_mae: 459.0521\n",
            "Epoch 22/200\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 1019825.5000 - mae: 765.9351 - val_loss: 300736.4062 - val_mae: 477.1642\n",
            "Epoch 23/200\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 997953.1875 - mae: 753.7645 - val_loss: 286808.9062 - val_mae: 468.0089\n",
            "Epoch 24/200\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 973757.8125 - mae: 740.7321 - val_loss: 273989.5312 - val_mae: 461.2813\n",
            "Epoch 25/200\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 945649.2500 - mae: 726.8982 - val_loss: 268643.6250 - val_mae: 461.0833\n",
            "Epoch 26/200\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 932121.7500 - mae: 722.8157 - val_loss: 263390.5625 - val_mae: 461.0833\n",
            "Epoch 27/200\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 931478.1250 - mae: 721.0392 - val_loss: 261113.5156 - val_mae: 464.6888\n",
            "Epoch 28/200\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 924765.1250 - mae: 718.1899 - val_loss: 256096.6719 - val_mae: 463.8864\n",
            "Epoch 29/200\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 877764.3125 - mae: 693.9099 - val_loss: 249448.0156 - val_mae: 461.0833\n",
            "Epoch 30/200\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 878778.4375 - mae: 691.6465 - val_loss: 245577.4219 - val_mae: 461.0833\n",
            "Epoch 31/200\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 872467.7500 - mae: 690.7639 - val_loss: 240212.5469 - val_mae: 459.2797\n",
            "Epoch 32/200\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 864178.5000 - mae: 691.3120 - val_loss: 244430.5781 - val_mae: 467.6512\n",
            "Epoch 33/200\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 842254.1875 - mae: 679.5476 - val_loss: 234399.7969 - val_mae: 460.9502\n",
            "Epoch 34/200\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 831208.2500 - mae: 675.4729 - val_loss: 229084.6250 - val_mae: 457.9481\n",
            "Epoch 35/200\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 810590.6250 - mae: 665.4355 - val_loss: 220989.8750 - val_mae: 452.6651\n",
            "Epoch 36/200\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 790962.8125 - mae: 661.5800 - val_loss: 225304.9375 - val_mae: 459.0521\n",
            "Epoch 37/200\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 794377.3750 - mae: 661.2867 - val_loss: 226707.0156 - val_mae: 462.5020\n",
            "Epoch 38/200\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 791323.1875 - mae: 662.2662 - val_loss: 224533.7344 - val_mae: 462.1315\n",
            "Epoch 39/200\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 765796.3125 - mae: 649.5918 - val_loss: 224714.3125 - val_mae: 463.6603\n",
            "Epoch 40/200\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 760831.2500 - mae: 650.4095 - val_loss: 216797.1719 - val_mae: 457.2481\n",
            "Epoch 41/200\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 758472.9375 - mae: 654.4422 - val_loss: 217979.6719 - val_mae: 459.5080\n",
            "Epoch 42/200\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 749517.5000 - mae: 652.8022 - val_loss: 217112.9531 - val_mae: 459.4326\n",
            "Epoch 43/200\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 733374.8750 - mae: 647.1027 - val_loss: 216142.0469 - val_mae: 459.0521\n",
            "Epoch 44/200\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 714400.3750 - mae: 641.2166 - val_loss: 217510.5000 - val_mae: 460.8391\n",
            "Epoch 45/200\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 714537.9375 - mae: 644.3821 - val_loss: 218738.4844 - val_mae: 462.3778\n",
            "Epoch 46/200\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 692883.1875 - mae: 638.9551 - val_loss: 219510.8906 - val_mae: 463.3958\n",
            "Epoch 47/200\n",
            "37/37 [==============================] - 9s 219ms/step - loss: 695058.9375 - mae: 638.3995 - val_loss: 216607.0469 - val_mae: 459.9366\n",
            "Epoch 48/200\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 680472.1250 - mae: 633.5130 - val_loss: 216366.2969 - val_mae: 459.3333\n",
            "Epoch 49/200\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 677843.5000 - mae: 635.6096 - val_loss: 218659.2031 - val_mae: 461.3646\n",
            "Epoch 50/200\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 673003.5000 - mae: 636.8819 - val_loss: 219110.5000 - val_mae: 460.9963\n",
            "Epoch 51/200\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 658336.2500 - mae: 631.0873 - val_loss: 218562.8594 - val_mae: 459.3333\n",
            "Epoch 52/200\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 651974.2500 - mae: 629.5220 - val_loss: 221222.9531 - val_mae: 461.3646\n",
            "Epoch 53/200\n",
            "37/37 [==============================] - 9s 219ms/step - loss: 638381.9375 - mae: 623.5130 - val_loss: 222074.6250 - val_mae: 461.0833\n",
            "Epoch 54/200\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 650274.4375 - mae: 633.9334 - val_loss: 223557.6719 - val_mae: 461.1685\n",
            "Epoch 55/200\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 632554.5625 - mae: 625.1627 - val_loss: 223692.7500 - val_mae: 459.3333\n",
            "Epoch 56/200\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 603034.2500 - mae: 616.7989 - val_loss: 224856.2969 - val_mae: 458.7607\n",
            "Epoch 57/200\n",
            "37/37 [==============================] - 8s 219ms/step - loss: 616221.4375 - mae: 619.5428 - val_loss: 229534.5000 - val_mae: 462.3873\n",
            "Epoch 58/200\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 619527.6250 - mae: 624.7329 - val_loss: 229144.5156 - val_mae: 460.1646\n",
            "Epoch 59/200\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 612873.5000 - mae: 623.2479 - val_loss: 227578.4531 - val_mae: 456.0080\n",
            "Epoch 60/200\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 608425.8750 - mae: 622.6057 - val_loss: 228274.5781 - val_mae: 453.9220\n",
            "Epoch 61/200\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 595123.0000 - mae: 616.0975 - val_loss: 235193.8281 - val_mae: 459.9271\n",
            "Epoch 62/200\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 597187.0000 - mae: 620.5631 - val_loss: 232200.5469 - val_mae: 453.2432\n",
            "Epoch 63/200\n",
            "37/37 [==============================] - 9s 226ms/step - loss: 588748.1250 - mae: 618.4596 - val_loss: 238172.9219 - val_mae: 457.2643\n",
            "Epoch 64/200\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 575842.9375 - mae: 612.0834 - val_loss: 246080.5625 - val_mae: 463.5881\n",
            "Epoch 65/200\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 578214.5625 - mae: 615.5021 - val_loss: 244322.2500 - val_mae: 459.2638\n",
            "Epoch 66/200\n",
            "37/37 [==============================] - 9s 222ms/step - loss: 575623.8750 - mae: 616.4604 - val_loss: 251990.7031 - val_mae: 464.1906\n",
            "Epoch 67/200\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 575688.1875 - mae: 620.2306 - val_loss: 251504.4531 - val_mae: 461.0833\n",
            "Epoch 68/200\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 567779.8750 - mae: 615.5482 - val_loss: 259828.2344 - val_mae: 468.2926\n",
            "Epoch 69/200\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 566767.3750 - mae: 620.3214 - val_loss: 264078.4688 - val_mae: 467.6810\n",
            "Epoch 70/200\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 554026.2500 - mae: 612.2529 - val_loss: 253425.7500 - val_mae: 453.2920\n",
            "Epoch 71/200\n",
            "37/37 [==============================] - 4s 79ms/step - loss: 562270.9375 - mae: 619.6188 - val_loss: 263596.0312 - val_mae: 461.3645\n",
            "Epoch 72/200\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 551584.8750 - mae: 613.9138 - val_loss: 261583.2656 - val_mae: 455.5999\n",
            "Epoch 73/200\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 553260.0000 - mae: 619.7364 - val_loss: 270128.9062 - val_mae: 463.1146\n",
            "Epoch 74/200\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 543547.1250 - mae: 615.0188 - val_loss: 280639.5312 - val_mae: 469.1272\n",
            "Epoch 75/200\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 536627.1875 - mae: 612.0275 - val_loss: 269498.3750 - val_mae: 453.1554\n",
            "Epoch 76/200\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 543397.2500 - mae: 616.4999 - val_loss: 278581.0000 - val_mae: 461.0833\n",
            "Epoch 77/200\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 543510.1875 - mae: 619.7874 - val_loss: 272574.7812 - val_mae: 450.7666\n",
            "Epoch 78/200\n",
            "37/37 [==============================] - 3s 83ms/step - loss: 537661.8750 - mae: 619.4020 - val_loss: 285043.5312 - val_mae: 461.0833\n",
            "Epoch 79/200\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 529107.4375 - mae: 616.0842 - val_loss: 288954.5312 - val_mae: 461.6458\n",
            "Epoch 80/200\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 539461.6875 - mae: 624.6748 - val_loss: 285044.9688 - val_mae: 452.2090\n",
            "Epoch 81/200\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 532110.9375 - mae: 620.6933 - val_loss: 288653.1562 - val_mae: 452.3665\n",
            "Epoch 82/200\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 526497.6875 - mae: 618.3998 - val_loss: 293668.8438 - val_mae: 456.5902\n",
            "Epoch 83/200\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 519335.0938 - mae: 615.4165 - val_loss: 296124.5625 - val_mae: 455.8335\n",
            "Epoch 84/200\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 526166.1875 - mae: 623.0916 - val_loss: 299406.0938 - val_mae: 456.0792\n",
            "Epoch 85/200\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 518206.6875 - mae: 621.8394 - val_loss: 296272.0625 - val_mae: 448.8513\n",
            "Epoch 86/200\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 526278.2500 - mae: 625.9865 - val_loss: 316479.4688 - val_mae: 468.5995\n",
            "Epoch 87/200\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 525703.2500 - mae: 628.0039 - val_loss: 319638.7188 - val_mae: 466.6923\n",
            "Epoch 88/200\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 515951.6250 - mae: 623.0625 - val_loss: 317046.4062 - val_mae: 461.3646\n",
            "Epoch 89/200\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 512376.6875 - mae: 622.7967 - val_loss: 301329.9062 - val_mae: 440.1896\n",
            "Epoch 90/200\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 518277.5000 - mae: 625.9644 - val_loss: 317374.8750 - val_mae: 453.7008\n",
            "Epoch 91/200\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 516544.0625 - mae: 627.3331 - val_loss: 326110.7812 - val_mae: 461.0833\n",
            "Epoch 92/200\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 512652.4375 - mae: 626.5429 - val_loss: 322228.4688 - val_mae: 452.9521\n",
            "Epoch 93/200\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 511593.1875 - mae: 626.1861 - val_loss: 338706.7188 - val_mae: 465.5355\n",
            "Epoch 94/200\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 515398.2812 - mae: 630.3447 - val_loss: 315818.9688 - val_mae: 438.6998\n",
            "Epoch 95/200\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 511520.5000 - mae: 628.3724 - val_loss: 338447.4688 - val_mae: 461.3646\n",
            "Epoch 96/200\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 508066.1875 - mae: 627.7109 - val_loss: 341385.5938 - val_mae: 459.3333\n",
            "Epoch 97/200\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 511221.7188 - mae: 631.6213 - val_loss: 344308.2500 - val_mae: 461.3646\n",
            "Epoch 98/200\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 505751.0312 - mae: 628.3114 - val_loss: 347045.8438 - val_mae: 459.6146\n",
            "Epoch 99/200\n",
            "37/37 [==============================] - 4s 87ms/step - loss: 506577.5312 - mae: 629.6743 - val_loss: 336105.5312 - val_mae: 444.6747\n",
            "Epoch 100/200\n",
            "37/37 [==============================] - 9s 217ms/step - loss: 505045.9375 - mae: 629.6685 - val_loss: 357770.2812 - val_mae: 467.2699\n",
            "Epoch 101/200\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 505317.3750 - mae: 630.3104 - val_loss: 360632.0000 - val_mae: 470.8782\n",
            "Epoch 102/200\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 504487.6562 - mae: 630.5211 - val_loss: 349044.7812 - val_mae: 455.6157\n",
            "Epoch 103/200\n",
            "37/37 [==============================] - 9s 217ms/step - loss: 510201.5625 - mae: 634.9806 - val_loss: 345520.4062 - val_mae: 452.6062\n",
            "Epoch 104/200\n",
            "37/37 [==============================] - 3s 83ms/step - loss: 510366.2500 - mae: 636.7555 - val_loss: 369584.5938 - val_mae: 478.1410\n",
            "Epoch 105/200\n",
            "37/37 [==============================] - 9s 217ms/step - loss: 502596.5000 - mae: 630.8017 - val_loss: 365038.0000 - val_mae: 471.3241\n",
            "Epoch 106/200\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 498170.6562 - mae: 632.0778 - val_loss: 374117.6250 - val_mae: 478.2118\n",
            "Epoch 107/200\n",
            "37/37 [==============================] - 8s 209ms/step - loss: 503176.9688 - mae: 633.0035 - val_loss: 369414.7812 - val_mae: 472.7635\n",
            "Epoch 108/200\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 507005.9062 - mae: 636.6238 - val_loss: 364958.6250 - val_mae: 468.6045\n",
            "Epoch 109/200\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 501883.3125 - mae: 633.7837 - val_loss: 381116.3750 - val_mae: 482.6978\n",
            "Epoch 110/200\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 494505.2500 - mae: 630.9894 - val_loss: 360166.0312 - val_mae: 460.5680\n",
            "Epoch 111/200\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 504876.9688 - mae: 636.1978 - val_loss: 369975.8750 - val_mae: 469.3918\n",
            "Epoch 112/200\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 502502.7500 - mae: 635.3942 - val_loss: 379614.9688 - val_mae: 480.2759\n",
            "Epoch 113/200\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 499662.6250 - mae: 633.7769 - val_loss: 388858.0312 - val_mae: 487.7168\n",
            "Epoch 114/200\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 498422.2188 - mae: 633.3752 - val_loss: 366927.6562 - val_mae: 465.9666\n",
            "Epoch 115/200\n",
            "37/37 [==============================] - 9s 217ms/step - loss: 500488.7500 - mae: 635.2418 - val_loss: 369523.8750 - val_mae: 466.5467\n",
            "Epoch 116/200\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 503477.1250 - mae: 638.6349 - val_loss: 394027.9062 - val_mae: 493.8208\n",
            "Epoch 117/200\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 495570.8438 - mae: 632.1084 - val_loss: 386191.1250 - val_mae: 483.4539\n",
            "Epoch 118/200\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 503182.1875 - mae: 637.4896 - val_loss: 380129.5000 - val_mae: 476.9023\n",
            "Epoch 119/200\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 502051.8438 - mae: 637.7181 - val_loss: 374314.9688 - val_mae: 470.4682\n",
            "Epoch 120/200\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 506559.7188 - mae: 641.1002 - val_loss: 399724.5938 - val_mae: 495.4575\n",
            "Epoch 121/200\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 502353.8750 - mae: 638.5578 - val_loss: 384965.8438 - val_mae: 479.8704\n",
            "Epoch 122/200\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 497698.2500 - mae: 635.3267 - val_loss: 386719.9062 - val_mae: 480.9166\n",
            "Epoch 123/200\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 500791.5312 - mae: 637.7970 - val_loss: 411966.7812 - val_mae: 506.5627\n",
            "Epoch 124/200\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 500895.1875 - mae: 638.0814 - val_loss: 388400.2812 - val_mae: 481.2977\n",
            "Epoch 125/200\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 504594.9062 - mae: 641.7363 - val_loss: 383055.2188 - val_mae: 475.6711\n",
            "Epoch 126/200\n",
            "37/37 [==============================] - 8s 214ms/step - loss: 501566.4688 - mae: 640.4131 - val_loss: 399626.8750 - val_mae: 491.7183\n",
            "Epoch 127/200\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 501894.2188 - mae: 638.7561 - val_loss: 407905.7188 - val_mae: 499.7581\n",
            "Epoch 128/200\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 502235.6562 - mae: 639.7994 - val_loss: 393225.1562 - val_mae: 484.8256\n",
            "Epoch 129/200\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 495960.1250 - mae: 636.5697 - val_loss: 402492.8750 - val_mae: 493.4533\n",
            "Epoch 130/200\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 496789.6562 - mae: 636.9333 - val_loss: 395284.2500 - val_mae: 486.5992\n",
            "Epoch 131/200\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 495923.6250 - mae: 636.0779 - val_loss: 412231.7500 - val_mae: 502.9581\n",
            "Epoch 132/200\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 500525.9688 - mae: 639.3743 - val_loss: 396202.7812 - val_mae: 486.0642\n",
            "Epoch 133/200\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 500532.2812 - mae: 639.0366 - val_loss: 387809.9062 - val_mae: 477.9359\n",
            "Epoch 134/200\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 505225.6250 - mae: 642.8226 - val_loss: 406326.2812 - val_mae: 496.2475\n",
            "Epoch 135/200\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 499885.2500 - mae: 639.5782 - val_loss: 397728.1562 - val_mae: 487.5039\n",
            "Epoch 136/200\n",
            "37/37 [==============================] - 8s 218ms/step - loss: 496559.4375 - mae: 636.8479 - val_loss: 414982.1250 - val_mae: 505.8705\n",
            "Epoch 137/200\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 499256.6875 - mae: 639.2519 - val_loss: 389200.5938 - val_mae: 478.7930\n",
            "Epoch 138/200\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 502799.5000 - mae: 641.1141 - val_loss: 390051.5000 - val_mae: 479.2821\n",
            "Epoch 139/200\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 502604.5312 - mae: 640.9843 - val_loss: 416183.7500 - val_mae: 504.3557\n",
            "Epoch 140/200\n",
            "37/37 [==============================] - 4s 81ms/step - loss: 501538.2500 - mae: 640.7373 - val_loss: 416974.6562 - val_mae: 506.5028\n",
            "Epoch 141/200\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 507186.2500 - mae: 644.8662 - val_loss: 409343.0000 - val_mae: 498.4096\n",
            "Epoch 142/200\n",
            "37/37 [==============================] - 9s 217ms/step - loss: 500237.0938 - mae: 639.2530 - val_loss: 425294.2812 - val_mae: 515.0750\n",
            "Epoch 143/200\n",
            "37/37 [==============================] - 9s 227ms/step - loss: 501278.9062 - mae: 640.5125 - val_loss: 419377.7500 - val_mae: 507.5072\n",
            "Epoch 144/200\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 501030.9375 - mae: 641.0513 - val_loss: 409699.3750 - val_mae: 497.7942\n",
            "Epoch 145/200\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 494483.6250 - mae: 638.9431 - val_loss: 394752.2500 - val_mae: 482.4528\n",
            "Epoch 146/200\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 502108.3750 - mae: 641.7834 - val_loss: 420351.0000 - val_mae: 508.0152\n",
            "Epoch 147/200\n",
            "37/37 [==============================] - 9s 229ms/step - loss: 501835.2812 - mae: 641.4658 - val_loss: 419788.7188 - val_mae: 507.3628\n",
            "Epoch 148/200\n",
            "37/37 [==============================] - 4s 88ms/step - loss: 505777.5938 - mae: 644.9730 - val_loss: 405364.5938 - val_mae: 492.6060\n",
            "Epoch 149/200\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 500776.5312 - mae: 640.2734 - val_loss: 396548.7500 - val_mae: 483.8115\n",
            "Epoch 150/200\n",
            "37/37 [==============================] - 9s 223ms/step - loss: 496200.8125 - mae: 639.1297 - val_loss: 405231.5938 - val_mae: 491.8551\n",
            "Epoch 151/200\n",
            "37/37 [==============================] - 4s 90ms/step - loss: 498965.6562 - mae: 639.7025 - val_loss: 405024.2500 - val_mae: 491.7474\n",
            "Epoch 152/200\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 501937.1562 - mae: 641.6712 - val_loss: 405316.5938 - val_mae: 491.9041\n",
            "Epoch 153/200\n",
            "37/37 [==============================] - 4s 82ms/step - loss: 501653.5000 - mae: 641.8994 - val_loss: 404824.1250 - val_mae: 491.2999\n",
            "Epoch 154/200\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 500430.5000 - mae: 639.8058 - val_loss: 405933.1250 - val_mae: 492.5819\n",
            "Epoch 155/200\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 499438.9062 - mae: 640.1682 - val_loss: 415965.3438 - val_mae: 501.4365\n",
            "Epoch 156/200\n",
            "37/37 [==============================] - 8s 221ms/step - loss: 498474.7188 - mae: 639.4468 - val_loss: 406623.0938 - val_mae: 492.6662\n",
            "Epoch 157/200\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 501488.7812 - mae: 641.3535 - val_loss: 407685.7188 - val_mae: 493.2748\n",
            "Epoch 158/200\n",
            "37/37 [==============================] - 3s 79ms/step - loss: 499601.4375 - mae: 641.2023 - val_loss: 398811.9062 - val_mae: 484.4623\n",
            "Epoch 159/200\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 501163.1562 - mae: 641.7381 - val_loss: 407458.0000 - val_mae: 493.4239\n",
            "Epoch 160/200\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 499846.8750 - mae: 641.2361 - val_loss: 409435.9062 - val_mae: 494.2536\n",
            "Epoch 161/200\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 503086.9688 - mae: 643.7628 - val_loss: 401537.7812 - val_mae: 486.2730\n",
            "Epoch 162/200\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 500457.1875 - mae: 641.4351 - val_loss: 417751.7188 - val_mae: 502.5045\n",
            "Epoch 163/200\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 499738.4375 - mae: 640.8091 - val_loss: 409517.2188 - val_mae: 494.0655\n",
            "Epoch 164/200\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 501019.0938 - mae: 641.4621 - val_loss: 417275.7188 - val_mae: 502.4691\n",
            "Epoch 165/200\n",
            "37/37 [==============================] - 3s 80ms/step - loss: 505285.7188 - mae: 644.9681 - val_loss: 408213.6250 - val_mae: 493.5765\n",
            "Epoch 166/200\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 501762.0312 - mae: 642.6526 - val_loss: 408518.0000 - val_mae: 493.7502\n",
            "Epoch 167/200\n",
            "37/37 [==============================] - 9s 221ms/step - loss: 503344.5000 - mae: 643.4850 - val_loss: 424410.0312 - val_mae: 510.0163\n",
            "Epoch 168/200\n",
            "37/37 [==============================] - 9s 220ms/step - loss: 499589.8750 - mae: 641.6118 - val_loss: 409021.3438 - val_mae: 494.0373\n",
            "Epoch 169/200\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 496175.2812 - mae: 639.5136 - val_loss: 416878.1562 - val_mae: 501.9828\n",
            "Epoch 170/200\n",
            "37/37 [==============================] - 3s 81ms/step - loss: 491336.6250 - mae: 637.0104 - val_loss: 409438.8438 - val_mae: 494.2553\n",
            "Epoch 171/200\n",
            "37/37 [==============================] - 5s 110ms/step - loss: 496793.1875 - mae: 639.0934 - val_loss: 408395.2812 - val_mae: 493.6595\n",
            "Epoch 172/200\n",
            "37/37 [==============================] - 8s 217ms/step - loss: 505519.4375 - mae: 645.1143 - val_loss: 408244.6250 - val_mae: 493.8578\n",
            "Epoch 173/200\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 499880.0312 - mae: 642.3599 - val_loss: 398026.8750 - val_mae: 484.3134\n",
            "Epoch 174/200\n",
            "37/37 [==============================] - 8s 210ms/step - loss: 500190.4688 - mae: 641.0667 - val_loss: 415840.2188 - val_mae: 501.6645\n",
            "Epoch 175/200\n",
            "37/37 [==============================] - 4s 89ms/step - loss: 501281.3125 - mae: 641.7764 - val_loss: 399531.5312 - val_mae: 485.1488\n",
            "Epoch 176/200\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 502787.5312 - mae: 642.3577 - val_loss: 416873.9688 - val_mae: 502.2442\n",
            "Epoch 177/200\n",
            "37/37 [==============================] - 8s 216ms/step - loss: 501192.1250 - mae: 642.7797 - val_loss: 409664.9062 - val_mae: 494.3939\n",
            "Epoch 178/200\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 501601.3750 - mae: 641.9158 - val_loss: 408678.2500 - val_mae: 493.8417\n",
            "Epoch 179/200\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 501461.1250 - mae: 642.3035 - val_loss: 415303.2188 - val_mae: 501.3680\n",
            "Epoch 180/200\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 502332.0000 - mae: 642.8912 - val_loss: 425026.2188 - val_mae: 510.3678\n",
            "Epoch 181/200\n",
            "37/37 [==============================] - 4s 91ms/step - loss: 499467.9062 - mae: 641.0374 - val_loss: 409166.5938 - val_mae: 494.1000\n",
            "Epoch 182/200\n",
            "37/37 [==============================] - 4s 81ms/step - loss: 495499.5312 - mae: 639.7854 - val_loss: 407938.7500 - val_mae: 493.1103\n",
            "Epoch 183/200\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 502988.4375 - mae: 642.4883 - val_loss: 408034.1250 - val_mae: 493.7411\n",
            "Epoch 184/200\n",
            "37/37 [==============================] - 4s 86ms/step - loss: 501216.4375 - mae: 641.9087 - val_loss: 408410.2500 - val_mae: 493.4109\n",
            "Epoch 185/200\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 501868.2188 - mae: 642.6631 - val_loss: 416736.1250 - val_mae: 502.1622\n",
            "Epoch 186/200\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 499724.6875 - mae: 640.8764 - val_loss: 416354.8438 - val_mae: 501.9582\n",
            "Epoch 187/200\n",
            "37/37 [==============================] - 8s 215ms/step - loss: 499027.1250 - mae: 642.1608 - val_loss: 415925.4062 - val_mae: 501.7123\n",
            "Epoch 188/200\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 498036.7188 - mae: 639.5003 - val_loss: 433480.2500 - val_mae: 519.1953\n",
            "Epoch 189/200\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 501955.1875 - mae: 642.4594 - val_loss: 400010.3438 - val_mae: 485.4278\n",
            "Epoch 190/200\n",
            "37/37 [==============================] - 4s 84ms/step - loss: 498291.5625 - mae: 639.5792 - val_loss: 432329.3438 - val_mae: 517.6915\n",
            "Epoch 191/200\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 489164.9688 - mae: 634.5751 - val_loss: 414536.2500 - val_mae: 500.6350\n",
            "Epoch 192/200\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 499180.9688 - mae: 640.8805 - val_loss: 422548.3750 - val_mae: 508.6368\n",
            "Epoch 193/200\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 496162.8125 - mae: 639.4158 - val_loss: 423734.1562 - val_mae: 509.3192\n",
            "Epoch 194/200\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 502041.9062 - mae: 643.0797 - val_loss: 398967.8438 - val_mae: 484.5534\n",
            "Epoch 195/200\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 503488.5000 - mae: 643.6766 - val_loss: 422776.2812 - val_mae: 508.7721\n",
            "Epoch 196/200\n",
            "37/37 [==============================] - 3s 77ms/step - loss: 497062.5938 - mae: 638.6625 - val_loss: 415555.8438 - val_mae: 501.7985\n",
            "Epoch 197/200\n",
            "37/37 [==============================] - 4s 79ms/step - loss: 500622.2812 - mae: 641.3192 - val_loss: 399022.8438 - val_mae: 484.5855\n",
            "Epoch 198/200\n",
            "37/37 [==============================] - 9s 224ms/step - loss: 501081.5625 - mae: 642.1100 - val_loss: 434519.4688 - val_mae: 519.5029\n",
            "Epoch 199/200\n",
            "37/37 [==============================] - 8s 212ms/step - loss: 502542.7812 - mae: 643.0427 - val_loss: 407816.6250 - val_mae: 493.3601\n",
            "Epoch 200/200\n",
            "37/37 [==============================] - 8s 213ms/step - loss: 501530.5000 - mae: 641.6895 - val_loss: 408316.4688 - val_mae: 493.6352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.history "
      ],
      "metadata": {
        "id": "tO_KJFVJu6ya",
        "outputId": "847c3ae2-628e-4987-8635-3dab27e08644",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': [1501082.5,\n",
              "  1448123.0,\n",
              "  1430092.25,\n",
              "  1398895.625,\n",
              "  1364619.375,\n",
              "  1370655.125,\n",
              "  1333659.875,\n",
              "  1299310.375,\n",
              "  1271174.875,\n",
              "  1266018.25,\n",
              "  1242101.375,\n",
              "  1222221.125,\n",
              "  1181734.5,\n",
              "  1140045.25,\n",
              "  1150647.0,\n",
              "  1129384.0,\n",
              "  1112630.75,\n",
              "  1082675.875,\n",
              "  1074828.375,\n",
              "  1036127.6875,\n",
              "  1024304.625,\n",
              "  1019825.5,\n",
              "  997953.1875,\n",
              "  973757.8125,\n",
              "  945649.25,\n",
              "  932121.75,\n",
              "  931478.125,\n",
              "  924765.125,\n",
              "  877764.3125,\n",
              "  878778.4375,\n",
              "  872467.75,\n",
              "  864178.5,\n",
              "  842254.1875,\n",
              "  831208.25,\n",
              "  810590.625,\n",
              "  790962.8125,\n",
              "  794377.375,\n",
              "  791323.1875,\n",
              "  765796.3125,\n",
              "  760831.25,\n",
              "  758472.9375,\n",
              "  749517.5,\n",
              "  733374.875,\n",
              "  714400.375,\n",
              "  714537.9375,\n",
              "  692883.1875,\n",
              "  695058.9375,\n",
              "  680472.125,\n",
              "  677843.5,\n",
              "  673003.5,\n",
              "  658336.25,\n",
              "  651974.25,\n",
              "  638381.9375,\n",
              "  650274.4375,\n",
              "  632554.5625,\n",
              "  603034.25,\n",
              "  616221.4375,\n",
              "  619527.625,\n",
              "  612873.5,\n",
              "  608425.875,\n",
              "  595123.0,\n",
              "  597187.0,\n",
              "  588748.125,\n",
              "  575842.9375,\n",
              "  578214.5625,\n",
              "  575623.875,\n",
              "  575688.1875,\n",
              "  567779.875,\n",
              "  566767.375,\n",
              "  554026.25,\n",
              "  562270.9375,\n",
              "  551584.875,\n",
              "  553260.0,\n",
              "  543547.125,\n",
              "  536627.1875,\n",
              "  543397.25,\n",
              "  543510.1875,\n",
              "  537661.875,\n",
              "  529107.4375,\n",
              "  539461.6875,\n",
              "  532110.9375,\n",
              "  526497.6875,\n",
              "  519335.09375,\n",
              "  526166.1875,\n",
              "  518206.6875,\n",
              "  526278.25,\n",
              "  525703.25,\n",
              "  515951.625,\n",
              "  512376.6875,\n",
              "  518277.5,\n",
              "  516544.0625,\n",
              "  512652.4375,\n",
              "  511593.1875,\n",
              "  515398.28125,\n",
              "  511520.5,\n",
              "  508066.1875,\n",
              "  511221.71875,\n",
              "  505751.03125,\n",
              "  506577.53125,\n",
              "  505045.9375,\n",
              "  505317.375,\n",
              "  504487.65625,\n",
              "  510201.5625,\n",
              "  510366.25,\n",
              "  502596.5,\n",
              "  498170.65625,\n",
              "  503176.96875,\n",
              "  507005.90625,\n",
              "  501883.3125,\n",
              "  494505.25,\n",
              "  504876.96875,\n",
              "  502502.75,\n",
              "  499662.625,\n",
              "  498422.21875,\n",
              "  500488.75,\n",
              "  503477.125,\n",
              "  495570.84375,\n",
              "  503182.1875,\n",
              "  502051.84375,\n",
              "  506559.71875,\n",
              "  502353.875,\n",
              "  497698.25,\n",
              "  500791.53125,\n",
              "  500895.1875,\n",
              "  504594.90625,\n",
              "  501566.46875,\n",
              "  501894.21875,\n",
              "  502235.65625,\n",
              "  495960.125,\n",
              "  496789.65625,\n",
              "  495923.625,\n",
              "  500525.96875,\n",
              "  500532.28125,\n",
              "  505225.625,\n",
              "  499885.25,\n",
              "  496559.4375,\n",
              "  499256.6875,\n",
              "  502799.5,\n",
              "  502604.53125,\n",
              "  501538.25,\n",
              "  507186.25,\n",
              "  500237.09375,\n",
              "  501278.90625,\n",
              "  501030.9375,\n",
              "  494483.625,\n",
              "  502108.375,\n",
              "  501835.28125,\n",
              "  505777.59375,\n",
              "  500776.53125,\n",
              "  496200.8125,\n",
              "  498965.65625,\n",
              "  501937.15625,\n",
              "  501653.5,\n",
              "  500430.5,\n",
              "  499438.90625,\n",
              "  498474.71875,\n",
              "  501488.78125,\n",
              "  499601.4375,\n",
              "  501163.15625,\n",
              "  499846.875,\n",
              "  503086.96875,\n",
              "  500457.1875,\n",
              "  499738.4375,\n",
              "  501019.09375,\n",
              "  505285.71875,\n",
              "  501762.03125,\n",
              "  503344.5,\n",
              "  499589.875,\n",
              "  496175.28125,\n",
              "  491336.625,\n",
              "  496793.1875,\n",
              "  505519.4375,\n",
              "  499880.03125,\n",
              "  500190.46875,\n",
              "  501281.3125,\n",
              "  502787.53125,\n",
              "  501192.125,\n",
              "  501601.375,\n",
              "  501461.125,\n",
              "  502332.0,\n",
              "  499467.90625,\n",
              "  495499.53125,\n",
              "  502988.4375,\n",
              "  501216.4375,\n",
              "  501868.21875,\n",
              "  499724.6875,\n",
              "  499027.125,\n",
              "  498036.71875,\n",
              "  501955.1875,\n",
              "  498291.5625,\n",
              "  489164.96875,\n",
              "  499180.96875,\n",
              "  496162.8125,\n",
              "  502041.90625,\n",
              "  503488.5,\n",
              "  497062.59375,\n",
              "  500622.28125,\n",
              "  501081.5625,\n",
              "  502542.78125,\n",
              "  501530.5],\n",
              " 'mae': [997.7481689453125,\n",
              "  975.3734741210938,\n",
              "  965.4711303710938,\n",
              "  954.058837890625,\n",
              "  936.8430786132812,\n",
              "  937.92236328125,\n",
              "  922.0698852539062,\n",
              "  903.5296630859375,\n",
              "  889.1444091796875,\n",
              "  888.1310424804688,\n",
              "  875.4149780273438,\n",
              "  865.4976196289062,\n",
              "  846.01806640625,\n",
              "  828.8735961914062,\n",
              "  833.1105346679688,\n",
              "  820.7945556640625,\n",
              "  810.5061645507812,\n",
              "  796.4996337890625,\n",
              "  793.0382690429688,\n",
              "  774.3032836914062,\n",
              "  770.4464721679688,\n",
              "  765.93505859375,\n",
              "  753.7644653320312,\n",
              "  740.7321166992188,\n",
              "  726.898193359375,\n",
              "  722.815673828125,\n",
              "  721.0391845703125,\n",
              "  718.18994140625,\n",
              "  693.909912109375,\n",
              "  691.646484375,\n",
              "  690.7638549804688,\n",
              "  691.31201171875,\n",
              "  679.547607421875,\n",
              "  675.472900390625,\n",
              "  665.4354858398438,\n",
              "  661.5799560546875,\n",
              "  661.2866821289062,\n",
              "  662.2661743164062,\n",
              "  649.591796875,\n",
              "  650.4095458984375,\n",
              "  654.4421997070312,\n",
              "  652.8021850585938,\n",
              "  647.1026611328125,\n",
              "  641.216552734375,\n",
              "  644.382080078125,\n",
              "  638.9551391601562,\n",
              "  638.3994750976562,\n",
              "  633.5130004882812,\n",
              "  635.609619140625,\n",
              "  636.8818969726562,\n",
              "  631.0872802734375,\n",
              "  629.52197265625,\n",
              "  623.5130004882812,\n",
              "  633.9334106445312,\n",
              "  625.1626586914062,\n",
              "  616.7988891601562,\n",
              "  619.5428466796875,\n",
              "  624.73291015625,\n",
              "  623.2479248046875,\n",
              "  622.605712890625,\n",
              "  616.0975341796875,\n",
              "  620.5631103515625,\n",
              "  618.4595947265625,\n",
              "  612.0833740234375,\n",
              "  615.5020751953125,\n",
              "  616.4603881835938,\n",
              "  620.2305908203125,\n",
              "  615.5482177734375,\n",
              "  620.3214111328125,\n",
              "  612.2529296875,\n",
              "  619.6188354492188,\n",
              "  613.913818359375,\n",
              "  619.7363891601562,\n",
              "  615.018798828125,\n",
              "  612.0275268554688,\n",
              "  616.4998779296875,\n",
              "  619.7874145507812,\n",
              "  619.4020385742188,\n",
              "  616.0841674804688,\n",
              "  624.6748046875,\n",
              "  620.6932983398438,\n",
              "  618.3997802734375,\n",
              "  615.41650390625,\n",
              "  623.0916137695312,\n",
              "  621.83935546875,\n",
              "  625.9864501953125,\n",
              "  628.00390625,\n",
              "  623.0625,\n",
              "  622.7966918945312,\n",
              "  625.9644165039062,\n",
              "  627.3330688476562,\n",
              "  626.5429077148438,\n",
              "  626.1860961914062,\n",
              "  630.3446655273438,\n",
              "  628.3724365234375,\n",
              "  627.7109375,\n",
              "  631.621337890625,\n",
              "  628.3114013671875,\n",
              "  629.67431640625,\n",
              "  629.6685180664062,\n",
              "  630.3103637695312,\n",
              "  630.5211181640625,\n",
              "  634.9805908203125,\n",
              "  636.7554931640625,\n",
              "  630.8016967773438,\n",
              "  632.0777587890625,\n",
              "  633.0035400390625,\n",
              "  636.6238403320312,\n",
              "  633.78369140625,\n",
              "  630.9894409179688,\n",
              "  636.19775390625,\n",
              "  635.3942260742188,\n",
              "  633.7769165039062,\n",
              "  633.375244140625,\n",
              "  635.2418212890625,\n",
              "  638.6349487304688,\n",
              "  632.1083984375,\n",
              "  637.4895629882812,\n",
              "  637.7181396484375,\n",
              "  641.1001586914062,\n",
              "  638.5578002929688,\n",
              "  635.3267211914062,\n",
              "  637.7969970703125,\n",
              "  638.0814208984375,\n",
              "  641.7362670898438,\n",
              "  640.4130859375,\n",
              "  638.756103515625,\n",
              "  639.7994384765625,\n",
              "  636.5697021484375,\n",
              "  636.933349609375,\n",
              "  636.0779418945312,\n",
              "  639.374267578125,\n",
              "  639.03662109375,\n",
              "  642.8225708007812,\n",
              "  639.5781860351562,\n",
              "  636.847900390625,\n",
              "  639.2518920898438,\n",
              "  641.1140747070312,\n",
              "  640.9843139648438,\n",
              "  640.7373046875,\n",
              "  644.8662109375,\n",
              "  639.2529907226562,\n",
              "  640.5125122070312,\n",
              "  641.0513305664062,\n",
              "  638.943115234375,\n",
              "  641.7833862304688,\n",
              "  641.4658203125,\n",
              "  644.9729614257812,\n",
              "  640.2734375,\n",
              "  639.1296997070312,\n",
              "  639.7024536132812,\n",
              "  641.6712036132812,\n",
              "  641.8993530273438,\n",
              "  639.8057861328125,\n",
              "  640.168212890625,\n",
              "  639.4468383789062,\n",
              "  641.353515625,\n",
              "  641.2022705078125,\n",
              "  641.7380981445312,\n",
              "  641.236083984375,\n",
              "  643.7627563476562,\n",
              "  641.4351196289062,\n",
              "  640.8091430664062,\n",
              "  641.4620971679688,\n",
              "  644.9680786132812,\n",
              "  642.6526489257812,\n",
              "  643.4850463867188,\n",
              "  641.6117553710938,\n",
              "  639.5136108398438,\n",
              "  637.0104370117188,\n",
              "  639.0933837890625,\n",
              "  645.1142578125,\n",
              "  642.3599243164062,\n",
              "  641.0667114257812,\n",
              "  641.7763671875,\n",
              "  642.357666015625,\n",
              "  642.7797241210938,\n",
              "  641.9158325195312,\n",
              "  642.3035278320312,\n",
              "  642.8911743164062,\n",
              "  641.037353515625,\n",
              "  639.785400390625,\n",
              "  642.48828125,\n",
              "  641.90869140625,\n",
              "  642.6631469726562,\n",
              "  640.8764038085938,\n",
              "  642.1607666015625,\n",
              "  639.5003051757812,\n",
              "  642.4593505859375,\n",
              "  639.5792236328125,\n",
              "  634.5751342773438,\n",
              "  640.8804931640625,\n",
              "  639.4158325195312,\n",
              "  643.0797119140625,\n",
              "  643.6766357421875,\n",
              "  638.6624755859375,\n",
              "  641.3191528320312,\n",
              "  642.1099853515625,\n",
              "  643.0426635742188,\n",
              "  641.6895141601562],\n",
              " 'val_loss': [534058.5625,\n",
              "  498156.25,\n",
              "  491462.0,\n",
              "  464789.5,\n",
              "  458297.53125,\n",
              "  430079.75,\n",
              "  435166.0,\n",
              "  412059.28125,\n",
              "  396617.96875,\n",
              "  408512.15625,\n",
              "  374095.0,\n",
              "  357562.0,\n",
              "  365786.65625,\n",
              "  343798.65625,\n",
              "  335857.59375,\n",
              "  336900.75,\n",
              "  336349.90625,\n",
              "  312229.03125,\n",
              "  315137.1875,\n",
              "  297351.3125,\n",
              "  290281.15625,\n",
              "  300736.40625,\n",
              "  286808.90625,\n",
              "  273989.53125,\n",
              "  268643.625,\n",
              "  263390.5625,\n",
              "  261113.515625,\n",
              "  256096.671875,\n",
              "  249448.015625,\n",
              "  245577.421875,\n",
              "  240212.546875,\n",
              "  244430.578125,\n",
              "  234399.796875,\n",
              "  229084.625,\n",
              "  220989.875,\n",
              "  225304.9375,\n",
              "  226707.015625,\n",
              "  224533.734375,\n",
              "  224714.3125,\n",
              "  216797.171875,\n",
              "  217979.671875,\n",
              "  217112.953125,\n",
              "  216142.046875,\n",
              "  217510.5,\n",
              "  218738.484375,\n",
              "  219510.890625,\n",
              "  216607.046875,\n",
              "  216366.296875,\n",
              "  218659.203125,\n",
              "  219110.5,\n",
              "  218562.859375,\n",
              "  221222.953125,\n",
              "  222074.625,\n",
              "  223557.671875,\n",
              "  223692.75,\n",
              "  224856.296875,\n",
              "  229534.5,\n",
              "  229144.515625,\n",
              "  227578.453125,\n",
              "  228274.578125,\n",
              "  235193.828125,\n",
              "  232200.546875,\n",
              "  238172.921875,\n",
              "  246080.5625,\n",
              "  244322.25,\n",
              "  251990.703125,\n",
              "  251504.453125,\n",
              "  259828.234375,\n",
              "  264078.46875,\n",
              "  253425.75,\n",
              "  263596.03125,\n",
              "  261583.265625,\n",
              "  270128.90625,\n",
              "  280639.53125,\n",
              "  269498.375,\n",
              "  278581.0,\n",
              "  272574.78125,\n",
              "  285043.53125,\n",
              "  288954.53125,\n",
              "  285044.96875,\n",
              "  288653.15625,\n",
              "  293668.84375,\n",
              "  296124.5625,\n",
              "  299406.09375,\n",
              "  296272.0625,\n",
              "  316479.46875,\n",
              "  319638.71875,\n",
              "  317046.40625,\n",
              "  301329.90625,\n",
              "  317374.875,\n",
              "  326110.78125,\n",
              "  322228.46875,\n",
              "  338706.71875,\n",
              "  315818.96875,\n",
              "  338447.46875,\n",
              "  341385.59375,\n",
              "  344308.25,\n",
              "  347045.84375,\n",
              "  336105.53125,\n",
              "  357770.28125,\n",
              "  360632.0,\n",
              "  349044.78125,\n",
              "  345520.40625,\n",
              "  369584.59375,\n",
              "  365038.0,\n",
              "  374117.625,\n",
              "  369414.78125,\n",
              "  364958.625,\n",
              "  381116.375,\n",
              "  360166.03125,\n",
              "  369975.875,\n",
              "  379614.96875,\n",
              "  388858.03125,\n",
              "  366927.65625,\n",
              "  369523.875,\n",
              "  394027.90625,\n",
              "  386191.125,\n",
              "  380129.5,\n",
              "  374314.96875,\n",
              "  399724.59375,\n",
              "  384965.84375,\n",
              "  386719.90625,\n",
              "  411966.78125,\n",
              "  388400.28125,\n",
              "  383055.21875,\n",
              "  399626.875,\n",
              "  407905.71875,\n",
              "  393225.15625,\n",
              "  402492.875,\n",
              "  395284.25,\n",
              "  412231.75,\n",
              "  396202.78125,\n",
              "  387809.90625,\n",
              "  406326.28125,\n",
              "  397728.15625,\n",
              "  414982.125,\n",
              "  389200.59375,\n",
              "  390051.5,\n",
              "  416183.75,\n",
              "  416974.65625,\n",
              "  409343.0,\n",
              "  425294.28125,\n",
              "  419377.75,\n",
              "  409699.375,\n",
              "  394752.25,\n",
              "  420351.0,\n",
              "  419788.71875,\n",
              "  405364.59375,\n",
              "  396548.75,\n",
              "  405231.59375,\n",
              "  405024.25,\n",
              "  405316.59375,\n",
              "  404824.125,\n",
              "  405933.125,\n",
              "  415965.34375,\n",
              "  406623.09375,\n",
              "  407685.71875,\n",
              "  398811.90625,\n",
              "  407458.0,\n",
              "  409435.90625,\n",
              "  401537.78125,\n",
              "  417751.71875,\n",
              "  409517.21875,\n",
              "  417275.71875,\n",
              "  408213.625,\n",
              "  408518.0,\n",
              "  424410.03125,\n",
              "  409021.34375,\n",
              "  416878.15625,\n",
              "  409438.84375,\n",
              "  408395.28125,\n",
              "  408244.625,\n",
              "  398026.875,\n",
              "  415840.21875,\n",
              "  399531.53125,\n",
              "  416873.96875,\n",
              "  409664.90625,\n",
              "  408678.25,\n",
              "  415303.21875,\n",
              "  425026.21875,\n",
              "  409166.59375,\n",
              "  407938.75,\n",
              "  408034.125,\n",
              "  408410.25,\n",
              "  416736.125,\n",
              "  416354.84375,\n",
              "  415925.40625,\n",
              "  433480.25,\n",
              "  400010.34375,\n",
              "  432329.34375,\n",
              "  414536.25,\n",
              "  422548.375,\n",
              "  423734.15625,\n",
              "  398967.84375,\n",
              "  422776.28125,\n",
              "  415555.84375,\n",
              "  399022.84375,\n",
              "  434519.46875,\n",
              "  407816.625,\n",
              "  408316.46875],\n",
              " 'val_mae': [562.910400390625,\n",
              "  529.3900756835938,\n",
              "  524.533203125,\n",
              "  498.7621154785156,\n",
              "  493.50390625,\n",
              "  463.0983581542969,\n",
              "  475.2217712402344,\n",
              "  459.3333435058594,\n",
              "  457.3020935058594,\n",
              "  479.0417175292969,\n",
              "  457.5833435058594,\n",
              "  450.3254089355469,\n",
              "  468.3459167480469,\n",
              "  457.3020935058594,\n",
              "  454.927734375,\n",
              "  466.9658508300781,\n",
              "  475.19287109375,\n",
              "  459.3333435058594,\n",
              "  468.7649230957031,\n",
              "  459.6145935058594,\n",
              "  459.0520935058594,\n",
              "  477.1641540527344,\n",
              "  468.0088806152344,\n",
              "  461.2812805175781,\n",
              "  461.0833435058594,\n",
              "  461.0833435058594,\n",
              "  464.6888122558594,\n",
              "  463.8864440917969,\n",
              "  461.0833435058594,\n",
              "  461.0833435058594,\n",
              "  459.2796936035156,\n",
              "  467.6512145996094,\n",
              "  460.9501953125,\n",
              "  457.9481201171875,\n",
              "  452.6650695800781,\n",
              "  459.0520935058594,\n",
              "  462.5019836425781,\n",
              "  462.1314697265625,\n",
              "  463.6602783203125,\n",
              "  457.2481384277344,\n",
              "  459.5079650878906,\n",
              "  459.4326477050781,\n",
              "  459.0520935058594,\n",
              "  460.8390808105469,\n",
              "  462.3777770996094,\n",
              "  463.3958435058594,\n",
              "  459.9366149902344,\n",
              "  459.3333435058594,\n",
              "  461.3645935058594,\n",
              "  460.9963073730469,\n",
              "  459.3333435058594,\n",
              "  461.3645935058594,\n",
              "  461.0833435058594,\n",
              "  461.16845703125,\n",
              "  459.3333435058594,\n",
              "  458.7606506347656,\n",
              "  462.3872985839844,\n",
              "  460.1646423339844,\n",
              "  456.0079650878906,\n",
              "  453.9220275878906,\n",
              "  459.9271240234375,\n",
              "  453.2431640625,\n",
              "  457.2642517089844,\n",
              "  463.588134765625,\n",
              "  459.2637939453125,\n",
              "  464.1905517578125,\n",
              "  461.0833435058594,\n",
              "  468.2925720214844,\n",
              "  467.6810302734375,\n",
              "  453.2919921875,\n",
              "  461.3645324707031,\n",
              "  455.599853515625,\n",
              "  463.1145935058594,\n",
              "  469.127197265625,\n",
              "  453.1553649902344,\n",
              "  461.0833435058594,\n",
              "  450.7666015625,\n",
              "  461.0833435058594,\n",
              "  461.6458435058594,\n",
              "  452.208984375,\n",
              "  452.366455078125,\n",
              "  456.5902404785156,\n",
              "  455.83349609375,\n",
              "  456.0791931152344,\n",
              "  448.851318359375,\n",
              "  468.5994567871094,\n",
              "  466.6922607421875,\n",
              "  461.3645935058594,\n",
              "  440.1896057128906,\n",
              "  453.7008361816406,\n",
              "  461.0833435058594,\n",
              "  452.9520568847656,\n",
              "  465.5354919433594,\n",
              "  438.6997985839844,\n",
              "  461.3645935058594,\n",
              "  459.3333435058594,\n",
              "  461.3645935058594,\n",
              "  459.6145935058594,\n",
              "  444.6746826171875,\n",
              "  467.2699279785156,\n",
              "  470.878173828125,\n",
              "  455.61572265625,\n",
              "  452.606201171875,\n",
              "  478.1410217285156,\n",
              "  471.3241271972656,\n",
              "  478.2117614746094,\n",
              "  472.7635192871094,\n",
              "  468.6045227050781,\n",
              "  482.6978454589844,\n",
              "  460.5680236816406,\n",
              "  469.391845703125,\n",
              "  480.27587890625,\n",
              "  487.716796875,\n",
              "  465.9666442871094,\n",
              "  466.5467224121094,\n",
              "  493.8207702636719,\n",
              "  483.4538879394531,\n",
              "  476.90234375,\n",
              "  470.4682312011719,\n",
              "  495.45751953125,\n",
              "  479.870361328125,\n",
              "  480.9166259765625,\n",
              "  506.562744140625,\n",
              "  481.2977294921875,\n",
              "  475.6710510253906,\n",
              "  491.71826171875,\n",
              "  499.758056640625,\n",
              "  484.8255615234375,\n",
              "  493.4533386230469,\n",
              "  486.5991516113281,\n",
              "  502.9580993652344,\n",
              "  486.0641784667969,\n",
              "  477.9358825683594,\n",
              "  496.2474670410156,\n",
              "  487.50390625,\n",
              "  505.8705139160156,\n",
              "  478.7929992675781,\n",
              "  479.2821350097656,\n",
              "  504.3556823730469,\n",
              "  506.5027770996094,\n",
              "  498.4096374511719,\n",
              "  515.074951171875,\n",
              "  507.5071716308594,\n",
              "  497.794189453125,\n",
              "  482.4527893066406,\n",
              "  508.0151672363281,\n",
              "  507.36279296875,\n",
              "  492.60595703125,\n",
              "  483.8115234375,\n",
              "  491.8551330566406,\n",
              "  491.7474060058594,\n",
              "  491.9041442871094,\n",
              "  491.2998962402344,\n",
              "  492.5818786621094,\n",
              "  501.4364929199219,\n",
              "  492.6662292480469,\n",
              "  493.2747802734375,\n",
              "  484.4622802734375,\n",
              "  493.4238586425781,\n",
              "  494.2536315917969,\n",
              "  486.2730407714844,\n",
              "  502.5044860839844,\n",
              "  494.0654602050781,\n",
              "  502.4691162109375,\n",
              "  493.5765075683594,\n",
              "  493.750244140625,\n",
              "  510.0162658691406,\n",
              "  494.0372619628906,\n",
              "  501.9828186035156,\n",
              "  494.2552795410156,\n",
              "  493.6595458984375,\n",
              "  493.8577575683594,\n",
              "  484.3133850097656,\n",
              "  501.6645202636719,\n",
              "  485.1488037109375,\n",
              "  502.2442321777344,\n",
              "  494.3938903808594,\n",
              "  493.8417053222656,\n",
              "  501.3680419921875,\n",
              "  510.3677978515625,\n",
              "  494.1000061035156,\n",
              "  493.1102600097656,\n",
              "  493.7410888671875,\n",
              "  493.410888671875,\n",
              "  502.1622009277344,\n",
              "  501.9581604003906,\n",
              "  501.7123107910156,\n",
              "  519.1953125,\n",
              "  485.4278259277344,\n",
              "  517.6914672851562,\n",
              "  500.6350402832031,\n",
              "  508.6368103027344,\n",
              "  509.3192443847656,\n",
              "  484.5533752441406,\n",
              "  508.7720642089844,\n",
              "  501.7984619140625,\n",
              "  484.5854797363281,\n",
              "  519.5028686523438,\n",
              "  493.3601379394531,\n",
              "  493.6352233886719]}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot training performance"
      ],
      "metadata": {
        "id": "54D1y5fZcRUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "mae = history.history['mae']\n",
        "val_mae = history.history['val_mae']\n",
        "\n",
        "epochs_x = range(len(loss))\n",
        "\n",
        "plt.plot(epochs_x, mae, 'co', label='Training MAE')\n",
        "plt.plot(epochs_x, val_mae, 'k', label='Validation MAE')\n",
        "plt.title('Training and Mean squared error')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'co', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Aig-yHOBcNrP",
        "outputId": "4eefa849-8a5d-4e68-ddd6-b6fd54f73ea1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAABBR0lEQVR4nO3deXxTVfo/8M/Tlm7sS2nZoQ77WigyyGIRFQRlU1FEFgERZURwAQRGGf0yijIj8lNBEBUVwYVRQGEQEAaQRYsiiAUELFCEAgXK2tI2n98f9+aatkm6pU1In/frlVeTc29uTm7SJ+c+59xzhSSUUkqVDgHeroBSSqmSo0FfKaVKEQ36SilVimjQV0qpUkSDvlJKlSIa9JVSqhTRoF+KichqERnm6XW9SUQSReRWb9fDn4nIdBH5yNv1UIWjQf86IyKXHG42Ebnq8HhwQbZF8g6Sizy9rq8SkfdFhCLSN0f5a2b5cC9VTakSo0H/OkOynP0G4CiAuxzKFtvXE5Eg79XSpx0AMNT+wNxPAwEc8lqNvMib3xNnr13Q+uj3vOA06PsJEYkTkSQRmSQiJwG8JyKVReQrETktIufM+7UdnrNRREaZ94eLyBYRmWWu+7uI3FHIdRuIyCYRuSgi60TkTVfpgHzW8UUR+c7c3jciUs1h+RAROSIiKSIyNR+7aiWAziJS2XzcE8BuACdz1GuEiCSYdVojIvUclr0uIsdE5IKI7BSRLg7LpovIpyLygVnfvSIS6+K9i3mUccrc1h4RaWEuqyoiK8zy7819sMVcVt88Mgly2Jbj53ODiHxr7pMzIrJYRCo5rJtofk92A7gsIkEi8lcR2Soi50XkZxGJc1i/gYj8z3w/awFY+9/F+7pTRHaZ29oqIq3cvPZfzPcyUkSOAvhWRAJEZJr5uZ4y92XFHO/dWt9dXVRuGvT9SxSAKgDqARgN4/N9z3xcF8BVAG+4eX4HAPth/FO/AmChiEgh1v0YwPcAqgKYDmCIm9fMTx0fAPAQgOoAggE8DQAi0gzAXHP7Nc3Xqw330gAsB3C/+XgogA8cVxAj/TMFwAAAEQA2A1jisMoPANrA2NcfA/hMREIdlvcBsBRAJQArnLwfu9sBdAXQCEBFGEccKeayN8261gAwwrzllwB4CcY+aQqgDozPwdEgAL3NOkYC+BrA/5nv6WkAy0Qkwlz3YwA7YXzWLwJw2bcjIjEA3gXwCIzP420AK0QkxMVrZ5plN5t17QFguHnrBiAaQDnk3oeO66uCIKm36/QGIBHAreb9OADXAIS6Wb8NgHMOjzcCGGXeHw7goMOycAAEEFWQdWEE7kwA4Q7LPwLwUT7fk7M6TnN4/BiA/5r3nwOw1GFZWXMf3Opi2+/DCGydAWyDEXSSAYQB2AJguLneagAjHZ4XAOAKgHoutnsOQGvz/nQA6xyWNQNw1cXzboGRbvorgACH8kAAGQCaOJT9E8AW8359c38HOfssnbxOPwA/5fjejHB4PAnAhzmeswZGcLd/nmUdln3s6vOE8SP8Yo6y/QBudvHa9vcS7VC2HsBjDo8bm/sjyNn6eivYTVv6/uU0yTT7AxEJF5G3zcPkCwA2AagkIoEunm+lOEheMe+WK+C6NQGcdSgDgGOuKpzPOjqmXq441Kmm47ZJXsafLWWXSG6B0YKfCuArkldzrFIPwOtmeuI8gLMwWs+1zDo/baZ+Us3lFZE95ZGzvqHiJPdM8lsYLdg3AZwSkfkiUsGsWxCy77cjeb0vOxGJFJGlInLc3KcfIXdKxnHb9QDca3+/5nvqDOMooyaMH+HL+axLPQBP5dhWHXM7zl7bWVnNHK9xBMb+iMxjGyofNOj7l5xTpj4Fo5XUgWQFGKkEwAhgxeUEgCoiEu5QVsfN+kWp4wnHbZuvWTWf9fzIfO0PnCw7BuARkpUcbmEkt5r5+4kwUjGVSVYCkJrP+uZCcg7JdjCOCBoBeAbAaRita8f9Vtfhvj0AO+7jKIf7/4TxXWhp7tMHndTP8btyDEZL3/H9liX5Mox9XFlEyrqoS07HAMzIsa1wko7pMWdT+zqW/QHjx8Px9TJhHJW524bKBw36/q08jBz5eRGpAuD54n5BkkcAxAOYLiLBItIRwF3FVMfPAdwpIp1FJBjAC8j/d3oOgNtgHFnkNA/AsyLSHABEpKKI3OtQ30wYgTlIRJ4DUKEAdbaISHsR6SAiZWAE8jQANpJZAP4DYx+Gm30XVh6d5GkAxwE8KCKBIjICwA0Omy4P4BKAVBGpBeOHxJ2PANwlIj3M7YWKMTCgtsPn+Q/z8+wM95/nAgBjzPclIlJWRHqLSPkC7JolACaYHcjlYPyIfUIyM4/nqXzQoO/fZsPIV58BsB3Af0vodQcD6Agj1fJ/AD4BkO5i3dkoZB1J7gUwFkaO+QSM3HpSPp97luR6mknjHMu+ADATwFIzPfILAPvopDVmHQ/ASDukofCphgowguQ5c1spAF41l/0NRhrrJIy+iPdyPPdhGME8BUBzAFsdlv0DQFsYRyBfw/gBcYnkMQD2zuvT5vt5Bn/GhwdgdNyfhfGj7OzoyL6teLNub5jv6yCMPqCCeBfAhzB+kH+HsY8fL+A2lAvi5DuvlEeJyCcA9pEs9iMNfyXGiWOjSHb2dl3U9U1b+srjzLTFDeZ4654wWpFferlaSikYPeJKeVoUjJRCVRjplkdJ/uTdKimlAE3vKKVUqaLpHaWUKkV8Or1TrVo11q9f39vVUEqp68rOnTvPkIxwtsyng379+vURHx/v7WoopdR1RURcnjWt6R2llCpFNOgrpVQpokFfKaVKEZ/O6SulSk5GRgaSkpKQlpaW98rKJ4SGhqJ27dooU6ZMvp+TZ9AXkXcB3AngFEn7VX2qwJhPpT6M+bEHkjxnXkTjdQC9YEwpO5zkj+ZzhgGYZm72/3idX29VKX+TlJSE8uXLo379+nB97RzlK0giJSUFSUlJaNCgQb6fl5/0zvswLinnaDKA9SQbwrjgwWSz/A4ADc3baBgXVLD/SDwPY9KmGwE8L39ers7jFicno/62bQjYuBH1t23D4uTkvJ+kVCmXlpaGqlWrasC/TogIqlatWuAjszyDPslNMGbXc9QXgL2lvgjGlXns5R/QsB3GxTBqwLik2VpzZsNzANYi9w+JRyxOTsbo/ftxJD0dBHAkPR2j9+/XwK9UPmjAv74U5vMqbEduJMkT5v2T+POKNrWQfZrZJLPMVXkuIjJaROJFJP706dMFrtjUw4dxxWbLVnbFZsPUw4cLvC2llPI3RR69Y85H7rEJfEjOJxlLMjYiwukJZW4dTXc+bburcqWUb0hJSUGbNm3Qpk0bREVFoVatWtbja9euuX1ufHw8xo0bl+dr3HTTTR6p68aNGyEieOedd6yyXbt2QUQwa9YsqywzMxMRERGYPHlytufHxcWhcePG1vu75557PFKv/Cjs6J1kEalB8oSZvjlllh9H9ku81TbLjsO4cLdj+cZCvrZbdUNCcMRJgK8bElIcL6dUqbU4ORlTDx/G0fR01A0JwYzoaAyOjMz7iS5UrVoVu3btAgBMnz4d5cqVw9NPP20tz8zMRFCQ85AVGxuL2NjYPF9j69atea6TXy1atMCnn36KUaNGAQCWLFmC1q1bZ1tn7dq1aNSoET777DO89NJL2dIxixcvzledPa2wLf0V+PPybcMALHcoH2peJu2vAFLNNNAaALeLSGWzA/d2s8zjZkRHIzwg+9sKDwjAjOjo4ng5pUqlkuo7Gz58OMaMGYMOHTpg4sSJ+P7779GxY0fExMTgpptuwv79+wEYLe8777wTgPGDMWLECMTFxSE6Ohpz5syxtleuXDlr/bi4ONxzzz1o0qQJBg8eDPuMw6tWrUKTJk3Qrl07jBs3ztpuTvXq1UNaWhqSk5NBEv/9739xxx13ZFtnyZIleOKJJ1C3bl1s27bNo/umsPIzZHMJjFZ6NRFJgjEK52UAn4rISBiXeRtorr4KxnDNgzCGbD4EGJemE5EXAfxgrvcCyZydwx5hb2l4sgWilMrOXd+Zp//XkpKSsHXrVgQGBuLChQvYvHkzgoKCsG7dOkyZMgXLli3L9Zx9+/Zhw4YNuHjxIho3boxHH30011j2n376CXv37kXNmjXRqVMnfPfdd4iNjcUjjzyCTZs2oUGDBhg0aJDbut1zzz347LPPEBMTg7Zt2yLEIaOQlpaGdevW4e2338b58+exZMmSbOmlwYMHIywsDABw22234dVXX821/eKQZ9An6epdd3eyLmFcs9TZdt6Fce3LYjc4MlKDvFLFqCT7zu69914EBgYCAFJTUzFs2DD89ttvEBFkZGQ4fU7v3r0REhKCkJAQVK9eHcnJyahdu3a2dW688UarrE2bNkhMTES5cuUQHR1tjXsfNGgQ5s+f77JuAwcOxH333Yd9+/Zh0KBB2dJHX331Fbp164awsDDcfffdePHFFzF79mzrvVxv6R2fp2P1lSo+rvrIiqPvrGzZstb9v//97+jWrRt++eUXrFy50uUYdccWd2BgIDIzMwu1Tl6ioqJQpkwZrF27Ft27Z28HL1myBOvWrUP9+vXRrl07pKSk4Ntvvy3wa3iaX07DYM832g8/7flGAHoEoJQHzIiOzvY/BpRM31lqaipq1TJGe7///vse337jxo1x+PBhJCYmon79+vjkk0/yfM4LL7yAU6dOWS14AFYa6tixY9aPy3vvvYclS5bgtttu83i9C8IvW/o6Vl+p4jU4MhLzGzdGvZAQCIB6ISGY37hxsTeqJk6ciGeffRYxMTGFapnnJSwsDG+99RZ69uyJdu3aoXz58qhYsaLb59x0003o169ftrIvvvgCt9xyS7ajib59+2LlypVIN1NggwcPtoZs3nrrrR5/L6749DVyY2NjWZiLqARs3Oj0xAEBYIuLK2q1lPJLCQkJaNq0qber4XWXLl1CuXLlQBJjx45Fw4YNMWHCBG9XyyVnn5uI7CTptMPAL1v6rvKKAYDm9pVSbi1YsABt2rRB8+bNkZqaikceecTbVfIov8zpO8s3AkAWoLl9pZRbEyZM8OmWfVH5ZUvfnm8MdLJMc/tKqdLML4M+YAR+m4tlOg+PUqq08tugD7jO7VcJdHYMoJRS/s+vg/6M6Gg4u4jYRZtNO3SVUqWSXwf9wZGRqOBkVr5rpOb1lfIx3bp1w5o12edhnD17Nh599FGXz4mLi4N9WHevXr1w/vz5XOtMnz4923THznz55Zf49ddfrcfPPfcc1q1bV4DaO+eLUzD7ddAHgLMuTuDQvL5SvmXQoEFYunRptrKlS5fmOemZ3apVq1CpUqVCvXbOoP/CCy947IQp+xTMdnlNwZzz3KnFixdj165d2LVrFz7//PMi18fvg35JzhGilCq8e+65B19//bV1wZTExET88ccf6NKlCx599FHExsaiefPmeP75550+v379+jhz5gwAYMaMGWjUqBE6d+5sTb8MGGPw27dvj9atW+Puu+/GlStXsHXrVqxYsQLPPPMM2rRpg0OHDmH48OFWgF2/fj1iYmLQsmVLjBgxwjqjtn79+nj++efRtm1btGzZEvv27XNaL1+bgtkvx+k7cjZmX2DMx1N/2zaddlkpJ8aPH29d0MRT2rRpg9mzZ7tcXqVKFdx4441YvXo1+vbti6VLl2LgwIEQEcyYMQNVqlRBVlYWunfvjt27d6NVq1ZOt7Nz504sXboUu3btQmZmJtq2bYt27doBAAYMGICHH34YADBt2jQsXLgQjz/+OPr06YM777wzV/okLS0Nw4cPx/r169GoUSMMHToUc+fOxfjx4wEA1apVw48//oi33noLs2bNypbGceRLUzD7fUvfcY4QO/vBk140XSnf4pjicUztfPrpp2jbti1iYmKwd+/ebKmYnDZv3oz+/fsjPDwcFSpUQJ8+faxlv/zyC7p06YKWLVti8eLF2Lt3r9v67N+/Hw0aNECjRo0AAMOGDcOmTZus5QMGDAAAtGvXDomJiS63M3DgQHz22WdYsmRJrnRVzimYv/zyS2RlZVnLHdM7nphz3+9b+sCfZ98OSUjINSdPcV34QanrmbsWeXHq27cvJkyYgB9//BFXrlxBu3bt8Pvvv2PWrFn44YcfULlyZQwfPtzllMp5GT58OL788ku0bt0a77//PjZu3Fik+tpb7HlNzew4BfPrr7+ebd79JUuWYMuWLahfvz4AWFMwF9dsnH7f0rebeviwy6u3a6euUr6hXLly6NatG0aMGGG1iC9cuICyZcuiYsWKSE5OxurVq91uo2vXrvjyyy9x9epVXLx4EStXrrSWXbx4ETVq1EBGRgYWL15slZcvXx4XL17Mta3GjRsjMTERBw8eBAB8+OGHuPnmmwv13l544QXMnDnT6RTMR48eRWJiIhITE/Hmm29iyZIlhXqN/CgVLX3AfWDXTl2lfMegQYPQv39/K83TunVrxMTEoEmTJqhTpw46derk9vlt27bFfffdh9atW6N69epo3769tezFF19Ehw4dEBERgQ4dOliB/v7778fDDz+MOXPmZBshExoaivfeew/33nsvMjMz0b59e4wZM6ZQ78sxT2/nagrmiRMnZpuC2Z7Tr1atWpGHkvrl1MrO1N+2DUecBH4B8GHTppreUaWeTq18fdKplV2YER2N8IDcb5cwUj/amauUKg1KTdDPOYpHHJbpKB6lVGlRaoI+YAT+xI4dUS8kxOUoHqVKM19O96rcCvN5laqgb+eqU1dH8ajSLDQ0FCkpKRr4rxMkkZKSgtDQ0AI9r9SM3nFUNyTEaaeujuJRpVnt2rWRlJSE06dPe7sqKp9CQ0NRu3btAj2nVAZ9Z1MzhAcEYEZ0tBdrpZR3lSlTBg0aNPB2NVQxK5XpHcdOXQFQLyQE8xs31mGbSim/Vypb+sCfUzNMPXwYR9PTrU5cDfxKKX9WpJa+iDwhIr+IyF4RGW+WVRGRtSLym/m3slkuIjJHRA6KyG4RaeuB+hfa4uRkjN6/H0fS00HosE2lVOlQ6KAvIi0APAzgRgCtAdwpIn8BMBnAepINAaw3HwPAHQAamrfRAOYWod5FNvXw4Ww5fUCHbSql/F9RWvpNAewgeYVkJoD/ARgAoC+AReY6iwD0M+/3BfABDdsBVBKRGkV4/SLRYZtKqdKoKEH/FwBdRKSqiIQD6AWgDoBIkifMdU4CsCfJawE45vD8JLMsGxEZLSLxIhJfnEPH9IpaSqnSqNBBn2QCgJkAvgHwXwC7AGTlWIeAyxmNXW13PslYkrERERGFrV6eXM3FcyQ9HdW2bNHcvlLKLxWpI5fkQpLtSHYFcA7AAQDJ9rSN+feUufpxGEcCdrXNMq+wD9us6jC3tV1KZiZG7NungV8p5XeKOnqnuvm3Lox8/scAVgAYZq4yDMBy8/4KAEPNUTx/BZDqkAbyisGRkSgX5HzU6jVSO3WVUn6nqOP0l4lIVQAZAMaSPC8iLwP4VERGAjgCYKC57ioYef+DAK4AeKiIr+0R7jputVNXKeVvihT0SXZxUpYCoLuTcgIYW5TXKw6u5uEBjMOgxcnJesKWUspvlMppGBzNiI5GGRfLsgA9YUsp5VdKfdAfHBmJ95o2ddqhC+gJW0op/1Lqgz5gBP4zXbpku5qWI83tK6X8hQZ9B65OzKri4ihAKaWuNxr0HbjK71+02TSvr5TyCxr0HQyOjEQFJ+P2dcy+UspfaNDP4WxmptNyzesrpfyBBv0cdCI2pZQ/06Cfg7OJ2PT6uUopf6FBPwe9fq5Syp9p0HdicGQkEjt2xIdNmwIAhiQkoP62bTqCRyl13Su1F0bPi/0auvZLKtqvoQvoxdOVUtcvbem7oNfQVUr5Iw36Lug1dJVS/kiDvguuhmgS0Py+Uuq6pUHfBVfX0AX+zO9r4FdKXW806Lvg7hq6gOb3lVLXJw36ebhKulym+X2l1PVGg74bzkbwONKpGZRS1xsN+m64a8kLgF5Vq5ZcZZRSygM06LvhriVPAItOntTOXKXUdUWDvhvuRvAA2pmrlLr+aNB3w3HyNVeOpKdra18pdd3QoJ8H++Rr7gK/jtlXSl0vNOjnk7tUj6Z5lFLXC51lM5/sM2s+mJDgdLmO2VdKXQ+K1NIXkQkisldEfhGRJSISKiINRGSHiBwUkU9EJNhcN8R8fNBcXt8j76AEDY6MdJnm0TH7SqnrQaGDvojUAjAOQCzJFgACAdwPYCaA10j+BcA5ACPNp4wEcM4sf81c77rjKs1zKStL8/pKKZ9X1Jx+EIAwEQkCEA7gBIBbAHxuLl8EoJ95v6/5GOby7iIiRXz9EudqTp6UzEzt0FVK+bxCB32SxwHMAnAURrBPBbATwHmSmeZqSQBqmfdrAThmPjfTXD/XKa0iMlpE4kUk/vTp04WtXrEaHBmJckG5u0Ou2Gx44sABL9RIKaXypyjpncowWu8NANQEUBZAz6JWiOR8krEkYyMiIoq6uWLjquM2RdM8SikfVpT0zq0Afid5mmQGgP8A6ASgkpnuAYDaAI6b948DqAMA5vKKAFKK8Ppe5a7jVodvKqV8VVGC/lEAfxWRcDM33x3ArwA2ALjHXGcYgOXm/RXmY5jLvyXdzFvs42ZER7tcpsM3lVK+qig5/R0wOmR/BLDH3NZ8AJMAPCkiB2Hk7BeaT1kIoKpZ/iSAyUWot9cNjoxEVSd5fUCHbyqlfFeRTs4i+TyA53MUHwZwo5N10wDcW5TX8zWvN2yI0fv3Z5tzPzwgwO1RgFJKeZNOw1AEOSdkC8SfUzJoZ65SyhfpNAxFZJ+ewbHFb79wuuNypZTyBdrS9wBnl1XUMftKKV+kQd8D3I3Zr7Zli6Z6lFI+Q4O+B7gbraPTMyilfIkGfQ/Ia7SOzrevlPIVGvQ9wN2YfTs9YUsp5Qs06HvI6w0bur2Iup6wpZTyBRr0PcTVlMsAIAB6Vc01oahSSpU4DfoeNDgyEme6dMGjNWvC8UIBBLDo5EntzFVKeZ0G/WKwKiUFOWeS085cpZQv0KBfDFx12mpnrlLK2zToFwNXnbYBgKZ4lFJepUG/GLi6eHoWoCdqKaW8SoN+MbCP5Mk9jkdz+0op79KgX0wGR0bC5mKZ5vaVUt6iQb8Yucrt64laSilv0aBfjJzl9vVELaWUN2nQL0aDIyMxLCoq14lac//4Q6dcVkp5hQb9YubsRC3AmHJ5SEICHtMLrSilSpAG/WLmrtNWW/1KqZKmQb+Y5afTVi+0opQqKRr0i5mrE7Vy0vH7SqmSoEG/mLmbcjknHb+vlCpuGvRLgKspl3PS8ftKqeKmQb8EvdWoET5s2tRpqz88ICDPa+0qpVRRFTroi0hjEdnlcLsgIuNFpIqIrBWR38y/lc31RUTmiMhBEdktIm099zauH/ZW/0dNm6JeSAgEQL2QEMxv3BiDIyO9XT2llJ8T0tko8gJuRCQQwHEAHQCMBXCW5MsiMhlAZZKTRKQXgMcB9DLXe51kB3fbjY2NZXx8fJHrp5RSpYmI7CQZ62yZp9I73QEcInkEQF8Ai8zyRQD6mff7AviAhu0AKolIDQ+9vlJKqXwI8tB27gewxLwfSfKEef8kAHvOohaAYw7PSTLLTqCUWpycjKmHD+NIejoCYcy3Xy8kBDOiozXVo5QqFkVu6YtIMIA+AD7LuYxG7qhA+SMRGS0i8SISf/r06aJWz2ctTk7G6P37ccQcpplllh9JT8eDCQmQjRtRf9s2PWFLKeVRnkjv3AHgR5L26JRsT9uYf0+Z5ccB1HF4Xm2zLBuS80nGkoyNiIjwQPV809TDh3HF5mrGfcOR9HQ9U1cp5VGeCPqD8GdqBwBWABhm3h8GYLlD+VBzFM9fAaQ6pIFKnfyeiKVn6iqlPKlIQV9EygK4DcB/HIpfBnCbiPwG4FbzMQCsAnAYwEEACwA8VpTXvt4V5EQsPVNXKeUpRerIJXkZQNUcZSkwRvPkXJcwhnMqGHPyjN6/P88UDwBUyccUDkoplR96Rq6X2OfkqZefWTizsnT6ZaWUR2jQ96LBkZFI7NgRjIuzztB1RadfVkp5ggZ9H2H/AXA3IZt26iqlikqDvo/Jq4NXO3WVUkWhQd/H5HXRlQBAUzxKqULz1DQMykPs0y88ceAAUrKyci3PAvBgQgIeTEgAAFQNCsLrDRvqtA1KqXzRlr4Pcpx+Oa/BmimZmRixb5+2/pVS+aJB34cNjoxE3qP4gWukdvAqpfJF0zs+rm5IiDUpmztH0tNRbfNmKyWkaR+llDPa0vdxM6Kj3Q7jdOTYB6BpH6WUMxr0fdzgyEiMyeOC6q5cIzEsIUEDv1LKokH/OmC/oLr9jN2C/ABkARii8/MrD1icnIz627YhII/vUn7XK+rrFuR1PF2novB2XTxyjdziotfIdS1g48aCXZ3GFB4QoBdhv07Zr7R2ND0ddXNcYc3dssJs0/GqbgLnV0IqA6BCUBDOZmYakwKKICUzM9d69u8cALdXisvPa+ZHAACbw7YB5HtyQ3fbqxoYiDSbDZedxEzHdSCCs5mZ1v4EYO3jcJFcz7e/V8f3nPM9FPT/1d01cjXoX6fqb9uWrw5eV/SyjL7JXRDOGbgEwJiaNQEA8/74w2mQdBY8FicnuzwPRAA0DQtDwtWrhQ66vkQAhIggzYfjXF4K01DToO+HFicn46GEBGR4aHs62qdo8moxO5YD2U++s+/771JTcwXvorR4lf+oFxKCxI4d872+Bn0/lbPFVjUoCAOrV8fcP/4o1PaCRfBukyYug5X+IDj32IEDuYJ1eEAAOlaogG/Pn9egrYpMANji4vK/vgb90qXali1Oc6sFkbOFWRr6AnL+0PWqWhWrUlJwND09W85aW9+qpHmypa8nZ/mh1xs2LFLHFZA7qNmndb7egn5+OirtnYqOwfxIenq2IybH/LcGfFWSwgMCrLSgJ2jQ90P2wOyJkRCOjqSn+0TaJ791yJl2OZKejtH79+O9EyeypV3s4VyDuW9yNXomP6NqrldFHb3jjqZ3SgHHVm1RBYvgmpPvTEmNBnI2isXZkMDSmoIpK8ZZHAUJgO6ek7OD39kRkrNhis5GCTkbSulueWG/S+5GJxVmwEJ+GxmO64n5Xpyp52Qop6cbUJrTVwCcB8zi4vjPlZ9cueNY77yCR2nmKmC6Cmauxr47W98XjuI8yZvvx13jpCTqoEFfWZwF4EUnT5bID0FBlYFxZOEPh+3BAK7lKAsPCMCwqCh8mpycawRWzs+kNHSk+xtv/uho0FdueTL9U9rklbJwd8TjLgj4W6tblSwN+ipfinqWr7+wp0Hyylkr5at0yKbKlxnR0SWW8/cV9nSKvY9Bg7rydxr0lcVxqKc9AF7KyiryiV7eVNCOT6X8nQZ9lc3gyMhcIzpcTfTVqWJFnz0ycNbxqQFeqSLOpy8ilUTkcxHZJyIJItJRRKqIyFoR+c38W9lcV0RkjogcFJHdItLWM29BFafBkZGY37gx6oWEQGC0nD9s2hRvNWrkdFnVINftiKqBgW6X56VqYCA+Mq8rYH+9j5o2BePicpXrSBelnCtSR66ILAKwmeQ7IhIMIBzAFABnSb4sIpMBVCY5SUR6AXgcQC8AHQC8TrKDu+1rR+71Jz/jk10dPRCuz67UIYtK5Z+7jtxCt/RFpCKArgAWAgDJayTPA+gLYJG52iIA/cz7fQF8QMN2AJVEpEZhX1/5Jmetf2dpFmdHD4yLw5kuXXDp5pu15a5UMSl0S19E2gCYD+BXAK0B7ATwBIDjJCuZ6wiAcyQrichXAF4mucVcth7AJJLxObY7GsBoAKhbt267I0eOFKp+SilVWhVLSx9GJ3BbAHNJxgC4DGCy4wo0flEK9KtCcj7JWJKxERERRaieUkqpnIoS9JMAJJHcYT7+HMaPQLI9bWP+PWUuPw6gjsPza5tlSimlSkihgz7JkwCOiUhjs6g7jFTPCgDDzLJhAJab91cAGGqO4vkrgFSSJwr7+koppQquqOP0Hwew2By5cxjAQzB+SD4VkZEAjgAYaK67CsbInYMArpjrKqWUKkFFCvokdwFw1lnQ3cm6BDC2KK+nlFKqaIp0cpZSSqnriwZ9pZQqRTToK6VUKaJBXymlShEN+kopVYpo0FdKqVLEL4P+nj170LVrV/zwww/eropSSvkUvwz6wcHB2Lx5M/bt2+ftqiillE/xy6Bfr149AMDvv//u5ZoopZRv8cugHxoaipo1a2rQV0qpHPwy6ANAgwYNNOgrpVQOGvSVUqoU8eugn5SUhIyMDG9XRSmlfIZfB32bzYajR496uypKKeUz/DroAzqCRymlHGnQV0qpUsRvg37t2rURFBSkQV8ppRz4bdAPDAxE3bp1NegrpZQDvw36ABAdHY2ffvoJ6enp3q6KUkr5BL8O+g8//DD279+P4cOHw2azebs6SinldX4d9AcOHIiXXnoJS5cuxZdffunt6iillNf5ddAHgCeffBJBQUHYuXOnt6uilPJzu3fvBslCPffHH3/EiRMnPFyj3Pw+6AcHB6Nhw4bYu3evt6uilPJjO3bsQOvWrbFmzRqkpaVh6NChOHjwYL6ff8cdd2DKlCnFWEOD3wd9AGjevLkGfaU8ZNmyZRg0aBCysrK8XRWfsm7dOgBAQkICdu3ahQ8//BDvv/9+vp574cIFnDp1Cnv27CnGGhpKRdBv1qwZDh06hKtXr3q7Kkpd9+bNm4elS5di4cKF3q5KsSKJM2fO5Hv9jRs3AjBOCD18+DAAYMOGDfl67pEjRwAYPxjFPeikVAT95s2bg6ReSUupIkpLS8OWLVsAANOmTUNqaqq17PLly1i1ahX27NnjldFyW7duRaVKlTx2bs6rr76KunXr4vTp03mum5GRga1btwLIHvS///57XLx4Ea+88gruvPNOjB49GoAR3GfNmmXl/xMTEwEAV65csX4AikuRgr6IJIrIHhHZJSLxZlkVEVkrIr+Zfyub5SIic0TkoIjsFpG2nngD+dG8eXMA0BSP8jtLlizBk08+6bHtrV+/HmvWrMlWduzYMTz++OMYO3Ystm3bhrS0NEyfPh1nzpzBv/71L2u9t99+G71790arVq3w9NNPe6xO+fX5558jNTUVK1euLPK2Ll26hFdeeQVXr17Ft99+m+f68fHxuHLlCsLCwrIF/czMTPztb3/DpEmTsH37dixYsADnz5/H3Llz8cwzz+Cjjz4C8GfQB4Bff/21yPV3i2ShbwASAVTLUfYKgMnm/ckAZpr3ewFYDUAA/BXAjry2365dO3pCeno6g4KCOHnyZI9sTylfcfvttzMoKIjp6en5Wv/MmTOcM2cOs7KynC5v1qwZmzZtaj0+deoUK1SoQAAEwI4dOzIwMJCpqans27cvq1atyitXrpAkhwwZwsjISMbFxbFu3bq02WxFf4M5bNmyhadOnSJJfv/99zx+/Li1rGXLlgTAO++8kyR5+vRpl9vJyspiRkYGSTI1NZX79+/Ptvxf//oXAbBMmTIcNWqU020cO3aMGzZsYHx8PCdOnEgAfPDBBxkeHs6uXbsyJiaGZcqUIQC2adOGK1asIABu2bKFN998MwEwIiKCKSkpfOqpp6x1Z86cWaR9RJIA4ukqbrtakJ+bi6C/H0AN834NAPvN+28DGORsPVc3TwV90vgy33XXXR7bnlK+oFatWgTAX375JVv5qVOn+M033+Ra/8UXX7QCT05nzpyxAt21a9dIkl9//TUB8KuvvmJ0dDQBsEOHDiTJ//3vfwTAt99+myTZtm1b3n777Zw/fz4BcM+ePfl6D2PGjGG3bt3y/JG4cOECg4OD2bt3byYlJTE0NJTdunUjSZ44cYIAGB4eznLlyvHjjz9mQEAAly1b5nRbkyZNYqtWrWiz2fj4448zNDSUiYmJJMlLly6xRo0a7NatG/v168d69erlqtu1a9es/WG/tWzZkq+//joBsFy5chw6dCg7depEAFyzZg2PHDlCAJw7dy6rVKnCzp07MzAwkFOnTuXdd9/NJk2asEaNGhw2bFi+9ps7xRn0fwfwI4CdAEabZecdlov9MYCvAHR2WLYeQKyTbY4GEA8gvm7dukV+83b33Xcfq1WrxuTkZI9tUylvOnfunBVwli5dmm1Znz59KCI8ceJEtnJ7C/PFF1+0yi5evMjLly9z+fLl1vb27dtHknz55ZcJgOfOnePHH39MAHz22WdJkjabje3atWOTJk2YmZnJ0NBQTpgwgUlJSQTAl19+Oc/3cODAAQYEBFg/LO6sXLnSql/Xrl2t+1u2bOHixYsJgFOnTiUAli1blgDYoEEDpqWl5dpW48aNCYAHDx607j/44IMkyeeee87a7htvvGGt5+jdd98lAM6ePZvLly/nBx98wL1791qteQD8xz/+wWXLlvGZZ56x9lfFihXZt29fAuAbb7zBzp0788Ybb2S7du3Ys2dPdu/enbGxsXnut7wUZ9CvZf6tDuBnAF0dg7657BwLEPQdb55s6cfHxzM0NJRdunTJ96GwUt6QmZnJHTt25CpPTk5m+/btmZCQQNJIddgDzLRp06z1Nm/ebJW/9957tNlsPHv2LC9dumSlEG655RZr/S5dujAuLo5PP/209bwvvviCJPnggw+ydu3aJI2UyP/7f/+Pf/zxh/Vce6v+iy++IAAuXLiQJNmmTRt26dIlz/c6fPhwhoaGsk6dOmzfvj1TU1N58eJFaz+sX7+ec+bMYVJSEp944gmGhoYyIiKCADhkyBBGREQwLi6Od911F6tUqcKUlBTrR+Spp54iAI4ePZorVqzgF198wV9//ZV//PGH9T6nT59OANYR0wsvvMDQ0FDef//9JMl9+/ZZP3SHDh3ixo0b+e233/KGG25gu3btch0B7N6929r2hx9+mOv9durUyfoM/ve//3HatGkMDAxk+fLlOWbMGI4bN45ly5blpk2b+PPPP+e5/1wptqCfbUPAdABP+2p6h6TVGnjnnXc8ul2lPGnZsmVWSsDR559/TgD8+9//TpJ8++23CYAVKlRgv379SBqtyU6dOrFGjRqMiorivffeyxkzZjAkJIQzZ84kALZo0YIhISG8evUqL1y4YAXJKlWqWHnxf/7znySN4N2zZ0+XdT127BgBsHPnzgTA7du3k6QVzJKTk/nHH39w9OjRHDNmDJ966ik+99xznDlzJkeOHMnAwECOGzfO+vEAwPr16zMtLY1jx461ynr37s3mzZvz9ttv5xtvvMEKFSrw6NGj1pEIAD7wwAMkjX6OXr160Waz8b777suWgqlevbrVSi9TpozVX7Fu3To2adLEOko4cuSItT/t5Tlvy5cvz7U/Ll68aC3/7rvvci1/5JFHrOVnz57lunXrrMcvvfQSFy5caD2+7777CvrVsRRL0AdQFkB5h/tbAfQE8Cqyd+S+Yt7vjewdud/n9RqeDvo2m41hYWGcMGGCR7erVFGkpqZaOXSSfP755wmAffr0ybaevbx9+/YkabUKBwwYwIYNG5Ikf/vtNwLgv//9b44cOZIVKlRgxYoVrUASHBzMpUuXEgA3bNjAb775hgAYFBREAJw4cSJr1arFIUOGMCMjgyEhIXz66afd1r9FixbW9i9cuEDSaCGLCJ999lkOGzaMgYGBrFatGsPCwqx1K1asyAceeICnT59meno6n3/+eT7xxBMEwClTprBMmTIcOnQo//73v1vPeeWVV0jSOlrPyMjg5s2buX37dl66dImkcYRg76S12Ww8ceIEt2/fzkWLFlmBv0KFChw8eLBVj8zMTNpsNp4+fTpXCvjKlSvcuHEjFyxYwG+++YYbNmzg+vXrXfZBVKtWjQB48uTJXMvs6aI6deqQJC9fvszg4GAC4JIlS5iWlsaVK1dy7dq1uTqXC6K4gn60mdL5GcBeAFPN8qpm6uY3AOsAVDHLBcCbAA4B2JNXaofFEPRJo4dfO3SVrzh37hxr1KjBp556yiobOHAgATAgIMDqXCTJu+++mwAoIjx9+jS7d+/O9u3bc/r06RQRXrlyhW+99RYB8MCBA/zPf/5jBctJkyYRAOPi4nj+/HkGBARw2rRpfO655xgQEMAZM2ZYefVbb72VsbGxVmrj/fffd/se7GmhnH1w9913H8PDwyki2X44srKyePHiRSswO7LZbOzYsaP1Q3TkyBFeuXKFtWvXJgD+9NNPhdzTf/ZB2I8c7D8Cno4H7du3Z9myZZ3+KNg7v3v16mWVdenShQC4bds2j9WhRNI7xXErjqA/YMCAbEPSlCopmzdv5vnz57OVjR8/PlvrnSRbtWrFNm3aMCAggBMnTrTKGzVqxLp161qtwqioKA4fPpyfffYZAXDnzp3ZRptcuHCBISEh7N+/P202G5999ll+/fXXJMm4uDjWrFmTHTt2ZExMDDMyMrh8+XJmZWXx8ccfZ7ly5aztxsfHu31f9hSFYyAjyT179lgt6ZSUlHzvp1WrVhEAR4wYYZUtX76c/fv3dznUNL+WLFliHTEcP36cZcqU4ZtvvlmkbeY0ZswY3nzzzU6XpaSkWEdAdvaOY2dHBoWlQd/BxIkTGRwczMzMzFzLbDab09aHUkV17Ngxigife+45q+zXX39lUFAQw8LCGBISwmvXrjEzM9NKqTzwwAMMDg7m3r17eeXKFQYEBHDq1KmsXLkyW7VqRQCcNWsWExISCID/+te/WKFChWzjyuPj43n27Nlc9dm0aZN1FDBu3Lhsy+xHC0OGDLGOINxJS0tjtWrV+MILL+RaNnPmzFwji/Jis9n44Ycfuh1nX1iZmZl84403rH3y+++/O40FRXHt2jWnI4bsVq9ene29paamWj/GnqJB38GCBQsIINths91HH33EKlWqWKMHimLFihVMTU0t8nbU9WPRokWcMmWKdf/RRx+1Asqbb75JALzjjjus9UeOHMnw8HDOmTPHSl0cOnTIGmxw8uRJVq1ale3bt+f3339PAPz00085YsQIBgYGskOHDty/fz+zsrKsMd8A+Mknn+Srvr169bK26Wjjxo3WD0J+j4rPnDmTrV9CeZcGfQcbNmywRkaMGTMm29C4oUOHWkOp8jJ37lzOnTvX6TJ7LnTs2LEeq7fyffZc9GuvvcbQ0FArl06SPXr0sDoRbTYbU1NTGR4ezpEjR/LAgQNWoP/qq6+yjfywd7rGxsYSABMSEpiVlZWr9Z2UlMSIiAiKCM+cOZOv+iYkJLBfv365Uk721vA777xTpM5E5T0a9B3Yh5jde++91iGsXfPmza3DZHcSExMZHBzMatWqOc0x2oefhYaGejRPp3yHfVSI42PH6QrKly/P+++/n4BxAk+ZMmVYtWpVAuDx48c5b948AuCOHTuYlZXFChUq8NFHH+Wrr75KAFYO3GazWR24wcHBbtOPP/zwA+fNm1fs7135Pg36DrKyshgWFkYRIQBGRUXRZrPx0qVL1nhl+3hfkjx06JA114fdQw89ZP1z79y5k7t37+amTZus5UOGDGH58uVzddjkl334mD9KSkripk2b3J4Z7angZbPZuHz5co//8KalpVnfAXuL/OjRowTAoUOHMjw8nG+//TbT0tJ42223ZRuHDYArVqxgTEwMW7dubX3ON998M2+88UaOHDmS1atXz/Z69jRPTEyMR9+H8l8a9HOwjyuuUqUKAXD37t387rvvrBZao0aNSBpBo169euzRo4f1XPtp4w888AABcMaMGWzUqBHLly/Pc+fOkSTr1avHu+++m/fccw/Lly/PY8eO5aqDq6Bus9l4yy23sF+/fn4X+K9evcobbrjBCoIbN27Mtc6pU6cYFRVVoDSFK/bcdHBwMCdPnux2f16+fJm7d+/O13bt47sDAgKsoYirV6+2UoNXr1611r169Sr79+/PRo0a8fz58xQRawoB+5w1JPnkk08yJCSEtWvXZteuXXO95s8//1yk4YqqdNGgn0P//v0JGKeo20dA2DvTxowZQwA8f/681akGgIcPHyZJTpkyhYGBgTxx4gRbt27NSpUqWevMmDHDavHNnj2bhw4dYlhYGPv06WMFnIyMDD7++OMMDw9nq1atOGvWrGyH7I5jq999912n9d+zZw93797NlStX8tFHH+XevXvdvt/ff/+d77zzDl9++eUidVJfvXqVSUlJ+Vp3/vz5XLFiBTMzM/nII49w9OjR1ljx119/neHh4XzssceyPcdms/HOO++03n9+OyRd+ec//0kA1rj32bNnu1x3/PjxDAkJ4eXLl91u0z5/ykMPPcRbbrmFLVq0IEkrLePqh8r+GdvP7qxdu3a2ER5r1qxhcHAw69aty/nz5xf0rSqVjQb9HGbPns0WLVowMzOTzZo14+23385hw4axevXq1hjhDRs2WD8KgDG3SVZWFuvVq2eNwHjmmWcIGKeN33bbbYyIiOC///1vK+1DkrNmzSIAtmrVih06dLAmd7r33nutU9cbNmzIm2++mePHj2ezZs3YqFEjdu7cmZUqVcrWuktPT+djjz1m1cl+a9myJdPT03n06FEmJCTw+PHjPHPmDD/44ANrgi37rXnz5ly1ahXXrFnDu+66izExMezduzffeecdvvbaa4yJiWFsbCw7d+7Mzp078+WXX2ZSUhITExPZqlUrBgQEcMiQIdnmX7l69Wq2etpbvQEBAbz11ltpP6HI/r5JY0KwOnXqMDk5mb179+bmzZutceGvvPIKK1asyFGjRnHDhg0cM2YMs7KyuGvXLt50002Mioqyzsx0p0+fPmzcuDGzsrLYr18/BgYGZhtzvmbNGk6aNImZmZmMioqyRtB89913jIuL48KFCzllyhR26tSJr776KlNTU3n48GEC4Lx586xAf/ToUQ4fPpxRUVF51sl+hDhnzpxcy/ztyE55jwZ9N5588kkGBASwXLlyvOOOO3jq1CkC4KuvvsoRI0awcuXK7NmzJ2vWrGkFs8WLF5Mk169fb/0Db9682Qps5cuXt4bqZWRk8JlnnuFdd93FHj16sHv37vzggw9IGv/kn3zyCW+99dZsEzEtWbKEBw4cYI0aNayTRxw79CZMmMDPPvuMq1evto4M7HOm5LzdcMMNnDFjBn/99VeuXbvWSmkBxlzevXr14l/+8herrEOHDuzRowfj4uKsESP2W4UKFTh69GiGhoYyOjqav//+O202m3XktHbtWqakpLBmzZps1qwZu3XrZtV3y5YtHDRokHWkYB86a/9RiIqKYt26ddmyZUtmZGSwf//+rFOnjlW3NWvWsGfPnqxcuTKbN2/OihUrWqf8k8ZkZI5HTDabjdWrV7emqT179ixFhP/4xz9IGmfC2ifusp/6D4Aff/wxx40bZz0WETZr1szq67HPi7Njxw7r5KMFCxawffv27N69e57ft88//5ydOnXKc+y7UkWhQd+Nc+fOcdy4cQwLC+Nrr71G0hjF07hxYzZo0IB9+vSxWv8iwrJly1pzfNhsNq5du9YK8Dt37uT8+fO5du3aQtXlxIkT/Oqrr6wW35kzZ9i7d28CsDoOX3rppVzPe/jhhxkeHs7Jkydz8eLFnDdvHmfNmsUNGzbkGl107tw5bty4kV988YUVeGw2G7dv3+70zMs9e/Zwzpw5nDJlijW7444dO1ipUiVWr16dQ4YMIWBMUtWgQQO2adOGZcqUYXx8PC9fvsxVq1Y5HeHkONNhjx49rCGO69evJ/nnCUIAGBISYp0+P336dO7YscMaZWWz2fjkk09aufsqVaqwcuXK/OSTTwgg27Bax2sqTJgwgSLCmjVrWvW3T03QpUsXduzYkZs2beKBAwdIkqNGjWL58uU5adIkBgYG8sqVK7TZbKxduzY7duzIsmXL8oknnijoR65UsdCgnw9ZWVlWsLUHeXuLnzTOYIyLi+PUqVNLrE6kMdlT+/btCYCdOnVyevZgVlZWts7DkrB7924rdXT77bdbc4qEhYVx9erV+drGjTfeyLCwMCYlJfHrr7/mrFmzrGUHDx4kAHbr1o1TpkwhYMzFYk8rde3alREREezevbs1auaZZ57h2LFjGRkZaU3stWvXLmubQ4cOZVRUFE+cOMGgoCA+/PDDVkrpgQce4F/+8hcOGDCA5cuXz3WOxZdffkkArFatGps3b26VL1iwwDopSnPxyldo0C+EPn36EPhzqlhvOn78OEeNGmV1JvuS3bt3W0c+y5Yt448//pjv5+7cudPp1Z3s5s2bx8OHD/Po0aMMDAzkwIEDrWUbN25kdHQ0GzVqxOnTp2fLh3/00UdW690x5WPvrJ82bRoB42pTNpuNM2bM4N69e9mnTx9rrH3O6bcvXrxopd/sF9uw++GHHzhkyJBcFyxRyls06BfCiRMn+NprrxV5giflGZs3b873Vc9sNht79OjB/v37ZyvfunWr9WPQqFGjXB2n9tFFgPNJxuz9D3mdvKeUt7kL+kFQTkVFRWH8+PHeroYyde7cOd/rigi+/vprBAQEZCtv06YNAgMDcfnyZQwYMAAikm1506ZNAQBBQUFo0aJFru326tUL69atQ0xMTCHegVK+QYO+8kuBgYG5ysLCwtCiRQv8/PPPGDBgQK7lzZo1s/6GhITkWj5q1CiICLp27er5CitVQjToq1Kle/fuSEtLQ2xsbK5lTZo0AQCXLfny5cvr0Z+67omR/vFNsbGxjI+P93Y1lB/JzMxERkYGwsLCnC6fNWsWunXrhnbt2pVwzZTyHBHZSTJ3ywba0lelTFBQEIKCXH/tn3766RKsjVIlLyDvVZRSSvkLDfpKKVWKaNBXSqlSRIO+UkqVIhr0lVKqFNGgr5RSpYgGfaWUKkU06CulVCni02fkishpAEeKsIlqAM54qDqepPUqGK1Xwflq3bReBVPYetUjGeFsgU8H/aISkXhXpyJ7k9arYLReBeerddN6FUxx1EvTO0opVYpo0FdKqVLE34P+fG9XwAWtV8FovQrOV+um9SoYj9fLr3P6SimlsvP3lr5SSikHGvSVUqoU8cugLyI9RWS/iBwUkclerEcdEdkgIr+KyF4RecIsny4ix0Vkl3nr5aX6JYrIHrMO8WZZFRFZKyK/mX8rl3CdGjvsl10ickFExntjn4nIuyJySkR+cShzun/EMMf8zu0WkbYlXK9XRWSf+dpfiEgls7y+iFx12G/ziqteburm8rMTkWfNfbZfRHqUcL0+cahToojsMstLbJ+5iRHF9z0j6Vc3AIEADgGIBhAM4GcAzbxUlxoA2pr3ywM4AKAZgOkAnvaBfZUIoFqOslcATDbvTwYw08uf5UkA9byxzwB0BdAWwC957R8AvQCsBiAA/gpgRwnX63YAQeb9mQ71qu+4npf2mdPPzvxf+BlACIAG5v9tYEnVK8fyfwF4rqT3mZsYUWzfM39s6d8I4CDJwySvAVgKoK83KkLyBMkfzfsXASQAqOWNuhRAXwCLzPuLAPTzXlXQHcAhkkU5K7vQSG4CcDZHsav90xfABzRsB1BJRGqUVL1IfkMy03y4HUDt4njtvLjYZ670BbCUZDrJ3wEchPH/W6L1EhEBMBDAkuJ4bXfcxIhi+575Y9CvBeCYw+Mk+ECgFZH6AGIA7DCL/mYenr1b0ikUBwTwjYjsFJHRZlkkyRPm/ZMAIr1TNQDA/cj+j+gL+8zV/vGl790IGK1BuwYi8pOI/E9EunipTs4+O1/ZZ10AJJP8zaGsxPdZjhhRbN8zfwz6PkdEygFYBmA8yQsA5gK4AUAbACdgHFp6Q2eSbQHcAWCsiHR1XEjjeNIrY3pFJBhAHwCfmUW+ss8s3tw/rojIVACZABabRScA1CUZA+BJAB+LSIUSrpbPfXY5DEL2xkWJ7zMnMcLi6e+ZPwb94wDqODyubZZ5hYiUgfFhLib5HwAgmUwyi6QNwAIU0yFtXkgeN/+eAvCFWY9k++Gi+feUN+oG44foR5LJZh19Yp/B9f7x+vdORIYDuBPAYDNQwEydpJj3d8LImzcqyXq5+ex8YZ8FARgA4BN7WUnvM2cxAsX4PfPHoP8DgIYi0sBsLd4PYIU3KmLmChcCSCD5b4dyxxxcfwC/5HxuCdStrIiUt9+H0RH4C4x9NcxcbRiA5SVdN1O21pcv7DOTq/2zAsBQc3TFXwGkOhyeFzsR6QlgIoA+JK84lEeISKB5PxpAQwCHS6pe5uu6+uxWALhfREJEpIFZt+9Lsm4AbgWwj2SSvaAk95mrGIHi/J6VRA91Sd9g9HAfgPELPdWL9egM47BsN4Bd5q0XgA8B7DHLVwCo4YW6RcMYOfEzgL32/QSgKoD1AH4DsA5AFS/UrSyAFAAVHcpKfJ/B+NE5ASADRu50pKv9A2M0xZvmd24PgNgSrtdBGLle+/dsnrnu3ebnuwvAjwDu8sI+c/nZAZhq7rP9AO4oyXqZ5e8DGJNj3RLbZ25iRLF9z3QaBqWUKkX8Mb2jlFLKBQ36SilVimjQV0qpUkSDvlJKlSIa9JVSqhTRoK+UUqWIBn2llCpF/j8TVfSpBQ1xQQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SAVE model** "
      ],
      "metadata": {
        "id": "okE8lIwPkoSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# os.makedirs('./content/drive/My Drive/new', exist_ok=True)\n",
        "# model.save('./content/drive/My Drive/new/2Class_regression_freeze_500.h5')"
      ],
      "metadata": {
        "id": "f_Xlg2XSuT9L"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files"
      ],
      "metadata": {
        "id": "HuBli3HajIR2"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# files.download(\"./content/drive/My Drive/new/2Class_regression_freeze_500.h5\")"
      ],
      "metadata": {
        "id": "zblzwvRGkSCR"
      },
      "execution_count": 64,
      "outputs": []
    }
  ]
}