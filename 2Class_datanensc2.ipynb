{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNnZZk4PihQoa6Us5QcRkP1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kittikhun62/efficientnet_keras_transfer_learning/blob/master/2Class_datanensc2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# import from drive"
      ],
      "metadata": {
        "id": "_2DRC-anSxem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "BVIqfqC1DtDt",
        "outputId": "c4ac5c44-3823-4756-ce82-8dbb3d94a3cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (r'/content/drive/My Drive/data_nsc - ใช้อันนี้เทรนV2.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "gABRUdVwDtBk",
        "outputId": "ddc6eb63-61ce-4a5d-9697-2f40632ab1f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        No                      Name_file  \\\n",
              "0        1  1-s2.0-S2352152X22008957-main   \n",
              "1        2  1-s2.0-S2352152X22008957-main   \n",
              "2        3  1-s2.0-S2352152X22008957-main   \n",
              "3        4  1-s2.0-S2352152X22008957-main   \n",
              "4        5  1-s2.0-S2352152X22008957-main   \n",
              "...    ...                            ...   \n",
              "1321  1322  1-s2.0-S0926669022000292-main   \n",
              "1322  1323                         new-sb   \n",
              "1323  1324                         new-sb   \n",
              "1324  1325                         new-sb   \n",
              "1325  1326                         new-sb   \n",
              "\n",
              "                                             Name_Paper  \\\n",
              "0     Activated carbons obtained by environmentally ...   \n",
              "1     Activated carbons obtained by environmentally ...   \n",
              "2     Activated carbons obtained by environmentally ...   \n",
              "3     Activated carbons obtained by environmentally ...   \n",
              "4     Activated carbons obtained by environmentally ...   \n",
              "...                                                 ...   \n",
              "1321  Low-cost activated carbon preparation from Cor...   \n",
              "1322  Biosugarcane-based carbon support for high- pe...   \n",
              "1323  Biosugarcane-based carbon support for high- pe...   \n",
              "1324  Biosugarcane-based carbon support for high- pe...   \n",
              "1325  Biosugarcane-based carbon support for high- pe...   \n",
              "\n",
              "                          journal  \\\n",
              "0       Journal of Energy Storage   \n",
              "1       Journal of Energy Storage   \n",
              "2       Journal of Energy Storage   \n",
              "3       Journal of Energy Storage   \n",
              "4       Journal of Energy Storage   \n",
              "...                           ...   \n",
              "1321  Industrial Crops & Products   \n",
              "1322                     iScience   \n",
              "1323                     iScience   \n",
              "1324                     iScience   \n",
              "1325                     iScience   \n",
              "\n",
              "                                           path_Picture    detail     Class  \\\n",
              "0     /content/drive/My Drive/modelnsc/1-s2.0-S23521...  original  401-3200   \n",
              "1     /content/drive/My Drive/modelnsc/1-s2.0-S23521...  original  401-3200   \n",
              "2     /content/drive/My Drive/modelnsc/1-s2.0-S23521...  original  401-3200   \n",
              "3     /content/drive/My Drive/modelnsc/1-s2.0-S23521...  original  401-3200   \n",
              "4     /content/drive/My Drive/modelnsc/1-s2.0-S23521...  original  401-3200   \n",
              "...                                                 ...       ...       ...   \n",
              "1321  /content/drive/My Drive/modelnsc/1-s2.0-S09266...  original     0-400   \n",
              "1322     /content/drive/My Drive/modelnsc/new-sb/18.png  original     0-400   \n",
              "1323     /content/drive/My Drive/modelnsc/new-sb/19.png  original     0-400   \n",
              "1324     /content/drive/My Drive/modelnsc/new-sb/20.png  original     0-400   \n",
              "1325     /content/drive/My Drive/modelnsc/new-sb/21.png  original     0-400   \n",
              "\n",
              "         BET  Size(mico)  \n",
              "0      923.0          10  \n",
              "1     1223.0          10  \n",
              "2     1056.0          10  \n",
              "3      856.0          10  \n",
              "4     1263.0          10  \n",
              "...      ...         ...  \n",
              "1321    11.0          10  \n",
              "1322    53.7          10  \n",
              "1323    34.3          10  \n",
              "1324    27.2          10  \n",
              "1325    24.0          10  \n",
              "\n",
              "[1326 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-24447dee-e018-48b5-a0bb-91a3ddae215d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>No</th>\n",
              "      <th>Name_file</th>\n",
              "      <th>Name_Paper</th>\n",
              "      <th>journal</th>\n",
              "      <th>path_Picture</th>\n",
              "      <th>detail</th>\n",
              "      <th>Class</th>\n",
              "      <th>BET</th>\n",
              "      <th>Size(mico)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1-s2.0-S2352152X22008957-main</td>\n",
              "      <td>Activated carbons obtained by environmentally ...</td>\n",
              "      <td>Journal of Energy Storage</td>\n",
              "      <td>/content/drive/My Drive/modelnsc/1-s2.0-S23521...</td>\n",
              "      <td>original</td>\n",
              "      <td>401-3200</td>\n",
              "      <td>923.0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1-s2.0-S2352152X22008957-main</td>\n",
              "      <td>Activated carbons obtained by environmentally ...</td>\n",
              "      <td>Journal of Energy Storage</td>\n",
              "      <td>/content/drive/My Drive/modelnsc/1-s2.0-S23521...</td>\n",
              "      <td>original</td>\n",
              "      <td>401-3200</td>\n",
              "      <td>1223.0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1-s2.0-S2352152X22008957-main</td>\n",
              "      <td>Activated carbons obtained by environmentally ...</td>\n",
              "      <td>Journal of Energy Storage</td>\n",
              "      <td>/content/drive/My Drive/modelnsc/1-s2.0-S23521...</td>\n",
              "      <td>original</td>\n",
              "      <td>401-3200</td>\n",
              "      <td>1056.0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1-s2.0-S2352152X22008957-main</td>\n",
              "      <td>Activated carbons obtained by environmentally ...</td>\n",
              "      <td>Journal of Energy Storage</td>\n",
              "      <td>/content/drive/My Drive/modelnsc/1-s2.0-S23521...</td>\n",
              "      <td>original</td>\n",
              "      <td>401-3200</td>\n",
              "      <td>856.0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1-s2.0-S2352152X22008957-main</td>\n",
              "      <td>Activated carbons obtained by environmentally ...</td>\n",
              "      <td>Journal of Energy Storage</td>\n",
              "      <td>/content/drive/My Drive/modelnsc/1-s2.0-S23521...</td>\n",
              "      <td>original</td>\n",
              "      <td>401-3200</td>\n",
              "      <td>1263.0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1321</th>\n",
              "      <td>1322</td>\n",
              "      <td>1-s2.0-S0926669022000292-main</td>\n",
              "      <td>Low-cost activated carbon preparation from Cor...</td>\n",
              "      <td>Industrial Crops &amp; Products</td>\n",
              "      <td>/content/drive/My Drive/modelnsc/1-s2.0-S09266...</td>\n",
              "      <td>original</td>\n",
              "      <td>0-400</td>\n",
              "      <td>11.0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1322</th>\n",
              "      <td>1323</td>\n",
              "      <td>new-sb</td>\n",
              "      <td>Biosugarcane-based carbon support for high- pe...</td>\n",
              "      <td>iScience</td>\n",
              "      <td>/content/drive/My Drive/modelnsc/new-sb/18.png</td>\n",
              "      <td>original</td>\n",
              "      <td>0-400</td>\n",
              "      <td>53.7</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1323</th>\n",
              "      <td>1324</td>\n",
              "      <td>new-sb</td>\n",
              "      <td>Biosugarcane-based carbon support for high- pe...</td>\n",
              "      <td>iScience</td>\n",
              "      <td>/content/drive/My Drive/modelnsc/new-sb/19.png</td>\n",
              "      <td>original</td>\n",
              "      <td>0-400</td>\n",
              "      <td>34.3</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1324</th>\n",
              "      <td>1325</td>\n",
              "      <td>new-sb</td>\n",
              "      <td>Biosugarcane-based carbon support for high- pe...</td>\n",
              "      <td>iScience</td>\n",
              "      <td>/content/drive/My Drive/modelnsc/new-sb/20.png</td>\n",
              "      <td>original</td>\n",
              "      <td>0-400</td>\n",
              "      <td>27.2</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1325</th>\n",
              "      <td>1326</td>\n",
              "      <td>new-sb</td>\n",
              "      <td>Biosugarcane-based carbon support for high- pe...</td>\n",
              "      <td>iScience</td>\n",
              "      <td>/content/drive/My Drive/modelnsc/new-sb/21.png</td>\n",
              "      <td>original</td>\n",
              "      <td>0-400</td>\n",
              "      <td>24.0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1326 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24447dee-e018-48b5-a0bb-91a3ddae215d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-24447dee-e018-48b5-a0bb-91a3ddae215d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-24447dee-e018-48b5-a0bb-91a3ddae215d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## hist check class"
      ],
      "metadata": {
        "id": "WMazXBQcTMl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "W34NcexJDs_Z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.hist();"
      ],
      "metadata": {
        "id": "Fm07UpEbDs5X",
        "outputId": "acf3fcaf-e7e7-41df-ce02-251114cfcce9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = df['BET']\n",
        "\n",
        "fig, ax = plt.subplots(figsize =(10, 5))\n",
        "ax.hist(a, bins = 200)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bxfNFKW2TXAY",
        "outputId": "d1de3cd3-36ff-429b-9fc7-91bb2ba1a93e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ['0-400','401-3200']\n",
        "len(classes)"
      ],
      "metadata": {
        "id": "TBsLszHgTW-D",
        "outputId": "84ebc3e6-ac50-44e5-edc4-d0af3bcda61b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone efficientnet repo"
      ],
      "metadata": {
        "id": "DSSZIFGhUyQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/"
      ],
      "metadata": {
        "id": "nFvKcuBDTj1N",
        "outputId": "2abbd42b-f7a6-47d3-b14f-740533a06a2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 1100, done.\u001b[K\n",
            "remote: Counting objects: 100% (263/263), done.\u001b[K\n",
            "remote: Compressing objects: 100% (142/142), done.\u001b[K\n",
            "remote: Total 1100 (delta 133), reused 241 (delta 121), pack-reused 837\u001b[K\n",
            "Receiving objects: 100% (1100/1100), 14.10 MiB | 21.20 MiB/s, done.\n",
            "Resolving deltas: 100% (630/630), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# การเเบ่งข้อมูล train/validation/test sets"
      ],
      "metadata": {
        "id": "JDJCDzEDWnVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/My Drive/modeldatansc'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Directories for our training,\n",
        "# validation and test splits\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.makedirs(test_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "R7L0rJNRU2MY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_1_dir = os.path.join(train_dir, '0-400')\n",
        "os.makedirs(train_1_dir, exist_ok=True)\n",
        "\n",
        "train_2_dir = os.path.join(train_dir, '401-3200')\n",
        "os.makedirs(train_2_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "validation_1_dir = os.path.join(validation_dir, '0-400')\n",
        "os.makedirs(validation_1_dir, exist_ok=True)\n",
        "\n",
        "validation_2_dir = os.path.join(validation_dir, '401-3200')\n",
        "os.makedirs(validation_2_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "test_1_dir = os.path.join(test_dir, '0-400')\n",
        "os.makedirs(test_1_dir, exist_ok=True)\n",
        "\n",
        "test_2_dir = os.path.join(test_dir, '401-3200')\n",
        "os.makedirs(test_2_dir, exist_ok=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "jtyFMXrWU2KD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val = df[df['No'].between(1290,1309)]\n",
        "train = df[df['No'].between(1,1289)]\n",
        "test = df[df['No'].between(1310,1326)] \n",
        "\n",
        "#Path Train\n",
        "T1_train = train[train['Class']=='0-400']\n",
        "T1_path_train = T1_train['path_Picture'].tolist() \n",
        "T2_train = train[train['Class']=='401-3200']\n",
        "T2_path_train = T2_train['path_Picture'].tolist() \n",
        "\n",
        "\n",
        "#Path Validation\n",
        "T1_val = val[val['Class']=='0-400']\n",
        "T1_path_val = T1_val['path_Picture'].tolist() \n",
        "T2_val = val[val['Class']=='401-3200']\n",
        "T2_path_val = T2_val['path_Picture'].tolist() \n",
        "\n",
        "\n",
        "\n",
        "#Path Test\n",
        "T1_test = test[test['Class']=='0-400']\n",
        "T1_path_test = T1_test['path_Picture'].tolist() \n",
        "T2_test = test[test['Class']=='401-3200']\n",
        "T2_path_test = T2_test['path_Picture'].tolist() \n"
      ],
      "metadata": {
        "id": "mlmd_kyhW2LZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "ZkfPduNQW43l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fnames = T1_path_train\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_1_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "fnames = T2_path_train\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_2_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "    \n"
      ],
      "metadata": {
        "id": "9jMgUluKU2Hp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test"
      ],
      "metadata": {
        "id": "Mj3sViKJaLSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fnames = T1_path_test\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_1_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "fnames = T2_path_test\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_2_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "    \n"
      ],
      "metadata": {
        "id": "WvK0Y2FIYat1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Validation"
      ],
      "metadata": {
        "id": "rc4HwwbPaD6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fnames = T1_path_val\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(test_1_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "fnames = T2_path_val\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(test_2_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n"
      ],
      "metadata": {
        "id": "XxtmCbyUYarp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('total training 1 images:', len(os.listdir(train_1_dir))) \n",
        "print('total training 2 images:', len(os.listdir(train_2_dir)),'\\n')\n",
        "\n",
        "print('total validation 1 images:', len(os.listdir(validation_1_dir)))\n",
        "print('total validation 2 images:', len(os.listdir(validation_2_dir)),'\\n')\n",
        "\n",
        "print('total test 1 images:', len(os.listdir(test_1_dir)))\n",
        "print('total test 2 images:', len(os.listdir(test_2_dir)),'\\n')\n"
      ],
      "metadata": {
        "id": "Tvk53f-WYapl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f3e32ea-ecc0-4722-947a-2780b0560361"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total training 1 images: 625\n",
            "total training 2 images: 654 \n",
            "\n",
            "total validation 1 images: 8\n",
            "total validation 2 images: 9 \n",
            "\n",
            "total test 1 images: 9\n",
            "total test 2 images: 11 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports library"
      ],
      "metadata": {
        "id": "VkYa-4LeTbir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "myAsBcVhTW7j"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## hyper parameter\n"
      ],
      "metadata": {
        "id": "T529UM_tVV-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "width = 150\n",
        "height = 150\n",
        "\n",
        "epochs = 500 #จำนวนรอบในการ Train\n",
        "\n",
        "NUM_TRAIN = 1289  # จำนวนภาพ Train\n",
        "NUM_TEST = 17 #จำนวนภาพ Test\n",
        "\n",
        "dropout_rate = 0.3\n",
        "input_shape = (height, width, 3) #ขนาด image enter"
      ],
      "metadata": {
        "id": "zXpmkJ2GVZ1l"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import efficientnet and load the conv base model"
      ],
      "metadata": {
        "id": "j3EgSOiSZHaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "iI3DQ18HU2TF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "#EfficientNet สร้างขึ้นสำหรับการจำแนกประเภท ImageNet ประกอบด้วยป้ายกำกับคลาส 1,000 รายการ เรามีเพียง 2 เลเยอร์เท่านั้น ซึ่งหมายความว่าเลเยอร์สองสามเลเยอร์สุดท้ายสำหรับการจำแนกไม่มีประโยชน์สำหรับเรา สามารถยกเว้นได้ขณะโหลดโมเดลโดยระบุอาร์กิวเมนต์ include_top เป็น False และนำไปใช้กับโมเดล ImageNet อื่นๆ ที่มีอยู่ในแอปพลิเคชัน Keras เช่นกัน\n",
        "\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "UmBDAgF_VAjq",
        "outputId": "e37d6829-62b2-4229-de4a-84145960c847",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "id": "rRXoFFzfU2Oi",
        "outputId": "168a8d52-8b90-40c3-e6a4-eeb2a78ac2bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 4,007,548\n",
            "Non-trainable params: 42,016\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Show architecture model"
      ],
      "metadata": {
        "id": "W1JJhCEWZjiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดัดแปลง GlobalMaxPooling2D เพื่อแปลง 4D the (batch_size, rows, cols,channels) tensor เป็น 2D tensor with shape (batch_size,channels)\n",
        "#GlobalMaxPooling2D ส่งผลให้มีจำนวนฟีเจอร์น้อยกว่ามากเมื่อเทียบกับเลเยอร์ Flatten ซึ่งช่วยลดจำนวนพารามิเตอร์ได้อย่างมีประสิทธิภาพ\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
        "# model.add(layers.Flatten(name=\"flatten\"))\n",
        "if dropout_rate > 0:\n",
        "    model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n",
        "# model.add(layers.Dense(256, activation='relu', name=\"fc1\"))\n",
        "model.add(layers.Dense(2, activation='softmax', name=\"fc_out\"))"
      ],
      "metadata": {
        "id": "-9EQ5AdjZT9s"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('This is the number of trainable layers '\n",
        "      'before freezing the conv base:', len(model.trainable_weights))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "print('This is the number of trainable layers '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ],
      "metadata": {
        "id": "xRyPafCIZXzU",
        "outputId": "e18e3e1c-11fa-48e4-ccf7-a99bc8b9f53f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable layers before freezing the conv base: 213\n",
            "This is the number of trainable layers after freezing the conv base: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "wmBUcgsMZVkW",
        "outputId": "d42a2c9c-d6bf-43e7-d7d3-9409a281e348",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 2)                 2562      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,052,126\n",
            "Trainable params: 2,562\n",
            "Non-trainable params: 4,049,564\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting data augmentation"
      ],
      "metadata": {
        "id": "X9Xfp10TY9xE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "#Image Augmentation \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, # image input 0-255 --> 0-1 เปลี่ยนค่าสี\n",
        "      rotation_range=40,# หมุนภาพในองศา\n",
        "      width_shift_range=0.2, #เปลี่ยนความกว้าง\n",
        "      height_shift_range=0.2, #ปลี่ยนความสูง\n",
        "      shear_range=0.2, #ทำให้ภาพเบี้ยว\n",
        "      zoom_range=0.2, # Randomly zoom image\n",
        "      horizontal_flip=True, \n",
        "      #โดย Default เมื่อมีการเลื่อนภาพ บิดภาพ หมุนภาพ จะเกิดพื้นที่ว่างที่มุม \n",
        "      #ซึ่งจะมีการเติมภาพให้เต็มโดยใช้เทคนิคแบบ Nearest neighbor ซึ่งเป็นการดึงสีบริเวณใหล้าเคียงมาระบายให้เต็ม แต่เราก็ยังสามารถกำหนดวิธีการ Fill ภาพด้วยเทคนิคอื่นได้จาก Parameter fill_mode\n",
        "      fill_mode='nearest')\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory #ไดเรกเป้าหมาย\n",
        "        train_dir,\n",
        "        # รูปภาพทั้งหมดจะถูกปรับขนาดตามความสูงและความกว้างของเป้าหมาย\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        #เนื่องจากเราใช้ categorical_crossentropy loss เราจึงต้องมีป้ายกำกับตามหมวดหมู่\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory( #การดึงภาพจาก Directory มาเข้าโมเดล \n",
        "        validation_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "id": "GC-vPos9Y9HD",
        "outputId": "d59638b5-0133-41c6-ae35-50262ae2aab8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1279 images belonging to 2 classes.\n",
            "Found 17 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "8S60IpOWcB7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(learning_rate=10e-5),\n",
        "              metrics=['acc'])\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "Od8zqlOwb9Iw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9607231a-d692-4c6a-b9d4-55d2f1bae81a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-afc7eebc5ed0>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "80/80 [==============================] - 22s 93ms/step - loss: 1.5586 - acc: 0.4754 - val_loss: 0.9901 - val_acc: 0.3750\n",
            "Epoch 2/500\n",
            "80/80 [==============================] - 5s 62ms/step - loss: 1.1511 - acc: 0.5066 - val_loss: 1.0251 - val_acc: 0.3750\n",
            "Epoch 3/500\n",
            "80/80 [==============================] - 6s 75ms/step - loss: 1.0625 - acc: 0.5207 - val_loss: 0.9624 - val_acc: 0.3750\n",
            "Epoch 4/500\n",
            "80/80 [==============================] - 6s 62ms/step - loss: 1.0050 - acc: 0.5473 - val_loss: 0.9793 - val_acc: 0.5000\n",
            "Epoch 5/500\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 0.9488 - acc: 0.5911 - val_loss: 0.9445 - val_acc: 0.4375\n",
            "Epoch 6/500\n",
            "80/80 [==============================] - 6s 62ms/step - loss: 0.9238 - acc: 0.5801 - val_loss: 1.0100 - val_acc: 0.5625\n",
            "Epoch 7/500\n",
            "80/80 [==============================] - 6s 68ms/step - loss: 0.9424 - acc: 0.5575 - val_loss: 0.9013 - val_acc: 0.5000\n",
            "Epoch 8/500\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 0.8830 - acc: 0.6083 - val_loss: 0.9051 - val_acc: 0.4375\n",
            "Epoch 9/500\n",
            "80/80 [==============================] - 6s 62ms/step - loss: 0.9052 - acc: 0.5747 - val_loss: 0.8736 - val_acc: 0.4375\n",
            "Epoch 10/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.8682 - acc: 0.5919 - val_loss: 0.9225 - val_acc: 0.5000\n",
            "Epoch 11/500\n",
            "80/80 [==============================] - 6s 68ms/step - loss: 0.8536 - acc: 0.6028 - val_loss: 0.8983 - val_acc: 0.5625\n",
            "Epoch 12/500\n",
            "80/80 [==============================] - 6s 70ms/step - loss: 0.8245 - acc: 0.6247 - val_loss: 0.8617 - val_acc: 0.5625\n",
            "Epoch 13/500\n",
            "80/80 [==============================] - 6s 67ms/step - loss: 0.8155 - acc: 0.6325 - val_loss: 0.8251 - val_acc: 0.5625\n",
            "Epoch 14/500\n",
            "80/80 [==============================] - 7s 77ms/step - loss: 0.8034 - acc: 0.6161 - val_loss: 0.8328 - val_acc: 0.6250\n",
            "Epoch 15/500\n",
            "80/80 [==============================] - 6s 63ms/step - loss: 0.8144 - acc: 0.6114 - val_loss: 0.8172 - val_acc: 0.6250\n",
            "Epoch 16/500\n",
            "80/80 [==============================] - 6s 61ms/step - loss: 0.8099 - acc: 0.6255 - val_loss: 0.8271 - val_acc: 0.6250\n",
            "Epoch 17/500\n",
            "80/80 [==============================] - 6s 69ms/step - loss: 0.8068 - acc: 0.6185 - val_loss: 0.8116 - val_acc: 0.5625\n",
            "Epoch 18/500\n",
            "80/80 [==============================] - 6s 76ms/step - loss: 0.8065 - acc: 0.6106 - val_loss: 0.8362 - val_acc: 0.5625\n",
            "Epoch 19/500\n",
            "80/80 [==============================] - 5s 62ms/step - loss: 0.7780 - acc: 0.6325 - val_loss: 0.7947 - val_acc: 0.5000\n",
            "Epoch 20/500\n",
            "80/80 [==============================] - 7s 74ms/step - loss: 0.7815 - acc: 0.6208 - val_loss: 0.8202 - val_acc: 0.5000\n",
            "Epoch 21/500\n",
            "80/80 [==============================] - 6s 64ms/step - loss: 0.7694 - acc: 0.6239 - val_loss: 0.7590 - val_acc: 0.5625\n",
            "Epoch 22/500\n",
            "80/80 [==============================] - 7s 76ms/step - loss: 0.7606 - acc: 0.6364 - val_loss: 0.7519 - val_acc: 0.5000\n",
            "Epoch 23/500\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 0.6890 - acc: 0.6575 - val_loss: 0.7621 - val_acc: 0.5625\n",
            "Epoch 24/500\n",
            "80/80 [==============================] - 7s 75ms/step - loss: 0.7034 - acc: 0.6482 - val_loss: 0.6547 - val_acc: 0.5625\n",
            "Epoch 25/500\n",
            "80/80 [==============================] - 6s 63ms/step - loss: 0.7038 - acc: 0.6403 - val_loss: 0.7564 - val_acc: 0.5625\n",
            "Epoch 26/500\n",
            "80/80 [==============================] - 6s 73ms/step - loss: 0.7347 - acc: 0.6271 - val_loss: 0.7455 - val_acc: 0.5625\n",
            "Epoch 27/500\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 0.7308 - acc: 0.6513 - val_loss: 0.6815 - val_acc: 0.6250\n",
            "Epoch 28/500\n",
            "80/80 [==============================] - 7s 76ms/step - loss: 0.6978 - acc: 0.6591 - val_loss: 0.6580 - val_acc: 0.5000\n",
            "Epoch 29/500\n",
            "80/80 [==============================] - 6s 64ms/step - loss: 0.7217 - acc: 0.6474 - val_loss: 0.7402 - val_acc: 0.5625\n",
            "Epoch 30/500\n",
            "80/80 [==============================] - 6s 74ms/step - loss: 0.6797 - acc: 0.6599 - val_loss: 0.6771 - val_acc: 0.5000\n",
            "Epoch 31/500\n",
            "80/80 [==============================] - 6s 70ms/step - loss: 0.7318 - acc: 0.6286 - val_loss: 0.6581 - val_acc: 0.5000\n",
            "Epoch 32/500\n",
            "80/80 [==============================] - 6s 69ms/step - loss: 0.6802 - acc: 0.6521 - val_loss: 0.6115 - val_acc: 0.5625\n",
            "Epoch 33/500\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 0.6825 - acc: 0.6560 - val_loss: 0.6857 - val_acc: 0.5625\n",
            "Epoch 34/500\n",
            "80/80 [==============================] - 6s 73ms/step - loss: 0.6569 - acc: 0.6787 - val_loss: 0.6305 - val_acc: 0.5625\n",
            "Epoch 35/500\n",
            "80/80 [==============================] - 6s 63ms/step - loss: 0.6489 - acc: 0.6771 - val_loss: 0.6359 - val_acc: 0.5625\n",
            "Epoch 36/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.6832 - acc: 0.6489 - val_loss: 0.6929 - val_acc: 0.5625\n",
            "Epoch 37/500\n",
            "80/80 [==============================] - 7s 78ms/step - loss: 0.6635 - acc: 0.6544 - val_loss: 0.6906 - val_acc: 0.5000\n",
            "Epoch 38/500\n",
            "80/80 [==============================] - 6s 64ms/step - loss: 0.6630 - acc: 0.6529 - val_loss: 0.6159 - val_acc: 0.6875\n",
            "Epoch 39/500\n",
            "80/80 [==============================] - 6s 67ms/step - loss: 0.6312 - acc: 0.6779 - val_loss: 0.6880 - val_acc: 0.5625\n",
            "Epoch 40/500\n",
            "80/80 [==============================] - 6s 67ms/step - loss: 0.6485 - acc: 0.6654 - val_loss: 0.6236 - val_acc: 0.6250\n",
            "Epoch 41/500\n",
            "80/80 [==============================] - 6s 74ms/step - loss: 0.6800 - acc: 0.6450 - val_loss: 0.6913 - val_acc: 0.6250\n",
            "Epoch 42/500\n",
            "80/80 [==============================] - 6s 64ms/step - loss: 0.6371 - acc: 0.6865 - val_loss: 0.6295 - val_acc: 0.5000\n",
            "Epoch 43/500\n",
            "80/80 [==============================] - 6s 73ms/step - loss: 0.6340 - acc: 0.6810 - val_loss: 0.6805 - val_acc: 0.6250\n",
            "Epoch 44/500\n",
            "80/80 [==============================] - 6s 68ms/step - loss: 0.6481 - acc: 0.6669 - val_loss: 0.6185 - val_acc: 0.6250\n",
            "Epoch 45/500\n",
            "80/80 [==============================] - 5s 62ms/step - loss: 0.6217 - acc: 0.6849 - val_loss: 0.5599 - val_acc: 0.6250\n",
            "Epoch 46/500\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 0.6166 - acc: 0.6880 - val_loss: 0.6332 - val_acc: 0.5625\n",
            "Epoch 47/500\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 0.6533 - acc: 0.6615 - val_loss: 0.6611 - val_acc: 0.6250\n",
            "Epoch 48/500\n",
            "80/80 [==============================] - 6s 63ms/step - loss: 0.6184 - acc: 0.6826 - val_loss: 0.5823 - val_acc: 0.6250\n",
            "Epoch 49/500\n",
            "80/80 [==============================] - 7s 81ms/step - loss: 0.6006 - acc: 0.6935 - val_loss: 0.6090 - val_acc: 0.6250\n",
            "Epoch 50/500\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 0.5905 - acc: 0.6904 - val_loss: 0.6201 - val_acc: 0.6250\n",
            "Epoch 51/500\n",
            "80/80 [==============================] - 7s 75ms/step - loss: 0.5883 - acc: 0.6990 - val_loss: 0.6465 - val_acc: 0.6250\n",
            "Epoch 52/500\n",
            "80/80 [==============================] - 6s 62ms/step - loss: 0.6302 - acc: 0.6724 - val_loss: 0.6489 - val_acc: 0.6250\n",
            "Epoch 53/500\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 0.6058 - acc: 0.6841 - val_loss: 0.5262 - val_acc: 0.6875\n",
            "Epoch 54/500\n",
            "80/80 [==============================] - 5s 62ms/step - loss: 0.6045 - acc: 0.6849 - val_loss: 0.6562 - val_acc: 0.5000\n",
            "Epoch 55/500\n",
            "80/80 [==============================] - 7s 74ms/step - loss: 0.6150 - acc: 0.6849 - val_loss: 0.5254 - val_acc: 0.6875\n",
            "Epoch 56/500\n",
            "80/80 [==============================] - 5s 62ms/step - loss: 0.5970 - acc: 0.6896 - val_loss: 0.6439 - val_acc: 0.5625\n",
            "Epoch 57/500\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 0.5967 - acc: 0.6935 - val_loss: 0.6409 - val_acc: 0.5625\n",
            "Epoch 58/500\n",
            "80/80 [==============================] - 7s 75ms/step - loss: 0.5974 - acc: 0.7029 - val_loss: 0.5661 - val_acc: 0.6875\n",
            "Epoch 59/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.6110 - acc: 0.6818 - val_loss: 0.5527 - val_acc: 0.6875\n",
            "Epoch 60/500\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 0.5986 - acc: 0.6951 - val_loss: 0.5404 - val_acc: 0.6875\n",
            "Epoch 61/500\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 0.5956 - acc: 0.6779 - val_loss: 0.6018 - val_acc: 0.6250\n",
            "Epoch 62/500\n",
            "80/80 [==============================] - 5s 62ms/step - loss: 0.5925 - acc: 0.6951 - val_loss: 0.5265 - val_acc: 0.6875\n",
            "Epoch 63/500\n",
            "80/80 [==============================] - 7s 75ms/step - loss: 0.5902 - acc: 0.7037 - val_loss: 0.5503 - val_acc: 0.6875\n",
            "Epoch 64/500\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 0.5935 - acc: 0.6896 - val_loss: 0.6328 - val_acc: 0.6250\n",
            "Epoch 65/500\n",
            "80/80 [==============================] - 7s 73ms/step - loss: 0.5925 - acc: 0.7091 - val_loss: 0.6245 - val_acc: 0.6250\n",
            "Epoch 66/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5943 - acc: 0.6865 - val_loss: 0.6510 - val_acc: 0.6250\n",
            "Epoch 67/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5780 - acc: 0.7084 - val_loss: 0.6441 - val_acc: 0.6250\n",
            "Epoch 68/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5864 - acc: 0.6873 - val_loss: 0.6525 - val_acc: 0.6250\n",
            "Epoch 69/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.6081 - acc: 0.6833 - val_loss: 0.6194 - val_acc: 0.6250\n",
            "Epoch 70/500\n",
            "80/80 [==============================] - 6s 64ms/step - loss: 0.5789 - acc: 0.7170 - val_loss: 0.6232 - val_acc: 0.6250\n",
            "Epoch 71/500\n",
            "80/80 [==============================] - 7s 78ms/step - loss: 0.5864 - acc: 0.7068 - val_loss: 0.6376 - val_acc: 0.6250\n",
            "Epoch 72/500\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 0.5709 - acc: 0.7131 - val_loss: 0.5941 - val_acc: 0.6875\n",
            "Epoch 73/500\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 0.5574 - acc: 0.7146 - val_loss: 0.6270 - val_acc: 0.6250\n",
            "Epoch 74/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5640 - acc: 0.7146 - val_loss: 0.6010 - val_acc: 0.6250\n",
            "Epoch 75/500\n",
            "80/80 [==============================] - 7s 76ms/step - loss: 0.5724 - acc: 0.7076 - val_loss: 0.5047 - val_acc: 0.6875\n",
            "Epoch 76/500\n",
            "80/80 [==============================] - 6s 67ms/step - loss: 0.5649 - acc: 0.7037 - val_loss: 0.6292 - val_acc: 0.6875\n",
            "Epoch 77/500\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 0.5439 - acc: 0.7295 - val_loss: 0.5482 - val_acc: 0.7500\n",
            "Epoch 78/500\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 0.5535 - acc: 0.7240 - val_loss: 0.6043 - val_acc: 0.5625\n",
            "Epoch 79/500\n",
            "80/80 [==============================] - 6s 68ms/step - loss: 0.5917 - acc: 0.6943 - val_loss: 0.5946 - val_acc: 0.6250\n",
            "Epoch 80/500\n",
            "80/80 [==============================] - 6s 62ms/step - loss: 0.5581 - acc: 0.7131 - val_loss: 0.5751 - val_acc: 0.6875\n",
            "Epoch 81/500\n",
            "80/80 [==============================] - 7s 75ms/step - loss: 0.5455 - acc: 0.7263 - val_loss: 0.5915 - val_acc: 0.6875\n",
            "Epoch 82/500\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 0.5760 - acc: 0.7076 - val_loss: 0.5921 - val_acc: 0.6250\n",
            "Epoch 83/500\n",
            "80/80 [==============================] - 6s 64ms/step - loss: 0.5745 - acc: 0.7005 - val_loss: 0.6016 - val_acc: 0.6250\n",
            "Epoch 84/500\n",
            "80/80 [==============================] - 7s 76ms/step - loss: 0.5511 - acc: 0.7193 - val_loss: 0.5915 - val_acc: 0.6250\n",
            "Epoch 85/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5667 - acc: 0.7091 - val_loss: 0.6065 - val_acc: 0.6250\n",
            "Epoch 86/500\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 0.5635 - acc: 0.6998 - val_loss: 0.5482 - val_acc: 0.6875\n",
            "Epoch 87/500\n",
            "80/80 [==============================] - 6s 73ms/step - loss: 0.5542 - acc: 0.7138 - val_loss: 0.5582 - val_acc: 0.6875\n",
            "Epoch 88/500\n",
            "80/80 [==============================] - 6s 68ms/step - loss: 0.5608 - acc: 0.7146 - val_loss: 0.6010 - val_acc: 0.6250\n",
            "Epoch 89/500\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 0.5646 - acc: 0.6959 - val_loss: 0.6198 - val_acc: 0.5625\n",
            "Epoch 90/500\n",
            "80/80 [==============================] - 7s 81ms/step - loss: 0.5488 - acc: 0.7154 - val_loss: 0.5524 - val_acc: 0.6875\n",
            "Epoch 91/500\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 0.5410 - acc: 0.7279 - val_loss: 0.6150 - val_acc: 0.5625\n",
            "Epoch 92/500\n",
            "80/80 [==============================] - 6s 76ms/step - loss: 0.5582 - acc: 0.7248 - val_loss: 0.5656 - val_acc: 0.6250\n",
            "Epoch 93/500\n",
            "80/80 [==============================] - 6s 62ms/step - loss: 0.5648 - acc: 0.7115 - val_loss: 0.5298 - val_acc: 0.6250\n",
            "Epoch 94/500\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 0.5440 - acc: 0.7295 - val_loss: 0.6088 - val_acc: 0.5000\n",
            "Epoch 95/500\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 0.5664 - acc: 0.7099 - val_loss: 0.5095 - val_acc: 0.6250\n",
            "Epoch 96/500\n",
            "80/80 [==============================] - 5s 62ms/step - loss: 0.5312 - acc: 0.7209 - val_loss: 0.4889 - val_acc: 0.7500\n",
            "Epoch 97/500\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.5437 - acc: 0.7256 - val_loss: 0.5690 - val_acc: 0.5625\n",
            "Epoch 98/500\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 0.5531 - acc: 0.7240 - val_loss: 0.5893 - val_acc: 0.6250\n",
            "Epoch 99/500\n",
            "80/80 [==============================] - 7s 76ms/step - loss: 0.5491 - acc: 0.7193 - val_loss: 0.5813 - val_acc: 0.6250\n",
            "Epoch 100/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5736 - acc: 0.7060 - val_loss: 0.5090 - val_acc: 0.6875\n",
            "Epoch 101/500\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 0.5635 - acc: 0.6943 - val_loss: 0.5514 - val_acc: 0.6875\n",
            "Epoch 102/500\n",
            "80/80 [==============================] - 6s 74ms/step - loss: 0.5266 - acc: 0.7396 - val_loss: 0.5736 - val_acc: 0.5625\n",
            "Epoch 103/500\n",
            "80/80 [==============================] - 6s 70ms/step - loss: 0.5510 - acc: 0.7232 - val_loss: 0.5134 - val_acc: 0.6875\n",
            "Epoch 104/500\n",
            "80/80 [==============================] - 6s 76ms/step - loss: 0.5319 - acc: 0.7287 - val_loss: 0.6303 - val_acc: 0.6250\n",
            "Epoch 105/500\n",
            "80/80 [==============================] - 6s 74ms/step - loss: 0.5594 - acc: 0.7037 - val_loss: 0.6244 - val_acc: 0.5625\n",
            "Epoch 106/500\n",
            "80/80 [==============================] - 6s 73ms/step - loss: 0.5434 - acc: 0.7224 - val_loss: 0.5709 - val_acc: 0.5625\n",
            "Epoch 107/500\n",
            "80/80 [==============================] - 6s 63ms/step - loss: 0.5307 - acc: 0.7498 - val_loss: 0.6244 - val_acc: 0.6250\n",
            "Epoch 108/500\n",
            "80/80 [==============================] - 6s 64ms/step - loss: 0.5399 - acc: 0.7310 - val_loss: 0.5903 - val_acc: 0.5625\n",
            "Epoch 109/500\n",
            "80/80 [==============================] - 7s 75ms/step - loss: 0.5413 - acc: 0.7318 - val_loss: 0.5672 - val_acc: 0.6250\n",
            "Epoch 110/500\n",
            "80/80 [==============================] - 6s 63ms/step - loss: 0.5600 - acc: 0.7115 - val_loss: 0.6080 - val_acc: 0.6250\n",
            "Epoch 111/500\n",
            "80/80 [==============================] - 6s 69ms/step - loss: 0.5350 - acc: 0.7349 - val_loss: 0.6092 - val_acc: 0.6250\n",
            "Epoch 112/500\n",
            "80/80 [==============================] - 6s 63ms/step - loss: 0.5496 - acc: 0.7326 - val_loss: 0.5847 - val_acc: 0.6250\n",
            "Epoch 113/500\n",
            "80/80 [==============================] - 7s 73ms/step - loss: 0.5610 - acc: 0.7162 - val_loss: 0.5451 - val_acc: 0.6875\n",
            "Epoch 114/500\n",
            "80/80 [==============================] - 6s 64ms/step - loss: 0.5529 - acc: 0.7131 - val_loss: 0.5510 - val_acc: 0.6875\n",
            "Epoch 115/500\n",
            "80/80 [==============================] - 7s 78ms/step - loss: 0.5560 - acc: 0.7123 - val_loss: 0.4897 - val_acc: 0.6875\n",
            "Epoch 116/500\n",
            "80/80 [==============================] - 5s 62ms/step - loss: 0.5418 - acc: 0.7217 - val_loss: 0.5767 - val_acc: 0.6875\n",
            "Epoch 117/500\n",
            "80/80 [==============================] - 7s 70ms/step - loss: 0.5302 - acc: 0.7240 - val_loss: 0.5481 - val_acc: 0.6875\n",
            "Epoch 118/500\n",
            "80/80 [==============================] - 6s 64ms/step - loss: 0.5550 - acc: 0.7193 - val_loss: 0.5493 - val_acc: 0.6875\n",
            "Epoch 119/500\n",
            "80/80 [==============================] - 7s 79ms/step - loss: 0.5300 - acc: 0.7381 - val_loss: 0.6007 - val_acc: 0.5625\n",
            "Epoch 120/500\n",
            "80/80 [==============================] - 6s 62ms/step - loss: 0.5560 - acc: 0.7240 - val_loss: 0.6224 - val_acc: 0.6250\n",
            "Epoch 121/500\n",
            "80/80 [==============================] - 7s 75ms/step - loss: 0.5276 - acc: 0.7326 - val_loss: 0.6304 - val_acc: 0.6875\n",
            "Epoch 122/500\n",
            "80/80 [==============================] - 6s 62ms/step - loss: 0.5305 - acc: 0.7318 - val_loss: 0.5835 - val_acc: 0.6875\n",
            "Epoch 123/500\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 0.5446 - acc: 0.7263 - val_loss: 0.6235 - val_acc: 0.5625\n",
            "Epoch 124/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5479 - acc: 0.7349 - val_loss: 0.6078 - val_acc: 0.5625\n",
            "Epoch 125/500\n",
            "80/80 [==============================] - 7s 79ms/step - loss: 0.5239 - acc: 0.7248 - val_loss: 0.5895 - val_acc: 0.5625\n",
            "Epoch 126/500\n",
            "80/80 [==============================] - 6s 64ms/step - loss: 0.5429 - acc: 0.7248 - val_loss: 0.6077 - val_acc: 0.5625\n",
            "Epoch 127/500\n",
            "80/80 [==============================] - 7s 77ms/step - loss: 0.5403 - acc: 0.7263 - val_loss: 0.5895 - val_acc: 0.6250\n",
            "Epoch 128/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5446 - acc: 0.7318 - val_loss: 0.4914 - val_acc: 0.6875\n",
            "Epoch 129/500\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 0.5501 - acc: 0.7138 - val_loss: 0.5282 - val_acc: 0.5000\n",
            "Epoch 130/500\n",
            "80/80 [==============================] - 7s 75ms/step - loss: 0.5553 - acc: 0.7279 - val_loss: 0.5966 - val_acc: 0.6250\n",
            "Epoch 131/500\n",
            "80/80 [==============================] - 6s 62ms/step - loss: 0.5416 - acc: 0.7287 - val_loss: 0.6021 - val_acc: 0.5625\n",
            "Epoch 132/500\n",
            "80/80 [==============================] - 7s 75ms/step - loss: 0.5327 - acc: 0.7365 - val_loss: 0.4866 - val_acc: 0.6875\n",
            "Epoch 133/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5456 - acc: 0.7162 - val_loss: 0.5234 - val_acc: 0.7500\n",
            "Epoch 134/500\n",
            "80/80 [==============================] - 7s 75ms/step - loss: 0.5368 - acc: 0.7232 - val_loss: 0.5327 - val_acc: 0.6875\n",
            "Epoch 135/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5276 - acc: 0.7373 - val_loss: 0.5608 - val_acc: 0.5000\n",
            "Epoch 136/500\n",
            "80/80 [==============================] - 6s 63ms/step - loss: 0.5527 - acc: 0.7131 - val_loss: 0.5940 - val_acc: 0.5625\n",
            "Epoch 137/500\n",
            "80/80 [==============================] - 7s 77ms/step - loss: 0.5242 - acc: 0.7389 - val_loss: 0.5808 - val_acc: 0.6250\n",
            "Epoch 138/500\n",
            "80/80 [==============================] - 6s 64ms/step - loss: 0.5350 - acc: 0.7201 - val_loss: 0.5543 - val_acc: 0.5625\n",
            "Epoch 139/500\n",
            "80/80 [==============================] - 7s 79ms/step - loss: 0.5315 - acc: 0.7310 - val_loss: 0.6068 - val_acc: 0.4375\n",
            "Epoch 140/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5408 - acc: 0.7263 - val_loss: 0.5733 - val_acc: 0.6875\n",
            "Epoch 141/500\n",
            "80/80 [==============================] - 6s 73ms/step - loss: 0.5427 - acc: 0.7334 - val_loss: 0.5525 - val_acc: 0.6250\n",
            "Epoch 142/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5339 - acc: 0.7334 - val_loss: 0.4710 - val_acc: 0.7500\n",
            "Epoch 143/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5189 - acc: 0.7389 - val_loss: 0.5557 - val_acc: 0.6250\n",
            "Epoch 144/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5138 - acc: 0.7310 - val_loss: 0.5577 - val_acc: 0.5625\n",
            "Epoch 145/500\n",
            "80/80 [==============================] - 7s 82ms/step - loss: 0.5384 - acc: 0.7185 - val_loss: 0.5532 - val_acc: 0.6250\n",
            "Epoch 146/500\n",
            "80/80 [==============================] - 6s 67ms/step - loss: 0.5460 - acc: 0.7248 - val_loss: 0.5253 - val_acc: 0.7500\n",
            "Epoch 147/500\n",
            "80/80 [==============================] - 6s 69ms/step - loss: 0.5656 - acc: 0.7224 - val_loss: 0.5388 - val_acc: 0.7500\n",
            "Epoch 148/500\n",
            "80/80 [==============================] - 6s 64ms/step - loss: 0.5283 - acc: 0.7396 - val_loss: 0.5683 - val_acc: 0.6875\n",
            "Epoch 149/500\n",
            "80/80 [==============================] - 6s 67ms/step - loss: 0.5399 - acc: 0.7303 - val_loss: 0.5073 - val_acc: 0.6875\n",
            "Epoch 150/500\n",
            "80/80 [==============================] - 7s 74ms/step - loss: 0.5371 - acc: 0.7365 - val_loss: 0.4932 - val_acc: 0.7500\n",
            "Epoch 151/500\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.5313 - acc: 0.7357 - val_loss: 0.5375 - val_acc: 0.6250\n",
            "Epoch 152/500\n",
            "80/80 [==============================] - 7s 78ms/step - loss: 0.5421 - acc: 0.7138 - val_loss: 0.5023 - val_acc: 0.7500\n",
            "Epoch 153/500\n",
            "80/80 [==============================] - 6s 62ms/step - loss: 0.5179 - acc: 0.7545 - val_loss: 0.5410 - val_acc: 0.6875\n",
            "Epoch 154/500\n",
            "80/80 [==============================] - 7s 75ms/step - loss: 0.5457 - acc: 0.7209 - val_loss: 0.5505 - val_acc: 0.6875\n",
            "Epoch 155/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5436 - acc: 0.7349 - val_loss: 0.5082 - val_acc: 0.8125\n",
            "Epoch 156/500\n",
            "80/80 [==============================] - 7s 78ms/step - loss: 0.5572 - acc: 0.7185 - val_loss: 0.5355 - val_acc: 0.7500\n",
            "Epoch 157/500\n",
            "80/80 [==============================] - 6s 75ms/step - loss: 0.5212 - acc: 0.7310 - val_loss: 0.5104 - val_acc: 0.7500\n",
            "Epoch 158/500\n",
            "80/80 [==============================] - 6s 64ms/step - loss: 0.5247 - acc: 0.7420 - val_loss: 0.5678 - val_acc: 0.6250\n",
            "Epoch 159/500\n",
            "80/80 [==============================] - 6s 69ms/step - loss: 0.5374 - acc: 0.7404 - val_loss: 0.5723 - val_acc: 0.6875\n",
            "Epoch 160/500\n",
            "80/80 [==============================] - 7s 72ms/step - loss: 0.5405 - acc: 0.7287 - val_loss: 0.5637 - val_acc: 0.6875\n",
            "Epoch 161/500\n",
            "80/80 [==============================] - 6s 73ms/step - loss: 0.5320 - acc: 0.7256 - val_loss: 0.5264 - val_acc: 0.6875\n",
            "Epoch 162/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5366 - acc: 0.7412 - val_loss: 0.5120 - val_acc: 0.7500\n",
            "Epoch 163/500\n",
            "80/80 [==============================] - 7s 72ms/step - loss: 0.5192 - acc: 0.7357 - val_loss: 0.5496 - val_acc: 0.6875\n",
            "Epoch 164/500\n",
            "80/80 [==============================] - 6s 69ms/step - loss: 0.5050 - acc: 0.7490 - val_loss: 0.4944 - val_acc: 0.7500\n",
            "Epoch 165/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5340 - acc: 0.7365 - val_loss: 0.5622 - val_acc: 0.6250\n",
            "Epoch 166/500\n",
            "80/80 [==============================] - 7s 75ms/step - loss: 0.5107 - acc: 0.7537 - val_loss: 0.5616 - val_acc: 0.6875\n",
            "Epoch 167/500\n",
            "80/80 [==============================] - 6s 63ms/step - loss: 0.5508 - acc: 0.7271 - val_loss: 0.5094 - val_acc: 0.6875\n",
            "Epoch 168/500\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 0.5375 - acc: 0.7162 - val_loss: 0.5853 - val_acc: 0.6875\n",
            "Epoch 169/500\n",
            "80/80 [==============================] - 7s 76ms/step - loss: 0.5207 - acc: 0.7295 - val_loss: 0.5527 - val_acc: 0.6875\n",
            "Epoch 170/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5223 - acc: 0.7435 - val_loss: 0.5636 - val_acc: 0.6250\n",
            "Epoch 171/500\n",
            "80/80 [==============================] - 7s 78ms/step - loss: 0.5035 - acc: 0.7451 - val_loss: 0.5622 - val_acc: 0.6250\n",
            "Epoch 172/500\n",
            "80/80 [==============================] - 6s 63ms/step - loss: 0.5263 - acc: 0.7545 - val_loss: 0.5411 - val_acc: 0.7500\n",
            "Epoch 173/500\n",
            "80/80 [==============================] - 7s 77ms/step - loss: 0.5271 - acc: 0.7138 - val_loss: 0.5499 - val_acc: 0.5625\n",
            "Epoch 174/500\n",
            "80/80 [==============================] - 6s 63ms/step - loss: 0.5304 - acc: 0.7389 - val_loss: 0.5924 - val_acc: 0.5625\n",
            "Epoch 175/500\n",
            "80/80 [==============================] - 7s 77ms/step - loss: 0.5382 - acc: 0.7248 - val_loss: 0.5946 - val_acc: 0.7500\n",
            "Epoch 176/500\n",
            "80/80 [==============================] - 6s 63ms/step - loss: 0.5323 - acc: 0.7201 - val_loss: 0.5800 - val_acc: 0.7500\n",
            "Epoch 177/500\n",
            "80/80 [==============================] - 6s 67ms/step - loss: 0.5235 - acc: 0.7475 - val_loss: 0.5933 - val_acc: 0.7500\n",
            "Epoch 178/500\n",
            "80/80 [==============================] - 5s 62ms/step - loss: 0.5369 - acc: 0.7295 - val_loss: 0.5919 - val_acc: 0.6875\n",
            "Epoch 179/500\n",
            "80/80 [==============================] - 7s 77ms/step - loss: 0.5283 - acc: 0.7287 - val_loss: 0.5534 - val_acc: 0.7500\n",
            "Epoch 180/500\n",
            "80/80 [==============================] - 6s 64ms/step - loss: 0.5251 - acc: 0.7185 - val_loss: 0.5328 - val_acc: 0.7500\n",
            "Epoch 181/500\n",
            "80/80 [==============================] - 7s 70ms/step - loss: 0.5389 - acc: 0.7248 - val_loss: 0.5389 - val_acc: 0.7500\n",
            "Epoch 182/500\n",
            "80/80 [==============================] - 6s 70ms/step - loss: 0.5395 - acc: 0.7389 - val_loss: 0.5717 - val_acc: 0.6875\n",
            "Epoch 183/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5190 - acc: 0.7420 - val_loss: 0.5152 - val_acc: 0.8125\n",
            "Epoch 184/500\n",
            "80/80 [==============================] - 6s 69ms/step - loss: 0.5157 - acc: 0.7389 - val_loss: 0.5728 - val_acc: 0.7500\n",
            "Epoch 185/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5347 - acc: 0.7381 - val_loss: 0.5347 - val_acc: 0.7500\n",
            "Epoch 186/500\n",
            "80/80 [==============================] - 7s 77ms/step - loss: 0.5212 - acc: 0.7310 - val_loss: 0.4745 - val_acc: 0.6875\n",
            "Epoch 187/500\n",
            "80/80 [==============================] - 6s 64ms/step - loss: 0.5250 - acc: 0.7271 - val_loss: 0.5515 - val_acc: 0.7500\n",
            "Epoch 188/500\n",
            "80/80 [==============================] - 6s 68ms/step - loss: 0.5286 - acc: 0.7529 - val_loss: 0.5636 - val_acc: 0.6875\n",
            "Epoch 189/500\n",
            "80/80 [==============================] - 6s 63ms/step - loss: 0.5326 - acc: 0.7389 - val_loss: 0.5357 - val_acc: 0.6250\n",
            "Epoch 190/500\n",
            "80/80 [==============================] - 7s 77ms/step - loss: 0.5402 - acc: 0.7232 - val_loss: 0.5647 - val_acc: 0.6875\n",
            "Epoch 191/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5383 - acc: 0.7248 - val_loss: 0.5871 - val_acc: 0.4375\n",
            "Epoch 192/500\n",
            "80/80 [==============================] - 6s 63ms/step - loss: 0.5489 - acc: 0.7170 - val_loss: 0.5372 - val_acc: 0.6875\n",
            "Epoch 193/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5377 - acc: 0.7123 - val_loss: 0.5264 - val_acc: 0.6875\n",
            "Epoch 194/500\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 0.5295 - acc: 0.7404 - val_loss: 0.5842 - val_acc: 0.7500\n",
            "Epoch 195/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5424 - acc: 0.7177 - val_loss: 0.5503 - val_acc: 0.6875\n",
            "Epoch 196/500\n",
            "80/80 [==============================] - 7s 77ms/step - loss: 0.5382 - acc: 0.7232 - val_loss: 0.5852 - val_acc: 0.6875\n",
            "Epoch 197/500\n",
            "80/80 [==============================] - 6s 62ms/step - loss: 0.5138 - acc: 0.7279 - val_loss: 0.5195 - val_acc: 0.7500\n",
            "Epoch 198/500\n",
            "80/80 [==============================] - 7s 76ms/step - loss: 0.5345 - acc: 0.7451 - val_loss: 0.5699 - val_acc: 0.7500\n",
            "Epoch 199/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5276 - acc: 0.7357 - val_loss: 0.5766 - val_acc: 0.6875\n",
            "Epoch 200/500\n",
            "80/80 [==============================] - 6s 67ms/step - loss: 0.5207 - acc: 0.7412 - val_loss: 0.5717 - val_acc: 0.6875\n",
            "Epoch 201/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5257 - acc: 0.7209 - val_loss: 0.5205 - val_acc: 0.7500\n",
            "Epoch 202/500\n",
            "80/80 [==============================] - 7s 79ms/step - loss: 0.5071 - acc: 0.7686 - val_loss: 0.5756 - val_acc: 0.6875\n",
            "Epoch 203/500\n",
            "80/80 [==============================] - 6s 64ms/step - loss: 0.5403 - acc: 0.7287 - val_loss: 0.5753 - val_acc: 0.6875\n",
            "Epoch 204/500\n",
            "80/80 [==============================] - 5s 62ms/step - loss: 0.5350 - acc: 0.7412 - val_loss: 0.5866 - val_acc: 0.6875\n",
            "Epoch 205/500\n",
            "80/80 [==============================] - 6s 73ms/step - loss: 0.5219 - acc: 0.7310 - val_loss: 0.5812 - val_acc: 0.7500\n",
            "Epoch 206/500\n",
            "80/80 [==============================] - 6s 64ms/step - loss: 0.5444 - acc: 0.7232 - val_loss: 0.4718 - val_acc: 0.7500\n",
            "Epoch 207/500\n",
            "80/80 [==============================] - 7s 75ms/step - loss: 0.5329 - acc: 0.7498 - val_loss: 0.5800 - val_acc: 0.6875\n",
            "Epoch 208/500\n",
            "80/80 [==============================] - 7s 74ms/step - loss: 0.5382 - acc: 0.7412 - val_loss: 0.5907 - val_acc: 0.5000\n",
            "Epoch 209/500\n",
            "80/80 [==============================] - 6s 75ms/step - loss: 0.5596 - acc: 0.7091 - val_loss: 0.5115 - val_acc: 0.7500\n",
            "Epoch 210/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5353 - acc: 0.7224 - val_loss: 0.5860 - val_acc: 0.5000\n",
            "Epoch 211/500\n",
            "80/80 [==============================] - 6s 69ms/step - loss: 0.5332 - acc: 0.7342 - val_loss: 0.5575 - val_acc: 0.6250\n",
            "Epoch 212/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5339 - acc: 0.7310 - val_loss: 0.4804 - val_acc: 0.6875\n",
            "Epoch 213/500\n",
            "80/80 [==============================] - 7s 72ms/step - loss: 0.5228 - acc: 0.7217 - val_loss: 0.5541 - val_acc: 0.6875\n",
            "Epoch 214/500\n",
            "80/80 [==============================] - 6s 62ms/step - loss: 0.5479 - acc: 0.7295 - val_loss: 0.4709 - val_acc: 0.6875\n",
            "Epoch 215/500\n",
            "80/80 [==============================] - 8s 86ms/step - loss: 0.4952 - acc: 0.7545 - val_loss: 0.5203 - val_acc: 0.6875\n",
            "79/80 [============================>.] - ETA: 0s - loss: 0.4956 - acc: 0.7538Epoch 216/500\n",
            "80/80 [==============================] - 6s 70ms/step - loss: 0.5428 - acc: 0.7177 - val_loss: 0.5481 - val_acc: 0.6875\n",
            "Epoch 217/500\n",
            "80/80 [==============================] - 6s 74ms/step - loss: 0.5351 - acc: 0.7248 - val_loss: 0.5839 - val_acc: 0.6875\n",
            "Epoch 218/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5340 - acc: 0.7248 - val_loss: 0.5090 - val_acc: 0.7500\n",
            "Epoch 219/500\n",
            "80/80 [==============================] - 6s 69ms/step - loss: 0.5174 - acc: 0.7498 - val_loss: 0.5403 - val_acc: 0.6875\n",
            "Epoch 220/500\n",
            "80/80 [==============================] - 6s 75ms/step - loss: 0.5147 - acc: 0.7381 - val_loss: 0.5562 - val_acc: 0.6875\n",
            "Epoch 221/500\n",
            "80/80 [==============================] - 6s 64ms/step - loss: 0.5334 - acc: 0.7459 - val_loss: 0.5518 - val_acc: 0.6875\n",
            "Epoch 222/500\n",
            "80/80 [==============================] - 7s 77ms/step - loss: 0.5246 - acc: 0.7342 - val_loss: 0.5690 - val_acc: 0.6875\n",
            "Epoch 223/500\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 0.5613 - acc: 0.7076 - val_loss: 0.5596 - val_acc: 0.6875\n",
            "Epoch 224/500\n",
            "80/80 [==============================] - 7s 79ms/step - loss: 0.5163 - acc: 0.7428 - val_loss: 0.5397 - val_acc: 0.7500\n",
            "Epoch 225/500\n",
            "80/80 [==============================] - 6s 63ms/step - loss: 0.5163 - acc: 0.7435 - val_loss: 0.5144 - val_acc: 0.6875\n",
            "Epoch 226/500\n",
            "80/80 [==============================] - 7s 76ms/step - loss: 0.5325 - acc: 0.7381 - val_loss: 0.5002 - val_acc: 0.7500\n",
            "Epoch 227/500\n",
            "80/80 [==============================] - 6s 64ms/step - loss: 0.5323 - acc: 0.7263 - val_loss: 0.5175 - val_acc: 0.7500\n",
            "Epoch 228/500\n",
            "80/80 [==============================] - 7s 74ms/step - loss: 0.5323 - acc: 0.7381 - val_loss: 0.4998 - val_acc: 0.7500\n",
            "Epoch 229/500\n",
            "80/80 [==============================] - 6s 63ms/step - loss: 0.5384 - acc: 0.7162 - val_loss: 0.5035 - val_acc: 0.8125\n",
            "Epoch 230/500\n",
            "80/80 [==============================] - 7s 78ms/step - loss: 0.5286 - acc: 0.7365 - val_loss: 0.5477 - val_acc: 0.6250\n",
            "Epoch 231/500\n",
            "80/80 [==============================] - 6s 67ms/step - loss: 0.5160 - acc: 0.7522 - val_loss: 0.5278 - val_acc: 0.6875\n",
            "Epoch 232/500\n",
            "80/80 [==============================] - 6s 64ms/step - loss: 0.5190 - acc: 0.7428 - val_loss: 0.5127 - val_acc: 0.7500\n",
            "Epoch 233/500\n",
            "80/80 [==============================] - 7s 75ms/step - loss: 0.5243 - acc: 0.7514 - val_loss: 0.5305 - val_acc: 0.7500\n",
            "Epoch 234/500\n",
            "80/80 [==============================] - 5s 62ms/step - loss: 0.5170 - acc: 0.7522 - val_loss: 0.5181 - val_acc: 0.6875\n",
            "Epoch 235/500\n",
            "80/80 [==============================] - 7s 75ms/step - loss: 0.5282 - acc: 0.7475 - val_loss: 0.5153 - val_acc: 0.7500\n",
            "Epoch 236/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5286 - acc: 0.7334 - val_loss: 0.5471 - val_acc: 0.6875\n",
            "Epoch 237/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5340 - acc: 0.7271 - val_loss: 0.5607 - val_acc: 0.6250\n",
            "Epoch 238/500\n",
            "80/80 [==============================] - 6s 73ms/step - loss: 0.5090 - acc: 0.7459 - val_loss: 0.5656 - val_acc: 0.7500\n",
            "Epoch 239/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5306 - acc: 0.7365 - val_loss: 0.5674 - val_acc: 0.6875\n",
            "Epoch 240/500\n",
            "80/80 [==============================] - 6s 63ms/step - loss: 0.5304 - acc: 0.7279 - val_loss: 0.5792 - val_acc: 0.7500\n",
            "Epoch 241/500\n",
            "80/80 [==============================] - 6s 69ms/step - loss: 0.5288 - acc: 0.7318 - val_loss: 0.5119 - val_acc: 0.8125\n",
            "Epoch 242/500\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 0.5562 - acc: 0.7209 - val_loss: 0.5693 - val_acc: 0.5625\n",
            "Epoch 243/500\n",
            "80/80 [==============================] - 6s 74ms/step - loss: 0.5255 - acc: 0.7310 - val_loss: 0.5482 - val_acc: 0.6875\n",
            "Epoch 244/500\n",
            "80/80 [==============================] - 6s 67ms/step - loss: 0.5286 - acc: 0.7357 - val_loss: 0.5232 - val_acc: 0.6875\n",
            "Epoch 245/500\n",
            "80/80 [==============================] - 6s 68ms/step - loss: 0.5189 - acc: 0.7357 - val_loss: 0.5108 - val_acc: 0.8125\n",
            "Epoch 246/500\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.5385 - acc: 0.7357 - val_loss: 0.5232 - val_acc: 0.6875\n",
            "Epoch 247/500\n",
            "80/80 [==============================] - 7s 77ms/step - loss: 0.5413 - acc: 0.7334 - val_loss: 0.5060 - val_acc: 0.8125\n",
            "Epoch 248/500\n",
            "80/80 [==============================] - 6s 64ms/step - loss: 0.5165 - acc: 0.7435 - val_loss: 0.5666 - val_acc: 0.7500\n",
            "Epoch 249/500\n",
            "80/80 [==============================] - 7s 74ms/step - loss: 0.5177 - acc: 0.7412 - val_loss: 0.5148 - val_acc: 0.7500\n",
            "Epoch 250/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5336 - acc: 0.7326 - val_loss: 0.4491 - val_acc: 0.8125\n",
            "Epoch 251/500\n",
            "80/80 [==============================] - 7s 79ms/step - loss: 0.5140 - acc: 0.7412 - val_loss: 0.5630 - val_acc: 0.6250\n",
            "Epoch 252/500\n",
            "80/80 [==============================] - 6s 64ms/step - loss: 0.5388 - acc: 0.7248 - val_loss: 0.5886 - val_acc: 0.7500\n",
            "Epoch 253/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5284 - acc: 0.7412 - val_loss: 0.5672 - val_acc: 0.6875\n",
            "Epoch 254/500\n",
            "80/80 [==============================] - 7s 74ms/step - loss: 0.5346 - acc: 0.7303 - val_loss: 0.5325 - val_acc: 0.7500\n",
            "Epoch 255/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5005 - acc: 0.7584 - val_loss: 0.5616 - val_acc: 0.6875\n",
            "Epoch 256/500\n",
            "80/80 [==============================] - 6s 63ms/step - loss: 0.5138 - acc: 0.7326 - val_loss: 0.5920 - val_acc: 0.6875\n",
            "Epoch 257/500\n",
            "80/80 [==============================] - 7s 75ms/step - loss: 0.5107 - acc: 0.7522 - val_loss: 0.5751 - val_acc: 0.6875\n",
            "Epoch 258/500\n",
            "80/80 [==============================] - 6s 62ms/step - loss: 0.5220 - acc: 0.7459 - val_loss: 0.5663 - val_acc: 0.6875\n",
            "Epoch 259/500\n",
            "80/80 [==============================] - 6s 64ms/step - loss: 0.5066 - acc: 0.7451 - val_loss: 0.4665 - val_acc: 0.6875\n",
            "Epoch 260/500\n",
            "80/80 [==============================] - 7s 76ms/step - loss: 0.5449 - acc: 0.7365 - val_loss: 0.5001 - val_acc: 0.7500\n",
            "Epoch 261/500\n",
            "80/80 [==============================] - 6s 74ms/step - loss: 0.5406 - acc: 0.7217 - val_loss: 0.5599 - val_acc: 0.6875\n",
            "Epoch 262/500\n",
            "80/80 [==============================] - 6s 73ms/step - loss: 0.5042 - acc: 0.7451 - val_loss: 0.5636 - val_acc: 0.6875\n",
            "Epoch 263/500\n",
            "80/80 [==============================] - 6s 67ms/step - loss: 0.5104 - acc: 0.7490 - val_loss: 0.4895 - val_acc: 0.8125\n",
            "Epoch 264/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5369 - acc: 0.7256 - val_loss: 0.5528 - val_acc: 0.6875\n",
            "Epoch 265/500\n",
            "80/80 [==============================] - 7s 75ms/step - loss: 0.5133 - acc: 0.7420 - val_loss: 0.5547 - val_acc: 0.7500\n",
            "Epoch 266/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5249 - acc: 0.7631 - val_loss: 0.5033 - val_acc: 0.7500\n",
            "Epoch 267/500\n",
            "80/80 [==============================] - 7s 81ms/step - loss: 0.5221 - acc: 0.7435 - val_loss: 0.5534 - val_acc: 0.6875\n",
            "Epoch 268/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5464 - acc: 0.7201 - val_loss: 0.5649 - val_acc: 0.6875\n",
            "Epoch 269/500\n",
            "80/80 [==============================] - 7s 81ms/step - loss: 0.5254 - acc: 0.7389 - val_loss: 0.5250 - val_acc: 0.6250\n",
            "Epoch 270/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5172 - acc: 0.7561 - val_loss: 0.4863 - val_acc: 0.7500\n",
            "Epoch 271/500\n",
            "80/80 [==============================] - 6s 70ms/step - loss: 0.5425 - acc: 0.7154 - val_loss: 0.4718 - val_acc: 0.6875\n",
            "Epoch 272/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5206 - acc: 0.7271 - val_loss: 0.5164 - val_acc: 0.6875\n",
            "Epoch 273/500\n",
            "80/80 [==============================] - 6s 67ms/step - loss: 0.5263 - acc: 0.7326 - val_loss: 0.5555 - val_acc: 0.6875\n",
            "Epoch 274/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5269 - acc: 0.7263 - val_loss: 0.5130 - val_acc: 0.6875\n",
            "Epoch 275/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5278 - acc: 0.7349 - val_loss: 0.5427 - val_acc: 0.6875\n",
            "Epoch 276/500\n",
            "80/80 [==============================] - 7s 71ms/step - loss: 0.5300 - acc: 0.7248 - val_loss: 0.5691 - val_acc: 0.6250\n",
            "Epoch 277/500\n",
            "80/80 [==============================] - 7s 75ms/step - loss: 0.5280 - acc: 0.7256 - val_loss: 0.5094 - val_acc: 0.7500\n",
            "Epoch 278/500\n",
            "80/80 [==============================] - 6s 76ms/step - loss: 0.5320 - acc: 0.7389 - val_loss: 0.5087 - val_acc: 0.7500\n",
            "Epoch 279/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5280 - acc: 0.7334 - val_loss: 0.5363 - val_acc: 0.6875\n",
            "Epoch 280/500\n",
            "80/80 [==============================] - 7s 76ms/step - loss: 0.5227 - acc: 0.7467 - val_loss: 0.5671 - val_acc: 0.6875\n",
            "Epoch 281/500\n",
            "80/80 [==============================] - 6s 64ms/step - loss: 0.5095 - acc: 0.7482 - val_loss: 0.5584 - val_acc: 0.7500\n",
            "Epoch 282/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5379 - acc: 0.7217 - val_loss: 0.4858 - val_acc: 0.7500\n",
            "Epoch 283/500\n",
            "80/80 [==============================] - 7s 75ms/step - loss: 0.5144 - acc: 0.7334 - val_loss: 0.5242 - val_acc: 0.7500\n",
            "Epoch 284/500\n",
            "80/80 [==============================] - 6s 67ms/step - loss: 0.5446 - acc: 0.7303 - val_loss: 0.5648 - val_acc: 0.6875\n",
            "Epoch 285/500\n",
            "80/80 [==============================] - 7s 82ms/step - loss: 0.5295 - acc: 0.7498 - val_loss: 0.5683 - val_acc: 0.6875\n",
            "Epoch 286/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5196 - acc: 0.7475 - val_loss: 0.5756 - val_acc: 0.6250\n",
            "Epoch 287/500\n",
            "80/80 [==============================] - 6s 70ms/step - loss: 0.5141 - acc: 0.7428 - val_loss: 0.5713 - val_acc: 0.6875\n",
            "Epoch 288/500\n",
            "80/80 [==============================] - 6s 69ms/step - loss: 0.5046 - acc: 0.7545 - val_loss: 0.5050 - val_acc: 0.7500\n",
            "Epoch 289/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5317 - acc: 0.7279 - val_loss: 0.5653 - val_acc: 0.6250\n",
            "Epoch 290/500\n",
            "80/80 [==============================] - 7s 85ms/step - loss: 0.5350 - acc: 0.7295 - val_loss: 0.5440 - val_acc: 0.6875\n",
            "Epoch 291/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5275 - acc: 0.7396 - val_loss: 0.5149 - val_acc: 0.7500\n",
            "Epoch 292/500\n",
            "80/80 [==============================] - 6s 67ms/step - loss: 0.5273 - acc: 0.7310 - val_loss: 0.5192 - val_acc: 0.7500\n",
            "Epoch 293/500\n",
            "80/80 [==============================] - 6s 75ms/step - loss: 0.5308 - acc: 0.7287 - val_loss: 0.5545 - val_acc: 0.6875\n",
            "Epoch 294/500\n",
            "80/80 [==============================] - 6s 67ms/step - loss: 0.5288 - acc: 0.7263 - val_loss: 0.5373 - val_acc: 0.6875\n",
            "Epoch 295/500\n",
            "80/80 [==============================] - 7s 77ms/step - loss: 0.5218 - acc: 0.7428 - val_loss: 0.5455 - val_acc: 0.6250\n",
            "Epoch 296/500\n",
            "80/80 [==============================] - 6s 69ms/step - loss: 0.5301 - acc: 0.7295 - val_loss: 0.5354 - val_acc: 0.6250\n",
            "Epoch 297/500\n",
            "80/80 [==============================] - 7s 77ms/step - loss: 0.5343 - acc: 0.7310 - val_loss: 0.5235 - val_acc: 0.7500\n",
            "Epoch 298/500\n",
            "80/80 [==============================] - 6s 64ms/step - loss: 0.5270 - acc: 0.7295 - val_loss: 0.5357 - val_acc: 0.7500\n",
            "Epoch 299/500\n",
            "80/80 [==============================] - 7s 77ms/step - loss: 0.5294 - acc: 0.7373 - val_loss: 0.5374 - val_acc: 0.6875\n",
            "Epoch 300/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5566 - acc: 0.7193 - val_loss: 0.5343 - val_acc: 0.6875\n",
            "Epoch 301/500\n",
            "80/80 [==============================] - 7s 76ms/step - loss: 0.5194 - acc: 0.7396 - val_loss: 0.5256 - val_acc: 0.6875\n",
            "Epoch 302/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5276 - acc: 0.7381 - val_loss: 0.5589 - val_acc: 0.6875\n",
            "Epoch 303/500\n",
            "80/80 [==============================] - 6s 69ms/step - loss: 0.5019 - acc: 0.7514 - val_loss: 0.5062 - val_acc: 0.7500\n",
            "Epoch 304/500\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 0.5108 - acc: 0.7592 - val_loss: 0.5695 - val_acc: 0.6250\n",
            "Epoch 305/500\n",
            "80/80 [==============================] - 7s 77ms/step - loss: 0.5357 - acc: 0.7498 - val_loss: 0.5303 - val_acc: 0.6875\n",
            "Epoch 306/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5222 - acc: 0.7263 - val_loss: 0.5298 - val_acc: 0.6875\n",
            "Epoch 307/500\n",
            "80/80 [==============================] - 7s 78ms/step - loss: 0.5281 - acc: 0.7334 - val_loss: 0.5470 - val_acc: 0.6875\n",
            "Epoch 308/500\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 0.5111 - acc: 0.7435 - val_loss: 0.4832 - val_acc: 0.6875\n",
            "Epoch 309/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5323 - acc: 0.7396 - val_loss: 0.5343 - val_acc: 0.6250\n",
            "Epoch 310/500\n",
            "80/80 [==============================] - 7s 76ms/step - loss: 0.5289 - acc: 0.7365 - val_loss: 0.5850 - val_acc: 0.6250\n",
            "Epoch 311/500\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 0.5265 - acc: 0.7381 - val_loss: 0.5466 - val_acc: 0.6250\n",
            "Epoch 312/500\n",
            "80/80 [==============================] - 7s 82ms/step - loss: 0.5248 - acc: 0.7467 - val_loss: 0.5290 - val_acc: 0.6875\n",
            "Epoch 313/500\n",
            "80/80 [==============================] - 6s 64ms/step - loss: 0.5200 - acc: 0.7506 - val_loss: 0.5773 - val_acc: 0.6250\n",
            "Epoch 314/500\n",
            "80/80 [==============================] - 7s 75ms/step - loss: 0.5370 - acc: 0.7303 - val_loss: 0.5516 - val_acc: 0.6250\n",
            "Epoch 315/500\n",
            "80/80 [==============================] - 6s 63ms/step - loss: 0.5304 - acc: 0.7584 - val_loss: 0.5631 - val_acc: 0.5625\n",
            "Epoch 316/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5457 - acc: 0.7295 - val_loss: 0.5466 - val_acc: 0.6875\n",
            "Epoch 317/500\n",
            "80/80 [==============================] - 6s 67ms/step - loss: 0.5144 - acc: 0.7529 - val_loss: 0.4954 - val_acc: 0.6875\n",
            "Epoch 318/500\n",
            "80/80 [==============================] - 7s 73ms/step - loss: 0.5427 - acc: 0.7326 - val_loss: 0.5539 - val_acc: 0.6875\n",
            "Epoch 319/500\n",
            "80/80 [==============================] - 7s 74ms/step - loss: 0.5202 - acc: 0.7482 - val_loss: 0.5999 - val_acc: 0.6250\n",
            "Epoch 320/500\n",
            "80/80 [==============================] - 7s 78ms/step - loss: 0.5189 - acc: 0.7467 - val_loss: 0.5729 - val_acc: 0.6250\n",
            "Epoch 321/500\n",
            "80/80 [==============================] - 6s 68ms/step - loss: 0.5320 - acc: 0.7303 - val_loss: 0.5985 - val_acc: 0.5625\n",
            "Epoch 322/500\n",
            "80/80 [==============================] - 7s 75ms/step - loss: 0.5105 - acc: 0.7608 - val_loss: 0.5869 - val_acc: 0.6250\n",
            "Epoch 323/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5326 - acc: 0.7373 - val_loss: 0.5909 - val_acc: 0.6250\n",
            "Epoch 324/500\n",
            "80/80 [==============================] - 7s 82ms/step - loss: 0.5408 - acc: 0.7217 - val_loss: 0.4959 - val_acc: 0.6875\n",
            "Epoch 325/500\n",
            "80/80 [==============================] - 6s 67ms/step - loss: 0.5363 - acc: 0.7170 - val_loss: 0.5056 - val_acc: 0.7500\n",
            "Epoch 326/500\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 0.5330 - acc: 0.7381 - val_loss: 0.5855 - val_acc: 0.6250\n",
            "Epoch 327/500\n",
            "80/80 [==============================] - 6s 75ms/step - loss: 0.5416 - acc: 0.7318 - val_loss: 0.5453 - val_acc: 0.6250\n",
            "Epoch 328/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5255 - acc: 0.7412 - val_loss: 0.5833 - val_acc: 0.6250\n",
            "Epoch 329/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5378 - acc: 0.7318 - val_loss: 0.5742 - val_acc: 0.6250\n",
            "Epoch 330/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5167 - acc: 0.7537 - val_loss: 0.5714 - val_acc: 0.6875\n",
            "Epoch 331/500\n",
            "80/80 [==============================] - 5s 62ms/step - loss: 0.5289 - acc: 0.7318 - val_loss: 0.5362 - val_acc: 0.6250\n",
            "Epoch 332/500\n",
            "80/80 [==============================] - 7s 74ms/step - loss: 0.5280 - acc: 0.7310 - val_loss: 0.5681 - val_acc: 0.6875\n",
            "Epoch 333/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5213 - acc: 0.7365 - val_loss: 0.5414 - val_acc: 0.6875\n",
            "Epoch 334/500\n",
            "80/80 [==============================] - 6s 69ms/step - loss: 0.5290 - acc: 0.7365 - val_loss: 0.5456 - val_acc: 0.6875\n",
            "Epoch 335/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5392 - acc: 0.7224 - val_loss: 0.5102 - val_acc: 0.6250\n",
            "Epoch 336/500\n",
            "80/80 [==============================] - 7s 81ms/step - loss: 0.5150 - acc: 0.7279 - val_loss: 0.5096 - val_acc: 0.6875\n",
            "Epoch 337/500\n",
            "80/80 [==============================] - 6s 70ms/step - loss: 0.5401 - acc: 0.7209 - val_loss: 0.5301 - val_acc: 0.6875\n",
            "Epoch 338/500\n",
            "80/80 [==============================] - 6s 64ms/step - loss: 0.5277 - acc: 0.7287 - val_loss: 0.4785 - val_acc: 0.7500\n",
            "Epoch 339/500\n",
            "80/80 [==============================] - 7s 77ms/step - loss: 0.5084 - acc: 0.7545 - val_loss: 0.5244 - val_acc: 0.6875\n",
            "Epoch 340/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5320 - acc: 0.7420 - val_loss: 0.5011 - val_acc: 0.8125\n",
            "Epoch 341/500\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.5073 - acc: 0.7428 - val_loss: 0.4771 - val_acc: 0.6875\n",
            "Epoch 342/500\n",
            "80/80 [==============================] - 6s 64ms/step - loss: 0.5152 - acc: 0.7467 - val_loss: 0.5447 - val_acc: 0.6875\n",
            "Epoch 343/500\n",
            "80/80 [==============================] - 7s 75ms/step - loss: 0.5031 - acc: 0.7506 - val_loss: 0.4621 - val_acc: 0.7500\n",
            "Epoch 344/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5485 - acc: 0.7318 - val_loss: 0.5234 - val_acc: 0.6250\n",
            "Epoch 345/500\n",
            "80/80 [==============================] - 6s 70ms/step - loss: 0.5367 - acc: 0.7287 - val_loss: 0.4921 - val_acc: 0.7500\n",
            "Epoch 346/500\n",
            "80/80 [==============================] - 7s 85ms/step - loss: 0.5348 - acc: 0.7357 - val_loss: 0.4903 - val_acc: 0.6875\n",
            "Epoch 347/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5237 - acc: 0.7412 - val_loss: 0.5015 - val_acc: 0.7500\n",
            "Epoch 348/500\n",
            "80/80 [==============================] - 7s 75ms/step - loss: 0.5173 - acc: 0.7475 - val_loss: 0.5291 - val_acc: 0.7500\n",
            "Epoch 349/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5333 - acc: 0.7357 - val_loss: 0.4956 - val_acc: 0.7500\n",
            "Epoch 350/500\n",
            "80/80 [==============================] - 6s 73ms/step - loss: 0.5160 - acc: 0.7490 - val_loss: 0.4999 - val_acc: 0.6250\n",
            "Epoch 351/500\n",
            "80/80 [==============================] - 6s 67ms/step - loss: 0.5394 - acc: 0.7334 - val_loss: 0.5402 - val_acc: 0.6250\n",
            "Epoch 352/500\n",
            "80/80 [==============================] - 6s 70ms/step - loss: 0.5255 - acc: 0.7310 - val_loss: 0.5392 - val_acc: 0.7500\n",
            "Epoch 353/500\n",
            "80/80 [==============================] - 6s 73ms/step - loss: 0.5179 - acc: 0.7381 - val_loss: 0.5414 - val_acc: 0.6875\n",
            "Epoch 354/500\n",
            "80/80 [==============================] - 6s 75ms/step - loss: 0.5611 - acc: 0.7185 - val_loss: 0.4796 - val_acc: 0.8125\n",
            "Epoch 355/500\n",
            "80/80 [==============================] - 7s 74ms/step - loss: 0.5407 - acc: 0.7263 - val_loss: 0.5720 - val_acc: 0.6875\n",
            "Epoch 356/500\n",
            "80/80 [==============================] - 7s 77ms/step - loss: 0.5257 - acc: 0.7396 - val_loss: 0.5442 - val_acc: 0.6250\n",
            "Epoch 357/500\n",
            "80/80 [==============================] - 6s 61ms/step - loss: 0.5359 - acc: 0.7279 - val_loss: 0.5384 - val_acc: 0.7500\n",
            "Epoch 358/500\n",
            "80/80 [==============================] - 7s 74ms/step - loss: 0.5158 - acc: 0.7443 - val_loss: 0.4915 - val_acc: 0.7500\n",
            "Epoch 359/500\n",
            "80/80 [==============================] - 5s 62ms/step - loss: 0.5339 - acc: 0.7310 - val_loss: 0.5187 - val_acc: 0.6875\n",
            "Epoch 360/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5264 - acc: 0.7381 - val_loss: 0.5484 - val_acc: 0.7500\n",
            "Epoch 361/500\n",
            "80/80 [==============================] - 7s 76ms/step - loss: 0.5293 - acc: 0.7459 - val_loss: 0.4890 - val_acc: 0.8125\n",
            "Epoch 362/500\n",
            "80/80 [==============================] - 5s 62ms/step - loss: 0.5137 - acc: 0.7506 - val_loss: 0.5309 - val_acc: 0.6250\n",
            "Epoch 363/500\n",
            "80/80 [==============================] - 8s 84ms/step - loss: 0.5442 - acc: 0.7365 - val_loss: 0.5446 - val_acc: 0.6875\n",
            "Epoch 364/500\n",
            "80/80 [==============================] - 6s 70ms/step - loss: 0.5247 - acc: 0.7357 - val_loss: 0.4882 - val_acc: 0.8125\n",
            "Epoch 365/500\n",
            "80/80 [==============================] - 7s 76ms/step - loss: 0.5187 - acc: 0.7514 - val_loss: 0.5504 - val_acc: 0.7500\n",
            "Epoch 366/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5203 - acc: 0.7373 - val_loss: 0.4993 - val_acc: 0.7500\n",
            "Epoch 367/500\n",
            "80/80 [==============================] - 7s 74ms/step - loss: 0.5351 - acc: 0.7310 - val_loss: 0.5062 - val_acc: 0.6875\n",
            "Epoch 368/500\n",
            "80/80 [==============================] - 6s 62ms/step - loss: 0.5153 - acc: 0.7428 - val_loss: 0.5228 - val_acc: 0.7500\n",
            "Epoch 369/500\n",
            "80/80 [==============================] - 7s 80ms/step - loss: 0.5400 - acc: 0.7435 - val_loss: 0.5520 - val_acc: 0.7500\n",
            "Epoch 370/500\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 0.5424 - acc: 0.7263 - val_loss: 0.5211 - val_acc: 0.7500\n",
            "Epoch 371/500\n",
            "80/80 [==============================] - 6s 70ms/step - loss: 0.5274 - acc: 0.7349 - val_loss: 0.4591 - val_acc: 0.7500\n",
            "Epoch 372/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5206 - acc: 0.7459 - val_loss: 0.5373 - val_acc: 0.6875\n",
            "Epoch 373/500\n",
            "80/80 [==============================] - 7s 79ms/step - loss: 0.5285 - acc: 0.7287 - val_loss: 0.5453 - val_acc: 0.7500\n",
            "Epoch 374/500\n",
            "80/80 [==============================] - 7s 77ms/step - loss: 0.5164 - acc: 0.7412 - val_loss: 0.5233 - val_acc: 0.7500\n",
            "Epoch 375/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5130 - acc: 0.7428 - val_loss: 0.5374 - val_acc: 0.6875\n",
            "Epoch 376/500\n",
            "80/80 [==============================] - 8s 85ms/step - loss: 0.5459 - acc: 0.7310 - val_loss: 0.5820 - val_acc: 0.7500\n",
            "Epoch 377/500\n",
            "80/80 [==============================] - 6s 68ms/step - loss: 0.5219 - acc: 0.7514 - val_loss: 0.5290 - val_acc: 0.8125\n",
            "Epoch 378/500\n",
            "80/80 [==============================] - 7s 74ms/step - loss: 0.5244 - acc: 0.7420 - val_loss: 0.5758 - val_acc: 0.6875\n",
            "Epoch 379/500\n",
            "80/80 [==============================] - 7s 77ms/step - loss: 0.5407 - acc: 0.7303 - val_loss: 0.5664 - val_acc: 0.6875\n",
            "Epoch 380/500\n",
            "80/80 [==============================] - 6s 67ms/step - loss: 0.5263 - acc: 0.7263 - val_loss: 0.5180 - val_acc: 0.6875\n",
            "Epoch 381/500\n",
            "80/80 [==============================] - 7s 78ms/step - loss: 0.5528 - acc: 0.7193 - val_loss: 0.5367 - val_acc: 0.6875\n",
            "Epoch 382/500\n",
            "80/80 [==============================] - 6s 74ms/step - loss: 0.5293 - acc: 0.7357 - val_loss: 0.5355 - val_acc: 0.7500\n",
            "Epoch 383/500\n",
            "80/80 [==============================] - 7s 72ms/step - loss: 0.5193 - acc: 0.7349 - val_loss: 0.5339 - val_acc: 0.7500\n",
            "Epoch 384/500\n",
            "80/80 [==============================] - 7s 77ms/step - loss: 0.5292 - acc: 0.7287 - val_loss: 0.5231 - val_acc: 0.6250\n",
            "Epoch 385/500\n",
            "80/80 [==============================] - 6s 70ms/step - loss: 0.5161 - acc: 0.7467 - val_loss: 0.5163 - val_acc: 0.6875\n",
            "Epoch 386/500\n",
            "80/80 [==============================] - 7s 70ms/step - loss: 0.5152 - acc: 0.7482 - val_loss: 0.5784 - val_acc: 0.7500\n",
            "Epoch 387/500\n",
            "80/80 [==============================] - 7s 83ms/step - loss: 0.5289 - acc: 0.7537 - val_loss: 0.5031 - val_acc: 0.8125\n",
            "Epoch 388/500\n",
            "80/80 [==============================] - 6s 67ms/step - loss: 0.5096 - acc: 0.7420 - val_loss: 0.5325 - val_acc: 0.6875\n",
            "Epoch 389/500\n",
            "80/80 [==============================] - 7s 78ms/step - loss: 0.5242 - acc: 0.7365 - val_loss: 0.5353 - val_acc: 0.7500\n",
            "Epoch 390/500\n",
            "80/80 [==============================] - 6s 73ms/step - loss: 0.5260 - acc: 0.7365 - val_loss: 0.5638 - val_acc: 0.7500\n",
            "Epoch 391/500\n",
            "80/80 [==============================] - 6s 74ms/step - loss: 0.5067 - acc: 0.7349 - val_loss: 0.5434 - val_acc: 0.7500\n",
            "Epoch 392/500\n",
            "80/80 [==============================] - 7s 79ms/step - loss: 0.5486 - acc: 0.7131 - val_loss: 0.5383 - val_acc: 0.7500\n",
            "Epoch 393/500\n",
            "80/80 [==============================] - 7s 79ms/step - loss: 0.5307 - acc: 0.7318 - val_loss: 0.5720 - val_acc: 0.7500\n",
            "Epoch 394/500\n",
            "80/80 [==============================] - 7s 76ms/step - loss: 0.5050 - acc: 0.7639 - val_loss: 0.5713 - val_acc: 0.7500\n",
            "Epoch 395/500\n",
            "80/80 [==============================] - 7s 77ms/step - loss: 0.5188 - acc: 0.7365 - val_loss: 0.5644 - val_acc: 0.6875\n",
            "Epoch 396/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5347 - acc: 0.7318 - val_loss: 0.4739 - val_acc: 0.8125\n",
            "Epoch 397/500\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 0.5172 - acc: 0.7435 - val_loss: 0.5270 - val_acc: 0.6875\n",
            "Epoch 398/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5195 - acc: 0.7326 - val_loss: 0.5601 - val_acc: 0.7500\n",
            "Epoch 399/500\n",
            "80/80 [==============================] - 7s 79ms/step - loss: 0.5221 - acc: 0.7537 - val_loss: 0.5029 - val_acc: 0.8125\n",
            "Epoch 400/500\n",
            "80/80 [==============================] - 6s 69ms/step - loss: 0.5258 - acc: 0.7389 - val_loss: 0.4887 - val_acc: 0.8125\n",
            "Epoch 401/500\n",
            "80/80 [==============================] - 6s 74ms/step - loss: 0.4893 - acc: 0.7568 - val_loss: 0.5473 - val_acc: 0.6875\n",
            "Epoch 402/500\n",
            "80/80 [==============================] - 7s 81ms/step - loss: 0.5322 - acc: 0.7318 - val_loss: 0.5523 - val_acc: 0.6250\n",
            "Epoch 403/500\n",
            "80/80 [==============================] - 6s 69ms/step - loss: 0.5401 - acc: 0.7248 - val_loss: 0.5616 - val_acc: 0.6875\n",
            "Epoch 404/500\n",
            "80/80 [==============================] - 8s 89ms/step - loss: 0.5184 - acc: 0.7420 - val_loss: 0.5544 - val_acc: 0.7500\n",
            "Epoch 405/500\n",
            "80/80 [==============================] - 6s 75ms/step - loss: 0.5307 - acc: 0.7357 - val_loss: 0.5414 - val_acc: 0.6875\n",
            "Epoch 406/500\n",
            "80/80 [==============================] - 7s 75ms/step - loss: 0.5093 - acc: 0.7412 - val_loss: 0.5221 - val_acc: 0.6875\n",
            "Epoch 407/500\n",
            "80/80 [==============================] - 6s 67ms/step - loss: 0.5314 - acc: 0.7310 - val_loss: 0.5242 - val_acc: 0.7500\n",
            "Epoch 408/500\n",
            "80/80 [==============================] - 7s 77ms/step - loss: 0.5283 - acc: 0.7365 - val_loss: 0.4834 - val_acc: 0.6875\n",
            "Epoch 409/500\n",
            "80/80 [==============================] - 6s 69ms/step - loss: 0.5485 - acc: 0.7217 - val_loss: 0.5013 - val_acc: 0.8125\n",
            "Epoch 410/500\n",
            "80/80 [==============================] - 7s 77ms/step - loss: 0.5234 - acc: 0.7498 - val_loss: 0.5105 - val_acc: 0.8125\n",
            "Epoch 411/500\n",
            "80/80 [==============================] - 6s 67ms/step - loss: 0.5341 - acc: 0.7373 - val_loss: 0.4800 - val_acc: 0.6875\n",
            "Epoch 412/500\n",
            "80/80 [==============================] - 6s 67ms/step - loss: 0.5168 - acc: 0.7545 - val_loss: 0.5274 - val_acc: 0.7500\n",
            "Epoch 413/500\n",
            "80/80 [==============================] - 7s 75ms/step - loss: 0.5257 - acc: 0.7389 - val_loss: 0.4536 - val_acc: 0.8125\n",
            "Epoch 414/500\n",
            "80/80 [==============================] - 6s 69ms/step - loss: 0.5303 - acc: 0.7318 - val_loss: 0.5420 - val_acc: 0.7500\n",
            "Epoch 415/500\n",
            "80/80 [==============================] - 7s 72ms/step - loss: 0.5283 - acc: 0.7412 - val_loss: 0.4988 - val_acc: 0.6875\n",
            "Epoch 416/500\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 0.5340 - acc: 0.7467 - val_loss: 0.5394 - val_acc: 0.6875\n",
            "Epoch 417/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5416 - acc: 0.7295 - val_loss: 0.5730 - val_acc: 0.6250\n",
            "Epoch 418/500\n",
            "80/80 [==============================] - 7s 77ms/step - loss: 0.5029 - acc: 0.7498 - val_loss: 0.5262 - val_acc: 0.6875\n",
            "Epoch 419/500\n",
            "80/80 [==============================] - 6s 68ms/step - loss: 0.5186 - acc: 0.7404 - val_loss: 0.5540 - val_acc: 0.6250\n",
            "Epoch 420/500\n",
            "80/80 [==============================] - 7s 76ms/step - loss: 0.5360 - acc: 0.7365 - val_loss: 0.5412 - val_acc: 0.6875\n",
            "Epoch 421/500\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 0.5259 - acc: 0.7443 - val_loss: 0.5888 - val_acc: 0.6875\n",
            "Epoch 422/500\n",
            "80/80 [==============================] - 6s 75ms/step - loss: 0.5155 - acc: 0.7365 - val_loss: 0.5760 - val_acc: 0.7500\n",
            "Epoch 423/500\n",
            "80/80 [==============================] - 7s 81ms/step - loss: 0.5383 - acc: 0.7271 - val_loss: 0.5708 - val_acc: 0.6875\n",
            "Epoch 424/500\n",
            "80/80 [==============================] - 7s 81ms/step - loss: 0.5391 - acc: 0.7334 - val_loss: 0.5567 - val_acc: 0.7500\n",
            "Epoch 425/500\n",
            "80/80 [==============================] - 6s 68ms/step - loss: 0.5237 - acc: 0.7303 - val_loss: 0.5964 - val_acc: 0.7500\n",
            "Epoch 426/500\n",
            "80/80 [==============================] - 7s 74ms/step - loss: 0.5400 - acc: 0.7373 - val_loss: 0.5377 - val_acc: 0.6875\n",
            "Epoch 427/500\n",
            "80/80 [==============================] - 7s 71ms/step - loss: 0.5099 - acc: 0.7420 - val_loss: 0.5056 - val_acc: 0.8125\n",
            "Epoch 428/500\n",
            "80/80 [==============================] - 7s 82ms/step - loss: 0.5281 - acc: 0.7224 - val_loss: 0.5746 - val_acc: 0.6250\n",
            "Epoch 429/500\n",
            "80/80 [==============================] - 7s 77ms/step - loss: 0.5625 - acc: 0.7037 - val_loss: 0.5933 - val_acc: 0.6250\n",
            "Epoch 430/500\n",
            "80/80 [==============================] - 6s 67ms/step - loss: 0.5222 - acc: 0.7396 - val_loss: 0.5900 - val_acc: 0.7500\n",
            "Epoch 431/500\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.5141 - acc: 0.7545 - val_loss: 0.5267 - val_acc: 0.8125\n",
            "Epoch 432/500\n",
            "80/80 [==============================] - 6s 64ms/step - loss: 0.5194 - acc: 0.7357 - val_loss: 0.5574 - val_acc: 0.7500\n",
            "Epoch 433/500\n",
            "80/80 [==============================] - 7s 78ms/step - loss: 0.5355 - acc: 0.7404 - val_loss: 0.5351 - val_acc: 0.6875\n",
            "Epoch 434/500\n",
            "80/80 [==============================] - 6s 63ms/step - loss: 0.5054 - acc: 0.7373 - val_loss: 0.5852 - val_acc: 0.6875\n",
            "Epoch 435/500\n",
            "80/80 [==============================] - 7s 82ms/step - loss: 0.5270 - acc: 0.7514 - val_loss: 0.5097 - val_acc: 0.8125\n",
            "Epoch 436/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5199 - acc: 0.7357 - val_loss: 0.5436 - val_acc: 0.5625\n",
            "Epoch 437/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5258 - acc: 0.7459 - val_loss: 0.5587 - val_acc: 0.6250\n",
            "Epoch 438/500\n",
            "80/80 [==============================] - 7s 77ms/step - loss: 0.5366 - acc: 0.7490 - val_loss: 0.4924 - val_acc: 0.8125\n",
            "Epoch 439/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5358 - acc: 0.7435 - val_loss: 0.5153 - val_acc: 0.6875\n",
            "Epoch 440/500\n",
            "80/80 [==============================] - 7s 82ms/step - loss: 0.5127 - acc: 0.7498 - val_loss: 0.5277 - val_acc: 0.7500\n",
            "Epoch 441/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5255 - acc: 0.7342 - val_loss: 0.5292 - val_acc: 0.7500\n",
            "Epoch 442/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5502 - acc: 0.7256 - val_loss: 0.5599 - val_acc: 0.6250\n",
            "Epoch 443/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5204 - acc: 0.7412 - val_loss: 0.5100 - val_acc: 0.6875\n",
            "Epoch 444/500\n",
            "80/80 [==============================] - 6s 67ms/step - loss: 0.5094 - acc: 0.7615 - val_loss: 0.5236 - val_acc: 0.7500\n",
            "Epoch 445/500\n",
            "80/80 [==============================] - 7s 76ms/step - loss: 0.4958 - acc: 0.7506 - val_loss: 0.5686 - val_acc: 0.6250\n",
            "Epoch 446/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5289 - acc: 0.7357 - val_loss: 0.4998 - val_acc: 0.8125\n",
            "Epoch 447/500\n",
            "80/80 [==============================] - 7s 74ms/step - loss: 0.5197 - acc: 0.7349 - val_loss: 0.4810 - val_acc: 0.6875\n",
            "Epoch 448/500\n",
            "80/80 [==============================] - 6s 67ms/step - loss: 0.5303 - acc: 0.7459 - val_loss: 0.5564 - val_acc: 0.7500\n",
            "Epoch 449/500\n",
            "80/80 [==============================] - 5s 62ms/step - loss: 0.5224 - acc: 0.7435 - val_loss: 0.5777 - val_acc: 0.7500\n",
            "Epoch 450/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5323 - acc: 0.7209 - val_loss: 0.5122 - val_acc: 0.7500\n",
            "Epoch 451/500\n",
            "80/80 [==============================] - 7s 73ms/step - loss: 0.5230 - acc: 0.7459 - val_loss: 0.4519 - val_acc: 0.8125\n",
            "Epoch 452/500\n",
            "80/80 [==============================] - 6s 70ms/step - loss: 0.5592 - acc: 0.7342 - val_loss: 0.5290 - val_acc: 0.7500\n",
            "Epoch 453/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5097 - acc: 0.7482 - val_loss: 0.5293 - val_acc: 0.7500\n",
            "Epoch 454/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5268 - acc: 0.7373 - val_loss: 0.5541 - val_acc: 0.6875\n",
            "Epoch 455/500\n",
            "80/80 [==============================] - 7s 81ms/step - loss: 0.4932 - acc: 0.7467 - val_loss: 0.5105 - val_acc: 0.6875\n",
            "Epoch 456/500\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 0.5431 - acc: 0.7318 - val_loss: 0.4516 - val_acc: 0.8125\n",
            "Epoch 457/500\n",
            "80/80 [==============================] - 6s 67ms/step - loss: 0.5157 - acc: 0.7459 - val_loss: 0.5351 - val_acc: 0.6250\n",
            "Epoch 458/500\n",
            "80/80 [==============================] - 8s 93ms/step - loss: 0.5293 - acc: 0.7389 - val_loss: 0.5217 - val_acc: 0.7500\n",
            "Epoch 459/500\n",
            "80/80 [==============================] - 6s 67ms/step - loss: 0.5125 - acc: 0.7420 - val_loss: 0.5715 - val_acc: 0.7500\n",
            "Epoch 460/500\n",
            "80/80 [==============================] - 7s 80ms/step - loss: 0.5456 - acc: 0.7287 - val_loss: 0.5510 - val_acc: 0.6250\n",
            "Epoch 461/500\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 0.5256 - acc: 0.7529 - val_loss: 0.5535 - val_acc: 0.7500\n",
            "Epoch 462/500\n",
            "80/80 [==============================] - 7s 72ms/step - loss: 0.5415 - acc: 0.7287 - val_loss: 0.5714 - val_acc: 0.6875\n",
            "Epoch 463/500\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.5309 - acc: 0.7373 - val_loss: 0.5753 - val_acc: 0.7500\n",
            "Epoch 464/500\n",
            "80/80 [==============================] - 7s 75ms/step - loss: 0.5476 - acc: 0.7271 - val_loss: 0.4584 - val_acc: 0.7500\n",
            "Epoch 465/500\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 0.4991 - acc: 0.7662 - val_loss: 0.5408 - val_acc: 0.6250\n",
            "Epoch 466/500\n",
            "80/80 [==============================] - 6s 75ms/step - loss: 0.5330 - acc: 0.7342 - val_loss: 0.5622 - val_acc: 0.6875\n",
            "Epoch 467/500\n",
            "80/80 [==============================] - 6s 69ms/step - loss: 0.5229 - acc: 0.7522 - val_loss: 0.4976 - val_acc: 0.8125\n",
            "Epoch 468/500\n",
            "80/80 [==============================] - 6s 67ms/step - loss: 0.5132 - acc: 0.7443 - val_loss: 0.5767 - val_acc: 0.7500\n",
            "Epoch 469/500\n",
            "80/80 [==============================] - 6s 74ms/step - loss: 0.5314 - acc: 0.7334 - val_loss: 0.4959 - val_acc: 0.8125\n",
            "Epoch 470/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5383 - acc: 0.7389 - val_loss: 0.4572 - val_acc: 0.8125\n",
            "Epoch 471/500\n",
            "80/80 [==============================] - 8s 84ms/step - loss: 0.5242 - acc: 0.7373 - val_loss: 0.5726 - val_acc: 0.7500\n",
            "Epoch 472/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5324 - acc: 0.7475 - val_loss: 0.5727 - val_acc: 0.6250\n",
            "Epoch 473/500\n",
            "80/80 [==============================] - 7s 77ms/step - loss: 0.5130 - acc: 0.7412 - val_loss: 0.5540 - val_acc: 0.7500\n",
            "Epoch 474/500\n",
            "80/80 [==============================] - 7s 76ms/step - loss: 0.5372 - acc: 0.7303 - val_loss: 0.5391 - val_acc: 0.6875\n",
            "Epoch 475/500\n",
            "80/80 [==============================] - 7s 75ms/step - loss: 0.5364 - acc: 0.7240 - val_loss: 0.5192 - val_acc: 0.6875\n",
            "Epoch 476/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5226 - acc: 0.7623 - val_loss: 0.5054 - val_acc: 0.6875\n",
            "Epoch 477/500\n",
            "80/80 [==============================] - 6s 75ms/step - loss: 0.5225 - acc: 0.7412 - val_loss: 0.5873 - val_acc: 0.7500\n",
            "Epoch 478/500\n",
            "80/80 [==============================] - 7s 76ms/step - loss: 0.5242 - acc: 0.7451 - val_loss: 0.4951 - val_acc: 0.8125\n",
            "Epoch 479/500\n",
            "80/80 [==============================] - 6s 74ms/step - loss: 0.5269 - acc: 0.7154 - val_loss: 0.5568 - val_acc: 0.7500\n",
            "Epoch 480/500\n",
            "80/80 [==============================] - 7s 76ms/step - loss: 0.4997 - acc: 0.7654 - val_loss: 0.4934 - val_acc: 0.8125\n",
            "Epoch 481/500\n",
            "80/80 [==============================] - 6s 70ms/step - loss: 0.4976 - acc: 0.7553 - val_loss: 0.5385 - val_acc: 0.7500\n",
            "Epoch 482/500\n",
            "80/80 [==============================] - 7s 77ms/step - loss: 0.5269 - acc: 0.7303 - val_loss: 0.5035 - val_acc: 0.7500\n",
            "Epoch 483/500\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.5342 - acc: 0.7342 - val_loss: 0.5506 - val_acc: 0.6250\n",
            "Epoch 484/500\n",
            "80/80 [==============================] - 6s 68ms/step - loss: 0.5574 - acc: 0.7170 - val_loss: 0.5745 - val_acc: 0.6250\n",
            "Epoch 485/500\n",
            "80/80 [==============================] - 7s 74ms/step - loss: 0.5484 - acc: 0.7318 - val_loss: 0.5367 - val_acc: 0.7500\n",
            "Epoch 486/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5211 - acc: 0.7318 - val_loss: 0.5685 - val_acc: 0.6875\n",
            "Epoch 487/500\n",
            "80/80 [==============================] - 7s 75ms/step - loss: 0.5255 - acc: 0.7412 - val_loss: 0.5648 - val_acc: 0.6250\n",
            "Epoch 488/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5343 - acc: 0.7334 - val_loss: 0.4751 - val_acc: 0.6875\n",
            "Epoch 489/500\n",
            "80/80 [==============================] - 6s 68ms/step - loss: 0.5177 - acc: 0.7412 - val_loss: 0.5574 - val_acc: 0.7500\n",
            "Epoch 490/500\n",
            "80/80 [==============================] - 7s 80ms/step - loss: 0.5375 - acc: 0.7342 - val_loss: 0.5317 - val_acc: 0.7500\n",
            "Epoch 491/500\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 0.5623 - acc: 0.7193 - val_loss: 0.5429 - val_acc: 0.6250\n",
            "Epoch 492/500\n",
            "80/80 [==============================] - 6s 74ms/step - loss: 0.5305 - acc: 0.7506 - val_loss: 0.5435 - val_acc: 0.6250\n",
            "Epoch 493/500\n",
            "80/80 [==============================] - 7s 76ms/step - loss: 0.5402 - acc: 0.7295 - val_loss: 0.5651 - val_acc: 0.7500\n",
            "Epoch 494/500\n",
            "80/80 [==============================] - 6s 66ms/step - loss: 0.5439 - acc: 0.7217 - val_loss: 0.4859 - val_acc: 0.8125\n",
            "Epoch 495/500\n",
            "80/80 [==============================] - 6s 64ms/step - loss: 0.5205 - acc: 0.7435 - val_loss: 0.5739 - val_acc: 0.7500\n",
            "Epoch 496/500\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.5235 - acc: 0.7349 - val_loss: 0.5553 - val_acc: 0.6250\n",
            "Epoch 497/500\n",
            "80/80 [==============================] - 6s 65ms/step - loss: 0.5228 - acc: 0.7404 - val_loss: 0.5447 - val_acc: 0.7500\n",
            "Epoch 498/500\n",
            "80/80 [==============================] - 6s 68ms/step - loss: 0.5436 - acc: 0.7303 - val_loss: 0.5568 - val_acc: 0.7500\n",
            "Epoch 499/500\n",
            "80/80 [==============================] - 7s 76ms/step - loss: 0.5363 - acc: 0.7217 - val_loss: 0.4804 - val_acc: 0.8125\n",
            "Epoch 500/500\n",
            "80/80 [==============================] - 6s 64ms/step - loss: 0.5135 - acc: 0.7342 - val_loss: 0.5542 - val_acc: 0.7500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.history "
      ],
      "metadata": {
        "id": "tO_KJFVJu6ya",
        "outputId": "f08424a4-8c4b-407b-8222-07b7bec25099",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': [1.558574914932251,\n",
              "  1.1510916948318481,\n",
              "  1.062542200088501,\n",
              "  1.0049537420272827,\n",
              "  0.9487552046775818,\n",
              "  0.9237923622131348,\n",
              "  0.9424390196800232,\n",
              "  0.8829545974731445,\n",
              "  0.9051701426506042,\n",
              "  0.8681670427322388,\n",
              "  0.8535597324371338,\n",
              "  0.824454665184021,\n",
              "  0.8155028820037842,\n",
              "  0.8034452199935913,\n",
              "  0.8144174218177795,\n",
              "  0.8098800182342529,\n",
              "  0.8067827224731445,\n",
              "  0.806530773639679,\n",
              "  0.777974545955658,\n",
              "  0.7815330624580383,\n",
              "  0.7694467306137085,\n",
              "  0.7606077194213867,\n",
              "  0.689023494720459,\n",
              "  0.7033942341804504,\n",
              "  0.7037861943244934,\n",
              "  0.7346742153167725,\n",
              "  0.7307907342910767,\n",
              "  0.6978158950805664,\n",
              "  0.721706748008728,\n",
              "  0.6797225475311279,\n",
              "  0.7318287491798401,\n",
              "  0.6802011132240295,\n",
              "  0.682533323764801,\n",
              "  0.6569083333015442,\n",
              "  0.6489475965499878,\n",
              "  0.6831706762313843,\n",
              "  0.6634790897369385,\n",
              "  0.6629824042320251,\n",
              "  0.6312472820281982,\n",
              "  0.6485118269920349,\n",
              "  0.679954469203949,\n",
              "  0.637125551700592,\n",
              "  0.6339923739433289,\n",
              "  0.6481484770774841,\n",
              "  0.6217369437217712,\n",
              "  0.6166282892227173,\n",
              "  0.6533235311508179,\n",
              "  0.618432879447937,\n",
              "  0.6005828380584717,\n",
              "  0.590459406375885,\n",
              "  0.5882688760757446,\n",
              "  0.6301751136779785,\n",
              "  0.6058419942855835,\n",
              "  0.6044608950614929,\n",
              "  0.6149805188179016,\n",
              "  0.5970413088798523,\n",
              "  0.5967276096343994,\n",
              "  0.5973638296127319,\n",
              "  0.6109931468963623,\n",
              "  0.5985970497131348,\n",
              "  0.5956180691719055,\n",
              "  0.59245765209198,\n",
              "  0.5901568531990051,\n",
              "  0.5934876799583435,\n",
              "  0.5925493240356445,\n",
              "  0.5942670106887817,\n",
              "  0.5780249834060669,\n",
              "  0.5864438414573669,\n",
              "  0.6080807447433472,\n",
              "  0.5788503885269165,\n",
              "  0.5864044427871704,\n",
              "  0.5708759427070618,\n",
              "  0.557428240776062,\n",
              "  0.564022958278656,\n",
              "  0.572409987449646,\n",
              "  0.5648733377456665,\n",
              "  0.5439226031303406,\n",
              "  0.5535449385643005,\n",
              "  0.5916852355003357,\n",
              "  0.558141827583313,\n",
              "  0.5454860925674438,\n",
              "  0.5760391354560852,\n",
              "  0.5745273232460022,\n",
              "  0.5510817766189575,\n",
              "  0.566723644733429,\n",
              "  0.5634697079658508,\n",
              "  0.5542077422142029,\n",
              "  0.5607852339744568,\n",
              "  0.5646305084228516,\n",
              "  0.5488461256027222,\n",
              "  0.5409621000289917,\n",
              "  0.5582331418991089,\n",
              "  0.5647542476654053,\n",
              "  0.5440275073051453,\n",
              "  0.5663639307022095,\n",
              "  0.5311933755874634,\n",
              "  0.5436811447143555,\n",
              "  0.5531373023986816,\n",
              "  0.5490831732749939,\n",
              "  0.5735785961151123,\n",
              "  0.5634576082229614,\n",
              "  0.5266384482383728,\n",
              "  0.5509759187698364,\n",
              "  0.53192138671875,\n",
              "  0.5593531727790833,\n",
              "  0.5433628559112549,\n",
              "  0.5307053327560425,\n",
              "  0.5399473905563354,\n",
              "  0.5412898063659668,\n",
              "  0.5600107908248901,\n",
              "  0.5349864959716797,\n",
              "  0.5495978593826294,\n",
              "  0.5609793066978455,\n",
              "  0.5529137253761292,\n",
              "  0.5560051798820496,\n",
              "  0.5418453216552734,\n",
              "  0.5302199125289917,\n",
              "  0.5550193786621094,\n",
              "  0.5300136208534241,\n",
              "  0.5559877157211304,\n",
              "  0.5276134014129639,\n",
              "  0.5305337309837341,\n",
              "  0.5445969700813293,\n",
              "  0.5479075312614441,\n",
              "  0.5238519310951233,\n",
              "  0.5429379940032959,\n",
              "  0.540317177772522,\n",
              "  0.5446339845657349,\n",
              "  0.5500527620315552,\n",
              "  0.5553374290466309,\n",
              "  0.5415563583374023,\n",
              "  0.532659113407135,\n",
              "  0.5456077456474304,\n",
              "  0.5367965698242188,\n",
              "  0.5275934338569641,\n",
              "  0.552732527256012,\n",
              "  0.5242367386817932,\n",
              "  0.5349933505058289,\n",
              "  0.5315058827400208,\n",
              "  0.540806770324707,\n",
              "  0.5426661372184753,\n",
              "  0.5339253544807434,\n",
              "  0.5189428329467773,\n",
              "  0.5137901306152344,\n",
              "  0.5384374260902405,\n",
              "  0.5460389852523804,\n",
              "  0.565572202205658,\n",
              "  0.5282984375953674,\n",
              "  0.5398744940757751,\n",
              "  0.5370756983757019,\n",
              "  0.531330943107605,\n",
              "  0.5420663952827454,\n",
              "  0.5178570747375488,\n",
              "  0.5456910133361816,\n",
              "  0.5435851216316223,\n",
              "  0.557220995426178,\n",
              "  0.521191418170929,\n",
              "  0.524664044380188,\n",
              "  0.5374049544334412,\n",
              "  0.5405087471008301,\n",
              "  0.5319661498069763,\n",
              "  0.5366417765617371,\n",
              "  0.5192334651947021,\n",
              "  0.5050340294837952,\n",
              "  0.53395676612854,\n",
              "  0.5107139945030212,\n",
              "  0.5507533550262451,\n",
              "  0.5375077724456787,\n",
              "  0.520677924156189,\n",
              "  0.5223013758659363,\n",
              "  0.5034786462783813,\n",
              "  0.5262837409973145,\n",
              "  0.5271415114402771,\n",
              "  0.5304449200630188,\n",
              "  0.5382430553436279,\n",
              "  0.5323342680931091,\n",
              "  0.5235414505004883,\n",
              "  0.536858081817627,\n",
              "  0.5282574892044067,\n",
              "  0.5250827074050903,\n",
              "  0.5388732552528381,\n",
              "  0.5394960641860962,\n",
              "  0.5190058946609497,\n",
              "  0.515682578086853,\n",
              "  0.5346729755401611,\n",
              "  0.5212084054946899,\n",
              "  0.5249976515769958,\n",
              "  0.5285877585411072,\n",
              "  0.5325952768325806,\n",
              "  0.5401664972305298,\n",
              "  0.5382518172264099,\n",
              "  0.5488750338554382,\n",
              "  0.5376932621002197,\n",
              "  0.5295088291168213,\n",
              "  0.5423750877380371,\n",
              "  0.5381870865821838,\n",
              "  0.5137892961502075,\n",
              "  0.5345285534858704,\n",
              "  0.5276320576667786,\n",
              "  0.5206515789031982,\n",
              "  0.5256748795509338,\n",
              "  0.5071002840995789,\n",
              "  0.5402910709381104,\n",
              "  0.5349869728088379,\n",
              "  0.521917462348938,\n",
              "  0.5443532466888428,\n",
              "  0.5329174399375916,\n",
              "  0.5381797552108765,\n",
              "  0.5596494078636169,\n",
              "  0.5352638959884644,\n",
              "  0.5332430601119995,\n",
              "  0.5339378714561462,\n",
              "  0.5228418111801147,\n",
              "  0.5479161739349365,\n",
              "  0.4951845705509186,\n",
              "  0.5427814722061157,\n",
              "  0.5350517630577087,\n",
              "  0.5340474247932434,\n",
              "  0.5173611044883728,\n",
              "  0.5147145390510559,\n",
              "  0.5333501100540161,\n",
              "  0.5246095061302185,\n",
              "  0.5612736940383911,\n",
              "  0.516268253326416,\n",
              "  0.5162572860717773,\n",
              "  0.5324667096138,\n",
              "  0.5322704911231995,\n",
              "  0.5322854518890381,\n",
              "  0.5383902788162231,\n",
              "  0.5286412835121155,\n",
              "  0.5159738659858704,\n",
              "  0.5190104842185974,\n",
              "  0.5243316292762756,\n",
              "  0.5169840455055237,\n",
              "  0.5281562209129333,\n",
              "  0.5286486148834229,\n",
              "  0.533982515335083,\n",
              "  0.5089957118034363,\n",
              "  0.5306106805801392,\n",
              "  0.5304483771324158,\n",
              "  0.5288134813308716,\n",
              "  0.5562129616737366,\n",
              "  0.5254939198493958,\n",
              "  0.5286006331443787,\n",
              "  0.5189359784126282,\n",
              "  0.5384589433670044,\n",
              "  0.541297435760498,\n",
              "  0.5164689421653748,\n",
              "  0.5176935195922852,\n",
              "  0.5336170792579651,\n",
              "  0.5140498280525208,\n",
              "  0.5387842655181885,\n",
              "  0.5283607244491577,\n",
              "  0.5345805883407593,\n",
              "  0.5005198121070862,\n",
              "  0.5137718915939331,\n",
              "  0.5107175707817078,\n",
              "  0.5219619870185852,\n",
              "  0.5066089034080505,\n",
              "  0.5449020266532898,\n",
              "  0.5405504107475281,\n",
              "  0.504167377948761,\n",
              "  0.5104263424873352,\n",
              "  0.5368878841400146,\n",
              "  0.5132611393928528,\n",
              "  0.5248894095420837,\n",
              "  0.5221077799797058,\n",
              "  0.54641193151474,\n",
              "  0.5254261493682861,\n",
              "  0.517170250415802,\n",
              "  0.5425132513046265,\n",
              "  0.520574688911438,\n",
              "  0.5263359546661377,\n",
              "  0.5269145369529724,\n",
              "  0.5278444290161133,\n",
              "  0.5299522876739502,\n",
              "  0.5280178785324097,\n",
              "  0.5319685935974121,\n",
              "  0.5279906392097473,\n",
              "  0.522668719291687,\n",
              "  0.509454607963562,\n",
              "  0.5379394888877869,\n",
              "  0.5144188404083252,\n",
              "  0.5445860028266907,\n",
              "  0.5294516682624817,\n",
              "  0.5195643901824951,\n",
              "  0.5140728950500488,\n",
              "  0.5046493411064148,\n",
              "  0.5317299962043762,\n",
              "  0.5350354909896851,\n",
              "  0.5275353789329529,\n",
              "  0.5273061394691467,\n",
              "  0.5307979583740234,\n",
              "  0.5288381576538086,\n",
              "  0.5217777490615845,\n",
              "  0.5301293134689331,\n",
              "  0.5343331098556519,\n",
              "  0.5269694924354553,\n",
              "  0.5294354557991028,\n",
              "  0.556553304195404,\n",
              "  0.5193704962730408,\n",
              "  0.5276059508323669,\n",
              "  0.5019345879554749,\n",
              "  0.5107612013816833,\n",
              "  0.5357181429862976,\n",
              "  0.522175669670105,\n",
              "  0.5281186699867249,\n",
              "  0.5110620260238647,\n",
              "  0.5322932004928589,\n",
              "  0.5289341807365417,\n",
              "  0.5264728665351868,\n",
              "  0.5248244404792786,\n",
              "  0.5199686884880066,\n",
              "  0.5369893908500671,\n",
              "  0.5304499268531799,\n",
              "  0.5457093715667725,\n",
              "  0.5144246816635132,\n",
              "  0.5426904559135437,\n",
              "  0.520224392414093,\n",
              "  0.5189420580863953,\n",
              "  0.5319792628288269,\n",
              "  0.5104719996452332,\n",
              "  0.5326066613197327,\n",
              "  0.540804922580719,\n",
              "  0.5363486409187317,\n",
              "  0.5330122113227844,\n",
              "  0.5415626764297485,\n",
              "  0.525483250617981,\n",
              "  0.537784218788147,\n",
              "  0.5167221426963806,\n",
              "  0.5289308428764343,\n",
              "  0.5280368328094482,\n",
              "  0.5213364958763123,\n",
              "  0.5289846658706665,\n",
              "  0.5391703248023987,\n",
              "  0.5150412321090698,\n",
              "  0.5401016473770142,\n",
              "  0.5276574492454529,\n",
              "  0.5084356665611267,\n",
              "  0.5319786667823792,\n",
              "  0.5072906017303467,\n",
              "  0.5151956677436829,\n",
              "  0.5030712485313416,\n",
              "  0.5484972596168518,\n",
              "  0.5366851091384888,\n",
              "  0.5348422527313232,\n",
              "  0.5237330198287964,\n",
              "  0.5172961950302124,\n",
              "  0.533317506313324,\n",
              "  0.5160033106803894,\n",
              "  0.5393984913825989,\n",
              "  0.5254639983177185,\n",
              "  0.5179217457771301,\n",
              "  0.5610576868057251,\n",
              "  0.5407330393791199,\n",
              "  0.5257222652435303,\n",
              "  0.5358730554580688,\n",
              "  0.515812873840332,\n",
              "  0.5338899493217468,\n",
              "  0.5263526439666748,\n",
              "  0.5293312668800354,\n",
              "  0.5136712789535522,\n",
              "  0.5442448854446411,\n",
              "  0.5246708393096924,\n",
              "  0.5186958909034729,\n",
              "  0.5202922821044922,\n",
              "  0.5350990295410156,\n",
              "  0.5153002142906189,\n",
              "  0.5399640202522278,\n",
              "  0.5424239039421082,\n",
              "  0.5273623466491699,\n",
              "  0.5205665826797485,\n",
              "  0.5285316705703735,\n",
              "  0.5164428353309631,\n",
              "  0.5130174160003662,\n",
              "  0.5458559989929199,\n",
              "  0.5219452977180481,\n",
              "  0.5243951678276062,\n",
              "  0.5406944751739502,\n",
              "  0.5263077020645142,\n",
              "  0.5527514219284058,\n",
              "  0.529312252998352,\n",
              "  0.5193453431129456,\n",
              "  0.5292431116104126,\n",
              "  0.5160536170005798,\n",
              "  0.5151748657226562,\n",
              "  0.5288817882537842,\n",
              "  0.5095551013946533,\n",
              "  0.5241564512252808,\n",
              "  0.5260376930236816,\n",
              "  0.5066825747489929,\n",
              "  0.5485678911209106,\n",
              "  0.5306637287139893,\n",
              "  0.5049872398376465,\n",
              "  0.5188326239585876,\n",
              "  0.5346511006355286,\n",
              "  0.5171623826026917,\n",
              "  0.5194525718688965,\n",
              "  0.522055447101593,\n",
              "  0.5257915258407593,\n",
              "  0.4892720878124237,\n",
              "  0.5321628451347351,\n",
              "  0.5400592684745789,\n",
              "  0.5183592438697815,\n",
              "  0.5307369232177734,\n",
              "  0.5092852711677551,\n",
              "  0.5314105749130249,\n",
              "  0.5282989740371704,\n",
              "  0.5485041737556458,\n",
              "  0.5233569741249084,\n",
              "  0.5341382622718811,\n",
              "  0.5167820453643799,\n",
              "  0.5256769061088562,\n",
              "  0.530290424823761,\n",
              "  0.5282896161079407,\n",
              "  0.5340104103088379,\n",
              "  0.5416224598884583,\n",
              "  0.5028504133224487,\n",
              "  0.5185737013816833,\n",
              "  0.536007821559906,\n",
              "  0.5259431600570679,\n",
              "  0.5154712796211243,\n",
              "  0.5383066534996033,\n",
              "  0.5391159653663635,\n",
              "  0.5236600041389465,\n",
              "  0.5400317907333374,\n",
              "  0.5098662972450256,\n",
              "  0.5281038880348206,\n",
              "  0.5624816417694092,\n",
              "  0.5222266316413879,\n",
              "  0.5141469836235046,\n",
              "  0.5193840861320496,\n",
              "  0.5355099439620972,\n",
              "  0.5054196119308472,\n",
              "  0.5269913077354431,\n",
              "  0.519852876663208,\n",
              "  0.525843620300293,\n",
              "  0.5366408228874207,\n",
              "  0.5357741713523865,\n",
              "  0.5126847624778748,\n",
              "  0.5254548788070679,\n",
              "  0.5501912832260132,\n",
              "  0.5204437971115112,\n",
              "  0.509361982345581,\n",
              "  0.4957708716392517,\n",
              "  0.528873860836029,\n",
              "  0.5196630954742432,\n",
              "  0.5303367376327515,\n",
              "  0.5223778486251831,\n",
              "  0.5322675108909607,\n",
              "  0.5229641795158386,\n",
              "  0.5591554641723633,\n",
              "  0.5096938014030457,\n",
              "  0.526840090751648,\n",
              "  0.49321556091308594,\n",
              "  0.5430518984794617,\n",
              "  0.5157466530799866,\n",
              "  0.5293223857879639,\n",
              "  0.512486457824707,\n",
              "  0.5456256866455078,\n",
              "  0.5255918502807617,\n",
              "  0.541473388671875,\n",
              "  0.5308961272239685,\n",
              "  0.5475514531135559,\n",
              "  0.499072790145874,\n",
              "  0.5330162048339844,\n",
              "  0.5229049324989319,\n",
              "  0.5131899118423462,\n",
              "  0.5314238667488098,\n",
              "  0.5382913947105408,\n",
              "  0.5242316126823425,\n",
              "  0.5324025750160217,\n",
              "  0.5130034685134888,\n",
              "  0.537161648273468,\n",
              "  0.5364134311676025,\n",
              "  0.5225690603256226,\n",
              "  0.5225425362586975,\n",
              "  0.5241645574569702,\n",
              "  0.5268697142601013,\n",
              "  0.499661386013031,\n",
              "  0.4976261258125305,\n",
              "  0.5269320607185364,\n",
              "  0.5341718792915344,\n",
              "  0.5573679208755493,\n",
              "  0.5483671426773071,\n",
              "  0.5210803151130676,\n",
              "  0.5254939198493958,\n",
              "  0.5343277454376221,\n",
              "  0.5176926255226135,\n",
              "  0.5375171303749084,\n",
              "  0.5623235702514648,\n",
              "  0.5305202007293701,\n",
              "  0.5401930212974548,\n",
              "  0.5439494848251343,\n",
              "  0.5205016732215881,\n",
              "  0.5234567523002625,\n",
              "  0.5227550864219666,\n",
              "  0.543648362159729,\n",
              "  0.5363130569458008,\n",
              "  0.513525128364563],\n",
              " 'acc': [0.475371390581131,\n",
              "  0.5066457986831665,\n",
              "  0.5207192897796631,\n",
              "  0.5473026037216187,\n",
              "  0.5910868048667908,\n",
              "  0.5801407098770142,\n",
              "  0.5574667453765869,\n",
              "  0.6082877516746521,\n",
              "  0.5746676921844482,\n",
              "  0.5918686389923096,\n",
              "  0.6028146743774414,\n",
              "  0.6247068047523499,\n",
              "  0.6325253844261169,\n",
              "  0.6161063313484192,\n",
              "  0.6114151477813721,\n",
              "  0.6254886388778687,\n",
              "  0.6184518933296204,\n",
              "  0.6106333136558533,\n",
              "  0.6325253844261169,\n",
              "  0.6207975149154663,\n",
              "  0.623924970626831,\n",
              "  0.6364347338676453,\n",
              "  0.6575449705123901,\n",
              "  0.6481626033782959,\n",
              "  0.6403440237045288,\n",
              "  0.627052366733551,\n",
              "  0.6512900590896606,\n",
              "  0.6591086983680725,\n",
              "  0.6473807692527771,\n",
              "  0.6598905324935913,\n",
              "  0.6286160945892334,\n",
              "  0.6520719528198242,\n",
              "  0.6559812426567078,\n",
              "  0.678655207157135,\n",
              "  0.6770914793014526,\n",
              "  0.6489444971084595,\n",
              "  0.6544175148010254,\n",
              "  0.652853786945343,\n",
              "  0.6778733134269714,\n",
              "  0.6653635501861572,\n",
              "  0.6450352072715759,\n",
              "  0.6864737868309021,\n",
              "  0.6810007691383362,\n",
              "  0.6669272780418396,\n",
              "  0.6849100589752197,\n",
              "  0.6880375146865845,\n",
              "  0.6614542603492737,\n",
              "  0.6825644969940186,\n",
              "  0.6935105323791504,\n",
              "  0.6903831362724304,\n",
              "  0.6989836096763611,\n",
              "  0.6724002957344055,\n",
              "  0.6841282248497009,\n",
              "  0.6849100589752197,\n",
              "  0.6849100589752197,\n",
              "  0.6896012425422668,\n",
              "  0.6935105323791504,\n",
              "  0.7028928995132446,\n",
              "  0.6817826628684998,\n",
              "  0.6950742602348328,\n",
              "  0.6778733134269714,\n",
              "  0.6950742602348328,\n",
              "  0.7036747336387634,\n",
              "  0.6896012425422668,\n",
              "  0.7091477513313293,\n",
              "  0.6864737868309021,\n",
              "  0.7083659172058105,\n",
              "  0.6872556805610657,\n",
              "  0.6833463907241821,\n",
              "  0.7169663906097412,\n",
              "  0.7068021893501282,\n",
              "  0.7130571007728577,\n",
              "  0.7146207690238953,\n",
              "  0.7146207690238953,\n",
              "  0.707584023475647,\n",
              "  0.7036747336387634,\n",
              "  0.7294761538505554,\n",
              "  0.7240031361579895,\n",
              "  0.694292426109314,\n",
              "  0.7130571007728577,\n",
              "  0.7263486981391907,\n",
              "  0.707584023475647,\n",
              "  0.7005472779273987,\n",
              "  0.7193119525909424,\n",
              "  0.7091477513313293,\n",
              "  0.6997654438018799,\n",
              "  0.7138389348983765,\n",
              "  0.7146207690238953,\n",
              "  0.6958561539649963,\n",
              "  0.7154026627540588,\n",
              "  0.727912425994873,\n",
              "  0.7247849702835083,\n",
              "  0.7114933729171753,\n",
              "  0.7294761538505554,\n",
              "  0.7099296450614929,\n",
              "  0.7208756804466248,\n",
              "  0.7255668640136719,\n",
              "  0.7240031361579895,\n",
              "  0.7193119525909424,\n",
              "  0.7060203552246094,\n",
              "  0.694292426109314,\n",
              "  0.7396403551101685,\n",
              "  0.7232212424278259,\n",
              "  0.7286943197250366,\n",
              "  0.7036747336387634,\n",
              "  0.7224394083023071,\n",
              "  0.7498045563697815,\n",
              "  0.7310398817062378,\n",
              "  0.7318217158317566,\n",
              "  0.7114933729171753,\n",
              "  0.7349491715431213,\n",
              "  0.7326036095619202,\n",
              "  0.7161844968795776,\n",
              "  0.7130571007728577,\n",
              "  0.7122752070426941,\n",
              "  0.7216575741767883,\n",
              "  0.7240031361579895,\n",
              "  0.7193119525909424,\n",
              "  0.7380766272544861,\n",
              "  0.7240031361579895,\n",
              "  0.7326036095619202,\n",
              "  0.7318217158317566,\n",
              "  0.7263486981391907,\n",
              "  0.7349491715431213,\n",
              "  0.7247849702835083,\n",
              "  0.7247849702835083,\n",
              "  0.7263486981391907,\n",
              "  0.7318217158317566,\n",
              "  0.7138389348983765,\n",
              "  0.727912425994873,\n",
              "  0.7286943197250366,\n",
              "  0.7365128993988037,\n",
              "  0.7161844968795776,\n",
              "  0.7232212424278259,\n",
              "  0.7372947335243225,\n",
              "  0.7130571007728577,\n",
              "  0.7388584613800049,\n",
              "  0.720093846321106,\n",
              "  0.7310398817062378,\n",
              "  0.7263486981391907,\n",
              "  0.733385443687439,\n",
              "  0.733385443687439,\n",
              "  0.7388584613800049,\n",
              "  0.7310398817062378,\n",
              "  0.7185301184654236,\n",
              "  0.7247849702835083,\n",
              "  0.7224394083023071,\n",
              "  0.7396403551101685,\n",
              "  0.7302579879760742,\n",
              "  0.7365128993988037,\n",
              "  0.7357310652732849,\n",
              "  0.7138389348983765,\n",
              "  0.7544956803321838,\n",
              "  0.7208756804466248,\n",
              "  0.7349491715431213,\n",
              "  0.7185301184654236,\n",
              "  0.7310398817062378,\n",
              "  0.7419859170913696,\n",
              "  0.7404221892356873,\n",
              "  0.7286943197250366,\n",
              "  0.7255668640136719,\n",
              "  0.7412040829658508,\n",
              "  0.7357310652732849,\n",
              "  0.7490226626396179,\n",
              "  0.7365128993988037,\n",
              "  0.753713846206665,\n",
              "  0.7271305918693542,\n",
              "  0.7161844968795776,\n",
              "  0.7294761538505554,\n",
              "  0.743549644947052,\n",
              "  0.7451133728027344,\n",
              "  0.7544956803321838,\n",
              "  0.7138389348983765,\n",
              "  0.7388584613800049,\n",
              "  0.7247849702835083,\n",
              "  0.720093846321106,\n",
              "  0.7474589347839355,\n",
              "  0.7294761538505554,\n",
              "  0.7286943197250366,\n",
              "  0.7185301184654236,\n",
              "  0.7247849702835083,\n",
              "  0.7388584613800049,\n",
              "  0.7419859170913696,\n",
              "  0.7388584613800049,\n",
              "  0.7380766272544861,\n",
              "  0.7310398817062378,\n",
              "  0.7271305918693542,\n",
              "  0.7529319524765015,\n",
              "  0.7388584613800049,\n",
              "  0.7232212424278259,\n",
              "  0.7247849702835083,\n",
              "  0.7169663906097412,\n",
              "  0.7122752070426941,\n",
              "  0.7404221892356873,\n",
              "  0.71774822473526,\n",
              "  0.7232212424278259,\n",
              "  0.727912425994873,\n",
              "  0.7451133728027344,\n",
              "  0.7357310652732849,\n",
              "  0.7412040829658508,\n",
              "  0.7208756804466248,\n",
              "  0.7685691714286804,\n",
              "  0.7286943197250366,\n",
              "  0.7412040829658508,\n",
              "  0.7310398817062378,\n",
              "  0.7232212424278259,\n",
              "  0.7498045563697815,\n",
              "  0.7412040829658508,\n",
              "  0.7091477513313293,\n",
              "  0.7224394083023071,\n",
              "  0.7341673374176025,\n",
              "  0.7310398817062378,\n",
              "  0.7216575741767883,\n",
              "  0.7294761538505554,\n",
              "  0.7544956803321838,\n",
              "  0.71774822473526,\n",
              "  0.7247849702835083,\n",
              "  0.7247849702835083,\n",
              "  0.7498045563697815,\n",
              "  0.7380766272544861,\n",
              "  0.7458952069282532,\n",
              "  0.7341673374176025,\n",
              "  0.707584023475647,\n",
              "  0.7427678108215332,\n",
              "  0.743549644947052,\n",
              "  0.7380766272544861,\n",
              "  0.7263486981391907,\n",
              "  0.7380766272544861,\n",
              "  0.7161844968795776,\n",
              "  0.7365128993988037,\n",
              "  0.7521501183509827,\n",
              "  0.7427678108215332,\n",
              "  0.7513682842254639,\n",
              "  0.7521501183509827,\n",
              "  0.7474589347839355,\n",
              "  0.733385443687439,\n",
              "  0.7271305918693542,\n",
              "  0.7458952069282532,\n",
              "  0.7365128993988037,\n",
              "  0.727912425994873,\n",
              "  0.7318217158317566,\n",
              "  0.7208756804466248,\n",
              "  0.7310398817062378,\n",
              "  0.7357310652732849,\n",
              "  0.7357310652732849,\n",
              "  0.7357310652732849,\n",
              "  0.733385443687439,\n",
              "  0.743549644947052,\n",
              "  0.7412040829658508,\n",
              "  0.7326036095619202,\n",
              "  0.7412040829658508,\n",
              "  0.7247849702835083,\n",
              "  0.7412040829658508,\n",
              "  0.7302579879760742,\n",
              "  0.7584050297737122,\n",
              "  0.7326036095619202,\n",
              "  0.7521501183509827,\n",
              "  0.7458952069282532,\n",
              "  0.7451133728027344,\n",
              "  0.7365128993988037,\n",
              "  0.7216575741767883,\n",
              "  0.7451133728027344,\n",
              "  0.7490226626396179,\n",
              "  0.7255668640136719,\n",
              "  0.7419859170913696,\n",
              "  0.7630961537361145,\n",
              "  0.743549644947052,\n",
              "  0.720093846321106,\n",
              "  0.7388584613800049,\n",
              "  0.7560594081878662,\n",
              "  0.7154026627540588,\n",
              "  0.7271305918693542,\n",
              "  0.7326036095619202,\n",
              "  0.7263486981391907,\n",
              "  0.7349491715431213,\n",
              "  0.7247849702835083,\n",
              "  0.7255668640136719,\n",
              "  0.7388584613800049,\n",
              "  0.733385443687439,\n",
              "  0.7466771006584167,\n",
              "  0.7482408285140991,\n",
              "  0.7216575741767883,\n",
              "  0.733385443687439,\n",
              "  0.7302579879760742,\n",
              "  0.7498045563697815,\n",
              "  0.7474589347839355,\n",
              "  0.7427678108215332,\n",
              "  0.7544956803321838,\n",
              "  0.727912425994873,\n",
              "  0.7294761538505554,\n",
              "  0.7396403551101685,\n",
              "  0.7310398817062378,\n",
              "  0.7286943197250366,\n",
              "  0.7263486981391907,\n",
              "  0.7427678108215332,\n",
              "  0.7294761538505554,\n",
              "  0.7310398817062378,\n",
              "  0.7294761538505554,\n",
              "  0.7372947335243225,\n",
              "  0.7193119525909424,\n",
              "  0.7396403551101685,\n",
              "  0.7380766272544861,\n",
              "  0.7513682842254639,\n",
              "  0.759186863899231,\n",
              "  0.7498045563697815,\n",
              "  0.7263486981391907,\n",
              "  0.733385443687439,\n",
              "  0.743549644947052,\n",
              "  0.7396403551101685,\n",
              "  0.7365128993988037,\n",
              "  0.7380766272544861,\n",
              "  0.7466771006584167,\n",
              "  0.7505863904953003,\n",
              "  0.7302579879760742,\n",
              "  0.7584050297737122,\n",
              "  0.7294761538505554,\n",
              "  0.7529319524765015,\n",
              "  0.7326036095619202,\n",
              "  0.7482408285140991,\n",
              "  0.7466771006584167,\n",
              "  0.7302579879760742,\n",
              "  0.7607505917549133,\n",
              "  0.7372947335243225,\n",
              "  0.7216575741767883,\n",
              "  0.7169663906097412,\n",
              "  0.7380766272544861,\n",
              "  0.7318217158317566,\n",
              "  0.7412040829658508,\n",
              "  0.7318217158317566,\n",
              "  0.753713846206665,\n",
              "  0.7318217158317566,\n",
              "  0.7310398817062378,\n",
              "  0.7365128993988037,\n",
              "  0.7365128993988037,\n",
              "  0.7224394083023071,\n",
              "  0.727912425994873,\n",
              "  0.7208756804466248,\n",
              "  0.7286943197250366,\n",
              "  0.7544956803321838,\n",
              "  0.7419859170913696,\n",
              "  0.7427678108215332,\n",
              "  0.7466771006584167,\n",
              "  0.7505863904953003,\n",
              "  0.7318217158317566,\n",
              "  0.7286943197250366,\n",
              "  0.7357310652732849,\n",
              "  0.7412040829658508,\n",
              "  0.7474589347839355,\n",
              "  0.7357310652732849,\n",
              "  0.7490226626396179,\n",
              "  0.733385443687439,\n",
              "  0.7310398817062378,\n",
              "  0.7380766272544861,\n",
              "  0.7185301184654236,\n",
              "  0.7263486981391907,\n",
              "  0.7396403551101685,\n",
              "  0.727912425994873,\n",
              "  0.7443315386772156,\n",
              "  0.7310398817062378,\n",
              "  0.7380766272544861,\n",
              "  0.7458952069282532,\n",
              "  0.7505863904953003,\n",
              "  0.7365128993988037,\n",
              "  0.7357310652732849,\n",
              "  0.7513682842254639,\n",
              "  0.7372947335243225,\n",
              "  0.7310398817062378,\n",
              "  0.7427678108215332,\n",
              "  0.743549644947052,\n",
              "  0.7263486981391907,\n",
              "  0.7349491715431213,\n",
              "  0.7458952069282532,\n",
              "  0.7286943197250366,\n",
              "  0.7412040829658508,\n",
              "  0.7427678108215332,\n",
              "  0.7310398817062378,\n",
              "  0.7513682842254639,\n",
              "  0.7419859170913696,\n",
              "  0.7302579879760742,\n",
              "  0.7263486981391907,\n",
              "  0.7193119525909424,\n",
              "  0.7357310652732849,\n",
              "  0.7349491715431213,\n",
              "  0.7286943197250366,\n",
              "  0.7466771006584167,\n",
              "  0.7482408285140991,\n",
              "  0.753713846206665,\n",
              "  0.7419859170913696,\n",
              "  0.7365128993988037,\n",
              "  0.7365128993988037,\n",
              "  0.7349491715431213,\n",
              "  0.7130571007728577,\n",
              "  0.7318217158317566,\n",
              "  0.7638780474662781,\n",
              "  0.7365128993988037,\n",
              "  0.7318217158317566,\n",
              "  0.743549644947052,\n",
              "  0.7326036095619202,\n",
              "  0.753713846206665,\n",
              "  0.7388584613800049,\n",
              "  0.7568413019180298,\n",
              "  0.7318217158317566,\n",
              "  0.7247849702835083,\n",
              "  0.7419859170913696,\n",
              "  0.7357310652732849,\n",
              "  0.7412040829658508,\n",
              "  0.7310398817062378,\n",
              "  0.7365128993988037,\n",
              "  0.7216575741767883,\n",
              "  0.7498045563697815,\n",
              "  0.7372947335243225,\n",
              "  0.7544956803321838,\n",
              "  0.7388584613800049,\n",
              "  0.7318217158317566,\n",
              "  0.7412040829658508,\n",
              "  0.7466771006584167,\n",
              "  0.7294761538505554,\n",
              "  0.7498045563697815,\n",
              "  0.7404221892356873,\n",
              "  0.7365128993988037,\n",
              "  0.7443315386772156,\n",
              "  0.7365128993988037,\n",
              "  0.7271305918693542,\n",
              "  0.733385443687439,\n",
              "  0.7302579879760742,\n",
              "  0.7372947335243225,\n",
              "  0.7419859170913696,\n",
              "  0.7224394083023071,\n",
              "  0.7036747336387634,\n",
              "  0.7396403551101685,\n",
              "  0.7544956803321838,\n",
              "  0.7357310652732849,\n",
              "  0.7404221892356873,\n",
              "  0.7372947335243225,\n",
              "  0.7513682842254639,\n",
              "  0.7357310652732849,\n",
              "  0.7458952069282532,\n",
              "  0.7490226626396179,\n",
              "  0.743549644947052,\n",
              "  0.7498045563697815,\n",
              "  0.7341673374176025,\n",
              "  0.7255668640136719,\n",
              "  0.7412040829658508,\n",
              "  0.7615324258804321,\n",
              "  0.7505863904953003,\n",
              "  0.7357310652732849,\n",
              "  0.7349491715431213,\n",
              "  0.7458952069282532,\n",
              "  0.743549644947052,\n",
              "  0.7208756804466248,\n",
              "  0.7458952069282532,\n",
              "  0.7341673374176025,\n",
              "  0.7482408285140991,\n",
              "  0.7372947335243225,\n",
              "  0.7466771006584167,\n",
              "  0.7318217158317566,\n",
              "  0.7458952069282532,\n",
              "  0.7388584613800049,\n",
              "  0.7419859170913696,\n",
              "  0.7286943197250366,\n",
              "  0.7529319524765015,\n",
              "  0.7286943197250366,\n",
              "  0.7372947335243225,\n",
              "  0.7271305918693542,\n",
              "  0.7662236094474792,\n",
              "  0.7341673374176025,\n",
              "  0.7521501183509827,\n",
              "  0.7443315386772156,\n",
              "  0.733385443687439,\n",
              "  0.7388584613800049,\n",
              "  0.7372947335243225,\n",
              "  0.7474589347839355,\n",
              "  0.7412040829658508,\n",
              "  0.7302579879760742,\n",
              "  0.7240031361579895,\n",
              "  0.7623143196105957,\n",
              "  0.7412040829658508,\n",
              "  0.7451133728027344,\n",
              "  0.7154026627540588,\n",
              "  0.7654417753219604,\n",
              "  0.7552775740623474,\n",
              "  0.7302579879760742,\n",
              "  0.7341673374176025,\n",
              "  0.7169663906097412,\n",
              "  0.7318217158317566,\n",
              "  0.7318217158317566,\n",
              "  0.7412040829658508,\n",
              "  0.733385443687439,\n",
              "  0.7412040829658508,\n",
              "  0.7341673374176025,\n",
              "  0.7193119525909424,\n",
              "  0.7505863904953003,\n",
              "  0.7294761538505554,\n",
              "  0.7216575741767883,\n",
              "  0.743549644947052,\n",
              "  0.7349491715431213,\n",
              "  0.7404221892356873,\n",
              "  0.7302579879760742,\n",
              "  0.7216575741767883,\n",
              "  0.7341673374176025],\n",
              " 'val_loss': [0.9900650978088379,\n",
              "  1.025145411491394,\n",
              "  0.9623873233795166,\n",
              "  0.9793043732643127,\n",
              "  0.9445160031318665,\n",
              "  1.0099570751190186,\n",
              "  0.9012845754623413,\n",
              "  0.905135989189148,\n",
              "  0.8735742568969727,\n",
              "  0.9224803447723389,\n",
              "  0.8983070850372314,\n",
              "  0.8617463111877441,\n",
              "  0.8251398205757141,\n",
              "  0.8328135013580322,\n",
              "  0.8171502351760864,\n",
              "  0.8271231055259705,\n",
              "  0.8115808367729187,\n",
              "  0.8361632823944092,\n",
              "  0.7946942448616028,\n",
              "  0.8202285766601562,\n",
              "  0.758953869342804,\n",
              "  0.7519203424453735,\n",
              "  0.7621008157730103,\n",
              "  0.6547179222106934,\n",
              "  0.7564280033111572,\n",
              "  0.7454954385757446,\n",
              "  0.681474506855011,\n",
              "  0.6579809188842773,\n",
              "  0.7401856780052185,\n",
              "  0.6770607233047485,\n",
              "  0.658139169216156,\n",
              "  0.6115360856056213,\n",
              "  0.6856791973114014,\n",
              "  0.6305131316184998,\n",
              "  0.6358590126037598,\n",
              "  0.692933201789856,\n",
              "  0.6906230449676514,\n",
              "  0.615890383720398,\n",
              "  0.6880493760108948,\n",
              "  0.6235933303833008,\n",
              "  0.6912596225738525,\n",
              "  0.6294896006584167,\n",
              "  0.6804936528205872,\n",
              "  0.618482768535614,\n",
              "  0.5598965883255005,\n",
              "  0.6332325339317322,\n",
              "  0.6611020565032959,\n",
              "  0.5823239088058472,\n",
              "  0.6089816093444824,\n",
              "  0.6200817823410034,\n",
              "  0.6464570760726929,\n",
              "  0.6488621830940247,\n",
              "  0.5261785387992859,\n",
              "  0.6562303304672241,\n",
              "  0.5254279375076294,\n",
              "  0.6439043879508972,\n",
              "  0.6408718824386597,\n",
              "  0.5660525560379028,\n",
              "  0.5526562929153442,\n",
              "  0.5403617024421692,\n",
              "  0.6017887592315674,\n",
              "  0.5264754295349121,\n",
              "  0.550342321395874,\n",
              "  0.6328303813934326,\n",
              "  0.624496579170227,\n",
              "  0.6510075330734253,\n",
              "  0.6440807580947876,\n",
              "  0.6524860262870789,\n",
              "  0.619439959526062,\n",
              "  0.6232201457023621,\n",
              "  0.6376272439956665,\n",
              "  0.594088613986969,\n",
              "  0.6269621253013611,\n",
              "  0.6009883880615234,\n",
              "  0.5047421455383301,\n",
              "  0.629182755947113,\n",
              "  0.5482051968574524,\n",
              "  0.6043328046798706,\n",
              "  0.5945526361465454,\n",
              "  0.575059175491333,\n",
              "  0.5915434956550598,\n",
              "  0.5920987129211426,\n",
              "  0.6015657186508179,\n",
              "  0.5914934873580933,\n",
              "  0.6065199971199036,\n",
              "  0.5481682419776917,\n",
              "  0.5582230091094971,\n",
              "  0.6010224223136902,\n",
              "  0.6198488473892212,\n",
              "  0.5524049997329712,\n",
              "  0.6149539351463318,\n",
              "  0.5656404495239258,\n",
              "  0.5298107862472534,\n",
              "  0.6088416576385498,\n",
              "  0.5094535946846008,\n",
              "  0.4889240264892578,\n",
              "  0.5690366625785828,\n",
              "  0.5892854928970337,\n",
              "  0.5812591314315796,\n",
              "  0.5089719891548157,\n",
              "  0.5514273643493652,\n",
              "  0.5735899806022644,\n",
              "  0.5133759379386902,\n",
              "  0.630273699760437,\n",
              "  0.6243574619293213,\n",
              "  0.5709247589111328,\n",
              "  0.6243883371353149,\n",
              "  0.5902512669563293,\n",
              "  0.5672475695610046,\n",
              "  0.6079675555229187,\n",
              "  0.6092381477355957,\n",
              "  0.5847280025482178,\n",
              "  0.5451000332832336,\n",
              "  0.5509755611419678,\n",
              "  0.48965218663215637,\n",
              "  0.5767179131507874,\n",
              "  0.5480790734291077,\n",
              "  0.5493029952049255,\n",
              "  0.6006772518157959,\n",
              "  0.6224092841148376,\n",
              "  0.6304157972335815,\n",
              "  0.5835477113723755,\n",
              "  0.6234579086303711,\n",
              "  0.6078370809555054,\n",
              "  0.589486300945282,\n",
              "  0.6076618432998657,\n",
              "  0.5894747972488403,\n",
              "  0.49139121174812317,\n",
              "  0.5282039642333984,\n",
              "  0.5965710282325745,\n",
              "  0.6021022796630859,\n",
              "  0.4865671396255493,\n",
              "  0.5234172940254211,\n",
              "  0.532654881477356,\n",
              "  0.5607854127883911,\n",
              "  0.5940326452255249,\n",
              "  0.5807563066482544,\n",
              "  0.5542858839035034,\n",
              "  0.6068122386932373,\n",
              "  0.573339581489563,\n",
              "  0.5525410771369934,\n",
              "  0.47101736068725586,\n",
              "  0.5556848645210266,\n",
              "  0.5577244162559509,\n",
              "  0.5531739592552185,\n",
              "  0.5253106951713562,\n",
              "  0.5387576818466187,\n",
              "  0.5683311223983765,\n",
              "  0.5073405504226685,\n",
              "  0.4932357668876648,\n",
              "  0.5375323295593262,\n",
              "  0.5023031830787659,\n",
              "  0.5410376787185669,\n",
              "  0.550527036190033,\n",
              "  0.5081580877304077,\n",
              "  0.5354729890823364,\n",
              "  0.5104073882102966,\n",
              "  0.5677717924118042,\n",
              "  0.5722566843032837,\n",
              "  0.5637377500534058,\n",
              "  0.5264160633087158,\n",
              "  0.5120285153388977,\n",
              "  0.5496363043785095,\n",
              "  0.4943849742412567,\n",
              "  0.562157154083252,\n",
              "  0.5616390109062195,\n",
              "  0.5093967914581299,\n",
              "  0.5853161811828613,\n",
              "  0.5527135133743286,\n",
              "  0.5635805130004883,\n",
              "  0.5621556043624878,\n",
              "  0.5410737991333008,\n",
              "  0.5498913526535034,\n",
              "  0.5923911929130554,\n",
              "  0.5945577025413513,\n",
              "  0.5799710750579834,\n",
              "  0.5932734608650208,\n",
              "  0.5919417142868042,\n",
              "  0.5533662438392639,\n",
              "  0.5328106880187988,\n",
              "  0.5389046669006348,\n",
              "  0.5716788172721863,\n",
              "  0.5152343511581421,\n",
              "  0.572770893573761,\n",
              "  0.5346649289131165,\n",
              "  0.4745122194290161,\n",
              "  0.551457405090332,\n",
              "  0.5635620355606079,\n",
              "  0.5356931686401367,\n",
              "  0.5647031664848328,\n",
              "  0.5871045589447021,\n",
              "  0.537153959274292,\n",
              "  0.5264317989349365,\n",
              "  0.5841734409332275,\n",
              "  0.5502796173095703,\n",
              "  0.5851670503616333,\n",
              "  0.5195144414901733,\n",
              "  0.569915771484375,\n",
              "  0.5766178369522095,\n",
              "  0.5716772079467773,\n",
              "  0.5205026268959045,\n",
              "  0.5756223797798157,\n",
              "  0.5753016471862793,\n",
              "  0.5866124629974365,\n",
              "  0.5812462568283081,\n",
              "  0.4718160629272461,\n",
              "  0.5799852013587952,\n",
              "  0.5906585454940796,\n",
              "  0.5115494728088379,\n",
              "  0.58599853515625,\n",
              "  0.5574675798416138,\n",
              "  0.4803833067417145,\n",
              "  0.5540677905082703,\n",
              "  0.4709147810935974,\n",
              "  0.5202664136886597,\n",
              "  0.5480742454528809,\n",
              "  0.5838832259178162,\n",
              "  0.5090214014053345,\n",
              "  0.5403012037277222,\n",
              "  0.5562175512313843,\n",
              "  0.5518040657043457,\n",
              "  0.5689534544944763,\n",
              "  0.5595728158950806,\n",
              "  0.5397024154663086,\n",
              "  0.5144341588020325,\n",
              "  0.5001834034919739,\n",
              "  0.5175444483757019,\n",
              "  0.49982190132141113,\n",
              "  0.5034999251365662,\n",
              "  0.5477369427680969,\n",
              "  0.5278388857841492,\n",
              "  0.5126696228981018,\n",
              "  0.5304813385009766,\n",
              "  0.5181487798690796,\n",
              "  0.5152660608291626,\n",
              "  0.5470948219299316,\n",
              "  0.5606927871704102,\n",
              "  0.5655547380447388,\n",
              "  0.5674201250076294,\n",
              "  0.5791851282119751,\n",
              "  0.5119471549987793,\n",
              "  0.5692784786224365,\n",
              "  0.548190712928772,\n",
              "  0.5232160091400146,\n",
              "  0.5107632875442505,\n",
              "  0.5232352018356323,\n",
              "  0.5060054063796997,\n",
              "  0.5666277408599854,\n",
              "  0.5148329138755798,\n",
              "  0.44914817810058594,\n",
              "  0.5629734992980957,\n",
              "  0.5886002779006958,\n",
              "  0.5672446489334106,\n",
              "  0.5325107574462891,\n",
              "  0.561570942401886,\n",
              "  0.5920114517211914,\n",
              "  0.5751070976257324,\n",
              "  0.5663338899612427,\n",
              "  0.4665360748767853,\n",
              "  0.5000896453857422,\n",
              "  0.5599150657653809,\n",
              "  0.5635963678359985,\n",
              "  0.4894960820674896,\n",
              "  0.5527668595314026,\n",
              "  0.554665207862854,\n",
              "  0.5033366680145264,\n",
              "  0.553368091583252,\n",
              "  0.5649054050445557,\n",
              "  0.5250270962715149,\n",
              "  0.48631465435028076,\n",
              "  0.47180524468421936,\n",
              "  0.5164062976837158,\n",
              "  0.5555140972137451,\n",
              "  0.5130233764648438,\n",
              "  0.542705774307251,\n",
              "  0.5690509080886841,\n",
              "  0.5093761682510376,\n",
              "  0.5087478756904602,\n",
              "  0.5363311171531677,\n",
              "  0.5670755505561829,\n",
              "  0.558399498462677,\n",
              "  0.48584574460983276,\n",
              "  0.5242262482643127,\n",
              "  0.5647602677345276,\n",
              "  0.5682579874992371,\n",
              "  0.5755816102027893,\n",
              "  0.5712945461273193,\n",
              "  0.5049940347671509,\n",
              "  0.5652579069137573,\n",
              "  0.5440067052841187,\n",
              "  0.5149386525154114,\n",
              "  0.5191739797592163,\n",
              "  0.554465115070343,\n",
              "  0.5372671484947205,\n",
              "  0.5455296635627747,\n",
              "  0.535392165184021,\n",
              "  0.5234587788581848,\n",
              "  0.5357227325439453,\n",
              "  0.5374181270599365,\n",
              "  0.5342797636985779,\n",
              "  0.5255564451217651,\n",
              "  0.5588513016700745,\n",
              "  0.5062366127967834,\n",
              "  0.569538950920105,\n",
              "  0.5303036570549011,\n",
              "  0.5298164486885071,\n",
              "  0.5469551086425781,\n",
              "  0.4832385778427124,\n",
              "  0.5343098044395447,\n",
              "  0.5850458145141602,\n",
              "  0.5466232895851135,\n",
              "  0.5290337800979614,\n",
              "  0.5772669315338135,\n",
              "  0.5515609383583069,\n",
              "  0.5631017088890076,\n",
              "  0.5465618371963501,\n",
              "  0.4954051971435547,\n",
              "  0.5538586378097534,\n",
              "  0.5998694896697998,\n",
              "  0.5728851556777954,\n",
              "  0.5985163450241089,\n",
              "  0.586888313293457,\n",
              "  0.590925931930542,\n",
              "  0.49587947130203247,\n",
              "  0.5056403875350952,\n",
              "  0.5854501724243164,\n",
              "  0.5452916622161865,\n",
              "  0.5832506418228149,\n",
              "  0.5742369890213013,\n",
              "  0.5713564157485962,\n",
              "  0.5361688137054443,\n",
              "  0.5680983066558838,\n",
              "  0.5413763523101807,\n",
              "  0.5456228852272034,\n",
              "  0.5101915597915649,\n",
              "  0.5096455812454224,\n",
              "  0.5300933718681335,\n",
              "  0.4784668982028961,\n",
              "  0.5244021415710449,\n",
              "  0.5011351108551025,\n",
              "  0.4770983159542084,\n",
              "  0.544651448726654,\n",
              "  0.46211034059524536,\n",
              "  0.5233649611473083,\n",
              "  0.4920515716075897,\n",
              "  0.49027442932128906,\n",
              "  0.5014594793319702,\n",
              "  0.5291459560394287,\n",
              "  0.4956490993499756,\n",
              "  0.49989503622055054,\n",
              "  0.5402135848999023,\n",
              "  0.5392180681228638,\n",
              "  0.5414032936096191,\n",
              "  0.47959408164024353,\n",
              "  0.5719727277755737,\n",
              "  0.544185221195221,\n",
              "  0.5383594036102295,\n",
              "  0.4914833605289459,\n",
              "  0.5186820030212402,\n",
              "  0.548437237739563,\n",
              "  0.48896709084510803,\n",
              "  0.5309224128723145,\n",
              "  0.54458087682724,\n",
              "  0.4881840944290161,\n",
              "  0.5504115223884583,\n",
              "  0.49927178025245667,\n",
              "  0.5061860084533691,\n",
              "  0.5227937698364258,\n",
              "  0.5520482063293457,\n",
              "  0.5210806131362915,\n",
              "  0.4591436982154846,\n",
              "  0.5373035669326782,\n",
              "  0.5452510714530945,\n",
              "  0.5232986211776733,\n",
              "  0.5374492406845093,\n",
              "  0.581952691078186,\n",
              "  0.5290437340736389,\n",
              "  0.5757826566696167,\n",
              "  0.5663650631904602,\n",
              "  0.5180050134658813,\n",
              "  0.5366862416267395,\n",
              "  0.5355361104011536,\n",
              "  0.5338663458824158,\n",
              "  0.5230904817581177,\n",
              "  0.5162782073020935,\n",
              "  0.5783861875534058,\n",
              "  0.5031430125236511,\n",
              "  0.5325456857681274,\n",
              "  0.535312831401825,\n",
              "  0.5638457536697388,\n",
              "  0.5433881282806396,\n",
              "  0.5382716655731201,\n",
              "  0.5719798803329468,\n",
              "  0.5713362693786621,\n",
              "  0.5643524527549744,\n",
              "  0.4738948941230774,\n",
              "  0.5270071029663086,\n",
              "  0.5601088404655457,\n",
              "  0.5029326677322388,\n",
              "  0.488654762506485,\n",
              "  0.5472893714904785,\n",
              "  0.5522857308387756,\n",
              "  0.5615808963775635,\n",
              "  0.5543617606163025,\n",
              "  0.541429340839386,\n",
              "  0.5220614671707153,\n",
              "  0.5242026448249817,\n",
              "  0.48338010907173157,\n",
              "  0.5013014078140259,\n",
              "  0.5105202794075012,\n",
              "  0.4799528121948242,\n",
              "  0.5274113416671753,\n",
              "  0.4535626173019409,\n",
              "  0.5419660806655884,\n",
              "  0.4988057017326355,\n",
              "  0.5394089221954346,\n",
              "  0.5730494260787964,\n",
              "  0.5262129902839661,\n",
              "  0.5539574027061462,\n",
              "  0.5411560535430908,\n",
              "  0.58880615234375,\n",
              "  0.5760289430618286,\n",
              "  0.5707533359527588,\n",
              "  0.5566614866256714,\n",
              "  0.5964050889015198,\n",
              "  0.537731409072876,\n",
              "  0.5055571794509888,\n",
              "  0.5745717883110046,\n",
              "  0.593309760093689,\n",
              "  0.5900495648384094,\n",
              "  0.5266547203063965,\n",
              "  0.5573647022247314,\n",
              "  0.5351260304450989,\n",
              "  0.5852435827255249,\n",
              "  0.509680449962616,\n",
              "  0.5435852408409119,\n",
              "  0.5587289929389954,\n",
              "  0.49241548776626587,\n",
              "  0.5153104662895203,\n",
              "  0.5277240872383118,\n",
              "  0.5292304754257202,\n",
              "  0.5598855018615723,\n",
              "  0.5100415945053101,\n",
              "  0.5236127376556396,\n",
              "  0.5685781240463257,\n",
              "  0.49980080127716064,\n",
              "  0.4810282588005066,\n",
              "  0.5563938617706299,\n",
              "  0.5776618719100952,\n",
              "  0.512224555015564,\n",
              "  0.4519358277320862,\n",
              "  0.5290131568908691,\n",
              "  0.5293363332748413,\n",
              "  0.5541374087333679,\n",
              "  0.5105353593826294,\n",
              "  0.45162782073020935,\n",
              "  0.5350779891014099,\n",
              "  0.5216895341873169,\n",
              "  0.5714545249938965,\n",
              "  0.5509766340255737,\n",
              "  0.5534654259681702,\n",
              "  0.5713898539543152,\n",
              "  0.5753164291381836,\n",
              "  0.4583606719970703,\n",
              "  0.5407847166061401,\n",
              "  0.5621752738952637,\n",
              "  0.4976404011249542,\n",
              "  0.5766605734825134,\n",
              "  0.49586713314056396,\n",
              "  0.45716243982315063,\n",
              "  0.5726118683815002,\n",
              "  0.5727150440216064,\n",
              "  0.5540430545806885,\n",
              "  0.5391497015953064,\n",
              "  0.5191937685012817,\n",
              "  0.5053973197937012,\n",
              "  0.5872728824615479,\n",
              "  0.4951478838920593,\n",
              "  0.5568156242370605,\n",
              "  0.4933736324310303,\n",
              "  0.5385445952415466,\n",
              "  0.5035486221313477,\n",
              "  0.5505841970443726,\n",
              "  0.5744861364364624,\n",
              "  0.5367292761802673,\n",
              "  0.5684798955917358,\n",
              "  0.5647949576377869,\n",
              "  0.4751013219356537,\n",
              "  0.5574449896812439,\n",
              "  0.5316672921180725,\n",
              "  0.5429065823554993,\n",
              "  0.5434812903404236,\n",
              "  0.5650597810745239,\n",
              "  0.4859113395214081,\n",
              "  0.573869526386261,\n",
              "  0.5552955865859985,\n",
              "  0.5446951985359192,\n",
              "  0.5568290948867798,\n",
              "  0.48038506507873535,\n",
              "  0.5541858077049255],\n",
              " 'val_acc': [0.375,\n",
              "  0.375,\n",
              "  0.375,\n",
              "  0.5,\n",
              "  0.4375,\n",
              "  0.5625,\n",
              "  0.5,\n",
              "  0.4375,\n",
              "  0.4375,\n",
              "  0.5,\n",
              "  0.5625,\n",
              "  0.5625,\n",
              "  0.5625,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.5625,\n",
              "  0.5625,\n",
              "  0.5,\n",
              "  0.5,\n",
              "  0.5625,\n",
              "  0.5,\n",
              "  0.5625,\n",
              "  0.5625,\n",
              "  0.5625,\n",
              "  0.5625,\n",
              "  0.625,\n",
              "  0.5,\n",
              "  0.5625,\n",
              "  0.5,\n",
              "  0.5,\n",
              "  0.5625,\n",
              "  0.5625,\n",
              "  0.5625,\n",
              "  0.5625,\n",
              "  0.5625,\n",
              "  0.5,\n",
              "  0.6875,\n",
              "  0.5625,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.5,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.5625,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.6875,\n",
              "  0.5,\n",
              "  0.6875,\n",
              "  0.5625,\n",
              "  0.5625,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.625,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.6875,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.5625,\n",
              "  0.625,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.625,\n",
              "  0.5625,\n",
              "  0.6875,\n",
              "  0.5625,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.5,\n",
              "  0.625,\n",
              "  0.75,\n",
              "  0.5625,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.5625,\n",
              "  0.6875,\n",
              "  0.625,\n",
              "  0.5625,\n",
              "  0.5625,\n",
              "  0.625,\n",
              "  0.5625,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.5625,\n",
              "  0.625,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.5625,\n",
              "  0.5625,\n",
              "  0.5625,\n",
              "  0.5625,\n",
              "  0.625,\n",
              "  0.6875,\n",
              "  0.5,\n",
              "  0.625,\n",
              "  0.5625,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.5,\n",
              "  0.5625,\n",
              "  0.625,\n",
              "  0.5625,\n",
              "  0.4375,\n",
              "  0.6875,\n",
              "  0.625,\n",
              "  0.75,\n",
              "  0.625,\n",
              "  0.5625,\n",
              "  0.625,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.625,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.8125,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.625,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.625,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.75,\n",
              "  0.5625,\n",
              "  0.5625,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.8125,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.625,\n",
              "  0.6875,\n",
              "  0.4375,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.5,\n",
              "  0.75,\n",
              "  0.5,\n",
              "  0.625,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.8125,\n",
              "  0.625,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.625,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.8125,\n",
              "  0.5625,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.8125,\n",
              "  0.6875,\n",
              "  0.8125,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.8125,\n",
              "  0.625,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.8125,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.625,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.625,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.625,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.625,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.625,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.6875,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.5625,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.5625,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.6875,\n",
              "  0.625,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.625,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.8125,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.625,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.8125,\n",
              "  0.6875,\n",
              "  0.625,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.8125,\n",
              "  0.625,\n",
              "  0.6875,\n",
              "  0.8125,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.8125,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.625,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.8125,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.8125,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.8125,\n",
              "  0.8125,\n",
              "  0.6875,\n",
              "  0.625,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.8125,\n",
              "  0.8125,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.8125,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.625,\n",
              "  0.6875,\n",
              "  0.625,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.8125,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.75,\n",
              "  0.8125,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.8125,\n",
              "  0.5625,\n",
              "  0.625,\n",
              "  0.8125,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.625,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.625,\n",
              "  0.8125,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.8125,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.8125,\n",
              "  0.625,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.625,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.625,\n",
              "  0.6875,\n",
              "  0.8125,\n",
              "  0.75,\n",
              "  0.8125,\n",
              "  0.8125,\n",
              "  0.75,\n",
              "  0.625,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.8125,\n",
              "  0.75,\n",
              "  0.8125,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.75,\n",
              "  0.6875,\n",
              "  0.625,\n",
              "  0.6875,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.75,\n",
              "  0.8125,\n",
              "  0.75,\n",
              "  0.625,\n",
              "  0.75,\n",
              "  0.75,\n",
              "  0.8125,\n",
              "  0.75]}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot training performance"
      ],
      "metadata": {
        "id": "54D1y5fZcRUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'co', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'k', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'co', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Aig-yHOBcNrP",
        "outputId": "58eea420-d50a-4ae1-c7e4-9e18a9e4b6fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SAVE model** "
      ],
      "metadata": {
        "id": "okE8lIwPkoSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('./content/drive/My Drive/new', exist_ok=True)\n",
        "model.save('./content/drive/My Drive/new/nsc2.h5')"
      ],
      "metadata": {
        "id": "f_Xlg2XSuT9L"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "HuBli3HajIR2"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"./content/drive/My Drive/new/nsc2.h5\")"
      ],
      "metadata": {
        "id": "zblzwvRGkSCR",
        "outputId": "45d8cad2-0e49-4e3b-cb2e-cadd362beee2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c2d6add0-1dd0-4e83-90db-41a2a657c7f5\", \"nsc2.h5\", 16604176)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}