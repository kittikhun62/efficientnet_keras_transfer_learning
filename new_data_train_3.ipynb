{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7jth/bl0+KYoJ0thXQdK3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kittikhun62/efficientnet_keras_transfer_learning/blob/master/new_data_train_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# import from drive"
      ],
      "metadata": {
        "id": "_2DRC-anSxem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "BVIqfqC1DtDt",
        "outputId": "35a975bb-696b-4cce-82e5-8c287684936e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (r'/content/drive/My Drive/data - new data.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "gABRUdVwDtBk",
        "outputId": "03f61094-f97c-45ef-cc55-6b8bdab9f0c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      No                      Name_file  \\\n",
              "0      1                        pore-sb   \n",
              "1      2                        pore-sb   \n",
              "2      3                        pore-sb   \n",
              "3      4                        pore-sb   \n",
              "4      5                        pore-sb   \n",
              "..   ...                            ...   \n",
              "840  841  1-s2.0-S2095268622000210-main   \n",
              "841  842  1-s2.0-S2095268622000210-main   \n",
              "842  843  1-s2.0-S2095268622000210-main   \n",
              "843  844  1-s2.0-S2095268622000210-main   \n",
              "844  845  1-s2.0-S2095268622000210-main   \n",
              "\n",
              "                                            Name_Paper  \\\n",
              "0    Preparation and electrochemical behaviour of b...   \n",
              "1    Preparation and electrochemical behaviour of b...   \n",
              "2    Preparation and electrochemical behaviour of b...   \n",
              "3    Preparation and electrochemical behaviour of b...   \n",
              "4    Preparation and electrochemical behaviour of b...   \n",
              "..                                                 ...   \n",
              "840  Integration of preparation of K, Na-embedded a...   \n",
              "841  Integration of preparation of K, Na-embedded a...   \n",
              "842  Integration of preparation of K, Na-embedded a...   \n",
              "843  Integration of preparation of K, Na-embedded a...   \n",
              "844  Integration of preparation of K, Na-embedded a...   \n",
              "\n",
              "                                               journal  \\\n",
              "0                                  Korean J. Chem. Eng   \n",
              "1                                  Korean J. Chem. Eng   \n",
              "2                                  Korean J. Chem. Eng   \n",
              "3                                  Korean J. Chem. Eng   \n",
              "4                                  Korean J. Chem. Eng   \n",
              "..                                                 ...   \n",
              "840  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "841  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "842  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "843  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "844  Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...   \n",
              "\n",
              "                                          path_Picture    detail  Class  \\\n",
              "0    /content/drive/My Drive/new train/pore-sb/PCC(...  original  0-500   \n",
              "1    /content/drive/My Drive/new train/pore-sb/PCC(...     zoom1  0-500   \n",
              "2    /content/drive/My Drive/new train/pore-sb/PCC(...     zoom2  0-500   \n",
              "3    /content/drive/My Drive/new train/pore-sb/PCC(...     zoom3  0-500   \n",
              "4    /content/drive/My Drive/new train/pore-sb/PCC(...     zoom4  0-500   \n",
              "..                                                 ...       ...    ...   \n",
              "840  /content/drive/My Drive/new train/1-s2.0-S2095...    zoom21  0-500   \n",
              "841  /content/drive/My Drive/new train/1-s2.0-S2095...    zoom22  0-500   \n",
              "842  /content/drive/My Drive/new train/1-s2.0-S2095...    zoom23  0-500   \n",
              "843  /content/drive/My Drive/new train/1-s2.0-S2095...    zoom24  0-500   \n",
              "844  /content/drive/My Drive/new train/1-s2.0-S2095...    zoom25  0-500   \n",
              "\n",
              "        BET  Size(mico)  \n",
              "0    135.06           5  \n",
              "1    135.06          10  \n",
              "2    135.06          10  \n",
              "3    135.06          10  \n",
              "4    135.06          10  \n",
              "..      ...         ...  \n",
              "840  301.70          10  \n",
              "841  301.70          10  \n",
              "842  301.70          10  \n",
              "843  301.70          10  \n",
              "844  301.70          10  \n",
              "\n",
              "[845 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a7d1c167-0b50-40ed-8fc9-b0dbfcca7190\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>No</th>\n",
              "      <th>Name_file</th>\n",
              "      <th>Name_Paper</th>\n",
              "      <th>journal</th>\n",
              "      <th>path_Picture</th>\n",
              "      <th>detail</th>\n",
              "      <th>Class</th>\n",
              "      <th>BET</th>\n",
              "      <th>Size(mico)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>original</td>\n",
              "      <td>0-500</td>\n",
              "      <td>135.06</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom1</td>\n",
              "      <td>0-500</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom2</td>\n",
              "      <td>0-500</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom3</td>\n",
              "      <td>0-500</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>pore-sb</td>\n",
              "      <td>Preparation and electrochemical behaviour of b...</td>\n",
              "      <td>Korean J. Chem. Eng</td>\n",
              "      <td>/content/drive/My Drive/new train/pore-sb/PCC(...</td>\n",
              "      <td>zoom4</td>\n",
              "      <td>0-500</td>\n",
              "      <td>135.06</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>840</th>\n",
              "      <td>841</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom21</td>\n",
              "      <td>0-500</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>841</th>\n",
              "      <td>842</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom22</td>\n",
              "      <td>0-500</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>842</th>\n",
              "      <td>843</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom23</td>\n",
              "      <td>0-500</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>843</th>\n",
              "      <td>844</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom24</td>\n",
              "      <td>0-500</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>844</th>\n",
              "      <td>845</td>\n",
              "      <td>1-s2.0-S2095268622000210-main</td>\n",
              "      <td>Integration of preparation of K, Na-embedded a...</td>\n",
              "      <td>Dingzheng Wang,Deqing Zhu,Jian Pan, Zhengqi Gu...</td>\n",
              "      <td>/content/drive/My Drive/new train/1-s2.0-S2095...</td>\n",
              "      <td>zoom25</td>\n",
              "      <td>0-500</td>\n",
              "      <td>301.70</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>845 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7d1c167-0b50-40ed-8fc9-b0dbfcca7190')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a7d1c167-0b50-40ed-8fc9-b0dbfcca7190 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a7d1c167-0b50-40ed-8fc9-b0dbfcca7190');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## hist check class"
      ],
      "metadata": {
        "id": "WMazXBQcTMl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "W34NcexJDs_Z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.hist();"
      ],
      "metadata": {
        "id": "Fm07UpEbDs5X",
        "outputId": "9f476259-34bb-42e1-d04d-c8aa3bdc93aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = df['BET']\n",
        "\n",
        "fig, ax = plt.subplots(figsize =(10, 5))\n",
        "ax.hist(a, bins = 200)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bxfNFKW2TXAY",
        "outputId": "a24b6584-e31f-4c73-9c82-1bc7b8520633",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlAAAAEvCAYAAACKfv/MAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARiElEQVR4nO3db4hl93kf8O9TrWyH2FRSNF2E5e3IjUjQi0Y2i+oQE4hdO7JVKhWEUSjp0qostDE4tCHdNFAS6It1IH9aCA1qbbotaSzXiZHIpk1URSEUWjmrWLYlq47W6ppayFolthLnTRI5T1/cs8pkPaO5v5k7e+/e+Xzgcs/5nTNzn/vMucOX8+9WdwcAgPn9lWUXAABwtRGgAAAGCVAAAIMEKACAQQIUAMAgAQoAYNCRK/liN954Y29ubl7JlwQA2JMnnnji97t7Y7tlVzRAbW5u5ty5c1fyJQEA9qSqvrTTMofwAAAGCVAAAIMEKACAQQIUAMAgAQoAYJAABQAwSIACABg0132gqupCkq8n+UaSV7r7eFXdkOTBJJtJLiT5QHd/7WDKBABYHSN7oL6vu2/v7uPT/Kkkj3b3rUkeneYBANbefg7h3Z3kzDR9Jsk9+y8HAGD1zRugOslvVNUTVXVyGjva3S9M019JcnTh1QEArKB5vwvvnd39fFX9tSSPVNX/2bqwu7uqersfnALXySQ5duzYvooFOEibp84mSS6cvmvJlQCrbq49UN39/PR8Mcknk9yR5MWquilJpueLO/zsA919vLuPb2xs+4XGAABXlV0DVFV9a1W96dJ0kvcmeSrJw0lOTKudSPLQQRUJALBK5jmEdzTJJ6vq0vr/pbv/e1X9TpKPV9X9Sb6U5AMHVyYAwOrYNUB193NJvmub8T9I8u6DKAoAYJW5EzkAwCABCgBgkAAFADBIgAIAGCRAAQAMEqAAAAYJUAAAgwQoAIBBAhQAwCABCgBgkAAFADBIgAIAGCRAAQAMEqAAAAYJUAAAgwQoAIBBAhQAwCABCgBgkAAFADBIgAIAGCRAAQAMEqAAAAYJUAAAgwQoAIBBAhQAwCABCgBgkAAFADBIgAIAGCRAAQAMEqAAAAYJUAAAgwQoAIBBAhQAwCABCgBgkAAFADBIgAIAGCRAAQAMEqAAAAYJUAAAgwQoAIBBAhQAwCABCgBgkAAFADBo7gBVVddU1aer6len+Vuq6vGqOl9VD1bV6w6uTACA1TGyB+pDSZ7ZMv/hJD/b3d+e5GtJ7l9kYQAAq2quAFVVNye5K8l/mOYrybuSfGJa5UySew6iQACAVTPvHqifS/KjSf58mv+2JC939yvT/JeTvHnBtQEArKRdA1RV/Z0kF7v7ib28QFWdrKpzVXXupZde2suvAABYKfPsgfqeJH+3qi4k+Vhmh+7+TZLrqurItM7NSZ7f7oe7+4HuPt7dxzc2NhZQMgDAcu0aoLr7x7r75u7eTHJfkt/s7r+f5LEk906rnUjy0IFVCQCwQvZzH6h/keSfVdX5zM6J+shiSgIAWG1Hdl/lL3T3byX5rWn6uSR3LL4kAIDV5k7kAACDBCgAgEECFADAIAEKAGCQAAUAMEiAAgAYJEABAAwSoAAABglQAACDBCgAgEEC1FVs89TZbJ46u+wyAODQEaAAAAYJUAAAgwQoAIBBAhQAwCABCgBgkAAFADBIgAIAGCRAAQAMEqAAAAYJUAAAg44suwCunK1f+3Lh9F1LrORgrPv7A2B12AMFADBIgAIAGCRAAQAMEqAAAAYJUAAAgwQoAIBBAhQAwCABCgBgkAAFADBIgAIAGCRAAQAMEqAAAAYJUAAAgwQoAIBBAhQAwCABCgBgkAAFADBIgAIAGCRAAQAMEqAAAAYJUAAAg3YNUFX1hqr6VFV9pqqerqqfnMZvqarHq+p8VT1YVa87+HIBAJZvnj1Qf5LkXd39XUluT3JnVb0jyYeT/Gx3f3uSryW5/+DKBABYHbsGqJ7542n22unRSd6V5BPT+Jkk9xxIhQAAK2auc6Cq6pqqejLJxSSPJPlikpe7+5VplS8nefMOP3uyqs5V1bmXXnppETUDACzVXAGqu7/R3bcnuTnJHUm+c94X6O4Huvt4dx/f2NjYY5kAAKtj6Cq87n45yWNJvjvJdVV1ZFp0c5LnF1wbAMBKmucqvI2qum6a/pYk70nyTGZB6t5ptRNJHjqoIgEAVsmR3VfJTUnOVNU1mQWuj3f3r1bV55N8rKr+dZJPJ/nIAdYJALAydg1Q3f3ZJG/bZvy5zM6HAgA4VNyJHABgkAAFADBIgAIAGCRAAQAMEqAAAAbNcxuDQ2Pz1NlXpy+cvmuJlQAAq8weKACAQQIUAMAgAQoAYJAABQAwaK0D1Oaps3/pxHAAgEVY6wAFAHAQBCgAgEECFADAIAEKAGCQAAWXcfEBALsRoAAABglQAACDBCgAgEECFADAoCPLLmAVLOqE4Uu/58LpuxZSw15+z3a/b97fs5/62b+9/M2uJtu9v3nf89Xam3X8TF2tf4tVsI7bw2FmDxQAwCABCgBgkAAFADBIgAIAGCRAAQAMEqAAAAYJUAAAgwQoAIBBAhQAwCABCgBgkAAFADBIgAIAGCRAAQAMEqAAAAYJUAAAgwQoAIBBAhQAwCABCgBgkAAFADBIgAIAGCRAAQAM2jVAVdVbquqxqvp8VT1dVR+axm+oqkeq6tnp+fqDLxcAYPnm2QP1SpJ/3t23JXlHkh+qqtuSnEryaHffmuTRaR4AYO3tGqC6+4Xu/t1p+utJnkny5iR3JzkzrXYmyT0HVSQAwCoZOgeqqjaTvC3J40mOdvcL06KvJDm60MoAAFbUkXlXrKo3JvnlJD/c3X9UVa8u6+6uqt7h504mOZkkx44d21+1rJXNU2eTJBdO3/WaY6yfS39ngKvVXHugqurazMLTL3b3r0zDL1bVTdPym5Jc3O5nu/uB7j7e3cc3NjYWUTMAwFLNcxVeJflIkme6+2e2LHo4yYlp+kSShxZfHgDA6pnnEN73JPnBJJ+rqiensX+Z5HSSj1fV/Um+lOQDB1MiAMBq2TVAdff/TFI7LH73YssBAFh97kQOADBIgAIAGCRAAQAMEqAAAAYJUAAAgwQoAIBBAhQAwCABCgBgkAAFADBIgAIAGCRAAQAMEqAAAAYJUAAAgwQoAIBBAhQAwCABCgBgkAAFADBIgAIAGCRAAQAMEqAAAAYJUAAAgwQoAIBBAhQAwCABCgBgkAAFADBIgAIAGCRAHVKbp85m89TZZZcBAFclAQoAYJAABQAwSIACABgkQAEADBKgDpiTtQFg/QhQAACDBCgAgEECFADAIAEKAGCQAAUAMOjIsgsAWHdbr8S9cPquJVYCLIo9UAAAgwQoAIBBAhQAwCABCgBgkAAFADBo1wBVVR+tqotV9dSWsRuq6pGqenZ6vv5gywQAWB3z7IH6j0nuvGzsVJJHu/vWJI9O8wAAh8KuAaq7fzvJVy8bvjvJmWn6TJJ7FlwXAMDK2us5UEe7+4Vp+itJji6oHgCAlbfvO5F3d1dV77S8qk4mOZkkx44d2+/LXTFb7xx8ydY7CF9afpB3Fb4Sr3E11HCJuzmPGenXKv2dt9ruc7isGq5Ub0ZfbxU+F6tQA1xpe90D9WJV3ZQk0/PFnVbs7ge6+3h3H9/Y2NjjywEArI69BqiHk5yYpk8keWgx5QAArL55bmPwS0n+V5LvqKovV9X9SU4neU9VPZvkb0/zAACHwq7nQHX3D+yw6N0LrgUA4KrgTuQAAIMEKACAQQIUAMAgAQoAYJAABQAwSIACABgkQAEADBKgAAAGCVAAAIMEKACAQQIUAMAgAQoAYJAABQAwSIACABgkQAEADBKgAAAGCVAAAIMEKACAQQIUAMAgAQoAYJAABQAwSIACABgkQAEADBKgAAAGCVAAAIMEKACAQQIUAMAgAQoAYJAABQAwSIACABgkQAEADDqy7AKA/ds8dfbV6Qun71piJQCHgz1QAACDBCgAgEECFADAIAEKAGDQ2p1EvvVk2u3GFn2C7Xavd5D28noHVeNOv3e7Hl9ad1VPcN5PX1ftPe32Xuate1XfH+vlar0A4mqt+yAdtv8Z9kABAAwSoAAABglQAACDBCgAgEECFADAoLW7Cm8363iVwLpfDfJaV1bu9H63W76fv/1r/exI/0drWNTf9kpfLcrBWPfP+qJd7f06yP8tB2m7uhf9v2wV3ue+9kBV1Z1V9YWqOl9VpxZVFADAKttzgKqqa5L8fJL3JbktyQ9U1W2LKgwAYFXtZw/UHUnOd/dz3f2nST6W5O7FlAUAsLr2E6DenOT/bZn/8jQGALDWqrv39oNV9ya5s7v/8TT/g0n+Vnd/8LL1TiY5Oc1+R5Iv7L3cudyY5PcP+DXWld7tj/7tnd7tnd7tj/7t3WHo3V/v7o3tFuznKrznk7xly/zN09hf0t0PJHlgH68zpKrOdffxK/V660Tv9kf/9k7v9k7v9kf/9u6w924/h/B+J8mtVXVLVb0uyX1JHl5MWQAAq2vPe6C6+5Wq+mCSX09yTZKPdvfTC6sMAGBF7etGmt39a0l+bUG1LMoVO1y4hvRuf/Rv7/Ru7/Ruf/Rv7w517/Z8EjkAwGHlu/AAAAatVYDy1TK7q6oLVfW5qnqyqs5NYzdU1SNV9ez0fP00XlX1b6d+fraq3r7c6q+sqvpoVV2sqqe2jA33qqpOTOs/W1UnlvFelmGH/v1EVT0/bX9PVtX7tyz7sal/X6iq798yfug+11X1lqp6rKo+X1VPV9WHpnHb3y5eo3e2vV1U1Ruq6lNV9Zmpdz85jd9SVY9PfXhwunAsVfX6af78tHxzy+/atqdrpbvX4pHZiexfTPLWJK9L8pkkty27rlV7JLmQ5MbLxn4qyalp+lSSD0/T70/y35JUknckeXzZ9V/hXn1vkrcneWqvvUpyQ5Lnpufrp+nrl/3elti/n0jyI9use9v0mX19klumz/I1h/VzneSmJG+fpt+U5PemHtn+9t47297uvaskb5ymr03y+LQ9fTzJfdP4LyT5J9P0P03yC9P0fUkefK2eLvv9LfqxTnugfLXM3t2d5Mw0fSbJPVvG/1PP/O8k11XVTcsocBm6+7eTfPWy4dFefX+SR7r7q939tSSPJLnz4Ktfvh36t5O7k3ysu/+ku/9vkvOZfaYP5ee6u1/o7t+dpr+e5JnMvunB9reL1+jdTmx7k2n7+eNp9trp0UneleQT0/jl292l7fETSd5dVZWde7pW1ilA+WqZ+XSS36iqJ2p2l/gkOdrdL0zTX0lydJrW02822is9/GYfnA4zffTSIajo346mwyJvy2xvgO1vwGW9S2x7u6qqa6rqySQXMwvcX0zycne/Mq2ytQ+v9mha/odJvi2HpHfrFKCYzzu7++1J3pfkh6rqe7cu7Nn+V5dmzkGv9uTfJfkbSW5P8kKSn15uOautqt6Y5JeT/HB3/9HWZba/17ZN72x7c+jub3T37Zl9u8gdSb5zySWtrHUKUHN9tcxh193PT88Xk3wysw/Ii5cOzU3PF6fV9fSbjfZKD7fo7henf9B/nuTf5y926+vfZarq2swCwC92969Mw7a/OWzXO9vemO5+OcljSb47s0PCl+4bubUPr/ZoWv5Xk/xBDknv1ilA+WqZXVTVt1bVmy5NJ3lvkqcy69Olq3NOJHlomn44yT+YrvB5R5I/3HL44LAa7dWvJ3lvVV0/HTJ47zR2KF12Dt3fy2z7S2b9u2+6queWJLcm+VQO6ed6Oo/kI0me6e6f2bLI9reLnXpn29tdVW1U1XXT9LckeU9m55A9luTeabXLt7tL2+O9SX5z2jO6U0/Xy7LPYl/kI7MrUX4vs2O2P77selbtkdnVJJ+ZHk9f6lFmx6wfTfJskv+R5IZpvJL8/NTPzyU5vuz3cIX79UuZ7er/s8yO4d+/l14l+UeZnUR5Psk/XPb7WnL//vPUn89m9k/2pi3r//jUvy8ked+W8UP3uU7yzswOz302yZPT4/22v331zra3e+/+ZpJPTz16Ksm/msbfmlkAOp/kvyZ5/TT+hmn+/LT8rbv1dJ0e7kQOADBonQ7hAQBcEQIUAMAgAQoAYJAABQAwSIACABgkQAEADBKgAAAGCVAAAIP+Pyl7KxX37ogQAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ['0-500','501-1000','1001-3200']\n",
        "len(classes)"
      ],
      "metadata": {
        "id": "TBsLszHgTW-D",
        "outputId": "27abaa84-fe87-45ed-be09-6ffd6a73ea8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone efficientnet repo"
      ],
      "metadata": {
        "id": "DSSZIFGhUyQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/"
      ],
      "metadata": {
        "id": "nFvKcuBDTj1N",
        "outputId": "0df8cd01-a4db-4977-a28b-c66fadac580e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 653, done.\u001b[K\n",
            "remote: Counting objects: 100% (175/175), done.\u001b[K\n",
            "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
            "remote: Total 653 (delta 143), reused 103 (delta 103), pack-reused 478\n",
            "Receiving objects: 100% (653/653), 12.00 MiB | 28.05 MiB/s, done.\n",
            "Resolving deltas: 100% (383/383), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# การเเบ่งข้อมูล train/validation/test sets"
      ],
      "metadata": {
        "id": "JDJCDzEDWnVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/My Drive/new project'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Directories for our training,\n",
        "# validation and test splits\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.makedirs(test_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "R7L0rJNRU2MY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_1_dir = os.path.join(train_dir, '0-500')\n",
        "os.makedirs(train_1_dir, exist_ok=True)\n",
        "\n",
        "train_2_dir = os.path.join(train_dir, '501-1000')\n",
        "os.makedirs(train_2_dir, exist_ok=True)\n",
        "\n",
        "train_3_dir = os.path.join(train_dir, '1001-3200')\n",
        "os.makedirs(train_3_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "validation_1_dir = os.path.join(validation_dir, '0-500')\n",
        "os.makedirs(validation_1_dir, exist_ok=True)\n",
        "\n",
        "validation_2_dir = os.path.join(validation_dir, '501-1000')\n",
        "os.makedirs(validation_2_dir, exist_ok=True)\n",
        "\n",
        "validation_3_dir = os.path.join(validation_dir, '1001-3200')\n",
        "os.makedirs(validation_3_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "test_1_dir = os.path.join(test_dir, '0-500')\n",
        "os.makedirs(test_1_dir, exist_ok=True)\n",
        "\n",
        "test_2_dir = os.path.join(test_dir, '501-1000')\n",
        "os.makedirs(test_2_dir, exist_ok=True)\n",
        "\n",
        "test_3_dir = os.path.join(test_dir, '1001-3200')\n",
        "os.makedirs(test_3_dir, exist_ok=True)\n",
        "     "
      ],
      "metadata": {
        "id": "jtyFMXrWU2KD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val = df[df['No'].between(682,764)]\n",
        "train = df[df['No'].between(1,681)]\n",
        "test = df[df['No'].between(756,845)] \n",
        "\n",
        "#Path Train\n",
        "T1_train = train[train['Class']=='0-500' ]\n",
        "T1_path_train = T1_train['path_Picture'].tolist() \n",
        "T2_train = train[train['Class']=='501-1000' ]\n",
        "T2_path_train = T2_train['path_Picture'].tolist() \n",
        "T3_train = train[train['Class']=='1001-3200' ]\n",
        "T3_path_train = T3_train['path_Picture'].tolist()\n",
        "\n",
        "#Path Validation\n",
        "T1_val = val[val['Class']=='0-500' ]\n",
        "T1_path_val = T1_val['path_Picture'].tolist() \n",
        "T2_val = val[val['Class']=='501-1000' ]\n",
        "T2_path_val = T2_val['path_Picture'].tolist() \n",
        "T3_val = val[val['Class']=='1001-3200']\n",
        "T3_path_val = T3_val['path_Picture'].tolist()\n",
        "\n",
        "\n",
        "#Path Test\n",
        "T1_test = test[test['Class']=='0-500' ]\n",
        "T1_path_test = T1_test['path_Picture'].tolist() \n",
        "T2_test = test[test['Class']=='501-1000' ]\n",
        "T2_path_test = T2_test['path_Picture'].tolist() \n",
        "T3_test = test[test['Class']=='1001-3200']\n",
        "T3_path_test = T3_test['path_Picture'].tolist()"
      ],
      "metadata": {
        "id": "mlmd_kyhW2LZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "ZkfPduNQW43l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fnames = T1_path_train\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_1_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "fnames = T2_path_train\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_2_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "    \n",
        "fnames = T3_path_train \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_3_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)"
      ],
      "metadata": {
        "id": "9jMgUluKU2Hp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test"
      ],
      "metadata": {
        "id": "Mj3sViKJaLSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fnames = T1_path_test\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_1_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "fnames = T2_path_test\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_2_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "    \n",
        "fnames = T3_path_test \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_3_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)"
      ],
      "metadata": {
        "id": "WvK0Y2FIYat1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Validation"
      ],
      "metadata": {
        "id": "rc4HwwbPaD6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fnames = T1_path_val\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(test_1_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "fnames = T2_path_val\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(test_2_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "    \n",
        "fnames = T3_path_val \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(test_3_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)"
      ],
      "metadata": {
        "id": "XxtmCbyUYarp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('total training 1 images:', len(os.listdir(train_1_dir))) \n",
        "print('total training 2 images:', len(os.listdir(train_2_dir)))\n",
        "print('total training 3 images:', len(os.listdir(train_3_dir)),'\\n')\n",
        "\n",
        "\n",
        "print('total validation 1 images:', len(os.listdir(validation_1_dir)))\n",
        "print('total validation 2 images:', len(os.listdir(validation_2_dir)))\n",
        "print('total validation 3 images:', len(os.listdir(validation_3_dir)),'\\n')\n",
        "\n",
        "\n",
        "print('total test 1 images:', len(os.listdir(test_1_dir)))\n",
        "print('total test 2 images:', len(os.listdir(test_2_dir)))\n",
        "print('total test 3 images:', len(os.listdir(test_3_dir)),'\\n')"
      ],
      "metadata": {
        "id": "Tvk53f-WYapl",
        "outputId": "e9eb20f8-273b-433e-de14-ba12c44dc28e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total training 1 images: 211\n",
            "total training 2 images: 145\n",
            "total training 3 images: 325 \n",
            "\n",
            "total validation 1 images: 68\n",
            "total validation 2 images: 27\n",
            "total validation 3 images: 12 \n",
            "\n",
            "total test 1 images: 62\n",
            "total test 2 images: 6\n",
            "total test 3 images: 15 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports library"
      ],
      "metadata": {
        "id": "VkYa-4LeTbir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "myAsBcVhTW7j"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## hyper parameter\n"
      ],
      "metadata": {
        "id": "T529UM_tVV-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 20\n",
        "\n",
        "width = 150\n",
        "height = 150\n",
        "\n",
        "epochs = 300 #จำนวนรอบในการ Train\n",
        "\n",
        "NUM_TRAIN = 681  # จำนวนภาพ Train\n",
        "NUM_TEST = 82 #จำนวนภาพ Test\n",
        "\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3) #ขนาด image enter"
      ],
      "metadata": {
        "id": "zXpmkJ2GVZ1l"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import efficientnet and load the conv base model"
      ],
      "metadata": {
        "id": "j3EgSOiSZHaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "iI3DQ18HU2TF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "#EfficientNet สร้างขึ้นสำหรับการจำแนกประเภท ImageNet ประกอบด้วยป้ายกำกับคลาส 1,000 รายการ เรามีเพียง 2 เลเยอร์เท่านั้น ซึ่งหมายความว่าเลเยอร์สองสามเลเยอร์สุดท้ายสำหรับการจำแนกไม่มีประโยชน์สำหรับเรา สามารถยกเว้นได้ขณะโหลดโมเดลโดยระบุอาร์กิวเมนต์ include_top เป็น False และนำไปใช้กับโมเดล ImageNet อื่นๆ ที่มีอยู่ในแอปพลิเคชัน Keras เช่นกัน\n",
        "\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "UmBDAgF_VAjq",
        "outputId": "0da6dc52-cf99-4c0b-805e-44f2bf8d1ca1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "id": "rRXoFFzfU2Oi",
        "outputId": "d5198d12-0026-4840-dcda-e6bb24ea47dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 4,007,548\n",
            "Non-trainable params: 42,016\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Show architecture model"
      ],
      "metadata": {
        "id": "W1JJhCEWZjiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดัดแปลง GlobalMaxPooling2D เพื่อแปลง 4D the (batch_size, rows, cols,channels) tensor เป็น 2D tensor with shape (batch_size,channels)\n",
        "#GlobalMaxPooling2D ส่งผลให้มีจำนวนฟีเจอร์น้อยกว่ามากเมื่อเทียบกับเลเยอร์ Flatten ซึ่งช่วยลดจำนวนพารามิเตอร์ได้อย่างมีประสิทธิภาพ\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
        "# model.add(layers.Flatten(name=\"flatten\"))\n",
        "if dropout_rate > 0:\n",
        "    model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n",
        "# model.add(layers.Dense(256, activation='relu', name=\"fc1\"))\n",
        "model.add(layers.Dense(3, activation='softmax', name=\"fc_out\"))"
      ],
      "metadata": {
        "id": "-9EQ5AdjZT9s"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "wmBUcgsMZVkW",
        "outputId": "f2a4b276-e3aa-46ce-b660-70e1c79ed928",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 3)                 3843      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,053,407\n",
            "Trainable params: 4,011,391\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('This is the number of trainable layers '\n",
        "      'before freezing the conv base:', len(model.trainable_weights))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "print('This is the number of trainable layers '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ],
      "metadata": {
        "id": "xRyPafCIZXzU",
        "outputId": "f0521a4c-77a3-4480-d7e1-8c8c7ac5be68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable layers before freezing the conv base: 213\n",
            "This is the number of trainable layers after freezing the conv base: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting data augmentation"
      ],
      "metadata": {
        "id": "X9Xfp10TY9xE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "#Image Augmentation \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, # image input 0-255 --> 0-1 เปลี่ยนค่าสี\n",
        "      rotation_range=40,# หมุนภาพในองศา\n",
        "      width_shift_range=0.2, #เปลี่ยนความกว้าง\n",
        "      height_shift_range=0.2, #ปลี่ยนความสูง\n",
        "      shear_range=0.2, #ทำให้ภาพเบี้ยว\n",
        "      zoom_range=0.2, # Randomly zoom image\n",
        "      horizontal_flip=True, \n",
        "      #โดย Default เมื่อมีการเลื่อนภาพ บิดภาพ หมุนภาพ จะเกิดพื้นที่ว่างที่มุม \n",
        "      #ซึ่งจะมีการเติมภาพให้เต็มโดยใช้เทคนิคแบบ Nearest neighbor ซึ่งเป็นการดึงสีบริเวณใหล้าเคียงมาระบายให้เต็ม แต่เราก็ยังสามารถกำหนดวิธีการ Fill ภาพด้วยเทคนิคอื่นได้จาก Parameter fill_mode\n",
        "      fill_mode='nearest')\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory #ไดเรกเป้าหมาย\n",
        "        train_dir,\n",
        "        # รูปภาพทั้งหมดจะถูกปรับขนาดตามความสูงและความกว้างของเป้าหมาย\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        #เนื่องจากเราใช้ categorical_crossentropy loss เราจึงต้องมีป้ายกำกับตามหมวดหมู่\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory( #การดึงภาพจาก Directory มาเข้าโมเดล \n",
        "        validation_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "id": "GC-vPos9Y9HD",
        "outputId": "1c32d8fd-64c1-459d-efd0-30fa32ac93a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 681 images belonging to 3 classes.\n",
            "Found 107 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "8S60IpOWcB7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
        "              metrics=['acc'])\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "Od8zqlOwb9Iw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "136b79cc-f7a3-4238-990e-887be81384f1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n",
            "<ipython-input-24-bbda3a575f01>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "34/34 [==============================] - 33s 742ms/step - loss: 1.6619 - acc: 0.3328 - val_loss: 1.1703 - val_acc: 0.5500\n",
            "Epoch 2/300\n",
            "34/34 [==============================] - 24s 659ms/step - loss: 1.6666 - acc: 0.3464 - val_loss: 1.2777 - val_acc: 0.4375\n",
            "Epoch 3/300\n",
            "34/34 [==============================] - 25s 669ms/step - loss: 1.5001 - acc: 0.4009 - val_loss: 1.2946 - val_acc: 0.4000\n",
            "Epoch 4/300\n",
            "34/34 [==============================] - 28s 766ms/step - loss: 1.5152 - acc: 0.3949 - val_loss: 1.3860 - val_acc: 0.3125\n",
            "Epoch 5/300\n",
            "34/34 [==============================] - 25s 684ms/step - loss: 1.4698 - acc: 0.4024 - val_loss: 1.4076 - val_acc: 0.3000\n",
            "Epoch 6/300\n",
            "34/34 [==============================] - 25s 691ms/step - loss: 1.5452 - acc: 0.3918 - val_loss: 1.3386 - val_acc: 0.3375\n",
            "Epoch 7/300\n",
            "34/34 [==============================] - 26s 706ms/step - loss: 1.5165 - acc: 0.3707 - val_loss: 1.4293 - val_acc: 0.2750\n",
            "Epoch 8/300\n",
            "34/34 [==============================] - 26s 703ms/step - loss: 1.4532 - acc: 0.3873 - val_loss: 1.3515 - val_acc: 0.3000\n",
            "Epoch 9/300\n",
            "34/34 [==============================] - 25s 681ms/step - loss: 1.5109 - acc: 0.3888 - val_loss: 1.3568 - val_acc: 0.2875\n",
            "Epoch 10/300\n",
            "34/34 [==============================] - 28s 767ms/step - loss: 1.4908 - acc: 0.4009 - val_loss: 1.3480 - val_acc: 0.3000\n",
            "Epoch 11/300\n",
            "34/34 [==============================] - 26s 723ms/step - loss: 1.4493 - acc: 0.3918 - val_loss: 1.2806 - val_acc: 0.3250\n",
            "Epoch 12/300\n",
            "34/34 [==============================] - 26s 719ms/step - loss: 1.3851 - acc: 0.4054 - val_loss: 1.3342 - val_acc: 0.3375\n",
            "Epoch 13/300\n",
            "34/34 [==============================] - 25s 672ms/step - loss: 1.4369 - acc: 0.4221 - val_loss: 1.3345 - val_acc: 0.3125\n",
            "Epoch 14/300\n",
            "34/34 [==============================] - 26s 710ms/step - loss: 1.4229 - acc: 0.4191 - val_loss: 1.2825 - val_acc: 0.3375\n",
            "Epoch 15/300\n",
            "34/34 [==============================] - 25s 687ms/step - loss: 1.4660 - acc: 0.4024 - val_loss: 1.1740 - val_acc: 0.3625\n",
            "Epoch 16/300\n",
            "34/34 [==============================] - 26s 696ms/step - loss: 1.3989 - acc: 0.4175 - val_loss: 1.2367 - val_acc: 0.3000\n",
            "Epoch 17/300\n",
            "34/34 [==============================] - 25s 698ms/step - loss: 1.4806 - acc: 0.3812 - val_loss: 1.3032 - val_acc: 0.3000\n",
            "Epoch 18/300\n",
            "34/34 [==============================] - 25s 692ms/step - loss: 1.3209 - acc: 0.4599 - val_loss: 1.2298 - val_acc: 0.3375\n",
            "Epoch 19/300\n",
            "34/34 [==============================] - 26s 699ms/step - loss: 1.4191 - acc: 0.3918 - val_loss: 1.2036 - val_acc: 0.3625\n",
            "Epoch 20/300\n",
            "34/34 [==============================] - 25s 690ms/step - loss: 1.4042 - acc: 0.4297 - val_loss: 1.2634 - val_acc: 0.3500\n",
            "Epoch 21/300\n",
            "34/34 [==============================] - 26s 714ms/step - loss: 1.4210 - acc: 0.4085 - val_loss: 1.3464 - val_acc: 0.2875\n",
            "Epoch 22/300\n",
            "34/34 [==============================] - 25s 692ms/step - loss: 1.2913 - acc: 0.4539 - val_loss: 1.2572 - val_acc: 0.3250\n",
            "Epoch 23/300\n",
            "34/34 [==============================] - 29s 764ms/step - loss: 1.4289 - acc: 0.4070 - val_loss: 1.2539 - val_acc: 0.3125\n",
            "Epoch 24/300\n",
            "34/34 [==============================] - 26s 700ms/step - loss: 1.4121 - acc: 0.3964 - val_loss: 1.2714 - val_acc: 0.3000\n",
            "Epoch 25/300\n",
            "34/34 [==============================] - 25s 688ms/step - loss: 1.3555 - acc: 0.4297 - val_loss: 1.2739 - val_acc: 0.2750\n",
            "Epoch 26/300\n",
            "34/34 [==============================] - 26s 697ms/step - loss: 1.3862 - acc: 0.3949 - val_loss: 1.2645 - val_acc: 0.3125\n",
            "Epoch 27/300\n",
            "34/34 [==============================] - 28s 719ms/step - loss: 1.3933 - acc: 0.4191 - val_loss: 1.2795 - val_acc: 0.2875\n",
            "Epoch 28/300\n",
            "34/34 [==============================] - 25s 689ms/step - loss: 1.3356 - acc: 0.4402 - val_loss: 1.2388 - val_acc: 0.2875\n",
            "Epoch 29/300\n",
            "34/34 [==============================] - 25s 691ms/step - loss: 1.3277 - acc: 0.4281 - val_loss: 1.3502 - val_acc: 0.2500\n",
            "Epoch 30/300\n",
            "34/34 [==============================] - 26s 700ms/step - loss: 1.2940 - acc: 0.4539 - val_loss: 1.2265 - val_acc: 0.3000\n",
            "Epoch 31/300\n",
            "34/34 [==============================] - 26s 714ms/step - loss: 1.3713 - acc: 0.4312 - val_loss: 1.2620 - val_acc: 0.3125\n",
            "Epoch 32/300\n",
            "34/34 [==============================] - 26s 717ms/step - loss: 1.2858 - acc: 0.4569 - val_loss: 1.2323 - val_acc: 0.3125\n",
            "Epoch 33/300\n",
            "34/34 [==============================] - 28s 760ms/step - loss: 1.3495 - acc: 0.4418 - val_loss: 1.2147 - val_acc: 0.2750\n",
            "Epoch 34/300\n",
            "34/34 [==============================] - 26s 712ms/step - loss: 1.3335 - acc: 0.4327 - val_loss: 1.1897 - val_acc: 0.3375\n",
            "Epoch 35/300\n",
            "34/34 [==============================] - 26s 707ms/step - loss: 1.2906 - acc: 0.4312 - val_loss: 1.2210 - val_acc: 0.3375\n",
            "Epoch 36/300\n",
            "34/34 [==============================] - 26s 708ms/step - loss: 1.2866 - acc: 0.4418 - val_loss: 1.1613 - val_acc: 0.3125\n",
            "Epoch 37/300\n",
            "34/34 [==============================] - 26s 711ms/step - loss: 1.3745 - acc: 0.4281 - val_loss: 1.2007 - val_acc: 0.3375\n",
            "Epoch 38/300\n",
            "34/34 [==============================] - 28s 772ms/step - loss: 1.3033 - acc: 0.4584 - val_loss: 1.2069 - val_acc: 0.3000\n",
            "Epoch 39/300\n",
            "34/34 [==============================] - 26s 708ms/step - loss: 1.3408 - acc: 0.4357 - val_loss: 1.2349 - val_acc: 0.3250\n",
            "Epoch 40/300\n",
            "34/34 [==============================] - 26s 708ms/step - loss: 1.3065 - acc: 0.4448 - val_loss: 1.2816 - val_acc: 0.2625\n",
            "Epoch 41/300\n",
            "34/34 [==============================] - 26s 696ms/step - loss: 1.3527 - acc: 0.4342 - val_loss: 1.2251 - val_acc: 0.2625\n",
            "Epoch 42/300\n",
            "34/34 [==============================] - 28s 753ms/step - loss: 1.3291 - acc: 0.4357 - val_loss: 1.1809 - val_acc: 0.3125\n",
            "Epoch 43/300\n",
            "34/34 [==============================] - 25s 674ms/step - loss: 1.2399 - acc: 0.4418 - val_loss: 1.2310 - val_acc: 0.3125\n",
            "Epoch 44/300\n",
            "34/34 [==============================] - 27s 730ms/step - loss: 1.2500 - acc: 0.4523 - val_loss: 1.3207 - val_acc: 0.2500\n",
            "Epoch 45/300\n",
            "34/34 [==============================] - 25s 677ms/step - loss: 1.3222 - acc: 0.4569 - val_loss: 1.2138 - val_acc: 0.3250\n",
            "Epoch 46/300\n",
            "34/34 [==============================] - 25s 678ms/step - loss: 1.2874 - acc: 0.4554 - val_loss: 1.2958 - val_acc: 0.2500\n",
            "Epoch 47/300\n",
            "34/34 [==============================] - 25s 682ms/step - loss: 1.3239 - acc: 0.4463 - val_loss: 1.2160 - val_acc: 0.3375\n",
            "Epoch 48/300\n",
            "34/34 [==============================] - 25s 676ms/step - loss: 1.3052 - acc: 0.4402 - val_loss: 1.2171 - val_acc: 0.2875\n",
            "Epoch 49/300\n",
            "34/34 [==============================] - 25s 676ms/step - loss: 1.3151 - acc: 0.4342 - val_loss: 1.2947 - val_acc: 0.3000\n",
            "Epoch 50/300\n",
            "34/34 [==============================] - 26s 719ms/step - loss: 1.2633 - acc: 0.4387 - val_loss: 1.1727 - val_acc: 0.3750\n",
            "Epoch 51/300\n",
            "34/34 [==============================] - 25s 673ms/step - loss: 1.2144 - acc: 0.4629 - val_loss: 1.2296 - val_acc: 0.3250\n",
            "Epoch 52/300\n",
            "34/34 [==============================] - 25s 698ms/step - loss: 1.2084 - acc: 0.4781 - val_loss: 1.2262 - val_acc: 0.3125\n",
            "Epoch 53/300\n",
            "34/34 [==============================] - 26s 690ms/step - loss: 1.1696 - acc: 0.4917 - val_loss: 1.1836 - val_acc: 0.3375\n",
            "Epoch 54/300\n",
            "34/34 [==============================] - 26s 714ms/step - loss: 1.2175 - acc: 0.4690 - val_loss: 1.2165 - val_acc: 0.3250\n",
            "Epoch 55/300\n",
            "34/34 [==============================] - 26s 710ms/step - loss: 1.2028 - acc: 0.4902 - val_loss: 1.2620 - val_acc: 0.2875\n",
            "Epoch 56/300\n",
            "34/34 [==============================] - 26s 710ms/step - loss: 1.3255 - acc: 0.4523 - val_loss: 1.1855 - val_acc: 0.3625\n",
            "Epoch 57/300\n",
            "34/34 [==============================] - 26s 711ms/step - loss: 1.1448 - acc: 0.5265 - val_loss: 1.2305 - val_acc: 0.3000\n",
            "Epoch 58/300\n",
            "34/34 [==============================] - 26s 718ms/step - loss: 1.2421 - acc: 0.4675 - val_loss: 1.2532 - val_acc: 0.3000\n",
            "Epoch 59/300\n",
            "34/34 [==============================] - 26s 720ms/step - loss: 1.1918 - acc: 0.4917 - val_loss: 1.2645 - val_acc: 0.2875\n",
            "Epoch 60/300\n",
            "34/34 [==============================] - 26s 710ms/step - loss: 1.2237 - acc: 0.4644 - val_loss: 1.1936 - val_acc: 0.3500\n",
            "Epoch 61/300\n",
            "34/34 [==============================] - 26s 713ms/step - loss: 1.2084 - acc: 0.4735 - val_loss: 1.2417 - val_acc: 0.3125\n",
            "Epoch 62/300\n",
            "34/34 [==============================] - 26s 714ms/step - loss: 1.1975 - acc: 0.4750 - val_loss: 1.2484 - val_acc: 0.3125\n",
            "Epoch 63/300\n",
            "34/34 [==============================] - 27s 726ms/step - loss: 1.1884 - acc: 0.4871 - val_loss: 1.2525 - val_acc: 0.3250\n",
            "Epoch 64/300\n",
            "34/34 [==============================] - 27s 724ms/step - loss: 1.1639 - acc: 0.4932 - val_loss: 1.2227 - val_acc: 0.3375\n",
            "Epoch 65/300\n",
            "34/34 [==============================] - 27s 726ms/step - loss: 1.2136 - acc: 0.4811 - val_loss: 1.2243 - val_acc: 0.3250\n",
            "Epoch 66/300\n",
            "34/34 [==============================] - 26s 708ms/step - loss: 1.1895 - acc: 0.4826 - val_loss: 1.1992 - val_acc: 0.3500\n",
            "Epoch 67/300\n",
            "34/34 [==============================] - 26s 715ms/step - loss: 1.2300 - acc: 0.4584 - val_loss: 1.0851 - val_acc: 0.4250\n",
            "Epoch 68/300\n",
            "34/34 [==============================] - 26s 718ms/step - loss: 1.2105 - acc: 0.4569 - val_loss: 1.2327 - val_acc: 0.3375\n",
            "Epoch 69/300\n",
            "34/34 [==============================] - 26s 718ms/step - loss: 1.1349 - acc: 0.5098 - val_loss: 1.2014 - val_acc: 0.3750\n",
            "Epoch 70/300\n",
            "34/34 [==============================] - 26s 718ms/step - loss: 1.2771 - acc: 0.4539 - val_loss: 1.1415 - val_acc: 0.4000\n",
            "Epoch 71/300\n",
            "34/34 [==============================] - 27s 724ms/step - loss: 1.1807 - acc: 0.4856 - val_loss: 1.1665 - val_acc: 0.3875\n",
            "Epoch 72/300\n",
            "34/34 [==============================] - 29s 785ms/step - loss: 1.1473 - acc: 0.4766 - val_loss: 1.1315 - val_acc: 0.3875\n",
            "Epoch 73/300\n",
            "34/34 [==============================] - 26s 720ms/step - loss: 1.1281 - acc: 0.4902 - val_loss: 1.1988 - val_acc: 0.3750\n",
            "Epoch 74/300\n",
            "34/34 [==============================] - 27s 721ms/step - loss: 1.1511 - acc: 0.4720 - val_loss: 1.1916 - val_acc: 0.3625\n",
            "Epoch 75/300\n",
            "34/34 [==============================] - 26s 722ms/step - loss: 1.1747 - acc: 0.4720 - val_loss: 1.1757 - val_acc: 0.4125\n",
            "Epoch 76/300\n",
            "34/34 [==============================] - 26s 715ms/step - loss: 1.1958 - acc: 0.4871 - val_loss: 1.1434 - val_acc: 0.4000\n",
            "Epoch 77/300\n",
            "34/34 [==============================] - 25s 756ms/step - loss: 1.2185 - acc: 0.4599 - val_loss: 1.2216 - val_acc: 0.3375\n",
            "Epoch 78/300\n",
            "34/34 [==============================] - 27s 749ms/step - loss: 1.1937 - acc: 0.4720 - val_loss: 1.2369 - val_acc: 0.3500\n",
            "Epoch 79/300\n",
            "34/34 [==============================] - 25s 681ms/step - loss: 1.1863 - acc: 0.4871 - val_loss: 1.1807 - val_acc: 0.3750\n",
            "Epoch 80/300\n",
            "34/34 [==============================] - 25s 694ms/step - loss: 1.2299 - acc: 0.4554 - val_loss: 1.1707 - val_acc: 0.3750\n",
            "Epoch 81/300\n",
            "34/34 [==============================] - 25s 683ms/step - loss: 1.1404 - acc: 0.4887 - val_loss: 1.2157 - val_acc: 0.3625\n",
            "Epoch 82/300\n",
            "34/34 [==============================] - 25s 678ms/step - loss: 1.1272 - acc: 0.4887 - val_loss: 1.1199 - val_acc: 0.4250\n",
            "Epoch 83/300\n",
            "34/34 [==============================] - 24s 660ms/step - loss: 1.0996 - acc: 0.5068 - val_loss: 1.2306 - val_acc: 0.3375\n",
            "Epoch 84/300\n",
            "34/34 [==============================] - 26s 716ms/step - loss: 1.1485 - acc: 0.5023 - val_loss: 1.1723 - val_acc: 0.3875\n",
            "Epoch 85/300\n",
            "34/34 [==============================] - 26s 690ms/step - loss: 1.1529 - acc: 0.4902 - val_loss: 1.1586 - val_acc: 0.3625\n",
            "Epoch 86/300\n",
            "34/34 [==============================] - 24s 666ms/step - loss: 1.1566 - acc: 0.4962 - val_loss: 1.1845 - val_acc: 0.3875\n",
            "Epoch 87/300\n",
            "34/34 [==============================] - 24s 667ms/step - loss: 1.1467 - acc: 0.4977 - val_loss: 1.1510 - val_acc: 0.3750\n",
            "Epoch 88/300\n",
            "34/34 [==============================] - 24s 665ms/step - loss: 1.1891 - acc: 0.4856 - val_loss: 1.1252 - val_acc: 0.3750\n",
            "Epoch 89/300\n",
            "34/34 [==============================] - 26s 707ms/step - loss: 1.0972 - acc: 0.5144 - val_loss: 1.1746 - val_acc: 0.3750\n",
            "Epoch 90/300\n",
            "34/34 [==============================] - 25s 680ms/step - loss: 1.1283 - acc: 0.5053 - val_loss: 1.1696 - val_acc: 0.3750\n",
            "Epoch 91/300\n",
            "34/34 [==============================] - 24s 664ms/step - loss: 1.1875 - acc: 0.4675 - val_loss: 1.1148 - val_acc: 0.4125\n",
            "Epoch 92/300\n",
            "34/34 [==============================] - 24s 653ms/step - loss: 1.2195 - acc: 0.4599 - val_loss: 1.1762 - val_acc: 0.3875\n",
            "Epoch 93/300\n",
            "34/34 [==============================] - 24s 664ms/step - loss: 1.1314 - acc: 0.5144 - val_loss: 1.1448 - val_acc: 0.4000\n",
            "Epoch 94/300\n",
            "34/34 [==============================] - 24s 658ms/step - loss: 1.1304 - acc: 0.4962 - val_loss: 1.2051 - val_acc: 0.3750\n",
            "Epoch 95/300\n",
            "34/34 [==============================] - 24s 653ms/step - loss: 1.1641 - acc: 0.4932 - val_loss: 1.0933 - val_acc: 0.4250\n",
            "Epoch 96/300\n",
            "34/34 [==============================] - 24s 667ms/step - loss: 1.1153 - acc: 0.5053 - val_loss: 1.1073 - val_acc: 0.3875\n",
            "Epoch 97/300\n",
            "34/34 [==============================] - 24s 663ms/step - loss: 1.1426 - acc: 0.5038 - val_loss: 1.1564 - val_acc: 0.3875\n",
            "Epoch 98/300\n",
            "34/34 [==============================] - 25s 672ms/step - loss: 1.1187 - acc: 0.5279 - val_loss: 1.0731 - val_acc: 0.4500\n",
            "Epoch 99/300\n",
            "34/34 [==============================] - 24s 655ms/step - loss: 1.1439 - acc: 0.5008 - val_loss: 1.2132 - val_acc: 0.3750\n",
            "Epoch 100/300\n",
            "34/34 [==============================] - 24s 726ms/step - loss: 1.1392 - acc: 0.4977 - val_loss: 1.1708 - val_acc: 0.3625\n",
            "Epoch 101/300\n",
            "34/34 [==============================] - 24s 659ms/step - loss: 1.1057 - acc: 0.5053 - val_loss: 1.1780 - val_acc: 0.3750\n",
            "Epoch 102/300\n",
            "34/34 [==============================] - 24s 663ms/step - loss: 1.1001 - acc: 0.5189 - val_loss: 1.1912 - val_acc: 0.3875\n",
            "Epoch 103/300\n",
            "34/34 [==============================] - 24s 662ms/step - loss: 1.0969 - acc: 0.5477 - val_loss: 1.2423 - val_acc: 0.3375\n",
            "Epoch 104/300\n",
            "34/34 [==============================] - 24s 669ms/step - loss: 1.1533 - acc: 0.4841 - val_loss: 1.2149 - val_acc: 0.3750\n",
            "Epoch 105/300\n",
            "34/34 [==============================] - 24s 664ms/step - loss: 1.1349 - acc: 0.5038 - val_loss: 1.2488 - val_acc: 0.3375\n",
            "Epoch 106/300\n",
            "34/34 [==============================] - 26s 694ms/step - loss: 1.0826 - acc: 0.5159 - val_loss: 1.1535 - val_acc: 0.4000\n",
            "Epoch 107/300\n",
            "34/34 [==============================] - 25s 673ms/step - loss: 1.1376 - acc: 0.5008 - val_loss: 1.1886 - val_acc: 0.3375\n",
            "Epoch 108/300\n",
            "34/34 [==============================] - 24s 661ms/step - loss: 1.1618 - acc: 0.5098 - val_loss: 1.1455 - val_acc: 0.3875\n",
            "Epoch 109/300\n",
            "34/34 [==============================] - 24s 641ms/step - loss: 1.1108 - acc: 0.5204 - val_loss: 1.1542 - val_acc: 0.3625\n",
            "Epoch 110/300\n",
            "34/34 [==============================] - 24s 659ms/step - loss: 1.0839 - acc: 0.5189 - val_loss: 1.1567 - val_acc: 0.3625\n",
            "Epoch 111/300\n",
            "34/34 [==============================] - 26s 722ms/step - loss: 1.1091 - acc: 0.5023 - val_loss: 1.1658 - val_acc: 0.3625\n",
            "Epoch 112/300\n",
            "34/34 [==============================] - 24s 655ms/step - loss: 1.0599 - acc: 0.5492 - val_loss: 1.1276 - val_acc: 0.4125\n",
            "Epoch 113/300\n",
            "34/34 [==============================] - 24s 638ms/step - loss: 1.1712 - acc: 0.5053 - val_loss: 1.2005 - val_acc: 0.3750\n",
            "Epoch 114/300\n",
            "34/34 [==============================] - 24s 652ms/step - loss: 1.0767 - acc: 0.5068 - val_loss: 1.1929 - val_acc: 0.3750\n",
            "Epoch 115/300\n",
            "34/34 [==============================] - 24s 653ms/step - loss: 1.0485 - acc: 0.5416 - val_loss: 1.2229 - val_acc: 0.3500\n",
            "Epoch 116/300\n",
            "34/34 [==============================] - 24s 655ms/step - loss: 1.1159 - acc: 0.5189 - val_loss: 1.1591 - val_acc: 0.3875\n",
            "Epoch 117/300\n",
            "34/34 [==============================] - 26s 719ms/step - loss: 1.0809 - acc: 0.5356 - val_loss: 1.2005 - val_acc: 0.3500\n",
            "Epoch 118/300\n",
            "34/34 [==============================] - 24s 662ms/step - loss: 1.0808 - acc: 0.5265 - val_loss: 1.1674 - val_acc: 0.4000\n",
            "Epoch 119/300\n",
            "34/34 [==============================] - 23s 637ms/step - loss: 1.1159 - acc: 0.5250 - val_loss: 1.2779 - val_acc: 0.3500\n",
            "Epoch 120/300\n",
            "34/34 [==============================] - 23s 634ms/step - loss: 1.0761 - acc: 0.5567 - val_loss: 1.1836 - val_acc: 0.4000\n",
            "Epoch 121/300\n",
            "34/34 [==============================] - 22s 603ms/step - loss: 1.1269 - acc: 0.4962 - val_loss: 1.1318 - val_acc: 0.4000\n",
            "Epoch 122/300\n",
            "34/34 [==============================] - 24s 641ms/step - loss: 1.1032 - acc: 0.5401 - val_loss: 1.2093 - val_acc: 0.3125\n",
            "Epoch 123/300\n",
            "34/34 [==============================] - 26s 705ms/step - loss: 1.1585 - acc: 0.5098 - val_loss: 1.1937 - val_acc: 0.3625\n",
            "Epoch 124/300\n",
            "34/34 [==============================] - 23s 637ms/step - loss: 1.1048 - acc: 0.5159 - val_loss: 1.1723 - val_acc: 0.3625\n",
            "Epoch 125/300\n",
            "34/34 [==============================] - 23s 638ms/step - loss: 1.0423 - acc: 0.5356 - val_loss: 1.1760 - val_acc: 0.3500\n",
            "Epoch 126/300\n",
            "34/34 [==============================] - 24s 648ms/step - loss: 0.9883 - acc: 0.5703 - val_loss: 1.1805 - val_acc: 0.4000\n",
            "Epoch 127/300\n",
            "34/34 [==============================] - 24s 637ms/step - loss: 1.0667 - acc: 0.5204 - val_loss: 1.2201 - val_acc: 0.3750\n",
            "Epoch 128/300\n",
            "34/34 [==============================] - 23s 620ms/step - loss: 1.0836 - acc: 0.5129 - val_loss: 1.1918 - val_acc: 0.3875\n",
            "Epoch 129/300\n",
            "34/34 [==============================] - 26s 705ms/step - loss: 1.1062 - acc: 0.5189 - val_loss: 1.2948 - val_acc: 0.3000\n",
            "Epoch 130/300\n",
            "34/34 [==============================] - 23s 636ms/step - loss: 1.1264 - acc: 0.4992 - val_loss: 1.1967 - val_acc: 0.3875\n",
            "Epoch 131/300\n",
            "34/34 [==============================] - 23s 623ms/step - loss: 1.1265 - acc: 0.5098 - val_loss: 1.1416 - val_acc: 0.4250\n",
            "Epoch 132/300\n",
            "34/34 [==============================] - 23s 633ms/step - loss: 1.0430 - acc: 0.5356 - val_loss: 1.1343 - val_acc: 0.4000\n",
            "Epoch 133/300\n",
            "34/34 [==============================] - 24s 671ms/step - loss: 1.0407 - acc: 0.5280 - val_loss: 1.1714 - val_acc: 0.3750\n",
            "Epoch 134/300\n",
            "34/34 [==============================] - 24s 643ms/step - loss: 1.1455 - acc: 0.5204 - val_loss: 1.1108 - val_acc: 0.4000\n",
            "Epoch 135/300\n",
            "34/34 [==============================] - 24s 651ms/step - loss: 1.0701 - acc: 0.5356 - val_loss: 1.2297 - val_acc: 0.3375\n",
            "Epoch 136/300\n",
            "34/34 [==============================] - 24s 658ms/step - loss: 1.0960 - acc: 0.5280 - val_loss: 1.2070 - val_acc: 0.3625\n",
            "Epoch 137/300\n",
            "34/34 [==============================] - 24s 650ms/step - loss: 1.1113 - acc: 0.5083 - val_loss: 1.1215 - val_acc: 0.4250\n",
            "Epoch 138/300\n",
            "34/34 [==============================] - 25s 695ms/step - loss: 1.0128 - acc: 0.5567 - val_loss: 1.1314 - val_acc: 0.4000\n",
            "Epoch 139/300\n",
            "34/34 [==============================] - 23s 633ms/step - loss: 1.0948 - acc: 0.5144 - val_loss: 1.2077 - val_acc: 0.3625\n",
            "Epoch 140/300\n",
            "34/34 [==============================] - 23s 632ms/step - loss: 1.0511 - acc: 0.5265 - val_loss: 1.1828 - val_acc: 0.3750\n",
            "Epoch 141/300\n",
            "34/34 [==============================] - 25s 690ms/step - loss: 1.0763 - acc: 0.5265 - val_loss: 1.1807 - val_acc: 0.3500\n",
            "Epoch 142/300\n",
            "34/34 [==============================] - 25s 669ms/step - loss: 1.0050 - acc: 0.5507 - val_loss: 1.2085 - val_acc: 0.3375\n",
            "Epoch 143/300\n",
            "34/34 [==============================] - 24s 655ms/step - loss: 1.1016 - acc: 0.5144 - val_loss: 1.2164 - val_acc: 0.3250\n",
            "Epoch 144/300\n",
            "34/34 [==============================] - 24s 653ms/step - loss: 1.0907 - acc: 0.5446 - val_loss: 1.1180 - val_acc: 0.4375\n",
            "Epoch 145/300\n",
            "34/34 [==============================] - 26s 714ms/step - loss: 1.0700 - acc: 0.5477 - val_loss: 1.1978 - val_acc: 0.3625\n",
            "Epoch 146/300\n",
            "34/34 [==============================] - 24s 654ms/step - loss: 1.1273 - acc: 0.5113 - val_loss: 1.1599 - val_acc: 0.4250\n",
            "Epoch 147/300\n",
            "34/34 [==============================] - 24s 666ms/step - loss: 1.0464 - acc: 0.5382 - val_loss: 1.1037 - val_acc: 0.3750\n",
            "Epoch 148/300\n",
            "34/34 [==============================] - 25s 675ms/step - loss: 1.0655 - acc: 0.5189 - val_loss: 1.1519 - val_acc: 0.4000\n",
            "Epoch 149/300\n",
            "34/34 [==============================] - 24s 657ms/step - loss: 1.0672 - acc: 0.5159 - val_loss: 1.2013 - val_acc: 0.3750\n",
            "Epoch 150/300\n",
            "34/34 [==============================] - 24s 655ms/step - loss: 1.0081 - acc: 0.5582 - val_loss: 1.2352 - val_acc: 0.3750\n",
            "Epoch 151/300\n",
            "34/34 [==============================] - 25s 673ms/step - loss: 1.1283 - acc: 0.5053 - val_loss: 1.1858 - val_acc: 0.3875\n",
            "Epoch 152/300\n",
            "34/34 [==============================] - 25s 673ms/step - loss: 1.0196 - acc: 0.5537 - val_loss: 1.2869 - val_acc: 0.3000\n",
            "Epoch 153/300\n",
            "34/34 [==============================] - 27s 721ms/step - loss: 1.1418 - acc: 0.5113 - val_loss: 1.1867 - val_acc: 0.3500\n",
            "Epoch 154/300\n",
            "34/34 [==============================] - 26s 698ms/step - loss: 1.0399 - acc: 0.5371 - val_loss: 1.2356 - val_acc: 0.3625\n",
            "Epoch 155/300\n",
            "34/34 [==============================] - 25s 685ms/step - loss: 1.0632 - acc: 0.5386 - val_loss: 1.1578 - val_acc: 0.3750\n",
            "Epoch 156/300\n",
            "34/34 [==============================] - 26s 714ms/step - loss: 0.9995 - acc: 0.5613 - val_loss: 1.1175 - val_acc: 0.4000\n",
            "Epoch 157/300\n",
            "34/34 [==============================] - 25s 679ms/step - loss: 1.0291 - acc: 0.5461 - val_loss: 1.1390 - val_acc: 0.3750\n",
            "Epoch 158/300\n",
            "34/34 [==============================] - 25s 697ms/step - loss: 1.0591 - acc: 0.5250 - val_loss: 1.2049 - val_acc: 0.3625\n",
            "Epoch 159/300\n",
            "34/34 [==============================] - 26s 704ms/step - loss: 1.0198 - acc: 0.5386 - val_loss: 1.2172 - val_acc: 0.3625\n",
            "Epoch 160/300\n",
            "34/34 [==============================] - 25s 680ms/step - loss: 1.0352 - acc: 0.5673 - val_loss: 1.1354 - val_acc: 0.3875\n",
            "Epoch 161/300\n",
            "34/34 [==============================] - 27s 710ms/step - loss: 1.0272 - acc: 0.5643 - val_loss: 1.1847 - val_acc: 0.3750\n",
            "Epoch 162/300\n",
            "34/34 [==============================] - 26s 696ms/step - loss: 1.0657 - acc: 0.5265 - val_loss: 1.2646 - val_acc: 0.3125\n",
            "Epoch 163/300\n",
            "34/34 [==============================] - 26s 787ms/step - loss: 1.0489 - acc: 0.5234 - val_loss: 1.2258 - val_acc: 0.3375\n",
            "Epoch 164/300\n",
            "34/34 [==============================] - 26s 704ms/step - loss: 1.0261 - acc: 0.5507 - val_loss: 1.2661 - val_acc: 0.3125\n",
            "Epoch 165/300\n",
            "34/34 [==============================] - 25s 670ms/step - loss: 0.9864 - acc: 0.5643 - val_loss: 1.2345 - val_acc: 0.3750\n",
            "Epoch 166/300\n",
            "34/34 [==============================] - 26s 661ms/step - loss: 1.0261 - acc: 0.5250 - val_loss: 1.2877 - val_acc: 0.3000\n",
            "Epoch 167/300\n",
            "34/34 [==============================] - 25s 668ms/step - loss: 1.0271 - acc: 0.5507 - val_loss: 1.2891 - val_acc: 0.3125\n",
            "Epoch 168/300\n",
            "34/34 [==============================] - 25s 679ms/step - loss: 1.0153 - acc: 0.5492 - val_loss: 1.2168 - val_acc: 0.3500\n",
            "Epoch 169/300\n",
            "34/34 [==============================] - 24s 656ms/step - loss: 1.0780 - acc: 0.5522 - val_loss: 1.2532 - val_acc: 0.3125\n",
            "Epoch 170/300\n",
            "34/34 [==============================] - 25s 672ms/step - loss: 1.0021 - acc: 0.5688 - val_loss: 1.1765 - val_acc: 0.3625\n",
            "Epoch 171/300\n",
            "34/34 [==============================] - 25s 691ms/step - loss: 1.0119 - acc: 0.5477 - val_loss: 1.2329 - val_acc: 0.3250\n",
            "Epoch 172/300\n",
            "34/34 [==============================] - 26s 698ms/step - loss: 0.9715 - acc: 0.5794 - val_loss: 1.2433 - val_acc: 0.3125\n",
            "Epoch 173/300\n",
            "34/34 [==============================] - 26s 701ms/step - loss: 1.0347 - acc: 0.5673 - val_loss: 1.1573 - val_acc: 0.3875\n",
            "Epoch 174/300\n",
            "34/34 [==============================] - 25s 666ms/step - loss: 0.9827 - acc: 0.5749 - val_loss: 1.1858 - val_acc: 0.3750\n",
            "Epoch 175/300\n",
            "34/34 [==============================] - 25s 666ms/step - loss: 1.0219 - acc: 0.5794 - val_loss: 1.2241 - val_acc: 0.3750\n",
            "Epoch 176/300\n",
            "34/34 [==============================] - 27s 741ms/step - loss: 0.9923 - acc: 0.5750 - val_loss: 1.2114 - val_acc: 0.3625\n",
            "Epoch 177/300\n",
            "34/34 [==============================] - 24s 646ms/step - loss: 0.9986 - acc: 0.5582 - val_loss: 1.1689 - val_acc: 0.3750\n",
            "Epoch 178/300\n",
            "34/34 [==============================] - 24s 643ms/step - loss: 1.0022 - acc: 0.5537 - val_loss: 1.1989 - val_acc: 0.3875\n",
            "Epoch 179/300\n",
            "34/34 [==============================] - 24s 646ms/step - loss: 1.0255 - acc: 0.5386 - val_loss: 1.1978 - val_acc: 0.3625\n",
            "Epoch 180/300\n",
            "34/34 [==============================] - 24s 651ms/step - loss: 1.0616 - acc: 0.5204 - val_loss: 1.2012 - val_acc: 0.3750\n",
            "Epoch 181/300\n",
            "34/34 [==============================] - 24s 653ms/step - loss: 0.9903 - acc: 0.5840 - val_loss: 1.2732 - val_acc: 0.3125\n",
            "Epoch 182/300\n",
            "34/34 [==============================] - 24s 642ms/step - loss: 0.9985 - acc: 0.5749 - val_loss: 1.1678 - val_acc: 0.4000\n",
            "Epoch 183/300\n",
            "34/34 [==============================] - 24s 644ms/step - loss: 0.9919 - acc: 0.5688 - val_loss: 1.2168 - val_acc: 0.3375\n",
            "Epoch 184/300\n",
            "34/34 [==============================] - 23s 638ms/step - loss: 1.0228 - acc: 0.5265 - val_loss: 1.2598 - val_acc: 0.3250\n",
            "Epoch 185/300\n",
            "34/34 [==============================] - 24s 660ms/step - loss: 1.0388 - acc: 0.5461 - val_loss: 1.2066 - val_acc: 0.3625\n",
            "Epoch 186/300\n",
            "34/34 [==============================] - 24s 653ms/step - loss: 1.0506 - acc: 0.5371 - val_loss: 1.1896 - val_acc: 0.3750\n",
            "Epoch 187/300\n",
            "34/34 [==============================] - 24s 647ms/step - loss: 1.0150 - acc: 0.5204 - val_loss: 1.2423 - val_acc: 0.3500\n",
            "Epoch 188/300\n",
            "34/34 [==============================] - 24s 642ms/step - loss: 1.0563 - acc: 0.5461 - val_loss: 1.1467 - val_acc: 0.3750\n",
            "Epoch 189/300\n",
            "34/34 [==============================] - 23s 624ms/step - loss: 1.0017 - acc: 0.5582 - val_loss: 1.2086 - val_acc: 0.3875\n",
            "Epoch 190/300\n",
            "34/34 [==============================] - 23s 612ms/step - loss: 0.9728 - acc: 0.5688 - val_loss: 1.2468 - val_acc: 0.3375\n",
            "Epoch 191/300\n",
            "34/34 [==============================] - 23s 614ms/step - loss: 0.9754 - acc: 0.5825 - val_loss: 1.1674 - val_acc: 0.3750\n",
            "Epoch 192/300\n",
            "34/34 [==============================] - 23s 635ms/step - loss: 1.0693 - acc: 0.5310 - val_loss: 1.1531 - val_acc: 0.4000\n",
            "Epoch 193/300\n",
            "34/34 [==============================] - 23s 626ms/step - loss: 1.0395 - acc: 0.5310 - val_loss: 1.2075 - val_acc: 0.3500\n",
            "Epoch 194/300\n",
            "34/34 [==============================] - 23s 623ms/step - loss: 1.0025 - acc: 0.5522 - val_loss: 1.2010 - val_acc: 0.3500\n",
            "Epoch 195/300\n",
            "34/34 [==============================] - 23s 633ms/step - loss: 1.0341 - acc: 0.5446 - val_loss: 1.2274 - val_acc: 0.3750\n",
            "Epoch 196/300\n",
            "34/34 [==============================] - 23s 636ms/step - loss: 0.9332 - acc: 0.5855 - val_loss: 1.2022 - val_acc: 0.3500\n",
            "Epoch 197/300\n",
            "34/34 [==============================] - 24s 648ms/step - loss: 1.0461 - acc: 0.5416 - val_loss: 1.1917 - val_acc: 0.3625\n",
            "Epoch 198/300\n",
            "34/34 [==============================] - 23s 638ms/step - loss: 0.9762 - acc: 0.5552 - val_loss: 1.1680 - val_acc: 0.3375\n",
            "Epoch 199/300\n",
            "34/34 [==============================] - 23s 636ms/step - loss: 1.0083 - acc: 0.5461 - val_loss: 1.1679 - val_acc: 0.3750\n",
            "Epoch 200/300\n",
            "34/34 [==============================] - 24s 631ms/step - loss: 0.9948 - acc: 0.5552 - val_loss: 1.2834 - val_acc: 0.3000\n",
            "Epoch 201/300\n",
            "34/34 [==============================] - 23s 629ms/step - loss: 0.9737 - acc: 0.5734 - val_loss: 1.2615 - val_acc: 0.3125\n",
            "Epoch 202/300\n",
            "34/34 [==============================] - 23s 628ms/step - loss: 0.9845 - acc: 0.5628 - val_loss: 1.2204 - val_acc: 0.3750\n",
            "Epoch 203/300\n",
            "34/34 [==============================] - 23s 633ms/step - loss: 1.0069 - acc: 0.5719 - val_loss: 1.1754 - val_acc: 0.3875\n",
            "Epoch 204/300\n",
            "34/34 [==============================] - 25s 673ms/step - loss: 1.0149 - acc: 0.5537 - val_loss: 1.1840 - val_acc: 0.3500\n",
            "Epoch 205/300\n",
            "34/34 [==============================] - 25s 697ms/step - loss: 0.9766 - acc: 0.5734 - val_loss: 1.1372 - val_acc: 0.3875\n",
            "Epoch 206/300\n",
            "34/34 [==============================] - 24s 642ms/step - loss: 0.9862 - acc: 0.5552 - val_loss: 1.2882 - val_acc: 0.3375\n",
            "Epoch 207/300\n",
            "34/34 [==============================] - 24s 649ms/step - loss: 1.0215 - acc: 0.5310 - val_loss: 1.2402 - val_acc: 0.3375\n",
            "Epoch 208/300\n",
            "34/34 [==============================] - 26s 698ms/step - loss: 1.0116 - acc: 0.5673 - val_loss: 1.1804 - val_acc: 0.3875\n",
            "Epoch 209/300\n",
            "34/34 [==============================] - 25s 694ms/step - loss: 0.9562 - acc: 0.5825 - val_loss: 1.2463 - val_acc: 0.3125\n",
            "Epoch 210/300\n",
            "34/34 [==============================] - 25s 679ms/step - loss: 0.9227 - acc: 0.6006 - val_loss: 1.2862 - val_acc: 0.2875\n",
            "Epoch 211/300\n",
            "34/34 [==============================] - 29s 772ms/step - loss: 0.9228 - acc: 0.6021 - val_loss: 1.1543 - val_acc: 0.4000\n",
            "Epoch 212/300\n",
            "34/34 [==============================] - 27s 722ms/step - loss: 0.9542 - acc: 0.5613 - val_loss: 1.1914 - val_acc: 0.4125\n",
            "Epoch 213/300\n",
            "34/34 [==============================] - 26s 722ms/step - loss: 0.9381 - acc: 0.5885 - val_loss: 1.2473 - val_acc: 0.3125\n",
            "Epoch 214/300\n",
            "34/34 [==============================] - 27s 721ms/step - loss: 0.9319 - acc: 0.5764 - val_loss: 1.1792 - val_acc: 0.3750\n",
            "Epoch 215/300\n",
            "34/34 [==============================] - 26s 713ms/step - loss: 0.9499 - acc: 0.5825 - val_loss: 1.2446 - val_acc: 0.3125\n",
            "Epoch 216/300\n",
            "34/34 [==============================] - 28s 738ms/step - loss: 0.9948 - acc: 0.5582 - val_loss: 1.2067 - val_acc: 0.3625\n",
            "Epoch 217/300\n",
            "34/34 [==============================] - 26s 706ms/step - loss: 0.9382 - acc: 0.5658 - val_loss: 1.1465 - val_acc: 0.4000\n",
            "Epoch 218/300\n",
            "34/34 [==============================] - 26s 713ms/step - loss: 1.0118 - acc: 0.5628 - val_loss: 1.2395 - val_acc: 0.3750\n",
            "Epoch 219/300\n",
            "34/34 [==============================] - 26s 721ms/step - loss: 0.9970 - acc: 0.5688 - val_loss: 1.1949 - val_acc: 0.3500\n",
            "Epoch 220/300\n",
            "34/34 [==============================] - 27s 746ms/step - loss: 0.9517 - acc: 0.5809 - val_loss: 1.1955 - val_acc: 0.3875\n",
            "Epoch 221/300\n",
            "34/34 [==============================] - 26s 704ms/step - loss: 0.9383 - acc: 0.5809 - val_loss: 1.1494 - val_acc: 0.4125\n",
            "Epoch 222/300\n",
            "34/34 [==============================] - 26s 708ms/step - loss: 0.9828 - acc: 0.5885 - val_loss: 1.2466 - val_acc: 0.3250\n",
            "Epoch 223/300\n",
            "34/34 [==============================] - 27s 718ms/step - loss: 0.9658 - acc: 0.5658 - val_loss: 1.1848 - val_acc: 0.3500\n",
            "Epoch 224/300\n",
            "34/34 [==============================] - 26s 708ms/step - loss: 1.0167 - acc: 0.5673 - val_loss: 1.3155 - val_acc: 0.2750\n",
            "Epoch 225/300\n",
            "34/34 [==============================] - 26s 703ms/step - loss: 0.9402 - acc: 0.5809 - val_loss: 1.1555 - val_acc: 0.3625\n",
            "Epoch 226/300\n",
            "34/34 [==============================] - 29s 790ms/step - loss: 0.9998 - acc: 0.5673 - val_loss: 1.2527 - val_acc: 0.3250\n",
            "Epoch 227/300\n",
            "34/34 [==============================] - 26s 671ms/step - loss: 0.9653 - acc: 0.5658 - val_loss: 1.2075 - val_acc: 0.3500\n",
            "Epoch 228/300\n",
            "34/34 [==============================] - 25s 677ms/step - loss: 0.9175 - acc: 0.6036 - val_loss: 1.2198 - val_acc: 0.3125\n",
            "Epoch 229/300\n",
            "34/34 [==============================] - 25s 677ms/step - loss: 0.9505 - acc: 0.6036 - val_loss: 1.2386 - val_acc: 0.3250\n",
            "Epoch 230/300\n",
            "34/34 [==============================] - 25s 671ms/step - loss: 0.9498 - acc: 0.5885 - val_loss: 1.2576 - val_acc: 0.3125\n",
            "Epoch 231/300\n",
            "34/34 [==============================] - 25s 671ms/step - loss: 0.9472 - acc: 0.5809 - val_loss: 1.1447 - val_acc: 0.3375\n",
            "Epoch 232/300\n",
            "34/34 [==============================] - 27s 735ms/step - loss: 0.9175 - acc: 0.5930 - val_loss: 1.1324 - val_acc: 0.3750\n",
            "Epoch 233/300\n",
            "34/34 [==============================] - 24s 665ms/step - loss: 1.0136 - acc: 0.5613 - val_loss: 1.2620 - val_acc: 0.3250\n",
            "Epoch 234/300\n",
            "34/34 [==============================] - 25s 672ms/step - loss: 0.9459 - acc: 0.6021 - val_loss: 1.2097 - val_acc: 0.3625\n",
            "Epoch 235/300\n",
            "34/34 [==============================] - 25s 670ms/step - loss: 0.9803 - acc: 0.5703 - val_loss: 1.2748 - val_acc: 0.3000\n",
            "Epoch 236/300\n",
            "34/34 [==============================] - 25s 676ms/step - loss: 0.9862 - acc: 0.5825 - val_loss: 1.2363 - val_acc: 0.3500\n",
            "Epoch 237/300\n",
            "34/34 [==============================] - 27s 743ms/step - loss: 0.9904 - acc: 0.5507 - val_loss: 1.2011 - val_acc: 0.3750\n",
            "Epoch 238/300\n",
            "34/34 [==============================] - 24s 659ms/step - loss: 0.9880 - acc: 0.5779 - val_loss: 1.1956 - val_acc: 0.3500\n",
            "Epoch 239/300\n",
            "34/34 [==============================] - 24s 645ms/step - loss: 0.9294 - acc: 0.5885 - val_loss: 1.2035 - val_acc: 0.3750\n",
            "Epoch 240/300\n",
            "34/34 [==============================] - 24s 658ms/step - loss: 0.9547 - acc: 0.5930 - val_loss: 1.2457 - val_acc: 0.3250\n",
            "Epoch 241/300\n",
            "34/34 [==============================] - 24s 665ms/step - loss: 0.9155 - acc: 0.5885 - val_loss: 1.2135 - val_acc: 0.3500\n",
            "Epoch 242/300\n",
            "34/34 [==============================] - 26s 721ms/step - loss: 0.9984 - acc: 0.5734 - val_loss: 1.1509 - val_acc: 0.4000\n",
            "Epoch 243/300\n",
            "34/34 [==============================] - 24s 646ms/step - loss: 0.9914 - acc: 0.5598 - val_loss: 1.2050 - val_acc: 0.3250\n",
            "Epoch 244/300\n",
            "34/34 [==============================] - 25s 675ms/step - loss: 0.9537 - acc: 0.5749 - val_loss: 1.1832 - val_acc: 0.3500\n",
            "Epoch 245/300\n",
            "34/34 [==============================] - 25s 682ms/step - loss: 0.9501 - acc: 0.5961 - val_loss: 1.2436 - val_acc: 0.3375\n",
            "Epoch 246/300\n",
            "34/34 [==============================] - 25s 676ms/step - loss: 0.9648 - acc: 0.5915 - val_loss: 1.2251 - val_acc: 0.3375\n",
            "Epoch 247/300\n",
            "34/34 [==============================] - 27s 742ms/step - loss: 0.9695 - acc: 0.5885 - val_loss: 1.2712 - val_acc: 0.3250\n",
            "Epoch 248/300\n",
            "34/34 [==============================] - 25s 668ms/step - loss: 0.9339 - acc: 0.5658 - val_loss: 1.1381 - val_acc: 0.4000\n",
            "Epoch 249/300\n",
            "34/34 [==============================] - 25s 671ms/step - loss: 0.9400 - acc: 0.5598 - val_loss: 1.1519 - val_acc: 0.3250\n",
            "Epoch 250/300\n",
            "34/34 [==============================] - 24s 640ms/step - loss: 0.9015 - acc: 0.6172 - val_loss: 1.1728 - val_acc: 0.3625\n",
            "Epoch 251/300\n",
            "34/34 [==============================] - 25s 669ms/step - loss: 0.8903 - acc: 0.5976 - val_loss: 1.2391 - val_acc: 0.3250\n",
            "Epoch 252/300\n",
            "34/34 [==============================] - 27s 744ms/step - loss: 0.9523 - acc: 0.5809 - val_loss: 1.2130 - val_acc: 0.3750\n",
            "Epoch 253/300\n",
            "34/34 [==============================] - 25s 687ms/step - loss: 0.9657 - acc: 0.5749 - val_loss: 1.1710 - val_acc: 0.3750\n",
            "Epoch 254/300\n",
            "34/34 [==============================] - 25s 678ms/step - loss: 0.9179 - acc: 0.6036 - val_loss: 1.2185 - val_acc: 0.4000\n",
            "Epoch 255/300\n",
            "34/34 [==============================] - 25s 671ms/step - loss: 1.0014 - acc: 0.5749 - val_loss: 1.2000 - val_acc: 0.3375\n",
            "Epoch 256/300\n",
            "34/34 [==============================] - 25s 674ms/step - loss: 0.9427 - acc: 0.5961 - val_loss: 1.2368 - val_acc: 0.3250\n",
            "Epoch 257/300\n",
            "34/34 [==============================] - 27s 736ms/step - loss: 0.9192 - acc: 0.5885 - val_loss: 1.1827 - val_acc: 0.3750\n",
            "Epoch 258/300\n",
            "34/34 [==============================] - 25s 669ms/step - loss: 0.9395 - acc: 0.5885 - val_loss: 1.1388 - val_acc: 0.4000\n",
            "Epoch 259/300\n",
            "34/34 [==============================] - 25s 668ms/step - loss: 0.9641 - acc: 0.5930 - val_loss: 1.2575 - val_acc: 0.3000\n",
            "Epoch 260/300\n",
            "34/34 [==============================] - 25s 679ms/step - loss: 0.9688 - acc: 0.5915 - val_loss: 1.1697 - val_acc: 0.3750\n",
            "Epoch 261/300\n",
            "34/34 [==============================] - 25s 684ms/step - loss: 0.9263 - acc: 0.6021 - val_loss: 1.2372 - val_acc: 0.3250\n",
            "Epoch 262/300\n",
            "34/34 [==============================] - 25s 669ms/step - loss: 0.9265 - acc: 0.5885 - val_loss: 1.1602 - val_acc: 0.3625\n",
            "Epoch 263/300\n",
            "34/34 [==============================] - 27s 671ms/step - loss: 0.9203 - acc: 0.5961 - val_loss: 1.2888 - val_acc: 0.2875\n",
            "Epoch 264/300\n",
            "34/34 [==============================] - 25s 676ms/step - loss: 0.9422 - acc: 0.5582 - val_loss: 1.2241 - val_acc: 0.3250\n",
            "Epoch 265/300\n",
            "34/34 [==============================] - 25s 680ms/step - loss: 0.9245 - acc: 0.5991 - val_loss: 1.1843 - val_acc: 0.3375\n",
            "Epoch 266/300\n",
            "34/34 [==============================] - 25s 676ms/step - loss: 0.9457 - acc: 0.5764 - val_loss: 1.2004 - val_acc: 0.3375\n",
            "Epoch 267/300\n",
            "34/34 [==============================] - 24s 660ms/step - loss: 0.9318 - acc: 0.5991 - val_loss: 1.2119 - val_acc: 0.3375\n",
            "Epoch 268/300\n",
            "34/34 [==============================] - 23s 626ms/step - loss: 0.9907 - acc: 0.5703 - val_loss: 1.2596 - val_acc: 0.3375\n",
            "Epoch 269/300\n",
            "34/34 [==============================] - 24s 639ms/step - loss: 0.9757 - acc: 0.5658 - val_loss: 1.3112 - val_acc: 0.3250\n",
            "Epoch 270/300\n",
            "34/34 [==============================] - 25s 672ms/step - loss: 0.9126 - acc: 0.6082 - val_loss: 1.2281 - val_acc: 0.3500\n",
            "Epoch 271/300\n",
            "34/34 [==============================] - 24s 721ms/step - loss: 0.9293 - acc: 0.5673 - val_loss: 1.1756 - val_acc: 0.3375\n",
            "Epoch 272/300\n",
            "34/34 [==============================] - 23s 633ms/step - loss: 0.9665 - acc: 0.5673 - val_loss: 1.2421 - val_acc: 0.3375\n",
            "Epoch 273/300\n",
            "34/34 [==============================] - 25s 699ms/step - loss: 0.8832 - acc: 0.6309 - val_loss: 1.2820 - val_acc: 0.3125\n",
            "Epoch 274/300\n",
            "34/34 [==============================] - 22s 608ms/step - loss: 0.9117 - acc: 0.5870 - val_loss: 1.2161 - val_acc: 0.3625\n",
            "Epoch 275/300\n",
            "34/34 [==============================] - 22s 608ms/step - loss: 0.9411 - acc: 0.5915 - val_loss: 1.2652 - val_acc: 0.3250\n",
            "Epoch 276/300\n",
            "34/34 [==============================] - 25s 677ms/step - loss: 0.8728 - acc: 0.6051 - val_loss: 1.2437 - val_acc: 0.3125\n",
            "Epoch 277/300\n",
            "34/34 [==============================] - 25s 666ms/step - loss: 0.9180 - acc: 0.6172 - val_loss: 1.1451 - val_acc: 0.3500\n",
            "Epoch 278/300\n",
            "34/34 [==============================] - 25s 674ms/step - loss: 0.9534 - acc: 0.5764 - val_loss: 1.1097 - val_acc: 0.3750\n",
            "Epoch 279/300\n",
            "34/34 [==============================] - 25s 666ms/step - loss: 0.9843 - acc: 0.5764 - val_loss: 1.2032 - val_acc: 0.3625\n",
            "Epoch 280/300\n",
            "34/34 [==============================] - 25s 665ms/step - loss: 0.8912 - acc: 0.6142 - val_loss: 1.1505 - val_acc: 0.3875\n",
            "Epoch 281/300\n",
            "34/34 [==============================] - 23s 610ms/step - loss: 0.9116 - acc: 0.6309 - val_loss: 1.3008 - val_acc: 0.3125\n",
            "Epoch 282/300\n",
            "34/34 [==============================] - 22s 608ms/step - loss: 0.9215 - acc: 0.5764 - val_loss: 1.1183 - val_acc: 0.3625\n",
            "Epoch 283/300\n",
            "34/34 [==============================] - 22s 614ms/step - loss: 0.8965 - acc: 0.6157 - val_loss: 1.1401 - val_acc: 0.3500\n",
            "Epoch 284/300\n",
            "34/34 [==============================] - 24s 666ms/step - loss: 0.9129 - acc: 0.5976 - val_loss: 1.2147 - val_acc: 0.3125\n",
            "Epoch 285/300\n",
            "34/34 [==============================] - 23s 614ms/step - loss: 0.8785 - acc: 0.6127 - val_loss: 1.2647 - val_acc: 0.2625\n",
            "Epoch 286/300\n",
            "34/34 [==============================] - 22s 609ms/step - loss: 0.9445 - acc: 0.5628 - val_loss: 1.1958 - val_acc: 0.3625\n",
            "Epoch 287/300\n",
            "34/34 [==============================] - 22s 610ms/step - loss: 0.9638 - acc: 0.5900 - val_loss: 1.1840 - val_acc: 0.3750\n",
            "Epoch 288/300\n",
            "34/34 [==============================] - 22s 600ms/step - loss: 0.9146 - acc: 0.5915 - val_loss: 1.3069 - val_acc: 0.2875\n",
            "Epoch 289/300\n",
            "34/34 [==============================] - 24s 660ms/step - loss: 0.8863 - acc: 0.6051 - val_loss: 1.2366 - val_acc: 0.3500\n",
            "Epoch 290/300\n",
            "34/34 [==============================] - 23s 614ms/step - loss: 0.8974 - acc: 0.5946 - val_loss: 1.2140 - val_acc: 0.3375\n",
            "Epoch 291/300\n",
            "34/34 [==============================] - 23s 626ms/step - loss: 0.9333 - acc: 0.5764 - val_loss: 1.2449 - val_acc: 0.3000\n",
            "Epoch 292/300\n",
            "34/34 [==============================] - 22s 597ms/step - loss: 0.9015 - acc: 0.6218 - val_loss: 1.2265 - val_acc: 0.3250\n",
            "Epoch 293/300\n",
            "34/34 [==============================] - 22s 595ms/step - loss: 0.9622 - acc: 0.5915 - val_loss: 1.3220 - val_acc: 0.2750\n",
            "Epoch 294/300\n",
            "34/34 [==============================] - 24s 668ms/step - loss: 0.8761 - acc: 0.6000 - val_loss: 1.1620 - val_acc: 0.3500\n",
            "Epoch 295/300\n",
            "34/34 [==============================] - 23s 609ms/step - loss: 0.8703 - acc: 0.6103 - val_loss: 1.1727 - val_acc: 0.3500\n",
            "Epoch 296/300\n",
            "34/34 [==============================] - 22s 592ms/step - loss: 0.9094 - acc: 0.6112 - val_loss: 1.2653 - val_acc: 0.3000\n",
            "Epoch 297/300\n",
            "34/34 [==============================] - 22s 589ms/step - loss: 0.9053 - acc: 0.6172 - val_loss: 1.2521 - val_acc: 0.3375\n",
            "Epoch 298/300\n",
            "34/34 [==============================] - 22s 595ms/step - loss: 0.8909 - acc: 0.6142 - val_loss: 1.2204 - val_acc: 0.3625\n",
            "Epoch 299/300\n",
            "34/34 [==============================] - 21s 584ms/step - loss: 0.9154 - acc: 0.5840 - val_loss: 1.1668 - val_acc: 0.3625\n",
            "Epoch 300/300\n",
            "34/34 [==============================] - 22s 598ms/step - loss: 0.9464 - acc: 0.5885 - val_loss: 1.1574 - val_acc: 0.3750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.history"
      ],
      "metadata": {
        "id": "tO_KJFVJu6ya",
        "outputId": "d3a62129-7cfe-4ca5-ae67-62421866d9fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': [1.6619395017623901,\n",
              "  1.6665633916854858,\n",
              "  1.5000780820846558,\n",
              "  1.5152373313903809,\n",
              "  1.4697657823562622,\n",
              "  1.5451951026916504,\n",
              "  1.516514539718628,\n",
              "  1.4531676769256592,\n",
              "  1.5109004974365234,\n",
              "  1.4908376932144165,\n",
              "  1.4493283033370972,\n",
              "  1.3850778341293335,\n",
              "  1.4369410276412964,\n",
              "  1.4229029417037964,\n",
              "  1.4660437107086182,\n",
              "  1.3989158868789673,\n",
              "  1.4805610179901123,\n",
              "  1.3209148645401,\n",
              "  1.419132947921753,\n",
              "  1.4042078256607056,\n",
              "  1.4209978580474854,\n",
              "  1.2912840843200684,\n",
              "  1.4288926124572754,\n",
              "  1.412109613418579,\n",
              "  1.3554953336715698,\n",
              "  1.3861908912658691,\n",
              "  1.3933025598526,\n",
              "  1.3355776071548462,\n",
              "  1.327669382095337,\n",
              "  1.2940174341201782,\n",
              "  1.371271014213562,\n",
              "  1.285799264907837,\n",
              "  1.3495171070098877,\n",
              "  1.3335018157958984,\n",
              "  1.2905524969100952,\n",
              "  1.2866308689117432,\n",
              "  1.3744758367538452,\n",
              "  1.3032861948013306,\n",
              "  1.340781331062317,\n",
              "  1.3065494298934937,\n",
              "  1.3526822328567505,\n",
              "  1.329107403755188,\n",
              "  1.239936351776123,\n",
              "  1.2500441074371338,\n",
              "  1.322157859802246,\n",
              "  1.287448763847351,\n",
              "  1.3238545656204224,\n",
              "  1.3051973581314087,\n",
              "  1.3150776624679565,\n",
              "  1.2632551193237305,\n",
              "  1.214398741722107,\n",
              "  1.2084115743637085,\n",
              "  1.1696031093597412,\n",
              "  1.2175065279006958,\n",
              "  1.2028108835220337,\n",
              "  1.3254666328430176,\n",
              "  1.1448301076889038,\n",
              "  1.2421340942382812,\n",
              "  1.1917859315872192,\n",
              "  1.2236837148666382,\n",
              "  1.20839524269104,\n",
              "  1.197488784790039,\n",
              "  1.18842351436615,\n",
              "  1.1639472246170044,\n",
              "  1.2135851383209229,\n",
              "  1.189534306526184,\n",
              "  1.2300350666046143,\n",
              "  1.2104626893997192,\n",
              "  1.1348776817321777,\n",
              "  1.2771183252334595,\n",
              "  1.1806782484054565,\n",
              "  1.1472702026367188,\n",
              "  1.1281388998031616,\n",
              "  1.1511443853378296,\n",
              "  1.174659013748169,\n",
              "  1.1958343982696533,\n",
              "  1.2184553146362305,\n",
              "  1.1937000751495361,\n",
              "  1.186269760131836,\n",
              "  1.2298688888549805,\n",
              "  1.1404433250427246,\n",
              "  1.127151608467102,\n",
              "  1.0995992422103882,\n",
              "  1.148532748222351,\n",
              "  1.1529226303100586,\n",
              "  1.1566026210784912,\n",
              "  1.146706223487854,\n",
              "  1.1891061067581177,\n",
              "  1.0971871614456177,\n",
              "  1.1282645463943481,\n",
              "  1.1874830722808838,\n",
              "  1.219504714012146,\n",
              "  1.1314321756362915,\n",
              "  1.130395770072937,\n",
              "  1.1641066074371338,\n",
              "  1.1152899265289307,\n",
              "  1.1425944566726685,\n",
              "  1.1187397241592407,\n",
              "  1.143854022026062,\n",
              "  1.1391539573669434,\n",
              "  1.1057097911834717,\n",
              "  1.1000840663909912,\n",
              "  1.0968986749649048,\n",
              "  1.1532849073410034,\n",
              "  1.1349432468414307,\n",
              "  1.0825806856155396,\n",
              "  1.1376287937164307,\n",
              "  1.161765694618225,\n",
              "  1.1108105182647705,\n",
              "  1.0839312076568604,\n",
              "  1.109055757522583,\n",
              "  1.0599219799041748,\n",
              "  1.1711870431900024,\n",
              "  1.0767024755477905,\n",
              "  1.0485087633132935,\n",
              "  1.1158668994903564,\n",
              "  1.080947756767273,\n",
              "  1.0808160305023193,\n",
              "  1.1158727407455444,\n",
              "  1.076094627380371,\n",
              "  1.12686288356781,\n",
              "  1.1031548976898193,\n",
              "  1.1585310697555542,\n",
              "  1.1047533750534058,\n",
              "  1.0423083305358887,\n",
              "  0.9882783889770508,\n",
              "  1.0667132139205933,\n",
              "  1.0836448669433594,\n",
              "  1.1061694622039795,\n",
              "  1.1264270544052124,\n",
              "  1.1264523267745972,\n",
              "  1.0430303812026978,\n",
              "  1.0407284498214722,\n",
              "  1.1454685926437378,\n",
              "  1.0701212882995605,\n",
              "  1.0959550142288208,\n",
              "  1.1112629175186157,\n",
              "  1.012793779373169,\n",
              "  1.0947567224502563,\n",
              "  1.051086187362671,\n",
              "  1.0762931108474731,\n",
              "  1.0049597024917603,\n",
              "  1.1016268730163574,\n",
              "  1.090696930885315,\n",
              "  1.0700384378433228,\n",
              "  1.127301812171936,\n",
              "  1.046444058418274,\n",
              "  1.0654852390289307,\n",
              "  1.067237377166748,\n",
              "  1.0080617666244507,\n",
              "  1.1282795667648315,\n",
              "  1.0196462869644165,\n",
              "  1.141789436340332,\n",
              "  1.0399024486541748,\n",
              "  1.063206434249878,\n",
              "  0.9995102286338806,\n",
              "  1.029147982597351,\n",
              "  1.059127926826477,\n",
              "  1.0197935104370117,\n",
              "  1.035183310508728,\n",
              "  1.0272290706634521,\n",
              "  1.0656909942626953,\n",
              "  1.048907995223999,\n",
              "  1.0260816812515259,\n",
              "  0.9863929748535156,\n",
              "  1.0260720252990723,\n",
              "  1.0270661115646362,\n",
              "  1.0153371095657349,\n",
              "  1.077987790107727,\n",
              "  1.0021113157272339,\n",
              "  1.0118707418441772,\n",
              "  0.9714664816856384,\n",
              "  1.0346612930297852,\n",
              "  0.9826712012290955,\n",
              "  1.0219186544418335,\n",
              "  0.9923428893089294,\n",
              "  0.9985522627830505,\n",
              "  1.0022190809249878,\n",
              "  1.0255043506622314,\n",
              "  1.0615605115890503,\n",
              "  0.990257740020752,\n",
              "  0.9984655380249023,\n",
              "  0.9919198155403137,\n",
              "  1.02279794216156,\n",
              "  1.0387840270996094,\n",
              "  1.0505748987197876,\n",
              "  1.0149807929992676,\n",
              "  1.0563368797302246,\n",
              "  1.0017448663711548,\n",
              "  0.9727766513824463,\n",
              "  0.9754177927970886,\n",
              "  1.069307565689087,\n",
              "  1.0395355224609375,\n",
              "  1.002503514289856,\n",
              "  1.0340676307678223,\n",
              "  0.9332026243209839,\n",
              "  1.0461186170578003,\n",
              "  0.9761996269226074,\n",
              "  1.0082910060882568,\n",
              "  0.994828999042511,\n",
              "  0.9737349152565002,\n",
              "  0.9845362901687622,\n",
              "  1.0068806409835815,\n",
              "  1.0149476528167725,\n",
              "  0.976624071598053,\n",
              "  0.9862183332443237,\n",
              "  1.0214858055114746,\n",
              "  1.011593222618103,\n",
              "  0.956186056137085,\n",
              "  0.9226555228233337,\n",
              "  0.9227721691131592,\n",
              "  0.9541776776313782,\n",
              "  0.9381459951400757,\n",
              "  0.9318983554840088,\n",
              "  0.9499093294143677,\n",
              "  0.9948268532752991,\n",
              "  0.9381946325302124,\n",
              "  1.0118147134780884,\n",
              "  0.996979832649231,\n",
              "  0.9517243504524231,\n",
              "  0.9383388161659241,\n",
              "  0.9827926158905029,\n",
              "  0.9657823443412781,\n",
              "  1.0167144536972046,\n",
              "  0.9401546120643616,\n",
              "  0.9997653961181641,\n",
              "  0.9653083086013794,\n",
              "  0.9174789786338806,\n",
              "  0.9505107402801514,\n",
              "  0.9497854113578796,\n",
              "  0.9471935033798218,\n",
              "  0.9175436496734619,\n",
              "  1.013623595237732,\n",
              "  0.9459092617034912,\n",
              "  0.9803101420402527,\n",
              "  0.9862475991249084,\n",
              "  0.9903500080108643,\n",
              "  0.9879804253578186,\n",
              "  0.9293584227561951,\n",
              "  0.9547163248062134,\n",
              "  0.9154688119888306,\n",
              "  0.9983732104301453,\n",
              "  0.9913766980171204,\n",
              "  0.9537457823753357,\n",
              "  0.9501000046730042,\n",
              "  0.9647544622421265,\n",
              "  0.969513475894928,\n",
              "  0.9339234232902527,\n",
              "  0.9400159120559692,\n",
              "  0.9015393257141113,\n",
              "  0.8902992606163025,\n",
              "  0.9523480534553528,\n",
              "  0.9656846523284912,\n",
              "  0.9178549647331238,\n",
              "  1.001352310180664,\n",
              "  0.9426634311676025,\n",
              "  0.9191710948944092,\n",
              "  0.939505934715271,\n",
              "  0.9640620350837708,\n",
              "  0.9687716960906982,\n",
              "  0.9262994527816772,\n",
              "  0.9265464544296265,\n",
              "  0.9203070402145386,\n",
              "  0.9421946406364441,\n",
              "  0.9244895577430725,\n",
              "  0.9456929564476013,\n",
              "  0.9317527413368225,\n",
              "  0.9907116889953613,\n",
              "  0.9756578803062439,\n",
              "  0.9125929474830627,\n",
              "  0.9293075203895569,\n",
              "  0.9665464758872986,\n",
              "  0.883245587348938,\n",
              "  0.9117472171783447,\n",
              "  0.9411255717277527,\n",
              "  0.8727571368217468,\n",
              "  0.9179926514625549,\n",
              "  0.9533795714378357,\n",
              "  0.9843218326568604,\n",
              "  0.891205370426178,\n",
              "  0.9116330742835999,\n",
              "  0.9215275049209595,\n",
              "  0.8965043425559998,\n",
              "  0.9128708839416504,\n",
              "  0.8785088062286377,\n",
              "  0.9444605708122253,\n",
              "  0.9637688398361206,\n",
              "  0.9146198630332947,\n",
              "  0.8863442540168762,\n",
              "  0.897412896156311,\n",
              "  0.9333235025405884,\n",
              "  0.9014807343482971,\n",
              "  0.962181031703949,\n",
              "  0.8760518431663513,\n",
              "  0.8703294396400452,\n",
              "  0.9093520641326904,\n",
              "  0.9052708745002747,\n",
              "  0.890946626663208,\n",
              "  0.9153740406036377,\n",
              "  0.9463667869567871],\n",
              " 'acc': [0.3328290581703186,\n",
              "  0.3464447855949402,\n",
              "  0.4009077250957489,\n",
              "  0.3948562741279602,\n",
              "  0.4024205803871155,\n",
              "  0.39183056354522705,\n",
              "  0.3706505298614502,\n",
              "  0.38729196786880493,\n",
              "  0.3888048529624939,\n",
              "  0.4009077250957489,\n",
              "  0.39183056354522705,\n",
              "  0.40544629096984863,\n",
              "  0.42208775877952576,\n",
              "  0.4190620183944702,\n",
              "  0.4024205803871155,\n",
              "  0.41754916310310364,\n",
              "  0.3812405467033386,\n",
              "  0.45990923047065735,\n",
              "  0.39183056354522705,\n",
              "  0.42965203523635864,\n",
              "  0.4084720015525818,\n",
              "  0.45385777950286865,\n",
              "  0.4069591462612152,\n",
              "  0.3963691294193268,\n",
              "  0.42965203523635864,\n",
              "  0.3948562741279602,\n",
              "  0.4190620183944702,\n",
              "  0.44024205207824707,\n",
              "  0.42813917994499207,\n",
              "  0.45385777950286865,\n",
              "  0.4311648905277252,\n",
              "  0.4568835198879242,\n",
              "  0.44175490736961365,\n",
              "  0.4326777756214142,\n",
              "  0.4311648905277252,\n",
              "  0.44175490736961365,\n",
              "  0.42813917994499207,\n",
              "  0.45839637517929077,\n",
              "  0.43570348620414734,\n",
              "  0.4447806477546692,\n",
              "  0.43419063091278076,\n",
              "  0.43570348620414734,\n",
              "  0.44175490736961365,\n",
              "  0.4523449242115021,\n",
              "  0.4568835198879242,\n",
              "  0.4553706645965576,\n",
              "  0.44629350304603577,\n",
              "  0.44024205207824707,\n",
              "  0.43419063091278076,\n",
              "  0.4387291967868805,\n",
              "  0.4629349410533905,\n",
              "  0.47806355357170105,\n",
              "  0.49167928099632263,\n",
              "  0.4689863920211792,\n",
              "  0.49016642570495605,\n",
              "  0.4523449242115021,\n",
              "  0.5264750123023987,\n",
              "  0.4674735367298126,\n",
              "  0.49167928099632263,\n",
              "  0.4644477963447571,\n",
              "  0.47352495789527893,\n",
              "  0.4750378131866455,\n",
              "  0.4871406853199005,\n",
              "  0.4931921362876892,\n",
              "  0.4810892641544342,\n",
              "  0.4826021194458008,\n",
              "  0.45839637517929077,\n",
              "  0.4568835198879242,\n",
              "  0.509833574295044,\n",
              "  0.45385777950286865,\n",
              "  0.48562783002853394,\n",
              "  0.4765506684780121,\n",
              "  0.49016642570495605,\n",
              "  0.47201210260391235,\n",
              "  0.47201210260391235,\n",
              "  0.4871406853199005,\n",
              "  0.45990923047065735,\n",
              "  0.47201210260391235,\n",
              "  0.4871406853199005,\n",
              "  0.4553706645965576,\n",
              "  0.4886535406112671,\n",
              "  0.4886535406112671,\n",
              "  0.5068078637123108,\n",
              "  0.5022692680358887,\n",
              "  0.49016642570495605,\n",
              "  0.49621784687042236,\n",
              "  0.49773070216178894,\n",
              "  0.48562783002853394,\n",
              "  0.5143721699714661,\n",
              "  0.5052949786186218,\n",
              "  0.4674735367298126,\n",
              "  0.45990923047065735,\n",
              "  0.5143721699714661,\n",
              "  0.49621784687042236,\n",
              "  0.4931921362876892,\n",
              "  0.5052949786186218,\n",
              "  0.5037821531295776,\n",
              "  0.5279411673545837,\n",
              "  0.5007564425468445,\n",
              "  0.49773070216178894,\n",
              "  0.5052949786186218,\n",
              "  0.5189107656478882,\n",
              "  0.5476550459861755,\n",
              "  0.48411497473716736,\n",
              "  0.5037821531295776,\n",
              "  0.5158849954605103,\n",
              "  0.5007564425468445,\n",
              "  0.509833574295044,\n",
              "  0.5204235911369324,\n",
              "  0.5189107656478882,\n",
              "  0.5022692680358887,\n",
              "  0.5491679310798645,\n",
              "  0.5052949786186218,\n",
              "  0.5068078637123108,\n",
              "  0.5416036248207092,\n",
              "  0.5189107656478882,\n",
              "  0.5355522036552429,\n",
              "  0.5264706015586853,\n",
              "  0.5249621868133545,\n",
              "  0.5567322373390198,\n",
              "  0.49621784687042236,\n",
              "  0.540090799331665,\n",
              "  0.509833574295044,\n",
              "  0.5158849954605103,\n",
              "  0.5355522036552429,\n",
              "  0.5703479647636414,\n",
              "  0.5204235911369324,\n",
              "  0.5128592848777771,\n",
              "  0.5189107656478882,\n",
              "  0.4992435574531555,\n",
              "  0.509833574295044,\n",
              "  0.5355522036552429,\n",
              "  0.5279878973960876,\n",
              "  0.5204235911369324,\n",
              "  0.5355522036552429,\n",
              "  0.5279878973960876,\n",
              "  0.5083207488059998,\n",
              "  0.5567322373390198,\n",
              "  0.5143721699714661,\n",
              "  0.5264750123023987,\n",
              "  0.5264750123023987,\n",
              "  0.5506808161735535,\n",
              "  0.5143721699714661,\n",
              "  0.5446293354034424,\n",
              "  0.5476550459861755,\n",
              "  0.5113464593887329,\n",
              "  0.5382353067398071,\n",
              "  0.5189107656478882,\n",
              "  0.5158849954605103,\n",
              "  0.558245062828064,\n",
              "  0.5052949786186218,\n",
              "  0.5537065267562866,\n",
              "  0.5113464593887329,\n",
              "  0.5370650291442871,\n",
              "  0.5385779142379761,\n",
              "  0.5612707734107971,\n",
              "  0.5461422204971313,\n",
              "  0.5249621868133545,\n",
              "  0.5385779142379761,\n",
              "  0.5673222541809082,\n",
              "  0.564296543598175,\n",
              "  0.5264750123023987,\n",
              "  0.5234493017196655,\n",
              "  0.5506808161735535,\n",
              "  0.564296543598175,\n",
              "  0.5249621868133545,\n",
              "  0.5506808161735535,\n",
              "  0.5491679310798645,\n",
              "  0.5521936416625977,\n",
              "  0.5688350796699524,\n",
              "  0.5476550459861755,\n",
              "  0.5794250965118408,\n",
              "  0.5673222541809082,\n",
              "  0.5748865604400635,\n",
              "  0.5794250965118408,\n",
              "  0.574999988079071,\n",
              "  0.558245062828064,\n",
              "  0.5537065267562866,\n",
              "  0.5385779142379761,\n",
              "  0.5204235911369324,\n",
              "  0.5839636921882629,\n",
              "  0.5748865604400635,\n",
              "  0.5688350796699524,\n",
              "  0.5264750123023987,\n",
              "  0.5461422204971313,\n",
              "  0.5370650291442871,\n",
              "  0.5204235911369324,\n",
              "  0.5461422204971313,\n",
              "  0.558245062828064,\n",
              "  0.5688350796699524,\n",
              "  0.582450807094574,\n",
              "  0.5310136079788208,\n",
              "  0.5310136079788208,\n",
              "  0.5521936416625977,\n",
              "  0.5446293354034424,\n",
              "  0.5854765772819519,\n",
              "  0.5416036248207092,\n",
              "  0.5552193522453308,\n",
              "  0.5461422204971313,\n",
              "  0.5552193522453308,\n",
              "  0.5733736753463745,\n",
              "  0.5627836585044861,\n",
              "  0.5718607902526855,\n",
              "  0.5537065267562866,\n",
              "  0.5733736753463745,\n",
              "  0.5552193522453308,\n",
              "  0.5310136079788208,\n",
              "  0.5673222541809082,\n",
              "  0.582450807094574,\n",
              "  0.6006051301956177,\n",
              "  0.6021180152893066,\n",
              "  0.5612707734107971,\n",
              "  0.5885022878646851,\n",
              "  0.5763993859291077,\n",
              "  0.582450807094574,\n",
              "  0.558245062828064,\n",
              "  0.5658093690872192,\n",
              "  0.5627836585044861,\n",
              "  0.5688350796699524,\n",
              "  0.5809379816055298,\n",
              "  0.5809379816055298,\n",
              "  0.5885022878646851,\n",
              "  0.5658093690872192,\n",
              "  0.5673222541809082,\n",
              "  0.5809379816055298,\n",
              "  0.5673222541809082,\n",
              "  0.5658093690872192,\n",
              "  0.6036308407783508,\n",
              "  0.6036308407783508,\n",
              "  0.5885022878646851,\n",
              "  0.5809379816055298,\n",
              "  0.5930408239364624,\n",
              "  0.5612707734107971,\n",
              "  0.6021180152893066,\n",
              "  0.5703479647636414,\n",
              "  0.582450807094574,\n",
              "  0.5506808161735535,\n",
              "  0.5779122710227966,\n",
              "  0.5885022878646851,\n",
              "  0.5930408239364624,\n",
              "  0.5885022878646851,\n",
              "  0.5733736753463745,\n",
              "  0.5597579479217529,\n",
              "  0.5748865604400635,\n",
              "  0.5960665941238403,\n",
              "  0.5915279984474182,\n",
              "  0.5885022878646851,\n",
              "  0.5658093690872192,\n",
              "  0.5597579479217529,\n",
              "  0.6172465682029724,\n",
              "  0.5975794196128845,\n",
              "  0.5809379816055298,\n",
              "  0.5748865604400635,\n",
              "  0.6036308407783508,\n",
              "  0.5748865604400635,\n",
              "  0.5960665941238403,\n",
              "  0.5885022878646851,\n",
              "  0.5885022878646851,\n",
              "  0.5930408239364624,\n",
              "  0.5915279984474182,\n",
              "  0.6021180152893066,\n",
              "  0.5885022878646851,\n",
              "  0.5960665941238403,\n",
              "  0.558245062828064,\n",
              "  0.5990923047065735,\n",
              "  0.5763993859291077,\n",
              "  0.5990923047065735,\n",
              "  0.5703479647636414,\n",
              "  0.5658093690872192,\n",
              "  0.608169436454773,\n",
              "  0.5673222541809082,\n",
              "  0.5673222541809082,\n",
              "  0.6308623552322388,\n",
              "  0.5869894027709961,\n",
              "  0.5915279984474182,\n",
              "  0.6051437258720398,\n",
              "  0.6172465682029724,\n",
              "  0.5763993859291077,\n",
              "  0.5763993859291077,\n",
              "  0.6142208576202393,\n",
              "  0.6308623552322388,\n",
              "  0.5763993859291077,\n",
              "  0.6157337427139282,\n",
              "  0.5975794196128845,\n",
              "  0.6127080321311951,\n",
              "  0.5627836585044861,\n",
              "  0.5900151133537292,\n",
              "  0.5915279984474182,\n",
              "  0.6051437258720398,\n",
              "  0.5945537090301514,\n",
              "  0.5763993859291077,\n",
              "  0.6217851638793945,\n",
              "  0.5915279984474182,\n",
              "  0.6000000238418579,\n",
              "  0.6102941036224365,\n",
              "  0.6111951470375061,\n",
              "  0.6172465682029724,\n",
              "  0.6142208576202393,\n",
              "  0.5839636921882629,\n",
              "  0.5885022878646851],\n",
              " 'val_loss': [1.1703119277954102,\n",
              "  1.277735710144043,\n",
              "  1.2946374416351318,\n",
              "  1.3860023021697998,\n",
              "  1.4076173305511475,\n",
              "  1.338629961013794,\n",
              "  1.429343819618225,\n",
              "  1.3515286445617676,\n",
              "  1.3567802906036377,\n",
              "  1.3479799032211304,\n",
              "  1.280626654624939,\n",
              "  1.3341968059539795,\n",
              "  1.3345286846160889,\n",
              "  1.2825126647949219,\n",
              "  1.1739593744277954,\n",
              "  1.2366572618484497,\n",
              "  1.3031591176986694,\n",
              "  1.2297967672348022,\n",
              "  1.2035844326019287,\n",
              "  1.2633845806121826,\n",
              "  1.346443772315979,\n",
              "  1.2572078704833984,\n",
              "  1.2539418935775757,\n",
              "  1.2713619470596313,\n",
              "  1.273876428604126,\n",
              "  1.2644940614700317,\n",
              "  1.2795264720916748,\n",
              "  1.2387639284133911,\n",
              "  1.3501518964767456,\n",
              "  1.226453423500061,\n",
              "  1.2619749307632446,\n",
              "  1.2323099374771118,\n",
              "  1.2147133350372314,\n",
              "  1.1896916627883911,\n",
              "  1.22100830078125,\n",
              "  1.1613030433654785,\n",
              "  1.2007153034210205,\n",
              "  1.2068545818328857,\n",
              "  1.2348673343658447,\n",
              "  1.281567096710205,\n",
              "  1.2250607013702393,\n",
              "  1.1809370517730713,\n",
              "  1.230993628501892,\n",
              "  1.3206924200057983,\n",
              "  1.2138493061065674,\n",
              "  1.2958141565322876,\n",
              "  1.2159950733184814,\n",
              "  1.217054843902588,\n",
              "  1.2946547269821167,\n",
              "  1.1726698875427246,\n",
              "  1.229614019393921,\n",
              "  1.2262325286865234,\n",
              "  1.183621883392334,\n",
              "  1.2164877653121948,\n",
              "  1.2619640827178955,\n",
              "  1.1855272054672241,\n",
              "  1.230534553527832,\n",
              "  1.2532312870025635,\n",
              "  1.2645227909088135,\n",
              "  1.1935694217681885,\n",
              "  1.2417420148849487,\n",
              "  1.2483649253845215,\n",
              "  1.2525041103363037,\n",
              "  1.2226805686950684,\n",
              "  1.2243214845657349,\n",
              "  1.1992089748382568,\n",
              "  1.085146188735962,\n",
              "  1.2327396869659424,\n",
              "  1.2014458179473877,\n",
              "  1.1414790153503418,\n",
              "  1.166535496711731,\n",
              "  1.131545066833496,\n",
              "  1.198807954788208,\n",
              "  1.1916110515594482,\n",
              "  1.1757335662841797,\n",
              "  1.1434283256530762,\n",
              "  1.2215644121170044,\n",
              "  1.236860990524292,\n",
              "  1.180719017982483,\n",
              "  1.170677661895752,\n",
              "  1.2156696319580078,\n",
              "  1.119899868965149,\n",
              "  1.2305643558502197,\n",
              "  1.172332525253296,\n",
              "  1.1585625410079956,\n",
              "  1.1845111846923828,\n",
              "  1.150976538658142,\n",
              "  1.1252479553222656,\n",
              "  1.174647331237793,\n",
              "  1.1695517301559448,\n",
              "  1.1148191690444946,\n",
              "  1.176216721534729,\n",
              "  1.1447807550430298,\n",
              "  1.2051385641098022,\n",
              "  1.0933122634887695,\n",
              "  1.1072734594345093,\n",
              "  1.156368613243103,\n",
              "  1.0731414556503296,\n",
              "  1.2132164239883423,\n",
              "  1.1708223819732666,\n",
              "  1.1779597997665405,\n",
              "  1.1912201642990112,\n",
              "  1.242286205291748,\n",
              "  1.2149235010147095,\n",
              "  1.2487809658050537,\n",
              "  1.1535238027572632,\n",
              "  1.1885700225830078,\n",
              "  1.1454970836639404,\n",
              "  1.1542142629623413,\n",
              "  1.1567357778549194,\n",
              "  1.1657845973968506,\n",
              "  1.12760591506958,\n",
              "  1.2004505395889282,\n",
              "  1.192870020866394,\n",
              "  1.2229255437850952,\n",
              "  1.1590538024902344,\n",
              "  1.2004964351654053,\n",
              "  1.167388916015625,\n",
              "  1.2778575420379639,\n",
              "  1.1836217641830444,\n",
              "  1.131819725036621,\n",
              "  1.2092835903167725,\n",
              "  1.1936559677124023,\n",
              "  1.1723288297653198,\n",
              "  1.1760327816009521,\n",
              "  1.1804816722869873,\n",
              "  1.2200595140457153,\n",
              "  1.1918025016784668,\n",
              "  1.2947940826416016,\n",
              "  1.1967122554779053,\n",
              "  1.1416261196136475,\n",
              "  1.134266972541809,\n",
              "  1.171393632888794,\n",
              "  1.1107680797576904,\n",
              "  1.2296788692474365,\n",
              "  1.2069686651229858,\n",
              "  1.1214523315429688,\n",
              "  1.1314263343811035,\n",
              "  1.2076905965805054,\n",
              "  1.1828043460845947,\n",
              "  1.1807130575180054,\n",
              "  1.2085342407226562,\n",
              "  1.2163586616516113,\n",
              "  1.1179773807525635,\n",
              "  1.19784414768219,\n",
              "  1.1598999500274658,\n",
              "  1.1037261486053467,\n",
              "  1.1519267559051514,\n",
              "  1.201254963874817,\n",
              "  1.2351709604263306,\n",
              "  1.185766339302063,\n",
              "  1.2869043350219727,\n",
              "  1.186699390411377,\n",
              "  1.23562753200531,\n",
              "  1.1578470468521118,\n",
              "  1.1175215244293213,\n",
              "  1.1390149593353271,\n",
              "  1.2049200534820557,\n",
              "  1.2172006368637085,\n",
              "  1.1353670358657837,\n",
              "  1.1847368478775024,\n",
              "  1.264591097831726,\n",
              "  1.2258117198944092,\n",
              "  1.2661206722259521,\n",
              "  1.234535574913025,\n",
              "  1.2876735925674438,\n",
              "  1.2891209125518799,\n",
              "  1.2168388366699219,\n",
              "  1.2532199621200562,\n",
              "  1.1765458583831787,\n",
              "  1.2329435348510742,\n",
              "  1.243285894393921,\n",
              "  1.1573022603988647,\n",
              "  1.185834288597107,\n",
              "  1.2241060733795166,\n",
              "  1.2113776206970215,\n",
              "  1.1689099073410034,\n",
              "  1.1989142894744873,\n",
              "  1.1978209018707275,\n",
              "  1.2011735439300537,\n",
              "  1.2731940746307373,\n",
              "  1.1678297519683838,\n",
              "  1.2168320417404175,\n",
              "  1.259842872619629,\n",
              "  1.2066400051116943,\n",
              "  1.1895965337753296,\n",
              "  1.242321252822876,\n",
              "  1.1466909646987915,\n",
              "  1.2086477279663086,\n",
              "  1.2467639446258545,\n",
              "  1.167356252670288,\n",
              "  1.1531198024749756,\n",
              "  1.2075231075286865,\n",
              "  1.2010078430175781,\n",
              "  1.2274078130722046,\n",
              "  1.2021534442901611,\n",
              "  1.191724181175232,\n",
              "  1.1679959297180176,\n",
              "  1.167876958847046,\n",
              "  1.2834283113479614,\n",
              "  1.2615026235580444,\n",
              "  1.2203537225723267,\n",
              "  1.1754052639007568,\n",
              "  1.1839616298675537,\n",
              "  1.1371679306030273,\n",
              "  1.2882177829742432,\n",
              "  1.240180492401123,\n",
              "  1.180415391921997,\n",
              "  1.246295690536499,\n",
              "  1.2862402200698853,\n",
              "  1.1542530059814453,\n",
              "  1.1914007663726807,\n",
              "  1.2472827434539795,\n",
              "  1.1792292594909668,\n",
              "  1.2445653676986694,\n",
              "  1.2067111730575562,\n",
              "  1.1464763879776,\n",
              "  1.2395411729812622,\n",
              "  1.1949007511138916,\n",
              "  1.1954931020736694,\n",
              "  1.1494009494781494,\n",
              "  1.2466470003128052,\n",
              "  1.1847909688949585,\n",
              "  1.3155038356781006,\n",
              "  1.1555025577545166,\n",
              "  1.252691626548767,\n",
              "  1.2075331211090088,\n",
              "  1.2198015451431274,\n",
              "  1.2385518550872803,\n",
              "  1.2576287984848022,\n",
              "  1.1447200775146484,\n",
              "  1.1324325799942017,\n",
              "  1.262009859085083,\n",
              "  1.2096912860870361,\n",
              "  1.274783730506897,\n",
              "  1.2362772226333618,\n",
              "  1.201080322265625,\n",
              "  1.195601224899292,\n",
              "  1.2034975290298462,\n",
              "  1.245650053024292,\n",
              "  1.2134785652160645,\n",
              "  1.1508516073226929,\n",
              "  1.2050065994262695,\n",
              "  1.1832263469696045,\n",
              "  1.2435777187347412,\n",
              "  1.2251259088516235,\n",
              "  1.2712029218673706,\n",
              "  1.1380778551101685,\n",
              "  1.1518948078155518,\n",
              "  1.1727975606918335,\n",
              "  1.2390708923339844,\n",
              "  1.2129852771759033,\n",
              "  1.1709988117218018,\n",
              "  1.2184661626815796,\n",
              "  1.2000300884246826,\n",
              "  1.2367894649505615,\n",
              "  1.1826940774917603,\n",
              "  1.1387876272201538,\n",
              "  1.2574821710586548,\n",
              "  1.169690728187561,\n",
              "  1.2372080087661743,\n",
              "  1.1601773500442505,\n",
              "  1.2887948751449585,\n",
              "  1.2241220474243164,\n",
              "  1.1842609643936157,\n",
              "  1.2003720998764038,\n",
              "  1.2119109630584717,\n",
              "  1.2596232891082764,\n",
              "  1.3112233877182007,\n",
              "  1.2281453609466553,\n",
              "  1.175649642944336,\n",
              "  1.2420772314071655,\n",
              "  1.282004714012146,\n",
              "  1.2160539627075195,\n",
              "  1.2651704549789429,\n",
              "  1.2436901330947876,\n",
              "  1.1451470851898193,\n",
              "  1.1097452640533447,\n",
              "  1.2032101154327393,\n",
              "  1.150492548942566,\n",
              "  1.300843358039856,\n",
              "  1.118342399597168,\n",
              "  1.1400811672210693,\n",
              "  1.214677333831787,\n",
              "  1.2646509408950806,\n",
              "  1.195840835571289,\n",
              "  1.1840450763702393,\n",
              "  1.3069231510162354,\n",
              "  1.2366454601287842,\n",
              "  1.2140090465545654,\n",
              "  1.2449003458023071,\n",
              "  1.226511001586914,\n",
              "  1.3219611644744873,\n",
              "  1.1619834899902344,\n",
              "  1.1726853847503662,\n",
              "  1.2652846574783325,\n",
              "  1.252063274383545,\n",
              "  1.2203733921051025,\n",
              "  1.1668468713760376,\n",
              "  1.1574065685272217],\n",
              " 'val_acc': [0.550000011920929,\n",
              "  0.4375,\n",
              "  0.4000000059604645,\n",
              "  0.3125,\n",
              "  0.30000001192092896,\n",
              "  0.3375000059604645,\n",
              "  0.2750000059604645,\n",
              "  0.30000001192092896,\n",
              "  0.2874999940395355,\n",
              "  0.30000001192092896,\n",
              "  0.32499998807907104,\n",
              "  0.3375000059604645,\n",
              "  0.3125,\n",
              "  0.3375000059604645,\n",
              "  0.36250001192092896,\n",
              "  0.30000001192092896,\n",
              "  0.30000001192092896,\n",
              "  0.3375000059604645,\n",
              "  0.36250001192092896,\n",
              "  0.3499999940395355,\n",
              "  0.2874999940395355,\n",
              "  0.32499998807907104,\n",
              "  0.3125,\n",
              "  0.30000001192092896,\n",
              "  0.2750000059604645,\n",
              "  0.3125,\n",
              "  0.2874999940395355,\n",
              "  0.2874999940395355,\n",
              "  0.25,\n",
              "  0.30000001192092896,\n",
              "  0.3125,\n",
              "  0.3125,\n",
              "  0.2750000059604645,\n",
              "  0.3375000059604645,\n",
              "  0.3375000059604645,\n",
              "  0.3125,\n",
              "  0.3375000059604645,\n",
              "  0.30000001192092896,\n",
              "  0.32499998807907104,\n",
              "  0.26249998807907104,\n",
              "  0.26249998807907104,\n",
              "  0.3125,\n",
              "  0.3125,\n",
              "  0.25,\n",
              "  0.32499998807907104,\n",
              "  0.25,\n",
              "  0.3375000059604645,\n",
              "  0.2874999940395355,\n",
              "  0.30000001192092896,\n",
              "  0.375,\n",
              "  0.32499998807907104,\n",
              "  0.3125,\n",
              "  0.3375000059604645,\n",
              "  0.32499998807907104,\n",
              "  0.2874999940395355,\n",
              "  0.36250001192092896,\n",
              "  0.30000001192092896,\n",
              "  0.30000001192092896,\n",
              "  0.2874999940395355,\n",
              "  0.3499999940395355,\n",
              "  0.3125,\n",
              "  0.3125,\n",
              "  0.32499998807907104,\n",
              "  0.3375000059604645,\n",
              "  0.32499998807907104,\n",
              "  0.3499999940395355,\n",
              "  0.42500001192092896,\n",
              "  0.3375000059604645,\n",
              "  0.375,\n",
              "  0.4000000059604645,\n",
              "  0.38749998807907104,\n",
              "  0.38749998807907104,\n",
              "  0.375,\n",
              "  0.36250001192092896,\n",
              "  0.4124999940395355,\n",
              "  0.4000000059604645,\n",
              "  0.3375000059604645,\n",
              "  0.3499999940395355,\n",
              "  0.375,\n",
              "  0.375,\n",
              "  0.36250001192092896,\n",
              "  0.42500001192092896,\n",
              "  0.3375000059604645,\n",
              "  0.38749998807907104,\n",
              "  0.36250001192092896,\n",
              "  0.38749998807907104,\n",
              "  0.375,\n",
              "  0.375,\n",
              "  0.375,\n",
              "  0.375,\n",
              "  0.4124999940395355,\n",
              "  0.38749998807907104,\n",
              "  0.4000000059604645,\n",
              "  0.375,\n",
              "  0.42500001192092896,\n",
              "  0.38749998807907104,\n",
              "  0.38749998807907104,\n",
              "  0.44999998807907104,\n",
              "  0.375,\n",
              "  0.36250001192092896,\n",
              "  0.375,\n",
              "  0.38749998807907104,\n",
              "  0.3375000059604645,\n",
              "  0.375,\n",
              "  0.3375000059604645,\n",
              "  0.4000000059604645,\n",
              "  0.3375000059604645,\n",
              "  0.38749998807907104,\n",
              "  0.36250001192092896,\n",
              "  0.36250001192092896,\n",
              "  0.36250001192092896,\n",
              "  0.4124999940395355,\n",
              "  0.375,\n",
              "  0.375,\n",
              "  0.3499999940395355,\n",
              "  0.38749998807907104,\n",
              "  0.3499999940395355,\n",
              "  0.4000000059604645,\n",
              "  0.3499999940395355,\n",
              "  0.4000000059604645,\n",
              "  0.4000000059604645,\n",
              "  0.3125,\n",
              "  0.36250001192092896,\n",
              "  0.36250001192092896,\n",
              "  0.3499999940395355,\n",
              "  0.4000000059604645,\n",
              "  0.375,\n",
              "  0.38749998807907104,\n",
              "  0.30000001192092896,\n",
              "  0.38749998807907104,\n",
              "  0.42500001192092896,\n",
              "  0.4000000059604645,\n",
              "  0.375,\n",
              "  0.4000000059604645,\n",
              "  0.3375000059604645,\n",
              "  0.36250001192092896,\n",
              "  0.42500001192092896,\n",
              "  0.4000000059604645,\n",
              "  0.36250001192092896,\n",
              "  0.375,\n",
              "  0.3499999940395355,\n",
              "  0.3375000059604645,\n",
              "  0.32499998807907104,\n",
              "  0.4375,\n",
              "  0.36250001192092896,\n",
              "  0.42500001192092896,\n",
              "  0.375,\n",
              "  0.4000000059604645,\n",
              "  0.375,\n",
              "  0.375,\n",
              "  0.38749998807907104,\n",
              "  0.30000001192092896,\n",
              "  0.3499999940395355,\n",
              "  0.36250001192092896,\n",
              "  0.375,\n",
              "  0.4000000059604645,\n",
              "  0.375,\n",
              "  0.36250001192092896,\n",
              "  0.36250001192092896,\n",
              "  0.38749998807907104,\n",
              "  0.375,\n",
              "  0.3125,\n",
              "  0.3375000059604645,\n",
              "  0.3125,\n",
              "  0.375,\n",
              "  0.30000001192092896,\n",
              "  0.3125,\n",
              "  0.3499999940395355,\n",
              "  0.3125,\n",
              "  0.36250001192092896,\n",
              "  0.32499998807907104,\n",
              "  0.3125,\n",
              "  0.38749998807907104,\n",
              "  0.375,\n",
              "  0.375,\n",
              "  0.36250001192092896,\n",
              "  0.375,\n",
              "  0.38749998807907104,\n",
              "  0.36250001192092896,\n",
              "  0.375,\n",
              "  0.3125,\n",
              "  0.4000000059604645,\n",
              "  0.3375000059604645,\n",
              "  0.32499998807907104,\n",
              "  0.36250001192092896,\n",
              "  0.375,\n",
              "  0.3499999940395355,\n",
              "  0.375,\n",
              "  0.38749998807907104,\n",
              "  0.3375000059604645,\n",
              "  0.375,\n",
              "  0.4000000059604645,\n",
              "  0.3499999940395355,\n",
              "  0.3499999940395355,\n",
              "  0.375,\n",
              "  0.3499999940395355,\n",
              "  0.36250001192092896,\n",
              "  0.3375000059604645,\n",
              "  0.375,\n",
              "  0.30000001192092896,\n",
              "  0.3125,\n",
              "  0.375,\n",
              "  0.38749998807907104,\n",
              "  0.3499999940395355,\n",
              "  0.38749998807907104,\n",
              "  0.3375000059604645,\n",
              "  0.3375000059604645,\n",
              "  0.38749998807907104,\n",
              "  0.3125,\n",
              "  0.2874999940395355,\n",
              "  0.4000000059604645,\n",
              "  0.4124999940395355,\n",
              "  0.3125,\n",
              "  0.375,\n",
              "  0.3125,\n",
              "  0.36250001192092896,\n",
              "  0.4000000059604645,\n",
              "  0.375,\n",
              "  0.3499999940395355,\n",
              "  0.38749998807907104,\n",
              "  0.4124999940395355,\n",
              "  0.32499998807907104,\n",
              "  0.3499999940395355,\n",
              "  0.2750000059604645,\n",
              "  0.36250001192092896,\n",
              "  0.32499998807907104,\n",
              "  0.3499999940395355,\n",
              "  0.3125,\n",
              "  0.32499998807907104,\n",
              "  0.3125,\n",
              "  0.3375000059604645,\n",
              "  0.375,\n",
              "  0.32499998807907104,\n",
              "  0.36250001192092896,\n",
              "  0.30000001192092896,\n",
              "  0.3499999940395355,\n",
              "  0.375,\n",
              "  0.3499999940395355,\n",
              "  0.375,\n",
              "  0.32499998807907104,\n",
              "  0.3499999940395355,\n",
              "  0.4000000059604645,\n",
              "  0.32499998807907104,\n",
              "  0.3499999940395355,\n",
              "  0.3375000059604645,\n",
              "  0.3375000059604645,\n",
              "  0.32499998807907104,\n",
              "  0.4000000059604645,\n",
              "  0.32499998807907104,\n",
              "  0.36250001192092896,\n",
              "  0.32499998807907104,\n",
              "  0.375,\n",
              "  0.375,\n",
              "  0.4000000059604645,\n",
              "  0.3375000059604645,\n",
              "  0.32499998807907104,\n",
              "  0.375,\n",
              "  0.4000000059604645,\n",
              "  0.30000001192092896,\n",
              "  0.375,\n",
              "  0.32499998807907104,\n",
              "  0.36250001192092896,\n",
              "  0.2874999940395355,\n",
              "  0.32499998807907104,\n",
              "  0.3375000059604645,\n",
              "  0.3375000059604645,\n",
              "  0.3375000059604645,\n",
              "  0.3375000059604645,\n",
              "  0.32499998807907104,\n",
              "  0.3499999940395355,\n",
              "  0.3375000059604645,\n",
              "  0.3375000059604645,\n",
              "  0.3125,\n",
              "  0.36250001192092896,\n",
              "  0.32499998807907104,\n",
              "  0.3125,\n",
              "  0.3499999940395355,\n",
              "  0.375,\n",
              "  0.36250001192092896,\n",
              "  0.38749998807907104,\n",
              "  0.3125,\n",
              "  0.36250001192092896,\n",
              "  0.3499999940395355,\n",
              "  0.3125,\n",
              "  0.26249998807907104,\n",
              "  0.36250001192092896,\n",
              "  0.375,\n",
              "  0.2874999940395355,\n",
              "  0.3499999940395355,\n",
              "  0.3375000059604645,\n",
              "  0.30000001192092896,\n",
              "  0.32499998807907104,\n",
              "  0.2750000059604645,\n",
              "  0.3499999940395355,\n",
              "  0.3499999940395355,\n",
              "  0.30000001192092896,\n",
              "  0.3375000059604645,\n",
              "  0.36250001192092896,\n",
              "  0.36250001192092896,\n",
              "  0.375]}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot training performance"
      ],
      "metadata": {
        "id": "54D1y5fZcRUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'co', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'k', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'co', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Aig-yHOBcNrP",
        "outputId": "22cb87b3-bfc6-4928-867a-bb4b66434482",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('./content/drive/My Drive/new', exist_ok=True)\n",
        "model.save('./content/drive/My Drive/new/newdata_SEM3.h5')"
      ],
      "metadata": {
        "id": "f_Xlg2XSuT9L"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "HuBli3HajIR2"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"./content/drive/My Drive/new/newdata_SEM3.h5\")"
      ],
      "metadata": {
        "id": "zblzwvRGkSCR",
        "outputId": "17e45912-33b7-4293-a1c1-f59ceabd31ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_22c4d8f1-eee4-4e1e-b280-57fb48ce7777\", \"newdata_SEM3.h5\", 16615536)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}